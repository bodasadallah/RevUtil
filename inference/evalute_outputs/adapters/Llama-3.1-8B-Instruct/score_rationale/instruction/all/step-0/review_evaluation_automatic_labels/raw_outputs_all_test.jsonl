{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the authors are using a min-max optimization, which is challenging to train and apply, especially for PDEs with advective terms. It notes that the methodology provided seems to outperform the baselines but expresses concern about the clarity of the presentation and the lack of detailed steps. However, the comment does not provide explicit guidance or suggestions on how the authors should revise the paper to address these issues. The action is implicit and vague, as the authors are left to infer that they need to improve the clarity of their presentation and methodology without specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the methodology used by the authors, specifically mentioning min-max optimization and its challenges, particularly for PDEs with advective terms. It suggests that the paper would benefit from a revision due to the lack of clarity in the presentation and the precise steps involved. However, the comment does not specify which part of the paper is unclear or needs revision, making it weakly grounded. The authors can infer that it relates to the methodology section, but without explicit references, it is challenging to pinpoint the exact areas needing attention. The comment is specific in suggesting a need for clarity and revision but lacks grounding, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that min-max optimization is \"hard to train and get right,\" especially for PDEs with advective terms. It also suggests that the paper would benefit from a revision due to the lack of clarity in the presentation and the precise steps involved. However, the comment lacks specific examples or detailed reasoning to support the claim about the difficulty of min-max optimization for PDEs. Additionally, it does not provide examples of how the presentation could be improved or what specific steps are unclear. This makes the claim somewhat verifiable, as it provides a general assertion but lacks detailed evidence or examples to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges the challenges associated with min-max optimization, particularly for PDEs with advective terms. It notes that the methodology provided by the authors seems to outperform the baselines but expresses concern about the clarity of the presentation and the lack of detailed steps. While the comment identifies a potential issue with the paper's clarity, it does not provide specific suggestions or guidance on how to improve the presentation or methodology. This limits the helpfulness of the feedback, as the authors are left without actionable steps to enhance their draft. Therefore, the comment is rated as barely helpful, aligning with a score of 2.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the practical application of the original proposal (Algorithm 1) compared to the modified TD learning algorithm defined in Definition 5.1. It does not provide explicit guidance or suggestions on how the authors should address this question or what changes they should make to their draft. The action is implicit and vague, as the authors are left to infer that they need to provide a justification or comparison between the two algorithms. However, the comment does not specify how to do this, making it difficult for the authors to know exactly what steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 5.1\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the practical use of the original proposal (Algorithm 1) over the modified TD learning algorithm defined in Definition 5.1, providing a clear direction for the authors to address this issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the practical application of the original proposal (Algorithm 1) compared to the modified TD learning algorithm defined in Definition 5.1. However, it does not provide any supporting evidence, reasoning, or references to justify why the original proposal should be used over the modified algorithm. The lack of justification or examples makes it difficult for the authors to understand the basis of the question, rendering the comment unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the practical application of the original proposal (Algorithm 1) compared to the modified TD learning algorithm defined in Definition 5.1. It prompts the authors to justify why the original proposal should be used over the modified algorithm in practice. This feedback is clear and actionable, as it encourages the authors to provide a rationale for their choice and potentially explore the implications of using the modified algorithm. However, the comment could be more helpful if it offered suggestions on how to address this question or provided examples of scenarios where the original proposal might be preferred. Overall, the comment is mostly helpful, as it directs the authors to a critical area of their work that requires further justification or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the practical utility of the data quality metric proposed in the paper, specifically the diversity coefficient. It notes that the paper does not empirically validate this claim, which is a significant concern given the emphasis on Task2Vec and model diversity. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific steps to take. The action is implicit, as the authors need to infer that they should conduct empirical validation to support their claim. The feedback lacks concrete details on how to implement this validation, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"data quality metric\" and the \"diversity coefficient,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of empirical validation of the claim, which is a significant concern given the emphasis on Task2Vec and model diversity. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper suggests the diversity coefficient as a potential data quality metric but does not empirically validate this claim. The reviewer highlights the concern, especially given the emphasis on Task2Vec and model diversity in the paper. However, the comment lacks specific examples or references to support the claim that the diversity coefficient is not empirically validated. This makes the claim somewhat verifiable, as it provides a logical reasoning but lacks detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the practical utility of the data quality metric proposed in the paper, specifically the diversity coefficient. It points out that the paper does not empirically validate this claim, which is a critical issue given the emphasis on Task2Vec and model diversity. This feedback is clear and actionable, as it highlights a specific area where the authors need to provide empirical validation to support their claims. However, the comment could be more helpful if it suggested specific methods or experiments that could be conducted to validate the diversity coefficient. Overall, the comment is mostly helpful as it directs the authors to a critical area that requires further investigation and validation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that using canary clients might be less efficient compared to using canary examples, implying that more resources might be needed. However, the comment does not provide explicit guidance on how to address this issue or suggest alternative methods for improving efficiency. The action is implicit and vague, as the authors are left to infer that they should consider alternative approaches but are not given concrete steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that using canary clients might be less efficient compared to using canary examples, implying that more resources might be needed. However, it does not specify which part of the paper discusses canary clients or examples, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not provide detailed guidance on how to address the potential inefficiency or suggest alternative methods. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that using canary clients might be less efficient compared to using canary examples, implying that more resources might be needed. However, the comment lacks specific evidence or reasoning to support this claim. It does not provide examples, references, or detailed explanations of why canary clients are less efficient, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that using canary clients might be less efficient compared to using canary examples, implying that more resources might be needed. While this observation highlights a potential area for improvement, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue or explore alternative methods. Without detailed suggestions or examples, the feedback is somewhat helpful as it points out a potential inefficiency but does not fully support the authors in making improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the relevance of Carefl to the paper and suggests that it might be a standard definition of a nonlinear SEM, similar to Equation (4) in \"On Causal Discovery with Cyclic Additive Noise Models.\" However, it does not provide explicit guidance or suggestions on how the authors should address this issue or clarify the relevance of Carefl. The comment implies that the authors should provide more context or explanation regarding Carefl, but it lacks concrete steps or details on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (6)\" and \"Equation (4) in \u201cOn Causal Discovery with Cyclic Additive Noise Models\u201d,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the relevance of Carefl and suggests that it might be a standard definition of a nonlinear SEM, providing a reference for comparison. This level of detail helps the authors understand what needs to be addressed in terms of clarifying the relevance of Carefl. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the relevance of Carefl to the paper, suggesting that it might be a standard definition of a nonlinear SEM, similar to Equation (4) in \"On Causal Discovery with Cyclic Additive Noise Models.\" The reviewer provides a specific reference to support their claim, which is a common practice in the field. This level of detail and reference makes the claim mostly verifiable, as it provides a clear basis for the reviewer\\'s skepticism about the novelty of Carefl. However, the comment could be strengthened by further elaboration or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a question about the relevance of Carefl to the paper, suggesting that it might be a standard definition of a nonlinear SEM, similar to Equation (4) in \"On Causal Discovery with Cyclic Additive Noise Models.\" This feedback prompts the authors to clarify the significance of Carefl in their work, which could be an important aspect of their methodology. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or provide additional context to support the relevance of Carefl. While it identifies a potential area for clarification, the feedback is somewhat helpful as it points out a gap in the paper but does not fully support the authors in resolving it. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the approach, noting that it is compute-intensive due to the need for pretraining the GAA model on the same dataset as the QA model. It also questions the assumption that the resultant GAA model is performant enough to provide meaningful prompts to annotators, which could lead to longer annotation times. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the approach. The action is implicit and vague, as the authors are left to infer that they should investigate ways to reduce computational intensity or improve the performance of the GAA model. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the compute-intensity of the approach due to the pretraining of the GAA model on the same dataset as the QA model. It questions the assumption that the resultant GAA model is performant enough to provide meaningful prompts to annotators, which could impact the speedup claim of the proposed approach. However, the comment does not specify which part of the paper discusses this aspect, making it weakly grounded. The comment is specific in detailing the issue with the approach, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the compute-intensity of the approach, specifically the pretraining of the GAA model on the same dataset as the QA model. It questions the assumption that the resultant GAA model is performant enough to provide meaningful prompts to annotators, which could lead to longer annotation times. However, the comment lacks specific examples or references to support the claim that the approach is compute-intensive or that the assumption about the GAA model\\'s performance is problematic. Without detailed evidence or reasoning, the claim remains somewhat verifiable, as the authors would need to investigate further to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the approach, specifically its compute-intensity due to the pretraining of the GAA model on the same dataset as the QA model. It questions the assumption that the resultant GAA model is performant enough to provide meaningful prompts to annotators, which could lead to longer annotation times and challenge the speedup claim of the proposed approach. This feedback is somewhat helpful as it highlights a critical aspect of the methodology that needs further consideration. However, it lacks specific suggestions or guidance on how the authors might address this issue, such as exploring alternative training strategies or evaluating the performance of the GAA model. Therefore, while the comment points out a relevant concern, it could be more helpful with additional actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed method, noting its high dependence on the server dataset, which significantly limits its potential use cases and reduces its generality. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might mitigate this limitation or improve the generality of their method. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the dependence of the proposed method on the server dataset, which limits its potential use cases and reduces its generality. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the limitation but lacks grounding, as it does not provide a clear reference to the part of the paper being discussed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method has a high dependence on the server dataset, which limits its potential use cases and reduces its generality. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed explanation makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the proposed method, noting its high dependence on the server dataset, which restricts its potential use cases and reduces its generality. This feedback is valuable as it highlights a critical area for improvement, prompting the authors to consider ways to enhance the method\\'s applicability and robustness. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation, such as proposing alternative approaches or strategies to reduce dependence on the server dataset. While it points out an important issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of providing only a single downstream search method, EA, and suggests that other methods like BO and LS should be included. While the comment implies that the authors should consider adding these methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should expand their analysis to include additional methods. However, the suggestion is concrete in terms of what methods to consider, providing some guidance on how to improve the draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the choice of providing only a single downstream search method, EA, and suggests adding other methods like BO and LS. However, it does not specify which part of the paper this critique pertains to, such as a specific section or table discussing search methods. Without explicit references, the authors may find it challenging to identify the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of additional methods, but it lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of providing only a single downstream search method, EA, and suggests that other methods like BO and LS should be included. However, the comment does not provide any reasoning or justification for why these additional methods should be considered or how they would enhance the paper. Without supporting evidence or examples, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the limited scope of the paper by pointing out that only a single downstream search method (EA) is provided, suggesting that other methods like BO and LS should be included. This feedback is somewhat helpful as it identifies a potential limitation in the paper and provides a clear suggestion for expansion. However, the comment lacks depth and does not offer specific guidance on why these additional methods are important or how they might enhance the paper. While it prompts the authors to consider broader coverage, it does not fully address their needs for improving the draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missing comparison between the FLOPs and FPS of the proposed pDETR model and other sparse models. It explicitly suggests that the paper should include a direct comparison with other sparse models, as FLOPs for pDETR are listed in Table 7. This feedback provides a clear and concrete action for the authors to take, which is to include a direct comparison with other sparse models. The comment is explicit and provides specific guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the need for a direct comparison of FLOPs and FPS with other sparse models, which is missing in the paper. This provides clear guidance on what needs to be addressed to improve the draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not sufficiently highlight the comparison of FLOPs and FPS in sparse network research. It supports this claim by noting that while FLOPs for pDETR are listed in Table 7, a direct comparison with other sparse models is missing. This provides a logical reasoning for the claim, as it highlights a gap in the paper\\'s analysis. However, the comment could be strengthened by providing specific examples of other sparse models that should be compared or by referencing relevant literature. Overall, the claim is mostly verifiable, as it provides a clear rationale but lacks detailed examples or references to fully substantiate the claim. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved: the lack of a direct comparison of FLOPs and FPS between the proposed pDETR model and other sparse models. It highlights that while FLOPs for pDETR are listed in Table 7, a comparison with other sparse models is missing. This feedback is clear and actionable, as it provides a clear direction for the authors to enhance their analysis by including a direct comparison. However, the comment could be more helpful if it suggested specific models or metrics to compare or offered guidance on how to present this comparison effectively. Overall, the comment is mostly helpful as it directs the authors to a significant improvement in their draft, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the metrics described in Appendix A.1, indicating that they are hard to understand and making it unclear what the numbers in the result tables mean. The reviewer provides a concrete example by explaining that if the accuracy for binary boolean questions in Table 5 is calculated by dividing the number of correct answers by the total number of questions, a specific scenario would yield an accuracy of 97%, which is deemed incorrect. This example provides a clear and actionable step for the authors to take, as it suggests that they should clarify the metrics used and ensure that the calculations are accurate. The comment is explicit in its action and provides concrete details on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix A.1\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the metrics, explaining that they are hard to understand and providing a concrete example of how the accuracy calculation in Table 5 could be misleading. This example helps the authors understand what needs to be clarified or corrected. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the metrics described in Appendix A.1 are hard to understand, leading to unclear results in the tables. It provides a specific example by explaining that if the accuracy for binary boolean questions in Table 5 is calculated by dividing the number of correct answers by the total number of questions, a particular scenario would yield an accuracy of 97%, which is deemed incorrect. This example offers a clear and logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed explanations or references to support the claim about the metrics being hard to understand. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the metrics described in Appendix A.1, noting that they are hard to understand and making it unclear what the numbers in the result tables mean. It provides a concrete example by explaining that if the accuracy for binary boolean questions in Table 5 is calculated in a certain way, it would yield an accuracy of 97%, which is deemed incorrect. This feedback is clear and actionable, as it highlights a potential misunderstanding in the metrics and suggests that the authors should clarify the calculations or explanations to ensure accuracy. By providing a specific example, the comment offers a detailed and constructive suggestion for improvement, making it highly helpful for the authors to address the issue and enhance the clarity of their work.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the Gaussian assumption in the analysis and its applicability in practice. It asks whether the situation where r << N is typical, whether it is always possible to compute the \"effective\" variance for non-Gaussian outputs, and whether there is a finite-N expansion that characterizes the departure from Gaussianity in the non-ideal case. While these questions imply that the authors should consider these aspects in their analysis, they do not provide explicit instructions or suggestions on how to address them. The actions are implicit and somewhat vague, as the authors need to infer that they should investigate these questions further. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the Gaussian assumption in the analysis, specifically asking if it is typical in practice and whether it is always possible to compute the \"effective\" variance for non-Gaussian outputs. It also inquires about a finite-N expansion that characterizes the departure from Gaussianity in the non-ideal case. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the theoretical or methodological sections where the Gaussian assumption is discussed. The comment is specific in detailing what needs to be addressed, such as the applicability of the Gaussian assumption and the possibility of computing the \"effective\" variance. However, it lacks full grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several questions about the applicability of the Gaussian assumption in the analysis, specifically asking if it is typical in practice, whether it is always possible to compute the \"effective\" variance for non-Gaussian outputs, and if there is a finite-N expansion that characterizes the departure from Gaussianity in the non-ideal case. While the questions are logical and relevant, they do not provide any supporting evidence, references, or detailed reasoning to substantiate the claims. The lack of specific examples or references makes it difficult for the authors to understand the context and address the concerns effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises important questions about the applicability of the Gaussian assumption in the analysis, specifically in the context of r << N. It questions whether this situation is typical in practice and whether it is always possible to compute the \"effective\" variance for non-Gaussian outputs. Additionally, it asks if there is a finite-N expansion that characterizes the departure from Gaussianity in the non-ideal case. These questions prompt the authors to consider the practical implications and limitations of their analysis, which could lead to a more comprehensive understanding and presentation of their results. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address these questions or if it offered examples of how to explore these issues further. Overall, the comment is somewhat helpful as it identifies areas for further exploration and improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the approach to the math and science categories, suggesting that it may be related to an open vocabulary problem that is not adequately addressed. It contrasts this with other categories, which use Wikipedia and a popularity metric. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their approach. The action is implicit and vague, as the authors are left to infer that they need to address the open vocabulary problem but are not given specific steps or methods to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the approach to the math and science categories, suggesting an open vocabulary problem that is not clearly tackled. It contrasts this with other categories, which use Wikipedia and a popularity metric. However, the comment does not specify which part of the paper discusses these categories or provide detailed guidance on how to address the open vocabulary problem. The authors can infer that the issue is related to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. Additionally, while it highlights a specific issue, it does not provide detailed suggestions for improvement. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the approach to the math and science categories suggests an open vocabulary problem that is not clearly addressed. It contrasts this with other categories, which use Wikipedia and a popularity metric. However, the comment lacks specific examples or detailed reasoning to support the claim about the open vocabulary problem in the math and science categories. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the approach to the math and science categories, suggesting that it may be related to an open vocabulary problem that is not clearly addressed. It contrasts this with other categories, which use Wikipedia and a popularity metric, implying that the authors should consider how to tackle the open vocabulary problem in the math and science categories. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending alternative methods or providing examples of how to incorporate Wikipedia or popularity metrics into the math and science categories. While it highlights a potential area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the similarity between the current work and stochastic routing warrants a more thorough discussion. However, it does not provide explicit guidance on what aspects of the similarity should be discussed or how to conduct this discussion. The action is implicit, as the authors need to infer that they should delve deeper into the comparison, but it lacks concrete details on how to execute this action. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the similarity between the current work and stochastic routing warrants a more thorough discussion. However, it does not specify which part of the paper this similarity is being discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the similarity should be discussed or how the discussion should be conducted. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the similarity between the current work and stochastic routing warrants a more thorough discussion. However, it does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the suggestion. The comment lacks verifiable evidence or references to substantiate the claim, leaving it unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the similarity between the current work and stochastic routing warrants a more thorough discussion. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how the authors should approach this discussion. The comment does not offer actionable steps or suggestions on what aspects of the similarity should be explored or how to conduct the discussion. As a result, the feedback is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that convergence in direction should be considered as convergence, given that the CE (cross-entropy) loss can never be minimized due to its exponential nature. However, the comment does not provide explicit guidance on how the authors should incorporate this consideration into their draft. The action is implicit, as the authors need to infer that they should address this aspect, and it is vague because it lacks concrete steps or examples on how to implement this consideration. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that convergence in direction should be considered as convergence, given the nature of the CE loss. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its suggestion but lacks grounding, as it does not provide a clear reference to the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that convergence in direction should be considered as convergence due to the nature of the CE loss, which cannot be minimized because of its exponential nature. This claim is somewhat verifiable as it provides a logical reasoning based on the properties of the CE loss. However, the comment lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that convergence in direction should be considered as convergence, given the nature of the CE loss, which cannot be minimized due to its exponential nature. This feedback is somewhat helpful as it points out a potential misunderstanding or misinterpretation in the paper regarding convergence. However, the comment lacks depth and does not provide specific guidance or examples on how the authors should address this issue or how it affects their analysis. While it highlights a potential area for clarification, it does not offer actionable steps for improvement, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should have tested the robustness of their proposed framework by replacing components with other models, as they claim that components can be replaced for flexibility. However, the comment does not provide explicit guidance on how to conduct these tests or which models to use as alternatives. The action is implicit, as the authors need to infer that they should conduct experiments with different models, but it is vague because it lacks specific details on how to implement this. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of the authors claiming that components can be replaced for flexibility but not attempting any changes or alternatives in the paper to prove the robustness of the proposed framework. However, it does not specify which part of the paper this claim is based on, such as a particular section or experiment, making it weakly grounded. The comment is specific in its critique of the lack of testing for robustness, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors did not test the robustness of their proposed framework by replacing components with other models, despite stating that components can be replaced for flexibility. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim is not fully verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out a potential weakness in the paper, noting that while the authors claim components can be replaced for flexibility, they did not attempt to test this claim by replacing components with other models to prove the robustness of the proposed framework. This feedback highlights an area where the authors could strengthen their work by providing empirical evidence or experiments to support their claims. However, the comment lacks specific suggestions or guidance on how to conduct these tests or which models to use as alternatives. While it identifies a relevant area for improvement, the lack of detailed advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of the number of disentangled factors in the Atari game experiments, specifically asking how this number was determined to be 30. While the comment does not provide explicit instructions or suggestions for improvement, it implies that the authors should clarify or justify their choice of 30 disentangled factors. This inference is concrete, as the authors know they need to address the rationale behind this choice. However, the comment does not provide specific guidance on how to address this issue, making it somewhat actionable. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the Atari game experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of the number of disentangled factors, which is a clear and actionable point for the authors to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of 30 disentangled factors in the Atari game experiments, suggesting that this might be difficult to specify for an arbitrary domain. However, the comment does not provide any supporting evidence, reasoning, or references to justify why 30 is an inappropriate choice or how it might be challenging to specify. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the choice of the number of disentangled factors in the Atari game experiments, which is a clear and actionable point for the authors to address. By questioning the rationale behind this choice, the comment prompts the authors to provide a justification or explanation for their selection, which could enhance the clarity and robustness of their work. However, the comment could be more helpful if it offered suggestions or guidance on how to address this issue or provided examples of alternative approaches. Overall, the comment is somewhat helpful as it identifies a potential area for improvement but lacks depth in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies colloquial expressions as unprofessional and provides a specific example, \"By the way, our training stage \u2026 \u2026\". This feedback is clear and actionable, as it instructs the authors to avoid using colloquial expressions in their writing. The comment provides a concrete example of what needs to be changed, allowing the authors to directly apply the suggested action to their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific colloquial expression, \"By the way,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of colloquial expressions, providing a concrete example of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"Colloquial expressions are unprofessional\" and provides a specific example, \"By the way, our training stage \u2026 \u2026\". This claim is supported by the example, which clearly illustrates the use of colloquial language. However, the comment could be strengthened by explaining why colloquial expressions are considered unprofessional or providing additional context or references to substantiate the claim. Despite this, the example provided is sufficient to support the claim, making it mostly verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of colloquial expressions in the paper, such as \"By the way,\" which is considered unprofessional. This feedback is clear and actionable, as it provides a concrete example of what needs to be avoided in the writing. By pointing out this issue, the comment helps the authors to improve the professionalism and clarity of their draft. However, the comment could be more helpful if it suggested alternative ways to express the same idea without using colloquial language. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the abbreviations \"LLH,\" \"OOD,\" and \"ECE\" are used without definition or explanation, despite being pivotal metrics in the work. This feedback explicitly instructs the authors to define these abbreviations and provide explanations for the readers. The action is clear and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abbreviations \"LLH,\" \"OOD,\" and \"ECE,\" allowing the authors to accurately identify the parts of the paper where these abbreviations are used. It is also specific because it clearly specifies the issue by pointing out that these abbreviations are not defined, which is crucial for the reader\\'s understanding. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abbreviations \"LLH,\" \"OOD,\" and \"ECE\" are used without definition or explanation, which is a critical issue for clarity. The comment provides a logical reasoning by pointing out the absence of definitions for these pivotal metrics, which is a common practice in academic writing. However, it does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to verify the claim by checking the paper\\'s content and ensuring that these abbreviations are indeed undefined. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically that the abbreviations \"LLH,\" \"OOD,\" and \"ECE\" are used without definition or explanation. This is a significant oversight, as these abbreviations are pivotal metrics in the work. By pointing out this lack of clarity, the comment provides the authors with a clear and actionable suggestion to define these abbreviations and provide explanations for the readers. This feedback is highly helpful as it directly addresses a critical aspect of the paper\\'s clarity and comprehensibility, allowing the authors to make a significant improvement. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the stability of the proposed method when stacking multiple layers of WLS units, given the potential failure of stochastic/random projection at each layer. It suggests that the authors should justify the stability of their method and address the impact of stacking more layers. While the comment implies that the authors should provide additional justification and analysis, it does not explicitly instruct them on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to address the concern. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"stochastic/random projection\" and \"stacking multiple layers of WLS units,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the concern about the stability of the proposed method when stacking layers and suggests that the authors should justify this stability. The comment provides a clear direction for the authors to address the issue by questioning the stability and potential impact of stacking more layers. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the stability of the proposed method when stacking multiple layers of WLS units, given the potential failure of stochastic/random projection at each layer. The reviewer suggests that this could hinder the formation of deeper GNNs and requests justification for the stability of the proposed method. While the comment identifies a potential issue, it does not provide specific evidence, examples, or references to support the claim. The reasoning is logical but lacks detailed justification, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the stability of the proposed method when stacking multiple layers of WLS units, given the potential failure of stochastic/random projection at each layer. It highlights a potential issue that could hinder the formation of deeper GNNs and suggests that the authors should justify the stability of their method. The comment is specific in its request for justification and provides a clear direction for the authors to address the concern. However, it could be more helpful if it offered suggestions on how to address the stability issue or provided examples of how to evaluate it. Overall, the comment is mostly helpful as it identifies a critical area for improvement and guides the authors toward a solution, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a lack of clarity in certain sections of the paper, specifically mentioning the computation of the Bottleneck Distance in Definition 4.1. However, it does not provide explicit guidance on how to improve the clarity or suggest specific changes that the authors could make. The action is implicit, as the authors can infer that they need to clarify this section, but it is vague because it does not specify how to achieve this clarity. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a lack of clarity in certain sections of the paper, specifically mentioning the computation of the Bottleneck Distance in Definition 4.1. This provides full grounding as it explicitly mentions a specific part of the paper, allowing the authors to accurately identify the section that needs clarification. The comment is also specific because it details the issue with the computation of the Bottleneck Distance, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"Some sections of the paper lack clarity, such as the computation of the Bottleneck Distance in Definition 4.1.\" However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable, as it lacks sufficient evidence or justification to substantiate the claim.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of certain sections in the paper, particularly the computation of the Bottleneck Distance in Definition 4.1. This feedback is somewhat helpful as it points out a potential issue that the authors should address to improve the comprehensibility of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how to clarify the computation or improve the clarity of the section. While it directs the authors' attention to a potential problem, it does not offer actionable steps to resolve it, limiting its helpfulness. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper\\'s visualization (Fig 5) is weaker compared to Balikas COLING16\\'s work, which raises doubts about the actual segmenting and assigning results of the document. The reviewer provides a specific action by recommending that the authors include a longer exemplar and ensure consistent color assignment with the topics listed in Figure 4. This feedback is explicit and provides concrete guidance on how to improve the visualization, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 5\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the visualization, suggesting that the authors provide a longer exemplar and ensure consistent color assignment with the topics listed in Figure 4. This provides clear guidance on what needs to be improved. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s visualization is weaker compared to Balikas COLING16\\'s work, specifically mentioning Figure 5. However, it does not provide any specific examples or detailed comparisons to support this claim. The suggestion to include a longer exemplar and consistent color assignment is logical but lacks evidence or references to substantiate the initial claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but lacks sufficient detail or references to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s visualization, noting that it is weaker compared to Balikas COLING16\\'s work. It provides a clear suggestion for improvement by recommending the inclusion of a longer exemplar and ensuring consistent color assignment with the topics listed in Figure 4. This feedback is actionable and provides the authors with a concrete way to enhance the clarity and effectiveness of their visualization, which is crucial for understanding the segmenting and assigning results of the document. However, the comment could be more helpful if it included a comparison of the two works or further elaborated on the specific aspects of the visualization that need improvement. Overall, the comment is mostly helpful as it offers a clear direction for enhancing the paper\\'s visual presentation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the necessity of using a parameter-efficient training method with the P5-small backbone model, which is considered small. However, it does not provide any explicit or implicit guidance on how the authors should address this concern or suggest alternative approaches. The comment lacks actionable details, leaving the authors without a clear understanding of what changes might be needed or how to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of \"P5-small\" as the backbone model, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of using a parameter-efficient training method with a small model, providing a clear direction for the authors to address this concern. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of using a parameter-efficient training method with the P5-small backbone model, suggesting that the choice is unclear. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or how it could be improved. Without additional context or explanation, the claim remains unverifiable, as the authors are left without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the choice of using a parameter-efficient training method with the P5-small backbone model, suggesting that the purpose of this choice is unclear. While it identifies a potential area of confusion, the comment lacks depth and does not provide any specific suggestions or guidance on how the authors might address this issue or improve their draft. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their work. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors\\' proposal for creating a challenging set is specific and not scalable. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the proposal more general or scalable, nor are there any suggestions for specific changes or improvements. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a general observation about the authors\\' proposal for creating a challenging set, noting that it seems specific and not scalable. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to identify the exact section or aspect being addressed. Additionally, the comment lacks specificity regarding what aspects of the proposal are specific or how it could be made more scalable. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors\\' proposal for creating a challenging set is specific and not scalable. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors\\' proposal for creating a challenging set, suggesting that it is specific and not scalable. However, it does not provide specific guidance or suggestions on how the authors might address this issue or make their proposal more generalizable. Without actionable feedback or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential concern about the proposed method\\'s reliance on the optimal value function corresponding to the reward function. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or suggestions for improvement. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the proposed method\\'s reliance on the optimal value function corresponding to the reward function. However, it does not specify which part of the paper this issue is discussed in, nor does it provide details on what specific aspects of this reliance are problematic. Without explicit references or detailed explanations, the authors cannot confidently identify the exact sections that need attention or improvement. This makes the comment not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a concern about the proposed method\\'s reliance on the optimal value function corresponding to the reward function. However, it does not provide any supporting evidence, reasoning, or examples to justify why this reliance is a strong one. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential concern about the proposed method\\'s reliance on the optimal value function corresponding to the reward function. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the approach is derivative, combining two existing approaches, and notes that it is not inherently bad. However, it does not provide any specific guidance or suggestions for improvement. The comment lacks actionable details, such as what aspects of the derivative approach could be enhanced or how it could be differentiated from existing work. Without explicit or implicit instructions on how to address the issue, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the overall approach of the paper, noting that it is derivative, combining two existing approaches. However, it does not specify which parts of the paper this assessment pertains to, such as specific sections or figures. The comment lacks grounding as it does not provide a clear reference to the paper, making it difficult for the authors to identify the exact parts that need attention. Additionally, the comment is not specific, as it does not detail what aspects of the derivative approach are problematic or how it could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the approach is \"derivative,\" combining two existing approaches. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is a concern or how it affects the paper\\'s originality or contribution. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the approach is derivative, combining two existing approaches, and notes that it is not inherently bad. However, it does not provide any specific feedback or suggestions for improvement. The comment lacks depth and does not offer any actionable advice on how the authors might enhance their work or differentiate it from existing approaches. Without detailed guidance or constructive feedback, the authors are left without a clear path for improvement, making the comment not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of comparisons against other potential baseline approaches in the evaluation, suggesting that a simple photographic style transfer method could achieve similar or better effects. While the comment implies that the authors should include comparisons with other methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add comparisons but are not provided with specific guidance on which methods to include or how to conduct the comparisons. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"motivation\" and the lack of comparisons against other potential baseline approaches in the evaluation. It also provides a specific example of a simple photographic style transfer method that could achieve similar or better effects, which gives the authors clear guidance on what needs to be addressed. This level of detail allows the authors to accurately identify the part of the paper being addressed and understand what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are no comparisons against other potential baseline approaches in the evaluation, suggesting that a simple photographic style transfer method could achieve similar or better effects. The reviewer provides a specific example of a method that could be used for comparison, which supports the claim. However, the comment lacks detailed reasoning or references to other studies that have used similar methods, which would strengthen the argument. Overall, the claim is mostly verifiable, as it provides a clear suggestion for improvement but could benefit from additional evidence or references to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the evaluation section of the paper, noting the absence of comparisons against other potential baseline approaches. It provides a specific example of a simple photographic style transfer method that could achieve similar or better effects, suggesting that this comparison would be valuable. This feedback is clear and actionable, as it directs the authors to consider including additional comparisons to enhance the robustness and validity of their results. However, the comment could be more helpful if it offered suggestions on which specific baseline methods to consider or how to conduct the comparisons. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the clarity of the paper, particularly regarding the mapping of symbols in Figure 2 to those in the equations. It explicitly identifies the need for the authors to explain the meaning of C_i, Q_i, R_i, A_i, and S_i in the context of the proposed method. The comment also points out a discrepancy between S_i in Figure 2 and the calligraphic S_j in line 431, suggesting that the authors should clarify how to compute S_i. This feedback provides clear and concrete actions for the authors to take, such as explaining the symbols and clarifying the computation of S_i. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"line 431,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the mapping of symbols in Figure 2 and the lack of explanation for C_i, Q_i, R_i, A_i, and S_i. Additionally, it points out a discrepancy between S_i in Figure 2 and the calligraphic S_j in line 431, suggesting that the authors should clarify how to compute S_i. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the difficulty in mapping symbols in Figure 2 to those in the equations makes it hard to understand the proposed method. It provides specific examples of symbols (C_i, Q_i, R_i, A_i, and S_i) that are not explained, which supports the claim. Additionally, it points out a discrepancy between S_i in Figure 2 and the calligraphic S_j in line 431, suggesting that the authors should clarify how to compute S_i. This level of detail provides a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more context or references to similar issues in the literature, which would further support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper, particularly regarding the mapping of symbols in Figure 2 to those in the equations. It highlights the difficulty in understanding the proposed method due to the lack of explanation for symbols like C_i, Q_i, R_i, A_i, and S_i. The comment also points out a discrepancy between S_i in Figure 2 and the calligraphic S_j in line 431, suggesting that the authors should clarify how to compute S_i. This feedback is clear and actionable, providing the authors with specific areas to address in order to improve the clarity and comprehensibility of their work. By addressing these issues, the authors can enhance the readability and understanding of their paper, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should study the number of backtracking steps and the acceptance rate in addition to the hyper-parameter $I$. It implies that these aspects could be important for understanding the results and potentially require tuning. However, the comment does not provide explicit guidance on how to conduct this study or what specific steps to take. The action is implicit and somewhat vague, as the authors can infer that they need to explore these additional factors but are not given concrete instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should study the number of backtracking steps and the acceptance rate in addition to the hyper-parameter $I$. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where these parameters are discussed. Without explicit references, the authors may find it challenging to identify the exact parts of the paper that need revision. The comment is specific in suggesting additional studies, but it lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should study the number of backtracking steps and the acceptance rate in addition to the hyper-parameter $I$. The comment implies that these additional factors could be important for understanding the results and potentially require tuning. However, the comment does not provide specific reasoning, examples, or references to support why these factors are crucial or how they might impact the results. The lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of these factors based on the context of the paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should consider studying the number of backtracking steps and the acceptance rate in addition to the hyper-parameter $I$. This feedback is somewhat helpful as it identifies a potential area for further exploration that could enhance the understanding and robustness of the results. However, the comment lacks specific guidance on how to conduct this study or what specific insights might be gained from it. While it points out a potential area for improvement, it does not provide detailed actionable steps or suggestions, limiting its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the objective function for GSdyn and FABOLAS, specifically asking whether the accuracy is based on the validation or test dataset. This comment is explicit in its request for clarification, as it directly asks the authors to specify the objective function and provide details about the accuracy. However, it does not provide guidance on how to address the issue or suggest specific steps for clarification. The action is clear but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by asking for clarification on the objective function for GSdyn and FABOLAS, particularly regarding the accuracy metric used. The comment requests details about whether the accuracy is based on the validation or test dataset, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the objective function for GSdyn and FABOLAS, specifically asking whether the accuracy is based on the validation or test dataset. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual question seeking additional information, making it a normal statement. Therefore, the label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the objective function for GSdyn and FABOLAS, asking for clarification on whether the accuracy is based on the validation or test dataset. This feedback is clear and actionable, as it prompts the authors to provide a precise answer to this question, which could help clarify the methodology and results presented in the paper. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue or its implications for the study. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests rearranging the structure of the paper by moving section 3.1 to the related work section and reorganizing the content to create a new section 3 that focuses on the proposal. This provides a clear and explicit action for the authors to take, as it specifies exactly what needs to be done to improve the draft. The suggestion is concrete, offering a specific way to reorganize the content, which makes it highly actionable. Therefore, the comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests rearranging the structure of the paper by moving section 3.1 to the related work section and reorganizing the content to create a new section 3 that focuses on the proposal. It explicitly mentions \"section 3.1\" and \"section 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. The comment is specific in suggesting how the sections should be rearranged to improve the organization of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests rearranging the structure of the paper by moving section 3.1 to the related work section and reorganizing the content to create a new section 3 that focuses on the proposal. However, the comment does not provide any reasoning or justification for why this rearrangement would be beneficial or how it would improve the clarity or coherence of the paper. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a structural rearrangement of the paper by proposing that section 3.1 be moved to the related work section and reorganizing the content to create a new section 3 that focuses on the proposal. This feedback is clear and actionable, providing the authors with a specific suggestion to improve the organization and flow of their paper. By making this change, the authors can better structure their work and enhance its clarity. However, the comment could be more helpful if it included additional guidance on how this rearrangement might impact the overall narrative or if it suggested any potential benefits or drawbacks of this change. Overall, the comment is mostly helpful as it offers a constructive suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how to efficiently obtain the priors and requests examples. It also implies that the authors lack a practical method for obtaining the required prior {$U_{k_n}$}, as inferred from the numerical experiment section. While the comment does not explicitly instruct the authors to provide examples or a practical method, it does suggest that these are necessary improvements. The action is implicit but concrete, as the authors know they need to address the lack of a practical method and provide examples. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"numerical experiment section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking a practical way to obtain the required prior {$U_{k_n}$} and requests examples. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the efficiency of obtaining priors and requests examples. It also makes an observation about the lack of a practical method for obtaining the required prior {$U_{k_n}$} based on the numerical experiment section. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the authors lack a practical method. This lack of evidence makes the claim difficult for the authors to address effectively, as they are left without a clear understanding of the issue or how to resolve it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific concern about the efficiency of obtaining priors and requests examples. It also points out a potential issue with the practicality of obtaining the required prior {$U_{k_n}$} based on the numerical experiment section. This feedback is clear and actionable, as it prompts the authors to address a critical aspect of their methodology. By providing examples, the authors can clarify their approach and improve the transparency and reproducibility of their work. However, the comment could be more helpful if it offered suggestions on how to improve the efficiency or practicality of obtaining these priors. Overall, the comment is mostly helpful as it identifies a key area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors perform additional evaluation on the VOT dataset using different metrics like Accuracy, Robustness, and EAO, in addition to the existing evaluation on OTB-50, OTB-100, OTB-2015, and LASOT datasets. This is an explicit action with concrete details on how to implement it, as it specifies the additional evaluation and metrics to be considered. The authors know exactly what needs to be done to enhance their evaluation, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the datasets used for evaluation (OTB-50, OTB-100, OTB-2015, and LASOT) and suggests an additional evaluation on the VOT dataset. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests performing additional evaluation on the VOT dataset using different metrics like Accuracy, Robustness, and EAO. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors perform additional evaluation on the VOT dataset using different metrics like Accuracy, Robustness, and EAO. The reviewer provides a logical reasoning by noting that the existing benchmarks evaluate competing methods using AUC and precision, implying that a broader evaluation would be beneficial. However, the comment lacks specific examples or references to support the claim that these metrics are necessary or would provide a more comprehensive evaluation. This makes the claim somewhat verifiable, as it provides a rationale but lacks detailed evidence or examples to fully substantiate the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the evaluation of the proposed framework, noting that the existing benchmarks focus on AUC and precision metrics. It suggests that the authors perform additional evaluation on the VOT dataset using different metrics like Accuracy, Robustness, and EAO. This feedback is clear and actionable, providing the authors with a specific direction to enhance their evaluation and comparison with competing methods. By suggesting a broader evaluation, the comment offers valuable guidance for improving the comprehensiveness and robustness of the study. Therefore, it is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern that the proposed method is not compared to any state-of-the-art unsupervised semantic segmentation techniques, despite claims of comparable performance to supervised semantic segmentation. The comment implies that the authors should include comparisons with state-of-the-art unsupervised methods to substantiate their claims. However, it does not provide specific guidance on which methods to compare against or how to conduct these comparisons. While the action is implicit, it is somewhat concrete in suggesting the need for comparisons, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of comparison with state-of-the-art unsupervised semantic segmentation techniques, which is a specific concern about the methodology and results section. It highlights the discrepancy between the claim of comparable performance to supervised semantic segmentation and the absence of comparisons with unsupervised methods. However, it does not specify which sections or parts of the paper should include these comparisons, making it weakly grounded. The comment is specific in detailing the issue, as it clearly identifies the need for comparisons with state-of-the-art unsupervised methods. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks comparison with state-of-the-art unsupervised semantic segmentation techniques, which is a critical omission given the claim of comparable performance to supervised semantic segmentation. The comment highlights the absence of such comparisons, which is a logical observation. However, it does not provide specific examples of state-of-the-art unsupervised methods or detailed reasoning on why these comparisons are necessary. This makes the claim somewhat verifiable, as it points out a gap in the paper but lacks detailed justification or references to support the need for these comparisons. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper, specifically the lack of comparison with state-of-the-art unsupervised semantic segmentation techniques. This is a critical oversight given the claim of comparable performance to supervised semantic segmentation. The comment highlights the need for the authors to include such comparisons to substantiate their claims and provide a more comprehensive evaluation of their method. However, the comment could be more helpful if it suggested specific state-of-the-art methods to compare against or provided guidance on how to conduct these comparisons. Despite this, the feedback is mostly helpful as it directs the authors to a crucial area for improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses uncertainty about the explanation of the first curve-finding part in relation to the FGE work. It suggests that the cyclical learning rate scheduling may perturb the weight around the initial converged weight but does not guarantee that the weight changes along the curve described. However, the comment does not provide explicit guidance or suggestions on how the authors might improve the explanation or address the issue. The action is implicit and vague, as the authors are left to infer what changes might be needed without clear direction. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first curve-finding part,\" allowing the authors to accurately identify the section being addressed. It is also specific because it details the issue with the explanation, specifically questioning why the FGE work is not well-explained and how the cyclical learning rate scheduling affects the weight. The comment provides a clear critique of the explanation, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the explanation of the first curve-finding part in relation to the FGE work, specifically regarding the impact of cyclical learning rate scheduling on the weight. The comment provides a logical reasoning by explaining that the cyclical learning rate scheduling may perturb the weight around the initial converged weight but does not guarantee that the weight changes along the curve described. This reasoning is clear and provides a basis for the claim, making the comment mostly verifiable. However, it could be strengthened with specific examples or references to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the explanation of the first curve-finding part in relation to the FGE work. It questions the effectiveness of the cyclical learning rate scheduling in ensuring that the weight changes along the curve described. This feedback is somewhat helpful as it identifies a potential weakness in the explanation and prompts the authors to clarify or improve their explanation. However, the comment lacks specific suggestions or guidance on how to address this issue, which limits its usefulness. To be more helpful, the comment could provide examples or alternative approaches to enhance the explanation. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors present a case study, ideally with synthetic datasets, to demonstrate when a distillation strategy is better. It also questions the performance differences observed in Table 3 and asks for more reasoning or hypotheses based on the performance. While the comment implies that the authors should conduct additional analysis and provide more detailed explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a case study and provide more reasoning. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests presenting a case study with synthetic datasets to demonstrate when a distillation strategy is better and questions the performance differences observed in Table 3. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors present a case study with synthetic datasets to demonstrate when a distillation strategy is better. It questions the performance differences observed in Table 3 and asks for more reasoning or hypotheses based on the performance. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that a case study would be beneficial. The request for more reasoning or hypotheses is reasonable but not fully substantiated, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper. It recommends presenting a case study, ideally with synthetic datasets, to demonstrate when a distillation strategy is better. This suggestion is clear and provides a concrete direction for the authors to enhance their work. Additionally, the comment questions the performance differences observed in Table 3, prompting the authors to investigate and provide more reasoning or hypotheses based on the performance. This level of detail and guidance makes the comment highly helpful, as it offers a clear path for the authors to improve their draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors focus on evaluating LM loss for style and topics, but notes that this approach may not be effective for factual knowledge. It implies that the authors could create specific evaluation sets, such as cloze-style or question-answering evaluations, to assess the generation of factual knowledge. While the comment provides a clear direction for improvement, it does not offer detailed guidance on how to implement these suggestions. The action is explicit but somewhat vague, as the authors know they need to create specific evaluation sets but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluation of LM loss throughout the paper, suggesting that while it is suitable for style and topics, it may not be effective for factual knowledge. The reviewer implies that the authors could create specific evaluation sets, such as cloze-style or question-answering evaluations, to focus on factual knowledge generation. However, the comment does not explicitly mention which part of the paper this critique pertains to, making it weakly grounded. It is specific in suggesting alternative evaluation methods, but without clear references to specific sections or elements of the paper, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the evaluation of LM loss is not effective for factual knowledge because only a few tokens in a sentence are related to facts. The reviewer proposes creating cloze-style or question-answering evaluation sets to focus on factual knowledge generation. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that LM loss is not effective for factual knowledge. This makes the claim somewhat verifiable, as the authors would need to explore the suggestion further to fully understand the critique.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the paper's evaluation methodology, suggesting that the focus on LM loss may not be effective for assessing factual knowledge. It provides a clear and actionable suggestion to create cloze-style or question-answering evaluation sets to better evaluate the generation of factual knowledge. This feedback is valuable as it offers a concrete way for the authors to enhance the robustness and comprehensiveness of their evaluation. However, the comment could be more helpful if it included examples or further details on how to implement these evaluation sets. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the theoretical or topological aspects of the RTD score\\'s sensitivity to clusters and its applicability to network representation. While it highlights areas that need further explanation, it does not provide explicit instructions or suggestions on how the authors should address these concerns. The comment implies that the authors should provide more theoretical or topological insights, but it lacks concrete guidance on what specific aspects to focus on or how to present this information. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the key contribution of the paper, specifically the sensitivity of the RTD score to clusters and its application to network representation. It raises questions about the theoretical or topological aspects of the RTD score and its applicability to measuring vectors of the same size. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as explaining the theoretical or topological sides of the RTD score and its applicability. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the theoretical or topological aspects of the RTD score\\'s sensitivity to clusters and its applicability to network representation. It suggests that the proposed RTD could be applied to measure any vectors with the same size, raising a logical concern about its specificity for network representation. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim. While it highlights a potential gap in the paper, the lack of supporting evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises important questions about the theoretical or topological aspects of the RTD score's sensitivity to clusters and its applicability to network representation. It challenges the authors to provide a deeper understanding of why the RTD score is specifically suited for network representation, rather than being a general measure for vectors of the same size. This feedback is valuable as it prompts the authors to clarify and strengthen their theoretical foundation, which could significantly enhance the paper's clarity and impact. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these questions. Overall, the comment is mostly helpful, as it identifies a critical area for improvement and encourages the authors to provide more detailed explanations.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part critiques the claim made in the paper regarding the complexity of ROCK compared to the original model, suggesting that inference timings should be provided to support this claim. This is an explicit request for additional data to substantiate the claim, making it clear and actionable. The second part suggests conducting ablation experiments to demonstrate the contribution of each auxiliary task on object detection performance in ROCK and standard MTL. This is also an explicit suggestion for additional experiments, providing clear guidance on how to improve the paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L88-89,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the claim about ROCK\\'s complexity, suggesting that inference timings should be provided to support this claim. Additionally, it provides a clear suggestion for conducting ablation experiments to demonstrate the contribution of each auxiliary task on object detection performance. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts. The first part questions the claim that ROCK has similar complexity to the original model, suggesting that the addition of multiple layers would likely increase complexity. This claim is somewhat verifiable as it provides a logical reasoning based on the structural changes introduced by ROCK. However, it lacks specific references or detailed comparisons to fully substantiate the claim. The second part suggests conducting ablation experiments to demonstrate the contribution of each auxiliary task on object detection performance. This suggestion is mostly verifiable as it provides a clear and actionable recommendation for improving the paper, but it could be strengthened with examples or references to similar experiments. Overall, the comment is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two distinct points of feedback. The first part critiques the claim that ROCK has similar complexity to the original model, suggesting that the addition of multiple layers would likely increase complexity. It explicitly requests that inference timings be provided to support this claim, offering a clear and actionable suggestion for improvement. The second part suggests conducting ablation experiments to demonstrate the contribution of each auxiliary task on object detection performance in ROCK and standard MTL. This feedback is also actionable, as it provides a specific method for the authors to enhance their experimental analysis. By addressing both the claim about complexity and the suggestion for additional experiments, the comment offers valuable guidance for improving the draft. Therefore, it is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly questions the calculation of the joint probability P(y_1, y_2, ..| y_{<i}, X) when the part is not autoregressive. It suggests adding the equation to the paper for clarity, providing a direct and concrete action for the authors to take. This feedback is clear and actionable, as it specifies exactly what needs to be added to the paper to address the reviewer\\'s concern. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 197-198, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the calculation of the joint probability and suggests adding the equation to the paper for clarity. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the calculation of the joint probability P(y_1, y_2, ..| y_{<i}, X) when the part is not autoregressive and suggests adding the equation to the paper for clarity. This is a logical request for clarification, as it points out a potential gap in the explanation of the methodology. However, the comment does not provide specific reasoning or examples to support why this clarification is necessary or how it would improve the paper. While the suggestion is reasonable, the lack of detailed justification makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the calculation of the joint probability P(y_1, y_2, ..| y_{<i}, X) when the part is not autoregressive. It questions how this calculation is performed and suggests adding the equation to the paper for clarity. This feedback is clear and actionable, as it directs the authors to a specific part of the paper that needs further explanation. By addressing this point, the authors can enhance the clarity and comprehensibility of their work. Therefore, the comment is rated as mostly helpful, as it provides a clear direction for improvement but could be more comprehensive by offering additional suggestions or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions or imaging variations. It also raises concerns about the model\\'s behavior on noisy or imbalanced real-world medical datasets. While the comment identifies areas that need attention, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they should include a more detailed discussion on dataset diversity and quality, as well as consider the model\\'s performance on real-world datasets. However, the comment lacks concrete steps or suggestions on how to implement these improvements. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions or imaging variations. It also raises concerns about the model\\'s behavior on noisy or imbalanced real-world medical datasets. However, the comment does not specify which part of the paper this issue is addressed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors can infer that it relates to the methodology or results sections, the comment lacks full grounding. It is specific in detailing what aspects of the dataset and model performance are lacking, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the limited discussion on the diversity and quality of the dataset, particularly regarding rare conditions or imaging variations. It also questions how the model might perform on noisy or imbalanced real-world medical datasets. While the comment highlights important aspects that could be explored further, it lacks specific examples, references, or detailed reasoning to support the claim. The authors are left to infer the potential issues without concrete evidence or guidance on how to address them. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the discussion regarding the diversity and quality of the dataset, particularly in relation to rare conditions or imaging variations. It also raises important questions about the model\\'s performance on noisy or imbalanced real-world medical datasets, where labels may be incomplete, inaccurate, or skewed. This feedback is valuable as it highlights areas where the authors could enhance the robustness and applicability of their work. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these issues, such as recommending additional data sources or methods for handling noisy data. Despite this, the comment is mostly helpful as it directs the authors to important aspects of their work that require further exploration and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the reproducibility of the results due to the lack of code and detailed training information. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should include code and more detailed training information to ensure reproducibility, but it does not specify what specific details should be included or how to present them. This makes the action vague and difficult for the authors to execute. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the reproducibility of the results due to the lack of code and detailed training information. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in detailing the issue with reproducibility, but without clear grounding, the authors may struggle to identify the exact parts that need revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lack of code and detailed training information makes the results non-reproducible. However, it does not provide specific examples or references to support this claim, nor does it offer detailed reasoning on how the absence of code and training details affects reproducibility. This lack of evidence and detailed justification makes the claim difficult for the authors to address effectively, rendering it borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the reproducibility of the results due to the lack of code and detailed training information. This is a critical concern for any scientific paper, as it affects the ability of others to verify and build upon the findings. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending the inclusion of a code repository or detailed documentation of the training process. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a critical issue but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a missing piece of information, specifically the total number of agents available in Flow\u2019s default configuration. This provides a clear and direct action for the authors to take, which is to include this critical setup information in their draft. The comment is explicit and concrete, as it specifies exactly what needs to be added to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"setup information\" and \"the total number of agents available in Flow\u2019s default configuration,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, which is the total number of agents in the default configuration. This provides clear guidance on what needs to be included to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"critical setup information is missing,\" specifically mentioning the total number of agents available in Flow\u2019s default configuration. However, the comment does not provide any reasoning or evidence to support why this information is critical or how its absence affects the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, namely the lack of critical setup information, such as the total number of agents available in Flow\u2019s default configuration. This feedback is clear and actionable, as it directs the authors to include this missing information, which is essential for understanding the experimental setup. By addressing this point, the authors can enhance the transparency and comprehensiveness of their paper. However, the comment could be more helpful if it provided additional context or suggested how this information might impact the results or interpretation of the study. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the claim of being the \"first deep generative model for unsupervised scene-graph discovery,\" suggesting that there are many works that infer structures in an unsupervised way. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific changes they should make to their claim. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific claim made in the paper, namely the assertion of being the \"first deep generative model for unsupervised scene-graph discovery.\" However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in questioning the fairness of the claim due to the existence of other works that infer structures in an unsupervised way. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim of being the \"first deep generative model for unsupervised scene-graph discovery,\" suggesting that there are many works that infer structures in an unsupervised way. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed evidence or references renders the claim somewhat verifiable, as the authors would need to conduct additional research to fully address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the claim of being the \"first deep generative model for unsupervised scene-graph discovery,\" suggesting that there are many works that infer structures in an unsupervised way. This feedback is somewhat helpful as it points out a potential issue with the claim, prompting the authors to reconsider their assertion. However, the comment lacks specific examples or references to support the claim, which would be beneficial for the authors to fully understand and address the critique. To be more helpful, the comment could include examples of such works or provide a more detailed explanation of why the claim is not accurate. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the ablation study, noting that it does not provide information on the effect of different numbers of projectors on distillation when feature dimensions are varied. However, it does not offer any explicit guidance or suggestions on how the authors might address this issue or what specific changes they should make to their study. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ablation study, namely that it does not provide the effect of different numbers of projectors on distillation when feature dimensions are different. This provides clear guidance on what needs to be addressed in the study. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study lacks information on the effect of different numbers of projectors on distillation when feature dimensions are different. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the ablation study, noting that it does not provide information on the effect of different numbers of projectors on distillation when feature dimensions are varied. This feedback is clear and actionable, as it highlights a gap in the study that the authors can address by including this information. However, the comment could be more helpful if it suggested ways to incorporate this analysis or provided examples of how to present the results. Despite this, the comment is mostly helpful as it directs the authors to a specific area for improvement, making it a 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting more experiments on diverse datasets to demonstrate the generalization capabilities of the model. It specifically recommends evaluating the model on more complex shapes with various topologies, beyond the current three categories (chair, airplane, car). While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on which datasets to use or how to implement these experiments. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments on diverse datasets to demonstrate the generalization capabilities of the model, specifically recommending the evaluation of more complex shapes with various topologies. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting additional experiments and datasets, but without clear grounding, it is challenging for the authors to implement the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experiments on diverse datasets could further demonstrate the generalization capabilities of the model. It recommends evaluating the model on more complex shapes with various topologies to demonstrate the core idea of the proposed method. However, the comment lacks specific examples or references to support the claim that the current dataset is insufficient or that additional experiments would be beneficial. Without detailed justification or evidence, the claim remains somewhat verifiable, as it provides a logical suggestion but lacks concrete support. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors conduct more experiments on diverse datasets to demonstrate the generalization capabilities of their model. It specifically recommends evaluating the model on more complex shapes with various topologies, beyond the current three categories (chair, airplane, car). This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the robustness and applicability of their method. However, the comment could be more helpful if it included suggestions on which specific datasets or shapes to use for these additional experiments. Overall, the comment is mostly helpful as it offers a concrete way for the authors to improve their work, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a comparison against methods requiring more training time is necessary. It implies that the authors should consider including such a comparison in their work. However, the comment does not provide explicit guidance on how to conduct this comparison or what specific methods should be included. The action is implicit and somewhat vague, as the authors can infer the need for a comparison but may not know exactly how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a comparison against methods that require more training time, specifically mentioning the work of Park & Van Hentenryck (2023) and others. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for a comparison and providing a rationale for why it is important, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a comparison against methods requiring more training time is necessary, particularly referencing the work of Park & Van Hentenryck (2023) and others. The comment provides a logical reasoning by highlighting the implications of low computational requirements and the potential need to train fewer models. However, it lacks specific examples or detailed references to support the claim, making it somewhat verifiable. The authors would need to conduct further research to fully understand the implications and provide evidence for the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that a comparison against methods requiring more training time is necessary, particularly referencing the work of Park & Van Hentenryck (2023) and others. It highlights the importance of understanding the implications of low computational requirements and the potential need to train fewer models. This feedback is clear and actionable, as it provides a specific direction for the authors to consider in their work. However, it could be more helpful if it included suggestions on how to conduct this comparison or which specific methods to include. Overall, the comment is mostly helpful as it offers a valuable insight for improving the draft, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the comparison between DetNAS and ResNet is unfair due to the efficiency of the ShuffleNetv2 block compared to the Residual block in ResNet. It provides a specific action for the authors to take: to include more comparisons between DetNAS and other networks constructed using efficient blocks. Additionally, it specifies that the authors should provide the results of a 3.8G FLOPs ShuffleNetv2 in Table 2. This feedback is clear and provides concrete steps for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison between DetNAS and ResNet, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the comparison is unfair due to the efficiency of the ShuffleNetv2 block compared to the Residual block in ResNet. The comment further suggests providing more comparisons with other networks constructed using efficient blocks and specifies the inclusion of results for a 3.8G FLOPs ShuffleNetv2 in Table 2. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison between DetNAS and ResNet is unfair due to the efficiency of the ShuffleNetv2 block compared to the Residual block in ResNet. The reviewer suggests providing more comparisons with other networks constructed using efficient blocks, specifically mentioning the inclusion of results for a 3.8G FLOPs ShuffleNetv2 in Table 2. This claim is somewhat verifiable as it provides a logical reasoning for the unfair comparison and suggests a specific action to improve the fairness of the comparison. However, the comment lacks detailed examples or references to support the claim fully, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the comparison between DetNAS and ResNet, pointing out that the ShuffleNetv2 block is more efficient than the Residual block in ResNet. It suggests that the authors should provide more comparisons with other networks constructed using efficient blocks, such as including the results of a 3.8G FLOPs ShuffleNetv2 in Table 2. This feedback is clear and actionable, offering a specific suggestion for improvement that could enhance the comprehensiveness and fairness of the comparison. However, the comment could be more helpful if it provided additional context or examples of other networks that should be included for comparison. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a perceived limitation in the input and output spaces/representations, noting that they are restricted to either the group itself under the regular or trivial representation, or a homogeneous space of the group. The reviewer contrasts this with other papers that can work with any finite-dimensional representation. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or expand their work to include more general representations. The action is implicit and vague, as the authors are left to infer that they should consider broader representations but are not given concrete steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the input and output spaces/representations, and notes that they are restricted to certain representations. However, it does not specify which part of the paper discusses these representations, making it weakly grounded. The comment is specific in detailing the limitation, noting that the current approach does not seem as general as other papers that can work with any finite-dimensional representation. This provides clear guidance on what needs to be addressed, but without explicit references to specific sections or elements of the paper, the comment remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the input and output spaces/representations are restricted to specific representations, contrasting this with other papers that can work with any finite-dimensional representation. The reviewer mentions specific papers in point (3) as examples, but the comment does not provide detailed references or explanations of these papers. This makes the claim somewhat verifiable, as the authors would need to look up the referenced papers to fully understand the comparison. However, the mention of specific papers provides some basis for the claim, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the paper's approach, noting that the input and output spaces/representations are restricted to specific representations. It contrasts this with other papers that can work with any finite-dimensional representation, suggesting that the current approach may not be as general. This feedback is somewhat helpful as it points out a specific area for improvement, encouraging the authors to consider expanding their work to include more general representations. However, the comment could be more helpful if it provided specific suggestions or examples of how to achieve this expansion. Overall, the feedback is clear but incomplete, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential complexity in practical applications of the system, specifically in real-world image editing tasks involving multiple objects and flexible prompts. It notes that the need to specify a source prompt, blend word, and various conditions can complicate the process and restrict usability for typical users seeking simpler image adjustments. However, the comment does not provide explicit guidance or suggestions on how the authors might address this complexity or simplify the system for practical use. The action is implicit and vague, as the authors are left to infer that they should consider simplifying the system but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the complexity of practical applications, specifically in real-world image editing tasks involving multiple objects and flexible prompts. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment provides a clear description of the complexity and its potential impact on usability, but without explicit grounding, the authors may struggle to identify where to make changes. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a potential complexity in practical applications of the system, specifically in real-world image editing tasks involving multiple objects and flexible prompts. It notes that the need to specify a source prompt, blend word, and various conditions can complicate the process and restrict usability for typical users seeking simpler image adjustments. However, the comment lacks specific examples or references to support the claim about the complexity and its impact on usability. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable, as the authors may need to infer the extent of the complexity and its implications. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential complexity in the practical applications of the system, specifically in real-world image editing tasks involving multiple objects and flexible prompts. It highlights the need to specify a source prompt, blend word, and various conditions, which can complicate the process and restrict usability for typical users seeking simpler image adjustments. This feedback is somewhat helpful as it points out a specific area where the system might be challenging for users, but it lacks detailed suggestions or guidance on how the authors might address this complexity or simplify the system. While it provides some insight into a potential limitation, it does not offer actionable steps for improvement, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the contributions of the paper are not significant and that there is a lack of effort in contrasting the technique with traditional classification or manifold learning literature. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the perceived lack of significance or how to improve the comparison with existing literature. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty and significance of the technique presented in the paper, as well as the lack of effort in contrasting it with traditional classification or manifold learning literature. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the paper\\'s contributions and the need for comparison with existing literature, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the contributions of the paper are not significant and that there is a lack of effort in contrasting the technique with traditional classification or manifold learning literature. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without such evidence, the authors may find it challenging to understand and address the feedback effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises concerns about the significance of the paper\\'s contributions and the lack of effort in contrasting the proposed technique with traditional classification or manifold learning literature. While it identifies a potential weakness in the paper, it does not provide specific suggestions or guidance on how the authors might address these issues. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a discussion on the impact of the few-shot dataset for the sparsity ratio is necessary. It acknowledges that larger datasets could provide more accurate estimates but would also require significantly more time to compute. The comment references two external sources, [1] and [2], which provide additional context and support for the suggestion. However, the comment does not explicitly instruct the authors to include this discussion or provide specific guidance on how to integrate it into the paper. While the authors can infer that they need to address this issue, the action is not explicitly stated, and the guidance is somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a discussion on the impact of the few-shot dataset for the sparsity ratio is necessary. It provides a rationale for this suggestion by mentioning that larger datasets could provide more accurate estimates but would also require significantly more time to compute. The comment references two external sources, [1] and [2], which support the suggestion. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in detailing the need for a discussion on the impact of the few-shot dataset, but without explicit references to specific sections or parts of the paper, the authors may find it challenging to pinpoint where this discussion should be integrated. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a discussion on the impact of the few-shot dataset for the sparsity ratio is necessary. It provides a logical reasoning by acknowledging that larger datasets could provide more accurate estimates but would also require significantly more time to compute. The comment references two external sources, [1] and [2], which support the suggestion by providing additional context and evidence. However, the comment could be strengthened by providing more detailed examples or specific references to how the few-shot dataset affects the sparsity ratio. Overall, the claim is mostly verifiable, as it provides a solid foundation for the suggestion but could benefit from more detailed evidence. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that a discussion on the impact of the few-shot dataset for the sparsity ratio is necessary. It provides a logical reasoning by acknowledging that larger datasets could provide more accurate estimates but would also require significantly more time to compute. The comment references two external sources, [1] and [2], which offer additional context and support for the suggestion. This feedback is clear and actionable, as it identifies a specific area for improvement and provides references that can guide the authors in addressing this issue. However, the comment could be more helpful if it offered specific suggestions on how to integrate this discussion into the paper or provided more detailed guidance on what aspects to focus on. Overall, the comment is mostly helpful, as it provides valuable insights and references that can significantly improve the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of explanation and experimental verification regarding the decision to keep representations in the same hidden space. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should provide a rationale or experimental evidence to support their choice, but it does not specify what kind of evidence or explanation is needed. As a result, the action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of explanation and experimental verification regarding the decision to keep representations in the same hidden space. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in detailing what is missing, but it lacks grounding as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not provide a rationale for keeping representations in the same hidden space and that this has not been experimentally verified. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence renders the claim somewhat verifiable, as the authors would need to infer the specific issues and address them without clear guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the rationale for keeping representations in the same hidden space and the lack of experimental verification to support this choice. This feedback is somewhat helpful as it points out an area where the authors could provide more explanation and evidence to strengthen their argument. However, the comment does not offer specific suggestions or guidance on how to address this issue, such as recommending additional experiments or providing examples of how to articulate the rationale. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the paper for lacking sufficient novelty in its methodologies, specifically mentioning that the introduction of Longitudinal Representation Learning as an extension of Karwande et al. (2022) using Faster R-CNN (Ren et al., 2015) does not offer a significant advancement beyond existing methods. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the novelty of their approach. It lacks actionable advice, such as recommending specific areas to explore for innovation or suggesting alternative methodologies to consider. As a result, the authors are left without a clear path forward to enhance the novelty of their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Longitudinal Representation Learning\" and \"Karwande et al. (2022)\" and \"Faster R-CNN (Ren et al., 2015),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of lacking sufficient novelty in methodologies and provides a reference to existing work, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks sufficient novelty in its methodologies, specifically citing the use of Longitudinal Representation Learning as an extension of Karwande et al. (2022) with Faster R-CNN (Ren et al., 2015). The comment provides a logical reasoning by comparing the current approach to existing methods, suggesting that it does not offer a significant advancement. However, the claim could be strengthened by providing more detailed examples or references to specific aspects where the novelty is lacking. Overall, the comment is mostly verifiable, as it provides a clear basis for the claim but could benefit from additional supporting evidence. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of sufficient novelty in the methodologies presented. It points out that the introduction of Longitudinal Representation Learning as an extension of Karwande et al. (2022) using Faster R-CNN (Ren et al., 2015) does not offer a significant advancement beyond existing methods. This feedback is valuable as it highlights a critical area for improvement, prompting the authors to reconsider the originality and contribution of their work. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might enhance the novelty of their approach. Despite this, the comment is mostly helpful as it directs the authors to a key area needing attention, making it a 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the paper overlooks various SSM-based approaches that do not require keeping \u0394t fixed, specifically mentioning S5 as an example. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this oversight or incorporate the mentioned approaches into their work. The action is implicit and somewhat vague, as the authors are left to infer that they should consider these alternative methods but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, noting that it overlooks various SSM-based approaches that do not require keeping \u0394t fixed. It mentions S5 as an example that avoids this issue by computing input-output via a parallel scan. This provides clear guidance on what needs to be addressed, specifically the inclusion of these alternative approaches. However, the comment does not explicitly mention which part of the paper this issue pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper overlooks various SSM-based approaches that do not require keeping \u0394t fixed, specifically mentioning S5 as an example. The comment provides a specific example, S5, which avoids the issue by computing input-output via a parallel scan. This level of detail provides a clear and logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more context or references to these alternative approaches, which would further support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific oversight in the paper, noting that it overlooks various SSM-based approaches that do not require keeping \u0394t fixed. It provides a concrete example, S5, which avoids this issue by computing input-output via a parallel scan. This feedback is clear and actionable, as it directs the authors to consider these alternative approaches and potentially incorporate them into their work. By highlighting a gap in the literature review or methodology, the comment offers a valuable suggestion for enhancing the paper\\'s comprehensiveness and depth. However, it could be more helpful if it provided additional context or guidance on how to integrate these approaches effectively. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several issues with the presentation and clarity of the paper. It questions the labeling of \"3\" as the underlying data generating mechanism, suggesting that it is not accurate. It also recommends using causal graphs when discussing the underlying system, rather than for label inference, and points out that definition 4 is hard to read due to a lack of clarity on which graph should be considered for determining independencies. However, the comment does not provide explicit instructions or concrete suggestions on how to address these issues. The actions are implicit and vague, leaving the authors to infer what needs to be done without clear guidance on how to implement the changes. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses several specific issues in the paper, including the labeling of \"3\" as the underlying data generating mechanism, the use of causal graphs when discussing the system, and the clarity of definition 4. It also mentions Fig. 2, which provides some grounding by referencing a specific figure. However, the comment does not specify which part of the paper discusses the label inference process, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as clarifying the data generating mechanism and using causal graphs appropriately. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims, including the assertion that \"3\" is not the underlying data generating mechanism and the suggestion that causal graphs should be used when discussing the underlying system. However, the comment lacks specific evidence or references to support these claims, making it difficult for the authors to understand the basis of the critique. The mention of \"definition 4\" being hard to read due to a lack of clarity on which graph should be considered for determining independencies is also not substantiated with detailed reasoning or examples. As a result, the comment is considered unverifiable due to the absence of supporting evidence or detailed justification.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the labeling of \"3\" as the underlying data generating mechanism, which the reviewer believes is incorrect. It suggests that the paper should discuss causal graphs when referring to the underlying system, rather than for label inference. Additionally, the comment points out that definition 4 is hard to read due to a lack of clarity on which graph should be considered for determining independencies. However, the comment does not provide specific guidance or suggestions on how to address these issues, such as recommending alternative ways to present the data generating mechanism or providing examples of how to clarify definition 4. While the comment highlights areas for improvement, it lacks actionable feedback, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about when evaluating the gradient of a conjugate function is expensive or infeasible and suggests including more examples in machine learning to motivate a dual-free approach. While the comment implies that the authors should provide more context or examples to support their approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more examples without specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the expense or infeasibility of evaluating the gradient of a conjugate function and suggests including more examples in machine learning to motivate a dual-free approach. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment lacks grounding as it does not reference a specific section, figure, or table, and it is also not specific about what examples should be included or how they would motivate the dual-free approach. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the expense or infeasibility of evaluating the gradient of a conjugate function and suggests including more examples in machine learning to motivate a dual-free approach. However, the comment does not provide any supporting evidence, reasoning, or references to justify why evaluating the gradient of a conjugate function is expensive or infeasible. Without such support, the claim remains vague and unverifiable, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the expense or infeasibility of evaluating the gradient of a conjugate function and suggests including more examples in machine learning to motivate a dual-free approach. While it identifies a potential area for improvement by questioning the feasibility of the approach, it lacks specific guidance or suggestions on how the authors might address this issue or provide additional examples. The comment is somewhat helpful as it prompts the authors to consider the practicality of their approach and the need for more examples, but it does not offer detailed advice on how to implement these suggestions. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the lack of explanation for the selection of a probability for the appearance of an unobservable data point in the data approximation technique. It explicitly asks the authors to provide an explanation for this choice, which is a direct and clear action. The comment does not leave any ambiguity about what needs to be addressed, as it specifies the exact aspect of the algorithm that requires clarification. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"step 3 of the Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the lack of explanation for selecting a probability from [0, Pcj(0)] in the data approximation technique. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the lack of explanation for selecting a probability from [0, Pcj(0)] in the data approximation technique. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual question seeking clarification, making it a normal statement. Therefore, the label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the lack of explanation for the selection of a probability in the data approximation technique. It asks the authors to provide an explanation for choosing a probability from [0, Pcj(0)], which is a clear and actionable request for clarification. This feedback is valuable as it directs the authors to address a potential gap in their explanation, thereby enhancing the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors provide a precise definition or an informal description of the \"spectrum of distributions and their characteristic functions.\" This is an explicit action that the authors can take to improve their draft. The comment specifies the lines where this issue is observed, providing clear guidance on where to make the changes. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (line 128 and line 168) where the authors refer to the \"spectrum of distributions and their characteristic functions.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests that the text would benefit from a precise definition or an informal description of this notion. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a precise definition or informal description of the \"spectrum of distributions and their characteristic functions.\" However, the comment does not provide any specific reasoning or examples to support why this definition or description is necessary. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification or evidence to fully support the recommendation.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting that the authors provide a precise definition or informal description of the \"spectrum of distributions and their characteristic functions.\" This feedback is clear and actionable, as it directs the authors to a particular aspect of their work that could benefit from clarification. By addressing this suggestion, the authors can enhance the clarity and comprehensibility of their paper for readers. However, the comment could be more helpful if it provided examples or further context on how this definition or description could be integrated into the paper. Overall, the comment is mostly helpful, as it offers a constructive suggestion for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the AIG-generation task, questioning its convincingness and suggesting that more background information is needed for readers unfamiliar with logic synthesis. It also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to make the task more convincing. While the comment implies that the authors should provide more background information and conduct benchmarking, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the AIG-generation task, suggesting that it is not convincing and lacks sufficient background information for readers unfamiliar with logic synthesis. It also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a). The comment is fully grounded as it explicitly mentions the AIG-generation task, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as adding background information and benchmarking the method on existing datasets. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the AIG-generation task is not convincing and suggests that more background information is needed for readers unfamiliar with logic synthesis. It also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to make the task more convincing. The comment provides a logical reasoning for the claim by suggesting that additional background information and benchmarking would enhance the paper\\'s credibility. However, it lacks specific examples or detailed references to support the claim fully, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a weakness in the paper regarding the AIG-generation task, questioning its convincingness and suggesting that more background information is needed for readers unfamiliar with logic synthesis. It also provides a specific recommendation to benchmark the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to enhance the paper\\'s credibility. This feedback is clear and actionable, offering the authors concrete steps to improve their draft by addressing the lack of background information and enhancing the validation of their method. However, the comment could be more helpful if it provided additional guidance on how to effectively integrate the background information or which specific datasets would be most relevant. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that some statements in the paper lack detail and analysis, but it does not provide specific examples or guidance on which statements are lacking or how the authors might improve them. The comment lacks explicit instructions or suggestions for the authors to address the issue, leaving them without a clear understanding of what needs to be done. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some statements in the paper lack detail and analysis, but it does not specify which statements or sections are being referred to. This makes it difficult for the authors to identify the exact parts of the paper that need improvement. Without specific examples or references to particular sections, the comment lacks grounding and specificity. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"some statements in this paper lack detail and analysis,\" but it does not provide specific examples or context to support this claim. Without detailed evidence or references to particular statements, the authors may find it challenging to understand which parts of the paper are lacking in detail and analysis. This lack of specificity makes the claim difficult for the authors to address, rendering it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a general issue with the paper, noting that some statements lack detail and analysis. However, it does not specify which statements are problematic or provide guidance on how the authors might address this issue. Without specific examples or suggestions for improvement, the comment lacks actionable feedback that could help the authors enhance their draft. As a result, it is barely helpful, as it points out a potential issue but does not offer enough detail for the authors to make meaningful improvements.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the comparison with other generative models, such as VAE, could be more informative. It specifically mentions that diffusion models have unique features like diffusion timesteps that distinguish them from other generative models. The comment implies that an analysis of how these differences affect feature learning would add significant value. While the action is implicit, it is concrete in suggesting a specific area for improvement and providing a clear direction for analysis. The authors can infer that they need to include a more detailed comparison with other generative models, focusing on the unique features of diffusion models. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the comparison with other generative models, such as VAE, could be more informative. It highlights the unique features of diffusion models, like the diffusion timesteps, and implies that an analysis of how these differences affect feature learning would add value. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. It is specific in suggesting a particular area for improvement, namely the comparison and analysis of unique features. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a comparison with other generative models, such as VAE, could be more informative, particularly in terms of the unique features of diffusion models like diffusion timesteps. The comment implies that analyzing how these differences affect feature learning would add significant value. However, the comment lacks specific examples or references to support the claim that diffusion models have unique features or how these features impact feature learning. This makes the claim somewhat verifiable, as it provides a general direction for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that the comparison with other generative models, such as VAE, could be more informative. It highlights the unique features of diffusion models, like the diffusion timesteps, and recommends an analysis of how these differences affect feature learning. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their draft by exploring the distinct characteristics of diffusion models. However, the comment could be more helpful if it included examples or references to guide the authors in their analysis. Overall, the comment is mostly helpful as it offers a constructive suggestion for improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two concerns. First, it questions the complementarity of the self-supervised tasks ICT and DaPI in Table 4, noting that the effectiveness of DaPI is not significant, which would double the GPU memory usage. Second, it points out that the paper proposes ICoL to mitigate insufficient memory on a single GPU and suggests using more negative instances for better performance, but lacks corresponding experiments to demonstrate the influence of the number of negatives. The comment implies that the authors should conduct experiments to show the impact of the number of negatives on performance. While the action is implicit, it is concrete in suggesting a specific area for experimentation. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the combination of self-supervised tasks ICT and DaPI, noting the lack of complementarity and the insignificant effectiveness of the DaPI task. Additionally, it points out the absence of experiments to demonstrate the influence of the number of negatives on performance, referencing TAS-B as a relevant example. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two claims. First, it questions the complementarity of the self-supervised tasks ICT and DaPI in Table 4, noting that the effectiveness of DaPI is not significant. This claim is somewhat verifiable as it provides a specific observation but lacks detailed reasoning or references to support the assertion about the lack of complementarity. Second, the comment suggests that the paper should include experiments to demonstrate the influence of the number of negatives on performance, referencing TAS-B as an example. This part of the claim is somewhat verifiable as it provides a logical basis for the suggestion but could be strengthened with more detailed reasoning or references. Overall, the comment is somewhat verifiable, as it provides some justification but lacks comprehensive evidence or detailed reasoning.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper. First, it questions the complementarity of the self-supervised tasks ICT and DaPI in Table 4, noting that the effectiveness of DaPI is not significant, which could double the GPU memory usage. This feedback is helpful as it points out a potential inefficiency in the experimental setup. Second, the comment suggests that the paper should include experiments to demonstrate the influence of the number of negatives on performance, referencing TAS-B as an example. This is a valuable suggestion as it highlights an area where the paper could be strengthened by providing more detailed analysis. However, the comment could be more helpful if it provided specific guidance on how to conduct these experiments or what metrics to use. Overall, the comment is mostly helpful as it offers actionable feedback for improving the draft, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests adding a caption to Figure 3 to clarify the differences between the three plots on the same row. This is a direct and concrete action that the authors can take to improve their draft. The comment clearly indicates what needs to be done, making it highly actionable. Therefore, the comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the differences between the three plots on the same row. The suggestion to add a caption to emphasize these differences provides clear guidance on how to address the issue. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the differences between the three plots in Figure 3. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual statement asking for additional information to be included in the caption. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting that it is unclear what the differences are between the three plots on the same row. It suggests adding a caption to emphasize these differences, which is a clear and actionable piece of feedback. This guidance is valuable for the authors as it directs them to enhance the clarity and readability of their figure, making it easier for readers to understand the results. However, the comment could be more helpful if it provided additional context or examples of how the caption could be improved. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but lacks depth in its suggestions. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need for a deeper analysis of the computational complexity of GPSE, particularly when compared to hand-crafted PSEs and other encoding strategies. While it identifies an area for improvement, it does not provide explicit guidance on how to conduct this analysis or what specific aspects of computational complexity should be explored. The action is implicit and somewhat vague, as the authors can infer that they need to delve into the computational complexity but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of computational complexity, specifically mentioning the need for a deeper dive into GPSE\\'s computational complexity compared to hand-crafted PSEs and other encoding strategies. However, it does not specify which part of the paper this analysis should be included in, such as a specific section or table. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in its request for a deeper analysis of computational complexity, but it lacks full grounding due to the lack of explicit references to specific parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper could benefit from a deeper analysis of GPSE\\'s computational complexity, particularly when compared to hand-crafted PSEs and other encoding strategies. The comment provides a logical reasoning by highlighting the potential limitation of hand-crafted PSEs and suggesting a comparison with GPSE. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to conduct their own analysis to fully understand the claim, which adds to the difficulty in verifying the comment. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper regarding the computational complexity of GPSE, particularly when compared to hand-crafted PSEs and other encoding strategies. It suggests that the paper could benefit from a deeper analysis of this aspect, which is a valuable insight for the authors. However, the comment lacks specific guidance on how to conduct this analysis or what aspects of computational complexity should be explored. While it points out an area for improvement, it does not provide detailed, actionable suggestions, making it somewhat helpful. The authors are given a direction to consider but need to figure out the specifics themselves. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the results on the VQA dataset should be reported on the test-standard split instead of the test-dev split, as per the guidelines from the VQA dataset authors. This provides a clear and direct action for the authors to take, ensuring that their results are reported accurately and in compliance with the dataset guidelines. The comment is explicit and provides concrete guidance on how to implement the change, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results being reported on the test-dev split instead of the test-standard split, as per the guidelines from the VQA dataset authors. This provides clear guidance on what needs to be corrected. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results on the VQA dataset should be reported on the test-standard split instead of the test-dev split, as per the guidelines from the VQA dataset authors. The comment provides a specific reference to the guidelines, which supports the claim. This reference provides a clear and logical justification for the recommendation, making the claim fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the reporting of results in Table 1, noting that the results on the VQA dataset are reported on the test-dev split instead of the test-standard split. It provides a clear and actionable suggestion by referencing the guidelines from the VQA dataset authors, which specify that numbers should be reported on the test-standard split to avoid overfitting. This feedback is valuable as it directs the authors to a specific area for improvement, ensuring that their results are reported accurately and in compliance with the dataset guidelines. However, the comment could be more helpful if it included additional context or examples of how this change might impact the interpretation of the results. Overall, the comment is mostly helpful, as it provides clear guidance but could be expanded for greater impact.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) to guarantee a certain decision-making loss level while optimizing Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss would improve the impact of the theoretical result. However, the comment does not provide explicit guidance on how to achieve this trade-off or how to control the term $T_i \\\\beta$. The action is implicit and somewhat vague, as the authors are left to infer that they need to find a way to manage the trade-off but are not given specific steps or methods to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) and their impact on decision-making loss while optimizing Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss would improve the impact of the theoretical result. However, the comment does not specify which part of the paper discusses these parameters or their optimization, making it weakly grounded. The comment is specific in detailing the issue with the term $T_i \\\\beta$ and the need to control it, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) and their impact on decision-making loss while optimizing Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss would improve the impact of the theoretical result. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the current approach is challenging or ineffective. The lack of supporting evidence or detailed justification makes the claim somewhat verifiable, as the authors would need to infer the potential issues and explore ways to address them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, which is the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) to guarantee a certain decision-making loss level while optimizing Brier scores. It highlights the challenge of managing the trade-off between prediction accuracy and decision-loss, suggesting that this is an important aspect to address to improve the impact of the theoretical result. The comment provides a clear direction for the authors to focus on, which is to explore ways to control the term $T_i \\\\beta$ and manage the trade-off. However, it could be more helpful if it offered specific suggestions or examples on how to achieve this. Overall, the comment is somewhat helpful as it points out a critical area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the limited applicability of the method to more structured layers like convolutions, noting that while it can be applied to convnets with minimal modification, its performance trails that of MON. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the applicability of their method. The comment implies that the authors should consider extending their methods to non-fully connected architectures, but it lacks concrete details on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the limited applicability of the method to more structured layers like convolutions, noting that while it can be applied to convnets with minimal modification, its performance trails that of MON. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in detailing the concern about applicability and performance but lacks grounding, as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the limited applicability of the method to more structured layers like convolutions, noting that while it can be applied to convnets with minimal modification, its performance trails that of MON. The comment provides a logical reasoning by questioning the readiness of the methods to be extended to non-fully connected architectures. However, it lacks specific examples or references to support the claim about the performance of MON, which would strengthen the argument. Therefore, the comment is somewhat verifiable, as it provides a logical basis but requires additional evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the limited applicability of the method to more structured layers like convolutions, noting that while it can be applied to convnets with minimal modification, its performance trails that of MON. This observation highlights a potential weakness in the paper's scope and applicability, prompting the authors to consider whether their methods are ready to be extended to non-fully connected architectures. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the applicability of their method. While it identifies a relevant area for improvement, the feedback is incomplete and does not provide actionable steps, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges a lack of clarity regarding the evaluation of the refactoring process and suggests that using a pass rate for unit tests is insufficient. It provides a list of potential metrics that could be considered for future benchmarks, implying that the authors should explore these options. While the comment does not explicitly instruct the authors to use these metrics, it offers a clear direction for improvement by suggesting specific alternatives. The action is concrete, as it provides a list of potential metrics, but it is implicit in the sense that the authors need to infer that they should consider these metrics for evaluation. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the evaluation of the refactoring process, specifically questioning the sufficiency of using a pass rate for unit tests. It suggests alternative metrics that could be considered for future benchmarks. However, it does not specify which part of the paper discusses the refactoring process or the evaluation metrics, making it weakly grounded. The comment is specific in suggesting potential metrics for evaluation, but without explicit references to the paper, the authors may find it challenging to pinpoint the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the sufficiency of using a pass rate for unit tests as a metric for evaluating the refactoring process. It suggests that this metric is insufficient and provides a list of potential alternative metrics that could be considered. However, the comment does not provide specific examples or detailed reasoning to support why the current metric is insufficient or why the suggested alternatives are better. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation of the refactoring process, noting that using a pass rate for unit tests is insufficient. It provides a list of potential metrics that could be considered for future benchmarks, offering a clear direction for improvement. This feedback is actionable and constructive, as it suggests specific alternatives that the authors could explore to enhance their evaluation methodology. However, the comment could be more helpful if it provided a detailed explanation of why the current metric is insufficient or how the suggested metrics would better capture the aspects of the refactoring process. Overall, the comment is mostly helpful, as it provides valuable guidance for improving the evaluation process, but it could be more comprehensive with additional context or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the Wiener deconvolution has already been proposed, implying that the main contribution of the paper is not significant. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of insufficient contribution or suggestions for enhancing the paper. Without actionable advice or specific feedback, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the Wiener deconvolution has already been proposed, implying that the main contribution of the paper is not significant. However, it does not specify which part of the paper discusses the Wiener deconvolution or how it relates to the main contribution. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the contribution are insufficient or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the Wiener deconvolution has already been proposed, implying that the main contribution of the paper is not significant. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without specific examples or references to existing work on Wiener deconvolution, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the main contribution of the paper is not significant because the Wiener deconvolution has already been proposed. However, it does not provide any specific feedback or suggestions on how the authors could enhance their contribution or address the issue. Without actionable guidance or detailed critique, the authors are left without a clear understanding of what needs to be improved or how to improve it. This lack of specificity and actionable advice makes the comment unhelpful for the authors.\", 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the connection made between the energy function of a spin glass and the regularization term in the paper. It highlights three areas where the connection appears weak: the role of regularization in escaping local minima, the effect on Parisi\u2019s order parameter, and the role of temperature in achieving desired low-entropic states. However, the comment does not provide explicit guidance or suggestions on how the authors might strengthen this connection or address these concerns. The feedback is implicit and lacks concrete details on what actions the authors should take to improve their draft. As a result, the comment is barely actionable, as the authors can infer that they need to provide more explanation but are not given specific steps to follow.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the weaknesses in the connection made between the energy function of a spin glass and the regularization term, including the lack of explanation regarding how the regularization helps escape local minima, the effect on Parisi\u2019s order parameter, and the role of temperature. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the connection made between the energy function of a spin glass and the regularization term in the paper. It highlights three areas where the connection appears weak: the role of regularization in escaping local minima, the effect on Parisi\u2019s order parameter, and the role of temperature in achieving desired low-entropic states. The comment provides a logical structure by breaking down the issues, but it lacks specific examples, references, or detailed reasoning to fully substantiate the claims. While the critique is based on a logical framework, it requires more detailed evidence or references to be considered fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the connection made between the energy function of a spin glass and the regularization term in the paper. It highlights three key aspects where the connection appears weak: the role of regularization in escaping local minima, the effect on Parisi\u2019s order parameter, and the role of temperature in achieving desired low-entropic states. By pointing out these gaps, the comment provides the authors with clear guidance on what needs to be addressed to strengthen the connection and improve the clarity of their work. However, the comment could be more helpful if it offered suggestions or examples on how to address these issues. Overall, the feedback is mostly helpful as it directs the authors to specific areas needing further explanation and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the exploration of a self-training scheme in the paper but notes that the contribution is relatively limited. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to enhance the contribution or suggestions for additional experiments or analyses that could strengthen the paper. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the self-training scheme in the paper, indicating that it is a direct application and that the contribution is relatively limited. However, it does not specify which part of the paper discusses the self-training scheme, making it weakly grounded. The comment is specific in its critique of the contribution, but without clear grounding, the authors may struggle to identify the exact sections needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the self-training scheme is a direct application and that the contribution is relatively limited. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the exploration of a self-training scheme in the paper but notes that the contribution is relatively limited. While it provides some insight into the nature of the work, it lacks specificity and actionable feedback. The comment does not offer suggestions on how the authors might enhance the contribution or provide guidance on what specific aspects could be improved. As a result, the authors are left without clear direction for improving their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should include zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality of the results. This provides a clear and direct action for the authors to take, as it specifies exactly what needs to be done to improve the draft. The comment is concrete in its guidance, leaving no ambiguity about how to implement the suggested action. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the results shown in the paper are low-resolution and recommends including zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality. However, it does not specify which part of the paper these results are presented in, making it weakly grounded. The comment is specific in suggesting a way to improve the resolution of the results, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the results shown in the paper are low-resolution and suggests including zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality. However, the comment does not provide any specific examples or references to support the claim that the results are low-resolution. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the resolution of the results presented in the paper, suggesting that including zoomed-in regions of the rendered focal stack or all-in-focus images would help inspect the quality. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the clarity and detail of their results. However, the comment could be more helpful if it offered additional guidance on how to effectively present these zoomed-in regions or why they are important for the paper\\'s findings. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two concerns regarding the comparative inference method: the significant increase in inference cost due to multiple forward passes and the requirement for validation data for post-hoc calibration. While the comment identifies these issues, it does not provide explicit guidance on how the authors might address them. The authors are left to infer that they should consider the computational resources and availability of validation data in their method, but without specific suggestions or concrete steps, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the comparative inference method and its implications for real-world applications, specifically mentioning the increased inference cost and the requirement for validation data for post-hoc calibration. However, it does not specify which part of the paper discusses this method, making it weakly grounded. The comment is specific in detailing the concerns about inference cost and the need for validation data, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparative inference method increases inference cost significantly due to multiple forward passes and that post-hoc calibration requires validation data, which may not be readily available for open-ended generation tasks. The comment provides a logical reasoning for the potential concern about computational resources and the applicability of the method in real-world scenarios. However, it lacks specific examples or references to support the claim about the increased inference cost or the limitations of post-hoc calibration in open-ended generation tasks. This makes the claim somewhat verifiable, as it provides a general rationale but requires more detailed evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two potential concerns with the comparative inference method: the significant increase in inference cost due to multiple forward passes and the requirement for validation data for post-hoc calibration. These are valid points that could impact the applicability and practicality of the method in real-world scenarios. However, the comment does not provide specific suggestions or guidance on how the authors might address these concerns or improve their method. While it highlights important issues, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out areas for consideration but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests an action for the authors to take: performing gradient clipping with a high value for the gradient norm to avoid NaNs appearing. This is a direct and concrete suggestion that provides clear guidance on how to address the issue of exploding gradients. The comment also critiques the current approach of reinitializing the model, labeling it as \"hacky,\" which further emphasizes the need for an alternative solution. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L265,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests an alternative approach to addressing exploding gradients by proposing gradient clipping with a high value for the gradient norm. This provides clear guidance on how to improve the draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the approach of reinitializing the model when exploding gradients are a problem, suggesting an alternative solution of using gradient clipping with a high value for the gradient norm. This is a logical suggestion based on common practices in deep learning to prevent exploding gradients. However, the comment does not provide specific references or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. The authors would need to consider the suggestion and potentially conduct further research to fully understand the implications. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the approach to handling exploding gradients in the paper. It questions the effectiveness of reinitializing the model and suggests an alternative solution, namely using gradient clipping with a high value for the gradient norm to prevent NaNs from appearing. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving their method. However, the comment could be more helpful if it included additional context or examples of how gradient clipping has been successfully applied in similar scenarios. Overall, the comment is mostly helpful as it offers a specific and actionable suggestion for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests a more detailed explanation of the term \"common pattern.\" This is a clear and direct action for the authors to take, as it specifies exactly what needs to be addressed in the draft. The comment provides a concrete suggestion by asking for a more detailed explanation, leaving no ambiguity about how the authors should improve their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need for a more detailed explanation of the term \"common pattern.\" This provides clear guidance on how the authors can improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification, asking for a more detailed explanation of the term \"common pattern.\" It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and direct, requesting a more detailed explanation of the term \"common pattern.\" This feedback is actionable and provides a specific area for the authors to improve their draft by clarifying a potentially ambiguous term. However, the comment could be more helpful if it offered suggestions on how to provide this explanation or what aspects of the term might be unclear. Despite this, the comment is mostly helpful as it guides the authors toward enhancing the clarity of their work. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the generalizability of the pre-trained model to datasets from sources other than Reddit, specifically mentioning Twitter and Facebook. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion on how to address this concern or whether the authors should conduct experiments on these platforms. Without any guidance or direction, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the generalizability of the pre-trained model to datasets from sources other than Reddit, specifically mentioning Twitter and Facebook. However, it does not specify which part of the paper this issue is related to, such as the methodology or results sections, making it weakly grounded. The comment is specific in its concern about the generalizability of the model, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the generalizability of the pre-trained model to datasets from sources other than Reddit, specifically mentioning Twitter and Facebook. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the generalizability of the pre-trained model to datasets from sources other than Reddit, specifically mentioning Twitter and Facebook. This is a valid point that could impact the applicability and robustness of the model. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or conduct experiments to evaluate the model\\'s performance on these platforms. Without actionable advice or detailed feedback, the authors are left with a general awareness of a potential limitation but without a clear path forward for improvement. Therefore, the comment is somewhat helpful, as it identifies a relevant concern but does not provide sufficient guidance for the authors to address it effectively.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential for LLMs to hallucinate and questions how the authors quality check the generated dataset. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific steps should be taken to address this concern or how to improve the quality checking process. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the potential for LLMs to hallucinate and questions how the authors quality check the generated dataset. However, it does not specify which part of the paper discusses the dataset or the quality checking process, making it difficult for the authors to identify the exact section that needs attention. The comment lacks grounding as it does not reference a specific section or part of the paper, and it is also not specific about what needs to be addressed regarding the quality checking process. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the potential for LLMs to hallucinate and questions how the authors quality check the generated dataset. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the potential for LLMs to hallucinate and questions how the authors quality check the generated dataset. This is a relevant issue that could impact the reliability and validity of the results. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this concern. Without actionable advice or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential issue but does not offer any constructive feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the comparison across four models, suggesting that the fine-tuned wav2vec model is likely to perform better than the others, which are trained from scratch. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative comparisons, additional experiments, or modifications to the training process. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the comparison across four models, specifically noting that only the wav2vec model is fine-tuned, while the others are trained from scratch. This implies that the comparison might not be meaningful due to the potential advantage of the fine-tuned model. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing the concern about the comparison, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison across four models may not be meaningful because the wav2vec model is fine-tuned, while the others are trained from scratch. This claim is based on a logical inference that the fine-tuned model would likely perform better. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to consider this reasoning and potentially conduct additional analysis or experiments to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the comparison across four models, noting that only the wav2vec model is fine-tuned, while the others are trained from scratch. This observation suggests that the comparison might not be meaningful due to the potential advantage of the fine-tuned model. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or modifications to the training process. While it identifies a potential weakness in the comparison, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specific guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the paper is well-written but notes that it feels dense, even compared to other pure-math ML papers. It suggests that more examples, such as Figure 2, would be helpful. While the comment implies that the authors should consider adding more examples to make the paper less dense, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given specific guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment mentions that the paper feels dense, even compared to other pure-math ML papers, and suggests that more examples, such as Figure 2, would help. This provides a specific suggestion for improvement, but it does not explicitly mention which part of the paper is dense or where Figure 2 is located. The authors can infer that the comment is related to the sections or figures that could benefit from additional examples, but the lack of explicit references makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper feels dense compared to other pure-math ML papers and suggests that more examples, such as Figure 2, would help. However, the comment lacks specific examples or references to support the claim about the paper\\'s density or the effectiveness of additional examples. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment acknowledges that the paper is well-written but notes that it feels dense, even compared to other pure-math ML papers. It suggests that more examples, such as Figure 2, would be beneficial. While the comment identifies a potential issue with the paper's density, it lacks specific guidance on how to address this issue or which sections might benefit from additional examples. The feedback is somewhat helpful as it points out a potential area for improvement, but it does not provide detailed actionable advice. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the high-level intuition provided in Section 4.2 and the lack of it in Section 4.1. However, it does not offer any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on how to improve Section 4.1 or what specific changes should be made to align it with the high-level intuition provided in Section 4.2. Without actionable advice or concrete steps, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a difference in the level of intuition provided between Sections 4.2 and 4.1. However, it does not specify which part of the paper these sections are in, making it difficult for the authors to identify the exact sections being addressed. Additionally, the comment lacks specificity regarding what needs to be improved or how the authors should address the difference in intuition. Without explicit references or detailed guidance, the authors cannot effectively respond to the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that Section 4.2 starts with high-level intuition, while Section 4.1 does not. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the comparison or how to address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a difference in the level of intuition provided between Sections 4.2 and 4.1. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might address this issue. Without detailed guidance or examples, the authors are left without a clear understanding of what changes are needed to improve their draft. This makes the comment barely helpful, as it identifies a potential area for improvement but does not offer sufficient guidance for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that more discussions can be introduced regarding the permutation matrices obtained in Figure 3, specifically mentioning Figure (e)(j)(o). While it implies that the authors should expand on these matrices, the comment does not provide specific guidance on what aspects should be discussed or how to present this information. The action is implicit and somewhat vague, as the authors need to infer that they should add more content but are not given concrete instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and specifies the particular figures \"(e)(j)(o)\" that are being addressed. This allows the authors to accurately identify the part of the paper being discussed. The comment is also specific because it suggests introducing more discussions about the permutation matrices obtained in these figures. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that more discussions can be introduced regarding the permutation matrices obtained in Figure 3, specifically mentioning Figure (e)(j)(o). However, the comment does not provide any reasoning or justification for why these discussions are necessary or how they would enhance the paper. Without supporting evidence or explanation, the claim lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that more discussions can be introduced regarding the permutation matrices obtained in Figure 3, specifically mentioning Figure (e)(j)(o). While it identifies an area where additional content could be beneficial, the comment lacks specificity and does not provide guidance on what aspects of the permutation matrices should be discussed or how to present this information. This makes it somewhat helpful, as it points out a potential area for improvement but does not offer detailed actionable feedback. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the crowd workers, specifically asking about their identity, recruitment, and training. While it implies that the authors should provide more information on these aspects, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address these questions but are not given specific guidance on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the crowd workers, specifically asking about their identity, recruitment, and training. However, it does not specify which part of the paper this information should be included in, such as the methodology or results sections. Without explicit references to these sections, the authors may find it challenging to determine where to address these questions. The comment is specific in its request for information but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a series of questions about the crowd workers, including their identity, recruitment, and training. These questions are factual and do not express an opinion or claim that requires verification. They are merely requests for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the crowd workers involved in the study, specifically asking about their identity, recruitment, and training. While it does not provide specific suggestions for improvement, it highlights a critical aspect of the methodology that needs clarification. This feedback is somewhat helpful as it prompts the authors to address these gaps in their paper, potentially enhancing the transparency and credibility of their work. However, it could be more helpful if it included suggestions on how to address these questions or provided examples of how similar studies have handled similar issues. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the weak correlation between automatic metrics and human evaluations, suggesting that the automatic metrics may not fully capture the quality of the simplifications. It raises questions about the validity and robustness of the conclusions drawn from the automatic metrics. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the evaluation process. The feedback is implicit and somewhat vague, as it does not offer concrete steps for the authors to follow. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of weak correlation between automatic metrics and human evaluations, suggesting that the automatic metrics may not fully capture the quality of the simplifications. It raises questions about the validity and robustness of the conclusions drawn from these metrics. However, the comment does not specify which part of the paper discusses this correlation or where the human evaluations are presented, making it weakly grounded. The comment is specific in detailing the issue with the correlation and the importance of human evaluations, but without clear grounding, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the weak correlation between automatic metrics and human evaluations raises questions about the validity and robustness of the conclusions. However, it does not provide specific examples or detailed reasoning to support this claim. The comment suggests that human evaluations are more important, but it lacks concrete evidence or references to substantiate this assertion. As a result, the claim is somewhat verifiable, as it provides a general direction for the authors to consider but lacks the depth needed for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment highlights a potential issue with the weak correlation between automatic metrics and human evaluations, suggesting that the automatic metrics may not fully capture the quality of the simplifications. It raises important questions about the validity and robustness of the conclusions drawn from these metrics. The comment also emphasizes the importance of human evaluations, which is a valuable insight for the authors. However, the feedback could be more helpful if it provided specific suggestions on how to address this issue, such as recommending additional human evaluation methods or discussing the limitations of the current approach. Despite this, the comment offers a clear direction for the authors to consider, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to be more specific in the \"Chain of Reasoning\" section, particularly at line 276. This provides a clear and direct action for the authors to take, as they know exactly what part of the paper needs improvement. The comment is explicit and concrete, offering a specific line to focus on, which makes it highly actionable. Therefore, the comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Chain of Reasoning\" section and a specific line number, \"line 276,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it instructs the authors to be more specific in this section, providing clear guidance on what needs to be improved. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification, specifically asking for more specificity in the \"Chain of Reasoning\" section, particularly at line 276. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for additional detail, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improvement by asking the authors to be more detailed in the \"Chain of Reasoning\" section, particularly at line 276. This feedback is clear and directs the authors to a specific area of the paper where they can enhance the clarity and depth of their argument. By addressing this suggestion, the authors can improve the comprehensibility and robustness of their reasoning, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a sample quality metric on the CARLA data, specifically mentioning the common metric minADE or minMSD. It provides a concrete example of how to implement this suggestion by mentioning the need to fix a budget of samples. This level of detail makes the action clear and actionable for the authors, as they know exactly what metric to include and how to compute it. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ability to perform \"hypothetical inference\" / planning\" and refers to a specific part of the paper, \"demonstrated using their graphical model and likelihood function,\" allowing the authors to accurately identify the section being addressed. It also specifies the need for a sample quality metric on the CARLA data, suggesting the use of minADE or minMSD, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should include a sample quality metric on the CARLA data, specifically mentioning minADE or minMSD. The reviewer provides a clear example of how this metric is computed, which supports the claim. However, the comment could be strengthened by providing more context or references to why this metric is important or how it relates to the paper\\'s findings. Overall, the claim is mostly verifiable, as it provides a specific suggestion with some supporting information, but it lacks detailed justification or references to fully substantiate the need for this metric. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending the inclusion of a sample quality metric on the CARLA data, such as minADE or minMSD. It offers a concrete example of how this metric is computed, which gives the authors clear guidance on what to add to their draft. This feedback is actionable and provides a clear direction for enhancing the paper, making it mostly helpful. However, the comment could be more helpful if it explained why this metric is important or how it relates to the paper\\'s findings, which would further enhance its utility for the authors. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the assumption of having every constraint and the corresponding discriminator. While it implies that the authors should clarify or address this assumption, the comment does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify their assumptions but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the assumption of having every constraint and the corresponding discriminator, but it does not specify which part of the paper this assumption is related to. The authors may infer that it pertains to the methodology or results sections, but without explicit grounding, it is difficult to pinpoint the exact part of the paper being addressed. The comment is specific in questioning the assumption, but it lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the assumption of having every constraint and the corresponding discriminator. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the assumption of having every constraint and the corresponding discriminator, which could be a critical aspect of the methodology or results. However, it does not provide any specific guidance or suggestions on how the authors might address this assumption or clarify it in their paper. The comment lacks depth and actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors might benefit from discussing or adding the Wasserstein GAN (WGAN) as a baseline method, given its connection to the use of Optimal Transport (OT) or the Wasserstein Distance in GANs. While the comment implies that discussing WGAN could be beneficial, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to incorporate WGAN into the paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Wasserstein GAN paper\" and \"WGAN (Arjovsky et al. ICML 2017),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests discussing WGAN or adding it as a baseline method, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of Optimal Transport (OT) or the Wasserstein Distance in GANs is first seen in the Wasserstein GAN paper by Arjovsky et al. (ICML 2017). The comment provides a specific reference to the WGAN paper, which supports the claim by establishing a clear connection to the original work. This level of detail makes the claim mostly verifiable, as it provides a robust basis for the assertion. However, the comment could be strengthened by further elaboration or examples of how WGAN could be integrated as a baseline method. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that the authors discuss or include the Wasserstein GAN (WGAN) as a baseline method, given its connection to the use of Optimal Transport (OT) or the Wasserstein Distance in GANs. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the paper by referencing a relevant and pioneering work in the field. By incorporating WGAN as a baseline, the authors can provide a more comprehensive comparison and context to their work, which could improve the paper\\'s depth and relevance. However, the comment could be more helpful if it offered additional guidance on how to integrate WGAN or what specific aspects to focus on. Overall, the comment is mostly helpful, as it offers a valuable suggestion for improvement but could be more detailed in its guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of important related work on MCMC in discrete spaces and suggests that several methods have applied Langevin MCMC to sample discrete sequences. It implies that the authors should discuss these methods. However, the comment does not explicitly instruct the authors to include these references or provide specific guidance on how to integrate this information into the paper. The action is implicit and somewhat vague, as the authors can infer that they need to discuss related work but are not given clear instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the absence of \"important related work on MCMC in discrete spaces,\" allowing the authors to identify the specific area needing attention. It also provides specific references to related work, such as \"Langevin MCMC to sample discrete sequences\" by Zhang et al. and Sun et al., which helps the authors understand what specific aspects should be discussed. The comment is specific in detailing what is missing and provides examples of relevant work, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that important related work on MCMC in discrete spaces is absent and suggests that several methods have applied Langevin MCMC to sample discrete sequences. The reviewer supports this claim by referencing specific papers by Zhang et al. and Sun et al., providing a clear and direct link to the relevant literature. This level of detail and reference to external sources makes the claim fully verifiable, as it provides a robust basis for the authors to understand and address the issue. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of important related work on MCMC in discrete spaces. It specifically mentions several methods that have applied Langevin MCMC to sample discrete sequences, which should be discussed in the paper. This feedback is clear and actionable, as it provides specific references to relevant work that the authors can include to enhance the paper. Additionally, the comment offers a broader assessment of the paper\\'s suitability for publication, suggesting that it may be more appropriate for a workshop due to its preliminary results and issues with clarity and organization. This feedback is highly helpful as it not only identifies a specific area for improvement but also offers a constructive suggestion for enhancing the paper\\'s quality and relevance. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the methods used by DS-FedDRO and FedDRO to estimate $g$, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on what the authors should do to address this question or how they might improve their draft. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the methods used by DS-FedDRO and FedDRO to estimate $g$, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to the methodology or results sections, but without explicit references, it is weakly grounded. The comment is specific in its inquiry about the methods used, but it lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification on the methods used by DS-FedDRO and FedDRO to estimate $g$. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the methods used by DS-FedDRO and FedDRO to estimate $g$, which could indicate a potential inconsistency or lack of clarity in the paper. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their draft. The comment lacks actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include some discussion about the difference between \"(6)\" in \"Nicekl Kiela\" and \"l.\" However, it does not provide any guidance on what specific aspects of the difference should be discussed or how this discussion should be integrated into the paper. The action is implicit and vague, leaving the authors without clear direction on how to address the suggestion. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests a discussion about the difference between \"(6)\" in \"Nicekl Kiela\" and \"l.\" However, it does not specify which part of the paper this discussion should be included in, nor does it provide details on what aspects of the difference should be discussed. This makes it difficult for the authors to identify the exact section that needs attention. The comment is not grounded as it does not reference a specific part of the paper, and it is also not specific in terms of what needs to be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests a discussion about the difference between \"(6)\" in \"Nicekl Kiela\" and \"l.\" However, it does not provide any context, explanation, or justification for why this discussion is necessary or how it would improve the paper. Without additional information or reasoning, the authors may find it challenging to understand the relevance or importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include a discussion about the difference between \"(6)\" in \"Nicekl Kiela\" and \"l.\" However, it does not provide any context or explanation about what this difference is or why it is important. Without additional information or guidance, the authors may find it challenging to understand the relevance of this suggestion or how to incorporate it into their paper. The comment lacks specificity and actionable feedback, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. While the comment implies that the authors should conduct multiple experiments and include variance analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer the need for these changes but may not be entirely sure of the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. However, it does not specify which experiments or sections of the paper this issue pertains to, making it weakly grounded. The comment is specific in identifying the lack of variance analysis, but without clear grounding, the authors may struggle to determine which parts of the paper need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or detailed explanations, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental methodology, specifically noting that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. This feedback is relevant and highlights an important aspect of experimental design that could impact the reliability and robustness of the findings. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending the number of repetitions or statistical tests to use for variance analysis. Despite this, the comment still offers valuable insight into an area that needs improvement, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights gaps between the experiments conducted in the paper and the goal of achieving label efficiency with a human in the loop, particularly in terms of differing dataset qualities and temporal drifts in data distributions. However, it does not provide explicit guidance or suggestions on how the authors should address these gaps. The comment implies that the authors should consider these factors in their experiments, but it lacks concrete details on how to incorporate them or what specific changes should be made. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights gaps between the experiments conducted in the paper and real-world datasets, specifically mentioning differing dataset qualities and temporal drifts in data distributions. However, it does not specify which part of the paper these gaps are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in detailing the issues with the experiments but lacks grounding, as it does not provide a clear reference to the sections where these gaps are discussed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are gaps between the experiments conducted in the paper and real-world datasets, specifically mentioning differing dataset qualities and temporal drifts in data distributions. The comment acknowledges the authors\\' recognition of these gaps but suggests that they should be addressed. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact nature of these gaps and how they impact the experiments, which could be challenging without further guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the use of real-world datasets, specifically highlighting the differences between the experimental setup and the goal of achieving label efficiency with a human in the loop. It points out factors such as differing dataset qualities and temporal drifts in data distributions that are not accounted for in the experiments. This feedback is somewhat helpful as it directs the authors\\' attention to a critical area for improvement, suggesting that they should consider these factors in their experiments. However, the comment lacks specific suggestions or guidance on how to address these gaps, which would make it more actionable. Therefore, it aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point compares the communication cost provided in the paper (O(SAH^2) or O(MSAH^2)) to that of other federated Q-learning algorithms, which have demonstrated O(H) communication rounds. While the comment highlights a potential issue with the communication cost, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit, as the authors need to infer that they should consider the communication cost in relation to other algorithms, but it lacks concrete details on how to improve it. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the communication cost provided in the paper, specifically mentioning the complexity O(SAH^2) or O(MSAH^2). However, it does not specify which part of the paper discusses this communication cost, making it weakly grounded. The comment is specific in its critique, as it compares the communication cost to that of other federated Q-learning algorithms, which have demonstrated O(H) communication rounds. This provides a clear basis for the authors to understand what needs to be addressed regarding the communication cost. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the communication cost provided in the paper is not particularly low or noteworthy compared to other federated Q-learning algorithms. The reviewer supports this claim by referencing other algorithms that have demonstrated O(H) communication rounds, which is a logical comparison. However, the comment could be strengthened by providing specific examples or references to these other algorithms, which would make the claim more fully verifiable. As it stands, the comment is mostly verifiable, as it provides a basis for the claim but lacks detailed evidence. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment points out that the communication cost provided in the paper, O(SAH^2) or O(MSAH^2), does not seem particularly low or noteworthy compared to other federated Q-learning algorithms that have demonstrated O(H) communication rounds. This feedback is somewhat helpful as it highlights a potential area for improvement in the paper's communication efficiency. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the communication cost. While it identifies a weakness, it does not provide actionable steps for the authors to take, limiting its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the originality of the paper\\'s main idea, stating that it is common in machine learning literature and lacks specific adaptation to the homomorphic encryption domain. However, it does not provide any explicit or implicit suggestions for improvement. The authors are left without guidance on how to address the issue or enhance the originality of their work. Without actionable advice or specific feedback, the comment does not help the authors improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the originality of the paper\\'s main idea, specifically mentioning the use of an ensemble of neural networks, which is common in machine learning literature. It also notes the lack of specific adaptation to the homomorphic encryption domain. However, the comment does not specify which part of the paper this critique is based on, such as a particular section or figure, making it weakly grounded. The comment is specific in its critique of the lack of originality and adaptation, but without clear grounding, the authors may struggle to identify the exact parts that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the main idea of using an ensemble of neural networks is \"trivial and very common in machine learning literature.\" However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The comment lacks detailed reasoning or evidence, such as comparisons with other works or explanations of why the adaptation to the homomorphic encryption domain is insufficient. Without this information, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the originality of the paper\\'s main idea, stating that using an ensemble of neural networks is a common practice in machine learning literature and lacks specific adaptation to the homomorphic encryption domain. While the comment identifies a potential weakness in the paper, it does not provide any actionable suggestions or guidance on how the authors might address this issue or enhance the originality of their work. Without specific feedback or recommendations, the authors are left without a clear path for improvement. Therefore, the comment is barely helpful, as it highlights a problem but lacks actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper presents a new model for detecting overlapping entities in text, which improves the previous state-of-the-art model, MH, on a few benchmark datasets. However, it notes that it is unclear why and how the new model works better. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should provide a clearer explanation of the new model's advantages. The feedback is somewhat actionable because it highlights a critical area for improvement, but it lacks concrete steps or suggestions on how to enhance the explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding why and how the new model works better than the previous state-of-the-art model, MH. The comment provides a clear direction for the authors to improve their paper by explaining the advantages of the new model. Therefore, this comment is labeled as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper presents a new model for detecting overlapping entities in text, which improves the previous state-of-the-art model, MH, on a few benchmark datasets. However, it notes that it is unclear why and how the new model works better. The comment lacks specific examples or detailed reasoning to support the claim that the new model is an improvement. Without additional evidence or explanation, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of clarity regarding why and how the new model for detecting overlapping entities in text improves upon the previous state-of-the-art model, MH. This is a critical area for improvement, as understanding the advantages of the new model is essential for evaluating its effectiveness. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments, theoretical analysis, or detailed explanations. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the formula used in the Adjective Projection part, suggesting a different approach for estimating whether an object is large or small. It explicitly states that the authors should first calculate the similarity between \"large\" and the object, then \"small\" and the object, and finally calculate the difference between the two similarities. This provides a clear and concrete action for the authors to take, ensuring they know exactly how to modify their formula. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Adjective Projection part,\" allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies the issue with the formula, suggesting a different approach for estimating whether an object is large or small. The reviewer provides a detailed explanation of the proposed change, including the steps to calculate the similarity and the difference between the two similarities. This level of detail helps the authors understand what needs to be addressed and how to improve their work. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the formula used in the Adjective Projection part, suggesting a different approach for estimating whether an object is large or small. The reviewer provides a logical explanation of why the current method is not reasonable and proposes an alternative method involving calculating similarities and differences. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by including specific examples or references to support the proposed alternative method. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the formula used in the Adjective Projection part, suggesting a different approach for estimating whether an object is large or small. It provides a clear and actionable suggestion by explaining the need to calculate the similarity between \"large\" and the object, then \"small\" and the object, and finally calculating the difference between the two similarities. This feedback is detailed and offers a concrete way for the authors to improve their draft, making it highly helpful. The comment effectively guides the authors in refining their methodology, which is a significant contribution to the paper\\'s improvement. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of the expression \"\u03c3_k = sigmoid(\u03c3_k)\" in line 121, indicating that \u03c3_k appears on both sides of the equation. This is an explicit question that prompts the authors to clarify the mathematical expression. Additionally, the reviewer expresses interest in the proposed method and suggests that the authors elaborate on the issues mentioned, which implies a request for further explanation. However, the comment does not provide specific guidance on how to elaborate or what aspects to focus on. While the question is clear, the suggestion for elaboration is vague, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 121,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the expression \"\u03c3_k = sigmoid(\u03c3_k),\" where \u03c3_k appears on both sides, which provides clear guidance on what needs to be clarified. Additionally, the comment suggests that the authors elaborate on the issues mentioned, which implies a request for further explanation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the meaning of the expression \"\u03c3_k = sigmoid(\u03c3_k)\" in line 121, indicating that \u03c3_k appears on both sides of the equation. This is a factual question seeking clarification, rather than a claim that requires verification. The comment also expresses interest in the proposed method and suggests that the authors elaborate on the issues mentioned, but it does not present any claims or opinions that need verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the mathematical expression \"\u03c3_k = sigmoid(\u03c3_k)\" in line 121, indicating that \u03c3_k appears on both sides of the equation. This is a clear and specific question that prompts the authors to clarify the meaning of the expression. Additionally, the reviewer expresses interest in the proposed method, noting its ability to capture long-range context information for several computer vision tasks. The comment suggests that the authors provide more information on the issues mentioned, which could be beneficial for the authors to address. However, the comment could be more helpful if it provided specific guidance on how to elaborate on these issues or what aspects to focus on. Overall, the comment is somewhat helpful as it identifies a need for clarification and suggests a direction for further elaboration, but it lacks depth and actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should discuss and compare their work on any-resolution generation with more recent works that focus on this specific area. The reviewer provides specific references to papers that could be used for comparison, such as [1] and [2]. While the action is explicit, the comment does not provide detailed guidance on how to conduct the comparison or what specific aspects should be discussed. The authors know they need to compare their work with recent studies, but the exact steps to take are not fully outlined. Therefore, the comment is mostly actionable, as it provides a clear direction but lacks detailed instructions on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the authors should discuss and compare their work on any-resolution generation with more recent works that focus on this specific area. It provides specific references to papers that could be used for comparison, such as [1] and [2]. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the discussion or results section, but this inference is not direct. The comment is specific in suggesting a comparison with recent works, but it lacks grounding in terms of identifying the exact part of the paper where this comparison should be made. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the claim of an advantage in any-resolution generation should be discussed and compared with more recent works on this topic. The reviewer provides specific references to papers that could be used for comparison, such as [1] and [2]. This provides a clear basis for the claim, as it references specific works that could be used to support or challenge the authors\\' claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how these works relate to the authors\\' claim. Overall, the claim is mostly verifiable, as it offers a solid foundation for further exploration but could benefit from more detailed justification. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that the authors should discuss and compare their work on any-resolution generation with more recent works that focus on this specific area. It provides specific references to papers that could be used for comparison, such as [1] and [2]. This feedback is clear and actionable, as it directs the authors to enhance the relevance and impact of their work by engaging with recent advancements in the field. However, the comment could be more helpful if it offered guidance on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the CT experiment having only one subject in the test set, which may lead to overfitting. It suggests that the authors should discuss limitations of the work, such as theoretical assumptions and implementation considerations. Additionally, it questions the relative improvement of ODER over RED (Unfold) or RED (Denoising) and asks about the training time comparison. While the comment implies that the authors should address these limitations and provide additional information, it does not explicitly instruct them to do so. The actions are inferred and somewhat vague, as the authors need to deduce the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 6\" and \"84: 1763\u2013 1780,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of overfitting in the CT experiment and suggests that the authors discuss limitations of the work, such as theoretical assumptions and implementation considerations. Additionally, it raises questions about the relative improvement of ODER over RED (Unfold) or RED (Denoising) and the training time comparison. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the CT experiment having only one subject in the test set, which could lead to overfitting. It suggests that the authors should discuss limitations of the work, such as theoretical assumptions and implementation considerations. Additionally, it questions the relative improvement of ODER over RED (Unfold) or RED (Denoising) and asks about the training time comparison. While the comment identifies potential issues, it lacks specific examples or references to support the claims, making it somewhat verifiable. The authors would need to provide additional evidence or reasoning to fully substantiate the concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the CT experiment having only one subject in the test set, which could lead to overfitting. It suggests that the authors should discuss limitations of the work, such as theoretical assumptions and implementation considerations, which is a valuable suggestion for improving the paper. Additionally, the comment raises questions about the relative improvement of ODER over RED (Unfold) or RED (Denoising) and the training time comparison, providing specific areas for further analysis. However, the comment could be more helpful if it offered more detailed guidance on how to address these limitations or provided examples of theoretical assumptions and implementation considerations that should be discussed. Overall, the comment is mostly helpful as it points out important areas for improvement and provides some direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point points out an error in the paper, specifically that the bound on the 2-Wasserstein is stated as $O(\\\\epsilon^2)$, but it should be the bound on the 2-Wasserstein squared. However, it does not provide explicit guidance on how the authors should correct this error or suggest a specific action to take. The comment implies that the authors need to correct the statement, but it lacks concrete instructions on how to do so. Therefore, the comment is somewhat actionable, as it identifies an issue but does not provide detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the line numbers \"216 and 217,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error regarding the bound on the 2-Wasserstein, indicating that the statement is incorrect and should be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the bound on the 2-Wasserstein is incorrectly stated as $O(\\\\epsilon^2)$, when it should be the bound on the 2-Wasserstein squared. This is a factual statement that requires no justification or evidence, as it is a straightforward correction of a mathematical statement. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific error in the paper, pointing out that the bound on the 2-Wasserstein is incorrectly stated as $O(\\\\epsilon^2)$ when it should be the bound on the 2-Wasserstein squared. This feedback is clear and actionable, as it directly addresses a mathematical mistake that needs correction. By highlighting this error, the comment provides the authors with a precise area for improvement, allowing them to correct their draft and enhance its accuracy. However, the comment could be more helpful if it provided additional context or suggestions on how to address the error or its implications. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the mathematical accuracy of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the differences between the proposed multi-scale hierarchical predictor and existing methods like IEConv and CDConv, which also use pooling layers. It references several papers that discuss related work, but it does not provide explicit guidance or suggestions for the authors to address this question. The authors are left to infer that they should clarify the differences between their method and the mentioned approaches, but without specific instructions on how to do so. This makes the comment somewhat actionable, as it identifies an area for clarification but lacks concrete steps for the authors to follow.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Comparison to other methods\" and references specific methods like IEConv and CDConv, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the differences between the proposed multi-scale hierarchical predictor and these previous methods. The comment provides references to relevant literature, which further supports the specificity of the feedback. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the differences between the proposed multi-scale hierarchical predictor and existing methods like IEConv and CDConv. It references several papers that discuss related work, which provides some context and background information. However, the comment does not provide a direct claim or opinion that requires verification. It is more of a request for clarification or a question, making it a normal statement. Therefore, the correct label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the differences between the proposed multi-scale hierarchical predictor and existing methods like IEConv and CDConv, which also use pooling layers. It references several relevant papers that discuss related work, providing a solid foundation for the authors to understand the context of their contribution. However, the comment does not offer specific suggestions or guidance on how the authors might address this question or differentiate their work from existing methods. While it highlights an important area for clarification, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it identifies a key area for improvement but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper requires more careful proofreading to improve its readability. However, it does not provide specific guidance on what aspects of the paper need proofreading or how to address the issue. The action is implicit and vague, leaving the authors without clear direction on how to implement the suggested improvement. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper needs more careful proofreading to improve its readability. However, it does not specify which parts of the paper are problematic or provide examples of areas that require attention. Without specific guidance or references to particular sections, the authors cannot confidently determine where to focus their efforts. This makes the comment not grounded, as it does not identify a specific area of the paper, and it is also not specific, as it lacks detailed guidance on what needs to be addressed. Therefore, this comment is categorized as not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper \"does not read well\" and suggests that more careful proofreading is needed. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or examples of what makes the paper difficult to read, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper requires more careful proofreading to improve its readability. However, it lacks specificity and does not provide any detailed guidance or examples of what aspects of the paper are problematic or how to address them. Without actionable feedback or suggestions, the authors are left without a clear understanding of what changes are needed to improve the draft. This makes the comment barely helpful, as it identifies a general issue but does not offer any concrete steps for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests several specific actions for the authors to consider: analyzing the distribution of addressing coefficients (Betas) with and without bias towards sequential addressing, discussing the value and selection of the trade-off parameter (Theta), and exploring a baseline where the attention from the previous question is used instead of soft attention. These suggestions are explicit and provide clear guidance on what the authors should investigate or discuss in their paper. The comment is highly actionable as it offers concrete steps for improvement, allowing the authors to know exactly what to focus on to enhance their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests several specific analyses and questions regarding the paper, such as the distribution of addressing coefficients (Betas) and the trade-off parameter (Theta). However, it does not explicitly mention which part of the paper these suggestions relate to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the analysis of Betas and the discussion of Theta. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests several analyses and questions regarding the distribution of addressing coefficients (Betas) and the trade-off parameter (Theta). It provides a logical reasoning for why these analyses are important, particularly in the context of the synthetic task where each question is based on the answer set of the previous one. However, the comment lacks specific examples or references to support the claim that these analyses are necessary or how they would impact the paper. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, providing specific suggestions that could enhance the draft. It suggests analyzing the distribution of addressing coefficients (Betas) with and without bias towards sequential addressing, which is an important aspect of the synthetic task. Additionally, it questions the value and selection of the trade-off parameter (Theta) and proposes a baseline where the attention from the previous question is used instead of soft attention. These suggestions are clear and actionable, offering the authors concrete ways to improve their analysis and presentation. However, the comment could be more helpful if it provided additional context or examples to support the suggestions. Overall, the feedback is mostly helpful as it guides the authors toward meaningful enhancements, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the necessity of proposition 1, suggesting that it is a standard regression problem and that the application of a standard concentration inequality is expected. The reviewer also expresses a personal opinion that the proposition is \"decorative math\" and does not contribute to the paper's interest. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should remove the proposition, modify it, or provide additional context to justify its inclusion. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"proposition 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with proposition 1, questioning its necessity and suggesting that it is a standard regression problem. The comment further critiques the proposition by stating that it does not contribute to the paper\\'s interest and does not make NC a complexity measure in the statistical learning sense. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of proposition 1, suggesting that it is a standard regression problem and that the application of a standard concentration inequality is expected. The reviewer also expresses a personal opinion that the proposition is \"decorative math\" and does not contribute to the paper\\'s interest. However, the comment lacks specific evidence or references to support the claim that proposition 1 is unnecessary or that it does not contribute to the paper\\'s interest. Without detailed reasoning or examples, the claim remains somewhat verifiable, as the authors would need to infer the basis of the critique and potentially conduct additional research to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the necessity of proposition 1, suggesting that it is a standard regression problem and that the application of a standard concentration inequality is expected. The reviewer also expresses a personal opinion that the proposition is \"decorative math\" and does not contribute to the paper\\'s interest. Additionally, the comment critiques the proposition by stating that it does not make NC a complexity measure in the statistical learning sense. While the comment identifies a potential issue with the inclusion of proposition 1, it lacks specific suggestions or guidance on how the authors might address this concern or improve the draft. The feedback is somewhat helpful as it prompts the authors to reconsider the relevance of the proposition, but it could be more actionable with additional details or recommendations. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the evaluation of defense techniques, specifically mentioning the importance of evaluating input perturbation-based defenses in the context of the proposed method. The reviewer suggests that this evaluation is crucial for a comprehensive understanding of the attacks. However, the comment does not provide explicit guidance on how the authors should conduct this evaluation or what specific aspects of the defense techniques should be considered. While the suggestion is clear, the lack of detailed instructions on how to implement it makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"evaluation of defense techniques,\" which allows the authors to identify the specific part of the paper being addressed. It is also specific because it highlights the importance of evaluating input perturbation-based defenses, such as those proposed by Doan et al. in their works \"Lira: Learnable, imperceptible and robust backdoor attacks\" and \"Backdoor attack with imperceptible input and latent modification.\" This provides clear guidance on what needs to be addressed in the evaluation section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation of defense techniques is limited and suggests that evaluating input perturbation-based defenses is essential for a comprehensive understanding of the attacks. The reviewer supports this claim by referencing specific works by Doan et al. (\"Lira: Learnable, imperceptible and robust backdoor attacks\" and \"Backdoor attack with imperceptible input and latent modification\") published in ICCV 2021 and NeurIPS 2021, respectively. This provides a clear and specific reference to external works that substantiate the claim, making the comment mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how these defenses should be evaluated in the context of the proposed method. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the evaluation of defense techniques, particularly in the context of backdooring classification. It highlights the importance of evaluating input perturbation-based defenses, such as those proposed by Doan et al. in their works \"Lira: Learnable, imperceptible and robust backdoor attacks\" and \"Backdoor attack with imperceptible input and latent modification.\" This feedback is valuable as it points out a gap in the evaluation and suggests specific references that could be used to enhance the comprehensiveness of the paper. However, the comment could be more helpful if it provided additional guidance on how to incorporate these defenses into the evaluation or suggested specific experiments to conduct. Overall, the comment is mostly helpful as it directs the authors to a relevant area for improvement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the related work section should be more focused and include descriptions of similar datasets for non-English or underrepresented languages. It also points out that the context and evidence-based methods are presented shallowly. While the comment implies that the authors should expand the related work section and provide more depth in the presentation of context and evidence-based methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific changes required. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the related work section should be more focused and include descriptions of similar datasets for non-English or underrepresented languages. It also criticizes the shallow presentation of context and evidence-based methods in the related work. However, the comment does not specify which part of the paper the related work section is located in, making it weakly grounded. The authors can infer that it relates to the section discussing related work, but this inference is not direct. The comment is specific in detailing what is missing or lacking in the related work section, such as the inclusion of datasets for non-English languages and a more in-depth presentation of context and evidence-based methods. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the related work section should be more focused and include descriptions of similar datasets for non-English or underrepresented languages. It also criticizes the shallow presentation of context and evidence-based methods. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or evidence renders the claim somewhat verifiable, as the authors would need to infer the specific areas needing improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the related work section, suggesting that it should be more focused and include descriptions of similar datasets for non-English or underrepresented languages. It also points out that the context and evidence-based methods are presented shallowly. This feedback is clear and actionable, as it directs the authors to expand their related work section and provide more depth in the presentation of context and evidence-based methods. However, the comment could be more helpful if it offered examples or specific suggestions on how to improve the related work section. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implementation of batch normalization (BN) in the paper, specifically regarding the placement of BN before or after ReLU. It suggests that BN can be folded into the convolution operation in a particular way, depending on the placement of BN. However, the comment does not provide explicit guidance or suggestions for the authors to address this issue or improve their draft. The authors are left to infer that they should clarify or discuss the implementation of BN in their paper, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Same paragraph\" and \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the placement of batch normalization (BN) before or after ReLU and suggests a possible way to fold BN into the convolution operation. The comment provides a clear explanation of the problem and offers a specific suggestion for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the implementation of batch normalization (BN) in the paper, specifically regarding the placement of BN before or after ReLU. The reviewer suggests that BN can be folded into the convolution operation in a particular way, depending on its placement. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the implementation of batch normalization (BN) in the paper, particularly regarding its placement before or after ReLU. It suggests that BN can be folded into the convolution operation in a particular way, depending on its placement. This feedback is somewhat helpful as it points out a potential area for clarification or improvement in the paper. However, it lacks depth and does not provide detailed guidance on how the authors might address this issue or why it is important. To be more helpful, the comment could include suggestions for experimental verification or theoretical justification. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the lack of large-scale experiments in the paper, noting that the models used are relatively small. It suggests that including experiments with varying network sizes could help determine whether the results from small-scale experiments are scalable. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on how to design these experiments or what parameters to vary. The action is implicit and somewhat vague, as the authors can infer the need for more experiments but may not know exactly how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments section\" and the specific models used in the MNIST and SVHN experiments, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of lacking large-scale experiments and suggests that varying the size of the network could help determine the scalability of the results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the models used in the experiments are too small, suggesting that larger-scale experiments would be beneficial. However, the comment does not provide specific examples or references to support the claim that larger models are necessary or that the current results are not scalable. The suggestion to vary the network size is logical, but without additional evidence or examples, the claim remains somewhat verifiable. The authors would need to infer the importance of larger-scale experiments based on the reviewer\\'s suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the paper, specifically the lack of large-scale experiments. It points out that the models used in the experiments are relatively small, which may limit the generalizability of the results. The comment suggests that including experiments with varying network sizes could help determine whether the findings from small-scale experiments are scalable. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their work by conducting additional experiments. However, it could be more helpful if it offered guidance on how to design these larger-scale experiments or what specific parameters to vary. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the behavior of the problem when W is an identity matrix, suggesting that this would reduce the problem to a spherical case and asking for a comparison with prior work. While the comment implies that the authors should address this scenario, it does not provide explicit instructions or guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this scenario and its implications. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the behavior of the problem when W is an identity matrix, suggesting that this would reduce the problem to a spherical case and asking for a comparison with prior work. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification and comparison, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification on the behavior of the problem when W is an identity matrix and how the results compare with prior work. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a relevant question about the behavior of the problem when W is an identity matrix, suggesting that this would reduce the problem to a spherical case. It also asks for a comparison with prior work, which is a valuable suggestion for enhancing the paper\\'s context and relevance. However, the comment lacks specific guidance or suggestions on how the authors might address this question or incorporate the comparison with prior work. While it identifies an important area for exploration, it does not provide actionable steps or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the work primarily focuses on CO problems on graphs, rather than general MILP or QUBO problems, which limits the application scope. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for how the authors might expand the scope of their work or address the limitation. Without any guidance or direction, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation in the work\\'s focus on CO problems on graphs, rather than general MILP or QUBO problems, which limits the application scope. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment lacks grounding as it does not provide a clear reference to a specific section, figure, or table. Additionally, it is not specific about what aspects of the application scope are limited or how this limitation could be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the work primarily focuses on CO problems on graphs, rather than general MILP or QUBO problems, which limits the application scope. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion or how it impacts the work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a limitation in the work\\'s focus on CO problems on graphs, rather than general MILP or QUBO problems, which limits the application scope. This feedback is somewhat helpful as it identifies a potential area for expansion or diversification of the work. However, it lacks specific suggestions or guidance on how the authors might address this limitation or explore broader applications. While it provides some insight into the scope of the work, it does not offer actionable steps for improvement, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the paper\\'s approach of learning both low- and high-frequency information in balance is not novel, as there have been previous works that promote uniformly learning various frequency domains. The reviewer provides specific references to related works, such as [1] Stochastic Frequency Masking to Improve Super-Resolution and Denoising Networks, [2] FSDR: Frequency Space Domain Randomization for Domain Generalization, [3] Spectrum Random Masking for Generalization in Image-based Reinforcement Learning, and [4] MASKED FREQUENCY MODELING FOR SELF-SUPERVISED VISUAL PRE-TRAINING. However, the comment does not explicitly instruct the authors to analyze or compare their work to these references, leaving the action implicit. While the authors can infer that they should consider these works, the comment lacks concrete guidance on how to integrate this information into their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the concept of learning both low- and high-frequency information in balance, which allows the authors to identify the relevant part of the paper being addressed. It is also specific because it highlights the lack of analysis or comparison to related works that promote uniformly learning various frequency domains. The comment provides specific references to these related works, which further enhances its specificity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approach of learning both low- and high-frequency information in balance is not novel, as there have been previous works that promote uniformly learning various frequency domains. The reviewer supports this claim by providing specific references to related works, such as [1] Stochastic Frequency Masking to Improve Super-Resolution and Denoising Networks, [2] FSDR: Frequency Space Domain Randomization for Domain Generalization, [3] Spectrum Random Masking for Generalization in Image-based Reinforcement Learning, and [4] MASKED FREQUENCY MODELING FOR SELF-SUPERVISED VISUAL PRE-TRAINING. These references provide a clear basis for the claim, making it fully verifiable. The reviewer has provided robust evidence to substantiate the claim, ensuring that the authors can understand and address the issue effectively. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment points out that the approach of learning both low- and high-frequency information in balance is not novel, as there have been previous works that promote uniformly learning various frequency domains. It provides specific references to related works, such as [1] Stochastic Frequency Masking to Improve Super-Resolution and Denoising Networks, [2] FSDR: Frequency Space Domain Randomization for Domain Generalization, [3] Spectrum Random Masking for Generalization in Image-based Reinforcement Learning, and [4] MASKED FREQUENCY MODELING FOR SELF-SUPERVISED VISUAL PRE-TRAINING. This feedback is mostly helpful as it directs the authors to consider these related works and potentially integrate them into their analysis or comparison. However, the comment could be more helpful if it provided specific guidance on how to incorporate these references or what aspects to focus on in the comparison. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the compression bandwidth of PC+IDF should be compared with IDF in Section 5. However, it does not provide explicit instructions on how to conduct this comparison or what specific aspects of the compression bandwidth should be evaluated. The action is implicit and somewhat vague, as the authors can infer that they need to make a comparison but are not given detailed guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the recommendation to compare the compression bandwidth of PC+IDF with IDF in this section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a comparison between the compression bandwidth of PC+IDF and IDF in Section 5. However, it does not provide any reasoning, evidence, or references to support why this comparison is necessary or beneficial. The lack of justification or explanation makes it difficult for the authors to understand the basis of the suggestion, rendering the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a specific comparison between the compression bandwidth of PC+IDF and IDF in Section 5. While it identifies a potential area for improvement by recommending a comparison, it lacks depth and does not provide any rationale or context for why this comparison is important or how it might impact the paper. The feedback is somewhat helpful as it points out a potential area for enhancement, but it does not offer detailed guidance or actionable steps for the authors to follow. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the model names \"T5-ind\" and \"T5-seq\" are misleading and proposes alternative names such as \"Desc-ind/seq,\" \"Eg-ind,\" and \"Demo-ind/seq.\" This feedback is explicit and provides concrete suggestions for renaming the models, giving the authors a clear direction on how to improve their draft. The action is direct and specific, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the model names \"T5-ind\" and \"T5-seq,\" suggesting that they are misleading and proposing alternative names. However, it does not specify which part of the paper these model names are mentioned in, making it weakly grounded. The comment is specific in suggesting alternative names, which provides clear guidance on how to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the model names \"T5-ind\" and \"T5-seq\" are misleading and suggests alternative names. However, the comment does not provide any reasoning or justification for why these names are misleading or how the suggested alternatives are more appropriate. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the model names \"T5-ind\" and \"T5-seq,\" suggesting that they are misleading. It provides a clear and actionable suggestion by proposing alternative names, such as \"Desc-ind/seq,\" \"Eg-ind,\" and \"Demo-ind/seq.\" This feedback is direct and offers a concrete way for the authors to improve the clarity and accuracy of their model naming conventions. By addressing this issue, the authors can enhance the readability and comprehensibility of their paper. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of the acronym \"AR\" for \"artificial intelligence\" and notes its repeated use in line 055. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion to change the acronym, provide a rationale for its choice, or clarify its usage. Without actionable advice or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the choice of the acronym \"AR\" for \"artificial intelligence\" and mentions its repeated use in line 055. This provides full grounding as it explicitly mentions the specific part of the paper where the issue is observed, allowing the authors to accurately identify the section. The comment is also specific because it clearly specifies the issue with the acronym and its repeated use, providing a clear direction for the authors to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of the acronym \"AR\" for \"artificial intelligence\" and its repeated use in line 055. However, it does not provide any reasoning, evidence, or justification for why this choice might be problematic or why it is used again. Without any supporting information or context, the claim lacks verifiability, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the choice of the acronym \"AR\" for \"artificial intelligence\" and notes its repeated use in line 055. While it identifies a potential issue with the consistency of the paper, it does not provide any guidance or suggestions on how the authors might address this issue. The comment lacks depth and does not offer actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the motivation behind the gating design for Multi-Task Learning (MTL) and questions the novelty of the gating mechanism. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the lack of clarity in the motivation or how to enhance the novelty of the gating mechanism. Without actionable suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the core idea of the paper, specifically questioning the motivation behind the gating design for Multi-Task Learning (MTL) and suggesting that the gating mechanism is not novel. However, it does not specify which part of the paper discusses the gating design or the motivation, making it difficult for the authors to pinpoint the exact sections that need revision. The comment lacks grounding as it does not provide explicit references to the paper, leaving the authors to make an educated guess about the relevant parts. Additionally, while it identifies a potential issue with the novelty of the gating mechanism, it does not specify how this could be addressed or improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the motivation behind the gating design for Multi-Task Learning (MTL) is unclear and that the gating mechanism is not novel. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by questioning the motivation behind the gating design for Multi-Task Learning (MTL) and suggesting that the gating mechanism is not novel. However, it does not provide specific guidance or suggestions on how the authors might address these issues or enhance the novelty of their approach. The comment highlights a critical area for improvement but lacks actionable feedback, making it somewhat helpful. The authors are given some insight into a potential weakness but are left without detailed guidance on how to improve their draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the practicality of the model, noting that the strong assumptions required for training, such as the availability of ground truth and DM\\'s decisions, may impair its practicability. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or mitigate the impact of these assumptions. The comment implies that the authors should consider the limitations of their model and how to make it more practical, but it lacks concrete steps or recommendations for improvement. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the practicality of the model, specifically mentioning the strong assumptions required for training, such as the availability of ground truth and DM\\'s decisions. However, it does not specify which part of the paper discusses these practical scenarios or assumptions, making it weakly grounded. The comment is specific in detailing the issue with the assumptions, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the practicability of the model is impaired by strong assumptions necessary for its training, such as the availability of ground truth and DM\\'s decisions. The comment provides a logical reasoning by highlighting the potential limitations of these assumptions, which could impact the model\\'s applicability. However, it lacks specific examples or references to support the claim fully, making it somewhat verifiable. The authors would need to consider these assumptions and their implications more deeply to fully address the comment. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper\\'s approach, specifically the strong assumptions required for training the model. It highlights the need for ground truth and DM\\'s decisions for each DM of interest, which may introduce biases, uncertainties, or behaviors during training. This feedback is somewhat helpful as it points out a critical aspect of the model\\'s practicability that the authors should consider. However, the comment lacks specific suggestions or guidance on how the authors might address these limitations or mitigate their impact. To be more helpful, the comment could provide recommendations or examples of how to improve the model\\'s robustness or applicability under these assumptions. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experimental part is less convincing due to the weakness of the LR and SVM baselines compared to deep learning approaches. However, it does not provide any explicit or implicit actions for the authors to take to improve the experimental section. There is no guidance on how to strengthen the baselines, what specific changes could be made, or what alternative approaches might be considered. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experimental part of the paper, suggesting that the LR and SVM baselines are too weak compared to deep learning approaches. However, it does not specify which part of the experimental section this issue pertains to, such as specific results, figures, or tables. Additionally, it lacks specificity in terms of what aspects of the baselines are weak or how they could be improved. Without explicit references or detailed guidance, the authors cannot confidently determine which parts of the paper need revision. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the experimental part is less convincing due to the weakness of the LR and SVM baselines compared to deep learning approaches. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any evidence or references to substantiate why these baselines are weak or how they compare to deep learning approaches. Without this information, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the experimental section, noting that the LR and SVM baselines are too weak compared to deep learning approaches. This feedback highlights an area where the authors could improve the robustness and credibility of their experimental results. However, the comment lacks specificity and does not provide actionable suggestions on how to strengthen the baselines or what specific changes could be made to improve the experimental section. Without detailed guidance, the authors may find it challenging to address the issue effectively. Therefore, the comment is somewhat helpful, as it points out a weakness but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the claimed motivation of the GLASU algorithm, which is to save communication, and the lack of discussion or analysis of the communication cost in the theorem and experiment sections. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this gap. The authors are left to infer that they need to include a discussion or analysis of the communication cost, but the comment lacks concrete details on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of discussion on communication cost in the paper, specifically mentioning the theorem and experiment sections. This provides full grounding as the authors can accurately identify the parts of the paper being addressed. However, the comment is not specific in detailing what aspects of the communication cost should be discussed or how it undermines the contribution of the paper. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the paper\\'s motivation for the GLASU algorithm is to save communication, but neither the theorem nor the experiment discusses the communication cost. This claim is somewhat verifiable as it highlights a potential gap in the paper\\'s discussion. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it difficult for the authors to understand the exact nature of the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the motivation for the GLASU algorithm is to save communication, but neither the theorem nor the experiment discusses the communication cost. This observation highlights a gap in the paper that could undermine its contribution. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the discussion of communication costs. While it points out a weakness, it lacks actionable feedback, making it somewhat helpful. The authors are left to infer that they need to include a discussion on communication costs, but without detailed guidance, the comment does not fully support their improvement efforts. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to \"explicitly state the contributions of the paper.\" This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete suggestion, leaving no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the contributions of the paper should be explicitly stated, but it does not specify which part of the paper this should be addressed in. The authors may need to review their introduction or conclusion sections to identify where the contributions are mentioned and how they can be clarified. Since the comment does not provide specific guidance on where to make these changes, it is weakly grounded but specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the contributions of the paper should be explicitly stated. However, it does not provide any reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the contributions of the paper should be explicitly stated. While this is a valid point, the feedback lacks specificity and does not provide guidance on how to articulate these contributions or where they should be emphasized in the paper. Without detailed suggestions or examples, the authors may find it challenging to address this feedback effectively. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but does not offer actionable advice. It aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the motivation and explanation of the work, specifically mentioning that the statement \"different densities directly will cause semantic conflicts\" should be justified experimentally or theoretically. While the comment identifies an area for improvement, it does not provide explicit guidance on how to justify this claim or what specific experiments or theoretical frameworks should be used. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide additional justification but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the motivation and explanation of the work, specifically mentioning a statement about \"different densities directly will cause semantic conflicts.\" This provides full grounding as it explicitly references a specific part of the paper, allowing the authors to accurately identify the section being addressed. The comment is also specific because it clearly specifies what is lacking, namely a justification of this claim either experimentally or theoretically. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation of the work is not clear and the explanation is not convincing. It specifically mentions a statement about \"different densities directly will cause semantic conflicts\" and suggests that this should be justified experimentally or theoretically. However, the comment does not provide any supporting evidence, examples, or references to substantiate the claim that the motivation is unclear or that the explanation is lacking. Without additional context or justification, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of clarity in the motivation and explanation of the work. It points out a specific statement about \"different densities directly will cause semantic conflicts\" and suggests that this claim should be justified either experimentally or theoretically. This feedback is clear and actionable, as it directs the authors to address a specific gap in their argumentation. However, the comment could be more helpful if it provided additional guidance on how to justify the claim or suggested potential experimental or theoretical frameworks to explore. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two distinct issues. First, it questions whether the three transformer modules are trained iteratively or in an end-to-end manner, which is an explicit request for clarification. This provides a clear action for the authors to take, ensuring they understand the training process of their model. Second, the comment critiques the repetition of visualization in Figure 5, suggesting that it does not add new insights and could be unnecessary. While the action is explicit, the comment could be more actionable by providing specific guidance on how to address the repetition or suggesting alternative ways to present the information. Overall, the comment is mostly actionable as it provides clear guidance on one aspect but could be more detailed in its suggestions.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the repetition of visualization and suggests that it is unnecessary if no new points are demonstrated. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two distinct claims. The first claim questions the training method of the three transformer modules, seeking clarification on whether they are trained iteratively or in an end-to-end manner. This is a factual question that requires no justification or evidence, as it is a request for clarification rather than an opinion or judgment. The second claim critiques the repetition of visualization in Figure 5, suggesting that it does not add new insights and could be unnecessary. This is also a factual observation that does not require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two distinct points. First, it questions the training method of the three transformer modules, asking whether they are trained iteratively or in an end-to-end manner. This is a clear and actionable question that prompts the authors to clarify their approach, providing valuable insight into the methodology. Second, the comment critiques the repetition of visualization in Figure 5, suggesting that it does not add new insights and could be unnecessary. This feedback is also helpful as it encourages the authors to refine their presentation and avoid unnecessary repetition. However, the comment could be more helpful if it provided specific suggestions on how to address the repetition or improve the visualization. Overall, the comment is mostly helpful as it identifies areas for clarification and improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the writing could benefit from greater precision and clarity, providing specific examples of improvements, such as distinguishing between \"parameters of BFNs\" and \"parameters of BFN-produced distributions.\" It also explicitly states that the authors should outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations not due to BFNs. This feedback is explicit and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the writing could benefit from greater precision and clarity, providing specific examples of improvements. It also addresses the need for the authors to clarify the unique contributions of ParamReL compared to infoDiffusion, particularly in relation to BFNs. However, the comment does not specify which sections of the paper need these improvements or where the unique contributions should be outlined. While it provides some guidance, it lacks full grounding as it does not explicitly mention specific sections or parts of the paper. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the writing could benefit from greater precision and clarity, providing specific examples of improvements. It also critiques the paper for not clearly distinguishing its contributions from those of infoDiffusion, particularly in the context of BFNs. The comment offers a logical reasoning by highlighting the need for explicit clarification of the unique contributions of ParamReL. However, it lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to provide additional context or evidence to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two main points of feedback. First, it suggests that the writing could benefit from greater precision and clarity, offering specific examples of improvements, such as distinguishing between \"parameters of BFNs\" and \"parameters of BFN-produced distributions.\" This feedback is actionable and helpful as it guides the authors on how to enhance the clarity of their writing. Second, the comment critiques the paper for not clearly distinguishing its contributions from those of infoDiffusion, particularly in the context of BFNs. It suggests that the authors should explicitly outline the unique contributions of ParamReL, which is a valuable suggestion for improving the paper\\'s clarity and originality. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to differentiate the contributions. Overall, the feedback is mostly helpful as it offers clear and actionable suggestions for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a perceived issue with the discussion in the paper, specifically regarding the focus on a situation where the gradient of the sum is not the sum of individual gradients. The reviewer suggests that this point is not communicated effectively in the text and proposes a way to address it by discussing the shared setting in all ERM approaches in less space. While the comment implies that the authors should clarify this point, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the discussion and potentially reorganize the content. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 60-74\" and \"the beginning of Sect. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that the authors want to focus on a specific situation but do not communicate it effectively. The comment suggests that the shared setting in all ERM approaches could be discussed in less space and that the rare situation where the gradient of the sum of losses is not the sum of individual loss gradients deserves more space. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors want to focus on a specific situation where the gradient of the sum is not the sum of individual gradients, but this is not communicated effectively in the text. The reviewer provides specific line numbers (60-74) and references a particular paragraph (lines 70-74) to support their claim. This level of detail provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more explicit reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the discussion in the paper, noting that the authors want to focus on a situation where the gradient of the sum is not the sum of individual gradients, but this point is not effectively communicated in the text. The reviewer suggests that the shared setting in all ERM approaches could be discussed in less space and that the rare situation where the gradient of the sum of losses is not the sum of individual loss gradients deserves more space. This feedback is clear and actionable, as it provides specific guidance on how to improve the clarity and focus of the discussion. However, it could be more helpful if it offered suggestions on how to reorganize the content or provide examples to support the claim. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses concern about the proposed question-rewrite strategy, questioning its effectiveness in covering a sufficiently large number of questions. The reviewer provides specific data and statistics to support their claim, noting that 23% of questions become invalid, with 44% attributed to unresolved coreference. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the strategy. While it highlights an issue, it lacks actionable advice on how to resolve it, leaving the authors with a vague understanding of what needs to be done. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed question-rewrite strategy\" and references specific data from Table 4 in the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concern about the method not covering a sufficiently large number of questions, citing the percentage of invalid questions and the specific issue of unresolved coreference. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the proposed question-rewrite strategy, specifically questioning its effectiveness in covering a sufficiently large number of questions. The reviewer provides detailed statistics, such as the percentage of invalid questions and those attributed to unresolved coreference, which supports the claim. Additionally, the comment references specific data from Table 4 in the appendix and mentions a particular line number (L373) for further context. This level of detail and reference to specific data points makes the claim mostly verifiable, as it provides a clear basis for the reviewer\\'s concern. However, the comment could be strengthened by providing more detailed analysis or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the proposed question-rewrite strategy, questioning its effectiveness in covering a sufficiently large number of questions. It provides specific data and statistics to support the claim, noting that 23% of questions become invalid, with 44% attributed to unresolved coreference. The comment also references a specific line number (L373) and mentions the limited impact of the proposed method, which rewrites only 12% of the questions. This feedback is clear and actionable, as it highlights a potential weakness in the methodology and suggests that the authors should address this issue to improve the effectiveness of their approach. However, the comment could be more helpful if it offered suggestions on how to enhance the question-rewrite strategy or provide additional context for the data analysis. Overall, the comment is mostly helpful, as it provides valuable insights for the authors to consider in improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the use of L2 distance in equation (4) and suggests that the earth mover's distance is more common in Optimal Transport (OT). It asks for clarification on the benefit of using L2 distance. While the comment implies that the authors should provide a justification or explanation for their choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the question raised. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (4),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of L2 distance in OT and asks for clarification on the benefit of this choice, providing a clear direction for the authors to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of L2 distance in equation (4) and suggests that the earth mover\\'s distance is more common in Optimal Transport (OT). The comment implies that the choice of L2 distance might not be the best option, but it does not provide specific reasoning or evidence to support this claim. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a specific question about the choice of L2 distance in equation (4) and suggests that the earth mover\\'s distance is more common in Optimal Transport (OT). This feedback is somewhat helpful as it prompts the authors to consider an alternative approach or provide a justification for their choice. However, the comment lacks depth and does not offer specific guidance on how to address the issue or what benefits the earth mover\\'s distance might offer in this context. To be more helpful, the comment could include suggestions or examples of how the earth mover\\'s distance could be applied or why it might be beneficial. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the description of related work is scattered throughout the paper and recommends a broader discussion on how the algorithm compares to other offline RL algorithms. While the comment implies that the authors should organize the related work section more cohesively and provide a comparative analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer the need for improvement but may not be entirely sure of the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the organization of the related work section, noting that it is scattered throughout the paper and suggests a broader discussion on how the algorithm compares to other offline RL algorithms. While it does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the sections discussing related work. The comment is specific in suggesting a broader discussion and comparison, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the description of related work is scattered throughout the paper and recommends a broader discussion on how the algorithm compares to other offline RL algorithms. However, the comment does not provide specific examples or references to support the claim that the current description is inadequate or that a broader discussion is necessary. Without detailed justification or evidence, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a weakness in the paper, noting that the description of related work is scattered throughout the document. It suggests that a broader discussion on how the algorithm compares to other offline RL algorithms would be beneficial. This feedback is somewhat helpful as it points out an area for improvement and provides a general direction for enhancing the paper. However, it lacks specificity and does not offer detailed guidance on how to organize the related work section or what specific comparisons should be made. To be more helpful, the comment could include examples of relevant papers or suggest specific aspects to focus on in the comparison. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about how the final solution would change if all increments were available at the same time. While it implies that the authors should consider this scenario, it does not provide explicit guidance or suggestions on how to address this question or what specific aspects of the solution might be affected. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the impact of having all increments available at the same time on the final solution. However, it does not specify which part of the paper this question pertains to, such as a specific section or analysis. Without explicit references or context, the authors cannot confidently determine where this question should be addressed in the paper. Additionally, the comment lacks specificity regarding what aspects of the solution might be affected or how the authors should consider this scenario. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification on how the final solution would change if all increments were available at the same time. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the impact of having all increments available at the same time on the final solution. While it identifies a potential area for exploration or clarification, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this question or what aspects of the solution might be affected. The comment does not offer actionable feedback or insights that could help the authors improve their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the technique used in the paper, specifically the use of multiple feature spaces, which is described as \"convoluted and potentially circular.\" However, it does not provide any explicit or implicit suggestions for improvement. The authors are left without guidance on how to address this issue or what changes could be made to clarify or simplify the technique. Without actionable advice or specific recommendations, the authors are unable to effectively respond to this feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the technique of using multiple different feature spaces, specifically mentioning the \"25 feature space of Mitchell et. al\" and the \"full/pruned glove model.\" However, it does not specify which part of the paper discusses these techniques, making it weakly grounded. The comment is specific in detailing the issue with the technique, explaining it as \"convoluted and potentially circular.\" Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technique of using multiple different feature spaces is \"convoluted and potentially circular.\" However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks concrete evidence or references to substantiate the assertion, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the technique used in the paper, specifically the use of multiple different feature spaces. It describes the technique as \"convoluted and potentially circular,\" which suggests that the authors may need to clarify or simplify their approach. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending alternative methods or ways to present the technique more clearly. While it highlights a potential area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include comparisons with other works that use the MobileNetV3 search space, specifically mentioning AtomNAS, and to provide FLOPs and parameter sizes. It also questions why the results of OFA with progressive shrink are not included in the table. This feedback is clear and provides specific actions for the authors to take, making it highly actionable. The authors know exactly what needs to be done to address the comment, which is to add these comparisons and clarify the exclusion of certain results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be added to the table, namely comparisons with other works using the MobileNetV3 search space, along with their FLOPs and parameter sizes. Additionally, it questions the exclusion of results from OFA with progressive shrink, prompting the authors to clarify this choice. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts: a suggestion to include comparisons with other works using the MobileNetV3 search space and a question about the exclusion of results from OFA with progressive shrink. The first part is a suggestion for improvement, which is not a claim requiring verification. The second part is a question seeking clarification, which is not a claim. Therefore, the comment is factual and does not contain any claims that need verification. It should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that Table 7 should include comparisons with other works that use the MobileNetV3 search space, such as AtomNAS, along with their FLOPs and parameter sizes. This recommendation is clear and directly guides the authors on how to enhance the comprehensiveness of their results. Additionally, the comment questions the exclusion of results from OFA with progressive shrink, prompting the authors to clarify this choice. This level of detail and guidance makes the comment highly helpful, as it empowers the authors to make significant improvements to their draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors include a brief discussion on why fixing hallucinations is necessary, in addition to referencing existing work. This is an explicit action that provides a clear direction for the authors to enhance their draft. The comment specifies what needs to be added, which is a discussion on the importance of addressing hallucinations, and suggests referencing existing work for context. This level of detail makes the action concrete and directly actionable, allowing the authors to know exactly what to do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including a discussion on why fixing hallucinations is necessary and references existing work. However, it does not specify which part of the paper this discussion should be added to, nor does it provide specific examples of existing work that should be referenced. This makes it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a brief discussion on the necessity of fixing hallucinations would be beneficial, along with referencing existing work. However, the comment does not provide any specific reasoning, examples, or references to support why fixing hallucinations is important or how existing work relates to this issue. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors include a brief discussion on why fixing hallucinations is necessary, in addition to referencing existing work. This feedback is clear and actionable, as it identifies a specific area for improvement and provides a concrete suggestion for enhancing the paper. By addressing the importance of fixing hallucinations and referencing existing work, the authors can provide a more comprehensive understanding of their research and its contributions. However, the comment could be more helpful if it offered specific examples or references to existing work, which would further guide the authors in implementing the suggested changes. Overall, the comment is mostly helpful, as it provides valuable guidance for improving the draft, but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the order of presentation in the paper, noting that terms like Type-1 error, Type-2 error, and false positive rate are mentioned before the null hypothesis is clearly stated. However, it does not provide explicit guidance on how the authors should reorder or clarify the presentation to address this issue. The action is implicit, as the authors can infer that they need to reorder the content, but it lacks concrete details on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 50-54, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue by pointing out that terms like Type-1 error, Type-2 error, and false positive rate are mentioned before the null hypothesis is clearly stated. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that terms like Type-1 error, Type-2 error, and false positive rate are mentioned before the null hypothesis is clearly stated. However, the comment does not provide any reasoning or evidence to support why this order is problematic or how it affects the clarity of the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the order of presentation in the paper, noting that terms like Type-1 error, Type-2 error, and false positive rate are mentioned before the null hypothesis is clearly stated. This feedback is clear and actionable, as it directs the authors to reorder their content to ensure that the null hypothesis is clearly stated before discussing these terms. However, the comment could be more helpful if it provided additional guidance on how to effectively integrate these concepts or suggested alternative ways to present the information. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential uncertainty in the estimates due to the probabilistic nature of the importance weight function and the regularization process. It asks the authors how they solve this issue, which implies that the authors should provide a response or explanation regarding their approach to addressing this uncertainty. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, leaving the action vague. The authors are aware of the need to address the concern but lack detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the potential uncertainty in the estimates due to the probabilistic nature of the importance weight function and the regularization process. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment does provide a clear question about how the authors solve this issue, which could guide the authors in addressing the concern. Therefore, the comment is weakly grounded as it does not specify the exact part of the paper being addressed, but it is specific in its request for a solution. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential uncertainty in the estimates due to the probabilistic nature of the importance weight function and the regularization process. However, it does not provide any specific evidence, examples, or references to support this claim. The comment is more of a question seeking clarification rather than a claim that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a potential issue with the estimation of a continuous importance weight function, which may introduce uncertainty due to the probabilistic nature of the process combined with regularization. It raises a valid concern about the model\\'s reliability in certain cases. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing alternative methods or techniques to mitigate the uncertainty. While it highlights an important area for consideration, the feedback is incomplete and does not provide actionable steps for improvement. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the performance of the SFAM scorers, which are fundamental components of the LISA embedding, in correlating with human judgments on different styles. It suggests that the LISA is more content-focused rather than style-focused due to this discrepancy. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the performance of the SFAM scorers. The action is implicit and vague, as the authors are left to infer that they need to investigate and potentially improve the performance of the SFAM scorers. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"SFAM scorers\" and \"LISA embedding,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the discrepancy in correlation between the SFAM scorers and human judgments on different styles, such as sentiment, emotion, simplification, and linguistic acceptability. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the SFAM scorers, which are fundamental components of the LISA embedding, do not correlate well with human judgments on more linguistics-relevant styles, such as simplification and linguistic acceptability. The comment provides a logical reasoning by contrasting the performance on semantics-relevant styles (e.g., sentiment, emotion) with linguistics-relevant styles, suggesting that this discrepancy might make the LISA more content-focused than style-focused. However, the comment lacks specific examples or references to support the claim, which would strengthen the argument. Therefore, the claim is somewhat verifiable, as it provides a logical basis but requires additional evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of the SFAM scorers, which are fundamental components of the LISA embedding. It notes that while the SFAM scorers correlate well with human judgments on semantics-relevant styles, they do not perform as well on linguistics-relevant styles. This observation suggests that the LISA might be more content-focused than style-focused. The comment provides a clear and actionable insight into a potential limitation of the model, prompting the authors to consider how to improve the performance of the SFAM scorers on linguistics-relevant styles. However, the comment could be more helpful if it offered specific suggestions or examples on how to address this issue. Overall, the feedback is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments should be evaluated on other real-world datasets, specifically mentioning DexYCB and more recent hand-object pose estimation pipelines. This provides a clear and explicit action for the authors to take, which is to include additional datasets and pipelines in their experiments. The suggestion is concrete, as it specifies the datasets and pipelines to consider, giving the authors a clear direction on how to improve their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests evaluating the experiments on other real-world datasets, specifically mentioning DexYCB and more recent hand-object pose estimation pipelines. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting additional datasets and pipelines for evaluation, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests evaluating the experiments on other real-world datasets like DexYCB and more recent hand-object pose estimation pipelines. However, it does not provide any reasoning or evidence to support why these datasets or pipelines are necessary or beneficial for the evaluation. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the experiments should be evaluated on other real-world datasets, specifically mentioning DexYCB and more recent hand-object pose estimation pipelines. This feedback is clear and actionable, as it provides specific guidance on how to enhance the robustness and generalizability of the experiments. By incorporating these additional datasets and pipelines, the authors can better validate the performance and applicability of their method. However, the comment could be more helpful if it explained why these specific datasets and pipelines are relevant or provided additional context. Overall, the comment is mostly helpful as it offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of explicit explanation regarding important components of the paper, such as the design of sequential models and the update of the attention model. While it identifies areas that need clarification, it does not provide specific guidance on how the authors should address these issues. The comment lacks concrete details on what aspects of the explanation should be included or how the authors should present the information. As a result, the authors are left with a vague understanding of what needs to be improved, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a lack of explicit explanation regarding important components, such as the design of sequential models and the update of the attention model. However, it does not specify which part of the paper these components are discussed in, making it difficult for the authors to pinpoint the exact sections that need clarification. The comment is specific in identifying the areas that need improvement but lacks grounding as it does not provide a clear reference to the specific sections or parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks explicit explanation on important components, such as the design of sequential models and the update of the attention model. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks references to relevant literature or detailed explanations that would help the authors understand the importance of these components or how they could be better explained. As a result, the claim is considered unverifiable due to the lack of supporting evidence or detailed justification.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically noting the lack of explicit explanation regarding important components such as the design of sequential models and the update of the attention model. This is a critical area for improvement, as it directly impacts the reader\\'s understanding of the proposed work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional sections or examples to clarify these components. While it highlights a key area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a crucial area for enhancement but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the entire code should be made accessible if the paper is accepted. This is an explicit action that the authors can take, as it clearly instructs them on what needs to be done. The comment provides a concrete suggestion by specifying that the code should be made accessible, which gives the authors a clear understanding of how to implement this action. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the entire code should be made accessible if the paper is accepted. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections where code is typically discussed. Without explicit references to specific sections or elements of the paper, the authors may find it challenging to determine where to address this feedback. Additionally, the comment lacks specificity regarding what aspects of the code should be made accessible or how this would enhance the paper. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the entire code should be made accessible if the paper is accepted. However, it does not provide any reasoning or justification for why this is necessary or beneficial. Without supporting evidence or explanation, the claim lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that making the entire code accessible would be beneficial if the paper is accepted. While this is a reasonable suggestion, it lacks specificity and does not provide any guidance on how to make the code accessible or why this would enhance the paper. The comment does not offer any detailed feedback or suggestions on how the authors might improve their draft, leaving them without actionable steps to take. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the explanations of specific processes, such as spike-driven token selection and intra- and inter-stage feature fusion, could be clearer. It recommends including pseudo-code or flow diagrams to enhance the reader\u2019s understanding of the model\u2019s operation. This feedback is explicit and provides a concrete suggestion on how to improve the clarity of the paper. The authors know exactly what needs to be done to enhance the reader\u2019s understanding, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"hybrid architecture\" and specific processes like \"spike-driven token selection\" and \"intra- and inter-stage feature fusion,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests ways to improve the clarity of these processes, such as including pseudo-code or flow diagrams. This provides clear guidance on what needs to be addressed to enhance the reader\u2019s understanding. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the explanations of specific processes, such as spike-driven token selection and intra- and inter-stage feature fusion, could be clearer. It recommends including pseudo-code or flow diagrams to enhance understanding. However, the comment does not provide specific examples or detailed reasoning to support why these processes are unclear or how the suggested enhancements would improve the paper. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the exact issues and potential improvements based on the general suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved: the clarity of explanations for certain processes within the hybrid architecture. It suggests that including pseudo-code or flow diagrams could enhance the reader\u2019s understanding of the model\u2019s operation. This feedback is actionable and provides a clear direction for the authors to improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered specific examples of where these diagrams or code snippets could be most beneficial or provided additional guidance on how to effectively integrate them into the paper. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement, but it could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a critique of the proposed method, stating that it is an incremental improvement over AutoAugment and that the performance gains are not significant compared to recent methods. It also mentions a specific performance difference on ImageNet and notes a large standard deviation, which raises concerns about generalizability. However, the comment does not offer any explicit or implicit actions for the authors to take in response to these observations. It lacks guidance on how the authors might address the concerns or improve their method. As a result, the comment is unactionable, as it does not provide any direction for the authors to enhance their draft.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a general critique of the proposed method, stating that it is an incremental improvement over AutoAugment and that the performance gains are not significant compared to recent methods. It also mentions a specific performance difference on ImageNet and notes a large standard deviation, which raises concerns about generalizability. However, the comment does not specify which part of the paper this critique is based on, such as a particular section or figure, making it difficult for the authors to pinpoint the exact area needing revision. Additionally, while the comment provides some specific details about the performance differences, it lacks detailed guidance on how to address these issues. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the proposed method is an incremental improvement over AutoAugment and that the performance gains are not significant compared to recent methods. It provides specific data points, such as a 0.3 improvement on ImageNet with resnet-50, and mentions a large standard deviation, which raises concerns about generalizability. However, the comment lacks detailed reasoning or references to support the claim that the performance gains are not significant. While it provides some evidence, the lack of comprehensive justification or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a critique of the proposed method, stating that it is an incremental improvement over AutoAugment and that the performance gains are not significant compared to recent methods. It also mentions a specific performance difference on ImageNet and notes a large standard deviation, which raises concerns about generalizability. While the comment identifies a potential weakness in the paper, it lacks actionable suggestions or guidance on how the authors might address these issues or improve their method. The feedback is somewhat helpful as it points out areas for improvement but does not provide detailed advice on how to enhance the draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the weakness of the comparison in the paper, noting the absence of references to existing prior arts and significant performance gaps between the proposed method and latest methods. While it implies that the authors should include references to prior arts and address the performance gaps, the comment does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include references and discuss the performance gaps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the comparison in the paper, specifically mentioning the absence of references to existing prior arts and significant performance gaps between the proposed method and latest methods. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, namely references to prior arts and a discussion of performance gaps. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison is weak due to the lack of references to existing prior arts and significant performance gaps between the proposed method and latest methods. The reviewer supports this claim by mentioning a simple search that shows performance gaps, but without providing specific examples or references to the prior arts or the latest methods, the claim remains somewhat verifiable. The authors would need to conduct their own search or include references to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant weakness in the paper's comparison, noting the absence of references to existing prior arts and the presence of significant performance gaps between the proposed method and latest methods. This feedback is valuable as it highlights an important area for improvement, suggesting that the authors should include references to prior arts and discuss the performance gaps. However, the comment could be more helpful if it provided specific examples of prior arts or methods to consider, or if it offered guidance on how to effectively address the performance gaps. Despite this, the comment provides a clear direction for the authors to enhance their draft, making it mostly helpful.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should provide quantification of the diversity of the data gathered, specifically mentioning that even a simple types vs. token statistic would be useful. This provides a clear and concrete action for the authors to take, as it specifies exactly what kind of quantification is needed. The comment is explicit and detailed, leaving no ambiguity about what the authors should do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of quantifying the diversity of the data gathered by the authors. It suggests that even a simple types vs. token statistic would be useful. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting a way to quantify diversity, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors argue for the diversity of the data gathered but fail to provide quantification. The reviewer suggests that even a simple types vs. token statistic would be useful. This claim is somewhat verifiable as it highlights a potential gap in the paper\\'s presentation of data diversity. However, the comment lacks specific examples or references to support the claim that quantification is necessary or how it would enhance the paper. Providing more detailed reasoning or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of quantification of the diversity of the data gathered. It suggests that even a simple types vs. token statistic would be useful, providing a clear and actionable suggestion for the authors to enhance their draft. This feedback is valuable as it directs the authors to a specific aspect of their work that could be strengthened with additional data analysis. However, the comment could be more helpful if it offered further guidance on how to implement this suggestion or why quantification is important in the context of the paper. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the paper for lacking sufficient evidence to support its claim of creating a more diverse set of positive (similar) instance pairs. It highlights the absence of a suggested measure of diversity and a comparison with earlier works regarding diversity. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors might address this issue, such as suggesting specific metrics or comparisons to include. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed analysis or comparisons, but they are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim made in the paper about creating a more diverse set of positive (similar) instance pairs. However, it does not specify which part of the paper this claim is made in, such as a particular section or figure. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue, as it points out the absence of a suggested measure of diversity and a comparison with earlier works regarding diversity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks sufficient evidence to support its claim of creating a more diverse set of positive (similar) instance pairs. It points out the absence of a suggested measure of diversity and a comparison with earlier works regarding diversity. This critique is somewhat verifiable as it highlights a gap in the paper\\'s justification, but it does not provide specific examples or references to support the claim. The authors would need to address this gap by providing additional evidence or comparisons to strengthen their claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper's claim about creating a more diverse set of positive (similar) instance pairs. It points out that the claim is not adequately supported, as there is no suggested measure of diversity and no comparison with earlier works regarding diversity. This feedback is valuable as it highlights a critical gap in the paper's justification and suggests areas where the authors could improve their argument. However, the comment could be more helpful if it provided specific suggestions on how to measure diversity or which earlier works to compare with. Despite this, the comment is mostly helpful as it directs the authors' attention to a crucial aspect of their claim that needs further elaboration. Therefore, it aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the authors\\' approach would compare to or work with other inputs, such as structured information, and mentions that AUCROC is high in other models in literature. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific aspects of the approach need to be addressed or how the authors should respond to the question about comparison with other inputs. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about how the authors\\' approach compares to other inputs, such as structured information, and mentions that AUCROC is high in other models in literature. However, it does not specify which part of the paper this question pertains to, nor does it provide specific guidance on what aspects of the approach need to be addressed. The authors cannot confidently determine which section of the paper this comment addresses, and it lacks specificity regarding what needs to be clarified or improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the comparison of the authors\\' approach with other inputs, such as structured information, and mentions that AUCROC is high in other models in literature. However, it does not provide any specific examples, references, or detailed reasoning to support the claim or question. The lack of supporting evidence or detailed justification makes it difficult for the authors to understand the basis of the comparison or how to address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about how the authors\\' approach compares to other inputs, such as structured information, and mentions that AUCROC is high in other models in literature. While it highlights a potential area for comparison, it lacks specificity and does not provide actionable feedback or suggestions for improvement. The comment does not guide the authors on how to address the question or what aspects of their approach might need to be adjusted in light of the comparison. As a result, the comment is barely helpful, as it identifies a potential area for exploration but does not offer sufficient guidance for the authors to make meaningful improvements to their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides several explicit actions for the authors to take. It suggests stating the objective function in experiments, specifically mentioning the use of Monte Carlo estimates of expectations. It also questions the inequality sign in Eq. 7, suggesting a potential correction based on the expected loss. Additionally, the comment recommends leaving more space in section 4 to explain the training procedure, which could help the audience better understand the main method. These suggestions are clear and concrete, providing the authors with specific steps to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3 (mainly sec. 3.2)\" and \"section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific suggestions, such as stating the objective function in experiments and questioning the inequality sign in Eq. 7, which further clarifies what needs to be addressed. Additionally, the comment suggests leaving more space in section 4 to explain the training procedure, offering a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several claims and suggestions, but they are not supported by specific evidence or references. The suggestion to state the objective function in experiments and the question about the inequality sign in Eq. 7 are based on logical reasoning but lack detailed justification or examples. The comment also suggests that certain parts of the paper are technical but do not help understand the main method, which is a subjective opinion. Overall, the claims are somewhat verifiable as they provide a basis for the suggestions but lack detailed evidence or references to fully substantiate them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several actionable suggestions for improving the clarity and comprehensibility of the paper. It explicitly recommends stating the objective function in experiments, which would help readers understand the experimental setup. Additionally, it questions the inequality sign in Eq. 7, suggesting a potential correction based on the expected loss. The comment also identifies a technical aspect of section 3 that may be confusing and suggests leaving more space in section 4 to explain the training procedure, which could enhance the audience\\'s understanding of the main method. While the comment is mostly helpful, it could be more comprehensive by providing specific examples or further elaboration on the suggested changes. Overall, the feedback is constructive and provides clear guidance for the authors to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for an explanation regarding the decrease in the Disc. reward for SPACE and f-PCPO in the Grid scenario, as depicted in Fig.3. The comment clearly states that this aspect should be explained, providing a direct and concrete action for the authors to take. By specifying the exact plot and the issue to be addressed, the authors know exactly what needs to be clarified in their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig.3, top right plot,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: explaining why the Disc. reward for SPACE and f-PCPO is going down in the Grid scenario. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification on a specific observation in the paper, specifically why the Disc. reward for SPACE and f-PCPO is going down in the Grid scenario, as shown in Fig.3. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and specific, asking for an explanation regarding the decrease in the Disc. reward for SPACE and f-PCPO in the Grid scenario, as depicted in Fig.3. This feedback is actionable and provides a direct direction for the authors to improve their draft by addressing the question raised. However, it could be more helpful if it offered suggestions on how to approach the explanation or provided additional context. Overall, the comment is mostly helpful as it guides the authors toward a specific area needing clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that key implementation details are missing, specifically mentioning the resolutions at which images successfully achieve adversarial effects. This provides a clear and direct action for the authors to take, which is to include these details in their draft. The comment is explicit and concrete, as it specifies exactly what information is lacking and needs to be added. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Key implementation details,\" which allows the authors to identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the resolutions at which images successfully achieve adversarial effects. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"Key implementation details are missing, such as the resolutions at which images successfully achieve adversarial effects.\" This statement is factual and descriptive, as it points out a specific gap in the paper. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, noting that key implementation details are missing, particularly regarding the resolutions at which images successfully achieve adversarial effects. This feedback is clear and actionable, as it directs the authors to include these details in their draft. By addressing this point, the authors can enhance the comprehensiveness and clarity of their work. However, the comment could be more helpful if it provided additional guidance on how to present these details or why they are important. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that while the use of DDIM Inversion for motion guidance is effective in reducing training time, it does not simplify the overall complexity. The reviewer recommends exploring improvements to the motion guidance strategy itself to enhance training efficiency. This feedback is explicit in suggesting a specific area for improvement, namely the motion guidance strategy, and provides a clear direction for the authors to consider. However, it does not offer concrete steps or detailed guidance on how to implement these improvements. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific instructions on how to execute it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"section on data preprocessing,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the approach used for motion guidance, suggesting that while it reduces training time, it does not simplify the overall complexity. The comment further provides a constructive suggestion to explore improvements in the motion guidance strategy. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that using DDIM Inversion for motion guidance is effective in reducing training time but does not simplify the overall complexity. The reviewer suggests exploring improvements to the motion guidance strategy to enhance training efficiency. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim about the effectiveness of DDIM Inversion or the potential improvements to the motion guidance strategy. This makes the claim somewhat verifiable, as it requires further evidence or detailed reasoning to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the data preprocessing section, where the use of DDIM Inversion for motion guidance is effective in reducing training time but does not simplify the overall complexity. It provides a constructive suggestion to explore improvements in the motion guidance strategy itself to enhance training efficiency. This feedback is clear and actionable, offering the authors a specific direction for enhancing their work. However, it could be more helpful if it included examples or specific strategies for improving the motion guidance, which would further guide the authors in making improvements. Overall, the comment is mostly helpful as it provides a valuable insight and direction for the authors to consider, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the statistics of relation phrases and their frequency in sentence predictions. It also mentions a potential disadvantage of chunking relation phrases, which could lead to issues with the heavy tail in relations. However, the comment does not provide explicit instructions or suggestions on how the authors should address these concerns or improve their draft. The authors are left to infer that they need to provide more detailed statistics or discuss the implications of the heavy tail in relations, but the comment lacks concrete guidance on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the statistics of relation phrases and their frequency in sentence predictions, as well as the potential issue of the heavy tail in relations. However, it does not specify which part of the paper these questions relate to, such as a specific section or figure. The authors can make an educated guess that it might relate to the methodology or results sections, but the comment lacks full grounding. The comment is specific in detailing the issues with relation phrases and the potential problem of the heavy tail, but without clear grounding, it is difficult for the authors to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the statistics of relation phrases and their frequency in sentence predictions, as well as the potential issue of the heavy tail in relations. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The comment lacks specific examples or detailed explanations that would help the authors understand the basis of the concerns. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to address the issues raised. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises important questions about the statistics of relation phrases and their frequency in sentence predictions. It also highlights a potential disadvantage of chunking relation phrases, which could lead to issues with the heavy tail in relations. This feedback is somewhat helpful as it identifies areas that the authors might need to address or explore further in their work. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their draft. While it provides some insight into potential weaknesses, it does not offer actionable steps for improvement, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the statement about static elements is generally true but highlights the need for more robust approaches in edge cases, such as the Bonn dataset where moving objects like humans can occupy a significant portion of the image. It suggests potential solutions, including masking out dynamic regions using segmentation masks or re-running relative pose estimation after identifying dynamic regions. While the comment provides explicit suggestions for addressing the issue, it lacks detailed guidance on how to implement these solutions, such as specific methods or techniques for masking or re-running pose estimation. The action is mostly actionable because it clearly identifies the need for more robust approaches and provides some direction, but the authors would need to infer the exact steps to take. Therefore, this comment is rated as mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the statement \"For most scenes, where most pixels are static, random samples of points will place more emphasis on the static elements,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific suggestions for addressing the issue, such as using segmentation masks or re-running relative pose estimation after identifying dynamic regions. This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement about static elements is generally true but highlights the need for more robust approaches in edge cases, such as the Bonn dataset where moving objects like humans can occupy a significant portion of the image. The reviewer suggests potential solutions, including masking out dynamic regions using segmentation masks or re-running relative pose estimation after identifying dynamic regions. While the comment provides some reasoning and examples, it lacks detailed evidence or references to fully substantiate the claim. The suggestion for potential solutions is logical but could be strengthened with more specific examples or references. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the need for more robust approaches to handle dynamic regions, particularly in datasets like the Bonn dataset where moving objects can occupy a significant portion of the image. It provides a clear and actionable suggestion by recommending the use of segmentation masks or re-running relative pose estimation after identifying dynamic regions. This feedback is valuable as it highlights a potential weakness in the current approach and offers concrete steps for enhancing the robustness of the method. However, the comment could be more helpful if it included additional details or examples of how these suggestions could be implemented or tested. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of comparison between the authors\\' models and other methods in the experiments. While it identifies a gap in the paper, it does not provide explicit guidance on how to address this issue or suggest specific methods to include for comparison. The action is implicit and somewhat vague, as the authors are left to infer that they should add comparisons with other methods but are not given concrete instructions on which methods to choose or how to implement the comparison. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the experiments section, specifically noting the lack of comparison with other methods. However, it does not specify which experiments or sections are being referred to, making it weakly grounded. The comment is specific in pointing out the absence of comparisons with other methods, which is a clear area for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments only focus on comparing various models proposed by the authors and lack comparison with other methods. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or detailed justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the paper, noting that the experiments only compare the authors\\' models among themselves and lack comparisons with other methods. This feedback is valuable as it highlights an important gap in the experimental design, which could impact the paper\\'s contribution and relevance. However, the comment does not provide specific suggestions on which methods should be included for comparison or how to conduct these comparisons. While it points out a critical area for improvement, it lacks actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point points out a minor inconsistency in the formatting of Table 3 and 4, where models considered math specialists are marked with an asterisk, but the MAVIS models are not. The reviewer suggests that the MAVIS models should also be considered math specialists and therefore should be marked with an asterisk. This feedback is explicit and provides a clear action for the authors to take, which is to add the asterisk to the MAVIS models in the tables. The action is concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a particular formatting inconsistency regarding the marking of models considered math specialists. The comment suggests that the MAVIS models should also be marked with an asterisk, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the formatting of tables in the paper, specifically noting that models considered math specialists are marked with an asterisk, but the MAVIS models are not. This is a descriptive statement without any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment points out a minor inconsistency in the formatting of Table 3 and 4, where models considered math specialists are marked with an asterisk, but the MAVIS models are not. The reviewer suggests that the MAVIS models should also be considered math specialists and therefore should be marked with an asterisk. This feedback is clear and actionable, providing the authors with a specific detail to correct in their draft. However, the comment is limited in its scope, as it does not offer broader insights or suggestions for improvement beyond this formatting issue. Therefore, the comment is somewhat helpful, as it identifies a specific area for improvement but lacks depth in terms of overall guidance or impact on the manuscript.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the technical novelty is limited, noting that KNN-based methods are widely studied in language modeling (LM) and machine translation (MT). It suggests that the work provides few insights into non-parametric methods for text classification. However, the comment does not offer any explicit or implicit actions for the authors to take. It lacks guidance on how to enhance the novelty or provide more insights, leaving the authors without a clear path for improvement. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the technical novelty of the paper, specifically mentioning that KNN-based methods are widely studied in language modeling (LM) and machine translation (MT). However, it does not specify which part of the paper discusses these methods or where the lack of novelty is observed. This makes it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the novelty but lacks grounding, as it does not provide a clear reference to the part of the paper being discussed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical novelty is limited, citing that KNN-based methods are widely studied in language modeling (LM) and machine translation (MT). However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim remains somewhat verifiable, as it provides a general statement but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges that the technical novelty of the paper is limited, noting that KNN-based methods are widely studied in language modeling (LM) and machine translation (MT). It suggests that the work provides few insights into non-parametric methods for text classification. However, the comment lacks specific guidance or suggestions on how the authors might enhance the novelty or provide more insights. Without actionable feedback or detailed advice, the authors are left without a clear path for improvement. Therefore, the comment is barely helpful, as it identifies a weakness but does not provide sufficient guidance for the authors to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the paper claims to enhance the IM for most existing RL algorithms, but the description of mainstream RL algorithms in the related work is outdated, referencing SAC from 2018. The comment suggests that the paper lacks a comparison with the latest work, particularly non-pixel-based approaches to solving data efficiency. While the comment identifies an issue with the paper\\'s claims and suggests a need for updating the related work section, it does not provide explicit guidance on how to address this issue or what specific comparisons should be included. The action is implicit and somewhat vague, as the authors are left to infer that they need to update the related work section and include comparisons with more recent work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the emphasis on the extensive enhancement of the IM for most existing RL algorithms and the outdated description of mainstream RL algorithms in the related work, specifically referencing SAC from 2018. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out the lack of comparison with the latest work, particularly non-pixel-based approaches to solving data efficiency. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s emphasis on the extensive enhancement of the IM for most existing RL algorithms is an overstatement due to the outdated description of mainstream RL algorithms in the related work, specifically referencing SAC from 2018. The comment suggests that the paper lacks a comparison with the latest work, particularly non-pixel-based approaches to solving data efficiency. While the comment highlights a potential issue with the paper\\'s claims, it does not provide specific examples or references to support the claim that the description is outdated or that the paper lacks a comparison with the latest work. This makes the claim somewhat verifiable, as the authors would need to investigate further to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s claims regarding the enhancement of the IM for most existing RL algorithms. It points out that the description of mainstream RL algorithms in the related work is outdated, referencing SAC from 2018, and suggests that the paper lacks a comparison with the latest work, particularly non-pixel-based approaches to solving data efficiency. This feedback is somewhat helpful as it highlights a specific area where the paper may be overstating its contributions and provides a direction for improvement by suggesting the inclusion of more recent work. However, the comment could be more helpful if it offered specific examples of recent work or more detailed guidance on how to incorporate these comparisons. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should expand the background discussion in Section 2 by including further background knowledge on adversarial examples and threat models. It also provides a concrete action by recommending the inclusion of relevant surveys to clarify the threat model and position at the state-of-the-art, which would help non-expert readers understand the distinctions. Additionally, it suggests referencing relevant surveys to facilitate this understanding. This feedback is clear and provides specific guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2\" and \"related work,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: expanding the background discussion on adversarial examples and threat models, and referencing relevant surveys to clarify the threat model and position at the state-of-the-art. This provides clear guidance on how to improve the paper, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests expanding the background discussion on adversarial examples and threat models, and references relevant surveys to clarify the threat model and position at the state-of-the-art. This claim is mostly verifiable as it provides a clear direction for improvement and references a specific area where additional information could be beneficial. However, the comment lacks specific examples or references to particular surveys, which would strengthen the justification. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting that the authors expand the background discussion in Section 2 to include further knowledge on adversarial examples and threat models. It specifically recommends referencing relevant surveys to clarify the threat model and position at the state-of-the-art, which would help non-expert readers understand these distinctions. This feedback is detailed and offers a concrete way for the authors to enhance the clarity and comprehensiveness of their work, making it highly helpful for improving the draft. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of how the proposed multiple-span answer setting is essential in real-world applications. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific aspects of the paper need to be clarified or how the authors might address this concern. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the clarity of how the proposed multiple-span answer setting is essential in real-world applications. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it difficult for the authors to identify the exact area needing revision. Additionally, the comment lacks specificity regarding what aspects of the application are unclear or how the authors might clarify this point. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the clarity of how the proposed multiple-span answer setting is essential in real-world applications. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the clarity of how the proposed multiple-span answer setting is essential in real-world applications. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve the clarity of their work. Without actionable feedback or detailed insights, the authors are left without a clear path to enhance their draft. Therefore, the comment is not helpful at all, as it lacks the necessary depth and direction to assist the authors in improving their work.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about why the train set examples are not mixed with hypernyms and non-hypernyms. While it implies that the authors should consider mixing these examples, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this mixing strategy. However, the comment provides a clear direction for potential improvement, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific page numbers (\"558\", \"574ff\"), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the decision not to mix train set examples with hypernyms and non-hypernyms, providing a clear direction for potential improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the decision not to mix train set examples with hypernyms and non-hypernyms, suggesting that this could be a potential improvement. However, the comment does not provide any reasoning, evidence, or examples to support why mixing these examples would be beneficial or necessary. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the decision not to mix train set examples with hypernyms and non-hypernyms. While it points out a potential area for improvement, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. The comment does not offer actionable advice or insights that would help the authors improve their draft. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests that the authors provide results for the AdpCLR_full approach for the ResNet-50 (1x, 2x, 4x) architecture, similar to the results provided for AdpCLR_pre in Table 1. This is a clear and direct action for the authors to take, as it specifies exactly what additional information is needed. The comment provides concrete guidance on how to implement this action, ensuring that the authors know exactly what to do to address the request. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table-1\" and \"AdpCLR_full\" and \"AdpCLR_pre,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the results for the AdpCLR_full approach for the ResNet-50 (1x, 2x, 4x) architecture, similar to the results provided for AdpCLR_pre. This provides clear guidance on what the authors need to include in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for additional information, specifically asking for results for the AdpCLR_full approach for the ResNet-50 (1x, 2x, 4x) architecture, similar to the results provided for AdpCLR_pre in Table 1. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and specific in its request for additional results, asking the authors to provide the results for the AdpCLR_full approach for the ResNet-50 (1x, 2x, 4x) architecture, similar to the results provided for AdpCLR_pre in Table 1. This feedback is actionable and provides a clear direction for the authors to enhance their draft by including the requested information. However, the comment could be more helpful if it explained why these results are important or how they might impact the overall understanding of the paper. Despite this, the comment is mostly helpful as it effectively guides the authors in improving their draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the similarity between N trajectories and the concept of replay in the Dyna model. However, it does not provide any explicit or implicit actions for the authors to take. The question lacks guidance on what the authors should do with this information or how it might impact their draft. Without any actionable steps or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the similarity between N trajectories and the concept of replay in the Dyna model. However, it does not specify which part of the paper this question pertains to, nor does it provide any context or details about what aspects of the Dyna model are being discussed. Without explicit references or detailed guidance, the authors cannot confidently determine which part of the paper is being addressed, making the comment not grounded. Additionally, the comment lacks specificity as it does not provide any details on what needs to be clarified or addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification about the similarity between N trajectories and the concept of replay in the Dyna model. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review point raises a question about the similarity between N trajectories and the concept of replay in the Dyna model. While it prompts the authors to clarify a specific aspect of their work, it does not provide any guidance or suggestions on how to address this question or improve the draft. The lack of actionable feedback or detailed insights makes the comment barely helpful, as it does not offer any meaningful direction for the authors to enhance their work. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the experiment results, specifically noting that Tables 16 and 17 share the same result despite a change from a 2-hop EG to a 3-hop EG. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending a re-run of the experiments or suggesting alternative methods to verify the results. As a result, the authors are left without a clear understanding of what steps to take to resolve the concern. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 16 and 17,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it points out a particular issue with the experiment results, noting that the results are suspicious and that Tables 16 and 17 share the same result despite a change in the experimental setup. This provides clear guidance on what needs to be addressed. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some experiment results are suspicious, specifically noting that Tables 16 and 17 share the same result despite a change from a 2-hop EG to a 3-hop EG. However, the comment lacks detailed reasoning or evidence to support this claim, such as comparisons with other studies or explanations of why the results are suspicious. Without additional context or examples, the authors may find it challenging to understand the basis of the concern. Therefore, the claim is considered borderline verifiable, as it provides some indication of an issue but lacks sufficient detail for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experiment results, noting that Tables 16 and 17 share the same result despite a change from a 2-hop EG to a 3-hop EG. This observation suggests a potential problem with the experimental setup or the interpretation of the results. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or what steps they could take to resolve the concern. Without actionable feedback or recommendations, the authors are left without a clear path forward to improve their draft. Therefore, the comment is barely helpful, as it highlights a potential issue but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the experimental results show some advantages of the proposed algorithms but notes that these advantages are not very significant. It also mentions that the results are still competitive with state-of-the-art algorithms. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to improve the significance of the results or what specific aspects need attention. Without actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experimental results, noting that they show some advantages of the proposed algorithms but do not find them to be very significant. It also mentions that the results are still competitive with state-of-the-art algorithms. However, the comment does not specify which part of the paper discusses these experimental results, making it weakly grounded. Additionally, it lacks specificity as it does not provide detailed feedback on what aspects of the results are not significant or how they could be improved. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the experimental results show some advantages of the proposed algorithms but notes that these advantages are not very significant. It also mentions that the results are still competitive with state-of-the-art algorithms. However, the comment lacks specific examples or detailed reasoning to support the claim about the lack of significance. Without additional context or evidence, the authors may find it challenging to understand and address the feedback. Therefore, the claim is considered borderline verifiable, as it provides some basis for the assertion but requires more detailed justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges that the experimental results show some advantages of the proposed algorithms but notes that these advantages are not very significant. It also mentions that the results are still competitive with state-of-the-art algorithms. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance or insights into what aspects of the results could be enhanced or how to make them more significant, the authors are left without a clear path for improvement. Therefore, the comment is barely helpful, as it identifies a general observation but does not offer meaningful guidance for enhancing the draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the per-sentence assessment protocol, suggesting that it may be prone to overconfidence in LLM predictions. However, it does not provide explicit guidance or suggestions on how to address this issue or improve the protocol. The comment implies that the authors should consider the potential for overconfidence, but it lacks concrete steps or recommendations for mitigation. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the \"per-sentence assessment protocol\" but does not specify which part of the paper this protocol is discussed in, making it weakly grounded. It highlights a potential issue with the protocol, specifically the risk of overconfidence in LLM predictions, but does not provide specific guidance on how to address this issue. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the per-sentence assessment protocol may be prone to LLM\\'s overconfidence, as it prefers its predictions even if they are wrong. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires more detailed justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the per-sentence assessment protocol, suggesting that it may be prone to overconfidence in LLM predictions. This is a relevant observation that could impact the reliability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the protocol. Without actionable advice, the authors are left with a general concern but no clear path for improvement. Therefore, the comment is somewhat helpful, as it highlights a potential problem but does not provide detailed feedback for resolution.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the claim that minimizing $L_{smo}$ with the aid of sampled $\\\\tilde{z}_{proj}$ ensures smooth non-semantic diversity modeling. It asks for clarification on what makes this reflect only non-semantic diversity and not semantic diversity. While the comment identifies a potential issue and prompts the authors for clarification, it does not provide explicit guidance on how to address the question or improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional explanation or evidence to clarify the distinction between non-semantic and semantic diversity. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W6.3\" and \"App. C,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning what makes the described method ensure only non-semantic diversity and not semantic diversity. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that minimizing $L_{smo}$ with the aid of sampled $\\\\tilde{z}_{proj}$ ensures smooth non-semantic diversity modeling. It asks for clarification on what makes this reflect only non-semantic diversity and not semantic diversity. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or the question. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the claim that minimizing $L_{smo}$ with the aid of sampled $\\\\tilde{z}_{proj}$ ensures smooth non-semantic diversity modeling. It prompts the authors to clarify what makes this approach reflect only non-semantic diversity and not semantic diversity. This feedback is somewhat helpful as it identifies a potential ambiguity in the paper and encourages the authors to provide further explanation or evidence to support their claim. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context for clarification. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the experimental results, questioning whether the promising outcome is due to the method\\'s superiority or if it is an accidental result from a specific kernel function and feature map. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what steps to take to clarify the results. As a result, the authors are left without any actionable information to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the experimental results, specifically whether the promising outcome is due to the method\\'s superiority or if it is an accidental result from a specific kernel function and feature map. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure discussing the experimental results. Without explicit references or context, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or how the authors might clarify the results. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the experimental results, questioning whether the promising outcome is due to the method\\'s superiority or if it is an accidental result from a specific kernel function and feature map. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to address this concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical question about the experimental results, questioning whether the promising outcome is due to the method\\'s superiority or if it is an accidental result from a specific kernel function and feature map. This is a valid concern that the authors should address to ensure the robustness and reliability of their findings. However, the comment does not provide any specific suggestions or guidance on how the authors might investigate or clarify this issue. While it identifies a potential weakness, it lacks actionable feedback, making it somewhat helpful. The authors are left with a clear question to consider but without detailed guidance on how to address it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the absence of a description for the estimation of \\\\(\\\\mu_t^a\\\\) in the algorithm. While it highlights a potential gap in the paper, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete details on what needs to be done to improve the draft, leaving the authors with an implicit action to include the missing description. However, the action is somewhat vague, as the authors are not directed on how to estimate \\\\(\\\\mu_t^a\\\\) or where it should be described in the algorithm. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the absence of a description for the estimation of \\\\(\\\\mu_t^a\\\\) in the algorithm. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where this estimation should be described. Without explicit references or context, the authors may find it challenging to identify the exact part of the paper being addressed. The comment is specific in its question about the estimation of \\\\(\\\\mu_t^a\\\\), but it lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking about the absence of a description for the estimation of \\\\(\\\\mu_t^a\\\\) in the algorithm. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the absence of a description for the estimation of \\\\(\\\\mu_t^a\\\\) in the algorithm. While it identifies a potential gap in the paper, it does not provide any suggestions or guidance on how the authors might address this issue or where such a description could be included. The comment lacks actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method is complex and likely increases time complexity due to the use of modified Gromov-Hausdorff distances and hypergraph structures. It suggests that a discussion of the computational costs associated with training would be beneficial. While the comment implies that the authors should include a discussion on computational costs, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not provided with specific guidance on how to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the complexity of the proposed method, specifically mentioning the use of modified Gromov-Hausdorff distances and hypergraph structures, which likely increases time complexity. It suggests that a discussion of the computational costs associated with training would be beneficial. The comment is fully grounded as it explicitly mentions the components of the method being discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, a discussion of the computational costs associated with training. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is complex and likely increases time complexity due to the use of modified Gromov-Hausdorff distances and hypergraph structures. It suggests that while the time complexity of each component is theoretically analyzed, a discussion of the computational costs associated with training would be beneficial. The comment provides a logical reasoning by acknowledging the theoretical analysis of time complexity but highlights the need for a discussion on training costs. However, it lacks specific examples or references to support the claim about the complexity and its impact on computational costs. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration or evidence to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the complexity of the proposed method, specifically mentioning the use of modified Gromov-Hausdorff distances and hypergraph structures, which may increase time complexity. It suggests that while the time complexity of each component is theoretically analyzed, a discussion of the computational costs associated with training would be beneficial. This feedback is somewhat helpful as it points out a specific area for improvement and provides a clear suggestion for enhancing the paper. However, it could be more helpful if it offered specific guidance on how to address the computational costs or suggested potential methods for optimization. Overall, the comment provides valuable insight but lacks depth, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the paper addresses important challenges in LLMs but suggests that the proposed method may not represent a groundbreaking innovation. It further notes that the paper does not adequately distinguish its proposed method from existing contrastive decoding techniques, which could leave readers without a clear understanding of the unique contributions and advantages. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the clarity of their contributions. The feedback is implicit and lacks concrete details, making it difficult for the authors to know exactly what steps to take to enhance their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s contribution by suggesting that it may not represent a groundbreaking innovation within the field of LLMs. It also points out that the paper does not adequately distinguish its proposed method from existing contrastive decoding techniques, which could leave readers without a clear understanding of the unique contributions and advantages. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or methodology, making it weakly grounded. The comment is specific in detailing what is lacking in terms of distinguishing the proposed method from existing techniques, but without clear grounding, the authors may struggle to identify the exact parts that need revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method may not represent a groundbreaking innovation within the field of LLMs and that the paper does not adequately distinguish its proposed method from existing contrastive decoding techniques. However, the comment lacks specific examples or references to existing work that would support this claim. Without detailed comparisons or evidence, the authors may find it challenging to understand the basis of the critique or to address it effectively. Therefore, the claim is considered borderline verifiable, as it provides some context but lacks sufficient detail to fully substantiate the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges that the paper addresses important challenges in LLMs but suggests that the proposed method may not represent a groundbreaking innovation. It points out that the paper does not adequately distinguish its proposed method from existing contrastive decoding techniques, which could leave readers without a clear understanding of the unique contributions and advantages. This feedback is somewhat helpful as it identifies a potential weakness in the paper\\'s contribution and suggests an area for improvement. However, it lacks specific guidance on how the authors might address this issue or enhance the clarity of their contributions. To be more helpful, the comment could provide examples or suggestions on how to better differentiate the proposed method from existing work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point comments on the tabular representation of node agent interactions in Figure 4, stating that it is not intuitive. However, it does not provide any explicit or implicit guidance on how to improve the figure or what changes should be made to enhance its intuitiveness. The authors are left without a clear understanding of what specific adjustments are needed to address the issue. As a result, the comment lacks actionable details, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the tabular representation of node agent interactions, indicating that it is not intuitive. This provides clear guidance on what needs to be addressed to improve the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"Figure 4\\\\\\'s tabular representation of node agent interactions is not intuitive.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why the representation is not intuitive. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the tabular representation of node agent interactions in Figure 4, noting that it is not intuitive. However, it lacks any further explanation or suggestions on how to improve the figure or make it more intuitive. Without actionable guidance or examples, the authors are left without a clear understanding of what changes are needed to address the issue. This limits the comment\\'s usefulness, as it does not provide the authors with a clear path for improvement. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: one about the appropriateness of using other frameworks besides PU as baselines and another about the impact of the PU loss on calibration. While the comment implies that the authors should consider alternative frameworks and explore the effect of the PU loss on calibration, it does not provide explicit instructions or concrete guidance on how to address these questions. The authors can infer that they need to explore other frameworks and investigate the impact of the PU loss, but the lack of specific guidance makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the appropriateness of using other frameworks besides PU as baselines and the impact of the PU loss on calibration. However, it does not specify which part of the paper these questions relate to, such as specific sections or experiments. This makes it difficult for the authors to pinpoint the exact areas needing attention. The comment is specific in its questions but lacks grounding, as it does not provide clear references to the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the appropriateness of using other frameworks besides PU as baselines and the impact of the PU loss on calibration. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the questions and how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises two important questions that could help the authors improve their draft. First, it questions whether other frameworks besides PU might be more appropriate as baselines, suggesting that the authors consider alternative approaches. Second, it inquires about the impact of the PU loss on calibration, highlighting the importance of uncertainty estimation for downstream use cases of AI text detectors. While the comment identifies potential areas for exploration and improvement, it lacks specific guidance or suggestions on how the authors might address these questions. The feedback is somewhat helpful as it points out areas for further investigation, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a disagreement with the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential Multi-Task Learning (MTL) in the introduction. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for how the authors should revise their characterization or what specific changes should be made to improve the clarity or accuracy of the introduction. Without any actionable guidance, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential Multi-Task Learning (MTL), providing a detailed explanation of the difference between TL, FT, and standard MTL. This level of detail helps the authors understand what needs to be addressed in the introduction. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses a disagreement with the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential Multi-Task Learning (MTL) in the introduction. The reviewer provides a logical explanation by distinguishing between TL as a broader phenomenon and FT as a specific method, and contrasts it with standard MTL as a parallel approach. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened with references to specific literature or examples to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential Multi-Task Learning (MTL) in the introduction. It provides a clear explanation of the distinction between TL as a broader phenomenon and FT as a specific method, and contrasts it with standard MTL as a parallel approach. This feedback is valuable as it highlights a misunderstanding in the paper and offers a nuanced perspective on the topic. However, the comment could be more helpful if it suggested how the authors might clarify or revise their characterization to better align with the correct understanding. Despite this, the comment provides a clear direction for improvement, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper lacks a Limitation section, which is an important component. However, it does not provide any guidance or suggestions on how to address this issue or what specific limitations should be included. The action is clear but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment points out the absence of a \"Limitation\" section, which is an important part of the paper. However, it does not specify which part of the paper is missing this section or provide details on what limitations should be discussed. This makes it difficult for the authors to pinpoint the exact area needing attention. The comment is not grounded as it does not identify a specific section or part of the paper, and it is also not specific about what limitations should be included. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper lacks a \"Limitation\" section, which is an important component. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this section is crucial or how its absence affects the paper. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a significant omission in the paper, namely the absence of a \"Limitation\" section. This is an important aspect of academic writing, as it allows readers to understand the scope and potential drawbacks of the research. However, the comment lacks specificity and does not provide guidance on what limitations should be discussed or how they might be addressed. While it highlights a critical area for improvement, the feedback is incomplete and does not offer actionable suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides several explicit actions for the authors to take. It suggests that Section 2.1 needs more detailed explanations of the theory behind diffusion models, which is a clear and concrete action. Additionally, it points out specific sections (2.2 and 3.2) where additional explanations or clarifications are needed, such as explaining the works of Choi et al. (2021) and Meng et al. (2021). The comment also highlights the need for more explanatory captions for figures, specifically mentioning Figures 3, 4, 7, and 8. These actions are explicit and provide concrete guidance on what needs to be addressed, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"Section 2.1,\" \"Section 2.2,\" and \"Section 3.2,\" allowing the authors to accurately identify the parts being addressed. It also mentions specific works and figures, providing clear guidance on what needs to be addressed. The comment is specific in detailing what is missing or unclear in these sections, such as the need for more detailed explanations of the theory behind diffusion models and the lack of explanation for certain works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of multiple claims and suggestions for improvement, but it does not provide specific evidence or reasoning to support these claims. It lacks detailed explanations or references to justify the need for more detailed explanations in Section 2.1, the use of CLIP guidance, or the explanation of specific works. Additionally, the comment about figure captions is a suggestion rather than a claim. Without supporting evidence or detailed reasoning, the claims are difficult for the authors to address, making the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying areas where the paper lacks detailed explanations or clarity. It points out the need for more detailed explanations in Section 2.1 regarding the theory behind diffusion models and in Section 2.2 regarding the use of CLIP guidance. Additionally, it highlights the importance of explaining specific works mentioned in Section 3.2 and improving the captions of figures to enhance their explanatory value. This feedback is clear and actionable, guiding the authors on how to improve the comprehensiveness and clarity of their draft. However, the comment could be more helpful if it offered suggestions on how to enhance the explanations or provided examples of what could be included in the captions. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the title should include the term \"tensor completion\" because it is the only application of the new model presented in the paper. This is an explicit action that provides clear guidance on how to modify the title to better reflect the content of the paper. The suggestion is concrete, as it specifies exactly what needs to be added to the title. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the title, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added to the title, namely the term \"tensor completion,\" to better reflect the content of the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the title should include the term \"tensor completion\" because it is the only application of the new model presented in the paper. This claim is based on a logical observation about the content of the paper and the relevance of the title to that content. However, the comment does not provide specific examples or references to support why \"tensor completion\" is the only relevant application, which could strengthen the justification. Therefore, the claim is mostly verifiable, as it provides a clear rationale but lacks detailed evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that the title should include the term \"tensor completion\" because it is the only application of the new model presented in the paper. This feedback is clear and actionable, providing a specific recommendation for improving the title to better reflect the content of the paper. By making this suggestion, the reviewer offers a straightforward way for the authors to enhance the clarity and relevance of their title, which is valuable for readers and the overall impact of the paper. However, the comment could be more helpful if it provided additional context or examples of how \"tensor completion\" is the primary application, which would further support the suggestion. Overall, the comment is mostly helpful, as it provides a clear and actionable piece of feedback that can improve the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should implement a simple baseline, such as character frequencies, and compare it to their proposed method to make the paper more persuasive. This is an explicit action with concrete details on how to improve the draft. The reviewer provides a specific suggestion for a baseline, which gives the authors clear guidance on what to do. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the lack of comparison to prior methods and suggests implementing a simple baseline for comparison. However, it does not specify which part of the paper this critique pertains to, such as a particular section or figure where comparisons are discussed. The authors can infer that it relates to the empirical evaluation section, but this inference is not direct. The comment is specific in suggesting the implementation of a baseline for comparison, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison to prior methods, which is a subjective opinion. The reviewer suggests that implementing a simple baseline, such as character frequencies, would make the paper more persuasive. However, the comment does not provide specific examples of prior methods or detailed reasoning for why the current evaluation is insufficient. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of comparisons to prior methods and the potential benefits of a baseline comparison. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, namely the lack of comparison to prior methods. It suggests that the authors should implement a simple baseline, such as character frequencies, to compare with their proposed method. This feedback is clear and actionable, providing the authors with a specific direction to enhance the empirical evaluation of their work. By incorporating a baseline comparison, the authors can make their paper more persuasive and robust. However, the comment could be more helpful if it offered additional suggestions or examples of how to implement the baseline or what specific aspects to focus on in the comparison. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of the proposed method in reducing computational load in real applications. It explains that the method may face challenges due to the activation of different channels by different tokens, making it difficult to apply a uniform activation pattern. The comment also notes that the reliance on precomputed PPL and activation patterns may not generalize well to other tokens, potentially requiring all tokens to activate all channels, which would negate the intended efficiency gains. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation. The action is implicit and somewhat vague, as the authors are left to infer that they should consider ways to improve the method\\'s practicality and efficiency. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the practicality of the proposed method in reducing computational load, specifically mentioning the challenges posed by different tokens activating different channels. It provides a detailed explanation of the potential issues, such as the difficulty in applying a uniform activation pattern and the reliance on precomputed PPL and activation patterns that may not generalize well. However, the comment does not specify which part of the paper discusses the proposed method or its computational load reduction, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the potential issues with the method, so it is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method may face challenges in reducing computational load in real applications due to the activation of different channels by different tokens. It provides a logical explanation by noting that the method relies on precomputed PPL and activation patterns, which may not generalize well to other tokens. The comment also suggests that in extreme cases, all tokens might need to activate all channels to achieve their unique activation pattern, negating the intended efficiency gains. This reasoning is clear and provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed method, specifically its practicality in reducing computational load in real applications. It provides a detailed explanation of the challenges, such as the difficulty in applying a uniform activation pattern across different tokens and the reliance on precomputed PPL and activation patterns that may not generalize well. The comment also highlights the potential consequence of this limitation, where all tokens might need to activate all channels to achieve their unique activation pattern, negating the intended efficiency gains. This feedback is clear and actionable, as it prompts the authors to consider these challenges and potential solutions, such as improving the method\\'s generalizability or efficiency. However, the comment could be more helpful if it offered specific suggestions or examples of how to address these issues. Overall, the comment is mostly helpful, as it provides valuable insights into a critical aspect of the method\\'s practicality and efficiency.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the core motivation of the paper is not clear, specifically mentioning the abstract\\'s statements about task boundaries and the proposed benchmark, metrics, and gating technique. However, it does not provide explicit guidance on how to improve the clarity of the motivation or suggest specific changes to make it clearer. The authors are left to infer that they need to clarify the motivation, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the core motivation is not clear, particularly with the stacked statements about task boundaries and the proposed benchmark, metrics, and gating technique. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the core motivation of the paper is not clear, specifically criticizing the abstract for presenting \"stacked statements\" that fail to capture the main problem to be solved. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. Without additional context or evidence, the claim remains vague and lacks sufficient justification, rendering it barely verifiable. Therefore, the comment is classified as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically that the core motivation is not clear. It points out that the abstract presents a series of statements without effectively capturing the main problem to be solved. This feedback is valuable as it highlights a critical area for improvement, helping the authors to clarify their paper\\'s focus and ensure that the abstract effectively communicates the paper\\'s contributions. However, the comment could be more helpful if it provided specific suggestions on how to rephrase or reorganize the abstract to better convey the motivation. Overall, the comment is mostly helpful as it directs the authors to a key area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concerns about the sequence inference classifier used for filtering data and questions the type of data that passes this filter. It suggests that the task of filtering data using the task description is different from the original MNLI distribution and recommends providing examples of the filtered data. While the comment implies that the authors should provide examples of filtered data, it does not explicitly instruct them to do so. The action is concrete in terms of what is needed, but it is implicit in the request for examples. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses concerns about the sequence inference classifier used for filtering data, specifically questioning what kind of data passes this filter and how it differs from the original MNLI distribution. It suggests that providing examples of the filtered data would be helpful. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the methodology or results sections where data filtering is discussed. The comment is specific in detailing what needs to be addressed, namely the need for examples of filtered data. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses concerns about the sequence inference classifier used for filtering data, questioning the type of data that passes this filter and suggesting that it differs from the original MNLI distribution. The comment requests examples of the filtered data to better understand the issue. While the comment highlights a potential concern, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the exact nature of the issue and how it affects the paper. Therefore, the comment is somewhat verifiable, as it provides a basis for further investigation but requires more detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the sequence inference classifier used for filtering data, questioning the type of data that passes this filter and how it differs from the original MNLI distribution. It suggests that providing examples of the filtered data would be helpful to better understand the issue. This feedback is somewhat helpful as it identifies a potential area of confusion and provides a clear suggestion for improvement. However, it could be more helpful if it offered specific guidance on how to address the issue or provided examples of what kind of data might be filtered. Overall, the comment provides a useful direction for the authors to clarify their methodology, but it could be more comprehensive with additional details or examples.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the application experiments, including potential biases due to the use of a single model (DALL-E) and a small dataset. It suggests that the experiment results are not convincing and recommends conducting comprehensive experiments to validate the proposed methods. Additionally, it advises the authors to examine the structure, argumentation, and language clarity of the paper to ensure it meets high-quality standards. The comment also points out specific issues with equation numbering and the format of Algorithm 1, recommending improvements. While the comment provides explicit actions and suggestions, it could be more actionable by offering concrete steps for addressing the issues with the experiments and the paper\\'s structure. Overall, the comment is mostly actionable, as it provides clear guidance on areas for improvement but could benefit from more detailed instructions on how to implement these changes.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the application experiments\" and \"the equation numbering in the paper\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the potential biases in the experiments, the need for comprehensive experiments, and specific issues with the paper\\'s structure, such as equation numbering and algorithm formatting. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the application experiments may have biases due to the use of a single model (DALL-E) and a small dataset. It suggests that this limits the validity of the experiment results and recommends conducting more comprehensive experiments. The comment provides a logical reasoning for the potential bias and suggests a way to address it, making the claim mostly verifiable. However, it could be strengthened by providing specific examples or references to support the claim about the small dataset and the need for more comprehensive experiments. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies several areas of concern with the paper, including potential biases in the application experiments due to the use of a single model and a small dataset. It highlights the need for more comprehensive experiments to validate the proposed methods and suggests that the paper requires an in-depth editorial review to ensure it meets high-quality standards. Additionally, the comment points out specific issues with the structure, argumentation, and language clarity, such as chaotic equation numbering and a lack of indentation in Algorithm 1. These observations provide clear and actionable feedback for the authors to address, making the comment mostly helpful. However, it could be more comprehensive by offering detailed suggestions for improving the experiments and the paper\\'s structure. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the lack of practical applications in the paper, specifically noting that the experiments are conducted on datasets created by concatenating manipulated samples from standard benchmarks. The reviewer suggests that the authors should comment on the potential for real-world tasks where such a model could be applied. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to discuss potential real-world applications. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the lack of practical applications in the paper, specifically noting that the experiments are conducted on datasets created by concatenating manipulated samples from standard benchmarks. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. The authors can infer that it relates to the experimental setup or results, but the comment lacks full grounding. It is specific in pointing out the absence of practical applications, but without explicit references to specific sections, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the lack of practical applications in the paper, specifically noting that the experiments are conducted on datasets created by concatenating manipulated samples from standard benchmarks. The reviewer suggests that the authors should comment on potential real-world tasks where such a model could be applied. However, the comment does not provide specific examples or references to support the claim that the experiments lack practical relevance. The reasoning is logical but lacks detailed evidence or examples, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the lack of practical applications in the paper, specifically noting that the experiments are conducted on datasets created by concatenating manipulated samples from standard benchmarks. This observation is relevant and could be a significant point for the authors to address, as it questions the relevance and generalizability of the findings. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or explore real-world applications. While it highlights an important area for improvement, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the CAL-MIR selection of m\\' and whether it is done exhaustively over all the loss minimizer subsets. The reviewer suggests that this process might be prohibitive at some point. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify the process in their draft. The action is implicit and vague, as the authors are left to infer that they need to provide more information about the selection process but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the CAL-MIR selection of m\\' and whether it is done exhaustively over all the loss minimizer subsets. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. The comment is specific in its inquiry about the selection process, but without grounding, it is challenging for the authors to determine where to make the necessary adjustments. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the CAL-MIR selection process, specifically whether it is done exhaustively over all loss minimizer subsets. It does not contain a claim or opinion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the CAL-MIR selection process, specifically asking whether it is done exhaustively over all the loss minimizer subsets. This inquiry highlights a potential area of confusion or lack of clarity in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify the process in their draft. While it identifies a point of confusion, it lacks actionable feedback, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider other backdoor detection methods that are input data-free, specifically mentioning methods that use weight matrix statistics or matrix factorization. While the comment implies that the authors should include these methods in their analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their analysis to include these additional methods. However, the suggestion is concrete in terms of what specific methods to consider, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Robustness\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests considering other backdoor detection methods that are input data-free, such as those using weight matrix statistics or matrix factorization. This provides clear guidance on what additional analysis should be included in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should consider other backdoor detection methods that are input data-free, specifically mentioning methods using weight matrix statistics or matrix factorization. This claim is somewhat verifiable as it provides a specific suggestion for expanding the analysis, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to explore these methods further to understand their relevance and potential impact on the analysis. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the \"Robustness\" section by suggesting that the authors consider other backdoor detection methods that are input data-free. It mentions methods using weight matrix statistics or matrix factorization, which could enhance the analysis of algorithm performance. This feedback is clear and actionable, as it provides a concrete suggestion for expanding the scope of the paper. However, it could be more helpful if it included a detailed explanation of why these methods are relevant or how they might impact the analysis. Overall, the comment is mostly helpful, as it directs the authors to a potential area of improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies two areas that need improvement: the \"relation works\" section and the problem definition methodology. It provides a clear action for the authors to take by suggesting that they need to describe which view of the knowledge graph is part of the assumption, such as instance-view, ontology-view, or two-view KG. This feedback is direct and concrete, giving the authors a clear understanding of what needs to be added to their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"relation works\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the section is incomplete and suggests that the authors need to describe which view of the knowledge graph is part of the assumption, such as instance-view, ontology-view, or two-view KG. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"relation works\" section is incomplete and suggests that the authors need to describe which view of the knowledge graph is part of the assumption. However, the comment does not provide any specific examples or references to support these claims, nor does it offer detailed reasoning or evidence to substantiate the need for this information. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific areas that need improvement in the paper: the \"relation works\" section and the problem definition methodology. It points out that the \"relation works\" section is incomplete and suggests that the authors should describe which view of the knowledge graph is part of the assumption, such as instance-view, ontology-view, or two-view KG. This feedback is clear and actionable, providing the authors with a direct path to enhance their draft by addressing these gaps. However, the comment could be more helpful if it offered additional guidance or examples on how to effectively describe these aspects. Overall, the comment is mostly helpful as it effectively directs the authors to specific areas needing improvement, but it could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare the accuracy of their method on the regression task to strong baselines, as the contribution primarily revolves around making predictions on \\\\(\\\\hat{y}\\\\). This is an explicit action that provides a clear direction for the authors to follow. However, the comment does not specify which baselines should be used or how the comparison should be conducted, leaving some room for interpretation. Therefore, the action is mostly actionable, as it gives the authors a clear direction but lacks detailed guidance on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the problem setup and the contribution of the paper, specifically mentioning the use of black box optimization techniques and the focus on regression to make predictions on \\\\(\\\\hat{y}\\\\). It suggests comparing the accuracy of the method to strong baselines, which implies that the comment is related to the methodology and results sections. However, the comment does not explicitly mention these sections, making it weakly grounded. It is specific in suggesting a comparison to strong baselines, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the contribution of the paper revolves around regression to make predictions on \\\\(\\\\hat{y}\\\\), and it suggests comparing the accuracy of the method to strong baselines. However, the comment does not provide specific examples of strong baselines or detailed reasoning to support the claim that the optimization is a downstream task that should be the same regardless of the regression mechanism. This lack of detailed justification or references makes the claim somewhat verifiable, as the authors would need to infer the relevance of the suggestion and identify appropriate baselines on their own. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper by noting that the contribution focuses on regression for making predictions on \\\\(\\\\hat{y}\\\\), but the optimality gap metric is not part of the proposal. It suggests that the authors should compare the accuracy of their method on this task to strong baselines, which is a clear and actionable suggestion for improvement. This feedback is valuable as it directs the authors to a specific area where they can enhance their work by providing a more comprehensive evaluation. However, the comment could be more helpful if it specified which baselines should be used or how the comparison should be conducted. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but lacks some detail.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of theoretical support for the technical design and questions the update derivation for the intrinsic reward parameters. It mentions that the design is based on Sorg et al. 2010, but notes that the update derivation is not convincing. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the theoretical support. The action is implicit and vague, as the authors are left to infer that they need to provide more theoretical justification and improve the update derivation, but without specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the technical design\" and \"Eq.7-10,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the lack of theoretical support for the technical design and questions the update derivation for the intrinsic reward parameters. The comment provides a clear critique of the theoretical foundation and suggests that the update derivation is not convincing, even referencing a related work (Sorg et al. 2010) for context. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical design lacks theoretical support and questions the update derivation for the intrinsic reward parameters. It references Sorg et al. 2010 as a related work, which provides some context and justification for the claim. However, the comment could be more verifiable by providing a detailed explanation of why the update derivation is not convincing or by offering specific examples or references to support the claim. The mention of Sorg et al. 2010 is a good start, but the comment could benefit from more detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the technical design of the paper, specifically noting a lack of theoretical support. It questions the update derivation for the intrinsic reward parameters, suggesting that even if the design is based on a previous work (Sorg et al. 2010), the current update derivation is not convincing. This feedback is valuable as it highlights a critical area that needs further justification or improvement. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue or improve the theoretical foundation. Despite this, the comment is mostly helpful as it directs the authors to a key area that requires attention and improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the adaptive variance reduction property claimed by the authors, suggesting that it is equivalent to simply choosing a \"small enough\" \u03b2 parameter. The reviewer implies that this does not truly represent adaptivity, as seen in methods like AdaGrad. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their claim. The action is implicit and vague, leaving the authors without clear direction on how to revise their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the adaptive variance reduction property claimed by the authors, specifically mentioning the choice of the \"\u03b2 parameter.\" However, it does not explicitly mention which part of the paper discusses this property, making it weakly grounded. The comment is specific in its critique, suggesting that the adaptivity claim is not truly represented by the choice of a \"small enough\" \u03b2 parameter and comparing it to adaptive methods like AdaGrad. This provides clear guidance on what aspect of the paper needs improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the adaptive variance reduction property is not truly adaptive and is equivalent to choosing a \"small enough\" \u03b2 parameter. The reviewer supports this claim by comparing it to adaptive methods like AdaGrad, suggesting that the adaptivity claim is not substantiated. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. The authors would need to delve deeper into the paper and the comparison to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the adaptive variance reduction property claimed by the authors, suggesting that it is equivalent to simply choosing a \"small enough\" \u03b2 parameter. This critique questions the adaptivity of the method, comparing it unfavorably to adaptive methods like AdaGrad. While the comment identifies a potential weakness in the authors\\' claim, it lacks specific suggestions or guidance on how the authors might address this issue or improve their method. The feedback is somewhat helpful as it points out a potential flaw, but it does not provide actionable advice for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the unclear value of different augmentation techniques and suggests that DINOv2 is the best-performing model most of the time. It implies that the authors should further investigate why DINOv2 is the best-performing model and how to improve it. However, the comment does not provide explicit guidance on how to conduct this investigation or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the steps to take and lack detailed instructions on how to execute them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the value of different augmentation techniques and the performance of DINOv2, but it does not specify which part of the paper discusses these techniques or models. This makes it difficult for the authors to pinpoint the exact section that needs attention. While the comment provides some guidance on what needs to be addressed, it lacks specificity in terms of what specific aspects of the augmentation techniques or DINOv2 should be further investigated. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the value of different augmentation techniques is unclear and suggests that DINOv2 is the best-performing model most of the time. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed evidence or reasoning, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of uncertainty regarding the value of different augmentation techniques and notes that DINOv2 seems to be the best-performing model most of the time. It suggests that further investigation is needed to understand why DINOv2 performs better and how to improve it. This feedback is somewhat helpful as it points out a potential area for improvement and encourages the authors to delve deeper into the performance of DINOv2. However, the comment lacks specific guidance on how to conduct this investigation or what aspects to focus on, which limits its usefulness. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the acronym \"FTL\" for \"follow the top perturbed leader\" is unfortunate because it is commonly associated with \"Follow the Leader\" in literature. The reviewer implies that a change of acronym might be necessary. While the comment explicitly suggests a potential issue with the acronym, it does not provide specific guidance on how to choose an alternative acronym or what criteria to consider. The action is explicit but somewhat vague, as the authors know they need to change the acronym but may not be sure of the best alternative. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the acronym \"FTL\" and its potential confusion with \"Follow the Leader\" in literature. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the acronym and suggests a change to avoid confusion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the acronym \"FTL\" for \"follow the top perturbed leader\" is unfortunate because it is commonly associated with \"Follow the Leader\" in literature. The reviewer provides a logical reasoning for the claim by referencing common usage in literature, which supports the suggestion for a change in the acronym. However, the comment could be strengthened by providing specific examples or references to further substantiate the claim. Overall, the claim is mostly verifiable, as it provides a clear rationale but lacks detailed references or examples. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the acronym \"FTL\" for \"follow the top perturbed leader,\" suggesting that it may be confused with \"Follow the Leader\" in literature. This is a clear and actionable feedback that could help the authors avoid confusion in their terminology. However, the comment could be more helpful if it provided suggestions for alternative acronyms or further guidance on how to address the issue. Despite this, the feedback is mostly helpful as it directs the authors to a specific area that needs attention, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the selection of attacks in Table 1 appears arbitrary and suggests that the authors should consider state-of-the-art attacks, such as MIDIFGSM. It also provides a reference to a survey that could help the authors identify better attacks. Additionally, the comment requests that the authors include information about the number of iterations the attacks are run for, among other details. This feedback is clear and provides specific actions for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the selection of attacks, noting that they are not state-of-the-art and suggests considering attacks like MIDIFGSM. The comment further specifies that the authors should include information about the number of iterations the attacks are run for, among other details. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the selection of attacks in Table 1 is arbitrary and suggests that there are better, state-of-the-art attacks available, such as MIDIFGSM. The reviewer provides a reference to a survey that could support this claim, offering a basis for the suggestion. However, the comment could be strengthened by providing more specific examples or detailed comparisons of the attacks mentioned. Overall, the claim is mostly verifiable, as it provides a logical reasoning and a reference, but it lacks detailed examples to fully substantiate the claim. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific issue with the selection of attacks in Table 1, labeling it as arbitrary and suggesting that state-of-the-art attacks, such as MIDIFGSM, should be considered. The comment provides a reference to a survey that could aid the authors in identifying better attacks. Additionally, it requests that the authors include information about the number of iterations the attacks are run for, among other details. This feedback is actionable and provides clear guidance on how to improve the draft, making it highly helpful for the authors.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the method, noting that it is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for improvement, additional experiments, or further analysis to address this limitation. As a result, the authors are left without any guidance on how to address this issue, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to the \"limitations and conclusion\" sections of the paper, providing some grounding by indicating where the issue is discussed. However, it does not specify which part of these sections is being addressed, making it weakly grounded. The comment is specific in its claim about the method\\'s effectiveness being limited to encoders pre-trained with contrastive learning and its potential lack of performance with other self-supervised learning methods like Masked Image Modeling (MIM). Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment highlights a specific limitation of the method, noting that it is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). This feedback is somewhat helpful as it points out a potential weakness in the method's applicability, prompting the authors to consider and address this limitation in their draft. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might explore or address this issue, such as recommending additional experiments or analyses. Therefore, while it offers some insight, it is not fully actionable, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and concerns about the qualitative analysis section, specifically regarding the determination of input sentences, the normalization of attribution values, and the performance of the attribution map for failed classifications. While the comment does not explicitly instruct the authors to make changes, it implies that they should address these issues by providing more detailed information. The actions are implicit but concrete, as the authors know exactly what needs to be clarified or explained. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 4.5.5\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the qualitative analysis, such as the determination of input sentences, the normalization of attribution values, and the performance of the attribution map for failed classifications. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several questions and concerns about the qualitative analysis, specifically regarding the determination of input sentences, the normalization of attribution values, and the performance of the attribution map for failed classifications. While the comment provides specific questions, it does not offer any supporting evidence, reasoning, or references to substantiate these claims. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the concerns. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several specific areas of concern regarding the qualitative analysis section, including the description of input sentences for qualitative analysis, the normalization of attribution values, and the performance of the attribution map for failed classifications. It provides clear and actionable feedback by asking for clarification on these points, which would help the authors improve the clarity and comprehensiveness of their qualitative analysis. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to improve the analysis. Overall, the comment is mostly helpful as it directs the authors to specific areas needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors include examples of practical applications where specific types of tensors need to be equivariant and clarify how these scenarios validate the advantages of using equivariant tensor functions. This feedback is explicit, as it clearly states what the authors should do to improve their draft. It also provides concrete guidance on what specific content should be added, making it clear to the authors how to implement the suggestion. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifying how these scenarios validate the advantages of using equivariant tensor functions. However, it does not specify which part of the paper this suggestion should be applied to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the inclusion of examples and clarification of practical applications. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifying how these scenarios validate the advantages of using equivariant tensor functions. However, the comment does not provide any specific examples, reasoning, or references to support the claim that such examples are necessary or beneficial. Without additional context or evidence, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It recommends including examples of practical applications where specific types of tensors need to be equivariant, which would help clarify the advantages of using equivariant tensor functions. This feedback is specific and provides a concrete direction for the authors to enhance their draft by demonstrating the practical relevance of their work. However, the comment could be more helpful if it offered additional guidance on how to select or present these examples. Overall, the comment is mostly helpful as it offers a clear path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific issues with the tables, particularly Table 2, where methods like ERM, cRT, and LWS are not properly referenced. It also mentions that Section 3.2.3 does not fully align with the table. While the comment highlights these problems, it does not provide explicit instructions on how to address them, such as suggesting ways to clarify the references or align the section with the table. The actions are implicit and somewhat vague, as the authors can infer that they need to clarify the references and ensure consistency between the section and the table. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Section 3.2.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the tables, such as the lack of proper references for methods like ERM, cRT, and LWS, and the misalignment between Section 3.2.3 and the table. This provides clear guidance on what needs to be addressed to improve the clarity and consistency of the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are issues with the tables, specifically Table 2, where methods like ERM, cRT, and LWS are not properly referenced. It also mentions that Section 3.2.3 does not fully align with the table. The comment provides specific examples of the issues, such as the lack of references for certain methods, which helps to support the claim. However, it does not provide detailed reasoning or examples of how these issues affect the paper\\'s clarity or validity. While the comment highlights specific problems, it lacks comprehensive justification or references to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides some support but could be strengthened with more detailed reasoning or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific issues with the tables, particularly Table 2, where methods like ERM, cRT, and LWS are not properly referenced. It also points out that Section 3.2.3 does not fully align with the table. This feedback is clear and actionable, as it directs the authors to clarify the references for the methods in the table and ensure that the section aligns with the table. By addressing these issues, the authors can improve the clarity and consistency of their paper. However, the comment could be more helpful if it provided suggestions on how to properly reference the methods or align the section with the table. Overall, the comment is mostly helpful as it provides specific guidance for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two explicit questions and requests for additional details. The first question asks whether the model is suitable for sarcastic or non-sarcastic utterances, and the authors are asked to provide more details for further analysis. The second question inquires about the usefulness of eye-movement data for sarcastic/non-sarcastic sentiment classification beyond textual features, with a request for more explanations. These questions and requests are clear and direct, providing the authors with specific actions to take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides two distinct questions and requests for additional details: one regarding the suitability of the model for sarcastic/non-sarcastic utterances and another about the usefulness of eye-movement data for sentiment classification. This level of detail guides the authors on what specific aspects need further analysis or explanation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and questions, without any subjective claims or opinions that require verification. It describes the paper as \"well written and organized\" and mentions the careful conduct of experiments and reasonable analysis. The questions posed are seeking clarification and additional information, which do not constitute claims. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a positive initial assessment of the paper, noting its overall quality and organization. However, it then offers two specific suggestions for improvement. The first question asks whether the model is suitable for sarcastic or non-sarcastic utterances, prompting the authors to provide more details for further analysis. The second question inquires about the usefulness of eye-movement data for sarcastic/non-sarcastic sentiment classification beyond textual features, requesting more explanations. These questions are clear and actionable, guiding the authors on how to enhance their work by addressing these specific areas. While the comment is mostly helpful, it could be more comprehensive by providing additional suggestions or examples to further support the authors in improving their draft. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the limited number of experimental results and the inappropriateness of the tables. It mentions that the paper only conducts experiments on two small-scale datasets and that the tables are unprofessional, specifically noting that DDIM is a sampler method rather than a model. However, the comment does not provide explicit guidance on how to address these issues or suggest specific actions for improvement. The authors are left to infer that they should conduct more experiments and ensure the tables are professionally presented, but the lack of concrete instructions makes the feedback somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table1 and table2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the experimental results, noting the limited number of datasets used and the inappropriateness of the tables, particularly the incorrect labeling of DDIM as a sampler method instead of a model. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results are limited, as the paper only conducts experiments on two small-scale datasets. It also points out that the tables are unprofessional, specifically mentioning that DDIM is a sampler method instead of a model. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or evidence renders the claim somewhat verifiable, as the authors would need to infer the issues from the general statements provided.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper: the limited number of experimental results and the unprofessional presentation of tables. It specifically points out that the paper only conducts experiments on two small-scale datasets and that the tables are inappropriately labeled, with DDIM being incorrectly identified as a sampler method instead of a model. This feedback is clear and actionable, as it directs the authors to expand their experimental scope and ensure the accuracy and professionalism of their table presentation. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered examples of datasets or presentation styles to consider. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors need to provide more clarification about the importance of their proposed method. It implies that the method is merely adjusting the variance level of DPSGD and questions how this affects utility and privacy levels. The comment explicitly states that the authors should present what is lost in terms of privacy level or what benefits are derived. This feedback is explicit and provides a clear direction for the authors to improve their draft by addressing the importance and implications of their method. The action is concrete, as it specifies what needs to be clarified and how to do it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors need to provide more clarification about the importance of their proposed method, specifically questioning whether it merely adjusts the variance level of DPSGD and how this affects utility and privacy levels. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the method is discussed. This makes it difficult for the authors to pinpoint the exact area that needs revision. The comment is specific in its request for clarification on the method\\'s importance and its impact on privacy levels, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the proposed method is merely an adjustment to the variance level of DPSGD and questions its importance. However, the comment does not provide specific evidence or reasoning to support this claim, such as comparisons with other methods or detailed analysis of the impact on utility and privacy levels. Without such evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a need for clarification about the importance of the proposed method, suggesting that it may be perceived as merely adjusting the variance level of DPSGD. It questions how this adjustment affects utility and privacy levels, prompting the authors to provide a clearer explanation of the benefits and potential trade-offs. This feedback is somewhat helpful as it highlights an area where the authors could improve their explanation and provide more context for the reader. However, it lacks specific suggestions or examples on how to address this issue, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the empirical results are more illustrative than demonstrative and recommends conducting a bigger-scale experiment, specifically with a longer-horizon example. The reviewer explicitly suggests presenting this in a tabular format. This feedback is explicit and provides concrete guidance on what the authors should do to improve their draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the empirical results, suggesting that they are more illustrative than demonstrative and recommending a bigger-scale experiment with a longer-horizon example. While it does not explicitly mention a specific section or figure, the authors can infer that it relates to the empirical results section. The comment is specific in suggesting a longer-horizon example and providing a format for presentation, which is a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the empirical results are \"illustrative, more than demonstrative\" and suggests that a bigger-scale experiment with a longer-horizon example would be beneficial. However, the comment lacks specific reasoning or evidence to support why the current results are insufficient or how a larger-scale experiment would improve the study. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a specific critique of the empirical results, noting that they are more illustrative than demonstrative. It suggests that a bigger-scale experiment with a longer-horizon example would be beneficial, offering a clear direction for improvement. The comment is actionable as it provides a concrete suggestion for enhancing the empirical section of the paper. However, it could be more helpful if it included additional guidance on how to conduct the larger-scale experiment or what specific aspects of the longer-horizon example should be explored. Overall, the comment is mostly helpful as it offers a clear path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Equation (13) does not have a closed-form solution in general and suggests that providing details about how it is solved in the experiments and on the computational complexity would be helpful. This feedback is explicit, as it clearly states what the authors need to address: providing details about the solution and computational complexity of Equation (13). The action is also concrete, as it specifies what information should be included. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (13),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of a closed-form solution and suggests that details about how it is solved in the experiments and the computational complexity would be helpful. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Equation (13) does not have a closed-form solution in general and suggests that providing details about its solution and computational complexity would be helpful. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Equation (13), noting that it does not have a closed-form solution in general. It suggests that providing details about how the equation is solved in the experiments and its computational complexity would be beneficial. This feedback is clear and actionable, as it directs the authors to address a particular mathematical aspect of their work. By following this suggestion, the authors can enhance the clarity and comprehensibility of their paper. However, the comment could be more helpful if it offered specific guidance on how to present the solution or complexity, such as suggesting a particular format or methodology. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of discussion on the choice of \"proximity\" and its nature in the context of the proposed tasks. It provides specific examples of how proximity in the solution space does not always correlate with proximity in the Euclidean metric, particularly in complex scenarios like mazes or robotic tasks with obstacles. The reviewer suggests that the paper would be improved by analyzing which tasks have reasonable proximity metrics and demonstrating failures in those that do not. While the comment implies that the authors should conduct this analysis, it does not explicitly instruct them to do so. The action is concrete in terms of what needs to be analyzed, but it is implicit in the sense that the authors must infer the need for this analysis. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of discussion on the choice of \"proximity\" and its nature, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by providing examples of tasks where the relationship between proximity in the solution space and Euclidean metric does not hold, such as complicated mazes and robotic tasks with obstacles. The comment suggests that the paper should analyze which tasks have reasonable proximity metrics and demonstrate failures in those that do not. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks discussion on the choice of \"proximity\" and its nature, particularly in relation to the proposed tasks. It provides specific examples, such as complicated mazes and robotic tasks with obstacles, where the relationship between proximity in the solution space and Euclidean metric does not hold. This reasoning is logical and provides a clear explanation of why the claim is valid. The examples given are specific and help to substantiate the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific sections of the paper where this discussion is lacking, which would further enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the discussion of \"proximity\" and its nature in the context of the proposed tasks. It provides specific examples, such as complicated mazes and robotic tasks with obstacles, where the relationship between proximity in the solution space and Euclidean metric does not hold. The reviewer suggests that the paper should analyze which tasks have reasonable proximity metrics and demonstrate failures in those that do not. This feedback is clear and actionable, offering a specific direction for the authors to improve their draft by addressing a critical aspect of their methodology. By providing concrete examples and a clear path forward, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of implementation details in the experiments, which is necessary for readers to fully understand or reproduce the results. However, it does not provide specific guidance on what implementation details are missing or how the authors should address this issue. The comment refers to \"Questions for details,\" but without elaboration, the authors are left uncertain about what specific details are needed. This lack of concrete guidance makes the action vague and difficult for the authors to implement. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of implementation details in the experiments, which is a specific issue that the authors need to address. However, it does not specify which experiments or sections of the paper are lacking these details, making it weakly grounded. The comment is specific in identifying the need for more implementation details, but without explicit references to specific parts of the paper, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments lack necessary implementation details, which would hinder readers\\' understanding or reproduction of the results. However, the comment does not provide specific examples or details about what implementation details are missing, making it difficult for the authors to address the issue effectively. Without concrete evidence or references, the claim remains vague and lacks sufficient justification, rendering it borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the experiments lack necessary implementation details. This is a critical point, as such details are crucial for readers to fully understand and reproduce the results. However, the comment does not provide specific guidance on what implementation details are missing or how the authors might address this issue. While it points to \"Questions for details,\" it does not elaborate on what those questions might be or how the authors should respond. This lack of specificity and actionable advice limits the comment\\'s helpfulness, making it somewhat helpful. The authors are aware of the need for more detail but are left without clear guidance on how to improve their draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential unfairness in the comparison between SSUL and the paper due to differences in data and model size. It suggests that SSUL uses an off-the-shelf saliency-map detector, while the paper uses a pretrained Mask2Former for region proposals. The reviewer questions whether SSUL would be more competitive if it adopted Mask2Former for detecting unseen classes or if it could generate object proposals without additional data or a heavy model. While the comment implies that the authors should consider these alternatives, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"SSUL\" and \"the paper,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the potential unfairness in the comparison due to differences in data and model size, and suggests alternative approaches for SSUL to adopt. The comment provides specific suggestions for improvement, such as using Mask2Former or generating object proposals without additional data or a heavy model. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the potential unfairness in the comparison between SSUL and the paper due to differences in data and model size. It suggests that SSUL uses an off-the-shelf saliency-map detector, while the paper uses a pretrained Mask2Former for region proposals. The reviewer questions whether SSUL would be more competitive if it adopted Mask2Former for detecting unseen classes or if it could generate object proposals without additional data or a heavy model. The comment provides a logical reasoning by highlighting the differences in data and model size, which could impact the fairness of the comparison. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison between SSUL and the paper, highlighting the use of different models and data sources. It suggests that the use of an off-the-shelf saliency-map detector by SSUL may introduce an unfair comparison, as the paper uses a pretrained Mask2Former for region proposals. The reviewer questions whether SSUL would be more competitive if it adopted Mask2Former or if it could generate object proposals without additional data or a heavy model. This feedback is mostly helpful as it points out a critical aspect of the comparison and provides suggestions for improvement. However, it could be more helpful if it included specific examples or references to support the claim, such as discussing the impact of using Mask2Former or the potential benefits of unsupervised object proposal generation. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the metrics used in the experiments, suggesting that they may not effectively validate the performance of the proposed approach. It provides specific examples, such as the use of a style classifier for style accuracy, which may be overly accurate, and the difficulty in verifying transfer results based on styled motion inputs. However, the comment does not explicitly instruct the authors to change or improve the metrics or provide specific guidance on how to address these concerns. The action is implicit and somewhat vague, as the authors can infer that they need to reassess their metrics but are not given concrete steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experiments and the metrics used to validate the performance of the proposed approach. It provides specific examples, such as the use of a style classifier for style accuracy and the difficulty in verifying transfer results based on styled motion inputs. However, it does not explicitly mention which part of the paper discusses the experiments or metrics, making it weakly grounded. The comment is specific in detailing the potential issues with the metrics, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the metrics used in the experiments, specifically questioning the style accuracy based on a style classifier and the difficulty in verifying transfer results with styled motion inputs. While the comment provides some reasoning by highlighting potential issues with the metrics, it lacks specific examples or references to support the claim. The reasoning is somewhat logical but incomplete, making it difficult for the authors to fully understand and address the concerns. Therefore, the comment is considered borderline verifiable, as it provides some justification but requires more detailed evidence or examples to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies potential issues with the metrics used in the experiments, specifically questioning the style accuracy based on a style classifier and the difficulty in verifying transfer results with styled motion inputs. It provides specific examples and reasoning, which can help the authors understand the limitations of their current approach and consider alternative or more robust metrics. However, the comment could be more helpful if it offered suggestions or guidance on how to address these issues, such as recommending alternative metrics or experimental designs. Overall, the feedback is somewhat helpful as it highlights areas for improvement but lacks detailed actionable advice.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of how individual preferences are generated in the proposed method. It questions whether the preferences are generated on an individual level or if they are based on rules/policies learned from experiences. The comment explicitly requests clarification on this point, providing a clear action for the authors to take. However, it does not specify how the authors should clarify this aspect, such as through additional explanation or examples. While the action is explicit, the lack of detailed guidance on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of how individual preferences are generated in the proposed method, specifically questioning whether these preferences are generated on an individual level or if they are based on rules/policies learned from experiences. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, namely the generation of individual preferences. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of how individual preferences are generated in the proposed method. It questions whether these preferences are generated on an individual level or if they are based on rules/policies learned from experiences. The comment highlights a potential ambiguity in the paper and requests clarification, which is a reasonable request for improvement. However, it does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to provide additional context or evidence to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of clarity regarding how individual preferences are generated in the proposed method. It questions whether these preferences are generated on an individual level or if they are based on rules/policies learned from experiences. This feedback is valuable as it highlights a potential ambiguity in the paper that needs to be addressed. However, the comment could be more helpful if it provided specific suggestions on how the authors might clarify this aspect, such as through additional examples or explanations. Overall, the comment is somewhat helpful as it points out a significant area for improvement but lacks detailed guidance for the authors to fully address the issue. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about Figure 4, specifically regarding the meaning of \"1-200 frames,\" how the values are computed, and why precision and recall change with the trajectory length. It also questions the term \"action repeat.\" While the comment identifies areas of confusion, it does not provide explicit instructions or suggestions on how the authors should address these issues. The authors can infer that they need to clarify these points, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it highlights areas for clarification but does not provide detailed steps for improvement.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the figure, such as the unclear meaning of \"1-200 frames,\" the computation of values, and the change in precision and recall with trajectory length. Additionally, it questions the term \"action repeat.\" This level of detail provides clear guidance on what needs to be clarified or addressed in the figure, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the clarity of Figure 4, specifically regarding the meaning of \"1-200 frames,\" the computation of values, and the change in precision and recall with trajectory length. It also questions the term \"action repeat.\" While the comment identifies areas of confusion, it does not provide any supporting evidence, reasoning, or references to help the authors understand or address these issues. The lack of justification or explanation makes the claim unverifiable, as the authors are left without a clear path to resolve the ambiguities. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific areas of confusion in Figure 4, such as the meaning of \"1-200 frames,\" the computation of values, and the change in precision and recall with trajectory length. It also questions the term \"action repeat.\" By pointing out these ambiguities, the comment provides clear and actionable feedback that can help the authors clarify and improve the clarity of their figure. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to clarify the figure. Overall, the comment is mostly helpful as it directs the authors to specific areas needing clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the arbitrariness of certain design decisions, such as the number of initial ground truth examples and labeled examples. It suggests that the authors should provide justification for these decisions, which would be beneficial for the authors to address. However, the comment does not explicitly instruct the authors to make specific changes or provide detailed guidance on how to justify these decisions. While the authors can infer that they need to provide more justification, the action is not explicitly stated, and the guidance is somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific design decisions, such as the number of initial ground truth examples and labeled examples, which are mentioned as being arbitrary. It suggests that the authors should provide justification for these decisions, particularly in the context of cost-effectiveness. However, the comment does not specify which part of the paper these decisions are discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in detailing what needs to be addressed, namely the justification for these design decisions. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some design decisions, such as the number of initial ground truth examples and labeled examples, seem arbitrary. It suggests that the authors should provide justification for these decisions, particularly in the context of cost-effectiveness. The reviewer proposes a specific comparison between LLaMAA and finetuning to demonstrate the cost-effectiveness of the approach. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that the current design decisions are arbitrary. The suggestion for a comparison is a good starting point, but the comment could be strengthened by providing more detailed reasoning or evidence. Therefore, the claim is somewhat verifiable, as it provides a direction for improvement but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the design decisions in the paper, specifically the number of initial ground truth examples and labeled examples, which are perceived as arbitrary. It suggests that the authors should provide justification for these decisions, particularly in the context of cost-effectiveness. The comment also proposes a specific comparison between LLaMAA and finetuning to demonstrate the cost-effectiveness of the approach. This feedback is clear and actionable, as it directs the authors to address a specific concern and provides a concrete suggestion for improvement. However, the comment could be more helpful if it included additional guidance on how to present the justification or the comparison. Overall, the comment is mostly helpful, as it provides valuable insights and actionable feedback that can significantly improve the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the motivation behind using a graph-structured model, given that the Transformer architecture can already capture global dependencies in sentences. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the confusion or whether the approach is indeed complex. Without actionable suggestions or guidance, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the motivation behind using a graph-structured model, given that the Transformer architecture can already capture global dependencies in sentences. However, it does not specify which part of the paper this concern is addressed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity as it does not detail what aspects of the graph-structured model are confusing or how they relate to the existing sequence models. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the motivation behind using a graph-structured model, given that the Transformer architecture can already capture global dependencies in sentences. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim of confusion. Without additional context or explanation, the authors may find it challenging to understand the basis of the reviewer\\'s concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the motivation behind using a graph-structured model, given that the Transformer architecture can already capture global dependencies in sentences. However, it does not provide any specific suggestions or feedback on how the authors might address this concern or improve their draft. The comment lacks depth and actionable guidance, leaving the authors without a clear understanding of what changes might be necessary or beneficial. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors provide videos showing different policies controlling cars on different tracks to enhance understanding of how different methods work. This is an explicit action that the authors can take to improve the clarity and reproducibility of their work. Additionally, the comment highlights a lack of implementation details in the main paper, which makes reproducing the results difficult. It specifically points out the need for clarity on the policy gradient approach used. These suggestions are concrete and provide clear guidance on what the authors need to do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing videos to demonstrate different policies controlling cars on various tracks, which would enhance understanding of the methods. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment also mentions a lack of implementation details and the unclear policy gradient approach, which are specific issues that need to be addressed. Since the authors can infer that these issues relate to the methodology or results sections, the comment is weakly grounded but specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two claims. The first claim suggests that providing videos showing different policies controlling cars on different tracks would enhance understanding. This is a subjective opinion and lacks specific reasoning or evidence to support why videos would be beneficial. The second claim points out a lack of implementation details and the unclear policy gradient approach, which is a factual observation. However, the comment does not provide specific examples or references to support the claim about the lack of implementation details. Therefore, the first claim is unverifiable, and the second is somewhat verifiable due to the lack of detailed evidence. Overall, the comment is rated as 1: Unverifiable for the first claim and 3: Somewhat Verifiable for the second claim.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides two distinct points for improvement. First, it suggests that including videos demonstrating different policies controlling cars on various tracks would enhance understanding of the methods. This is a clear and actionable suggestion that could significantly improve the paper\\'s clarity and reproducibility. Second, the comment highlights a lack of implementation details in the main paper, which makes reproducing the results difficult. It specifically points out the need for clarity on the policy gradient approach used. These suggestions are specific and provide concrete guidance for the authors to enhance the comprehensiveness and reproducibility of their work. Therefore, the comment is highly helpful, as it offers detailed and actionable feedback that can lead to substantial improvements in the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the approximation method proposed by the authors in Equation 11 and suggests that it only considers the impact of parameters in each layer without accounting for the effect of the order of layers with the same parameters. It also critiques Figure 1 for not indicating which specific layer each color represents. The comment implies that the authors should conduct more experiments and theoretical analyses to explore this aspect. While the comment identifies areas for improvement, it does not provide explicit instructions on how to conduct these experiments or analyses. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 11\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the approximation method proposed by the authors, noting that it only considers the impact of parameters in each layer and does not account for the effect of the order of layers with the same parameters. Additionally, it critiques Figure 1 for not indicating which specific layer each color represents. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the approximation method proposed by the authors in Equation 11, suggesting that it only considers the impact of parameters in each layer without accounting for the effect of the order of layers with the same parameters. The reviewer also critiques Figure 1 for not indicating which specific layer each color represents. While the comment raises valid concerns, it lacks specific examples or references to support the claim that the approximation method is inadequate. The critique of Figure 1 is more factual, as it points out a lack of clarity in the figure. Therefore, the comment is somewhat verifiable, as it provides a logical critique but lacks detailed evidence or references to fully substantiate the claims. This aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the approximation method proposed by the authors in Equation 11, questioning why it can be approximated in the way described. It points out that the approximation only considers the impact of parameters in each layer and does not account for the effect of the order of layers with the same parameters. Additionally, it critiques Figure 1 for not indicating which specific layer each color represents, suggesting that the authors should conduct more experiments and theoretical analyses to explore this aspect. This feedback is mostly helpful as it identifies specific weaknesses in the approximation method and the presentation of Figure 1, providing clear guidance on areas that need further exploration and clarification. However, it could be more helpful if it offered specific suggestions on how to address these issues. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the offline-to-online learning adaptation appears to be incremental and feasible, given that most previous offline RL benchmarks are based on simulation environments and rule-based reward functions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this perceived incremental nature or suggestions for improvement. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the topic of offline-to-online learning adaptation, suggesting that it appears to be incremental. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment also lacks specificity regarding what aspects of the adaptation are considered incremental or how this impacts the paper. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that addressing offline-to-online learning adaptation appears to be incremental, suggesting that most previous offline RL benchmarks are based on simulation environments and rule-based reward functions. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed evidence or reasoning, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the offline-to-online learning adaptation appears to be incremental, given that most previous offline RL benchmarks are based on simulation environments and rule-based reward functions. It implies that implementing online fine-tuning on top of existing benchmarks is feasible. However, the comment lacks specificity and does not provide actionable guidance or suggestions for improvement. It does not offer any detailed feedback or recommendations on how the authors might address the incremental nature of their approach or how to enhance it. As a result, the comment is somewhat helpful, as it identifies a potential area for consideration but does not provide enough detail to be fully actionable. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a contradiction in the evidence presented in Table 6, specifically regarding the performance of AT and BERTsynth, and GAS. It suggests that the results do not support the claim that emotion-awareness is useful for synthetic text detection. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their draft. It lacks actionable suggestions, such as recommending additional experiments or analyses to clarify the role of emotion-awareness. Without specific instructions or suggestions, the authors are left uncertain about how to respond to this critique. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the evidence presented in the table, specifically highlighting the contradictions in the results between AT and BERTsynth, and GAS. The comment provides clear examples of the discrepancies, which helps the authors understand what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 6 presents contradicting evidence regarding the usefulness of emotion-awareness for synthetic text detection. It provides specific examples, such as the performance of AT and BERTsynth, and GAS, to support this claim. The examples are detailed and provide a clear rationale for why the results do not support the claim. This level of detail and specific examples make the claim fully verifiable, as it provides a robust basis for the authors to understand and address the critique. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results presented in Table 6, pointing out contradictions that challenge the claim about the usefulness of emotion-awareness for synthetic text detection. It provides concrete examples, such as the performance of AT and BERTsynth, and GAS, which highlights the discrepancies in the results. This feedback is actionable as it prompts the authors to reconsider their claims and potentially conduct additional experiments or analyses to clarify the role of emotion-awareness. However, the comment could be more helpful if it suggested specific ways to address these discrepancies or offered additional insights into how to improve the draft. Overall, the comment is mostly helpful, as it directs the authors to a critical area that requires further attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting more experiments to address the research question, specifically testing with various models like Vision Transformers (ViT) and including results under more complex input noise models. This provides explicit actions for the authors to take, such as conducting additional experiments and testing with specific models. The comment also specifies the types of experiments that would be beneficial, offering concrete guidance on how to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments to address the research question, specifically testing with various models like Vision Transformers (ViT) and including results under more complex input noise models. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental section. The comment is specific in detailing the types of experiments that would be beneficial, such as testing with ViT and under multiplicative distortions. However, since the authors cannot pinpoint the exact section being addressed, the comment is weakly grounded but specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting more experiments to address the research question, specifically testing with various models like Vision Transformers (ViT) and including results under more complex input noise models. The claim is supported by references to specific papers, such as \"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\" and \"Learning Transferable Visual Models From Natural Language Supervision,\" which provide a basis for the suggestion. However, the comment could be strengthened by providing more detailed reasoning or examples of how these experiments would improve the paper. Overall, the claim is mostly verifiable, as it provides a solid foundation for the suggestion but could benefit from additional explanation. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting additional experiments to address the research question. It recommends testing the method with various models, such as Vision Transformers (ViT), and including results under more complex input noise models. This feedback is clear and detailed, offering the authors concrete steps to enhance the comprehensiveness and generalizability of their work. By suggesting specific experiments and models, the comment empowers the authors to improve their draft significantly. Therefore, it is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the number of human annotators mentioned in the D.2 appendix should be four, based on the author responses. This provides a clear and direct action for the authors to take, ensuring that the information in the appendix is accurate. The comment is explicit and concrete, as it specifies exactly what needs to be corrected, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"D.2 appendix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the discrepancy in the number of human annotators mentioned. The comment provides a clear instruction for correction, ensuring that the authors know exactly what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the number of human annotators mentioned in the D.2 appendix should be four, based on the author responses. However, the comment does not provide any supporting evidence or reasoning to justify why the number should be four. Without additional context or explanation, the claim remains unverifiable, as the authors may not understand the basis for the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the number of human annotators mentioned in the D.2 appendix, pointing out that it should be four based on the author responses. This feedback is clear and actionable, as it provides a precise correction that the authors need to make to ensure the accuracy of their work. However, the comment could be more helpful if it explained why the number should be four or how this discrepancy affects the overall validity of the study. Despite this, the comment is mostly helpful as it directs the authors to a specific area needing correction, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a better motivation for the encoder and decoder structure would be beneficial for understanding the value of the proposed approach. However, it does not provide explicit guidance on how to achieve this motivation or what specific aspects of the structure need to be addressed. The action is implicit and vague, leaving the authors uncertain about the steps to take to improve their draft. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that a better motivation for the encoder and decoder structure would enhance understanding of the proposed approach. However, it does not specify which part of the paper discusses the encoder and decoder structure, making it difficult for the authors to identify the exact section that needs improvement. Additionally, the comment lacks specificity regarding what aspects of the motivation are lacking or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that a better motivation for the encoder and decoder structure would improve understanding of the proposed approach. However, it does not provide any specific reasoning, examples, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that a better motivation for the encoder and decoder structure would enhance the understanding of the proposed approach. However, it lacks specificity and does not provide any guidance on what aspects of the motivation are lacking or how they could be improved. Without actionable suggestions or detailed feedback, the authors are left without a clear direction for enhancing their draft. Therefore, the comment is not helpful at all, as it does not offer any meaningful insights or improvements.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the novelty of the loss functions explored, the absence of black-box evaluation, and the limitation to untargeted attacks. While it identifies areas for improvement, it does not provide explicit or concrete actions for the authors to take. The comment suggests that the loss functions are not new and that the attacks are limited to white-box scenarios, but it does not offer specific guidance on how to address these issues or improve the novelty of the work. The suggestion to extend the analysis to targeted attacks is vague and lacks detail on how to implement this. Therefore, the comment is barely actionable, as it highlights areas for improvement but does not provide clear steps for the authors to follow.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the novelty of the loss functions explored, the absence of black-box evaluation, and the limitation to untargeted attacks. While it does not explicitly mention specific sections of the paper, the authors can infer that these issues relate to the methodology and results sections. The comment is specific in detailing what is lacking, such as the absence of black-box evaluation and the need to extend the analysis to targeted attacks. However, it does not provide explicit references to specific parts of the paper, making it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims about the novelty of the loss functions, the absence of black-box evaluation, and the limitation to untargeted attacks. The claim about the loss functions being \"not new\" is subjective and lacks specific evidence or references to support this assertion. The comment also suggests that the attacks are limited to white-box scenarios and that extending the analysis to targeted attacks would be beneficial. While the reviewer provides some logical reasoning, the lack of specific examples or references makes the claims somewhat verifiable. The authors would need to consider these points and potentially conduct additional research to fully address the concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several areas of concern regarding the novelty of the loss functions, the absence of black-box evaluation, and the limitation to untargeted attacks. It provides a clear critique of the paper's methodology and suggests that the loss functions are not new, which could limit the novelty of the work. The comment also highlights the importance of evaluating black-box attacks and suggests extending the analysis to targeted attacks to showcase the strength of the proposed method. While the feedback is clear and identifies specific weaknesses, it could be more helpful by providing suggestions on how to address these issues or offering examples of how to incorporate black-box evaluation or targeted attacks. Overall, the comment is somewhat helpful as it directs the authors' attention to important areas for improvement but lacks detailed guidance on implementation.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the results for CIFAR10 are not impressive and suggests that a direct comparison with other approaches is necessary. It also requests results for CIFAR100. While the comment implies that the authors should include these comparisons and results, it does not provide explicit instructions on how to conduct these comparisons or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer the need for additional comparisons but may not know exactly how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Results for CIFAR10,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the results are not impressive and suggests that a direct comparison with other approaches is necessary. Additionally, it requests results for CIFAR100. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results for CIFAR10 are not impressive and suggests that a direct comparison with other approaches is necessary. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The request for results on CIFAR100 is a suggestion rather than a claim. Without detailed justification or evidence, the comment is considered borderline verifiable, as it lacks sufficient support for the claim about CIFAR10 results.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results for CIFAR10, noting that they do not appear impressive compared to other approaches. It emphasizes the need for a direct comparison with these approaches, which is a critical aspect of evaluating the effectiveness of the proposed method. Additionally, the comment suggests including results for CIFAR100, which could provide further insights into the model's performance. While the comment highlights important areas for improvement, it could be more helpful by providing specific suggestions on how to conduct these comparisons or what metrics to use. Overall, the feedback is mostly helpful as it directs the authors to enhance the robustness and comprehensiveness of their results, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that hyperbolic space is well-suited for hierarchical datasets but notes that the experiments do not clearly demonstrate this. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what specific experiments or analyses should be conducted to demonstrate the suitability of hyperbolic space for hierarchical datasets. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that hyperbolic space is well-suited for hierarchical datasets but notes that the experiments do not clearly demonstrate this. However, it does not specify which experiments or sections of the paper are being referred to, making it difficult for the authors to identify the exact parts that need attention. The comment lacks grounding as it does not provide a clear reference to specific parts of the paper. Additionally, it is not specific about what needs to be addressed or how the experiments could be improved to demonstrate the suitability of hyperbolic space for hierarchical datasets. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that hyperbolic space is well-suited for hierarchical datasets but notes that the experiments do not clearly demonstrate this. However, the comment lacks specific examples, references, or detailed reasoning to support the claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the experiments, noting that hyperbolic space is well-suited for hierarchical datasets but that the experiments do not clearly demonstrate this. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their experiments to demonstrate the suitability of hyperbolic space for hierarchical datasets. Without actionable feedback or detailed advice, the comment lacks depth and does not fully assist the authors in improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the main strength of MixBoost, asking whether it is related to computational savings, generalization performance, or the use of Random Fourier Features. While the comment identifies a gap in the paper\\'s clarity, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the main strength of MixBoost, but without specific instructions on how to do so. This makes the action vague and somewhat inferable, aligning with a score of 2: Borderline Actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the main strength of MixBoost, specifically asking whether it is related to computational savings, generalization performance, or the use of Random Fourier Features. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs clarification. The comment is specific in its questioning of the main strength but lacks grounding, as it does not reference a particular section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a series of questions seeking clarification about the main strength of MixBoost. It does not contain any claims, opinions, or suggestions that require verification. It is purely descriptive and factual, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a critical question about the main strength of MixBoost, which is a crucial aspect of the paper. By asking whether the strength lies in computational savings, generalization performance, or the use of Random Fourier Features, the reviewer prompts the authors to clarify and emphasize the key benefits of their method. This feedback is valuable as it encourages the authors to provide a clear and focused explanation of their work\\'s strengths, which can enhance the paper\\'s impact and clarity. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how to effectively communicate the main strength. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the wording of a statement regarding hyperparameter tuning and suggests an alternative approach to avoid using a \"smaller training set.\" While the comment identifies a potential issue with the wording and offers a suggestion for improvement, it does not provide explicit instructions on how to rephrase the statement or implement the suggested alternative. The action is implicit and somewhat vague, as the authors need to infer that they should rephrase the statement and consider the suggested approach. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line numbers (243 and 245), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the wording regarding hyperparameter tuning and suggests an alternative approach to avoid using a \"smaller training set.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the wording being \"a bit hard\" and suggests an alternative approach to hyperparameter tuning. However, it does not provide specific reasoning or evidence to support why the current wording is problematic or how the suggested alternative would improve the clarity. The comment lacks detailed justification or examples, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the wording regarding hyperparameter tuning, suggesting that it is \"a bit hard\" to understand. It also provides a constructive suggestion to avoid using a \"smaller training set\" by training the network with optimal parameters on the complete train+val set. This feedback is clear and actionable, offering the authors a direct way to improve the clarity and effectiveness of their draft. However, the comment could be more helpful if it provided additional context or examples to further support the suggestion. Overall, the comment is mostly helpful as it provides valuable guidance for enhancing the manuscript.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing of the paper needs improvement, specifically noting that the introduction is obscure and high-level, lacking detailed elaboration on the implementation. The reviewer recommends that the authors provide more clarity by hinting at how they tokenize parameters and use DDPM to predict actual parameters. While the comment implies that the authors should include more detailed information, it does not provide explicit guidance on how to achieve this. The action is implicit and somewhat vague, as the authors can infer that they need to add more details but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the writing of the paper needs improvement, specifically mentioning that the introduction is \"quite obscure and high-level\" and lacks detailed elaboration on the implementation. It provides a specific suggestion to hint at how parameters are tokenized and how DDPM is used to predict actual parameters. However, the comment does not explicitly mention which part of the paper this issue pertains to, such as a specific section or figure. While the authors can infer that it relates to the introduction, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing what needs to be addressed, such as providing more clarity on the implementation. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the writing of the paper needs improvement, specifically noting that the introduction is \"quite obscure and high-level\" and lacks detailed elaboration on the implementation. The reviewer suggests that the authors should provide more clarity by hinting at how they tokenize parameters and use DDPM to predict actual parameters. However, the comment does not provide specific examples or references to support these claims, making it somewhat vague. The authors would need to infer the exact areas that require improvement, which could be challenging without more detailed guidance. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some justification but lacks concrete evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the writing needs improvement, particularly in the introduction, which is described as \"obscure and high-level.\" It suggests that the authors should provide more detailed information on how they tokenize parameters and use DDPM to predict actual parameters. This feedback is somewhat helpful as it points out a weakness in the paper and offers a suggestion for improvement. However, the comment could be more helpful if it provided specific examples or guidance on how to enhance the clarity of the introduction. Overall, the feedback is actionable but could be more comprehensive, aligning with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the presentation is not good but does not provide any specific examples or suggestions for improvement. It lacks explicit guidance or concrete actions for the authors to take, leaving them without a clear understanding of what needs to be addressed. The comment is vague and does not offer any actionable steps for the authors to enhance their presentation. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the presentation is not good but does not specify which aspects of the presentation are lacking or provide examples. It lacks grounding as it does not identify a specific part of the paper, such as sections, figures, or tables, that the authors should focus on. Additionally, it is not specific about what needs to be improved in the presentation. Without clear guidance or examples, the authors cannot effectively address the issue. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"the presentation is not good,\" but it lacks any supporting evidence, examples, or specific details to substantiate this claim. Without further elaboration or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment claims that the presentation is not good but does not provide any specific examples or details to support this claim. It lacks actionable feedback or suggestions for improvement, leaving the authors without a clear understanding of what aspects of the presentation need to be addressed. Without specific guidance or examples, the authors are unable to effectively enhance their presentation. Therefore, the comment is not helpful at all, as it does not provide any actionable insights or constructive feedback.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly mentions a specific omission in the related work section, pointing out that the authors have missed the work by Rieck et al. [2] when discussing the correlation of topological complexity with generalization ability. This provides a clear and direct action for the authors to take, which is to include the work by Rieck et al. in their discussion. The comment is explicit and concrete, as it specifies exactly what needs to be added to the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Related work\" and \"the correlation of topological complexity with generalization ability,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a missing reference, \"the work by Rieck et al. [2],\" which the authors should include in their discussion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have missed the work by Rieck et al. [2] when discussing the correlation of topological complexity with generalization ability. This is a specific claim that requires verification, as it suggests an omission in the related work section. However, the comment does not provide any reasoning or explanation for why this work is relevant or how it relates to the topic. Without additional context or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support for the authors to understand and act upon the feedback.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific omission in the related work section, pointing out that the authors have missed the work by Rieck et al. [2] when discussing the correlation of topological complexity with generalization ability. This feedback is clear and actionable, as it provides a direct suggestion for the authors to include the missing reference in their discussion. By addressing this gap, the authors can enhance the comprehensiveness and accuracy of their related work section. However, the comment could be more helpful if it provided additional context or explanation about why this work is relevant or how it contributes to the discussion. Overall, the comment is mostly helpful as it offers a specific and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the utility of the exploration parameter gamma in Algorithm 1 and Theorem 3.1, given that only upper bounds on pseudo-regret are provided. It suggests that the choice of gamma=0 might be optimal and proposes a remark on high-probability upper bounds and the role of gamma. Additionally, it questions whether the analysis, which is based on expectations, can be extended to high-probability bounds on regret. While the comment identifies areas for potential improvement and suggests specific topics for discussion, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to consider the role of gamma and explore the possibility of extending their analysis to high-probability bounds, but the comment lacks concrete guidance on how to implement these suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Alg 1\" and \"Thm 3.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the provided upper bounds on pseudo-regret, questioning the utility of the exploration parameter gamma and suggesting a remark on high-probability upper bounds and the role of gamma. Additionally, it raises a question about extending the analysis to high-probability bounds on regret. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the utility of the exploration parameter gamma in Algorithm 1 and Theorem 3.1, given that only upper bounds on pseudo-regret are provided. The reviewer suggests that the choice of gamma=0 might be optimal and proposes a remark on high-probability upper bounds and the role of gamma. The comment questions whether the analysis, which is based on expectations, can be extended to high-probability bounds on the regret. While the comment provides some logical reasoning and questions, it lacks specific examples or references to support the claim about the utility of gamma or the extension of the analysis. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the utility of the exploration parameter gamma in Algorithm 1 and Theorem 3.1, given that only upper bounds on pseudo-regret are provided. It suggests that the choice of gamma=0 might be optimal and proposes a remark on high-probability upper bounds and the role of gamma. Additionally, the comment questions whether the analysis, which is based on expectations, can be extended to high-probability bounds on the regret. This feedback is somewhat helpful as it points out a specific area for improvement and suggests a potential direction for further analysis. However, it could be more helpful if it provided more detailed guidance or examples on how to address these issues. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to add a restatement of the LCA relaxation definition from Wang et al. or provide a description in the appendix. This feedback is clear and direct, providing the authors with a specific action to take to address the issue. The comment is highly actionable as it leaves no ambiguity about what needs to be done to improve the draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 150,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of the LCA relaxation not being directly defined and suggests that the authors either add a restatement of the definition from Wang et al. or provide a description in the appendix. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the definition of LCA relaxation, which is referenced but not directly defined in the paper. The comment suggests adding a restatement of the definition from Wang et al. or providing a description in the appendix. This feedback is factual and does not contain subjective opinions or claims that require verification. It is purely informative and does not fit the criteria for a claim. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely that the LCA relaxation is referenced but not directly defined. It provides a clear and actionable suggestion to either include a restatement of the definition from Wang et al. or add a description in the appendix. This feedback is valuable as it directs the authors to a precise area needing clarification, allowing them to improve the comprehensibility and accuracy of their work. The comment is specific and actionable, making it highly helpful for the authors. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that providing more information on how validation and test splits influence model training could enhance reproducibility. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify exactly what kind of information should be included or how it should be presented. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that more information on how validation and test splits influence model training could strengthen reproducibility. However, it does not specify which part of the paper this information should be added to, such as the methodology or results sections. This makes it difficult for the authors to pinpoint the exact location where this information should be included. The comment is specific in its suggestion but lacks grounding, as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that providing more information on how validation and test splits influence model training could enhance reproducibility. However, the comment does not offer specific examples or detailed reasoning to support why this information is crucial or how it would impact reproducibility. The lack of explicit justification or examples makes it difficult for the authors to understand the significance of this suggestion. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The comment identifies a potential area for improvement by suggesting that more information on how validation and test splits influence model training could enhance reproducibility. This is a relevant point, as understanding the impact of these splits on model training is crucial for ensuring the robustness and reliability of the results. However, the comment lacks specificity and does not provide detailed guidance on what kind of information should be included or how it should be presented. While it highlights an important aspect, the feedback could be more actionable and helpful if it offered concrete suggestions or examples. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scope of the authors\\' approach to addressing overfitting, specifically questioning why they limit their focus to dropout and not other regularization techniques like L2 regularization, data augmentation, or adding noise. It also asks about the potential impact of combining ZeroLiers with these techniques. While the comment implies that the authors should consider a broader range of regularization techniques, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their approach to include other techniques. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the scope of the authors\\' approach to addressing overfitting, specifically questioning why they limit their focus to dropout and not other regularization techniques. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its questioning of the approach but lacks grounding, as it does not reference a particular section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' decision to limit their approach to dropout for addressing overfitting, suggesting that other regularization techniques, such as L2 regularization, data augmentation, or adding noise, should also be considered. The comment logically reasons that in practice, multiple techniques are often used together, and it asks about the potential impact of combining ZeroLiers with these techniques. However, the comment lacks specific examples or references to support the claim that these techniques are commonly used together or that ZeroLiers should be combined with them. This makes the claim somewhat verifiable, as it provides a logical basis but requires further elaboration or evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the scope of the authors\\' approach to addressing overfitting, specifically questioning why they limit their focus to dropout and not other regularization techniques like L2 regularization, data augmentation, or adding noise. It also prompts the authors to consider the potential impact of combining ZeroLiers with these techniques. This feedback is valuable as it encourages the authors to broaden their approach and consider a more comprehensive set of methods for addressing overfitting. However, the comment could be more helpful if it provided specific examples or references to support the suggestion or offered guidance on how to incorporate these additional techniques. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more actionable with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the generalizability of Assumption A, which is reasonable in a tabular setting, to a function approximation setting. It suggests that the authors should discuss this in the section about consistency. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to discuss the generalizability or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Assumption A (overlap)\" and \"the section about consistency,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the generalizability of the assumption from a tabular setting to a function approximation setting and suggests that discussing this in the section about consistency would be beneficial. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the generalizability of Assumption A from a tabular setting to a function approximation setting. It suggests that the authors should discuss this in the section about consistency. However, the comment does not provide any evidence, reasoning, or references to support why this generalization is challenging or how it impacts the paper. The lack of supporting information makes it difficult for the authors to understand the basis of the suggestion, rendering the claim unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the generalizability of Assumption A from a tabular setting to a function approximation setting. It suggests that the authors should discuss this in the section about consistency, which is a logical and actionable suggestion. By addressing this point, the authors can provide a more comprehensive understanding of their work and its applicability to different settings. However, the comment could be more helpful if it offered specific guidance on how to discuss the generalizability or what aspects to focus on. Overall, the comment is mostly helpful as it identifies a potential area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit suggestions for improving the layout of the paper, specifically recommending that Table 1 should be one column wide and that figures 3, 5, and 6 would benefit from a two-column width. It also suggests that major improvements could be achieved by straightening up the content. These suggestions are clear and concrete, giving the authors specific actions to take to enhance the readability and presentation of their paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"figures 3, 5, and 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on the layout improvements needed, such as making Table 1 one column wide and figures 3, 5, and 6 two columns wide. Additionally, the comment suggests that major improvements could be achieved by straightening up the content, offering a general direction for enhancing readability. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper could be improved by adjusting the layout of tables and figures, specifically recommending that Table 1 should be one column wide and that figures 3, 5, and 6 would benefit from a two-column width. The comment also mentions that the paper was not easy to understand during the first read, implying that major improvements could be achieved by organizing the content better. However, the comment lacks specific examples or detailed reasoning to support why these layout changes would improve the paper\\'s clarity or readability. Without additional context or evidence, the claim remains somewhat verifiable, as it provides a general suggestion but lacks detailed justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the layout of the paper, suggesting that Table 1 should be one column wide and that figures 3, 5, and 6 would benefit from a two-column width. This feedback is clear and directly addresses a visual aspect of the paper that could enhance its readability. Additionally, the comment suggests that major improvements could be achieved by straightening up the content, offering a general direction for enhancing the overall organization and clarity of the paper. While the comment could be more detailed in its suggestions, it provides valuable guidance that is mostly helpful for the authors to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests repeating the Text-DPO baseline but with generated images used for DPO as images for additional image-question-answer triplets. It also implies that the additional performance benefit may come from training with perturbed images rather than the specific DPO objective. While the comment provides a specific action to repeat the baseline with perturbed images, it lacks detailed guidance on how to implement this suggestion or what specific perturbations to use. The authors are left with some direction but still need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Text-DPO baseline\" and \"perturbed images,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to repeat the baseline with generated images used for DPO as images for additional image-question-answer triplets. Additionally, it offers a hypothesis about the source of the additional performance benefit, which is the use of perturbed images rather than the specific DPO objective. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the additional performance benefit of the method may come from training with perturbed images rather than the specific DPO objective. The reviewer provides a specific suggestion to repeat the Text-DPO baseline with generated images used for DPO as images for additional image-question-answer triplets. This suggestion is based on a logical reasoning that the perturbed images might be the source of the performance improvement. However, the comment lacks specific examples or references to support the claim that training with perturbed images is the primary contributor to the additional performance. While the suggestion is clear, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion to repeat the Text-DPO baseline with generated images used for DPO as images for additional image-question-answer triplets. This is a clear and actionable piece of feedback that could help the authors better understand the source of the additional performance benefit in their method. By suggesting this experiment, the reviewer offers a concrete way for the authors to test their hypothesis and potentially improve their work. However, the comment could be more helpful if it included additional guidance on how to interpret the results or what specific aspects of the baseline to focus on. Overall, the comment is mostly helpful as it provides a clear direction for further investigation, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a final assumption in the paper regarding the difference in expertise between Alice and Bob. It notes that the assumption may not hold in real-world tasks and suggests that there could be non-linear interactions between success rate and speed-up due to varying levels of expertise. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or whether they should consider alternative assumptions. The action is implicit and vague, as the authors are left to infer that they should reconsider their assumption but without clear instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific assumption in the paper regarding the difference in expertise between Alice and Bob. It highlights a potential issue with this assumption, noting that it may not hold in real-world tasks and could lead to non-linear interactions between success rate and speed-up. However, the comment does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The authors can infer that it relates to the sections discussing human-AI collaboration or expertise, but this inference is not direct. The comment is specific in detailing the issue with the assumption, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the assumption of no difference in expertise between Alice and Bob may not hold in real-world tasks, suggesting that there could be non-linear interactions between success rate and speed-up due to varying levels of expertise. The comment provides a logical reasoning by pointing out the potential issue with the assumption, but it lacks specific examples or references to support this claim. While the reasoning is sound, the absence of concrete evidence or detailed examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical assumption in the paper regarding the difference in expertise between Alice and Bob. It highlights that this assumption may not hold in real-world tasks, where there could be non-linear interactions between success rate and speed-up due to varying levels of expertise. This feedback is valuable as it points out a potential flaw in the paper\\'s assumptions, which could impact the validity of the results. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue or explore alternative assumptions. Despite this, the comment is somewhat helpful as it directs the authors\\' attention to a significant area for improvement, prompting them to reconsider their assumptions and potentially expand their analysis. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the framework\\'s generalizability and applicability to other LLMs and datasets. It suggests that the mitigation strategies, such as sanitizing the data, may be dataset-specific and not universally applicable. However, the comment does not provide explicit guidance on how the authors might address this issue or improve the generalizability of their framework. The action is implicit and vague, as the authors are left to infer that they need to consider more generalizable approaches or provide additional examples to demonstrate broader applicability. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the generalizability and applicability of the framework, specifically mentioning the mitigation strategies like sanitizing the data. However, it does not specify which part of the paper discusses these strategies or where the authors could improve the generalizability. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding. It is specific in highlighting the issue of generalizability and the limitations of the mitigation strategies, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the mitigation strategies, such as sanitizing the data, are dataset-specific and may not be applicable more generally. This claim is somewhat verifiable as it provides a logical reasoning about the potential limitations of the mitigation strategies. However, the comment lacks specific examples or references to support the claim, which would strengthen the argument. The authors might need to consider additional evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the framework's generalizability and applicability to other LLMs and datasets. It highlights that the mitigation strategies, such as sanitizing the data, may be dataset-specific and not universally applicable. This feedback is somewhat helpful as it points out a potential weakness in the framework's broader applicability. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the generalizability of their framework. Providing more detailed advice or examples would enhance the helpfulness of the feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the paper lacks clarity in some aspects and provides a list of questions to support this claim. However, it does not specify which aspects are unclear or what specific questions need to be addressed. The comment implies that the weaknesses could be fixed before the final submission, but it does not provide explicit guidance on how to address these issues. The action is implicit and vague, as the authors are left to infer what needs to be done without clear instructions. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment indicates that the paper is not sufficiently clear in some aspects and mentions a list of questions that follow. However, it does not specify which parts of the paper are unclear or provide the list of questions, making it difficult for the authors to pinpoint the exact areas needing improvement. The comment is not grounded as it does not identify specific sections or elements of the paper, and it is also not specific because it lacks detailed guidance on what needs to be clarified. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is not sufficiently clear in some aspects, but it does not provide specific examples or details to support this claim. It mentions a list of questions but does not elaborate on them, making it difficult for the authors to understand the basis of the critique. Without specific examples or detailed reasoning, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the paper has some unclear aspects but does not specify which parts are unclear or provide detailed guidance on how to address these issues. It also mentions that the weaknesses could be fixed before the final submission, which is a vague suggestion without actionable steps. The comment lacks depth and does not offer constructive feedback or suggestions for improvement, leaving the authors without a clear understanding of what needs to be addressed. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two questions: one about the relationship between natural and synthetic audio signals and the task conditions referenced in Figure 2, and another about the task participants are performing. While the questions imply that the authors should clarify these aspects, they do not provide explicit instructions or suggestions on how to address them. The lack of concrete guidance or actionable steps makes it difficult for the authors to know exactly what changes to make. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also raises specific questions about the relationship between natural and synthetic audio signals and the task conditions, as well as the task participants are performing. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two questions seeking clarification about the relationship between natural and synthetic audio signals and the task conditions referenced in Figure 2, as well as the task participants are performing. These questions are factual and do not contain subjective claims or opinions that require verification. They are merely requests for clarification, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions about the paper: whether the natural and synthetic audio signals are related to the task conditions referenced in Figure 2, and what task participants are performing. While these questions are relevant and could help clarify aspects of the paper, they do not provide actionable feedback or suggestions for improvement. The authors are left with a clear understanding of what needs to be clarified but without guidance on how to address these issues. Therefore, the comment is somewhat helpful, as it identifies areas for clarification but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the paper did not address other problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense and facts. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to incorporate these aspects or suggestions on what specific changes should be made. As a result, the authors are left without a clear understanding of what steps to take to address the issues raised. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation in the paper by mentioning that it did not address other problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense and facts. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in detailing the areas that were not addressed, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper did not address other problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense and facts. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the context and scope of the issues not addressed. Without detailed justification or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper by noting that it does not address other problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense and facts. This feedback is somewhat helpful as it points out areas where the paper could be expanded or improved. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address these issues. Without detailed advice or examples, the authors may find it challenging to incorporate these suggestions into their work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the inclusion of papers from Arxiv in the study, suggesting that these papers may not be considered formal publications and could introduce bias. The reviewer expresses reservations about the significance of the results presented in the paper due to the inclusion of Arxiv papers. However, the comment does not provide explicit guidance on how the authors should address these concerns or suggest specific actions to take. The authors are left to infer that they should reconsider the inclusion of Arxiv papers or provide additional justification for their inclusion. While the comment highlights an important issue, it lacks concrete steps or suggestions for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the inclusion of papers from ArXiv in the study, suggesting that these papers may not be considered formal publications and could introduce bias. However, it does not specify which part of the paper discusses the venues or the inclusion of ArXiv papers, making it weakly grounded. The comment is specific in detailing the concerns about the inclusion of ArXiv papers and the potential bias they may introduce, but without explicit references to specific sections or tables, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the inclusion of papers from ArXiv introduces bias and questions the significance of the results. However, the comment lacks specific evidence or examples to support this claim. It relies on general statements about ArXiv papers not being considered formal publications and being of lower quality. Without detailed reasoning or references to substantiate the claim, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient evidence or detailed justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the inclusion of papers from ArXiv in the study, suggesting that these papers may not be considered formal publications and could introduce bias. The reviewer expresses reservations about the significance of the results presented in the paper due to the inclusion of ArXiv papers. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or provide evidence to support their claims. Without actionable feedback or detailed reasoning, the authors are left with a general concern but no clear path for improvement. Therefore, the comment is barely helpful, as it identifies a potential issue but does not provide sufficient guidance for the authors to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should focus more on the proposed problem and framework rather than devoting a lot of space to applications. However, it does not provide explicit guidance on how to achieve this shift in focus or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to rebalance the content of their paper. Without concrete instructions or examples, the authors may struggle to implement this suggestion effectively. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should focus more on the proposed problem and framework rather than spending much space on applications. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or chapters that need adjustment. Without explicit references or detailed guidance, the authors cannot confidently determine which parts of the paper need revision. Additionally, the comment lacks specificity regarding what aspects of the problem or framework should be emphasized. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should focus more on the proposed problem and framework rather than spending much space on applications. However, the comment does not provide any reasoning, examples, or evidence to support why this shift in focus is necessary or beneficial. Without additional context or justification, the authors may find it challenging to understand the basis of this suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should focus more on the proposed problem and framework, rather than devoting a significant amount of space to applications. While this feedback identifies a potential imbalance in the paper, it lacks specificity and does not provide actionable guidance on how to achieve this shift in focus. The authors are left without clear instructions on which aspects of the problem or framework to emphasize or how to rebalance the content. Without detailed suggestions or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a general assessment of the paper, stating that it is \"marginally above acceptance threshold\" and that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, it does not offer any specific guidance or suggestions for improvement. There is no explicit or implicit action for the authors to take, leaving them without a clear understanding of what changes might be necessary to enhance their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a general assessment of the paper, stating that it is \"marginally above acceptance threshold\" and that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, it does not specify which part of the paper this assessment is based on, nor does it provide detailed feedback on what aspects of the limitations or societal impact have been adequately addressed. Without specific references or detailed guidance, the authors cannot confidently determine which parts of the paper need attention or improvement. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a factual statement about the paper\\'s quality and a general observation about the authors\\' handling of limitations and societal impact. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a general assessment of the paper, stating that it is \"marginally above acceptance threshold\" and that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, the comment lacks specificity and does not offer any actionable feedback or suggestions for improvement. It does not provide details on what aspects of the paper are considered marginal or how the authors could further enhance their work. Without specific guidance or constructive feedback, the authors are left without a clear understanding of how to address the identified issues or improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the simplicity of the current dataset could be addressed by an agent translating natural language into triples and using code or search libraries. It implies that the paper may have limited research impact if future studies follow the path of the GSM8K dataset, using methods like PAL or LLMs with code interpreters. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the dataset. The action is implicit and somewhat vague, as it lacks concrete steps for the authors to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the simplicity of the current dataset and suggests that it could be solved by an agent translating natural language into <source, path, destination> triples, then using code or search libraries. It also mentions the use of patterns to generate natural language, making natural language understanding easy. However, the comment does not specify which part of the paper discusses the dataset or its simplicity, making it weakly grounded. The comment is specific in detailing the potential limitations of the dataset and the methods that could be used in future studies, such as PAL or LLMs with code interpreters. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the simplicity of the current dataset could be addressed by an agent translating natural language into <source, path, destination> triples and using code or search libraries. It suggests that this approach makes natural language understanding easy and implies that the paper may have limited research impact if future studies follow the path of the GSM8K dataset using methods like PAL or LLMs with code interpreters. However, the comment lacks specific examples or references to support the claim about the simplicity of the dataset or the potential limitations of the paper. The reasoning is somewhat vague and does not provide sufficient evidence to fully substantiate the claim, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the current dataset, suggesting that its simplicity could be addressed by an agent translating natural language into <source, path, destination> triples and using code or search libraries. It also implies that the paper may have limited research impact if future studies follow the path of the GSM8K dataset, using methods like PAL or LLMs with code interpreters. While the comment highlights a critical issue, it lacks specific suggestions or guidance on how the authors might address this limitation or enhance the research impact of their work. The feedback is somewhat helpful as it points out a potential weakness, but it does not provide actionable steps for improvement, making it incomplete. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests revising a statement regarding the maximum likelihood estimation and the limitations of the proposed measure. It implies that the authors should address the limitations of their measure, specifically regarding its theoretical connection to generalization and experimental performance compared to other measures. While the comment identifies an area for improvement, it does not provide explicit guidance on how to revise the statement or what specific aspects should be included. The action is implicit and somewhat vague, as the authors need to infer the exact changes needed to address the limitations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"25: masures 242,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the discussion of the limitations of the proposed measure, particularly regarding its theoretical connection to generalization and experimental performance compared to other measures. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the limitations of the proposed measure are not fairly discussed, specifically regarding its theoretical connection to generalization and experimental performance compared to other measures. The reviewer provides a detailed explanation of the issue, which is a clear and logical reasoning supporting the claim. However, the comment could be strengthened by referencing specific sections or studies that demonstrate the limitations, which would make the claim fully verifiable. As it stands, the comment is mostly verifiable, as it provides a solid foundation for the claim but lacks detailed references or examples to fully substantiate it.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely that the limitations of the proposed measure are not fairly discussed. It points out that the measure does not provide a stronger theoretical connection to generalization than competing measures and lacks experimental evidence to outperform other measures. This feedback is clear and actionable, as it directs the authors to revise their discussion to address these limitations. However, the comment could be more helpful if it provided specific suggestions on how to improve the discussion or what additional information should be included. Overall, the comment is mostly helpful, as it highlights a critical area for improvement and guides the authors toward enhancing their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the lack of results from fine-tuned open-source Large Language Models (LLMs) in the paper, which is considered important for a domain-specific benchmark. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to include these results. The action is implicit and vague, as the authors are left to infer that they need to include these results but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the lack of results from fine-tuned open-source Large Language Models (LLMs), which is considered important for a domain-specific benchmark. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table where these results should be included. Without explicit references or clear guidance on where the authors should address this issue, the comment lacks grounding. Additionally, it is not specific about what specific results or aspects of fine-tuned LLMs are missing. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the lack of results from fine-tuned open-source Large Language Models (LLMs) is important for a domain-specific benchmark. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these results are crucial or how they would impact the benchmark. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by noting the lack of results from fine-tuned open-source Large Language Models (LLMs), which is considered important for a domain-specific benchmark. This feedback is clear and actionable, as it directs the authors to include these results, which could enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it provided suggestions on how to incorporate these results or why they are particularly important for the domain-specific benchmark. Overall, the comment is mostly helpful as it points out a significant gap in the paper and encourages the authors to address it, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of a series of questions seeking clarification on the training process of the regression model, including details about the input, output, and parameter space for models with different feature sizes. While the questions are explicit and provide a clear direction for the authors to follow, they lack specific guidance on how to address these questions or what specific information should be included in the paper. The authors know what information is needed but may not be entirely sure of the exact format or level of detail required. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the training process of the regression model, including questions about the input, output, and parameter space for models with different feature sizes. It also asks whether the model performance was affected by the number of parameters. This level of detail allows the authors to accurately identify the parts of the paper being addressed. The comment is specific because it clearly outlines what needs to be clarified or addressed regarding the training process and model performance. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of questions seeking clarification on the training process of the regression model, including details about the input, output, and parameter space for models with different feature sizes. These questions are factual and do not contain subjective claims or opinions that require verification. They are requests for clarification or additional information, which are not considered claims. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several important questions about the regression model, including how it is trained, the input and output, and how the parameter space differs for models with different feature sizes. It also inquires about the impact of the number of parameters on model performance. These questions are clear and actionable, providing the authors with specific areas to address in their draft. By answering these questions, the authors can enhance the clarity and comprehensiveness of their paper, making it more understandable and valuable for readers. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of how to address these questions effectively. Overall, the comment is mostly helpful as it identifies key areas for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies an issue with the operator in equation 6 and related equations, suggesting that it should be the multiplication of the underlying vector space rather than \\\\cross_g. This provides a clear and direct action for the authors to take, which is to correct the operator in the equations. The feedback is specific and concrete, leaving no ambiguity about what needs to be changed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"eq 6 and related equations,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the operator after w_i, suggesting that it should be the multiplication of the underlying vector space rather than \\\\cross_g. This provides clear guidance on what needs to be corrected. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the operator after w_i should be the multiplication of the underlying vector space rather than \\\\cross_g. The reviewer provides a logical explanation by stating that \\\\cross_g is an operator between a scalar and a tensor, not just between two scalars. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation in equation 6 and related equations, suggesting that the operator after w_i should be the multiplication of the underlying vector space rather than \\\\cross_g. This feedback is clear and actionable, as it provides a precise correction that the authors can make to improve the accuracy and clarity of their mathematical expressions. By addressing this issue, the authors can enhance the rigor and readability of their work. Therefore, the comment is rated as highly helpful, as it offers a direct and constructive suggestion for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to add more ablation experiments to demonstrate the effectiveness of the proposed model. It specifies the types of experiments that should be conducted, such as exploring the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. This provides clear and concrete guidance on what the authors need to do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding more ablation experiments to demonstrate the effectiveness of the proposed model, specifically mentioning the role of different updating methods and reweighting after selection. However, it does not specify which part of the paper this suggestion should be implemented in, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine where to make these additions. The comment is specific in detailing what needs to be addressed, namely the addition of ablation experiments to explore the effectiveness of the model. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding more ablation experiments to demonstrate the effectiveness of the proposed model. It provides specific examples of what these experiments should include, such as exploring the role of different updating methods and reweighting after selection. This guidance is clear and actionable, offering a concrete path for the authors to enhance their work. However, the comment does not include any supporting evidence or references to justify the necessity of these experiments, which would strengthen the argument. Therefore, the claim is mostly verifiable, as it provides a clear direction but lacks detailed justification or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting the addition of more ablation experiments to demonstrate the effectiveness of the proposed model. It identifies particular areas that need exploration, such as the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. This feedback is clear and constructive, offering the authors a concrete way to enhance the comprehensiveness and robustness of their study. By following this suggestion, the authors can gain a deeper understanding of their model\\'s components and their impact, which can lead to a more robust and convincing presentation of their results. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experimental results could be improved by using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. It also mentions the possibility of considering adaptive mechanisms like those in Phan et al. (2017, 2019, 2020) as baseline approaches for comparison. While the comment implies that the authors should consider using more complex datasets and adaptive mechanisms, it does not provide explicit instructions on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experimental results could be improved by using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. It also mentions the possibility of considering adaptive mechanisms like those in Phan et al. (2017, 2019, 2020) as baseline approaches for comparison. However, the comment does not specify which part of the paper discusses the experimental results or where these suggestions should be implemented. The authors can infer that it relates to the experimental sections, but the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting the use of more complex datasets and adaptive mechanisms, but it does not provide detailed guidance on how to implement these suggestions. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experimental results could be improved by using more complex datasets and learning tasks. It provides specific examples of datasets with limited dimensions and mentions the possibility of using image datasets with thousands of dimensions and deep learning tasks. Additionally, it references adaptive mechanisms like those in Phan et al. (2017, 2019, 2020) as potential baseline approaches for comparison. This provides a clear rationale for the suggestion, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to specific studies that demonstrate the effectiveness of these adaptive mechanisms. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the experimental results by suggesting the use of more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. It also mentions the possibility of considering adaptive mechanisms like those in Phan et al. (2017, 2019, 2020) as baseline approaches for comparison. This feedback is clear and actionable, as it provides specific suggestions for enhancing the experimental rigor and depth of the paper. However, the comment could be more helpful if it included examples of how these complex datasets or adaptive mechanisms could be integrated into the existing framework or if it offered guidance on how to adapt the current approach to accommodate these suggestions. Overall, the comment is mostly helpful as it directs the authors toward meaningful improvements, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the experiment results, specifically questioning the effectiveness of PRESENCE and the justification for the two-stage pre-training process. It highlights the relationship between temperature \u03c4 and downstream performance in Figure 5 and suggests that using a positive or negative \u03c4 could yield improvement over no reweighting. Additionally, it points out that the results from Table 4 do not demonstrate the advantage of using PRESENCE. While the comment identifies areas of concern, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The authors are left to infer that they need to provide more convincing evidence or clarify the benefits of PRESENCE. Therefore, this comment is somewhat actionable, as it highlights areas for improvement but lacks specific guidance on how to address them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5\" and \"Table 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the experiment results, questioning the effectiveness of PRESENCE and the justification for the two-stage pre-training process. The comment provides specific examples and questions regarding the relationship between temperature \u03c4 and downstream performance, as well as the results from Table 4. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the experiment results, specifically questioning the effectiveness of PRESENCE and the justification for the two-stage pre-training process. It points out that the relationship between temperature \u03c4 and downstream performance in Figure 5 does not seem to justify the two-stage pre-training, and that using a positive or negative \u03c4 could yield improvement over no reweighting. Additionally, it notes that the results from Table 4 do not show the advantage of using PRESENCE. While the comment provides some reasoning and observations, it lacks specific examples or references to support the claims fully. The reasoning is somewhat verifiable, as it highlights potential issues with the experiment results, but it could be strengthened with more detailed evidence or comparisons. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises concerns about the experiment results, specifically questioning the effectiveness of PRESENCE and the justification for the two-stage pre-training process. It points out that the relationship between temperature \u03c4 and downstream performance in Figure 5 does not seem to justify the two-stage pre-training, and suggests that using a positive or negative \u03c4 could yield improvement over no reweighting. Additionally, it notes that the results from Table 4 do not show the advantage of using PRESENCE. This feedback is somewhat helpful as it identifies specific areas where the results may not be convincing and suggests potential avenues for improvement. However, it lacks detailed guidance on how the authors might address these concerns or provide more convincing evidence. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the results presented in Table 2, noting that the performance for k=1 is already better than the baselines. It suggests that this might indicate a performance gain for a reason unrelated to the application of Eq.10. However, the comment does not provide explicit guidance or suggestions on how the authors should address this observation or what specific actions they should take to improve their draft. The feedback implies that the authors should consider alternative explanations for the performance gain, but it lacks concrete steps or recommendations for further investigation or improvement. As a result, the comment is vague and does not provide actionable advice, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the results, noting that the performance for k=1 is already better than the baselines, and suggests that this might indicate a performance gain for a reason unrelated to the application of Eq.10. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results in Table 2 for k=1 are already better than the baselines, suggesting that the performance gain might be due to a reason other than the application of Eq.10. However, the comment lacks specific reasoning or evidence to support this claim, such as comparisons with other methods or detailed analysis of the results. Without additional context or examples, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the results presented in Table 2, noting that the performance for k=1 is already better than the baselines. It suggests that this might indicate a performance gain for a reason unrelated to the application of Eq.10. This observation could prompt the authors to reconsider their interpretation of the results and explore alternative explanations. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional analysis could be conducted to clarify the findings. While it highlights a potential area for improvement, the feedback is incomplete and does not provide actionable steps, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of solid grounding in the proposed method, specifically questioning the choice of mixed-integer programming and its advantages over alternative approaches. However, it does not provide explicit guidance or suggestions on how the authors might address these concerns. The comment implies that the authors should justify their choice and compare it with other methods, but it does not specify what kind of justification or comparison is needed. As a result, the action is implicit and vague, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of solid grounding in the proposed method, specifically questioning the choice of mixed-integer programming and its advantages over alternative approaches. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure where the method is discussed. This makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in its critique of the method\\'s justification and comparison to alternatives, but it lacks grounding, as it does not direct the authors to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method lacks solid grounding and questions the choice of mixed-integer programming without providing specific examples or references to support this claim. The comment lacks detailed reasoning or evidence to substantiate the assertion that the choice of mixed-integer programming is not fully justified or that its advantages over alternative approaches are unclear. Without additional context or examples, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a significant weakness in the paper, specifically the lack of solid grounding for the proposed method, particularly regarding the choice of mixed-integer programming. It highlights that the advantages of this choice over alternative approaches are unclear, which is a critical issue that needs to be addressed. However, the comment does not provide specific suggestions or guidance on how the authors might justify their choice or compare it with other methods. While it points out a key area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it directs the authors to a critical area but does not fully support them in making improvements.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two separate issues: the notation in Equation 1 being confusing and the missing reference to Pedersen et al 2007 in the reference section. The first issue is explicit and clear, as it directly points out the confusion in the notation and suggests a specific change. The second issue is also explicit, as it clearly states that the reference is missing and should be included. Both parts of the comment provide concrete actions for the authors to take, making the feedback highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 1\" and \"Line 361,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, noting the confusion in the notation and the missing reference to Pedersen et al 2007. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two separate claims: the notation in Equation 1 is confusing and the reference to Pedersen et al 2007 is missing. The first claim is supported by a specific example of the notation issue, providing clear evidence of the confusion. The second claim is also supported by a specific reference to the missing citation, which allows the authors to easily verify and address the issue. Both claims are well-supported and provide clear guidance for improvement, making them fully verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies two specific issues that need attention. First, it points out a notation confusion in Equation 1, suggesting that \"c\" is used instead of \"o,\" which could lead to confusion in the reader\\'s understanding. Second, it notes the absence of a reference to Pedersen et al 2007 in the reference section. Both issues are clear and actionable, providing the authors with direct feedback on how to improve the clarity and accuracy of their work. By addressing these points, the authors can enhance the readability and credibility of their paper. Therefore, the comment is mostly helpful, as it offers specific guidance for improvement but could be more comprehensive by suggesting how to resolve the notation issue or providing additional context for the missing reference.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the second contribution of the paper, combining SSMs with Attention, is not new and has been proposed before in MEGA and Block-state Transformer. It suggests that the similarities and differences between S++ and this work should be discussed thoroughly and ablated. While the comment implies that the authors should address this issue, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss and ablate the similarities and differences. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"second contribution\" of the paper, which is the proposal to combine SSMs with Attention, and references specific works like MEGA and Block-state Transformer. It also mentions Figure 5, allowing the authors to accurately identify the part of the paper being addressed. The comment is specific because it points out that this contribution is not new and suggests that the similarities and differences between S++ and the mentioned works should be discussed and ablated. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the second contribution of the paper, combining SSMs with Attention, is not new and has been proposed before in MEGA and Block-state Transformer. The reviewer supports this claim by referencing specific works, including a citation to MEGA and a link to Block-state Transformer. This provides a clear and robust basis for the claim, making it fully verifiable. The comment also suggests that the similarities and differences between S++ and this work should be discussed and ablated, which further supports the claim. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a potential issue with the originality of the paper\\'s second contribution, which is the proposal to combine SSMs with Attention. It points out that this idea has been previously proposed in MEGA and Block-state Transformer, and that the architecture in Figure 5 bears similarities to the proposed architecture in Mega. The comment suggests that the authors should discuss and ablate the similarities and differences between S++ and this work. This feedback is clear and actionable, as it directs the authors to address a specific concern about the novelty of their contribution and to provide a more thorough comparison with existing work. However, the comment could be more helpful if it provided specific guidance on how to conduct the ablation study or discuss the differences. Overall, the comment is mostly helpful, as it highlights an important area for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the selection of environments for reporting results on knowledge transfer in section 4.3. While it implies that the authors should provide a justification or explanation for this choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to address this issue but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the rationale behind reporting results on knowledge transfer in only a few select environments, prompting the authors to provide a justification or explanation for this choice. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification on the rationale behind reporting results on knowledge transfer in only a few select environments. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the selection of environments for reporting results on knowledge transfer in section 4.3. While it does not provide a direct suggestion for improvement, it prompts the authors to consider the rationale behind their choice and potentially address any limitations or biases in their methodology. This feedback encourages the authors to reflect on their experimental design and provide a clearer justification for their approach, which could lead to a more robust and transparent presentation of their results. However, the comment could be more helpful if it offered specific guidance or suggestions on how to address this issue. Overall, the comment is somewhat helpful as it identifies an area for consideration, but it lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the lack of specific ablation experiments, suggesting that the performance improvement could be attributed to pre-trained weights rather than the method proposed in the manuscript. It also mentions that the absence of detailed ablation comparisons may lead to confusion. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it, such as suggesting specific experiments or comparisons to include. The action is implicit and somewhat vague, as the authors can infer that they need to conduct more detailed ablation experiments but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of specific ablation experiments, which could be attributed to pre-trained weights rather than the method proposed in the manuscript. It also mentions the absence of detailed ablation comparisons, which may lead to confusion. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue of lacking ablation experiments and their potential impact on the interpretation of results. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lack of specific ablation experiments makes it difficult to determine whether the performance improvement is due to the proposed method or the pre-trained weights. This claim is somewhat verifiable as it logically reasons that without detailed ablation comparisons, it is challenging to attribute the results to the method or the pre-trained weights. However, the comment lacks specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides a logical basis for the claim but requires more detailed evidence to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant weakness in the paper, specifically the lack of specific ablation experiments. It suggests that the performance improvement could be attributed to pre-trained weights rather than the method proposed in the manuscript, which may lead to confusion. This feedback is clear and actionable, as it directs the authors to conduct more detailed ablation comparisons to clarify the contribution of their method. However, the comment could be more helpful if it provided specific suggestions on how to design these experiments or what aspects to focus on. Overall, the comment is mostly helpful as it highlights a critical area for improvement and guides the authors toward enhancing the clarity and robustness of their results.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific limitation in the lemmatizer, noting that it strips suffixes from words that are already lemmas but end with a suffix substring. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to improve the lemmatizer or suggestions for testing or validation to ensure it handles evolving vocabularies effectively. Without actionable steps or suggestions, the authors are left without a clear path forward to address this issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific limitation in the lemmatizer, noting that it strips suffixes from words that are already lemmas but end with a suffix substring. This issue is related to the lemmatizer\\'s functionality, which is a specific part of the paper. However, the comment does not specify which section or part of the paper discusses the lemmatizer, making it weakly grounded. The comment is specific in detailing the issue with the lemmatizer, but without explicit references to the paper, the authors may find it challenging to pinpoint the exact location. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the described limitation in the lemmatizer is a major concern for real-world texts with evolving vocabularies. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the significance of this limitation or how it affects real-world applications. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the lemmatizer, noting that it strips suffixes from words that are already lemmas but end with a suffix substring. This is a critical issue, especially for real-world texts with evolving vocabularies. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or improve the lemmatizer. Without actionable feedback or potential solutions, the authors are left without a clear path to resolve the issue. Therefore, the comment is somewhat helpful as it highlights a significant concern but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the comparison in Table 2, suggesting that the use of pre-trained DGCNN for semantic segmentation makes the comparison of segmentation metrics less meaningful. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should reconsider their comparison methodology, but it lacks concrete details on what changes should be made or how to improve the comparison. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparison of segmentation metrics, explaining that the use of pre-trained DGCNN makes the comparison less meaningful. The comment provides a clear critique of the methodology used in the table, specifying what aspect needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison of segmentation metrics in Table 2 is not meaningful because it involves using pre-trained DGCNN for semantic segmentation. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the comparison in Table 2, where pre-trained DGCNN is used for semantic segmentation across different completion methods. It points out that this setup makes the comparison of segmentation metrics less meaningful, as it only indicates that the segmentation of those methods combined with DGCNN is worse than the proposed method. This feedback is somewhat helpful as it highlights a potential flaw in the experimental design and suggests that the authors should reconsider their comparison methodology. However, the comment lacks specific suggestions or guidance on how to improve the comparison or what alternative approaches could be taken. Therefore, while it provides some insight, it is not fully actionable, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it is challenging to obtain rules in real-world applications and implies that statistical rules learned from data might be a feasible alternative. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue or what specific steps to consider in their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the difficulty of obtaining rules in real-world applications and suggests that statistical rules learned from data may be feasible. However, it does not specify which part of the paper this issue pertains to, nor does it provide specific guidance on how to address the challenge. The authors cannot confidently determine which section of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not detail what needs to be addressed or how the authors might improve their approach. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that it is difficult to obtain rules in real-world applications and implies that statistical rules learned from data may be a feasible alternative. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the difficulty of obtaining rules in real-world applications and suggests that statistical rules learned from data may be a feasible alternative. However, it does not provide any specific guidance or suggestions on how the authors might incorporate this idea into their work or address the challenges of obtaining rules in real-world applications. The comment lacks depth and actionable feedback, leaving the authors without a clear understanding of how to improve their draft. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a comparison with dynamic sparse training-based and other sparsity-based methods. While the comment implies that this comparison is missing, it does not explicitly instruct the authors to add it. The action is implicit and somewhat vague, as the authors need to infer that they should include this comparison and figure out how to do it. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that a comparison with dynamic sparse training-based and other sparsity-based methods is missing. However, it does not specify which part of the paper this comparison should be included in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its suggestion for additional comparisons but lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a comparison with dynamic sparse training-based and other sparsity-based methods is missing. However, it does not provide any reasoning, examples, or references to support why this comparison is necessary or how it would enhance the paper. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper by suggesting that a comparison with dynamic sparse training-based and other sparsity-based methods is missing. This feedback is somewhat helpful as it points out an area where the paper could be strengthened by including additional comparisons. However, the comment lacks specificity and does not provide guidance on how to conduct this comparison or which specific methods should be included. While it highlights an area for improvement, it does not offer detailed actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the reasoning provided in the paper regarding the intractability of $p_\u03b8(y|x)$ in a latent variable model. It suggests that the intractability of $p_\u03b8(y|x)$ does not necessarily follow from the intractability of $p_\u03b8(z|x)$, as both the posterior and likelihood can be tractable while $p_\u03b8(y|x)$ remains intractable. The comment provides an example of a Bernoulli likelihood with a Gaussian posterior to illustrate this point. While the comment highlights a potential issue with the reasoning in the paper, it does not explicitly instruct the authors to revise their argument or provide specific guidance on how to address the concern. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their explanation of intractability. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly references a specific statement from the paper regarding the intractability of $p_\u03b8(y|x)$ in a latent variable model. It provides a clear and specific critique of the reasoning presented in the paper, questioning the assumption that the intractability of $p_\u03b8(y|x)$ is solely due to the intractability of $p_\u03b8(z|x)$. The comment offers an example to illustrate an alternative scenario where both the posterior and likelihood are tractable but $p_\u03b8(y|x)$ remains intractable. This level of detail allows the authors to accurately identify the part of the paper being addressed and understand what needs to be revised. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the reasoning provided in the paper regarding the intractability of $p_\u03b8(y|x)$ in a latent variable model. It suggests that the intractability of $p_\u03b8(y|x)$ does not necessarily follow from the intractability of $p_\u03b8(z|x)$, as both the posterior and likelihood can be tractable while $p_\u03b8(y|x)$ remains intractable. The comment provides an example of a Bernoulli likelihood with a Gaussian posterior to support this claim. This example offers a logical and specific counterexample to the original reasoning, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to similar cases in the literature. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a thoughtful critique of the reasoning presented in the paper regarding the intractability of $p_\u03b8(y|x)$ in a latent variable model. It challenges the assumption that the intractability of $p_\u03b8(y|x)$ is solely due to the intractability of $p_\u03b8(z|x)$, suggesting that both the posterior and likelihood can be tractable while $p_\u03b8(y|x)$ remains intractable. The comment offers a specific example, such as a Bernoulli likelihood with a Gaussian posterior, to illustrate this point. This feedback is valuable as it prompts the authors to reconsider their explanation and potentially revise their argument to provide a more comprehensive understanding of the intractability issue. However, the comment could be more helpful if it offered suggestions on how to address this critique or provided additional context for the authors to improve their draft. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the reproducibility of the study due to inaccessible collected datasets outside of the associated groups. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the datasets more accessible or suggestions for alternative methods to ensure reproducibility. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of reproducibility due to inaccessible collected datasets outside of the associated groups. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity as it does not provide details on how to make the datasets more accessible or suggestions for alternative methods to ensure reproducibility. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the study is \"irreproducible\" due to inaccessible collected datasets outside of the associated groups. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the reproducibility of the study due to inaccessible collected datasets outside of the associated groups. This is a critical concern that can impact the validity and reliability of the research findings. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue, such as by making the datasets publicly available or providing alternative methods for accessing them. Without actionable feedback, the authors are left without a clear path for improvement. Therefore, the comment is barely helpful, as it highlights a critical issue but does not offer any constructive advice for resolution.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the presence of a missing equation before a specific reference to \"where p is the firing rate\" in Section 3.4.1. While it implies that the authors should check for the missing equation, the comment does not explicitly instruct them to add it or provide guidance on how to identify or address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should verify the presence of the equation. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"sec 3.4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the presence of a missing equation before a specific reference to \"where p is the firing rate.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question asking about the presence of a missing equation in Section 3.4.1. It does not contain any claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the presence of a missing equation in Section 3.4.1, which is a clear and actionable point for the authors to address. By pointing out this potential omission, the reviewer provides a direct way for the authors to improve their draft by ensuring that all necessary equations are included. However, the comment could be more helpful if it provided additional context or suggested why this equation might be important. Despite this, the feedback is clear and actionable, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests conducting experiments to evaluate the effects of the sentiment word position detection module and the predicted sentiment word candidates. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be done to improve the draft. The comment provides concrete guidance on how to implement this action, making it highly actionable. Therefore, the comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the lack of evaluation of sentiment word detection and correction, which is a specific aspect of the paper. It suggests conducting experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. This provides clear guidance on what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper this issue pertains to, leaving the authors to infer that it relates to the methodology or results sections. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks evaluation of sentiment word detection and correction, which is a critical aspect of the SWRM. The reviewer suggests conducting experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. However, the comment does not provide specific examples or references to support the claim that this evaluation is necessary or how it would impact the paper. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the importance of this evaluation themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the evaluation of the paper, specifically the lack of assessment of sentiment word detection and correction. It highlights the importance of these aspects, as they are key ideas in the SWRM. The comment provides a clear and actionable suggestion to conduct experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. This feedback is valuable as it directs the authors to a specific area that needs further exploration and validation, potentially leading to a more comprehensive understanding and improvement of their work. However, the comment could be more helpful if it offered additional guidance on how to design these experiments or what specific metrics to use for evaluation. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the results of KMLM-XLM-R_{large} in the result tables and suggests that the authors did not report all the performance of KMLM-large without logical reasoning. While the comment implies that the authors should provide more detailed results or explain the reasoning behind their reporting, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"all the result tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the results of KMLM-XLM-R_{large} and suggesting that the authors did not report all the performance of KMLM-large without logical reasoning. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the absence of results for KMLM-XLM-R_{large} in the result tables and suggests that the authors did not report all the performance of KMLM-large without logical reasoning. However, the comment does not provide specific examples or detailed reasoning to support the claim that the results are missing or that the reasoning is lacking. This makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a specific concern about the results presented in the paper, questioning the absence of results for KMLM-XLM-R_{large} in the result tables. It also suggests that the authors did not report all the performance of KMLM-large without providing logical reasoning. This feedback is clear and actionable, as it directs the authors to address a potential gap in their reporting and to provide a logical explanation for their choices. However, the comment could be more helpful if it offered suggestions on how to present the missing results or how to improve the logical reasoning. Overall, the comment is mostly helpful as it identifies a specific area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the results where many in-context learning baselines, such as static few-shot and chain-of-thought, underperform the backbone in several items. It suggests that this could be due to the large variance of the results or the uncareful design of the baselines. The comment implies that the authors should provide more explanations to support the reliability of their claims. While the action is implicit, it is concrete in suggesting that the authors need to address the discrepancy and provide additional explanations. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the performance of in-context learning baselines, such as static few-shot and chain-of-thought, which underperform the backbone in many items. It suggests that this could be due to the large variance of the results or the uncareful design of the baselines. The comment implies that the authors should provide more explanations to support the reliability of their claims. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the results or discussion sections where these baselines are compared. The comment is specific in detailing what needs to be addressed, namely the need for more explanations regarding the underperformance of these baselines. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that many in-context learning baselines, such as static few-shot and chain-of-thought, underperform the backbone in many items, suggesting that this could be due to the large variance of the results or the uncareful design of the baselines. The comment implies that more explanations are needed to support the reliability of the claims. While the reviewer provides a logical explanation for the underperformance, the comment lacks specific examples or references to substantiate the claim further. This makes the claim somewhat verifiable, as it requires additional evidence or detailed reasoning to fully support the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results, noting that many in-context learning baselines, such as static few-shot and chain-of-thought, underperform the backbone in several items. It suggests that this discrepancy could be due to the large variance of the results or the uncareful design of the baselines. The comment provides a clear direction for the authors to address this issue by requesting more explanations to support the reliability of their claims. This feedback is actionable and provides a specific area for improvement, making it mostly helpful. However, it could be more helpful if it offered suggestions on how to analyze or address the variance or baseline design issues. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the key innovation driving the improvements in GFNSeqEditor. It suggests that the paper should better articulate the novel techniques or insights that lead to these improvements, which would enhance the reader\\'s understanding of the method\\'s unique value. While the comment implies that the authors should provide more detailed explanations, it does not specify exactly how to articulate these improvements or what specific aspects need clarification. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations but may not know exactly how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the ambiguity in the key innovation of GFNSeqEditor, specifically the claim that it can produce novel sequences with improved properties. It suggests that the paper should better articulate the novel techniques or insights that lead to these improvements. However, it does not specify which part of the paper this issue is most relevant to, such as a particular section or figure. While the authors can infer that it relates to the introduction or results sections, the comment lacks full grounding. It is specific in detailing what needs to be addressed, namely the need for clearer articulation of the innovation. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks clarity regarding the key innovation driving the improvements in GFNSeqEditor. It suggests that the paper should better articulate the novel techniques or insights leading to these improvements. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the exact areas where clarification is needed, which could be challenging without additional guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the paper's clarity regarding the key innovation of GFNSeqEditor. It points out that the claim of producing novel sequences with improved properties lacks clarity about the specific techniques or insights that drive these improvements. The comment provides a clear and actionable suggestion for the authors to better articulate the novel aspects of their method, which would enhance the reader's understanding of its unique value. By addressing this feedback, the authors can significantly improve the clarity and impact of their paper. Therefore, the comment is rated as highly helpful, aligning with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors need to demonstrate the faithfulness of their proposed approach and address the claim that it is less at risk to biases compared to other methods. The reviewer explicitly recommends conducting \"at least a simple experiment\" to support this claim. This feedback is clear and provides a concrete action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the faithfulness of the proposed approach and suggests that the authors need to demonstrate it through a simple experiment. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting a way to address the issue, namely by conducting an experiment to demonstrate the faithfulness of the approach. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors need to demonstrate the faithfulness of their proposed approach, specifically addressing the claim that it is less at risk to biases compared to other methods. The reviewer recommends conducting \"at least a simple experiment\" to support this claim. However, the comment lacks specific details or references to existing literature that could substantiate the claim or provide a basis for the suggested experiment. This makes the claim somewhat verifiable, as it provides a direction for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by questioning the faithfulness of the proposed approach and the claim that it is less susceptible to biases compared to other methods. It suggests that the authors should demonstrate this claim through a simple experiment, providing a clear and actionable suggestion for enhancing the paper. However, the comment could be more helpful if it offered additional guidance on how to design the experiment or what specific aspects of the approach should be tested. Despite this, the feedback is mostly helpful as it directs the authors to a critical area that needs further validation, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the manuscript for proposing a method that can only operate with state-action spaces, which is not suitable for most real-world applications that are continuous in nature. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggest alternative approaches that could be more applicable to real-world scenarios. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the manuscript for proposing a method that can only operate with state-action spaces, which is not suitable for most real-world applications that are continuous in nature. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure. This makes it difficult for the authors to identify the exact part of the paper that needs revision. Additionally, the comment lacks specificity regarding what aspects of the method are problematic or how it could be improved to better address continuous applications. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the manuscript\\'s proposed method is not suitable for most real-world applications because it can only operate with state-action spaces, which are difficult to discretize or solve in continuous scenarios. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a limitation in the manuscript by noting that the proposed method can only operate with state-action spaces, which is not suitable for most real-world applications that are continuous in nature. This critique highlights a potential weakness in the applicability of the proposed method, which could be an important consideration for the authors. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or improve the applicability of their method. While it identifies a relevant issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the experiment results are not competitive with state-of-the-art (SOTA) methods, and the presentation of the main results in Table 1 is unclear due to the inclusion of different backbones compared to prior methods. The reviewer suggests moving the baseline to the ablation study and only showing the proposed method. While the comment identifies specific areas for improvement, it does not provide detailed guidance on how to address the lack of competitiveness or how to clarify the presentation of the results. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to improve their results and presentation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the experiment results, noting that they are not competitive with state-of-the-art methods and that the presentation of the main results is unclear due to the inclusion of different backbones compared to prior methods. Additionally, the comment suggests moving the baseline to the ablation study and only showing the proposed method. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiment results are not competitive with state-of-the-art (SOTA) methods and that the presentation of the main results in Table 1 is unclear due to the inclusion of different backbones compared to prior methods. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The suggestion to move the baseline to the ablation study and only show the proposed method is a logical recommendation but lacks detailed reasoning or evidence to substantiate the claim. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks sufficient detail to fully support the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper: the experiment results are not competitive with state-of-the-art methods, and the presentation of the main results in Table 1 is unclear due to the inclusion of different backbones compared to prior methods. It provides a clear suggestion to move the baseline to the ablation study and only show the proposed method, which is a constructive and actionable piece of feedback. However, the comment could be more helpful if it offered additional guidance on how to improve the competitiveness of the results or provided specific examples of how to clarify the presentation of the results. Overall, the comment is mostly helpful as it directs the authors to focus on improving the presentation and competitiveness of their results, but it could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the manuscript could be improved by providing a clearer delineation of the copyright scenario. It explicitly recommends specifying whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. This feedback is clear and provides a concrete action for the authors to take, making it highly actionable. The authors know exactly what needs to be done to enhance their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically regarding whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion for improvement, but without clear grounding, it is challenging for the authors to know where to make the changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically regarding whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the manuscript, namely the need for a clearer delineation of the copyright scenario. It suggests that the authors should specify whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. This feedback is clear and actionable, providing the authors with a concrete direction to enhance their draft. However, the comment could be more helpful if it offered additional guidance on how to address this issue or provided examples of how other papers have handled similar scenarios. Overall, the comment is mostly helpful as it directs the authors to a specific area that requires clarification, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of theoretical justification or intuitive explanation for why the low-rank adapter acquires domain-agnostic information, while the high-rank adapter collects domain-specific knowledge. However, it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment implies that the authors should provide a theoretical justification or explanation, but it does not specify what kind of explanation or how it should be presented. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the theoretical justification or intuitive explanation for the behavior of the low-rank and high-rank adapters in acquiring domain-agnostic and domain-specific knowledge, respectively. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, namely a theoretical justification or intuitive explanation for the observed behavior. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no theoretical justification or intuitive explanation for why the low-rank adapter acquires domain-agnostic information, while the high-rank adapter collects domain-specific knowledge. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of theoretical justification or intuitive explanation for why the low-rank adapter acquires domain-agnostic information, while the high-rank adapter collects domain-specific knowledge. This is a critical observation that highlights a potential weakness in the paper\\'s theoretical foundation. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what kind of theoretical justification or explanation would be appropriate. While it points out an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it directs the authors\\' attention to a critical area but does not fully support them in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the statement regarding local explanations, specifically asking why the local models will only be nontrivial if the data point is near a decision boundary. It also suggests an alternative approach by proposing to measure differences in probabilities. While the comment implies that the authors should provide a justification for their statement or consider an alternative approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the question or consider the alternative approach. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 154,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reasoning behind the statement about local explanations and suggests an alternative approach by proposing to measure differences in probabilities. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the statement about local explanations, specifically asking for a justification of why local models are only nontrivial near decision boundaries. It also suggests an alternative approach by proposing to measure differences in probabilities. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or the suggested alternative. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the statement regarding local explanations, specifically asking for a justification of why local models are only nontrivial near decision boundaries. It also suggests an alternative approach by proposing to measure differences in probabilities, such as \"if feature 1 were higher, the model would be less confident in class y.\" This feedback is somewhat helpful as it prompts the authors to clarify their reasoning and consider an alternative perspective on local explanations. However, it could be more helpful if it provided additional context or examples to support the suggested alternative approach. Overall, the comment offers a direction for improvement but lacks depth, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the experiments, noting that results are only reported on ImageNet and suggesting that results on classic datasets like CIFAR-10 and CIFAR-100 should also be included. This feedback is explicit, as it clearly states what needs to be added to the experiments. However, it lacks concrete guidance on how to implement this suggestion, such as which specific metrics or analyses should be conducted on these additional datasets. While the action is clear, the lack of detailed instructions makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments and the specific datasets (ImageNet, CIFAR-10, and CIFAR-100) that are being addressed. This allows the authors to accurately identify the part of the paper being discussed. The comment is also specific because it clearly specifies what is missing from the experiments, namely results on classic datasets like CIFAR-10 and CIFAR-100. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments only report results on ImageNet and suggests that results on classic datasets like CIFAR-10 and CIFAR-100 should also be included. This claim is somewhat verifiable as it highlights a potential limitation in the experimental scope. However, the comment lacks specific reasoning or examples to fully substantiate the claim, such as why results on these additional datasets are important or how they might impact the overall findings. Providing more detailed justification or references to similar studies would strengthen the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the experimental setup, noting that the results are only reported on ImageNet and suggesting that results on classic datasets like CIFAR-10 and CIFAR-100 should also be included. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to enhance the comprehensiveness and robustness of their experiments. By including results on these additional datasets, the authors can provide a more comprehensive evaluation of their method and its applicability. However, the comment could be more helpful if it suggested specific metrics or analyses to conduct on these datasets. Overall, the comment is mostly helpful as it directs the authors to a meaningful improvement in their experimental setup.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a confusion in the DinoSR part of Figure 1, noting that the softmax layer is not clearly shown, despite the text description indicating it is not included in the encoder. The comment contrasts this with the clarity of the figure in the original DinoSR paper. While the comment identifies a specific issue with the figure, it does not provide explicit guidance on how to address this confusion or suggest improvements. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the figure, but they are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"the DinoSR part,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely the confusion caused by the absence of the softmax layer, which is not included in the encoder according to the text description. The comment contrasts this with the clarity of the figure in the original DinoSR paper, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the DinoSR part in Figure 1 is confusing due to the absence of the softmax layer, which is not included in the encoder according to the text description. The comment contrasts this with the clarity of the figure in the original DinoSR paper. While the comment highlights a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors might need to clarify the figure or provide additional context to understand the critique fully. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 1, noting that the DinoSR part is confusing due to the absence of the softmax layer, which is not included in the encoder according to the text description. This observation is valuable as it points out a potential source of confusion in the figure. However, the comment could be more helpful if it provided suggestions on how to clarify the figure or offered examples of how the original DinoSR paper presents this information more clearly. While it highlights a weakness, the feedback lacks actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should review more related work on causal inference and discuss additional works related to the paper. While it implies that the authors should expand their literature review, it does not provide specific guidance on which works to include or how to integrate them into the paper. The action is implicit and somewhat vague, as the authors are left to infer which works are relevant and how to incorporate them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more related work on causal inference should be reviewed and discussed, specifically mentioning references [1], [2], and [3]. However, it does not specify which part of the paper this suggestion pertains to, such as the literature review section or where these references should be integrated. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in suggesting the inclusion of additional related work, but without clear grounding, it is weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more related work on causal inference should be reviewed and discussed, specifically mentioning references [1], [2], and [3]. However, the comment does not provide any reasoning or justification for why these specific works are relevant or how they relate to the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of these references or how to incorporate them into their work. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should review and discuss more related work on causal inference, specifically mentioning references [1], [2], and [3]. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to integrate these works into the paper or why they are relevant. The comment does not offer actionable suggestions or detailed advice on how to enhance the literature review or the discussion of causal inference. As a result, the comment is somewhat helpful, as it points out a gap but does not fully support the authors in addressing it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that sections 3.1 and 3.2 could have been avoided if the authors had used the LLM2Vec encoder, which is already cited in the paper. It implies that the authors should consider using this encoder and validate their decision with ablation studies. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to conduct the ablation studies or explain how to implement the suggested change. The action is mostly implicit, as the authors need to infer that they should conduct ablation studies to validate their decision. However, the suggestion is concrete, as it specifies the use of the LLM2Vec encoder and the need for validation. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with these sections, namely that they could have been avoided by using the LLM2Vec encoder, which is already cited in the paper. The comment further suggests that the reasoning for not adopting this approach remains unclear and recommends validating the decision with ablation studies. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that sections 3.1 and 3.2 could have been avoided by using the LLM2Vec encoder, which is already cited in the paper. The reviewer suggests that the reasoning for not adopting this approach is unclear and recommends validating the decision with ablation studies. While the comment provides a logical suggestion for improvement, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors might need to infer the exact issues with the current approach and how the LLM2Vec encoder could have been beneficial. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential improvement in the paper by suggesting that sections 3.1 and 3.2 could have been avoided if the authors had used the LLM2Vec encoder, which is already cited in the paper. It points out that the reasoning for not adopting this approach is unclear and recommends validating the decision with ablation studies. This feedback is clear and actionable, as it provides a specific suggestion for improvement and a method to validate the decision-making process. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation studies or what specific aspects of the decision-making process should be clarified. Overall, the comment is mostly helpful as it directs the authors to a potential area of improvement and provides a constructive suggestion for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and lack real-world problems. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting the inclusion of real-world problems or providing examples of how to incorporate them. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experiments comparing the proposed Batch BORE method with existing baselines, specifically noting that only synthetic objective functions are used and that there are no real-world problems included. This provides full grounding as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue of lacking real-world problems in the experiments. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and lack real-world problems. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a limitation in the experimental setup, noting that only synthetic objective functions are used to compare the proposed Batch BORE method with existing baselines, and that real-world problems are absent. This feedback is somewhat helpful as it highlights a potential gap in the evaluation of the proposed method. However, it lacks specific suggestions or guidance on how the authors might address this issue, such as recommending the inclusion of real-world datasets or providing examples of how to incorporate them into the experiments. While the comment identifies a weakness, it does not offer actionable steps for improvement, limiting its usefulness. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a challenge in distinguishing roles using explanation-focused cues, suggesting that LLMs may rely more on language style than informational depth. It implies that a detailed analysis of benchmark sentence differences between explanation and listener-focused parts could clarify these findings. While the comment identifies a potential area for improvement, it does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to analyze the benchmark sentences but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment discusses the challenge of distinguishing roles using explanation-focused cues and suggests that LLMs may rely more on language style than informational depth. It implies that a detailed analysis of benchmark sentence differences between explanation and listener-focused parts could clarify these findings. However, the comment does not specify which part of the paper this analysis should be conducted in, making it weakly grounded. The suggestion to analyze benchmark sentence differences is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that distinguishing roles using explanation-focused cues is challenging, suggesting that LLMs may rely more on language style than informational depth. It provides a logical reasoning by explaining the potential reason for this challenge, which is a reasonable inference based on the characteristics of LLMs. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to consider this reasoning and potentially conduct further analysis to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a challenge in distinguishing roles using explanation-focused cues, suggesting that LLMs may rely more on language style than informational depth. It provides a logical explanation for this challenge and offers a specific suggestion for improvement by recommending a detailed analysis of benchmark sentence differences between explanation and listener-focused parts. This feedback is clear and actionable, as it directs the authors to a particular area where they can enhance their work by providing more insight into the findings. However, the comment could be more helpful if it included examples or further guidance on how to conduct this analysis. Overall, the comment is mostly helpful, as it provides valuable guidance for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the issue of heavy use of acronyms in the paper, specifically mentioning that the acronym \"DU\" is used without a clear definition. This feedback is explicit, as it directly identifies the problem and suggests that the authors should provide a clear definition for the acronym. However, it does not specify how to implement this change, such as suggesting where the definition should be included or how to make it more accessible to readers. Therefore, the action is explicit but somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of heavy use of acronyms and specifically points out the acronym \"DU\" being used without a clear definition. This allows the authors to accurately identify the part of the paper being addressed, which is the use of acronyms. The comment is also specific because it highlights the problem of lack of definition for the acronym \"DU,\" providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s heavy use of acronyms affects readability and specifically mentions the acronym \"DU\" without a clear definition. This is a subjective opinion regarding the paper\\'s readability and a suggestion for improvement. However, the comment lacks specific examples or detailed reasoning to support why the use of acronyms is problematic or how it impacts readability. Without additional context or evidence, the claim is somewhat verifiable, as it provides a general critique but lacks detailed justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the heavy use of acronyms, which affects readability. It highlights a particular example, the acronym \"DU,\" which is mentioned without a clear definition. This feedback is clear and actionable, as it directs the authors to address the problem by providing definitions for the acronyms used in the paper. By doing so, the authors can improve the accessibility and clarity of their work for readers. However, the comment could be more helpful if it suggested where these definitions should be included or provided examples of how to present them in a more reader-friendly manner. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the estimation of variance in the distribution p(q|s) and whether it is sentence-independent. It asks if the variance is determined using the sample variance of quality values in the training data and whether a diagonal covariance matrix is assumed. While the comment implies that the authors should provide more information on this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the estimation method but are not given specific guidance on how to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the estimation of variance in the distribution p(q|s) and whether it is sentence-independent, and it asks for clarification on how the variance is determined, whether a diagonal covariance matrix is assumed, and whether this assumption is reasonable. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the assumption of sentence-independent variance in the distribution p(q|s) and seeks clarification on how this variance is estimated. It questions whether the sample variance of quality values in the training data is used and whether a diagonal covariance matrix is assumed. While the comment highlights areas that need clarification, it does not provide specific evidence or references to support the claim that the assumption is problematic or that the current approach is inadequate. The lack of detailed reasoning or examples makes the claim somewhat verifiable, as the authors would need to provide additional context or evidence to fully address the concerns.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the assumption of sentence-independent variance in the distribution p(q|s) and seeks clarification on how this variance is estimated. It asks whether the sample variance of quality values in the training data is used and whether a diagonal covariance matrix is assumed, which could be a simplification that may not be reasonable for the problem. This feedback is clear and actionable, as it prompts the authors to provide more detailed information about their methodology, which could help improve the transparency and robustness of their work. However, the comment could be more helpful if it offered suggestions on how to address these concerns or provided examples of alternative approaches. Overall, the comment is mostly helpful, as it directs the authors to a critical area that requires clarification and potentially improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the initial accuracy of the MIL-based baseline model being higher than the converged models, particularly for the NSCLC dataset. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this observation or what steps they should consider to improve their model. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the initial accuracy of the MIL-based baseline model being higher than the converged models, particularly for the NSCLC dataset. This provides clear guidance on what aspect of the figure needs further explanation or clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the initial accuracy of the MIL-based baseline model being higher than the converged models, particularly for the NSCLC dataset. However, it does not provide any supporting evidence, reasoning, or references to justify why this observation is noteworthy or how it impacts the paper. The lack of context or explanation makes it difficult for the authors to understand the significance of this observation or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the initial accuracy of the MIL-based baseline model being higher than the converged models, particularly for the NSCLC dataset. While it identifies an interesting observation, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or explore its implications. The comment does not offer actionable feedback or insights that could help the authors improve their draft. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should consider other datasets to explore the generalization of the proposed method across diverse data sources. While the comment implies that the authors should expand their dataset analysis, it does not provide specific guidance on which datasets to consider or how to incorporate them into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should explore additional datasets but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should consider other datasets to explore the generalization of the proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements of the paper, the authors may find it challenging to determine where to address this feedback. Additionally, the comment lacks specificity regarding which other datasets should be considered or how they would enhance the generalization of the proposed method. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper should consider other datasets to explore the generalization of the proposed method. However, it does not provide specific examples of alternative datasets or explain why these datasets would be beneficial for generalization. The comment lacks detailed reasoning or references to support the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should consider other datasets to explore the generalization of the proposed method. This is a valid point, as relying on a single dataset may limit the applicability and robustness of the findings. However, the comment lacks specificity and does not provide guidance on which datasets to consider or how to incorporate them into the paper. While it identifies a potential area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it provides a general direction for improvement but lacks depth and detail.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the expectation that the systems investigated in the paper are not Bayes-optimal, particularly on straightforward problems. It suggests that more work is needed at the beginning of the paper to establish alternative hypotheses and to gear the analyses and results towards ruling those out. The comment explicitly states that the current analysis is mostly confirmatory and that laying out alternatives and experiments to discriminate between them is crucial. This provides a clear and concrete action for the authors to take, which is to include alternative hypotheses and experiments to test them. The feedback is explicit and actionable, as it guides the authors on how to enhance their draft by providing a specific direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises a question about the expectation that the systems investigated in the paper are not Bayes-optimal, particularly on straightforward problems. It suggests that more work is needed at the beginning of the paper to establish alternative hypotheses and to gear the analyses and results towards ruling those out. The comment implies that the current analysis is mostly confirmatory and lacks a critical approach to testing hypotheses. However, it does not explicitly mention a specific section or part of the paper where this issue is most relevant, making it weakly grounded. The comment is specific in suggesting the need to establish alternative hypotheses and conduct experiments to discriminate between them. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the expectation that the systems investigated in the paper are not Bayes-optimal, particularly on straightforward problems. It suggests that more work is needed to establish alternative hypotheses and to gear the analyses and results towards ruling those out. The comment implies that the current analysis is mostly confirmatory and lacks a critical approach to testing hypotheses. However, it does not provide specific examples or references to support the claim that the systems are not Bayes-optimal or to substantiate the need for alternative hypotheses. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the necessity of additional work based on the reviewer\\'s suggestions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the expectation that the systems investigated in the paper are not Bayes-optimal, particularly on straightforward problems. It suggests that more work is needed at the beginning of the paper to establish alternative hypotheses and to gear the analyses and results towards ruling those out. The comment highlights the need for a more critical approach to testing hypotheses, rather than a confirmatory analysis. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by considering alternative hypotheses and experiments to discriminate between them. However, the comment could be more helpful if it offered specific examples or suggestions for how to implement these changes. Overall, the comment is mostly helpful, as it guides the authors toward a more rigorous and comprehensive analysis, but it could be more detailed in its suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors add confidence intervals to the results presented in Table 1, as the reported values are very close and do not allow for a clear conclusion. This is a direct and concrete action that the authors can take to improve their draft. The comment provides a clear and specific suggestion, making it highly actionable. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the reported values being very close, making it difficult to draw conclusions, and suggests adding confidence intervals to improve the clarity of the results. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the reported values in Table 1 are very close, making it difficult to draw conclusions. The reviewer suggests adding confidence intervals to improve the clarity of the results. While the comment highlights a potential issue with the presentation of results, it does not provide specific examples or detailed reasoning to support the claim that the values are too close. The suggestion to add confidence intervals is logical but lacks detailed justification or examples, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Table 1, noting that the reported values are very close, making it difficult to draw conclusions. It provides a clear and actionable suggestion to add confidence intervals, which would enhance the clarity and interpretability of the results. This feedback is valuable as it directs the authors to a specific area for improvement, offering a concrete step to enhance the quality and usefulness of their findings. However, the comment could be more helpful if it included additional context or examples of how confidence intervals could be applied or interpreted. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that some choices in the paper are not justified or clear, but it does not specify which choices are being referred to or provide any guidance on how to address this issue. The comment includes a suggestion to \"see questions for the authors,\" which implies that the reviewer has posed questions that could help clarify the issue, but these questions are not provided in the comment. As a result, the authors are left without explicit or implicit guidance on how to improve their draft. The lack of specificity and actionable steps makes this comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that some choices are not justified or clear, but it does not specify which choices are being referred to or provide any details about what is unclear. It also mentions \"see questions for the authors,\" which implies that the reviewer has posed questions, but these questions are not included in the comment. Without specific references or details, the authors cannot confidently determine which part of the paper is being addressed, making the comment not grounded. Additionally, the lack of specificity about what needs to be clarified or justified further exacerbates the issue. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"some choices are not justified/not clear,\" but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or references, the authors may find it challenging to understand which choices are in question or how to address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a lack of justification or clarity regarding some choices made in the paper. However, it does not specify which choices are being referred to or provide any guidance on how to address this issue. The suggestion to \"see questions for the authors\" implies that the reviewer has posed questions, but these questions are not included in the comment. Without specific feedback or actionable suggestions, the authors are left without a clear understanding of what needs to be improved or how to improve it. Therefore, the comment is not helpful at all, as it lacks actionable feedback and does not provide any meaningful guidance for the authors to enhance their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about hyperparameter tuning, specifically the complexity introduced by having two hyperparameters that affect both FLOPs and accuracy. It suggests that this makes the tuning process difficult and notes the lack of clarity in the current presentation regarding the grid search. The reviewer explicitly requests \"detailed discussions regarding this issue for reproducibility.\" This feedback is explicit and provides a clear action for the authors to take, which is to include detailed discussions on the grid search process. The action is concrete, as it specifies what needs to be addressed to improve the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of hyperparameter tuning, specifically the complexity introduced by having two hyperparameters that affect both FLOPs and accuracy. It highlights the difficulty in navigating the tuning process due to the interdependence of these parameters. The reviewer requests detailed discussions regarding this issue for reproducibility. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or experimental sections where hyperparameter tuning is discussed. The comment is specific in detailing the issue with hyperparameter tuning and the need for additional discussion. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the complexity of hyperparameter tuning due to the two hyperparameters affecting both FLOPs and accuracy. It suggests that this complexity makes the tuning process difficult and notes the lack of clarity in the current presentation regarding the grid search. The reviewer requests detailed discussions on this issue for reproducibility. While the comment highlights a potential issue, it does not provide specific examples or references to support the claim about the complexity of hyperparameter tuning. The reasoning is logical but lacks detailed evidence or examples, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding the complexity of hyperparameter tuning in the paper, particularly with the use of two hyperparameters that affect both FLOPs and accuracy. It highlights the difficulty in navigating the tuning process due to the interdependence of these parameters, making it challenging to find solutions that hit the same FLOPs. The reviewer requests detailed discussions on this issue for reproducibility, which is a valuable suggestion for improving the clarity and comprehensiveness of the paper. However, the comment could be more helpful if it provided specific suggestions on how to address this complexity or offered examples of alternative approaches. Overall, the feedback is mostly helpful as it directs the authors to a critical area that needs further elaboration, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missing aspect in Figure 1, specifically the accuracies of the target model using different defenses against the FGSM attack. It points out that this omission makes it unclear how the known attacks differ from the unknown attacks. While the comment identifies a gap in the figure, it does not provide explicit instructions on how to address this issue or suggest specific ways to include the missing information. The action is implicit and somewhat vague, as the authors can infer that they need to add the missing data but are not given concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of accuracies for the target model using different defenses against the FGSM attack, which makes it unclear how known attacks differ from unknown attacks. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the accuracies of the target model using different defenses against the FGSM attack are not shown in Figure 1, which makes it unclear how known attacks differ from unknown attacks. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Figure 1, noting that the accuracies of the target model using different defenses against the FGSM attack are not shown. This observation highlights a gap in the figure that could impact the reader\\'s understanding of the differences between known and unknown attacks. By pointing out this omission, the comment provides a clear and actionable suggestion for improvement, guiding the authors to include the missing information to enhance the clarity and comprehensiveness of their results. However, the comment could be more helpful if it offered specific suggestions on how to present these results or what additional information could be included. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors consider using a log-scale for the y-axis in some figures that are hard to read. This is a direct and concrete action that the authors can take to improve their draft. The comment provides a specific suggestion on how to enhance the readability of the figures, making it clear what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W5,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue with the figures, namely that they are hard to read, and provides a concrete suggestion to use a log-scale for the y-axis. This level of detail gives the authors clear guidance on what needs to be addressed to improve the readability of their figures. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that some figures are hard to read and recommends using a log-scale for the y-axis. However, the comment does not provide specific examples or detailed reasoning to support why the figures are difficult to read or how a log-scale would improve them. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the figures in the paper, noting that they are hard to read. It provides a clear and actionable suggestion by recommending the use of a log-scale for the y-axis. This feedback is valuable as it offers a concrete way for the authors to improve the readability and clarity of their figures, which is crucial for the paper\\'s overall impact. However, the comment could be more helpful if it specified which figures are problematic or provided additional guidance on how to implement the suggested change. Overall, the comment is mostly helpful as it directs the authors toward a specific improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the validation of the proposed method, specifically noting that the authors claim augmentation information is useful but do not provide experimental validation. It suggests using fine-grained datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset to validate the claims. While the comment implies that the authors should conduct additional experiments to validate their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct experiments on these datasets. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Introduction\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method\\'s motivation, based on the claim that \"augmentation information is useful,\" was not validated in the experiment. The comment suggests using specific fine-grained datasets, such as the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset, to validate the claims. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method\\'s motivation, based on the usefulness of augmentation information, was not validated in the experiment. It suggests using specific fine-grained datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset to validate the claims. The comment provides a logical reasoning by pointing out the lack of validation and offers a specific suggestion for improvement. However, it could be strengthened by providing more detailed reasoning or examples of how these datasets could be used to validate the claims. Overall, the comment is mostly verifiable, as it provides a clear direction for improvement but lacks detailed evidence or examples to fully substantiate the claim. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper, specifically that the proposed method\\'s motivation, based on the claim that \"augmentation information is useful,\" was not validated in the experiment. It suggests using specific fine-grained datasets, such as the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset, to validate the claims. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the validation of their method. By addressing this gap, the authors can strengthen the credibility and robustness of their work. Therefore, the comment is mostly helpful, as it offers a specific and actionable suggestion for enhancing the paper\\'s validity and impact.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the paper\\'s claim about opponents evolving toward the Nash equilibrium and the lack of theoretical analyses or empirical evidence supporting this claim. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include theoretical analyses or empirical evaluations to support their claim, but it does not specify what kind of analyses or evaluations are needed. This makes the action implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific statement from the paper, \"Over time, those opponents will evolve toward the Nash equilibrium,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of theoretical analyses and unclear empirical evaluations regarding GEMS converging to the Nash equilibrium. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s statement about opponents evolving toward the Nash equilibrium is not supported by theoretical analyses or empirical evaluations. However, the comment does not provide specific examples or references to substantiate this claim, making it somewhat verifiable. The authors would need to conduct their own analysis to understand the basis of the claim, which could be challenging without additional guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the claim that opponents will evolve toward the Nash equilibrium without providing theoretical analyses or empirical evidence to support this claim. This feedback is clear and actionable, as it highlights a critical gap in the paper that needs to be addressed. By pointing out the lack of theoretical analyses and empirical evaluations, the comment provides the authors with a clear direction for improvement, such as conducting additional analyses or providing more detailed empirical results. However, the comment could be more helpful if it offered suggestions on how to conduct these analyses or what specific aspects of the Nash equilibrium should be explored. Overall, the comment is mostly helpful as it directs the authors to a significant area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and concerns about Equation (1), specifically regarding its clarity and the definitions used. It questions the purpose of the equation, whether it defines a loss function or an optimization problem, and notes that it seems to be mixing both. Additionally, it points out potential inconsistencies in the notation, such as the optimization variable x being defined in R^n, which might be a typo and should be in R^k, and the unusual constraints notation (s.t. C(A, x)). While the comment identifies areas of confusion and potential errors, it does not provide explicit instructions or suggestions on how to clarify or correct these issues. The authors are left to infer that they need to clarify the purpose and notation of Equation (1), but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (1),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the equation, including the confusion about its purpose, the definition of the optimization variable x, and the unusual constraints notation. The comment provides clear guidance on what needs to be clarified or corrected, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several questions and concerns about Equation (1), specifically regarding its clarity and the definitions used. It questions the purpose of the equation, whether it defines a loss function or an optimization problem, and notes potential inconsistencies in the notation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to address these concerns effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific issues with Equation (1), questioning its clarity and the definitions used. It raises concerns about the purpose of the equation, whether it defines a loss function or an optimization problem, and notes potential inconsistencies in the notation, such as the optimization variable x being defined in R^n, which might be a typo and should be in R^k. Additionally, it points out the unusual constraints notation (s.t. C(A, x)). While the comment highlights areas that need clarification, it does not provide detailed guidance or suggestions on how to address these issues. The feedback is somewhat helpful as it directs the authors to specific parts of the paper that require clarification, but it lacks actionable advice on how to improve the clarity and notation. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the NMT system when including the collected LIV-EN parallel data for fine-tuning, noting that it makes the system perform worse. The reviewer asks for more discussions or explanations on this observation. While the comment implies that the authors should provide additional context or analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 257,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular observation regarding the performance of the NMT system when including the collected LIV-EN parallel data for fine-tuning, and it requests additional discussions or explanations on this issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance of the NMT system when including the collected LIV-EN parallel data for fine-tuning, noting that it makes the system perform worse. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this observation is unexpected or problematic. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific observation regarding the performance of the NMT system when including the collected LIV-EN parallel data for fine-tuning, noting that it makes the system perform worse. It requests additional discussions or explanations on this point, which could help the authors clarify the reasoning behind this observation and potentially identify areas for improvement in their methodology or experimental setup. However, the comment could be more helpful if it provided specific suggestions or insights on how to address this issue or what aspects of the fine-tuning process might be contributing to the observed performance degradation. Overall, the comment is somewhat helpful as it points out a potential area of concern and prompts the authors to provide more context, but it could be more actionable with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of substantiation and reasoning in the paper regarding the concept of \"fine-tuning as exposure of existing capabilities in LMs.\" It points out that without adequate reasoning or references, it is difficult for the authors or readers to understand the claim. However, the comment does not provide specific guidance on how the authors should address this issue, such as suggesting additional evidence or references to include. The action is implicit and vague, as the authors are left to infer that they need to provide more substantiation but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the paper\" and \"the \"fine-tuning as exposure of existing capabilities in LMs\" conjectures,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of unsubstantiated conjectures and the lack of adequate reasoning or references, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper contains unsubstantiated conjectures about \"fine-tuning as exposure of existing capabilities in LMs.\" The comment highlights the lack of reasoning or references to support these claims, making it challenging for the authors or readers to understand the basis of the conjectures. However, the comment does not provide specific examples or references to substantiate the claim, leaving it somewhat verifiable. The authors would need to infer the specific issues and address them accordingly. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of substantiation and reasoning for the conjectures about \"fine-tuning as exposure of existing capabilities in LMs.\" It highlights the difficulty in comprehending these claims due to the absence of adequate reasoning or references. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations or references to support their claims. However, the comment could be more helpful if it suggested specific ways to address this issue, such as recommending additional literature or experiments to substantiate the conjectures. Overall, the comment is mostly helpful, as it effectively points out a critical area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests including NaturalSpeech 3 as a baseline for voice cloning tasks when using FACodec. While the comment implies that this would be beneficial, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to incorporate NaturalSpeech 3 or why it would be beneficial. The authors can infer that they should consider adding NaturalSpeech 3 as a baseline, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including NaturalSpeech 3 as a baseline for voice cloning tasks when using FACodec. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This makes it difficult for the authors to identify the exact area that needs attention. The comment is specific in suggesting the inclusion of NaturalSpeech 3 as a baseline, but it lacks grounding as it does not clearly indicate where this suggestion should be implemented. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including NaturalSpeech 3 as a baseline for voice cloning tasks when using FACodec. However, the comment does not provide any reasoning or evidence to support why NaturalSpeech 3 would be beneficial or how it would enhance the evaluation. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including NaturalSpeech 3 as a baseline for voice cloning tasks when using FACodec. This is a specific and actionable suggestion that could enhance the evaluation and comparison of the paper\\'s results. By incorporating NaturalSpeech 3 as a baseline, the authors can provide a more comprehensive assessment of their method\\'s performance and effectiveness. However, the comment could be more helpful if it explained why NaturalSpeech 3 is a relevant baseline or how it would improve the evaluation. Overall, the feedback is mostly helpful as it provides a clear direction for improvement, but it could be more detailed to fully support the authors\\' understanding of the suggestion.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the experiments, suggesting that if the proposed method uses only the first 4 weeks of data for inference, other methods should also use this data for training. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to the experimental setting. The action is implicit and vague, as the authors are left to infer that they need to adjust the experimental setup but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the fairness of the experiments, specifically regarding the use of data for inference and training. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. The authors can make an educated guess that it relates to the experimental setup or results section, but the comment lacks full grounding. It is specific in detailing the issue of fairness in the experimental setting, but without explicit references to specific sections or elements, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the fairness of the experiments, suggesting that if the proposed method uses only the first 4 weeks of data for inference, other methods should also use this data for training. The reviewer questions the fairness of the current experimental setting, implying that the proposed method is at a disadvantage. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat logical but requires more detailed justification or evidence to be considered fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the fairness of the experiments, specifically noting that if the proposed method uses only the first 4 weeks of data for inference, other methods should also use this data for training. This observation highlights a potential issue with the experimental setup, suggesting that the proposed method may be at a disadvantage due to the limited training data. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the fairness of the experiments. While it identifies a potential problem, it does not provide actionable feedback, making it somewhat helpful. The authors are left to infer that they need to reconsider their experimental setup, but without detailed guidance, the comment does not fully support their improvement efforts. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category. This provides a clear and direct action for the authors to take, specifying exactly what additional data should be included in the paper. The comment is highly actionable because it gives precise guidance on what needs to be done, leaving no ambiguity for the authors. Therefore, this comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper should include results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category. However, it does not specify which part of the paper this suggestion should be added to, such as the results section or the discussion. This makes it weakly grounded, as the authors cannot confidently determine where to incorporate the suggestion. The comment is specific in detailing what additional results should be reported, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category. However, it does not provide any reasoning or evidence to support why this comparison is necessary or how it would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific suggestion for additional analysis that could enhance the paper. It recommends reporting results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category. This feedback is actionable and could help the authors improve the comprehensiveness and depth of their results section. However, the comment could be more helpful if it explained why this comparison is important or how it would contribute to the overall understanding of the paper. Despite this, the suggestion is clear and provides a concrete direction for improvement, making the comment mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of sequential bias on the VisDial results, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or what specific steps they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the impact of sequential bias on the VisDial results but does not specify which part of the paper this question pertains to. The authors cannot confidently determine the exact section or context being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide any details or suggestions on how to address the issue of sequential bias. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point is a question seeking clarification on the impact of sequential bias on VisDial results. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the impact of sequential bias on the VisDial results, which is a relevant concern for the authors to address. However, it does not provide any specific guidance or suggestions on how the authors might investigate or mitigate this bias. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is barely helpful, as it identifies a potential issue but does not offer any actionable advice or depth of analysis.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the experimental results and the stated goal of the LTAP method. It notes that LTAP achieves a larger performance improvement for head classes than for tail classes, which contradicts the goal of strengthening parameter protection for tail classes. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or improve the draft. Without actionable suggestions or guidance, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental results on the ImageNet-LT dataset\" and compares LTAP with ATO and RReg, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the discrepancy between the experimental results and the stated goal of LTAP, specifically highlighting the performance improvement for head classes versus tail classes. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results on the ImageNet-LT dataset show a larger performance improvement for head classes than for tail classes, which contradicts the stated goal of strengthening parameter protection for tail classes in LTAP. This claim is somewhat verifiable as it is based on the comparison of experimental results, but it lacks specific details or references to support the assertion. The comment does not provide examples or further explanation of how the results contradict the stated goal, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential contradiction between the experimental results and the stated goal of the LTAP method. It points out that the performance improvement is larger for head classes than for tail classes, which seems to contradict the aim of strengthening parameter protection for tail classes. This observation highlights a critical issue that the authors need to address, as it may impact the validity and effectiveness of their method. However, the comment does not provide specific suggestions or guidance on how the authors might resolve this discrepancy or improve their draft. While it raises an important point, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the reliability of the search process due to its dependency on LLM-based evaluation by prompting. It suggests that this dependency may introduce biases or inconsistencies in the quality assessment of generated documentations. However, the comment does not provide explicit guidance on how the authors should address these concerns or suggest alternative methods for evaluation. The action is implicit and vague, as the authors are left to infer that they should consider alternative evaluation methods or address the potential biases. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the reward computation in the paper, specifically mentioning the reliance on LLM-based evaluation by prompting. It raises concerns about the reliability of the search process and potential biases or inconsistencies in the quality assessment of generated documentations. However, the comment does not specify which part of the paper discusses the reward computation or provide detailed guidance on how to address these concerns. The authors can infer that it relates to the methodology or results sections, but the lack of explicit grounding and specificity makes it challenging for them to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the reliability of the search process due to its dependency on LLM-based evaluation by prompting. It suggests that this dependency may introduce biases or inconsistencies in the quality assessment of generated documentations. The comment provides a logical reasoning for the potential issue, noting that LLMs may generate inaccurate scores. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider the potential impact of LLMs on the evaluation process and address these concerns in their work. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reward computation in the paper, specifically highlighting the reliance on LLM-based evaluation by prompting. It raises concerns about the reliability of the search process and the potential for biases or inconsistencies in the quality assessment of generated documentations. This feedback is somewhat helpful as it points out a critical area that needs attention, but it lacks specific suggestions or guidance on how the authors might address these concerns. Providing more detailed advice or examples of alternative evaluation methods could enhance the helpfulness of the comment. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more empirical examples to support the claim that the described process is surprisingly effective. It also mentions comparing the results to the state-of-the-art (SOTA) performance from referenced papers, specifically mentioning Equation 12 as a potential starting point. However, the comment does not provide explicit guidance on how to conduct these comparisons or what specific examples should be included. While the action is implicit, the authors can infer that they need to add more empirical evidence and comparisons to support their claims. The feedback is somewhat actionable as it provides a general direction for improvement but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq 12,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the process described is \"extremely unclear,\" providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the described process is \"surprisingly effective\" and suggests that more empirical examples and comparisons to state-of-the-art (SOTA) performance from referenced papers are needed to support this claim. However, the comment does not provide specific examples or references to substantiate the claim, making it somewhat verifiable. The mention of Equation 12 as a potential starting point for this comparison is a step in the right direction, but without further elaboration or evidence, the claim remains somewhat vague. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of Equation 12, suggesting that it is unclear and could be improved by providing more empirical examples and comparisons to state-of-the-art (SOTA) performance from referenced papers. This feedback is somewhat helpful as it points out a potential area for improvement and suggests a direction for enhancing the clarity and robustness of the paper. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct these comparisons or improve the clarity of Equation 12. Overall, the feedback is actionable but could be more comprehensive, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the difficulty of the problem and questions the assumption that the adversary cannot pick arbitrary S, but only those with a constant alpha-fraction of observations hidden or removed. It provides a detailed analysis of the impact of this assumption on the problem, suggesting that even with a reduction to alpha * m pairs (a, y), accurate recovery is still possible if m = O(k log n). However, the comment does not provide explicit guidance or suggestions for the authors to address this concern or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should address the issue of problem difficulty and the implications of the assumption. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Assumption 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concern about the problem\\'s difficulty and the implications of the assumption regarding the adversary\\'s ability to pick observations. The comment provides a clear analysis of the impact of the assumption on the problem, suggesting that even with a reduction in the number of observations, accurate recovery is still possible under certain conditions. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the difficulty of the problem, specifically questioning the assumption that the adversary cannot pick arbitrary S, but only those with a constant alpha-fraction of observations hidden or removed. The reviewer provides a detailed analysis, explaining that even with a reduction to alpha * m pairs (a, y), accurate recovery is still possible if m = O(k log n). This reasoning is logical and provides a clear explanation of the issue, making the claim mostly verifiable. However, the comment could be strengthened by referencing specific literature or experiments that support this analysis. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the difficulty of the problem, specifically questioning the assumption that the adversary cannot pick arbitrary S, but only those with a constant alpha-fraction of observations hidden or removed. It provides a detailed analysis of the impact of this assumption, suggesting that even with a reduction to alpha * m pairs (a, y), accurate recovery is still possible if m = O(k log n). This feedback is clear and actionable, as it prompts the authors to reconsider the problem\\'s difficulty and the implications of their assumption. However, the comment could be more helpful if it offered suggestions on how to address this issue or improve the draft. Overall, the comment is mostly helpful, as it provides valuable insights but could be expanded for greater impact.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a contradiction between Figure 1 and the last two columns of Table 1 regarding the relationship between NNGS and the number of selected k-nearest neighbors. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to resolve this contradiction, such as suggesting a revision to the figure or table, or how to address the discrepancy. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out a contradiction between the figure and the table regarding the relationship between NNGS and the number of selected k-nearest neighbors. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 1 contradicts the comparison with the last two columns of Table 1 regarding the relationship between NNGS and the number of selected k-nearest neighbors. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the contradiction or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, pointing out a contradiction between Figure 1 and the last two columns of Table 1 regarding the relationship between NNGS and the number of selected k-nearest neighbors. This is a clear and actionable feedback that highlights a potential error or inconsistency in the paper. However, the comment does not provide any suggestions or guidance on how the authors might resolve this contradiction or clarify the relationship between the figure and the table. While it identifies a critical issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight into a specific problem but lacks comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the extensibility of the proposed method to a large number of tasks, similar to the challenges faced in multitask learning. It questions the impact of a large number of tasks on the set of shared parameters and requests the authors to address this concern. The comment explicitly asks the authors to address the question regarding the effect of the number of tasks on the proposed approach, providing a clear and direct action for the authors to take. The feedback is specific and actionable, as it guides the authors on what aspect of their work needs further exploration and explanation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises a concern about the extensibility of the proposed method to a large number of tasks, similar to the challenges in multitask learning. It questions the impact of a large number of tasks on the set of shared parameters and requests the authors to address this concern. The comment explicitly mentions the need to address the question regarding the effect of the number of tasks on the proposed approach, providing a clear direction for improvement. However, it does not specify which part of the paper this concern relates to, such as a particular section or experiment. While the authors can infer that it relates to the experimental results or methodology sections, the comment lacks full grounding. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the extensibility of the proposed method to a large number of tasks, similar to the challenges in multitask learning. It questions the impact of a large number of tasks on the set of shared parameters and requests the authors to address this concern. However, the comment does not provide any specific evidence, reasoning, or references to support the claim that the proposed method would face challenges with a large number of tasks. The request for the authors to address the question regarding the effect of the number of tasks on the proposed approach is more of a suggestion than a claim that requires verification. Therefore, the comment is considered borderline verifiable, as it lacks detailed justification or evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the extensibility of the proposed method to a large number of tasks, similar to the challenges faced in multitask learning. It questions the impact of a large number of tasks on the set of shared parameters and requests the authors to address this concern. The comment provides a clear and specific question for the authors to consider, which is valuable for improving the draft. However, it could be more helpful if it offered suggestions or examples on how the authors might address this concern or explore the implications of a large number of tasks. Overall, the comment is somewhat helpful as it identifies a potential area for improvement and prompts the authors to consider a critical aspect of their work, but it lacks depth and actionable guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the eyetracking data selection and filtering process, noting that it appears everything is analyzed with some exclusions. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their methodology. The comment lacks explicit or implicit actions, leaving the authors without a clear understanding of what changes are needed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the \"eyetracking data selection/filtering\" but does not specify which part of the paper this issue is discussed in, making it weakly grounded. It provides some specificity by noting that everything seems to be analyzed with some exclusions, which gives the authors an idea of what might be unclear or problematic. However, without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a concern about the eyetracking data selection and filtering process, noting that it appears everything is analyzed with some exclusions. However, the comment does not provide specific examples, reasoning, or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed justification or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the eyetracking data selection and filtering process, noting that it appears everything is analyzed with some exclusions. While the comment identifies a potential issue, it lacks specificity and does not provide actionable guidance on how the authors might address this concern or improve their methodology. Without detailed suggestions or examples, the feedback is limited in its usefulness to the authors. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the credibility of the results in the Appendix for InitNO, specifically regarding the text-image alignment on StableDiffusion-v1-4. It highlights a discrepancy between the reported improvement in the paper and the results shown in Table 6, where InitNO\\'s alignment is lower than that of StableDiffusion-v1-4. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the credibility of the results. The action is implicit and vague, leaving the authors to infer that they need to clarify or correct the discrepancy. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix results for InitNO\" and \"Table 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the credibility of the results, particularly regarding the text-image alignment on StableDiffusion-v1-4, and highlights the discrepancy between the reported improvement and the results shown in Table 6. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the credibility of the results in the Appendix for InitNO, specifically regarding the text-image alignment on StableDiffusion-v1-4. It points out a discrepancy between the reported improvement in the paper and the results shown in Table 6, where InitNO\\'s alignment is lower than that of StableDiffusion-v1-4. This claim is somewhat verifiable as it provides a specific observation and highlights a potential issue with the results. However, it lacks detailed reasoning or references to support the claim fully, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the credibility of the results in the Appendix for InitNO, specifically regarding the text-image alignment on StableDiffusion-v1-4. It points out a discrepancy between the reported improvement in the paper and the results shown in Table 6, where InitNO\\'s alignment is lower than that of StableDiffusion-v1-4. This feedback is somewhat helpful as it identifies a potential issue with the results and prompts the authors to clarify or correct the discrepancy. However, it lacks specific guidance on how to address the issue or what additional information might be needed to resolve the concern. Therefore, the comment is somewhat helpful, as it provides insight into a potential problem but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing is occasionally uneven and could benefit from additional editing, particularly in terms of language usage and type. It also points out that the notation in the equations becomes unwieldy at times and suggests considering the removal of sub/superscripts for convenience, noting that this change should be acknowledged. While the comment provides explicit suggestions for improvement, it lacks concrete guidance on how to implement these changes, such as specific examples of where the writing is uneven or how to effectively edit the language. The action is mostly actionable because it provides a clear direction for improvement but lacks detailed instructions on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the writing style and notation in the equations, suggesting that the writing is occasionally uneven and could benefit from additional editing, particularly in terms of language usage and type. It also mentions that the notation in the equations becomes unwieldy at times and suggests considering the removal of sub/superscripts for convenience. However, the comment does not specify which sections of the paper are uneven or where the notation becomes unwieldy, making it weakly grounded. The suggestion to drop sub/superscripts is specific, but without explicit references to the sections or equations, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the writing is occasionally uneven and could benefit from additional editing, particularly in terms of language usage and type. It also notes that the notation in the equations becomes unwieldy at times and suggests considering the removal of sub/superscripts for convenience. While the comment provides a logical reasoning for the need for editing and suggests a potential solution for the notation issue, it lacks specific examples or references to support the claim about the uneven writing. This makes the claim somewhat verifiable, as the authors would need to infer the specific areas needing improvement based on the general feedback provided.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two areas for improvement in the draft: the writing style and the notation in the equations. It suggests that the writing is occasionally uneven and could benefit from additional editing, particularly in terms of language usage and type. Additionally, it notes that the notation in the equations becomes unwieldy at times and recommends considering the removal of sub/superscripts for convenience, with the caveat that this change should be acknowledged. While the comment provides clear and actionable feedback, it could be more helpful by offering specific examples of where the writing is uneven or suggesting ways to improve the language usage and notation. Overall, the comment is mostly helpful as it directs the authors to areas that need attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two main parts. The first part raises a concern about the dataset size relative to the development cost and requests an explanation of the image acquisition cost and the manual collection process. This is an explicit request for additional information, making it clear and actionable. The second part consists of minor comments that are more observational and do not provide specific actions for the authors to take. While they highlight areas for clarification, they lack explicit instructions or suggestions for improvement. Overall, the comment is mostly actionable due to the explicit request for additional information about the dataset, but the minor comments are less actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (79 and 263) where the issues are located, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, such as explaining the image acquisition cost, the manual collection process, and clarifying the content of \"regulatory requirements\" and \"politically sensitive\" information. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several claims and requests for clarification. The first claim about the dataset size relative to development cost is somewhat verifiable, as it highlights a potential issue but lacks specific evidence or references to support the claim. The second part of the comment, which questions the content of \"regulatory requirements\" and \"politically sensitive\" information, is more specific but still lacks detailed justification or examples. The minor comments about line 79 and 263 are factual and do not contain claims. Overall, the comment is somewhat verifiable, as it provides some justification but lacks detailed evidence or references to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several points that are relevant to the authors' work. It highlights a concern about the dataset size relative to the development cost, which is an important consideration for the validity and generalizability of the study. The request for an explanation of the image acquisition cost and the manual collection process is clear and actionable, providing the authors with specific guidance on how to improve their paper. Additionally, the comment points out minor issues, such as the phrasing of a question in the text and the need for clarification on \"regulatory requirements\" and \"politically sensitive\" information. While the comment is mostly helpful, it could be more comprehensive by providing additional suggestions or examples to further enhance the clarity and robustness of the paper. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses curiosity about the generation of the third column in Fig. 7, specifically questioning whether the visualizations are normalized. However, it does not provide any explicit or implicit guidance on what the authors should do to address this curiosity. There is no suggestion for further clarification, normalization, or additional information that the authors should include. As a result, the comment lacks actionable advice, leaving the authors without a clear path for improvement. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the normalization of the visualizations in the third column of Fig. 7, providing clear guidance on what needs to be clarified or addressed. Therefore, this comment is labeled as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses curiosity about the generation of the third column in Fig. 7, questioning whether the visualizations are normalized. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks specific details or examples that would help the authors understand the issue or how to address it. As a result, the claim is considered unverifiable, as it does not provide sufficient information for the authors to make improvements.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses curiosity about the generation of the third column in Fig. 7, specifically questioning whether the visualizations are normalized. While it highlights a potential issue, it does not provide any guidance or suggestions on how the authors might address this concern or improve their draft. The comment lacks actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is rated as not helpful at all, as it does not offer any meaningful insights or suggestions for enhancing the paper.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should evaluate the advantages of using assignment entropy maximization in the ablation experiment, as the current investigation is described as heuristic. It also points out that the authors should discuss potential negative societal impacts of their work. While the comment implies that the authors should conduct additional analysis and discuss societal impacts, it does not provide explicit instructions on how to perform these tasks. The actions are inferred and somewhat vague, as the authors need to determine the specifics of the evaluation and discussion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the ablation experiment (section of benefit of assignment entropy maximization),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, evaluating the advantages of using assignment entropy maximization in the ablation experiment. Additionally, the comment points out the lack of discussion on potential negative societal impacts, which is another specific area for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the investigation of assignment entropy maximization is \"rather heuristic\" and suggests that the advantages of using it should be evaluated in the ablation experiment. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Additionally, the comment mentions the lack of discussion on potential negative societal impacts, but this is not a claim that requires verification. Overall, the comment lacks sufficient evidence and reasoning to be considered verifiable, aligning with a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two main areas for improvement. First, it points out that the investigation of assignment entropy maximization is described as heuristic and suggests that the authors should evaluate the advantages of using it in the ablation experiment. This feedback is clear and actionable, providing a specific direction for the authors to enhance their analysis. Second, the comment notes that the authors have not discussed potential negative societal impacts of their work, which is an important consideration for ethical and responsible research practices. By highlighting this omission, the comment encourages the authors to include a critical discussion on the potential consequences of their work. Overall, the comment is mostly helpful as it offers constructive feedback that can guide the authors in improving their draft, particularly in terms of methodology and ethical considerations.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point notes that there is only one baseline model in the experimental section, but it does not provide any explicit or implicit suggestions for improvement. It lacks actionable guidance on what the authors should do to address this issue, such as suggesting additional baseline models or explaining the rationale behind the current choice. Without specific instructions or recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of multiple baseline models in the experimental section. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is only one baseline model in the experimental section. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the paper. Without additional context or explanation, the claim remains unverifiable, as the authors are left without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a specific issue with the experimental section, noting that there is only one baseline model. This feedback is somewhat helpful as it identifies a potential limitation in the experimental setup, suggesting that the authors should consider including more baseline models for comparison. However, the comment lacks depth and does not provide guidance on why this is important or how it might impact the results or conclusions. It does not offer suggestions for additional baseline models or how to incorporate them effectively. Therefore, while it highlights an area for improvement, it is incomplete and could be more helpful with additional context or guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies missing baselines and literature comparisons in the results section, specifically mentioning traditional QAT (LSQ, LSQ+), other LLM-based QAT work (e.g., LLM-QAT [1]), and a more recent PTQ baseline (SpinQuant [2]). It suggests including these comparisons to better understand the benefits of using extra memory versus relying on fine-tuning low-rank adapters. The comment provides a clear and concrete action for the authors to take, which is to include these comparisons in the results section. This makes the comment highly actionable, as the authors know exactly what needs to be done to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"results\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the missing baselines and literature comparisons, such as traditional QAT (LSQ, LSQ+), other LLM-based QAT work (e.g., LLM-QAT [1]), and a more recent PTQ baseline like SpinQuant [2]. The comment provides clear guidance on what needs to be addressed in the results section, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some baselines and literature comparisons are missing in the results section, specifically mentioning traditional QAT (LSQ, LSQ+), other LLM-based QAT work (e.g., LLM-QAT [1]), and a more recent PTQ baseline like SpinQuant [2]. The reviewer provides specific examples of what is missing, which supports the claim. However, the comment could be strengthened by explaining why these comparisons are important or how they would enhance the understanding of the results. Overall, the claim is mostly verifiable, as it provides a clear list of missing comparisons but lacks detailed reasoning or examples to fully substantiate the importance of these comparisons. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the results section by pointing out the absence of certain baselines and literature comparisons, such as traditional QAT (LSQ, LSQ+), other LLM-based QAT work (e.g., LLM-QAT [1]), and a more recent PTQ baseline like SpinQuant [2]. It highlights the importance of including these comparisons to better understand the benefits of using extra memory versus relying on fine-tuning low-rank adapters. The comment provides specific examples of what is missing, offering clear and actionable guidance for the authors to enhance their results section. By suggesting the inclusion of these comparisons, the comment empowers the authors to improve the comprehensiveness and depth of their analysis, making it highly helpful. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the definition of an attribute and requests more detailed instructions. While it implies that the authors should provide clearer definitions and instructions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the definitions but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the definition of an attribute and the differences between attributes, suggesting that more detailed instructions should be provided. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need clarification. The comment is specific in its request for more detailed instructions but lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions and requests for clarification, such as \"How to define attribute?\" and \"What is the difference between attribute?\" These are not claims or opinions but rather requests for information or clarification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the definition of an attribute and the differences between attributes, which are crucial for clarity and understanding in the paper. It also suggests that more detailed instructions should be provided, which is a constructive feedback. However, the comment lacks specificity and does not offer detailed guidance on how the authors might address these questions or provide the requested instructions. While it identifies an area for improvement, it does not fully support the authors in making those improvements. Therefore, the comment is somewhat helpful, as it points out a need for clarification but does not provide comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern that the theory presented in the paper is insufficient to predict whether a model can be trained to be robust to adversarial perturbations. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might improve the theory or what specific aspects need to be revised. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the theory\\'s ability to predict robustness to adversarial perturbations but does not specify which part of the paper this issue pertains to. It lacks grounding as the authors cannot confidently determine which section or aspect of the theory is being addressed. Additionally, the comment is not specific, as it does not provide details on what aspects of the theory are insufficient or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the theory in the paper is insufficient for predicting whether a model can be trained to be robust to adversarial perturbations. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the theory\\'s ability to predict robustness to adversarial perturbations, suggesting that it may not be effective in this regard. However, the comment lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address this issue. Without detailed feedback or examples, the authors are left without a clear understanding of what needs to be improved or how to enhance their theory. As a result, the comment is not helpful at all, as it does not offer any actionable insights for the authors to improve their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the clarity of terms used in the paper, specifically \"scenario\" and \"agnostic.\" While it identifies areas of confusion, it does not provide explicit guidance or suggestions on how the authors should clarify these terms. The authors are left to infer that they need to provide definitions or explanations for these terms, but the comment lacks concrete details on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the clarity of terms used in the paper, specifically \"scenario\" and \"agnostic.\" However, it does not specify which part of the paper these terms are used in, making it difficult for the authors to pinpoint the exact sections that need clarification. The comment is specific in its questioning of the terms, but it lacks grounding as it does not provide a clear reference to the sections where these terms are used. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the terms \"scenario\" and \"agnostic\" used in the paper. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the clarity of terms used in the paper, specifically \"scenario\" and \"agnostic.\" It highlights a potential source of confusion for readers and prompts the authors to clarify these terms. However, the comment does not provide specific suggestions or guidance on how to address these issues, such as recommending definitions or examples to clarify the usage of these terms. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a problem but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the origin of the method named \"Maestro\" and expresses confusion about its introduction. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion to clarify the origin of the method, provide additional context, or make any changes to the draft. As a result, the authors are left without any actionable steps to take in response to this comment. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the origin of the method named \"Maestro\" and expresses confusion about its introduction. However, it does not specify which part of the paper discusses this method, making it difficult for the authors to identify the exact section that needs clarification. The comment lacks grounding as it does not provide a clear reference to the part of the paper being addressed. Additionally, it is not specific because it does not detail what needs to be clarified or addressed regarding the method. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the origin of the method named \"Maestro\" and expresses confusion about its introduction. However, it does not provide any supporting evidence, reasoning, or references to justify why the method\\'s name is confusing or why it should be clarified. The comment lacks a clear claim or suggestion that would require verification, making it difficult for the authors to understand the basis of the feedback. Therefore, the comment is considered \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment questions the origin of the method named \"Maestro\" and expresses confusion about its introduction. While it highlights a potential issue with the clarity of the paper, it does not provide any suggestions or guidance on how the authors might address this confusion. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to clarify the definition of \"best\" on page 5, specifying that it should be defined within the context of the paper. It also provides concrete guidance by asking the authors to clarify whether \"best\" refers to candidates with the highest confidence scores, those most relevant for prediction, or another criterion. This feedback is clear and actionable, as it directly tells the authors what needs to be done and how to do it. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the definition of \"best\" within the context of the paper. The comment provides guidance on whether \"best\" refers to candidates with the highest confidence scores, those most relevant for prediction, or another criterion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the definition of \"best\" in the context of the paper. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual request for clarification, making it a normal statement. Therefore, the label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by pointing out a specific area where the paper lacks clarity. It instructs the authors to explicitly define what \"best\" means within the context of the paper, which is crucial for understanding the results and conclusions. The comment also suggests clarifying whether \"best\" refers to candidates with the highest confidence scores, those most relevant for prediction, or another criterion. This feedback is highly helpful as it guides the authors to improve the clarity and precision of their work, allowing them to better communicate their findings to readers. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that some claims in the paper are over-asserted, specifically regarding the consideration of feed-forward layers in the proposed method. However, it does not provide explicit guidance on how to address this issue or suggest specific changes to make the claims more accurate. The comment implies that the authors should be more precise in their descriptions, but it lacks concrete instructions or examples on how to achieve this. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights an issue with the claims made in the paper, specifically regarding the consideration of feed-forward layers in the proposed method. However, it does not specify which parts of the paper contain these over-claimed statements, making it weakly grounded. The comment is specific in identifying the issue with the claims, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some points in the paper are over-claimed, specifically regarding the consideration of feed-forward layers in the proposed method. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that some claims are over-asserted, particularly regarding the consideration of feed-forward layers in the proposed method. This feedback is valuable as it points out a potential misrepresentation of the method\\'s capabilities. However, the comment lacks depth and does not provide specific suggestions or examples on how the authors might address this issue or clarify their claims. While it highlights an important area for improvement, the feedback is incomplete and could be more helpful with additional guidance or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clear motivation in the experiment design, specifically mentioning the \"no variations\" and \"Up to 18 games\" finetuning methods. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify the motivation behind these experimental designs, but it lacks concrete details on what specific information should be added or how the motivation should be articulated. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the experiment design, mentioning \"no variations\" and \"Up to 18 games\" finetuning methods. However, it does not specify which part of the paper these experiments are described in, making it weakly grounded. The comment is specific in detailing the issue with the experiment design, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location of the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiment design lacks clear motivation, specifically mentioning \"no variations\" and \"Up to 18 games\" finetuning methods. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these aspects are unclear or problematic. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experiment design, noting that the motivations behind certain experimental variations (\"no variations\" and \"Up to 18 games\" finetuning methods) are not clearly explained. This feedback is somewhat helpful as it points out a potential area for improvement, suggesting that the authors should clarify the rationale behind these experimental choices. However, the comment lacks depth and does not provide specific guidance on how to address this issue or what additional information should be included. While it directs the authors' attention to a relevant area, it could be more helpful with additional details or suggestions for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to evaluate the method performance under missing modality cases, such as testing with different missing ratios. It also suggests including results for Miss-V and Miss-A in tables 1 and 2. The comment provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1/2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the need to evaluate the method performance under missing modality cases, such as testing with different missing ratios. Additionally, it suggests including results for Miss-V and Miss-A. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the evaluation of the method should include results for missing modality cases, such as testing with different missing ratios. This claim is somewhat verifiable as it provides a logical reasoning for the need to evaluate the method under these conditions. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand the rationale behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation of the method, noting that only Miss-V and Miss-A results are shown in tables 1 and 2. It suggests that the authors should evaluate the method performance under missing modality cases, such as testing with different missing ratios. This feedback is clear and actionable, providing the authors with a specific area to focus on for improving their draft. However, the comment could be more helpful if it offered additional guidance on how to conduct these evaluations or suggested specific missing modality cases to consider. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that even if certain conditions are not changed during web browsing, an ablation study on the effect of using image features would be necessary. This implies that the authors should conduct an ablation study to explore the impact of image features on their work. However, the comment does not provide specific guidance on how to conduct this study or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer the need for an ablation study but may not know exactly how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that even if certain conditions are not changed during web browsing, an ablation study on the effect of using image features would be needed. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This makes it difficult for the authors to identify the exact area that needs attention. The comment is specific in suggesting the need for an ablation study, but it lacks grounding as it does not clearly reference a particular part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that even if certain conditions are not changed during web browsing, an ablation study on the effect of using image features would be necessary. However, the comment does not provide any reasoning or evidence to support why this ablation study is needed or how it would contribute to the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential gap in the study by suggesting that even if certain conditions are not changed during web browsing, an ablation study on the effect of using image features would be necessary. This feedback is somewhat helpful as it points out an area where the study could be improved by exploring the impact of image features. However, the comment lacks specificity and does not provide detailed guidance on how to conduct the ablation study or what aspects to focus on. While it highlights a potential area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the approach in challenging settings, specifically mentioning \"Transformer Big and deep Transformers.\" However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what specific experiments or analyses could be conducted to evaluate the approach in these challenging settings. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the performance of the approach in challenging settings, specifically mentioning \"Transformer Big and deep Transformers.\" However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment. The authors might infer that it relates to the experimental setup or results, but this is not explicitly stated. The comment is specific in its inquiry about the approach\\'s performance in challenging settings, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the performance of the approach in challenging settings, specifically mentioning \"Transformer Big and deep Transformers.\" However, it does not provide any supporting evidence, reasoning, or references to justify why these settings are challenging or how the approach might perform differently. The comment lacks specific examples or detailed analysis, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the performance of the approach in challenging settings, specifically mentioning \"Transformer Big and deep Transformers.\" While it identifies a potential area for further exploration, it lacks specificity and does not provide any actionable guidance or suggestions for the authors to address this concern. The comment does not offer any insights into how the authors might evaluate or improve the approach in these challenging settings, leaving the authors without a clear path for improvement. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but lacks depth and actionable feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the authors\\' understanding of identifiability is incorrect and provides a clear explanation of what identifiability is, specifically noting that it is a property of a model assuming infinite data can be observed. The reviewer also clarifies that a model cannot be considered non-identifiable due to insufficient data. This feedback is direct and provides concrete guidance on the issue, allowing the authors to understand and correct their misunderstanding. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the authors\\' understanding of identifiability, which is a specific concept discussed in the paper. However, it does not specify which part of the paper this misunderstanding is presented in, making it weakly grounded. The comment is specific in its critique of the authors\\' understanding of identifiability, providing a clear explanation of what identifiability is and why the authors\\' claim is incorrect. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' understanding of identifiability is incorrect. It provides a clear explanation of what identifiability is, specifically stating that it is a property of a model assuming infinite data can be observed. This reasoning is logical and provides a specific correction to the authors\\' understanding, making the claim fully verifiable. The comment offers a clear and direct justification for the claim, ensuring that the authors understand the basis of the critique. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment addresses a specific issue with the authors\\' understanding of identifiability, providing a clear and direct correction to their concept. It explains that identifiability is a property of a model assuming infinite data can be observed, and that a model cannot be considered non-identifiable due to insufficient data. This feedback is highly helpful as it not only identifies a misunderstanding but also offers a precise and actionable correction, allowing the authors to improve their understanding and presentation of the concept. The comment is clear, specific, and provides a significant improvement to the draft, making it highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the results show no particular benefit compared to a simple baseline, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their results. Without any suggestions or directions for improvement, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the results show no particular benefit compared to a simple baseline, but it does not specify which results or sections of the paper this observation is based on. Without explicit references to specific parts of the paper, the authors cannot confidently determine which aspects need attention. Additionally, the comment lacks specificity regarding what aspects of the results or baseline comparison are lacking. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the results show no particular benefit compared to a simple baseline. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the results do not show any particular benefit compared to a simple baseline. However, it lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or improve their results. Without actionable feedback or detailed analysis, the authors are left without a clear understanding of what needs to be changed or how to enhance their work. Therefore, the comment is not helpful at all, as it does not offer any meaningful direction for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the lack of description of the time cost for pre-training the WaveFiT vocoder and the potential slower inference speed due to the incorporation of a diffusion-based vocoder. While the comment identifies these areas for improvement, it does not provide explicit instructions or suggestions on how the authors should address these issues. The authors are left to infer that they should include the time cost for pre-training and discuss the implications of the slower inference speed. However, the comment lacks concrete guidance on how to present this information or mitigate the slower inference speed. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not provide detailed instructions on how to address them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"training process\" and \"inference process,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the method, such as the lack of description of the time cost for pre-training the WaveFiT vocoder and the potential slower inference speed due to the incorporation of a diffusion-based vocoder. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the efficiency of the method, specifically regarding the time cost of pre-training the WaveFiT vocoder and the potential slower inference speed due to the incorporation of a diffusion-based vocoder. The comment provides a logical reasoning by pointing out the lack of information on the time cost and the expected impact on inference speed. However, it does not provide specific examples or references to support these claims, making it somewhat verifiable. The authors would need to conduct their own analysis or provide additional information to fully substantiate the claims. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement in the paper: the lack of description of the time cost for pre-training the WaveFiT vocoder and the potential slower inference speed due to the incorporation of a diffusion-based vocoder. By highlighting these issues, the comment provides the authors with clear and actionable feedback on how to enhance the clarity and efficiency of their method. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as providing examples of how to estimate the time cost or discussing strategies to mitigate the slower inference speed. Overall, the comment is mostly helpful as it directs the authors to important aspects of their work that require further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the generalization of the framework, noting that while the paper mentions the potential for the scoring function to be generalized for multiple goal documents or without a gold document, this aspect is not explored. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or explore the generalization of the framework. The action is implicit and vague, leaving the authors without clear direction on how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the generalization of the framework, specifically mentioning the scoring function s(\u00b7; G) and its potential for multiple goal documents or without a gold document. However, it does not specify which part of the paper discusses this aspect, making it weakly grounded. The comment is specific in pointing out the lack of exploration of this generalization, which raises questions about the framework\\'s applicability. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the generalization of the framework is questionable because the paper mentions the potential for the scoring function to be generalized for multiple goal documents or without a gold document, but this aspect is not explored. However, the comment does not provide specific examples or detailed reasoning to support why the generalization is questionable. Without additional context or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper by noting that while it mentions the generalization of the scoring function for multiple goal documents or without a gold document, this aspect is not explored. This observation raises questions about the applicability and robustness of the framework. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or explore the generalization of the framework. While it highlights an area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in improving their draft.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that including information on the success rate at each conversation turn would provide a more comprehensive understanding of the proposed approach\\'s performance. This is a clear and explicit action for the authors to take, as it specifies what additional data should be included to enhance the paper. The comment also provides a reference to a related work, which could serve as a basis for the authors to understand the context and relevance of the suggestion. However, the comment could be more actionable if it provided specific guidance on how to present this data or what metrics to use. Overall, the comment is mostly actionable, as it gives the authors a clear direction for improvement but lacks detailed instructions on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests including information on the success rate at each conversation turn to provide a more comprehensive understanding of the proposed approach\\'s performance. It implies that this information would help readers assess the framework\\'s effectiveness in a more nuanced manner. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where this information could be included. The authors can infer that it relates to the evaluation or results section, but the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting what additional data could be included, but without explicit references to specific sections, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including information on the success rate at each conversation turn would provide a more comprehensive understanding of the proposed approach\\'s performance. The comment references a specific paper, \"Multiple choice questions based multi-interest policy learning for conversational recommendation,\" which supports the claim by providing a related work that could serve as a basis for the suggestion. However, the comment does not fully explain why this information is crucial or how it would enhance the understanding of the proposed approach. While the reference provides some context, the claim could be more fully verifiable with additional reasoning or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that including information on the success rate at each conversation turn would provide a more comprehensive understanding of the proposed approach\\'s performance. This feedback is clear and actionable, as it identifies a specific area for improvement that could enhance the paper\\'s clarity and usefulness. By suggesting the inclusion of this data, the comment offers a concrete way for the authors to improve their draft, making it mostly helpful. However, the comment could be more helpful if it provided additional guidance on how to present this data or what metrics to use. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper is dense and difficult to read in parts, suggesting that numbered lists could be presented as actual lists instead of being embedded in paragraphs. This feedback provides a clear and explicit action for the authors to take, which is to reformat the lists to improve readability. The suggestion is concrete, as it specifies a specific change that can be made to enhance the paper\\'s readability. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment provides a general observation about the paper being dense and difficult to read, but it does not specify which parts of the paper are particularly dense or which paragraphs contain the numbered lists that could be improved. While the authors might infer that this issue affects the readability of the entire paper, the comment lacks full grounding as it does not pinpoint specific sections or elements. Additionally, the suggestion to present numbered lists as actual lists is specific, but it does not provide detailed guidance on how to implement this change. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is \"very dense\" and difficult to read, suggesting that numbered lists could be presented as actual lists to improve readability. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the lists are problematic, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some basis for the critique but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s density and readability, suggesting that numbered lists could be presented as actual lists to improve the flow of the text. This feedback is clear and actionable, providing the authors with a concrete suggestion to enhance the readability of their draft. However, the comment could be more helpful if it included specific examples or sections where this issue is particularly pronounced, which would give the authors a clearer direction for improvement. Overall, the comment is mostly helpful as it offers a constructive suggestion for improving the paper\\'s readability, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the simplicity of the classifier and whether other \"fake image detectors\" might be using similar spectral cues in a more opaque manner. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what steps to consider in their analysis. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the simplicity of the classifier and whether other \"fake image detectors\" might be using similar spectral cues in a more opaque way. However, it does not specify which part of the paper this question pertains to, nor does it provide details on what needs to be addressed or improved. The authors cannot confidently determine which section of the paper this comment relates to, and it lacks specificity regarding what aspects need clarification or further discussion. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the simplicity of the classifier and whether other \"fake image detectors\" might be using similar spectral cues in a more opaque way. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations that would help the authors understand the basis of the question or how it relates to their work. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to address or improve their work. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the simplicity of the classifier and whether other \"fake image detectors\" might be using similar spectral cues in a more opaque way. While it prompts the authors to consider the broader implications of their findings, it does not provide specific guidance or suggestions on how to address this question or improve the draft. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their work. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the visualization results are \"terrible\" compared to the ground truth and suggests that the authors should include analysis of both satisfied and terrible cases. Additionally, it provides a specific suggestion to include class-incremental learning for semantic segmentation that re-uses neither old data nor old labels. This feedback is clear and provides concrete actions for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"3\" and \"the visualization results,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the visualization results are \"terrible\" compared to the ground truth and suggests including analysis of satisfied and terrible cases. Additionally, it provides a specific suggestion regarding class-incremental learning for semantic segmentation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the visualization results are \"terrible\" compared to the ground truth and suggests analyzing both satisfied and terrible cases. However, it does not provide any specific examples, reasoning, or references to support this claim. The mention of \"class-incremental learning for semantic segmentation re-using neither old data nor old labels\" seems to be a separate point, but it is not clearly connected to the initial claim about the visualization results. Without detailed justification or evidence, the claim remains unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the visualization results, noting that they are \"terrible\" compared to the ground truth. It suggests that the authors should include analysis of both satisfied and terrible cases, which could help in understanding the performance of the method. Additionally, the comment provides a specific suggestion regarding class-incremental learning for semantic segmentation, which could be a valuable direction for improvement. However, the comment could be more helpful if it provided more detailed guidance on how to analyze the satisfied and terrible cases or offered examples of class-incremental learning approaches. Overall, the feedback is mostly helpful as it points out a critical area for improvement and offers a potential direction for enhancement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the paper builds upon a large body of previous work, which could potentially affect the validity and effectiveness of the proposed method, TIW. It also notes that the implementation process is similar to previous work on GAN. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the potential limitations or issues from previous works or how to differentiate the implementation from existing GAN work. Without actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s reliance on previous work and its potential impact on the validity and effectiveness of the proposed method, TIW. It also mentions the similarity in implementation to previous work on GAN. However, the comment does not specify which sections of the paper these observations relate to, making it difficult for the authors to pinpoint the exact parts that need attention. Additionally, while it highlights potential issues, it does not provide specific guidance on how to address these concerns. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper builds upon a large body of previous work, which could affect the validity and effectiveness of the proposed method, TIW. It also notes that the implementation process is similar to previous work on GAN. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the exact nature of the potential issues or how they might impact the paper. The lack of detailed justification or evidence renders the claim somewhat verifiable, as the authors would need to invest additional effort to fully understand and address the concerns raised.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights that the paper builds upon a large body of previous work, which could potentially affect the validity and effectiveness of the proposed method, TIW. It also notes that the implementation process is similar to previous work on GAN. While the comment identifies a relevant issue regarding the paper\\'s reliance on previous work, it lacks specific suggestions or guidance on how the authors might address these concerns or differentiate their work from existing literature. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the partitioning step and whether any information unavailable to the policy is being used. It questions the rationale behind not incorporating patient characteristics, which are used for clustering, into the policy training. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify the use of information in the partitioning step and consider incorporating patient characteristics into the policy training. However, the comment lacks concrete details on how to implement these changes, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the partitioning step and the use of information unavailable to the policy. It questions the rationale behind not incorporating patient characteristics, which are used for clustering, into the policy training. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the exact location is not clearly identified. The comment is specific in detailing the issue with the partitioning step and the potential use of patient characteristics, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the partitioning step and whether any information unavailable to the policy is being used. It questions the rationale behind not incorporating patient characteristics, which are used for clustering, into the policy training. The comment provides a logical reasoning by pointing out the potential inconsistency in the use of information, but it lacks specific examples or references to support the claim. This makes the claim somewhat verifiable, as the authors would need to provide additional context or evidence to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the partitioning step in the methodology, specifically whether any information unavailable to the policy is being used. It challenges the rationale behind not incorporating patient characteristics, which are used for clustering, into the policy training. This feedback is somewhat helpful as it prompts the authors to clarify their approach and consider whether incorporating additional information could improve the policy. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending alternative methods or providing examples of how to incorporate patient characteristics. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the rendering quality of NeRF compared to NeuS and Geo NeuS, as presented in Appendix C. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what specific aspects of the rendering quality should be improved. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the rendering quality of NeRF compared to NeuS and Geo NeuS, providing a clear direction for the authors to address this issue. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question asking for clarification on why NeRF\\'s rendering quality is worse than NeuS and Geo NeuS, as presented in Appendix C. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the rendering quality of NeRF compared to NeuS and Geo NeuS, as presented in Appendix C. While it identifies a potential issue, it lacks depth and does not provide any suggestions or guidance on how the authors might address this concern or improve their work. The comment is somewhat helpful as it points out an area for further clarification, but it does not offer actionable advice or detailed feedback to help the authors improve their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques a statement in Section 3.7, questioning the bold assumption that purely unsupervised large-scale pretraining might not be suitable for NLP applications. The reviewer expresses confusion about how this conclusion is drawn from the proposed evaluation approach. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the concern or clarify the assumption, leaving the authors without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it critiques a particular statement and questions the bold assumption made about the suitability of purely unsupervised large-scale pretraining for NLP applications. The comment clearly specifies what needs to be addressed, which is the justification for this assumption. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions a bold assumption made in the manuscript regarding the suitability of purely unsupervised large-scale pretraining for NLP applications. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption is problematic or how it contradicts the evaluation approach. Without additional context or explanation, the claim remains unverifiable, as the authors are left without a clear understanding of the basis for the critique. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques a specific statement in Section 3.7, questioning the bold assumption that purely unsupervised large-scale pretraining might not be suitable for NLP applications. It expresses confusion about how this conclusion is drawn from the proposed evaluation approach, indicating a lack of clarity or justification in the manuscript. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their argument. While it identifies a potential weakness, it lacks actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the lack of discussion on recent related work, specifically mentioning [A] and its performance on SUN, and the omission of DCN [18] in Table 3, despite its better performance on CUB. Additionally, it notes the relevance of [B] with respect to transductive label propagation. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues or what specific aspects of the related work should be discussed. The authors can infer that they need to include these works in their discussion and possibly update Table 3, but the comment lacks concrete guidance on how to integrate this information effectively. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not provide detailed instructions on how to implement these changes.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Related work 2.1\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the missing discussions on recent related work, including specific references like [A] and [B], and highlights the omission of DCN [18] in Table 3. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper misses discussing recent related work, specifically mentioning [A] and its performance on SUN, and also notes the omission of DCN [18] in Table 3. The reviewer provides specific references to support the claim, such as [A] and [18], which helps to substantiate the critique. However, the comment could be strengthened by providing more detailed reasoning or examples of how these works relate to the paper\\'s contributions. Overall, the claim is mostly verifiable due to the inclusion of specific references, but it could benefit from more detailed justification. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement in the paper. First, it points out the lack of discussion on recent related work, including a specific reference [A] that achieves higher performance on SUN, and the omission of DCN [18] in Table 3, which is better than other prior work on CUB. Second, it highlights the relevance of [B] with respect to transductive label propagation. By mentioning these specific works and their contributions, the comment provides clear and actionable feedback that can guide the authors in enhancing their discussion of related work and potentially updating their analysis. However, the comment could be more helpful if it offered suggestions on how to integrate these works into the paper or provided additional context for the authors to consider. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the operator should be a Hadamard product between the DAG and Attention, rather than an addition, as shown in figure 2. This provides a clear and direct action for the authors to take, specifying exactly what change is needed. The comment is explicit and concrete, leaving no ambiguity about how to implement the suggested change. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the change needed, indicating that the operator should be a Hadamard product between the DAG and Attention instead of an addition. This provides clear guidance on what needs to be revised. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a specific change to the operator used in figure 2, recommending a Hadamard product between the DAG and Attention instead of an addition. This claim is based on a logical suggestion for improvement, as it provides a clear and specific alternative to the current approach. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change is necessary or beneficial. Therefore, the claim is somewhat verifiable, as it lacks detailed justification or examples to fully substantiate the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the draft. It identifies a particular issue with the operator used in figure 2, recommending a change from an addition to a Hadamard product between the DAG and Attention. This feedback is clear and direct, offering the authors a concrete way to enhance their work. However, the comment could be more helpful if it explained the reasoning behind this suggestion or provided additional context on why this change is beneficial. Despite this, the comment is mostly helpful as it provides a clear path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the authors have addressed the reviewer\\'s concerns in their revision and response, leading to an increase in the score from 7 to 8. However, it identifies two specific areas that are only partially addressed: the non-standard finite sum assumption and the discrepancy between theoretical and practical updates of SABA. The comment suggests that the non-standard finite sum assumption should be anticipated in the abstract and that the discrepancy should be more thoroughly addressed. While the comment implies that these areas need further clarification or discussion, it does not provide explicit instructions on how to address them. The actions are implicit and somewhat vague, as the authors need to infer the specific steps to take to improve these aspects. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"weakness 2\" and \"theoretical analysis section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, such as the non-standard finite sum assumption and the discrepancy between theoretical and practical updates of SABA. The comment provides clear guidance on how to improve the paper by suggesting that these issues should be anticipated in the abstract and more thoroughly discussed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges that the authors have addressed the reviewer\\'s concerns, leading to an increase in the score. It provides specific feedback on the limitations that are only partially addressed, such as the non-standard finite sum assumption and the discrepancy between theoretical and practical updates of SABA. The comment suggests that these issues should be more thoroughly discussed, particularly in the abstract. While the comment highlights areas for improvement, it does not provide detailed reasoning or references to support the claim that these limitations are only partially addressed. The feedback is mostly verifiable, as it identifies specific areas for improvement but lacks comprehensive evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges that the authors have addressed some of the reviewer\\'s concerns in their revision and response, leading to an increase in the score. It provides specific feedback on the limitations that are only partially addressed, such as the non-standard finite sum assumption and the discrepancy between theoretical and practical updates of SABA. The comment suggests that these issues should be more thoroughly discussed, particularly in the abstract. This feedback is clear and actionable, as it directs the authors to specific areas that need further clarification or expansion. However, the comment could be more helpful if it provided additional guidance on how to address these limitations or suggested specific ways to improve the discussion. Overall, the comment is mostly helpful, as it offers valuable insights for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the paper\\'s claim and the experimental results, noting that UnKE\\'s ability to retain original knowledge is worse than the baseline. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative methods to improve knowledge preservation or recommending additional experiments. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that UnKE\\'s ability to retain original knowledge is worse than the baseline, as indicated by the metrics in the tables. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s assertion about UnKE\\'s ability to preserve pre-trained knowledge during editing is contradicted by the experimental results, which show that UnKE performs worse than the baseline. The claim is supported by specific references to tables in the paper (MMLU in Table 2 and Src-Acc and Tgt-Acc in Table 3), providing a clear basis for the critique. Additionally, the comment references an external work, \"Long-form evaluation of model editing,\" which further substantiates the claim. This makes the claim fully verifiable, as it is supported by both internal and external evidence.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the paper\\'s claim and the experimental results, specifically noting that UnKE\\'s ability to retain original knowledge is worse than the baseline. This is a critical observation that highlights a potential flaw in the paper\\'s assertions. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their results. While it points out a significant weakness, it lacks actionable feedback, making it somewhat helpful. The authors are informed of a problem but are not given a clear path to resolve it, limiting the comment\\'s utility. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clear explanation for the intention of BWTP/GLBW and notes that many details are relegated to the appendix, making it difficult to understand them initially. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific changes to improve the clarity of the explanation. The action is implicit and somewhat vague, as the authors can infer that they need to provide a clearer explanation but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of clear explanation for the intention of BWTP/GLBW and notes that many details are in the appendix, making it hard to understand them at first sight. However, it does not specify which part of the paper discusses BWTP/GLBW, making it weakly grounded. The comment is specific in identifying the issue with the explanation and the placement of details in the appendix. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the explanation for the intention of BWTP/GLBW is weak and that many details are relegated to the appendix, making it hard to understand them initially. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence or detailed justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the explanation for the intention of BWTP/GLBW is weak and that many details are relegated to the appendix, making it difficult to understand them initially. This feedback is somewhat helpful as it points out a potential area for improvement, suggesting that the authors should provide a clearer explanation for BWTP/GLBW. However, the comment lacks specific guidance or suggestions on how to enhance the explanation or reorganize the content to address this issue. While it provides some insight, it could be more helpful with additional details or actionable advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include a proof that was omitted due to space constraints. It suggests that the proof should be included in the revision, either as supplementary material or potentially integrated into the main paper. This feedback is clear and provides a direct action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of omitting a proof and suggests including it in the revision, either as supplementary material or potentially integrating it into the main paper. This provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for the authors to include a proof that was omitted due to space constraints. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual statement asking for additional content, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the omission of a proof in Section 3 due to space constraints. It provides a clear and actionable suggestion for the authors to include the proof in the revision, either as supplementary material or potentially integrating it into the main paper. This feedback is valuable as it highlights a potential gap in the paper and offers a concrete way for the authors to address it, thereby improving the draft. However, the comment could be more helpful if it provided additional context or suggestions on how to effectively integrate the proof into the main text. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement with actionable guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that instead of providing a general statement about the lack of direct dependence on magnitudes as the reason for NPPs performing worse than ETAS, the authors should provide specific experimental results or references to support this claim. This feedback is explicit, as it clearly instructs the authors to include specific data or references to substantiate their argument. It is also concrete, as it provides a clear action for the authors to take, namely, to include experimental results or references to support their claim. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide specific experimental results or references to support the claim that NPPs perform worse than ETAS due to the lack of direct dependence on magnitudes. However, it does not specify which part of the paper this claim is made in, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its suggestion to provide experimental results or references, but it lacks grounding as it does not clearly indicate where in the paper this issue is discussed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the statement \"Since the NPPs lack any direct dependence on magnitudes\" is insufficient as a reason for NPPs performing worse than ETAS. The reviewer implies that specific experimental results or references should be provided to support this claim. However, the comment does not provide any additional evidence, examples, or references to substantiate the claim that the current reasoning is inadequate. Without further elaboration or support, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide specific experimental results or references to support the claim that NPPs perform worse than ETAS due to the lack of direct dependence on magnitudes. This feedback is clear and actionable, as it identifies a specific area where the paper could be strengthened by including empirical evidence or references to substantiate the claim. By providing this guidance, the comment helps the authors improve the rigor and credibility of their argument, making it mostly helpful. However, it could be more helpful if it offered suggestions on how to present these results or references effectively. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the implementation details, specifically regarding the application of connectivity patterns to complex architectures like UNet, ResNet, and MobileNet. The reviewer notes that this lack of guidance raises problems for understanding the paper\\'s details. While the comment identifies the issue, it does not provide explicit instructions on how to address it, such as suggesting specific sections to expand or examples to include. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed guidance on implementing the connectivity patterns for various architectures. However, the comment lacks concrete guidance on how to achieve this, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"methodology section\" and references specific equations (3 and 4) and tables (1, 4, and 5), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of guidance on applying connectivity patterns to complex architectures like UNet, ResNet, and MobileNet, and notes that these details are not incorporated in the Appendix. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the implementation details are unclear, specifically regarding the application of connectivity patterns to complex architectures like UNet, ResNet, and MobileNet. The reviewer provides a logical reasoning by pointing out the lack of specific guidance in the methodology section and the absence of these details in the Appendix. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to specific sections where the implementation details are unclear. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the implementation details in the paper. It points out that the methodology section provides equations for connectivity patterns between layers but lacks specific guidance on how to apply these connections to complex architectures like UNet, ResNet, and MobileNet. This lack of clarity is highlighted as a problem for understanding the paper\\'s details, particularly when trying to dive into the specifics. The comment also notes that these details are not incorporated in the Appendix, which further exacerbates the issue. By pinpointing this specific area for improvement, the comment provides actionable feedback that could help the authors clarify and enhance the implementation details, making it mostly helpful. However, it could be more helpful if it offered suggestions on how to address this issue, such as providing examples or additional guidance on incorporating these details into the Appendix. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the calculation of HTER label relies on automatic scripts and questions whether this approach can be scaled to other annotations like MQM or DA. It implies that the authors should experiment with other languages and annotations to verify scalability. While the comment identifies a potential issue and suggests an action, it does not provide specific guidance on how to conduct these experiments or what aspects to focus on. The action is explicit but somewhat vague, as it lacks detailed instructions on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the calculation of HTER label and its reliance on automatic scripts, questioning its scalability to other annotations like MQM or DA. However, it does not specify which part of the paper discusses this calculation, making it weakly grounded. The comment is specific in its suggestion to experiment with other languages and annotations to verify scalability, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the scalability of the HTER label calculation, suggesting that it relies on automatic scripts and may not be applicable to other annotations like MQM or DA. The comment implies that the authors should experiment with other languages and annotations to verify this scalability. However, the comment lacks specific examples or references to support the claim about the limitations of the current approach. This makes the claim somewhat verifiable, as it provides a logical suggestion but requires further evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper\\'s methodology, specifically the reliance on automatic scripts for calculating HTER labels. It questions the scalability of this approach to other annotations like MQM or DA, suggesting that the authors should experiment with these other languages and annotations to verify the scalability. This feedback is clear and actionable, as it directs the authors to a specific area where they can improve their work by expanding their experiments. However, the comment could be more helpful if it provided additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about how the overall performance depends on $m$ in $G_m$. While it implies that the authors should investigate or discuss this relationship, it does not provide explicit guidance on how to address this question or what specific aspects of performance should be considered. The action is implicit and somewhat vague, as the authors can infer that they need to explore this relationship but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about how overall performance depends on $m$ in $G_m$. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this relationship is discussed. Without explicit references or context, the authors may find it challenging to determine where to address this inquiry. The comment is specific in its request for clarification but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification on how overall performance depends on $m$ in $G_m$. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, the correct label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about how overall performance depends on $m$ in $G_m$. While it identifies a potential area for clarification, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this question or what aspects of performance should be considered. The comment does not offer actionable feedback or insights that could help the authors improve their draft. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a theory-practice gap in deep learning, specifically mentioning that sparse neural nets are difficult to fit. It suggests that the authors should comment on this issue to help readers understand the key elements that allow Causal-Stonet to learn sparse neural nets. While the comment implies that the authors should address this gap, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to discuss the theoretical aspects of their work in relation to practice. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the theory-practice gap in deep learning, specifically mentioning sparse neural nets and referencing a work by Farrell, Liang, and Misra (ECTA 2021). It suggests that the authors should comment on the key elements that allow Causal-Stonet to learn sparse neural nets. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the theoretical aspects of the work. The suggestion to comment on the key elements is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a theory-practice gap in deep learning, specifically mentioning that sparse neural nets are difficult to fit. It references a work by Farrell, Liang, and Misra (ECTA 2021) to support this claim. However, the comment does not provide detailed reasoning or examples from the paper being reviewed to substantiate how Causal-Stonet addresses this gap. While the reference to external work provides some context, the claim remains somewhat verifiable due to the lack of specific evidence or detailed explanation within the review comment. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights a significant issue in the field of deep learning, specifically the theory-practice gap, and suggests that the authors should address this gap in their paper. It references a relevant work by Farrell, Liang, and Misra (ECTA 2021) that discusses the difficulty of fitting sparse neural nets. The comment provides a clear direction for the authors to comment on the key elements that allow Causal-Stonet to learn sparse neural nets, which could help readers better understand the theoretical aspects of the work. However, the comment could be more helpful if it offered specific suggestions on how to address this gap or provided examples of key elements that should be discussed. Overall, the feedback is mostly helpful as it identifies a critical area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit suggestions for improving the layout of the manuscript, specifically recommending that the authors consider making some tables smaller or relocating them to the appendix, and possibly reducing the size of certain figures. The comment also provides specific examples, such as Table 1 and Figure 2, to guide the authors on which elements to focus on. This level of detail and specificity makes the action clear and concrete, allowing the authors to know exactly what steps to take to address the issue. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figures and tables\" and \"the text,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific suggestions for improvement, such as making some tables smaller or relocating them to the appendix, and reducing the size of certain figures. This level of detail makes the comment specific, as it clearly outlines what needs to be addressed to improve the layout of the manuscript. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the manuscript is \"densely packed in terms of space\" due to the close positioning of figures and tables to the text, which can make the paper seem cluttered and condensed. The reviewer suggests possible solutions, such as making some tables smaller or relocating them to the appendix, and reducing the size of certain figures. While the comment provides a logical reasoning for the issue, it lacks specific examples or references to support the claim about the current state of the manuscript. This makes the claim somewhat verifiable, as the authors would need to verify the assertion themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the layout of the manuscript, noting that figures and tables are positioned very closely to the text, which can make the paper appear cluttered and condensed. It provides actionable suggestions for improvement, such as making some tables smaller or relocating them to the appendix, and possibly reducing the size of certain figures. This feedback is clear and offers concrete steps for the authors to enhance the readability and visual appeal of their manuscript. By addressing these suggestions, the authors can significantly improve the overall presentation of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the ReCPE method being too strategic and lacking a strong theoretical guarantee. It suggests that the authors may be able to strengthen their article by addressing this issue. However, the comment does not provide specific guidance on how to strengthen the theoretical foundation or what aspects need improvement. The suggestion is implicit and lacks concrete details, making it somewhat actionable. The authors can infer that they need to enhance the theoretical aspects of their method, but they are not given explicit instructions on how to do so.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Note 2 on page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the spelling of \"real word,\" providing clear guidance on what needs to be corrected. However, the comment primarily focuses on the theoretical aspects of the ReCPE method, which is not explicitly linked to a specific section of the paper. While the authors can infer that this relates to the methodology or results sections, the comment could be more specific in its guidance. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ReCPE method is too strategic and lacks a strong theoretical guarantee, suggesting that the authors should strengthen the article from this perspective. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The mention of \"minor comments\" about a spelling error in \"real word\" is unrelated to the main claim and does not contribute to the verifiability of the critique. Without additional evidence or detailed justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant concern about the ReCPE method being too strategic and lacking a strong theoretical guarantee. It suggests that the authors may be able to strengthen their article by addressing this issue, which is a valuable insight for improvement. However, the comment does not provide specific guidance or suggestions on how to enhance the theoretical foundation or what aspects need improvement. Additionally, it includes a minor comment about a spelling error, which, while helpful, does not significantly contribute to the overall feedback. The comment is somewhat helpful as it points out a critical area for improvement but lacks depth and actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the applicability of the work beyond NLU tasks, specifically asking if it can be applied to generation tasks. However, it does not provide any explicit or implicit guidance on how the authors should address this question or whether it is relevant to their work. The comment lacks actionable details, such as suggesting ways to explore or discuss this potential application. As a result, the authors are left without a clear understanding of what steps to take in response to this inquiry. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the work beyond NLU tasks, specifically asking if it can be applied to generation tasks. However, it does not specify which part of the paper this question pertains to, nor does it provide any details on what aspects of the work might be relevant to generation tasks. Without explicit references or specific guidance, the authors cannot confidently determine which part of the paper this comment addresses, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide any details on what needs to be addressed or improved regarding the application to generation tasks. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point is a question seeking clarification on the applicability of the work beyond NLU tasks, specifically asking if it can be applied to generation tasks. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the work beyond NLU tasks, specifically asking if it can be applied to generation tasks. While this question prompts the authors to consider the broader scope of their work, it lacks depth and does not provide any specific guidance or suggestions on how to address this question or explore its implications. The comment does not offer actionable feedback or insights that could help the authors improve their draft. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that $N_d$ is not defined and suggests that it would be beneficial to state explicitly that there could be a different number of observations per task. This provides a clear and direct action for the authors to take, which is to define $N_d$ and clarify the potential variation in observations per task. The comment is explicit and concrete, offering specific guidance on how to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l.145ff,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of $N_d$ not being defined and suggests that it would be beneficial to state explicitly that there could be a different number of observations per task. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that $N_d$ is not defined and suggests that it would be beneficial to explicitly state that there could be a different number of observations per task. This claim is straightforward and logical, as it points out a potential ambiguity in the paper. However, it lacks specific examples or references to support the suggestion, making it somewhat verifiable. The authors would need to infer the importance of defining $N_d$ and the potential impact of varying observations per task. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, namely that $N_d$ is not defined, and suggests that it would be beneficial to explicitly state that there could be a different number of observations per task. This feedback is clear and actionable, as it provides a direct suggestion for improvement that can help clarify the paper\\'s content. However, the comment could be more helpful if it offered additional context or examples of how this clarification might impact the reader\\'s understanding. Overall, the comment is mostly helpful, as it effectively guides the authors toward a specific improvement but could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the appendix is not cut from the main paper and that the provided PDF is a 14-page document. This feedback is clear and actionable, as it instructs the authors to ensure that the appendix is properly separated from the main paper. The comment provides a concrete action for the authors to take, which is to format the appendix correctly. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Appendix\" and the \"main paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of the appendix not being cut from the main paper and notes that the provided PDF is a 14-page document. This provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual statement regarding the formatting of the appendix and the main paper, noting that the appendix is not separated from the main paper and that the provided PDF is a 14-page document. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the formatting of the paper, noting that the appendix is not separated from the main paper and that the provided PDF is a 14-page document. This feedback is clear and actionable, as it instructs the authors to ensure that the appendix is properly formatted and separated from the main content. By addressing this issue, the authors can improve the organization and clarity of their paper. However, the comment could be more helpful if it provided additional guidance on how to format the appendix or suggested ways to improve the overall structure of the paper. Nonetheless, it provides a clear direction for improvement, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more insight into why the ternary potential is the main contributor to the improvement in the proposed model. It implies that the authors should clarify the role of the ternary potential and its impact on the model\\'s performance. However, the comment does not explicitly instruct the authors to include this information or provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the main improvement in the proposed model, which is attributed to the ternary potential, and suggests that the authors provide more insight into this aspect. The comment specifies what needs to be addressed, namely, the role of the ternary potential and its impact on the model\\'s performance. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main improvement in the proposed model comes from the ternary potential, as indicated by the results in Table 1. It suggests that without the ternary potential, the model does not outperform existing models for a 2-modalities setup, except for HieCoAtt. However, the comment does not provide specific data or detailed analysis to support this claim, making it somewhat verifiable. The authors would need to refer to Table 1 to understand the basis of the claim, which adds a layer of complexity to verifying the statement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific observation from the results in Table 1, suggesting that the main improvement in the proposed model comes from the ternary potential. It points out that without the ternary potential, the model does not outperform existing models for a 2-modalities setup, except for HieCoAtt. This feedback is somewhat helpful as it highlights a potential area of improvement and encourages the authors to provide more insight into the role of the ternary potential. However, the comment could be more helpful if it offered specific suggestions on how the authors might address this issue or provide additional analysis. Overall, the comment provides a clear direction for the authors to explore but lacks depth in terms of actionable guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should note which methods use data augmentations, what architecture they use, and what objective they employ, as this information would facilitate a more straightforward assessment of the comparisons in the tables. While the comment implies that this information is necessary, it does not explicitly instruct the authors to include it. The action is concrete, as it specifies the details that need to be added, but it is implicit, as the authors need to infer that they should include this information. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide additional information to facilitate the assessment of the comparisons in the tables. It implies that this information could include noting which methods use data augmentations, what architecture they use, and what objective they employ. However, the comment does not specify which tables or sections of the paper this information should be added to, making it weakly grounded. The suggestion is specific, as it details what information should be included, but the lack of explicit references to specific parts of the paper limits the comment\\'s grounding. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that noting which methods use data augmentations, what architecture they use, and what objective they employ would facilitate a more straightforward assessment of the comparisons in the tables. The comment provides a logical reasoning for why this information would be useful, as it highlights the importance of understanding the specifics of each method for accurate comparisons. However, the comment does not provide specific examples or references to support the claim, which could make it more challenging for the authors to fully understand the context. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the suggestion but lacks detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the clarity and comprehensiveness of the paper. It recommends noting which methods use data augmentations, what architecture they use, and what objective they employ, as this information would facilitate a more straightforward assessment of the comparisons in the tables. This feedback is actionable and constructive, as it identifies a clear area for improvement that could enhance the reader\\'s understanding of the paper. However, the comment could be more helpful if it included examples or further elaboration on why this information is crucial. Overall, the comment is mostly helpful, as it offers a valuable suggestion for enhancing the paper\\'s clarity and comprehensiveness.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the claim that hyperpruning methods would beat the state of the art, questioning the choice of architectures (LSTM and LSH networks) and the use of the PTB benchmark. It suggests that it would be interesting to see how LSH performs on actual state-of-the-art models and to test the hyperpruning method on more recent benchmarks and architectures. While the comment implies that the authors should consider these points, it does not explicitly instruct them to conduct these tests or analyses. The action is implicit and somewhat vague, as the authors can infer what needs to be done but may not be entirely sure of the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim that hyperpruning methods would beat the state of the art, specifically questioning the choice of architectures (LSTM and LSH networks) and the use of the PTB benchmark. It suggests that it would be interesting to see how LSH performs on actual state-of-the-art models and to test the hyperpruning method on more recent benchmarks and architectures. The comment is fully grounded as it explicitly mentions the claim about hyperpruning methods and the specific architectures and benchmarks being used. It is also specific because it clearly specifies what needs to be addressed, namely the choice of architectures and the use of the PTB benchmark. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the claim that hyperpruning methods would beat the state of the art, questioning the choice of architectures (LSTM and LSH networks) and the use of the PTB benchmark. The reviewer suggests that it would be interesting to see how LSH performs on actual state-of-the-art models and to test the hyperpruning method on more recent benchmarks and architectures. While the comment provides a logical reasoning for questioning the claim, it lacks specific references or examples to support the assertion that the chosen architectures are not state-of-the-art. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires further evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the claim that hyperpruning methods would beat the state of the art, questioning the choice of architectures (LSTM and LSH networks) and the use of the PTB benchmark. It suggests that it would be interesting to see how LSH performs on actual state-of-the-art models and to test the hyperpruning method on more recent benchmarks and architectures. This feedback is somewhat helpful as it identifies a potential weakness in the paper\\'s claims and provides a direction for further exploration. However, it could be more helpful if it offered specific suggestions on how to address these concerns or provided examples of state-of-the-art models to consider. Overall, the comment provides valuable insights but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include more experimental details, such as neural networks and hyperparameters, in the appendix. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be added to their draft. The comment is specific and concrete, offering a straightforward path for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more experimental details, such as neural networks and hyperparameters, should be included in the appendix. While it does not specify which part of the paper these details should be added to, the authors can infer that it relates to the experimental section. The comment is specific in its request for additional details but lacks full grounding as it does not explicitly mention the section or part of the paper where these details should be included. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experimental details, such as neural networks and hyperparameters, should be included in the appendix. This is a reasonable request for additional information to enhance the transparency and reproducibility of the study. However, the comment does not provide specific examples or reasoning to support why these details are crucial or how they would impact the understanding of the results. Without detailed justification or examples, the claim remains somewhat verifiable, as the authors would need to infer the importance of these details themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of more experimental details, such as neural networks and hyperparameters, in the appendix. This feedback is specific and directly addresses a potential area for enhancement, allowing the authors to take concrete steps to improve the transparency and reproducibility of their work. However, the comment could be more helpful if it explained why these details are important or how they would impact the understanding of the results. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional context or justification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that section 5.1 does not provide useful information regarding why the new model is superior. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on what specific information should be added or how the authors might improve the section to address the issue. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is that the section does not provide useful information regarding why the new model is superior. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that section 5.1 does not provide useful information regarding why the new model is superior. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with section 5.1, noting that it does not provide useful information regarding why the new model is superior. This feedback is somewhat helpful as it points out a potential weakness in the paper, prompting the authors to reconsider the content and presentation of this section. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address the issue or improve the section. While it highlights an area for improvement, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a comparison is necessary to evaluate the transferability of the single-IMP, implying that the authors should conduct this comparison. However, the comment does not provide specific guidance on how to conduct the comparison or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that a comparison is needed but may not know exactly how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a comparison is necessary to evaluate the transferability of the single-IMP, implying that the authors should consider this aspect. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a comparison for evaluating transferability, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a comparison is necessary to evaluate the transferability of the single-IMP, implying that the current analysis may not fully capture its capabilities. However, the comment does not provide specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support for the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment suggests that a comparison is necessary to evaluate the transferability of the single-IMP, implying that the current analysis may not fully capture its capabilities. This feedback is somewhat helpful as it identifies a potential area for improvement and suggests a specific action the authors could take to enhance their draft. However, the comment lacks depth and does not provide detailed guidance on how to conduct the comparison or what aspects to focus on. While it offers a direction for improvement, it does not fully support the authors in making the necessary changes. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that there are no specific ethical concerns with the proposed methods but suggests that the authors consider human-factors literature to improve the interaction with humans. While the comment implies that the authors should explore this area, it does not provide explicit guidance on how to incorporate this literature or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should look into human-factors literature and how to apply it to their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"No.03. 2020,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it acknowledges the absence of specific ethical concerns with the proposed methods and suggests that the authors consider human-factors literature to improve interaction with humans. The comment provides a clear direction for the authors to explore, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges the absence of specific ethical concerns with the proposed methods but suggests that the authors consider human-factors literature to improve interaction with humans. The comment is somewhat verifiable as it provides a logical suggestion for improvement, but it lacks specific examples or references to support the claim about the limitations of the proposed method. While the suggestion to explore human-factors literature is reasonable, the comment could be strengthened by providing more detailed guidance or examples of how this literature could be applied. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the absence of specific ethical concerns with the proposed methods but suggests that the authors consider human-factors literature to improve interaction with humans. It provides a clear direction for the authors to explore, which is helpful in guiding them towards a potential area of improvement. However, the comment could be more helpful if it offered specific examples or references from the human-factors literature that the authors should consider. Despite this, the feedback is mostly helpful as it provides a constructive suggestion for enhancing the paper. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the proposed model selection approach, questioning whether it can be applied beyond the MNIST-fashion dataset. It also suggests comparing the approach with other neural network pruning methods. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to conduct these experiments or comparisons. The action is implicit and somewhat vague, as the authors can infer the need for additional experiments but are not provided with specific guidance on how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the scalability of the proposed model selection approach, specifically questioning whether it can be applied beyond the MNIST-fashion dataset. It also suggests comparing the proposed approach with other neural network pruning methods. However, the comment does not specify which part of the paper discusses the experiments or the proposed model selection approach, making it weakly grounded. The authors can infer that it relates to the experimental section, but the lack of explicit reference makes it difficult to pinpoint. The comment is specific in suggesting additional experiments and comparisons, but without grounding, it is challenging for the authors to identify the exact parts that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the scalability of the proposed model selection approach, questioning whether it can be applied beyond the MNIST-fashion dataset. It also suggests comparing the proposed approach with other neural network pruning methods. However, the comment lacks specific examples or references to support the claim that the approach does not scale beyond MNIST-like datasets. Without detailed justification or evidence, the claim remains somewhat verifiable, as it provides a direction for further exploration but lacks concrete support. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the scalability of the proposed model selection approach, questioning whether it can be applied beyond the MNIST-fashion dataset. It also suggests comparing the proposed approach with other neural network pruning methods, which could provide a more comprehensive evaluation of the approach\\'s effectiveness. While the comment identifies a potential limitation and offers a direction for further exploration, it lacks specific guidance on how to conduct these comparisons or what specific aspects to focus on. The feedback is somewhat helpful as it points out an area for improvement but could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies several mathematical formulation issues and inconsistencies in the paper, providing specific line numbers and suggesting corrections. For example, it suggests replacing \"max\" with \"$max$\", clarifying the use of \"$i$-th objective\" instead of \"$j$\", and addressing inconsistent index notation. Additionally, it points out an unexplained variable in the hypervolume formula and suggests a correction for a distribution. These explicit and concrete suggestions provide the authors with clear actions to take to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific line numbers (e.g., Line 345, Line 347, Line 344, Line 374, Line 225, and Line 819) where the issues are identified. This allows the authors to accurately pinpoint the parts of the paper being addressed. The comment is also specific because it details the mathematical formulation issues and inconsistencies, such as suggesting corrections for index notation, clarifying the use of variables, and pointing out redundant elements in the hypervolume formula. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies several specific mathematical formulation issues and inconsistencies in the paper, providing detailed examples and line numbers where these issues occur. This level of detail allows the authors to understand and address each problem effectively. The comment is fully verifiable as it provides clear and specific evidence to support the claim of mathematical formulation issues, making it easy for the authors to verify and correct these errors. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment is highly helpful as it provides detailed and specific feedback on mathematical formulation issues and inconsistencies in the paper. It identifies multiple problems, such as incorrect notation, inconsistencies in index usage, and redundant variables, and suggests corrections for each issue. By pointing out these specific errors, the comment empowers the authors to make targeted improvements to their draft, ensuring that the mathematical formulations are accurate and consistent. The level of detail and actionable suggestions make this feedback highly valuable for the authors, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include experiments demonstrating the effect of using different numbers of particles. This is an explicit action, as it clearly instructs the authors to conduct additional experiments. However, the comment does not provide specific guidance on how to design these experiments or what parameters to test. While the action is explicit, the lack of concrete details on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting experiments to show the effect of using different numbers of particles, indicating that the current lack of such experiments makes it unclear how important this choice is. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure. The authors can infer that it relates to the experimental methodology or results section, but this inference is not direct. The comment is specific in suggesting the need for additional experiments but lacks grounding in terms of identifying the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be beneficial to include experiments demonstrating the effect of using different numbers of particles. However, the comment does not provide any specific reasoning, examples, or references to support why this is important or how it would impact the study. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include experiments to demonstrate the effect of using different numbers of particles. This is a clear and actionable suggestion that could help the authors better understand the importance of this choice and potentially improve their methodology. However, the comment could be more helpful if it provided specific guidance on how to design these experiments or what parameters to test. Despite this, the feedback is mostly helpful as it directs the authors to a potential area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of comparison between methods on plasticity evaluation metrics, specifically mentioning the covariance metric. While it identifies a gap in the paper, it does not provide explicit guidance on how to address this issue or suggest specific metrics or methods for comparison. The action is implicit, as the authors need to infer that they should include such comparisons, and it is vague because it lacks concrete details on how to implement this. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of comparison of methods on plasticity evaluation metrics, specifically referencing the covariance metric. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing, namely the comparison of methods on plasticity evaluation metrics, and references a specific metric, the covariance metric. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison of methods on plasticity evaluation metrics, specifically mentioning the covariance metric. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. The absence of detailed reasoning or specific examples makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, namely the lack of comparison of methods on plasticity evaluation metrics, such as the covariance metric. This feedback is clear and actionable, as it directs the authors to include such comparisons to enhance the comprehensiveness of their work. However, the comment could be more helpful if it provided suggestions on which specific metrics to use or how to conduct these comparisons. Despite this, the feedback is mostly helpful as it points out a clear area for improvement, guiding the authors toward enhancing the depth and breadth of their analysis.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to provide a better explanation for Table 5, specifically asking for clarification on what A, B, C, and D represent. It also requests an explanation of why positive paths lead to a monotonic solution and under what scenarios. This feedback is clear and direct, providing the authors with specific actions to take to improve their draft. The explicit nature of the instructions and the concrete details on what needs to be addressed make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests clarification on what A, B, C, and D represent in Table 5 and asks for an explanation of why positive paths lead to a monotonic solution and under what scenarios. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual questions and requests for clarification regarding Table 5, specifically asking for explanations about the labels A, B, C, and D, and the relationship between positive paths and monotonic solutions. These are descriptive statements that do not contain subjective opinions, claims, or suggestions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area in the paper that requires clarification, namely Table 5. It asks for an explanation of what A, B, C, and D represent in the table and requests further explanation on why positive paths lead to a monotonic solution and under what scenarios. This feedback is clear and actionable, as it directs the authors to provide additional context and clarity in their presentation. However, the comment could be more helpful if it suggested specific ways to present this information or provided examples of how similar issues have been addressed in other papers. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and comprehensiveness of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the time it takes to obtain a single US accuracy and suggests exploring proxy or surrogate methods for a cheaper estimation. It also questions the reliability of early predictions of US accuracy based on the saturation of the curve in Figure 1. Additionally, it asks how power law prediction can be used for model selection in practice, referencing specific figures in the Appendix. While the comment identifies areas for potential improvement and raises questions, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, as the authors need to infer what specific changes or explorations are needed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Appendix Fig. F6, F7, F8, F9,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the curve being saturated only towards the end, questioning the reliability of early predictions of US accuracy and suggesting the use of power law prediction for model selection. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the time it takes to obtain a single US accuracy and suggests exploring proxy or surrogate methods for a cheaper estimation. It also questions the reliability of early predictions of US accuracy based on the saturation of the curve in Figure 1. The comment provides a logical reasoning by pointing out the saturation of the curve, which implies that early predictions may not be reliable. However, it lacks specific examples or references to support the claim about the feasibility of using power law prediction for model selection. While the comment provides some justification, it could be strengthened with more detailed evidence or examples, making it mostly verifiable. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a practical concern about the time it takes to obtain a single US accuracy and suggests exploring proxy or surrogate methods for a cheaper estimation. It also questions the reliability of early predictions of US accuracy based on the saturation of the curve in Figure 1. Additionally, the comment asks how power law prediction can be used for model selection in practice, referencing specific figures in the Appendix. This feedback is somewhat helpful as it identifies a potential issue with the current approach and suggests an area for improvement. However, it lacks specific guidance or suggestions on how to address these concerns, such as proposing alternative methods or providing examples of how to implement power law prediction. While it points out areas for improvement, it does not fully support the authors in making those improvements, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to conduct ablation studies to isolate the impact of specific factors contributing to epsilon sampling\\'s strong performance. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete suggestion, leaving no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting ablation studies to isolate the impact of specific factors contributing to epsilon sampling\\'s strong performance. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to these sections, the authors may find it challenging to determine where to implement the suggested ablation studies. The comment is specific in its request for ablation studies but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting ablation studies to isolate the impact of specific factors contributing to epsilon sampling\\'s strong performance. However, it does not provide any reasoning, examples, or references to support why these ablation studies are necessary or how they would contribute to the understanding of the results. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting ablation studies to isolate the impact of specific factors contributing to epsilon sampling\\'s strong performance. This is a clear and actionable suggestion that can help the authors better understand and communicate the effectiveness of their approach. By providing ablation studies, the authors can gain insights into which factors are most critical to the success of epsilon sampling, allowing them to refine their methodology and present more robust results. However, the comment could be more helpful if it specified which factors should be isolated or provided guidance on how to design the ablation studies. Overall, the feedback is mostly helpful as it offers a constructive direction for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point references a specific publication, \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" and suggests that the authors should consider how their proposed attack performs against the mode connectivity-based defense proposed in this paper. While the comment implies that the authors should conduct this analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to conduct the analysis or what specific aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific publication, \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" which allows the authors to identify the relevant part of the paper being addressed. It also specifies what needs to be addressed, namely, how well the proposed attack performs against the mode connectivity-based defense proposed in the ICLR paper. This provides clear guidance on what the authors should focus on to improve their work. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point references a specific publication, \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" to support the claim that Fine-Tuning is not the most effective approach to recover backdoor models without sufficient clean data. The reviewer suggests that the proposed attack should be evaluated against the mode connectivity-based defense proposed in the ICLR paper. While the reference to the publication provides some context, the comment lacks detailed reasoning or specific examples of how the proposed attack might perform against the referenced defense. This makes the claim somewhat verifiable, as it provides a basis for the suggestion but requires further elaboration for full understanding.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment references a specific publication, \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" which provides context for evaluating the effectiveness of the proposed attack. It suggests that the authors should consider how their attack performs against the mode connectivity-based defense proposed in the referenced paper. This feedback is clear and actionable, as it directs the authors to a specific area of comparison that could enhance the robustness of their work. However, the comment could be more helpful if it provided additional guidance on how to conduct this evaluation or what specific aspects to focus on. Overall, the comment is mostly helpful, as it offers a valuable direction for improvement but could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point criticizes the authors for not including codes during the review process, which makes the claims less transparent. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what steps to take to improve transparency. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment criticizes the authors for not including codes during the review process, which makes the claims less transparent. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. Without explicit references to specific sections or elements of the paper, the authors cannot confidently determine where to address this concern. Additionally, the comment lacks specificity regarding what aspects of the claims are less transparent due to the absence of codes. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors\\' choice of not including codes during the review process makes the claims less transparent. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the absence of codes affects transparency. Without additional context or explanation, the claim remains unsubstantiated, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the transparency of the paper due to the absence of codes during the review process. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve the transparency of their claims. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should validate their proposed approach in Waymax, which offers more traffic scenarios compared to the current version. This is an explicit action with concrete guidance on how to improve the draft by expanding the validation scope. The authors know exactly what needs to be done to enhance their work, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that \"3\" is not necessary and encourages the authors to validate their proposed approach in Waymax, which provides more traffic scenarios. However, it does not specify which part of the paper \"3\" refers to, making it weakly grounded. The comment is specific in suggesting an additional validation step using Waymax, but without clear grounding, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should validate their proposed approach in Waymax, which provides more traffic scenarios compared to the current version. However, the comment does not provide any reasoning or evidence to support why this validation is necessary or how it would improve the paper. Without specific examples or justification, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that a particular aspect of the paper, labeled as \"3,\" is not necessary. It also encourages the authors to validate their proposed approach in Waymax, which offers more traffic scenarios compared to the current version. This feedback is somewhat helpful as it identifies a potential area for improvement and provides a specific suggestion for enhancing the validation of the proposed approach. However, the comment could be more helpful if it explained why \"3\" is not necessary or how the validation in Waymax would benefit the paper. Overall, the feedback is actionable but incomplete, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the technical contribution of the paper, suggesting that it is not significant due to the use of a transformer-based TAPG method that has been studied in previous works like RTD-Net. The reviewer highlights the main difference as the consideration of 3D pose and action features obtained by Laban Movement Analysis (LMA), but notes that LMA has been proven effective in dance action recognition, making the additional features not particularly surprising. The comment implies that the choice of additional features may not bring enough insights to the community. However, it does not provide explicit guidance or suggestions on how the authors could enhance their contribution or address the critique. The action is implicit and vague, leaving the authors without a clear path for improvement. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the technical contribution of the paper, suggesting that it is not significant due to the use of a transformer-based TAPG method that has been studied in previous works like RTD-Net. It highlights the main difference as the consideration of 3D pose and action features obtained by Laban Movement Analysis (LMA), but notes that LMA has been proven effective in dance action recognition, making the additional features not particularly surprising. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing the critique of the technical contribution, but without clear references to specific sections or elements of the paper, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical contribution of the paper is not significant, suggesting that the use of a transformer-based TAPG method has been studied in previous works like RTD-Net. The reviewer provides a logical reasoning by highlighting the main difference between RTD-Net and the proposed method, which is the consideration of 3D pose and action features obtained by Laban Movement Analysis (LMA). However, the comment also acknowledges that LMA has been proven effective in dance action recognition, which somewhat diminishes the novelty of the additional features. While the comment provides a logical framework for its claim, it lacks specific references or detailed examples to fully substantiate the assertion. Therefore, the claim is somewhat verifiable, as it provides a basis for the critique but could be strengthened with more detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the technical contribution of the paper, suggesting that it is not significant due to the use of a transformer-based TAPG method that has been studied in previous works like RTD-Net. The reviewer highlights the main difference as the consideration of 3D pose and action features obtained by Laban Movement Analysis (LMA), but notes that LMA has been proven effective in dance action recognition, making the additional features not particularly surprising. This feedback provides some insight into the potential lack of novelty in the paper's contribution, but it lacks specific suggestions or guidance on how the authors might enhance their work or address the critique. The comment is somewhat helpful as it identifies a potential weakness, but it does not offer actionable advice for improvement, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the implementation of tree construction requires more experimental comparisons to evaluate the different design choices of merging nodes among adjacent layers. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on how to design these experiments or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to conduct more experiments but may not know exactly how to proceed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the implementation of tree construction and suggests that more experimental comparisons are needed to evaluate the different design choices of merging nodes among adjacent layers. However, it does not specify which part of the paper discusses this implementation or where these design choices are presented. This makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in suggesting the need for more experimental comparisons, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experimental comparisons are needed to evaluate the different design choices of merging nodes among adjacent layers in the implementation of tree construction. However, the comment does not provide any specific reasoning, examples, or references to support why these comparisons are necessary or how they would improve the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the implementation of tree construction, namely the need for more experimental comparisons to evaluate the different design choices of merging nodes among adjacent layers. This feedback is clear and actionable, as it directs the authors to conduct additional experiments to better understand and justify their design choices. However, the comment could be more helpful if it provided specific suggestions on how to design these experiments or what aspects to focus on. Despite this, the feedback is mostly helpful as it guides the authors toward a meaningful enhancement of their work. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that Table 2 in the paper is incomplete and that the authors should report additional baselines that outperform the current results, as mentioned in the Re-BART paper. The comment provides clear guidance on what needs to be done, which is to include these additional baselines in the table for completeness. This feedback is direct and concrete, giving the authors a clear understanding of the action required to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of incompleteness and the need to include additional baselines that outperform the current results, as reported in the Re-BART paper. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 2 in the paper is incomplete and that it hides several baselines that outperform it. The reviewer supports this claim by referencing the Re-BART paper, which suggests that these baselines are reported there. This provides a basis for the claim, as it references an external source that corroborates the assertion. However, the comment could be strengthened by providing more detailed information about the specific baselines or results mentioned in the Re-BART paper. Overall, the claim is mostly verifiable, as it offers a reasonable basis for the assertion but could benefit from more specific references or examples. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 2 in the paper, noting that it is incomplete and that several baselines that outperform the current results are not reported. The reviewer suggests that these baselines, as reported in the Re-BART paper, should be included for completeness, even though their results are slightly weaker. This feedback is clear and actionable, providing the authors with a direct suggestion to enhance the completeness and transparency of their results. By addressing this issue, the authors can improve the robustness and credibility of their findings. Therefore, the comment is rated as highly helpful, as it offers specific guidance that can significantly enhance the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the thoroughness of the evaluations on real datasets, specifically questioning the choice of only three scenes from the HS-ERGB dataset and asking about the performance on other sequences. While the comment implies that the authors should provide more comprehensive evaluations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to expand their evaluations but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the thoroughness of the evaluations on real datasets, specifically questioning the choice of only three scenes from the HS-ERGB dataset and asking about the performance on other sequences. However, it does not specify which part of the paper these evaluations are discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its questioning of the evaluation methodology but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the thoroughness of the evaluations on real datasets, specifically asking why only three scenes are chosen from the HS-ERGB dataset and inquiring about the performance on other sequences. This is a logical question that seeks clarification on the methodology used in the evaluation. However, it does not contain a subjective claim or opinion that requires verification. It is a factual inquiry, making it a normal statement. Therefore, the label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a valid question about the thoroughness of the evaluations on real datasets, specifically questioning the choice of only three scenes from the HS-ERGB dataset and asking about the performance on other sequences. This feedback is somewhat helpful as it prompts the authors to consider expanding their evaluation to include more scenes or sequences, which could provide a more comprehensive understanding of their method\\'s performance. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional datasets or sequences to evaluate. Therefore, while it identifies a potential area for improvement, it could be more helpful with additional details or actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two concerns: first, it suggests that the use of 44 bits is too small and that more bits could be used without affecting computation time on a GPU. Second, it questions the interpretation of bit-embeddings, suggesting that the model is predicting the rank of words rather than their semantic relations. The comment implies that the authors should explore using more bits and provide a clearer interpretation of the bit-embeddings. However, it does not explicitly instruct the authors to do so, leaving the action implicit. The feedback is somewhat actionable as it provides a direction for improvement but lacks concrete guidance on how to implement the suggested changes.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific aspects of the paper, such as the use of 44 bits and the interpretation of bit-embeddings. However, it does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the use of 44 bits and the interpretation of bit-embeddings, including the observation that the model predicts the rank of words rather than their semantic relations. This provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two claims: first, that using 44 bits is too small and that more bits could be used without affecting computation time on a GPU; second, that the model is predicting the rank of words rather than their semantic relations, and questions the interpretation of bit-embeddings. The first claim is somewhat verifiable as it provides a logical reasoning about the potential for using more bits without impacting computation time. However, it lacks specific examples or references to support the claim fully. The second claim is also somewhat verifiable as it raises a logical observation about the model\\'s behavior, but it lacks detailed reasoning or evidence to fully substantiate the claim. Overall, the comment is somewhat verifiable, as it provides a basis for the claims but requires further elaboration for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two distinct concerns that could help the authors improve their draft. First, it suggests that the use of 44 bits might be too small and that more bits could be used without affecting computation time on a GPU, which could be an area for exploration. Second, it questions the interpretation of bit-embeddings, noting that the model is predicting the rank of words rather than their semantic relations, and raises a concern about the lack of semantic relations among words with odd ranks. This feedback is mostly helpful as it identifies specific areas for improvement and provides a direction for the authors to consider, such as exploring the use of more bits and clarifying the interpretation of bit-embeddings. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these issues. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the proposed method, specifically the need for human annotation to provide semantically meaningful information, which can be subjective. The authors acknowledge this limitation in the appendix but do not offer any solutions for mitigation. While the comment identifies a problem, it does not provide explicit guidance or suggestions on how the authors might address this issue. The action is implicit, as the authors are left to infer that they should propose a solution or discuss potential mitigations, but the comment lacks concrete details on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the practical use of the proposed method, specifically the need for human annotation to provide semantically meaningful information, which can be subjective. The authors mention this limitation in the appendix, but the comment points out that no solution for mitigation is provided. This provides some specificity about what needs to be addressed, namely the lack of a solution for mitigating the subjectivity of human annotation. However, the comment does not specify which part of the appendix this issue is discussed in, making it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method requires human annotation for semantically meaningful information, which can be subjective. The authors acknowledge this limitation in the appendix but do not provide a solution for mitigation. The comment highlights a potential issue with the practical application of the method, but it lacks specific examples or detailed reasoning to fully substantiate the claim. While it points out a limitation, the lack of additional evidence or detailed explanation makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the proposed method, specifically the need for human annotation to provide semantically meaningful information, which can be subjective. This is acknowledged by the authors in the appendix, but the comment points out that no solution or mitigation is provided. While the comment highlights a critical issue, it lacks specific suggestions or guidance on how the authors might address this limitation or improve the method. Providing actionable feedback or potential solutions would enhance the comment\\'s helpfulness. Therefore, the comment is somewhat helpful, as it directs the authors\\' attention to a crucial area for improvement but does not offer detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit instructions on what the authors should do to improve their draft. It suggests pretraining a CausalLM using a specific dataset and comparing its performance against ObscuraCoder to attribute any improvements to the deobfuscation objective. The actions are clear and concrete, leaving no ambiguity for the authors on how to implement the suggested changes. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment provides specific instructions on what the authors should do to improve their draft, such as pretraining a CausalLM using a specific dataset and comparing its performance against ObscuraCoder. However, it does not explicitly mention which part of the paper these actions should be taken from, making it weakly grounded. The comment is specific in detailing the actions needed, but without clear grounding, the authors may struggle to identify the exact sections that require these changes. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests a specific experimental approach to evaluate the effectiveness of the deobfuscation objective. It provides a clear and actionable suggestion for the authors to pretrain a CausalLM using a mixed dataset and compare its performance against ObscuraCoder. This recommendation is well-supported by logical reasoning, as it aims to isolate the impact of the deobfuscation objective on performance. However, the comment does not provide specific references or detailed examples of how this approach would be beneficial or how it relates to existing literature. Therefore, the claim is mostly verifiable, as it provides a clear direction but lacks detailed justification or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting a concrete experiment to evaluate the effectiveness of the deobfuscation objective. It recommends pretraining a CausalLM using a mixed dataset and comparing its performance against ObscuraCoder to conclusively attribute any improvements to the deobfuscation objective. This feedback is clear and detailed, offering a direct path for the authors to improve their draft by providing empirical evidence for their claims. The suggestion is well-structured and provides a clear direction for the authors to follow, making it highly helpful. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to add the geometric loss to the reconstruction loss in the loss equation shown in lines 264-266. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be changed, making it highly actionable. The authors know exactly what modification to make and how to apply it, ensuring that the feedback is actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L264-L266,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, namely adding the geometric loss to the reconstruction loss. This provides clear guidance on how to improve the draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a minor adjustment to the loss equation by adding the geometric loss to the reconstruction loss. However, it does not provide any reasoning or justification for why this change is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the loss equation in the paper, suggesting that the geometric loss should be added to the reconstruction loss. This feedback is clear and actionable, providing the authors with a precise direction for improvement. By addressing this minor issue, the authors can enhance the accuracy and completeness of their loss function, which is a valuable contribution to the paper. However, the comment could be more helpful if it explained why this change is necessary or how it impacts the overall analysis. Nonetheless, the feedback is mostly helpful as it offers a concrete suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method (MLM) should be employed in autoregressive language models, which are used more in real-world applications. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to implement this suggestion or what specific changes should be made to the draft. The comment lacks concrete details, leaving the authors uncertain about how to address the issue. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the method (MLM) should be employed in autoregressive language models, which are used more in real-world applications. However, it does not specify which part of the paper this suggestion pertains to, nor does it provide details on how to implement this suggestion. The authors cannot confidently determine which section of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide clear guidance on what needs to be addressed or how to incorporate MLM into autoregressive language models. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the method (MLM) should be employed in autoregressive language models, which are used more in real-world applications. However, the comment lacks any supporting evidence, reasoning, or references to justify why this is necessary or beneficial. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the method (MLM) should be employed in autoregressive language models, which are used more in real-world applications. While it highlights an important point about the relevance of MLM in real-world applications, the comment lacks specificity and does not provide actionable guidance on how to incorporate MLM into autoregressive language models or what specific improvements would be beneficial. The feedback is somewhat helpful as it points out a potential area for expansion, but it does not offer detailed suggestions or examples to aid the authors in making improvements. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the claim that the GAN is difficult to optimize and suggests that the proposed idea is not clearly better than GAN. It also questions how the proposed method avoids the issue of vanishing gradients and model collapsing. While the comment identifies areas that need clarification and improvement, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The authors are left to infer that they need to provide more detailed explanations and comparisons, but the comment lacks specific guidance on how to do so. Therefore, the comment is somewhat actionable, as it highlights areas for improvement but does not provide detailed steps for execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim that the GAN is difficult to optimize and the proposed idea is better than GAN. It questions the clarity of this claim and the method\\'s ability to avoid issues like vanishing gradients and model collapsing. However, the comment does not specify which part of the paper discusses these claims or where the proposed method is described, making it weakly grounded. The authors can infer that it relates to the method section, but this inference is not direct. The comment is specific in detailing what needs to be addressed, such as providing more clarity on the proposed method\\'s advantages and addressing the issue of vanishing gradients and model collapsing. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that the GAN is difficult to optimize and suggests that the proposed idea is not clearly better than GAN. It also raises concerns about the method\\'s ability to avoid issues like vanishing gradients and model collapsing. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The absence of concrete evidence or detailed explanations makes it difficult for the authors to understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claims but lacks sufficient detail to fully substantiate them.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a critical point about the claim that the GAN is difficult to optimize and suggests that the proposed idea is not clearly better than GAN. It questions the clarity of this claim and the method\\'s ability to avoid issues like vanishing gradients and model collapsing. This feedback is somewhat helpful as it identifies a potential weakness in the paper\\'s argument and prompts the authors to provide more detailed explanations and comparisons. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how to improve the clarity of the proposed method. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind the ablation study, specifically asking why the ablations were designed on BART and BART+Longformer instead of the original model, GraphSum. While the comment raises a valid question, it does not provide explicit guidance or suggestions for the authors to address this issue. The authors are left to infer that they should reconsider their ablation study design, but without concrete instructions on how to do so. This makes the comment somewhat actionable, as it highlights an area for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study\" and questions the choice of models used for the ablation, specifically asking why BART and BART+Longformer were chosen instead of the original model, GraphSum. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the rationale behind the choice of models for the ablation study. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the rationale behind the choice of models for the ablation study, specifically asking why BART and BART+Longformer were chosen instead of the original model, GraphSum. This is a factual question seeking clarification, as it does not express an opinion or make a subjective claim. It is purely descriptive and does not require verification, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind the choice of models for the ablation study, specifically why BART and BART+Longformer were selected instead of the original model, GraphSum. This feedback is somewhat helpful as it prompts the authors to reconsider their experimental design and provide a clear justification for their choices. However, the comment lacks depth and does not offer specific suggestions or guidance on how to address this issue or improve the study. While it identifies a potential area for improvement, it does not provide actionable steps for the authors to take, limiting its helpfulness. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the removal of the previous report of SciBERT and its impact on the analysis of model outcomes. However, it does not provide any explicit or implicit actions for the authors to take. The comment acknowledges that the issue is not entirely fair to write as a weakness since the current paper does not mention it, but it does not offer any guidance on how the authors might address this issue or improve their draft. As a result, the comment lacks actionable advice, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the removal of the previous report of SciBERT and its impact on the analysis of model outcomes. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing the problem with the cursory and unsupported analyses, but it does not provide guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the removal of the previous report of SciBERT exacerbates the earlier problem of cursory and unsupported analyses in the outcomes of the models. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The lack of evidence or references leaves the claim somewhat verifiable, as it requires more information to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the removal of the previous report of SciBERT and its impact on the analysis of model outcomes. It acknowledges that the current paper does not mention this issue, which somewhat mitigates the critique. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their analysis. While it highlights a potential weakness, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and actionable advice.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the origin of the \"connectivity graph\" and the clarity of the section regarding the source of patches and their mixing. While it identifies areas that need clarification, it does not provide explicit instructions or suggestions on how the authors should address these issues. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Functional connectivity encoder\" and the connectivity graph $\\cal{G}_{F}$, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the section, such as the unclear origin of the graph and the difficulty in discerning the source of patches and their mixing. This provides clear guidance on what needs to be clarified or improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the origin of the \"connectivity graph\" and the clarity of the section regarding the source of patches and their mixing. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The lack of detailed explanation or examples makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific areas of confusion in the paper, namely the origin of the \"connectivity graph\" and the clarity of the section regarding the source of patches and their mixing. By pointing out these issues, the comment provides the authors with clear guidance on what aspects of their draft need improvement. However, it could be more helpful if it offered suggestions or examples on how to clarify these points. Despite this, the comment is mostly helpful as it directs the authors to focus on enhancing the clarity and transparency of their work. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the interpretation of Figure 4(b) and suggests that the proposed method does not necessarily result in faster training, given that all networks are trained for the same number of epochs. It also implies that the paper could benefit from a more in-depth discussion of related work in the field of pruning. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they should clarify the interpretation of Figure 4(b) and expand the discussion of related work. However, the lack of specific guidance makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4(b),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the interpretation of the figure, specifically regarding the claim that the proposed method results in faster training, and suggests that the paper would benefit from a longer discussion of related work in the field of pruning. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that Figure 4(b) indicates the proposed method results in faster training, given that all networks are trained for the same number of epochs. The reviewer suggests that this interpretation is \"a bit far-fetched\" and implies that the paper lacks a thorough discussion of related work in the field of pruning. While the comment raises a valid concern about the interpretation of the figure, it does not provide specific examples or references to support the claim that the paper lacks a comprehensive discussion of related work. The reasoning is somewhat verifiable, as it highlights a potential issue but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the interpretation of Figure 4(b), questioning whether it accurately indicates that the proposed method results in faster training. It also suggests that the paper could benefit from a longer discussion of related work in the field of pruning. While the comment highlights a specific area for improvement, it lacks detailed guidance on how to address the issue or expand the discussion of related work. The feedback is somewhat helpful as it points out a potential weakness and a direction for improvement, but it could be more actionable with specific suggestions or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific error in the paper, stating that the derivative of the \"Lagrangian\" is incorrect. It provides a clear and concrete correction, specifying that the derivative of n^{-1/2} is -1/2n^{-3/2} rather than 1/2n^{-3/2}, and notes that the minus sign is omitted. This feedback is direct and provides precise guidance on what needs to be corrected in the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"derivative of the \\'Lagrangian,\\'\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error in the derivative, providing a precise correction. This level of detail helps the authors understand what needs to be corrected, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the derivative of the \"Lagrangian\" is incorrect, specifying that the derivative of n^{-1/2} is -1/2n^{-3/2} rather than 1/2n^{-3/2}. This claim is supported by a clear and precise mathematical correction, providing a logical and straightforward justification for the critique. The comment is fully verifiable as it offers a specific and detailed explanation of the error, allowing the authors to easily understand and address the issue. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific mathematical error in the paper, namely the incorrect derivative of the \"Lagrangian.\" It provides a clear and precise correction, specifying that the derivative of n^{-1/2} is -1/2n^{-3/2} rather than 1/2n^{-3/2}, and notes the omission of the minus sign. This feedback is highly actionable as it directly points out a critical mistake that needs to be corrected, allowing the authors to make a precise adjustment to their draft. The comment is clear, specific, and provides a detailed suggestion for improvement, making it highly helpful for the authors. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the introduction part lacks sufficient background information about cognitive models, implying that the authors should refine their writing to improve clarity. However, it does not provide specific guidance on what aspects of the background need to be included or how the writing should be refined. The action is implicit and somewhat vague, as the authors can infer that they need to add more background information but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the introduction part lacks clarity regarding the background of cognitive models, implying that the authors should refine their writing. However, it does not specify which part of the introduction is unclear or what specific aspects of the background are missing. The authors can make an educated guess that it relates to the introduction, but the comment lacks full grounding as it does not explicitly mention sections or elements. Additionally, the comment is not specific about what needs to be addressed or how the writing should be refined. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the introduction part lacks clarity regarding the background of cognitive models, suggesting that the authors need to refine their writing. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references to particular sections or aspects of the introduction that are unclear, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered unverifiable due to the lack of supporting evidence or detailed justification.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the clarity of the introduction, specifically noting that it lacks sufficient background information about cognitive models. It suggests that the authors should refine their writing to improve this aspect. However, the comment does not provide specific guidance on what aspects of the background are missing or how the writing could be improved. While it highlights an area for improvement, the feedback lacks depth and actionable suggestions, making it somewhat helpful. The authors are given a general direction but not detailed steps to enhance their draft. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the performance of DFA compared to backprop on the NLP task, suggesting that this difference is not adequately emphasized in the paper. The reviewer notes that the abstract gives the impression that DFA performs similarly to backprop on this task, which is not the case. While the comment identifies an issue with the presentation of results, it does not provide explicit guidance on how the authors should address this discrepancy or how to rephrase the abstract to accurately reflect the performance differences. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the performance differences but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"NLP task\" and \"DFA performance,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a discrepancy in performance between DFA and backprop on the NLP task, suggesting that this difference is not adequately emphasized in the paper. The comment further specifies that the abstract gives readers an incorrect impression of DFA\\'s performance on this task. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that DFA performance lags behind backprop performance on the NLP task, which is not sufficiently emphasized in the paper. The reviewer provides a specific example from the abstract, suggesting that it gives readers an incorrect impression of DFA\\'s performance. This claim is somewhat verifiable as it is based on a logical observation of the performance difference and a critique of the abstract\\'s representation. However, the comment could be strengthened by providing more detailed comparisons or references to support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in the paper, noting that the performance of DFA on the NLP task is not adequately emphasized. It points out that the abstract gives readers an incorrect impression of DFA\\'s performance on this task, suggesting that it performs similarly to backprop, which is not the case. This feedback is clear and actionable, as it directs the authors to revisit their presentation of results and ensure that the abstract accurately reflects the performance differences. However, the comment could be more helpful if it provided suggestions on how to rephrase the abstract or highlight the performance differences more effectively. Overall, the comment is mostly helpful as it guides the authors to improve the clarity and accuracy of their results presentation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack in the baseline, specifically mentioning the need to include SRW and FROT as baselines for dimensional reduction methods in optimal transport estimation. While the comment identifies a specific action\u2014adding these baselines\u2014it does not provide detailed guidance on how to implement this change or why these specific baselines are important. The authors are left with a clear direction but without concrete steps on how to execute it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"baseline\" and \"dimensional reduction methods in optimal transport estimation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need to include SRW and FROT as baselines, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the baseline is lacking, specifically for dimensional reduction methods in optimal transport estimation. It provides an example by mentioning SRW and FROT, which are mentioned in the paper, and suggests that they should be included as baselines. This claim is somewhat verifiable as it provides specific examples of what is missing from the baseline, but it lacks detailed reasoning or references to support why these specific methods are important or how they would enhance the baseline. The authors would need to infer the importance of these methods based on the context of the paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the paper, namely the lack of a comprehensive baseline for dimensional reduction methods in optimal transport estimation. It provides a clear suggestion by mentioning SRW and FROT as examples of methods that should be included as baselines. This feedback is actionable and provides the authors with a concrete direction for improving their draft by enhancing the baseline comparison. However, the comment could be more helpful if it offered additional context or explanation about why these specific methods are important or how they relate to the paper\\'s contributions. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the advantage and disadvantage of transductive learning have not been discussed. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on what aspects of transductive learning should be discussed or how to present them. Without specific instructions or examples, the authors are left without a clear understanding of what changes are needed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out that the advantage and disadvantage of transductive learning have not been discussed. However, it does not specify which part of the paper this issue pertains to, such as a section or chapter where this topic should be addressed. Without explicit references or context, the authors cannot confidently determine where to make these discussions. Additionally, the comment lacks specificity regarding what aspects of transductive learning should be discussed or how they should be framed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the advantage and disadvantage of transductive learning have not been discussed. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the discussion regarding the advantages and disadvantages of transductive learning. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. Without actionable feedback or examples, the authors are left without a clear understanding of what changes are needed to improve their draft. This makes the comment barely helpful, as it highlights a potential area for improvement but does not offer any concrete steps for the authors to take.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the invariance of the contractivity should be stated formally. While it implies that the authors should include a formal statement of invariance, it does not provide specific guidance on how to do so or what aspects of the contractivity should be emphasized. The action is implicit and somewhat vague, as the authors can infer the need for a formal statement but may not know exactly how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the invariance of the contractivity should be stated formally. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or equation where the contractivity is discussed. Without explicit references or context, the authors may find it challenging to identify the exact area needing attention. The comment is specific in its request for formalization but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the invariance of the contractivity should be stated formally. However, it does not provide any reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the invariance of the contractivity should be stated formally, which is a specific and actionable piece of feedback. By making this suggestion, the reviewer provides the authors with a clear direction for improving their draft, as it highlights an area where the paper could be strengthened. However, the comment could be more helpful if it offered additional guidance on how to formalize the invariance or what specific aspects of the contractivity should be emphasized. Despite this, the feedback is mostly helpful as it directs the authors toward a meaningful improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the lack of application or evaluation of uncertainty saliency maps, which makes their significance unclear. It also disagrees with the notion that uncertainty or confidence generated from the same mechanism as the explanation is more trustworthy than the explanation itself. However, the comment does not provide specific guidance or suggestions on how the authors might address these concerns or improve their draft. It lacks actionable details, such as recommending additional experiments or evaluations to demonstrate the significance of uncertainty saliency maps. Without explicit instructions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the potential contribution of uncertainty saliency maps but expresses concern about their significance due to the lack of an application or evaluation. It also disagrees with the notion that uncertainty or confidence generated from the same mechanism as the explanation is more trustworthy than the explanation itself. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The authors can infer that it relates to the sections discussing uncertainty saliency maps or explanations, but this inference is not direct. The comment is specific in detailing the concerns about the lack of application and the trustworthiness of the explanation mechanism. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the significance of uncertainty saliency maps is unclear due to the lack of an application or evaluation. It also disagrees with the notion that uncertainty or confidence generated from the same mechanism as the explanation is more trustworthy than the explanation itself. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the concerns. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically the lack of application or evaluation of uncertainty saliency maps, which makes their significance unclear. It also expresses disagreement with the notion that uncertainty or confidence generated from the same mechanism as the explanation is more trustworthy than the explanation itself. However, the comment does not provide specific suggestions or guidance on how the authors might address these concerns or improve their draft. Without actionable feedback or detailed recommendations, the authors are left without a clear path to enhance their work. Therefore, the comment is barely helpful, as it highlights a weakness but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the lack of discussion on the importance of using a diffusion model in style transfer. It questions what unique benefits the diffusion model provides that other methods cannot. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific aspects of the diffusion model should be discussed. The action is implicit and vague, leaving the authors to infer that they need to discuss the benefits of the diffusion model but without clear direction on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the lack of discussion on the importance of using a diffusion model in style transfer. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its request for an explanation of the benefits of the diffusion model, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the importance of using a diffusion model in style transfer, specifically asking what benefits it provides that other methods cannot. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to address the question effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the discussion regarding the importance of using a diffusion model in style transfer. It questions what unique benefits the diffusion model provides that other methods cannot, which is a relevant and important aspect to address in the paper. However, the comment lacks specific suggestions or guidance on how the authors might explore or discuss this issue further. While it highlights a potential area for improvement, it does not provide actionable steps or detailed feedback, making it somewhat helpful. The authors are left with a general direction but without concrete advice on how to enhance their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a discussion or comparison in the related work section to enhance understanding of the multi-view effect. While the comment implies that this would be beneficial, it does not explicitly instruct the authors to make this change. The action is implicit and somewhat vague, as the authors are not provided with specific guidance on how to conduct the discussion or comparison. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that a discussion or comparison in the related work section would enhance understanding of the multi-view effect. It implies that the multi-view latent attack enhances the model\\'s meta generalizability and outperforms other Adversarial Meta-Learning methods in the cross-domain setting. However, it does not specify which part of the paper this discussion should be added to, making it weakly grounded. The comment is specific in suggesting a comparison with task augmentation meta-learning methods, but it lacks detailed guidance on how to conduct this comparison. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the multi-view latent attack enhances the model\\'s meta generalizability and outperforms other Adversarial Meta-Learning methods in the cross-domain setting. It also suggests that the multi-view training is similar to task augmentation meta-learning methods. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and verify the basis of the comparison. The mention of references [1,2,3] is not sufficient to substantiate the claim, as it does not provide detailed information about how these references relate to the claim. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks detailed evidence or examples.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a constructive suggestion for enhancing the paper by proposing a discussion or comparison in the related work section. It highlights the potential benefits of the multi-view latent attack in terms of meta generalizability and its similarity to task augmentation meta-learning methods. This feedback is actionable as it directs the authors to a specific area where they can improve the clarity and depth of their work. However, the comment could be more helpful if it included specific examples or references to guide the authors in conducting this comparison. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the impact of Age and FaceID features is not studied in the ablation. While it identifies a specific area that needs attention, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to include the study of these features in the ablation. The action is implicit and somewhat vague, as the authors can infer that they need to include an analysis of these features but are not given concrete instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Age and FaceID features,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely, the study of the impact of these features in the ablation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the impact of Age and FaceID features is not studied in the ablation. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks analysis, namely, the impact of Age and FaceID features in the ablation. This feedback is clear and actionable, as it directs the authors to include an analysis of these features, which could significantly enhance the comprehensiveness of their study. However, the comment could be more helpful if it provided suggestions on how to conduct this analysis or what specific aspects to focus on. Despite this, the feedback is mostly helpful as it points out a clear area for improvement, prompting the authors to expand their study. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include a discussion of Table 2 and Fig. 5 in the main manuscript, as they were not mentioned in the manuscript. It also suggests moving the detailed discussion from the appendix to the main manuscript. This feedback is clear and provides a direct action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Fig. 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the values in these tables and figures and suggests moving the detailed discussion from the appendix to the main manuscript. This provides clear guidance on what needs to be addressed and improved. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the absence of references to Table 2 and Fig. 5 in the manuscript and questions the values and the placement of the detailed discussion. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The comment lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript, noting that Table 2 and Fig. 5 are not mentioned in the main text. It questions the values in these tables and figures and suggests moving the detailed discussion from the appendix to the main manuscript. This feedback is clear and actionable, providing the authors with a direct way to improve the clarity and organization of their work. By addressing this issue, the authors can enhance the readability and comprehensibility of their draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the authors should include more LLM-related results in the paper, specifically mentioning examples like llama-3-70B and Mistral-7B. This provides a clear and concrete action for the authors to take, as it specifies the types of results they should include. The comment is highly actionable because it gives the authors a direct and detailed instruction on how to enhance their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"introduction\" and the \"Lorta method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely more LLM-related results in the experiments, and provides examples of specific models that should be included, such as llama-3-70B and Mistral-7B. This provides clear guidance on what the authors need to add to their experiments. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper should include more LLM-related results, specifically mentioning examples like llama-3-70B and Mistral-7B. The reviewer supports this claim by referencing the introduction, where the main purpose of the Lorta method is stated as solving the problem of efficient fine-tuning of LLMs. This provides a logical basis for the expectation of more LLM-related results. However, the comment could be strengthened by providing more detailed reasoning or examples of how these additional results would enhance the paper. Overall, the claim is mostly verifiable, as it is supported by the introduction and provides specific examples, but it could benefit from more detailed justification. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It identifies a specific area where the authors could enhance their work by including more LLM-related results, such as experiments with models like llama-3-70B and Mistral-7B. This feedback is valuable as it directs the authors to expand their experimental scope, which could significantly strengthen the paper\\'s contribution and relevance. However, the comment could be more helpful if it offered additional guidance on why these specific models are important or how they might impact the results. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the novelty of the \"Depth First Search-based Decision Tree\" (DFSDT) proposed by the authors, suggesting that it is closely related to existing techniques like self-consistency + CoT and Tree-of-thoughts. It also questions the performance of DFSDT for other types of Large Language Models (LLMs) beyond LLaMA, GPT, and Claude. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their work. The lack of actionable advice or specific recommendations makes it difficult for the authors to know exactly what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the \"Depth First Search-based Decision Tree\" (DFSDT) proposed by the authors, which is a specific part of the paper. It raises concerns about the novelty of DFSDT, noting its similarity to existing techniques like self-consistency + CoT and Tree-of-thoughts. The comment also questions the performance of DFSDT for other types of Large Language Models (LLMs) beyond LLaMA, GPT, and Claude. This provides clear guidance on what needs to be addressed, specifically the novelty and applicability of DFSDT. Therefore, the comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, and it is specific in detailing the issues with DFSDT. This aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"Depth First Search-based Decision Tree\" (DFSDT) is closely related to existing techniques like self-consistency + CoT and Tree-of-thoughts, and questions its novelty. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the comparison. The lack of detailed reasoning or evidence renders the claim somewhat verifiable, as the authors would need to conduct additional research to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises concerns about the novelty of the \"Depth First Search-based Decision Tree\" (DFSDT) proposed by the authors, suggesting that it is closely related to existing techniques like self-consistency + CoT and Tree-of-thoughts. It also questions the performance of DFSDT for other types of Large Language Models (LLMs) beyond LLaMA, GPT, and Claude. While the comment identifies potential issues with the novelty and applicability of the proposed technique, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. The feedback is somewhat helpful as it points out areas for improvement, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the importance of acknowledging contributions, particularly when proposing an identical method while claiming originality. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting specific ways to acknowledge previous work or how to differentiate their contribution. The action is implicit and vague, leaving the authors uncertain about the exact steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of acknowledging contributions, specifically in the context of proposing an identical method while claiming originality. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the method is described. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in its critique of the method's originality, but it is not grounded, as it does not provide a clear indication of where in the paper this issue is discussed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that it is inappropriate to propose an identical method while claiming originality, emphasizing the importance of acknowledging contributions. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim remains somewhat verifiable, as it lacks the necessary depth to fully substantiate the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights an important issue regarding the acknowledgment of contributions, particularly when proposing an identical method while claiming originality. It emphasizes the importance of proper citation and acknowledgment of previous work. However, the comment lacks specific guidance or suggestions on how the authors should address this issue, such as recommending particular references or methods for acknowledging contributions. While it identifies a critical area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a significant issue but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of MMV compared to XDC and their respective baselines. It asks the authors to explain why MMV shows better performance than XDC, suggesting that the difference might be due to the use of a better backbone architecture. While the comment implies that the authors should provide an explanation for the observed performance difference, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation and consider the potential impact of the backbone architecture. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the performance of MMV compared to XDC and their respective baselines, specifically asking for an explanation of why MMV shows better performance than XDC. However, it does not specify which part of the paper this discussion is based on, such as a particular section or table where these results are presented. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. The comment is specific in its request for an explanation, but it is not grounded, as it does not provide a clear reference to the paper. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the performance of MMV compared to XDC and their respective baselines, asking for an explanation of why MMV shows better performance than XDC. The comment suggests that the difference might be due to the use of a better backbone architecture. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to address the question effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the performance comparison between MMV and XDC, noting that MMV outperforms XDC despite XDC outperforming its baseline, while MMV does not exceed its baseline. The comment asks for an explanation of this discrepancy and suggests that it might be due to the use of a better backbone architecture by MMV. This feedback is somewhat helpful as it identifies a potential inconsistency in the results and prompts the authors to clarify the reasons behind the observed performance differences. However, it lacks specific guidance on how to address the issue or what aspects of the backbone architecture might be contributing to the difference. To be more helpful, the comment could provide more detailed suggestions or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies the writing as verbose and difficult to follow, suggesting that the paper appears more like an implementation paper than a theoretical or general advancement. The reviewer recommends focusing on a main idea or two and providing analyses on why they work, rather than detailing a well-engineered system with many functions. This feedback is explicit and provides a clear direction for the authors to improve their draft by streamlining their content and focusing on key aspects. The suggestion is concrete, as it specifies what the authors should do to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment critiques the writing as verbose and difficult to follow, suggesting that the paper appears more like an implementation paper than a theoretical or general advancement. It provides a suggestion to focus on a main idea or two and show analyses on why they work, rather than detailing a well-engineered system with many functions. However, the comment does not specify which parts of the paper are particularly verbose or which sections should be focused on. While the authors can infer that the critique relates to the overall structure and content of the paper, the lack of explicit references to specific sections or elements makes it weakly grounded. The comment is specific in suggesting a focus on main ideas and analyses, but without clear grounding, it is challenging for the authors to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the writing is too verbose and difficult to follow, suggesting that the paper appears more like an implementation paper than a theoretical or general advancement. The reviewer provides a suggestion to focus on a main idea or two and show analyses on why they work, rather than detailing a well-engineered system with many functions. However, the comment lacks specific examples or references to support the claim about verbosity or the perceived imbalance between implementation and theoretical aspects. Without detailed evidence or examples, the claim remains somewhat verifiable, as the authors would need to infer the specific issues and make adjustments based on the general feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper's writing, noting that it is too verbose and difficult to follow. It suggests that the paper appears more like an implementation paper rather than a theoretical or general advancement. The reviewer provides a clear and actionable suggestion to focus on a main idea or two and show analyses on why they work, rather than detailing a well-engineered system with many functions. This feedback is valuable as it directs the authors to streamline their content and emphasize key aspects, which could improve the clarity and impact of their work. However, the comment could be more helpful if it offered specific examples or guidance on how to identify and prioritize the main ideas. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper lacks code and supplementary documentation, which are essential for enhancing clarity and reproducibility. It suggests that providing these resources would be beneficial for readers to understand and replicate the methodology. This feedback is clear and direct, giving the authors a concrete action to take: they should include code and supplementary documentation in their draft. The comment is highly actionable as it provides a specific and explicit instruction on how to improve the paper.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights the lack of code and supplementary documentation, which is a specific issue that affects the clarity and reproducibility of the paper. However, it does not specify which part of the paper this issue pertains to, such as the methodology section or the results section. Without explicit references to these sections, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks code and supplementary documentation, which would enhance clarity and reproducibility. This claim is somewhat verifiable as it highlights a common issue in research papers, but it lacks specific examples or references to support the assertion. The comment provides a logical reasoning that the absence of these resources could hinder understanding and replication, but it does not offer detailed evidence or examples to substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, namely the lack of code and supplementary documentation, which hinders clarity and reproducibility. It provides a clear and actionable suggestion for improvement by recommending the inclusion of these resources. This feedback is valuable as it directly addresses a critical aspect of the paper that could impact its overall quality and usability. However, the comment could be more helpful if it offered specific guidance on how to present the code and documentation or suggested potential sources for such resources. Despite this, the comment is mostly helpful as it effectively guides the authors toward enhancing the paper\\'s clarity and reproducibility.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should discuss and empirically compare the use of ensembles and uncertainty estimation in the context of offline reinforcement learning (RL), specifically mentioning the use of random ensembles (REM) which outperforms DQN/naive ensembling in the offline setting. While the comment implies that the authors should include this discussion and comparison, it does not provide explicit instructions on how to conduct the empirical comparison or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer the need for additional discussion and comparison but may not know exactly how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ensembles and uncertainty estimation,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be discussed and compared, namely the use of random ensembles (REM) in offline reinforcement learning (RL) and its comparison to DQN/naive ensembling. This provides clear guidance on what the authors should address in their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that ensembles have been studied in the context of offline RL on discrete Atari games, with random ensembles (REM) outperforming DQN/naive ensembling. The claim is supported by a reference to a specific study [1], which provides a basis for the assertion. However, the comment could be strengthened by including more detailed information about the study or its findings, such as specific results or comparisons. Overall, the claim is mostly verifiable due to the reference, but it could be more robust with additional details. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a relevant area for discussion and comparison in the context of ensembles and uncertainty estimation in offline reinforcement learning (RL). It points out that ensembles have been studied in the context of offline RL on discrete Atari games, with random ensembles (REM) outperforming DQN/naive ensembling. The comment suggests that this should be discussed and empirically compared in the paper, providing a clear and actionable suggestion for improvement. By highlighting this aspect, the comment offers valuable guidance for the authors to enhance their work by incorporating a relevant and impactful comparison. However, it could be more helpful if it provided specific guidance on how to conduct the empirical comparison or what aspects to focus on. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the combination of the two methods lacks novelty, implying that the authors should address this perceived lack of originality. However, it does not provide specific guidance on how to enhance the novelty or suggest concrete changes to the methodology. The comment lacks explicit instructions or detailed feedback, leaving the authors uncertain about how to address the issue. As a result, the action is implicit and vague, making this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"second paragraph of the introduction\" and the \"proposed methodology,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the combination of the two methods lacks novelty, providing a clear direction for the authors to consider. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the combination of the two methods lacks novelty, suggesting that the authors have cleverly combined existing methods without adding significant originality. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the combination of the two methods lacks novelty, implying that the authors have cleverly combined existing approaches without adding significant originality. However, it does not provide specific examples or details on how the authors could enhance the novelty or suggest alternative approaches. While the comment identifies a potential issue, it lacks actionable guidance or constructive feedback, leaving the authors with limited insight into how to address the concern. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the proposed approach, suggesting that it may not be scalable because a different model needs to be fine-tuned for each target language. However, the comment does not provide any explicit or implicit actions for the authors to take to address this concern. It lacks guidance on how the authors might improve the scalability or provide evidence to support the claim. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the scalability of the proposed approach, specifically questioning whether a different model needs to be fine-tuned for each target language. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of scalability but lacks grounding, as it does not provide a clear reference to the relevant part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the scalability of the proposed approach, suggesting that it may not be scalable because a different model needs to be fine-tuned for each target language. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires more detailed justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the scalability of the proposed approach, questioning whether a different model needs to be fine-tuned for each target language. This is a valid point that could impact the practicality and applicability of the method. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or improve the scalability of their approach. Without actionable feedback or detailed insights, the authors are left without a clear path to enhance their work. Therefore, the comment is barely helpful, as it identifies a potential weakness but does not offer any constructive advice for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors provide more details for readers unfamiliar with bAbI or question answering in Equation 20. It clarifies that \"valid words\" refer to possible answer words for the given story and question. This feedback is explicit and provides a clear action for the authors to take, which is to add more explanatory details to enhance reader understanding. The comment is highly actionable as it specifies exactly what needs to be done to improve the draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq.20,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific guidance by suggesting that more details should be included for readers unfamiliar with bAbI or question answering, clarifying the meaning of \"valid words.\" This level of detail helps the authors understand what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that more details should be provided for readers unfamiliar with bAbI or question answering in Equation 20. The comment clarifies the meaning of \"valid words\" as possible answer words for the given story and question. This feedback is logical and provides a clear explanation of what additional information is needed, making it mostly verifiable. However, it could be strengthened by providing specific examples or references to further support the suggestion. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the clarity of the paper by adding more details for readers unfamiliar with bAbI or question answering in Equation 20. It clarifies the meaning of \"valid words,\" which is crucial for understanding the context. This feedback is actionable and constructive, as it guides the authors on how to enhance the accessibility and comprehensibility of their work. However, the comment could be more helpful if it offered additional suggestions or examples of how to present this information. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the idea of interested-region-based adversarial attacking is not novel, as it has been proposed earlier by Yao et al. in their work \"Trust Region Based Adversarial Attack on Neural Networks\" at CVPR 2019. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or what changes they should make to their draft. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the idea of interested-region-based adversarial attacking is not novel, referencing a specific earlier work by Yao et al. However, it does not specify which part of the paper this claim pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its claim about the novelty of the idea but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the idea of interested-region-based adversarial attacking is not novel, referencing an earlier work by Yao et al. at CVPR 2019. This claim is supported by the specific reference to the earlier work, which provides a clear basis for the assertion. The inclusion of a specific reference enhances the verifiability of the claim, making it mostly verifiable. However, the comment could be strengthened by providing more context or explanation about how the earlier work relates to the current paper, which would further solidify the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment points out that the idea of interested-region-based adversarial attacking is not novel, as it has been proposed earlier by Yao et al. in their work \"Trust Region Based Adversarial Attack on Neural Networks\" at CVPR 2019. This feedback is somewhat helpful as it alerts the authors to a potential issue with the originality of their contribution. However, the comment lacks depth and does not provide specific guidance on how the authors might address this issue or differentiate their work from the earlier proposal. Without actionable suggestions or further elaboration, the authors may find it challenging to fully understand and respond to this feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed methods are comprised of well-known effective components, which may imply that the contribution of the paper is not significant. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the perceived lack of significance or what specific aspects of the paper need improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the proposed methods are comprised of well-known effective components, which may imply that the contribution of the paper is not significant. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to identify the exact section or components being addressed. Additionally, the comment lacks specificity regarding what aspects of the paper are considered \"well-known\" or how the contribution could be improved. Without clear grounding or specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed methods are comprised of well-known effective components, which may imply that the contribution of the paper is not significant. However, the comment lacks specific examples or references to support this claim. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the reviewer\\'s assertion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the proposed methods are comprised of well-known effective components, which may imply that the contribution of the paper is not significant. However, the comment does not provide any specific examples or details about which components are well-known or how they relate to the paper's contribution. Without actionable feedback or suggestions for improvement, the authors are left without a clear understanding of how to address the perceived lack of significance. The comment lacks depth and does not offer any constructive guidance, making it barely helpful. Therefore, it aligns with a score of 2.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with data leakage in the dataset due to the inclusion of multi-turn data and publicly available history conversations in the test set. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider ways to mitigate data leakage, but it lacks concrete steps or recommendations for improvement. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of data leakage in the dataset, specifically mentioning the inclusion of multi-turn data and publicly available history conversations in the test set. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential risk of data leakage, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a risk of data leakage in the dataset due to the inclusion of multi-turn data and publicly available history conversations in the test set. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The lack of evidence or references leaves the claim somewhat verifiable, as it requires more information to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with data leakage in the dataset, specifically mentioning the inclusion of multi-turn data and publicly available history conversations in the test set. This is a relevant concern that could impact the validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending methods to mitigate data leakage or suggesting alternative approaches. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential problem but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) in Figure 7. It suggests that a comparison with VSD + TTUR would be more convincing, implying that the authors should consider including this comparison. However, the comment does not explicitly instruct the authors to make this comparison or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison with VSD + TTUR. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) and suggests that a comparison with VSD + TTUR would be more convincing. This provides clear guidance on what needs to be addressed in Figure 7. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) in Figure 7 and suggests that a comparison with VSD + TTUR would be more convincing. The comment provides a logical reasoning by referencing the DMD2 paper, which states that TTUR improves the performance of VSD. This reference supports the claim, making it mostly verifiable. However, the comment could be strengthened by providing more specific details or examples of how the comparison with VSD + TTUR would enhance the paper. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a specific question about the application of TTUR proposed by DMD2 (Yin et al. 2024a) in Figure 7 and suggests that a comparison with VSD + TTUR would be more convincing. This feedback is clear and actionable, as it identifies a potential area for improvement and provides a specific suggestion for enhancing the paper. By addressing this point, the authors can strengthen their argument and provide a more comprehensive evaluation of their results. However, the comment could be more helpful if it included additional guidance on how to implement this comparison or why it would be beneficial. Overall, the comment is mostly helpful, as it provides valuable insights for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the merit of the theoretical result presented in the paper, given that the authors define OOD actions as those not drawn from \\\\hat{\\\\pi}{\\\\beta}(.)|s) but then assume in Assumption 3.1 that \\\\hat{\\\\pi}_{\\\\beta}(a|s) > 0, implying no OOD actions. This comment does not provide any explicit or implicit actions for the authors to take. It does not suggest any changes or improvements to the draft, leaving the authors without guidance on how to address the issue. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 109\" and \"Assumption 3.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly questions the merit of the theoretical result presented, pointing out a potential contradiction between the definition of OOD actions and the assumption made in Assumption 3.1. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the merit of the theoretical result presented in the paper, pointing out a potential contradiction between the definition of out-of-distribution (OOD) actions and the assumption made in Assumption 3.1. The comment highlights a logical inconsistency that could impact the validity of the theoretical result. However, it does not provide specific examples or detailed reasoning to fully substantiate the claim. While the comment raises a valid concern, it lacks sufficient evidence or references to make the claim fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some justification but requires more detailed support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the merit of the theoretical result presented in the paper. It points out a potential contradiction between the definition of out-of-distribution (OOD) actions and the assumption made in Assumption 3.1, which assumes that there are no OOD actions. This observation challenges the validity of the theoretical result and prompts the authors to reconsider their approach. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their work. While it highlights a significant concern, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the analysis provided in the paper is shallow and lacks clear takeaways or conclusions. It implies that if the analysis does not enhance the paper\\'s value or clarity, it might be better suited for the appendix. Additionally, it suggests integrating essential details from the appendix, such as dataset splitting justifications, into the main text. While the comment provides a clear direction for improvement, it does not specify exactly which parts of the analysis are shallow or how to enhance the takeaways. The action is mostly implicit, as the authors need to infer that they should focus on making the analysis more substantial and integrating key details from the appendix. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the analysis provided in the paper, specifically noting that it is shallow and lacks clear takeaways or conclusions. It suggests that if the analysis does not enhance the paper\\'s value or clarity, it might be better suited for the appendix. Additionally, it recommends integrating essential details from the appendix, such as dataset splitting justifications, into the main text. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the analysis section. The comment is specific in its suggestions for improvement, such as enhancing the analysis and integrating key details. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper provides a \"shallow linguistic dataset analysis\" without clear takeaways or conclusions. It suggests that if the analysis does not enhance the paper\\'s value or clarity, it might be better suited for the appendix. The comment also recommends integrating essential details from the appendix, such as dataset splitting justifications, into the main text. However, the review does not provide specific examples or detailed reasoning to support the claim of a shallow analysis, making it somewhat verifiable. The authors would need to infer the specific issues with the analysis and how to address them, which could be challenging without further guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a weakness in the paper, specifically noting that the linguistic dataset analysis is shallow and lacks clear takeaways or conclusions. It suggests that if the analysis does not enhance the paper\\'s value or clarity, it might be better suited for the appendix. Additionally, the comment provides a constructive suggestion to integrate essential details from the appendix, such as dataset splitting justifications, into the main text. This feedback is clear and actionable, offering the authors a specific direction for improving the depth and clarity of their analysis. However, the comment could be more helpful if it provided examples of how to enhance the analysis or suggested specific details to include. Overall, the comment is mostly helpful as it guides the authors toward improving the quality and relevance of their analysis.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies two issues with the experimental results section: the lack of clarity regarding the metric used in Table 1 and the absence of experimental details such as backbone choice, learning rate, and optimization schedules. The comment provides clear and specific actions for the authors to take, namely clarifying the metric used and including the missing experimental details. This feedback is direct and concrete, giving the authors a clear understanding of what needs to be addressed in their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the experimental results, namely the lack of clarity regarding the metric used and the absence of experimental details such as backbone choice, learning rate, and optimization schedules. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the metric used in Table 1 is not clearly stated and that experimental details such as backbone choice, learning rate, and optimization schedules are missing. This is a factual observation that requires no justification or evidence beyond the description of the issue. The comment does not express an opinion, judgment, or suggestion, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies two specific issues with the experimental results section: the lack of clarity regarding the metric used in Table 1 and the absence of experimental details such as backbone choice, learning rate, and optimization schedules. This feedback is clear and actionable, as it provides the authors with specific areas to address in order to improve the transparency and comprehensiveness of their experimental results. By highlighting these gaps, the comment empowers the authors to make targeted improvements to their draft. However, the comment could be more helpful if it suggested ways to clarify the metric or provided examples of how to present the experimental details. Overall, the comment is mostly helpful, as it directs the authors to important aspects of their work that need clarification and expansion.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential advantage of POMDPs that is not leveraged in the paper. It suggests that the paper should discuss how previous decisions affect the data observable to the decision-maker, as only outcomes are observed when a positive decision is given. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects should be discussed. The action is implicit and somewhat vague, as the authors can infer that they need to discuss the impact of previous decisions on observable data but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the advantage of POMDPs in assuming the decision-maker does not directly observe the target variable Y. It points out that this advantage is not leveraged in the paper, specifically mentioning the lack of discussion on how previous decisions affect the data observable to the decision-maker. This provides clear guidance on what needs to be addressed, making the comment fully grounded. However, it does not specify which part of the paper should include this discussion, so it is fully grounded but under-specific. Therefore, this comment aligns with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the paper does not leverage the advantage of POMDPs, specifically the assumption that the decision-maker does not directly observe the target variable Y. The reviewer suggests that the paper should discuss how previous decisions affect the data observable to the decision-maker, as only outcomes are observed when a positive decision is given. This claim is somewhat verifiable as it provides a logical reasoning for the potential oversight in the paper. However, it lacks specific examples or references to support the claim fully, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential oversight in the paper regarding the advantage of POMDPs, specifically the assumption that the decision-maker does not directly observe the target variable Y. It points out that this advantage is not leveraged in the paper, suggesting that the authors should discuss how previous decisions affect the data observable to the decision-maker. This feedback is clear and actionable, as it highlights a specific area for improvement and provides a direction for the authors to enhance their work. However, the comment could be more helpful if it offered specific suggestions on how to incorporate this discussion or provided examples of how previous decisions impact observable data. Overall, the comment is mostly helpful, as it directs the authors to a meaningful area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights concerns about the pretraining tokens_per_sample being extremely small (256) and questions whether this is sufficient for a regular-size program. It also expresses skepticism about using batch_size=64 for pretraining. However, the comment does not provide explicit guidance or suggestions on how to address these concerns or what specific changes the authors should make to improve their draft. The feedback lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses specific aspects of the pretraining process, mentioning \"tokens_per_sample\" and \"batch_size.\" However, it does not specify which part of the paper these settings are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the small tokens_per_sample and batch_size, but without clear references to the paper, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses skepticism about the pretraining tokens_per_sample being extremely small (256) and questions whether it is sufficient for a regular-size program. It also questions the use of batch_size=64 for pretraining. However, the comment lacks specific reasoning, examples, or references to support these claims. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the reviewer\\'s concerns or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific concerns about the pretraining process, noting that the tokens_per_sample is extremely small (256) and questioning whether this is sufficient for a regular-size program. It also expresses skepticism about using batch_size=64 for pretraining. While the comment highlights potential issues, it lacks detailed guidance or suggestions on how the authors might address these concerns or improve their pretraining setup. Without actionable advice or specific recommendations, the feedback is somewhat helpful, as it points out areas for consideration but does not fully support the authors in making improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the work lacks sufficient ablation experiments to help readers understand the proposed method. It provides specific examples, such as replacing the clustering algorithm with K-Means and testing the model\\'s performance on different-sized descendant models. This feedback is clear and actionable, as it gives the authors concrete steps to take to improve their draft. The authors know exactly what experiments to conduct and how to address the issue, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of ablation experiments, allowing the authors to identify the specific part of the paper being addressed. It also provides specific suggestions for additional experiments, such as replacing the clustering algorithm with K-Means and testing the model\\'s performance on different-sized descendant models. This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the work lacks sufficient ablation experiments to help readers understand the proposed method. It provides specific examples, such as replacing the clustering algorithm with K-Means and testing the model\\'s performance on different-sized descendant models. These examples offer a clear and logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to similar studies that have successfully used ablation experiments. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of ablation experiments to help readers understand the proposed method. It provides specific suggestions for additional experiments, such as replacing the clustering algorithm with K-Means and testing the model\\'s performance on different-sized descendant models. This feedback is clear and actionable, offering the authors concrete steps to enhance the comprehensiveness and robustness of their work. By addressing these suggestions, the authors can significantly improve the clarity and validity of their results, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the Talking Heads Transformer should be the de-facto baseline for all tasks in the paper, as it is a relevant baseline. It implies that the authors should include a comparison to this baseline for all tasks, rather than just comparing against the vanilla transformer. This provides a clear and explicit action for the authors to take, which is to expand the comparison to include the Talking Heads Transformer for all tasks. The comment is highly actionable because it specifies exactly what needs to be done to improve the draft, providing a concrete step for the authors to follow.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, suggesting that the Talking Heads Transformer should be the baseline for all tasks and that the comparison should be expanded beyond the vanilla transformer. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the Talking Heads Transformer should be the de-facto baseline for all tasks, implying that the current comparison to the vanilla transformer is insufficient. The reviewer provides a logical reasoning by stating that it is hard to gauge the benefit of the proposed interaction modules and many-to-many formulation compared to a simple linear transform. However, the comment lacks specific examples or references to support the claim that the Talking Heads Transformer is the most relevant baseline. This makes the claim somewhat verifiable, as it provides a logical argument but requires further evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a relevant baseline, the Talking Heads Transformer, and suggests that it should be the de-facto baseline for all tasks in the paper. It points out that the current comparison to the vanilla transformer is insufficient and recommends expanding the comparison to include the Talking Heads Transformer for all tasks. This feedback is clear and actionable, as it provides a specific suggestion for improvement that can help the authors better evaluate the effectiveness of their proposed interaction modules and many-to-many formulation. However, the comment could be more helpful if it included additional guidance on how to implement this comparison or why the Talking Heads Transformer is a more appropriate baseline. Overall, the comment is mostly helpful, as it offers valuable insights for enhancing the paper\\'s evaluation and comparison sections.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should check and benchmark their scenario using the HI-MIA dataset, which is recorded in a real-time environment with noise setup and microphone array. This is an explicit action with concrete details on what needs to be done, as it specifies the dataset to use and the task to perform (speaker identification). The authors know exactly what action to take and how to implement it, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests checking and benchmarking the scenario using the HI-MIA dataset, which is recorded in a real-time environment with noise setup and microphone array. While it does not explicitly mention a specific section of the paper, the mention of \"Following2)\" implies that it relates to a previous point or section. However, without explicit references, the authors might find it challenging to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting a particular dataset and task for benchmarking, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should check and benchmark their scenario using the HI-MIA dataset, which is recorded in a real-time environment with noise setup and microphone array. The suggestion is based on the existence of such a dataset, which is a factual statement. However, the comment does not provide any further reasoning or evidence to support why this dataset is relevant or how it would improve the paper. Without additional context or justification, the claim remains somewhat verifiable, as it lacks detailed explanation or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should consider using the HI-MIA dataset, which is recorded in a real-time environment with noise setup and microphone array, to benchmark their scenario. This is a specific and actionable suggestion that could help the authors improve the robustness and validity of their work by testing it against a more realistic and challenging dataset. However, the comment could be more helpful if it provided additional context or explanation about why this dataset is particularly relevant or how it might impact the results. Despite this, the suggestion is clear and provides a concrete direction for the authors to enhance their draft. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests an alternative framing for the paper, focusing on the loss function and its applications rather than breast cancer. While it implies that the authors should consider a different approach to framing their work, it does not provide explicit guidance on how to achieve this or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to adjust the framing but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Introduction\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper\\'s focus is not on breast cancer, despite the introduction focusing on it. The comment suggests an alternative framing that focuses on the loss function and its applications, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper\\'s framing is not appropriate, as it focuses on breast cancer in the introduction but the contributions and evaluations are broader. The reviewer proposes an alternative framing that focuses on the loss function and its applications. While the comment provides a logical reasoning for the suggested change, it lacks specific examples or references to support the claim that the current framing is misleading or that the alternative framing would be more appropriate. This makes the claim somewhat verifiable, as it requires the authors to infer the necessity of the suggested change based on the reviewer\\'s reasoning.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the framing of the paper, noting that while the introduction focuses on breast cancer, the contributions and evaluations are broader and not particularly focused on breast cancer. It suggests an alternative framing that focuses on the loss function and its applications, which could be more appropriate given the paper\\'s scope. This feedback is clear and provides a specific suggestion for improvement, offering the authors a way to reframe their work to better align with its actual contributions. However, the comment could be more helpful if it included additional guidance on how to implement this reframing or what specific aspects of the paper should be emphasized. Overall, the comment is mostly helpful as it directs the authors toward a more appropriate focus for their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks the authors to include agreement statistics for the corpus in sections 3.1 or 3.2. This request is clear and direct, providing the authors with a specific action to take. The comment specifies exactly where the information should be included, leaving no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.1 or 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be included, namely \"agreement statistics for the corpus.\" This provides clear guidance on what the authors should add to their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for additional information, specifically asking for agreement statistics to be included in sections 3.1 or 3.2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual request for clarification or addition of data, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, requesting the inclusion of agreement statistics for the corpus in sections 3.1 or 3.2. This feedback is specific and provides a direct suggestion for enhancing the paper by adding relevant data, which can help improve the clarity and comprehensiveness of the draft. However, the comment could be more helpful if it explained why these statistics are important or how they would contribute to the paper\\'s overall impact. Despite this, the feedback is mostly helpful as it offers a concrete step for the authors to take, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point discusses the novelty of the paper, specifically mentioning the use of LLMs for instruction aggregation and the concept of cross-trajectory chaining. However, it notes that existing LLMs are used and that the use of consecutive sub-trajectories seems straightforward. The comment highlights that while cross-trajectory chaining has novelty, its techniques are inspired by goal-conditioned RL approaches. While the comment identifies areas of novelty and potential inspiration, it does not provide explicit guidance or suggestions for the authors to improve their work. The feedback lacks actionable steps or concrete recommendations, leaving the authors uncertain about how to address the issues raised. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the novelty of the paper, specifically mentioning the use of LLMs for instruction aggregation and the concept of cross-trajectory chaining. It notes that while the use of LLMs might be novel, existing LLMs are used, and the use of consecutive sub-trajectories seems straightforward. The comment also mentions that cross-trajectory chaining has novelty but is inspired by goal-conditioned RL approaches. However, the comment does not specify which part of the paper these discussions are based on, making it difficult for the authors to pinpoint the exact sections that need attention. The lack of explicit references to sections or specific elements of the paper results in weak grounding. The comment is specific in detailing the novelty and inspiration behind certain techniques, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point discusses the novelty of the paper, specifically mentioning the use of LLMs for instruction aggregation and the concept of cross-trajectory chaining. It notes that while the use of LLMs might be novel, existing LLMs are used, and the use of consecutive sub-trajectories seems straightforward. The comment also mentions that cross-trajectory chaining has novelty but is inspired by goal-conditioned RL approaches, referencing a specific work by Chebotar et al. (2021). This reference provides a basis for the claim, making the comment mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a nuanced evaluation of the paper\\'s novelty, acknowledging that the use of LLMs for instruction aggregation and cross-trajectory chaining may be novel. However, it notes that existing LLMs are used and that the use of consecutive sub-trajectories seems straightforward. The comment also highlights that cross-trajectory chaining is inspired by goal-conditioned RL approaches, as mentioned in the paper. While the comment identifies areas of novelty and potential inspiration, it lacks specific suggestions or guidance on how the authors might enhance their work or address these points. The feedback is somewhat helpful as it provides insights into the paper\\'s originality, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the identity of the attention map and its potential to improve the expressive power of the attention module. It also questions whether identity mapping is the best choice and suggests that more discussion should be conducted. While the comment implies that the authors should provide more explanation and discussion on this topic, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more discussion without specific guidance on how to structure it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the identity of the attention map and its potential to improve the expressive power of the attention module, as well as questioning whether identity mapping is the best choice. However, it does not specify which part of the paper discusses the attention module or where this discussion should be expanded. The authors can make an educated guess that it relates to the methodology or results sections, but the comment lacks full grounding. It is specific in identifying the need for more discussion on the topic, but without clear references to specific sections, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the identity of the attention map and its potential to improve the expressive power of the attention module, as well as questioning whether identity mapping is the best choice. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to address these questions effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises important questions about the identity of the attention map and its potential to improve the expressive power of the attention module. It also questions whether identity mapping is the best choice, suggesting that more discussion should be conducted on this topic. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address these questions or what additional discussion could be included. The feedback is somewhat helpful as it points out a gap in the paper but does not provide detailed actionable advice for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to explain why they are considering decoder-only transformers, providing a clear and direct action for the authors to take. This feedback is specific and concrete, as it specifies exactly what needs to be addressed in the paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the explanation for considering decoder-only transformers. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification, asking the authors to explain their choice of considering decoder-only transformers. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and direct, requesting an explanation for the consideration of decoder-only transformers. This feedback is actionable and provides a specific point for the authors to address, which can help clarify the rationale behind their choice and potentially enhance the comprehensibility of their work. However, the comment could be more helpful if it offered additional context or suggestions on how to present this explanation. Overall, the comment is mostly helpful as it guides the authors toward a specific improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the qualitative analysis, specifically mentioning the lack of details about the proportion of each error category. It suggests that the contribution could be strengthened by including more fruitful thoughts or speculations about the underlying causes of the observed issues and potential ways to mitigate them. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to incorporate these suggestions into the draft. The authors are left to infer that they should add more detailed analysis or discussion, but without concrete steps or examples, the action remains somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"qualitative analysis\" and the lack of details about the proportion of each error category, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what is missing, such as more detailed discussions or speculations about the underlying causes of the observed issues and potential ways to mitigate them. The reference to \"Turpin et al.\" adds further specificity by providing a relevant external work for comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the qualitative analysis lacks important details, such as the proportion of each error category. It suggests that the contribution could be strengthened by including more fruitful thoughts or speculations about the underlying causes of the observed issues and potential ways to mitigate them. The comment references \"Turpin et al.\" as a relevant work, which provides some context and supports the claim. However, the comment could be more verifiable with specific examples or detailed reasoning about how the referenced work relates to the current analysis. Therefore, the claim is mostly verifiable, as it provides some support but lacks detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a gap in the qualitative analysis, specifically noting the absence of details about the proportion of each error category. It suggests that the contribution could be strengthened by including more in-depth thoughts or speculations about the underlying causes of the observed issues and potential ways to mitigate them. The comment references a relevant work, \"Turpin et al.,\" which provides a basis for the suggestion. However, the comment could be more helpful if it offered specific examples or guidance on how to incorporate these suggestions into the draft. Despite this, the feedback provides a clear direction for improvement, making it mostly helpful for the authors.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should empirically validate the claim that Reinforcement Learning, RNNs, and Wasserstein GANs are not suitable for incomplete or small data by applying these methods with data filled by simple methods. This is an explicit action with concrete details on how to implement it, as it provides a specific suggestion for experimentation. The authors know exactly what they need to do to address the comment, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific part of the paper, \"The typical MTTP baselines like Reinforcement Learning, RNNs, Wasserstein GANs,\" allowing the authors to accurately identify the section being addressed. It is also specific because it suggests a way to empirically validate the claim that these methods are not suitable for incomplete or small data by applying them with data filled by simple methods. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should empirically validate the claim that Reinforcement Learning, RNNs, and Wasserstein GANs are not suitable for incomplete or small data. The reviewer provides a logical reasoning by suggesting that the authors apply these methods with data filled by simple methods to test their applicability. This suggestion is based on a clear and logical argument, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by questioning the authors\\' claim that certain MTTP baselines, such as Reinforcement Learning, RNNs, and Wasserstein GANs, are not applicable due to the need for significant data. The reviewer suggests a way to empirically validate this claim by applying these methods with data filled by simple methods. This feedback is actionable and provides a clear direction for the authors to strengthen their argument by testing the applicability of these baselines under different conditions. However, the comment could be more helpful if it offered additional guidance on how to implement this suggestion or what specific aspects to focus on. Overall, the comment is mostly helpful as it offers a constructive way to improve the paper\\'s validation and argumentation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of baseline comparison in the paper, specifically noting that the G-EVAL method is based on GPT-3.5 and GPT-4 but does not demonstrate its performance using the simplest prompt for these LLMs and compare it with the G-EVAL method. This feedback implies that the authors should include a baseline comparison to demonstrate the effectiveness of their method. However, it does not provide explicit instructions on how to conduct this comparison or what specific prompts should be used. The action is implicit and somewhat vague, as the authors can infer the need for a baseline comparison but may not know exactly how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"G-EVAL method\" and \"GPT-3.5 and GPT-4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking baseline comparisons and suggests a particular comparison that should be made, namely using the simplest prompt for these LLMs and comparing it with the G-EVAL method. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a baseline comparison, specifically noting that the G-EVAL method is based on GPT-3.5 and GPT-4 but does not demonstrate its performance using the simplest prompt for these LLMs and compare it with the G-EVAL method. This claim is somewhat verifiable as it provides a clear rationale for the lack of baseline comparison, which is a common practice in evaluating the effectiveness of a method. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider this feedback and potentially include additional comparisons to strengthen their evaluation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of baseline comparison. It specifically highlights that the G-EVAL method is based on GPT-3.5 and GPT-4 but does not demonstrate its performance using the simplest prompt for these LLMs and compare it with the G-EVAL method. This feedback is clear and actionable, as it provides a specific suggestion for improvement by recommending a baseline comparison. However, the comment could be more helpful if it offered guidance on how to conduct this comparison or which prompts to use. Despite this, the comment effectively directs the authors to enhance the evaluation of their method, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with updating weights in multiagent environments, specifically mentioning the need to compute expected rewards or NE gaps for different perturbations. It also notes that this requires full knowledge of the game payoffs, unlike the base policies, and that computing NE gaps requires knowing the policies of other agents. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or what specific changes they should make to their draft. The action is implicit and vague, leaving the authors without clear direction on how to improve their work. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to updating weights in multiagent environments, particularly focusing on the need to compute expected rewards or NE gaps for different perturbations. It highlights the requirement for full knowledge of game payoffs and the policies of other agents, which is a clear and specific issue. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to sections discussing multiagent environments or policy updates, but the exact location is not specified. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the requirement to compute expected rewards or NE gaps for different perturbations in multiagent environments, noting that this necessitates full knowledge of the game payoffs, unlike the base policies. It also points out that computing NE gaps requires knowing the policies of other agents. While the comment highlights a potential issue, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to delve deeper into the paper to fully understand the implications of this requirement, and the comment does not provide sufficient evidence or reasoning to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with updating weights in multiagent environments, specifically highlighting the need to compute expected rewards or NE gaps for different perturbations. It points out that this requires full knowledge of the game payoffs, unlike the base policies, and that computing NE gaps also necessitates knowing the policies of other agents. This feedback is somewhat helpful as it alerts the authors to a specific challenge in their approach and encourages them to consider the implications of their method. However, the comment could be more helpful if it provided suggestions or guidance on how to address these challenges or offered potential solutions. Therefore, it aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point simply states that the paper primarily compares the proposed methods with DiffUCO, without providing any explicit or implicit actions for the authors to take. It lacks any guidance or suggestions on how the authors might improve their draft or address any potential issues related to this comparison. As a result, the authors are left without any actionable steps to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it addresses, leaving the authors uncertain about where to focus their attention. It also lacks specificity, as it does not detail what aspects of the comparison with DiffUCO are being discussed or what improvements could be made. Without clear guidance, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a factual statement describing the comparison made in the paper, specifically mentioning that it primarily compares the proposed methods with DiffUCO. Since it does not express an opinion, judgment, or suggestion, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review point simply states that the paper primarily compares the proposed methods with DiffUCO, without providing any context, analysis, or suggestions for improvement. It lacks depth and does not offer any actionable feedback or insights that could help the authors enhance their draft. As a result, the comment is not helpful at all, as it does not provide any meaningful guidance for the authors to address or improve their work. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the paper, including the lack of explicit definition of local subtasks and their corresponding policies, the absence of a complete proof of the equivalence between the local policy product and the globally optimal policy, and the superficial exposition of the decomposition method. While the comment identifies areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to provide more detailed definitions and a complete proof, but the comment lacks concrete steps or suggestions on how to achieve this. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not offer specific guidance on how to implement the changes.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"contribution\" and the \"decomposition method,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the lack of explicit definition of local subtasks and their corresponding policies, the absence of a complete proof of the equivalence, and the superficial exposition of the decomposition method. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is too repetitive and superficial in its exposition of the decomposition method, and it lacks explicit definitions of local subtasks and their corresponding policies. The reviewer also criticizes the absence of a complete proof of the equivalence between the local policy product and the globally optimal policy. While the comment highlights specific areas of concern, it does not provide detailed reasoning or examples to support these claims. The lack of specific evidence or references makes it difficult for the authors to fully understand and address the issues. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claims but lacks sufficient detail for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several critical issues with the paper, including the lack of explicit definition of local subtasks and their corresponding policies, the absence of a complete proof of the equivalence between the local policy product and the globally optimal policy, and the superficial exposition of the decomposition method. These are significant concerns that could impact the clarity and validity of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues, such as recommending additional examples or a more detailed proof. While it highlights important areas for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out weaknesses but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the performance curve of each algorithm during the training is missing. This provides a clear and direct action for the authors to take, which is to include the missing performance curves in their draft. The comment is explicit and concrete, as it specifies exactly what needs to be added to the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"performance curve of each algorithm during the training,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, which is the performance curve during training. This provides clear guidance on what needs to be included in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance curve of each algorithm during the training is missing. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this omission or how it affects the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, namely the absence of the performance curve of each algorithm during the training. This feedback is clear and actionable, as it directly points out a missing element that could enhance the comprehensiveness and clarity of the paper. By including the performance curves, the authors can provide a more detailed analysis of their results, which is beneficial for readers and reviewers. However, the comment could be more helpful if it suggested how to present these curves or why they are important. Overall, the comment is mostly helpful as it provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a computational complexity issue with the proposed Gaussian kernel-based graph construction method, specifically noting that it requires computing the full adjacency matrix with an O(N^2) time complexity. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue, such as suggesting alternative methods or optimizations that could reduce computational complexity. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed Gaussian kernel-based graph construction method, namely the computational expense of computing the full adjacency matrix for large-scale graphs. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed Gaussian kernel-based graph construction method requires computing the full adjacency matrix, which is computationally expensive for large-scale graphs with an O(N^2) time complexity. This claim is supported by logical reasoning, as the reviewer explains the computational complexity of the method. However, the comment lacks specific examples or references to substantiate the claim further, such as comparisons with other methods or detailed computational analyses. Therefore, the claim is mostly verifiable, as it provides a clear rationale but could benefit from additional evidence or examples to fully substantiate the assertion.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific computational complexity issue with the proposed Gaussian kernel-based graph construction method, noting that it requires computing the full adjacency matrix with an O(N^2) time complexity. This is a clear and actionable feedback that highlights a potential bottleneck in the method, particularly for large-scale graphs. However, the comment does not provide suggestions or guidance on how the authors might address this issue, such as exploring alternative methods or optimizations that could reduce computational complexity. While it points out a significant problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight into a critical area for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the choice of loss reweighting case used in the paper, specifically questioning the default choice of case (1) over case (3), which achieves better performance for most widths. The reviewer disagrees with the authors\\' explanation for choosing case (1) and suggests that all sub-networks with different widths should be equally important. This feedback implies that the authors should reconsider their choice of default case and provide a more balanced approach. However, the comment does not explicitly instruct the authors to make this change or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their choice and provide a more balanced approach. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 8\" and \"Table 2e,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of loss reweighting case and the authors\\' explanation for it. The comment provides a clear critique of the authors\\' reasoning and suggests that all sub-networks with different widths should be equally important, which adds specificity to the feedback. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the choice of loss reweighting case used in the paper, specifically questioning the default choice of case (1) over case (3), which achieves better performance for most widths. The reviewer disagrees with the authors\\' explanation for choosing case (1) and suggests that all sub-networks with different widths should be equally important. This claim is somewhat verifiable as it provides a logical reasoning for questioning the choice of case (1) and highlights a potential inconsistency in the authors\\' explanation. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the choice of loss reweighting case used in the paper, questioning the default choice of case (1) over case (3), which achieves better performance for most widths. It challenges the authors\\' explanation for choosing case (1) and suggests that all sub-networks with different widths should be equally important. This feedback is clear and actionable, as it prompts the authors to reconsider their choice and provide a more balanced approach. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context. Overall, the comment is mostly helpful, as it directs the authors to a critical area that requires attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the paper for claiming to address a specific issue related to fine-tuning multiplicity in tabular LLMs, but the main results are general and do not leverage unique characteristics of tabular data or LLMs. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their work. Without actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the paper for claiming to address a specific issue related to fine-tuning multiplicity in tabular LLMs, but the main results are general and do not leverage unique characteristics of tabular data or LLMs. However, it does not specify which part of the paper this critique is based on, such as a particular section or result. This makes it difficult for the authors to pinpoint the exact area that needs revision. The comment is specific in its critique of the paper\\'s scope and relevance but lacks grounding, as it does not identify the specific sections or results being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s main results are general and do not leverage unique characteristics of tabular data or LLMs, contradicting the paper\\'s claim to address fine-tuning multiplicity in tabular LLMs. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence renders the claim somewhat verifiable, as the authors would need to infer the specific issues from the general statement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, pointing out that despite the claim to address a specific problem related to fine-tuning multiplicity in tabular LLMs, the main results are general and do not leverage unique characteristics of tabular data or LLMs. This critique highlights a gap between the paper\\'s claims and its actual contributions, which is crucial for the authors to address. However, the comment does not provide specific suggestions or guidance on how the authors might improve their work to better align with the claimed focus. While it points out a critical weakness, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggestions for improvement. It explicitly asks for a double summation and questions the function \"f(.)\" in the line above equation 3. Additionally, it suggests referencing existing works like TailorNet and Patel et al. 2021 to provide context on the challenges of simulating multiple layers compared to single-layered clothing. While the comment provides explicit actions, it lacks detailed guidance on how to implement the double summation or how to address the question about \"f(.)\". The suggestion to reference existing works is concrete, but the comment could be more actionable with additional details on how to incorporate these references effectively. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"12\" and \"eq. 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific feedback by questioning the need for a double summation and asking for clarification on the function \"f(.)\" in the line above equation 3. Additionally, it suggests referencing existing works like TailorNet and Patel et al. 2021 to provide context on the challenges of simulating multiple layers. This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several claims and questions, making it challenging to determine the primary claim. However, the comment suggests that the summation should be a double summation, which is a logical suggestion based on the context of the paper. The mention of existing works like TailorNet and Patel et al. 2021 provides some support for the claim that simulating multiple layers is more challenging. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to provide more context or evidence to fully understand and address the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several specific and actionable points for improvement. It questions the need for a double summation, which could be a critical oversight in the mathematical formulation. Additionally, it asks for clarification on the function \"f(.)\" in the line above equation 3, which could help resolve any confusion in the mathematical representation. The comment also references existing works like TailorNet and Patel et al. 2021, suggesting that the authors provide details on how simulating multiple layers is more challenging than simulating single-layered clothing. This feedback is clear and actionable, offering the authors concrete steps to enhance the clarity and depth of their work. However, the comment could be more helpful if it provided specific suggestions on how to address the challenges of simulating multiple layers. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the theoretical analysis, specifically questioning the choice of the supremum in Definition 1 and asking for clarification on how the proposed GRADE reduces this supremum. While the comment identifies a potential area of confusion, it does not provide explicit instructions or suggestions for how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the theoretical analysis, but it is not concrete, as it lacks specific guidance on how to resolve the confusion. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"theoretical analysis\" and \"Definition 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of the supremum in Definition 1 and asks for clarification on how the proposed GRADE reduces this supremum. This provides clear guidance on what needs to be addressed in the theoretical analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the theoretical analysis, specifically questioning the choice of the supremum in Definition 1 and asking for clarification on how the proposed GRADE reduces this supremum. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim of confusion or the need for clarification. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the theoretical analysis, questioning the choice of the supremum in Definition 1 and asking for clarification on how the proposed GRADE reduces this supremum. This feedback is clear and actionable, as it directs the authors to address a particular aspect of their theoretical framework. By asking for an explanation of the supremum and its relation to the proposed GRADE, the comment provides a concrete step for the authors to improve their draft. However, it could be more helpful if it offered suggestions or examples on how to clarify the theoretical analysis. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their theoretical foundation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include results and analysis on lengthy dialogue samples and asks whether the performance drops on these samples. This feedback is explicit, as it clearly states what the authors should do to improve their draft. It also provides a specific example of what the authors could investigate, which makes the action concrete. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including results and analysis on lengthy dialogue samples and asks about the performance drop on these samples. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors can infer that it relates to the experimental results or methodology section, but this inference is not direct. The comment is specific in suggesting what additional analysis could be included, but it lacks full grounding due to the lack of explicit reference to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be beneficial to include results and analysis on lengthy dialogue samples and asks about the performance drop on these samples. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would impact the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include results and analysis on lengthy dialogue samples, which could provide valuable insights into the performance of the model on longer conversations. It also asks a specific question about whether the performance drops on lengthy dialogues, which could guide the authors in identifying potential areas for improvement. While the comment is clear and actionable, it could be more helpful if it provided additional context or suggestions on how to approach this analysis. Overall, the feedback is mostly helpful as it directs the authors to a specific area for further exploration, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the datasets used in the paper should include more natural modalities, such as audio and visual, for better evaluation. It provides references to relevant studies that support this suggestion. However, the comment does not explicitly instruct the authors to include these modalities or provide specific guidance on how to incorporate them. While the references offer a starting point for the authors to explore, the action is implicit and somewhat vague, as it does not specify the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the datasets used in the paper should include more natural modalities, such as audio and visual, for better evaluation. It provides references to relevant studies that support this suggestion. However, the comment does not specify which part of the paper discusses the datasets or where these modalities should be included. The authors can infer that it relates to the methodology or results sections, but the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting the inclusion of additional modalities and providing references, but the absence of explicit grounding limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the datasets used in the paper should include more natural modalities, such as audio and visual, for better evaluation. It supports this claim by referencing three external studies: Weiyao Wang et al., Thomas Winterbottom et al., and Ya Sun et al. These references provide evidence that the inclusion of multiple modalities is beneficial for evaluation, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed explanations or examples of how these modalities could be integrated into the current evaluation framework. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that the datasets used in the paper should include more natural modalities, such as audio and visual, for better evaluation. It provides references to relevant studies that support this suggestion, offering a starting point for the authors to explore. However, the comment could be more helpful if it provided specific guidance on how to incorporate these modalities or suggested potential datasets that could be used. While it identifies a potential area for improvement, the feedback is somewhat vague and lacks detailed actionable steps, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a similarity between the oracle-context model and existing works like Visual Prompt Tuning & Prompt Learning for Vision-Language Models, noting that these works are not discussed in the paper. While the comment identifies a potential omission, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The authors can infer that they should discuss these related works, but the comment lacks concrete details on how to integrate this information into the paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a similarity between the oracle-context model and existing works like Visual Prompt Tuning & Prompt Learning for Vision-Language Models, noting that these works are not discussed in the paper. However, it does not specify which part of the paper this similarity is discussed in, making it weakly grounded. The comment is specific in identifying the omission of related works, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the oracle-context model is similar to existing works like Visual Prompt Tuning & Prompt Learning for Vision-Language Models, but these works are not discussed in the paper. The comment provides a specific reference to related works, which supports the claim by offering a clear example of the similarity. However, it does not provide detailed reasoning or examples of how these works are similar or how they relate to the oracle-context model. While the reference to specific works is a good start, the comment could be strengthened by providing more detailed comparisons or explanations. Therefore, the claim is mostly verifiable, as it provides some support but lacks full elaboration.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential omission in the paper by noting that the oracle-context model is similar to existing works like Visual Prompt Tuning & Prompt Learning for Vision-Language Models, yet these works are not discussed in the paper. This observation highlights a gap in the literature review or discussion section, which could be important for contextualizing the contribution of the oracle-context model. However, the comment does not provide specific guidance on how the authors should address this issue or suggest ways to integrate the discussion of these related works into the paper. While it points out a relevant area for improvement, the feedback lacks depth and actionable suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper, noting that it only discusses observed phenomena without providing deeper insights into how these observations can be used to design better resilient systems. The reviewer suggests that the authors could explore joining a proposed defense method to make it more closely resemble a hierarchical system, thereby demonstrating the usefulness and significance of the observed results. While the comment implies an action for the authors to take, it does not provide explicit instructions on how to implement this suggestion. The authors can infer that they need to explore the application of defense methods to enhance the resilience of systems, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s focus on observed phenomena without providing deeper insights into how these observations can be used to design better resilient systems. It suggests exploring the application of a proposed defense method to make the system more closely resemble a hierarchical system, thereby demonstrating the usefulness and significance of the observed results. However, the comment does not specify which part of the paper this critique pertains to, making it weakly grounded. The suggestion to explore the application of a defense method is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper only discusses observed phenomena without providing deeper insights into how these observations can be used to design better resilient systems. The reviewer suggests exploring the application of a proposed defense method to make the system more closely resemble a hierarchical system, thereby demonstrating the usefulness and significance of the observed results. However, the comment lacks specific examples or references to support the claim that the current approach is insufficient or that the suggested method would be beneficial. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the feedback. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks detailed evidence or examples.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by noting that it only discusses observed phenomena without providing deeper insights into how these observations can be used to design better resilient systems. It suggests that the authors could explore joining a proposed defense method to make it more closely resemble a hierarchical system, which could demonstrate the usefulness and significance of the observed results. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by exploring the application of defense methods. However, the comment could be more helpful if it included examples or references to existing work that could guide the authors in implementing this suggestion. Overall, the comment is mostly helpful, as it offers a constructive way to improve the paper, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors are attempting to evaluate a form of reliability or trust by examining what Large Language Models (LLMs) \"know,\" but it criticizes the lack of rigorous definitions. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific definitions should be included. The action is implicit and vague, as the authors are left to infer that they need to provide definitions but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors are evaluating a form of reliability or trust by examining what Large Language Models (LLMs) \"know,\" but it criticizes the lack of rigorous definitions. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its critique of the lack of definitions but lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors are attempting to evaluate a form of reliability or trust by examining what Large Language Models (LLMs) \"know,\" but it criticizes the lack of rigorous definitions. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the authors are attempting to evaluate a form of reliability or trust by examining what Large Language Models (LLMs) \"know,\" but it criticizes the lack of rigorous definitions. This feedback highlights a critical area for improvement, as the absence of clear definitions can undermine the validity of the evaluation. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as proposing potential definitions or frameworks for evaluation. While it points out a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it directs the authors to a key area for improvement but does not fully support them in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the necessity of masked self-attention in the Y-Future encoder and the preference for ProbSparse. It also inquires about the impact on computational efficiency, particularly in the context of larger forecasting horizons compared to history lengths in some experiments. While the comment identifies areas that need clarification or exploration, it does not provide explicit instructions or suggestions on how the authors should address these questions. The authors are left to infer that they should investigate the importance of masked self-attention and its impact on computational efficiency, but without concrete guidance, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the necessity of masked self-attention in the Y-Future encoder and the preference for ProbSparse, as well as its impact on computational efficiency. It references Appendix E.2, which provides some grounding by indicating the specific section where the experiments are discussed. However, the comment does not specify which part of the paper discusses the Y-Future encoder or the preference for ProbSparse, making it weakly grounded. The comment is specific in its questions about the importance of masked self-attention and its potential impact on computational efficiency. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the necessity of masked self-attention in the Y-Future encoder and the preference for ProbSparse, as well as its impact on computational efficiency. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The comment lacks specific examples or detailed explanations that would help the authors understand the basis of the questions or how to address them. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to improve their work. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises important questions about the necessity of masked self-attention in the Y-Future encoder and the preference for ProbSparse. It also inquires about the impact on computational efficiency, particularly in the context of larger forecasting horizons compared to history lengths in some experiments. These questions are relevant and could prompt the authors to clarify their design choices and their implications. However, the comment does not provide specific suggestions or guidance on how the authors might address these questions or improve their work. While it identifies areas for further exploration, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack in the theoretical analysis regarding why deep layer parameters are more suitable for distillation. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion of what specific aspects of the theoretical analysis need to be included or how the authors might improve it. As a result, the authors are left without a clear understanding of what actions to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out a lack in the theoretical analysis regarding why deep layer parameters are more suitable for distillation. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. Without explicit references or detailed guidance, the authors cannot confidently determine where to address this concern. The comment is not grounded as it does not identify a specific part of the paper, and it is also not specific because it lacks details on what aspects of the theoretical analysis are lacking. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the theoretical analysis of why deep layer parameters are more suitable for distillation is lacking. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks depth, namely the theoretical analysis of why deep layer parameters are more suitable for distillation. This feedback is clear and highlights a critical aspect of the paper that needs further elaboration. However, the comment does not provide specific suggestions or guidance on how the authors might enhance this theoretical analysis or what additional insights could be included. While it points out a significant gap, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that many important details are located in the appendix, suggesting that the paper is not sufficiently self-contained. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The comment implies that the authors should consider moving important details to the main body of the paper, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that important details are in the appendix, implying that the paper is not self-contained. However, it does not specify which details are missing or which parts of the paper are affected. The authors might infer that the appendix is the issue, but the comment lacks specificity and grounding, making it difficult for them to pinpoint the exact areas needing improvement. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"a lot of the important paper details are in the appendix,\" suggesting that the paper is not sufficiently self-contained. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand which details are missing or why they are crucial. Without detailed justification or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that many important details are located in the appendix, suggesting that the paper is not sufficiently self-contained. This is a valid observation that could help the authors improve their draft by ensuring that critical information is included in the main body of the paper. However, the comment lacks specific guidance on which details are missing or how to integrate them into the main text. While it identifies a potential issue, it does not provide actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a mixed opinion about the argument presented in the paper, acknowledging the potential for scaling with gradient descent methods but questioning whether the dataset size of 50K points is considered \"large enough.\" However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the concern or what specific steps to consider for scaling to larger datasets. As a result, the comment lacks actionable advice, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a general observation about the argument presented in the paper regarding the use of gradient descent methods for clustering and the scalability to large datasets. However, it does not specify which part of the paper this observation is based on, making it weakly grounded. The comment also lacks specificity as it does not detail what aspects of the argument are unclear or how the dataset size affects the scalability. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point expresses a mixed opinion about the argument presented in the paper, acknowledging the potential for scaling with gradient descent methods but questioning whether the dataset size of 50K points is considered \"large enough.\" However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that 50K points are not large enough. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the argument presented in the paper regarding the use of gradient descent methods for clustering and their potential for scaling to large datasets. However, it questions the dataset size used in the study, suggesting that 50K points may not be considered \"large enough.\" While the comment identifies a potential limitation in the dataset size, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their dataset size. The feedback is somewhat helpful as it points out a potential area for improvement but lacks depth and actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practicality of the assumptions made in the paper, specifically questioning the feasibility of \"overloading the library with ASD subroutines\" (assumption 3.2). However, it does not provide any explicit or implicit guidance on how the authors should address this concern or what steps they should take to improve the practicality of their assumptions. The comment lacks actionable details, leaving the authors without a clear understanding of how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific assumption related to \"overloading the library with ASD subroutines\" (assumption 3.2), which provides full grounding as the authors can accurately identify the part of the paper being discussed. However, the comment lacks specificity because it does not detail what is meant by \"how hard it is\" or how this affects the practicality of the assumptions. The authors are left without clear guidance on what needs to be addressed or improved in this regard. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point questions the practicality of the assumptions made in the paper, specifically regarding the method\\'s reliance on \"overloading the library with ASD subroutines\" (assumption 3.2). However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate why this assumption might be impractical. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the practicality of the assumptions made in the paper, specifically questioning the feasibility of \"overloading the library with ASD subroutines\" (assumption 3.2). While it identifies a potential issue, the comment lacks depth and does not provide any actionable suggestions or guidance on how the authors might address this concern. Without specific advice or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the methodology used in the paper is not exciting because it is commonly used in data augmentation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what changes could be made to improve the paper. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the methodology used in the paper is not exciting because it is commonly used in data augmentation. However, it does not specify which part of the paper this comment addresses, nor does it provide details on what aspects of the methodology are not exciting or how it could be improved. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which part of the paper is being critiqued. Additionally, the comment lacks specificity regarding what needs to be addressed or how the authors might enhance the methodology. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the methodology used in the paper is not exciting because it is commonly used in data augmentation. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without further explanation or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the methodology used in the paper is not exciting because it is commonly used in data augmentation. However, it does not provide any specific guidance or suggestions on how the authors might enhance their methodology or make it more innovative. Without actionable feedback or detailed critique, the authors are left without a clear understanding of what changes could be made to improve their work. This lack of specificity and actionable advice makes the comment unhelpful, as it does not contribute to the authors\\' understanding of how to enhance their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific issue with the paper, stating that some statements are incorrect. It provides a concrete example by referencing section 4 and Fig. 4, where it claims that the multi-image IMP does not significantly improve the quality of LIPs in the cross-domain setting. This feedback is clear and actionable, as it directs the authors to correct the incorrect statements in their paper. The authors know exactly which part of the paper needs revision and what needs to be corrected. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4\" and \"Fig. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the statements in section 4 regarding the results presented in Fig. 4. The comment points out that the multi-image IMP does not show significant improvement in the quality of LIPs in the cross-domain setting, as suggested by the authors. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some statements in the paper are incorrect, specifically regarding the results presented in Fig. 4. It provides a clear example by contrasting the authors\\' statement with the actual data from Fig. 4, which shows that multi-image IMP does not significantly improve the quality of LIPs in the cross-domain setting. This claim is fully verifiable as it is supported by a specific reference to the figure and a direct comparison of the results, providing a clear and logical justification for the claim. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, pointing out that some statements are incorrect. It provides a concrete example by referencing section 4 and Fig. 4, where it claims that the multi-image IMP does not significantly improve the quality of LIPs in the cross-domain setting, contrary to what the authors have stated. This feedback is clear and actionable, as it directs the authors to correct the incorrect statements in their paper. By addressing this issue, the authors can improve the accuracy and credibility of their work. Therefore, the comment is rated as highly helpful, as it provides specific guidance that can lead to significant improvements in the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a ranking of the proposed method in the VLN Leaderboard and compares it unfavorably to existing methods, citing specific references. However, it does not offer any explicit or implicit actions for the authors to take in response to this feedback. The comment highlights a performance issue but does not suggest ways to improve the method or address the comparison with existing works. Without actionable guidance, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"VLN Leaderboard\" and the ranking of the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it compares the results of the proposed method to existing methods, providing references to specific works ([1, 2, 3]) that the authors can use for comparison. This level of detail helps the authors understand what needs to be addressed in terms of improving the performance of their method. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results of the proposed method are not better than existing methods, citing specific references to support this claim. The inclusion of references to Zhu et al. (2020), Tan et al., and Ke et al. provides a basis for the comparison, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or specific metrics to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment points out that the proposed method\\'s performance in the VLN Leaderboard is not better than existing methods, as evidenced by its 22nd rank. It supports this claim by referencing specific existing works, such as Zhu et al. (2020), Tan et al., and Ke et al. This feedback is valuable as it highlights a critical issue with the proposed method\\'s performance and provides references for the authors to consider in their improvement efforts. However, the comment could be more helpful if it offered suggestions on how to improve the method or provided additional context for the comparison. Overall, the comment is mostly helpful, as it directs the authors\\' attention to a significant area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the discussion in section 2.2, stating that it is not convincing regarding how semantic similarity is modeled with the proposed approach. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on what specific aspects of the discussion need improvement, how the authors might enhance the convincingness of their argument, or what additional information could be included. As a result, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, stating that it is not convincing regarding how semantic similarity is modeled with the proposed approach. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion in section 2.2 is not convincing regarding how semantic similarity is modeled with the proposed approach. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the discussion in section 2.2, stating that it is not convincing regarding how semantic similarity is modeled with the proposed approach. This feedback is somewhat helpful as it points out a weakness in the paper, prompting the authors to revisit and strengthen their discussion. However, the comment lacks depth and does not provide specific suggestions or guidance on how to improve the discussion or what aspects need more elaboration. While it directs the authors' attention to an area needing improvement, it does not offer actionable steps to enhance the draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the proposed SEPAI3R3O model, specifically the introduction of over 10 parameters that may be difficult to estimate reliably due to limited real-world observations. It also notes that modeling these parameters as time-varying further complicates the estimation challenge. The comment explicitly suggests that the authors should discuss the uncertainty in fitted parameter values and provide sensitivity analysis. This feedback is clear and direct, providing specific actions for the authors to take to address the concern. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the proposed SEPAI3R3O model, specifically mentioning the introduction of over 10 parameters and the challenge of estimating them with limited real-world observations. It suggests that the authors should discuss the uncertainty in fitted parameter values and provide sensitivity analysis. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the model's parameters and estimation challenges. The authors can infer that this comment relates to the methodology or results sections, where the model is discussed. The comment is specific in detailing what needs to be addressed, namely the uncertainty in parameter values and the need for sensitivity analysis. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed SEPAI3R3O model introduces over 10 parameters, which may be difficult to estimate reliably due to limited real-world observations. It further suggests that modeling these parameters as time-varying exacerbates the estimation challenge. The comment provides a logical reasoning for the potential difficulty in estimation, which is based on the complexity of the model and the limited data available. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider the reasoning and potentially conduct additional analysis to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed SEPAI3R3O model, specifically the introduction of over 10 parameters that may be difficult to estimate reliably due to limited real-world observations. It also notes that modeling these parameters as time-varying further complicates the estimation challenge. The comment provides a clear and actionable suggestion for the authors to discuss the uncertainty in fitted parameter values and conduct sensitivity analysis. This feedback is valuable as it highlights a critical aspect of the model's reliability and offers a specific direction for improvement. By addressing these concerns, the authors can enhance the robustness and credibility of their model. Therefore, the comment is mostly helpful, as it provides actionable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the assumption that causal parameters across domains are random samples, questioning whether this assumption is a direct consequence of not having latent confounders. It also suggests that the performance of the proposed method and the relative performances of MC, IB, and HSIC tests depend on how parameters change across domains. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The feedback lacks actionable details, such as recommending specific analyses or experiments to conduct, making it difficult for the authors to know exactly what steps to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the assumption that causal parameters across domains are random samples and questions the relationship between this assumption and the presence of latent confounders. It also discusses the performance of the proposed method and the relative performances of MC, IB, and HSIC tests, suggesting that these depend on how parameters change across domains. However, the comment does not specify which part of the paper these concerns relate to, such as specific sections or figures, making it weakly grounded. The comment is specific in detailing the issues with the assumption and the performance dependency, but without clear grounding, it is challenging for the authors to identify the exact parts of the paper that need revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the assumption that causal parameters across domains are random samples, questioning whether this assumption is a direct consequence of not having latent confounders. It also suggests that the performance of the proposed method and the relative performances of MC, IB, and HSIC tests depend on how parameters change across domains. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The lack of concrete evidence or detailed justification makes it difficult for the authors to understand and address the concerns. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires more detailed support to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a critical concern about the assumption that causal parameters across domains are random samples, questioning whether this assumption is a direct consequence of not having latent confounders. It also highlights the potential dependency of the proposed method\\'s performance and the relative performances of MC, IB, and HSIC tests on how parameters change across domains. This feedback is somewhat helpful as it identifies a potential weakness in the paper\\'s assumptions and suggests that the authors should consider the impact of parameter changes on their results. However, the comment lacks specific guidance or suggestions on how to address these concerns, such as recommending additional analyses or experiments. To be more helpful, the comment could provide more detailed advice or examples, making it somewhat actionable but not fully comprehensive. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the novelty of the structural optimization method and suggests that it is not clear whether it is new or not. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify the novelty or what specific aspects of the paper need to be revised. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the novelty of the structural optimization method and suggests that it is not clear if it is new or not. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the novelty is discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, the comment does not provide specific guidance on how to address the issue of novelty. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the novelty of the structural optimization method, suggesting that it is not clear whether it is new or not. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the novelty of the structural optimization method, questioning whether it is new or not. It also points out that the method is mentioned in the paper title, which makes the narrative weaker. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or clarify the novelty of their method. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful at all, as it lacks actionable insights or constructive suggestions.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the proof, specifically that it assumes lambda should not be 0.5, whereas in standard mixup, lambda can indeed be 0.5. This implies that the authors should reconsider their assumption in the proof. However, the comment does not provide explicit guidance on how to address this issue or suggest specific changes to the proof. The action is implicit and somewhat vague, as the authors need to infer that they should revisit their assumptions and potentially revise the proof. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the assumption in the proof regarding the value of lambda. The comment clearly specifies what needs to be addressed, namely the assumption that lambda should not be 0.5, and how it may not align with standard mixup practices. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the assumption in the proof may not be correct because the lambda value is not restricted to 0.5 in standard mixup. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the assertion. This lack of supporting information makes the claim somewhat verifiable, as the authors would need to investigate further to understand the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proof, specifically the assumption that lambda should not be 0.5. It points out that in standard mixup, the mixed sample can be generated even when lambda is 0.5, which may contradict the assumption in the proof. This feedback is somewhat helpful as it highlights a specific area of concern that the authors should address. However, it lacks detailed guidance or suggestions on how to resolve this issue or improve the proof. To be more helpful, the comment could provide additional context or examples to support the claim or suggest potential revisions. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two explicit actions for the authors to take. First, it suggests highlighting which set of equations have the same form as the Riccati equation in the paragraph above Theorem 3.1. This is a clear and concrete instruction that guides the authors on what specific information to include in their draft. Second, it recommends extracting some of the inlined math into environments to facilitate looking up symbols, specifically on page 6. This action is also explicit and provides a clear direction for improvement. Both suggestions are concrete and directly actionable, allowing the authors to know exactly what changes to make to enhance their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the paragraph above Theorem 3.1\" and \"page 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear instructions on what needs to be addressed: highlighting which set of equations have the same form as the Riccati equation and extracting inlined math into environments to facilitate symbol lookup. This level of detail guides the authors on how to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two separate suggestions: one regarding highlighting equations similar to the Riccati equation and another about extracting inlined math into environments. Neither suggestion is a claim that requires verification; they are requests for clarification or improvement. Therefore, the comment is factual and does not contain any claims, fitting the label \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides two specific and actionable suggestions for improving the clarity and readability of the paper. First, it recommends highlighting which set of equations have the same form as the Riccati equation, which would enhance the understanding of the mathematical content. Second, it suggests extracting inlined math into environments to facilitate symbol lookup, particularly on page 6. These suggestions are clear and concrete, offering the authors direct guidance on how to enhance the presentation and accessibility of their work. By addressing these points, the authors can improve the overall quality and readability of their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that certain sections of the paper would benefit from clearer structure and transitions. It also points out the use of subjective terms like \"significant\" and recommends providing statistical evidence, such as p-values, to support these claims. While the comment identifies areas for improvement, it does not provide specific guidance on how to achieve clearer structure or how to incorporate statistical evidence. The action is explicit but somewhat vague, as the authors know they need to improve clarity but may not be entirely sure how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses issues with clarity in writing, specifically mentioning the need for clearer structure and transitions in certain sections. It also points out the use of subjective terms like \"significant\" and suggests providing statistical evidence, such as p-values, to support these claims. However, the comment does not specify which sections are problematic or where the term \"significant\" is used, making it weakly grounded. The authors can infer that it relates to specific sections of the paper but cannot pinpoint them accurately. The comment is specific in suggesting improvements, such as providing statistical evidence, but lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that certain sections of the paper would benefit from clearer structure and transitions, and it specifically mentions the use of subjective terms like \"significant\" without statistical evidence. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim about the need for clearer structure and transitions. Additionally, the suggestion to use statistical evidence like p-values is a reasonable recommendation but is not fully elaborated. Therefore, the comment is somewhat verifiable, as it provides a general direction for improvement but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two areas for improvement in the paper: clarity in writing and the use of subjective terms without statistical evidence. It suggests that certain sections could benefit from clearer structure and transitions, which is a valuable observation. Additionally, it points out the use of subjective terms like \"significant\" and recommends providing statistical evidence, such as p-values, to support these claims. This feedback is clear and actionable, as it directs the authors to enhance the clarity and rigor of their writing. However, the comment could be more helpful if it provided specific examples or sections where these improvements are needed. Overall, the comment is mostly helpful, as it offers constructive feedback that can guide the authors in improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the detailed information for graph construction is missing, specifically mentioning the definition of edges and the construction of graphs for non-Euclidean datasets. This provides a clear and direct action for the authors to take, which is to include this information in their draft. The comment is explicit and concrete, as it specifies exactly what needs to be added to improve the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"detailed information for graph construction,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what is missing, namely the definition of edges and the construction of graphs for non-Euclidean datasets. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the detailed information for graph construction is missing, specifically mentioning the definition of edges and the construction of graphs for non-Euclidean datasets. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the specific issues or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, namely the lack of detailed information on graph construction, particularly for non-Euclidean datasets. It highlights the need for clarification on how edges are defined and how graphs are constructed in such datasets. This feedback is clear and actionable, as it directs the authors to include this critical information in their draft. However, the comment could be more helpful if it provided examples or suggestions on how to address these issues. Overall, the comment is mostly helpful as it points out a significant area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the default settings for hyper-parameters \u03b1 and \u03b2, implying that the authors should provide more information on how these settings are determined. However, the comment does not explicitly instruct the authors to include this information or provide guidance on how to present it. The action is implicit and somewhat vague, as the authors can infer that they need to address the question but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the default settings for hyper-parameters \u03b1 and \u03b2, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to the methodology or experimental setup sections, but without explicit grounding, it is difficult to pinpoint the exact location. The comment is specific in asking for clarification on the determination of these default settings, but it lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the default settings for hyper-parameters \u03b1 and \u03b2, referencing a specific paper for context. However, the comment does not provide any reasoning or justification for why this information is important or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the relevance of this question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the default settings for hyper-parameters \u03b1 and \u03b2, which is an important aspect of the methodology. However, it does not provide any context or explanation for why this information is relevant or how it might impact the results. Without additional guidance or suggestions, the authors are left with a vague question that does not offer a clear path for improvement. The comment lacks actionable feedback, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification regarding the visual or textual representations used in each method presented in Table 4. It also questions whether the end-to-end performance gain is due to the proposed attention model. This feedback provides a clear and direct action for the authors to take, which is to provide more detailed information about the representations used in each method. The comment is explicit and concrete, as it specifies exactly what needs to be addressed and how to improve the clarity of the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the visual or textual representations used in each method, which is necessary to understand the performance gain attributed to the proposed attention model. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the visual or textual representations used in each method presented in Table 4, suggesting that without this information, it is unclear whether the end-to-end performance gain is due to the proposed attention model. This is a logical observation that requires clarification from the authors. However, the comment does not provide any supporting evidence or references to substantiate the claim, making it somewhat verifiable. The authors would need to provide additional information to fully address the concern, which aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the lack of clarity regarding the visual or textual representations used in each method presented in Table 4. It questions whether the end-to-end performance gain is due to the proposed attention model, highlighting a potential gap in the explanation of the results. This feedback is clear and actionable, as it prompts the authors to provide more detailed information about the representations used, which would enhance the understanding and interpretation of the results. However, the comment could be more helpful if it suggested specific ways to address this issue or provided examples of how to clarify the representations. Overall, the comment is mostly helpful, as it directs the authors to a critical area that needs clarification, but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the convergence analysis, including the lack of clarity in the main part of the paper, the simplicity of the proof in the appendix, and the unclear presentation of notations such as D and G. It also points out the absence of an explanation for the assumption that \\\\(\\\\alpha_k\\\\) converges to \\\\(\\\\alpha\\\\) and the lack of justification for Eq. (15). While the comment identifies specific areas that need improvement, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they need to clarify the convergence analysis and provide more detailed explanations, but the comment lacks actionable guidance on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"convergence analysis\" and the appendix, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the convergence analysis, such as the lack of clarity in the main part, the simplicity of the proof in the appendix, and the unclear presentation of notations like D and G. Additionally, it points out the absence of an explanation for the assumption that \\\\(\\\\alpha_k\\\\) converges to \\\\(\\\\alpha\\\\) and the lack of justification for Eq. (15). This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the convergence analysis is unclear and lacks detailed explanations in the main part of the paper. It specifically mentions the simplicity of the proof in the appendix and the unclear presentation of notations such as D and G. The reviewer also points out the absence of an explanation for the assumption that \\\\(\\\\alpha_k\\\\) converges to \\\\(\\\\alpha\\\\) and the lack of justification for Eq. (15). While the comment highlights several issues, it does not provide detailed reasoning or examples to fully substantiate the claims. The lack of specific examples or references makes it somewhat verifiable, as the authors would need to delve deeper into the paper to understand the exact nature of the issues. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the convergence analysis, including the lack of clarity in the main part of the paper, the simplicity of the proof in the appendix, and the unclear presentation of notations such as D and G. It also points out the absence of an explanation for the assumption that \\\\(\\\\alpha_k\\\\) converges to \\\\(\\\\alpha\\\\) and the lack of justification for Eq. (15). These specific criticisms provide the authors with clear areas for improvement, such as enhancing the clarity of the convergence analysis and providing more detailed explanations for the assumptions and equations. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to improve the clarity of the proof. Overall, the comment is mostly helpful as it directs the authors to focus on enhancing the clarity and rigor of their convergence analysis.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies several issues with the paper, including the lack of well-driven and illustrated problems, insufficient description of uncertainty calibration, and the need for better organization and summarization of studied issues. However, it does not provide explicit guidance or suggestions on how to address these issues. The authors are left to infer that they need to improve the clarity and organization of their work, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of well-driven and illustrated problems, specifically mentioning the insufficient description of uncertainty calibration. It also highlights the need for better organization and summarization of studied issues like small datasets, heterogeneous data distribution, uncertainty calibration, and new clients. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the introduction or background sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed, such as improving the description of uncertainty calibration and organizing the studied issues. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the studied problems are not well-driven and illustrated, specifically mentioning the insufficient description of uncertainty calibration. It also suggests that the studied issues, such as small datasets and heterogeneous data distribution, should be further organized and summarized. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it provides a general direction for improvement but lacks concrete guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas where the paper could be improved, specifically noting that the studied problems are not well-driven and illustrated. It highlights the insufficient description of uncertainty calibration, which is a critical aspect that may be unfriendly to new readers. Additionally, the comment suggests that the studied issues, such as small datasets and heterogeneous data distribution, should be further organized and summarized. While the comment provides some direction for improvement, it lacks specific suggestions or examples on how to address these issues, such as proposing alternative methods for describing uncertainty calibration or providing examples of how to better organize the studied issues. This limits the comment\\'s usefulness, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the results section, noting that there are no explorations of incorporating PAC-tuning with other fine-tuning techniques like pruning and data augmentation. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how the authors should address this gap or suggest specific techniques to explore. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct additional experiments or analyses to fill this gap. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific area for improvement by noting the absence of results exploring the incorporation of PAC-tuning with other fine-tuning techniques like pruning and data augmentation. However, it does not specify which part of the paper this observation pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the missing exploration, but without clear grounding, it is challenging for the authors to know where to focus their efforts. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are no results exploring the incorporation of PAC-tuning with other fine-tuning techniques like pruning and data augmentation. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the significance of this claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by noting the absence of results exploring the incorporation of PAC-tuning with other fine-tuning techniques like pruning and data augmentation. This feedback is clear and actionable, as it directs the authors to consider additional experiments or analyses that could enhance the comprehensiveness of their work. However, the comment could be more helpful if it provided suggestions on which specific techniques to explore or how to integrate them effectively. Despite this, the feedback is mostly helpful as it guides the authors toward a meaningful expansion of their study. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experimental analysis is insufficient and recommends validating it on more models. However, it does not provide specific guidance on which models should be used or how the analysis should be expanded. The action is implicit and somewhat vague, as the authors are left to infer the details of the suggested improvement. While the comment highlights an area for improvement, it lacks concrete details on how to implement the suggested changes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experimental analysis is insufficient and recommends validating it on more models. However, it does not specify which part of the paper the experimental analysis is in, making it difficult for the authors to pinpoint the exact section that needs improvement. Additionally, the comment lacks specificity regarding what aspects of the analysis are insufficient or how the validation on more models should be conducted. The reference to the fourth question below does not provide additional context or guidance. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the experimental analysis is insufficient and suggests that it should be validated on more models. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the current analysis is insufficient or how validating it on more models would improve the paper. Without specific details or references, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a weakness in the experimental analysis, noting that it is insufficient and suggests that it should be validated on more models. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by expanding the scope of their experimental validation. However, the comment could be more helpful if it offered additional guidance on which models should be considered or how the analysis could be enhanced. Despite this, the comment is mostly helpful as it directs the authors toward a meaningful improvement in their experimental section.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a critique of the proposed method, noting that while it improves over the original initialization, the results are limited to a specific scenario (trainability of a network with 100 layers on CIFAR) and do not demonstrate significant improvement over baselines in ImageNet experiments. The comment references two external works, [1] and [2], which suggests that the authors should consider these references in their work. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve the method. The action is implicit and somewhat vague, as the authors can infer that they need to expand their experiments or improve their method, but they are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"original initialization,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the proposed method only shows improvement in a specific scenario (trainability of a network with 100 layers on CIFAR) and lacks significant improvement over baselines in ImageNet experiments. The reference to specific external works, [1] and [2], further supports the critique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method improves over the original initialization but only demonstrates this improvement in a specific scenario (trainability of a network with 100 layers on CIFAR). It also notes that the ImageNet experiments show marginal improvement over baselines. The comment supports this claim by referencing two external works, [1] and [2], which provide context and suggest that the proposed method may not be as effective as claimed. However, the comment could be strengthened by providing more detailed comparisons or specific examples from the referenced works. Overall, the claim is mostly verifiable, as it provides some justification but could benefit from more detailed evidence or references. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a critique of the proposed method, noting that while it improves over the original initialization, the results are limited to a specific scenario (trainability of a network with 100 layers on CIFAR) and do not demonstrate significant improvement over baselines in ImageNet experiments. The comment references two external works, [1] and [2], which suggests that the authors should consider these references in their work. However, the comment lacks specific suggestions or guidance on how the authors might address these limitations or improve their method. While it identifies an area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to enhance their draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. This is an explicit action that provides a clear direction for the authors to enhance their draft. The comment specifies what needs to be addressed, which is the comparison of robustness and immunizability, and suggests a specific reference for the comparison. This level of detail makes the action concrete and directly actionable for the authors. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. However, it does not specify which part of the paper this discussion should be added to, nor does it provide details on what aspects of robustness and immunizability should be compared. This makes it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in suggesting a comparison, but it lacks grounding and specificity, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. However, it does not provide any reasoning, examples, or references to support why such a comparison is necessary or beneficial. The comment lacks specific details or evidence to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. This feedback is clear and actionable, as it identifies a specific area for improvement and provides a clear direction for the authors to enhance their draft. By incorporating this comparison, the authors can provide a more comprehensive evaluation of their method and its strengths relative to existing work. However, the comment could be more helpful if it included specific suggestions on how to conduct this comparison or what aspects to focus on. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the claim that the proposed algorithm produces \"better\" samples and requests clarification. It also suggests that a plot of the time complexity of the decoding scheme as a function of m would be beneficial. While the comment implies that the authors should provide additional information or clarification, it does not explicitly instruct them to do so. The action is somewhat vague, as it does not specify exactly what kind of clarification or additional information is needed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"3)\" and \"adaptive top-k decoding,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the claim of producing \"better\" samples and suggests that a plot of the time complexity of the decoding scheme as a function of m would be beneficial. This provides clear guidance on what the authors need to address or include in their work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that the proposed algorithm produces \"better\" samples, suggesting a need for clarification. However, it does not provide any specific evidence, reasoning, or references to support this claim. The request for a plot of the time complexity of the decoding scheme as a function of m is a suggestion for improvement but lacks detailed justification or examples. As a result, the comment is considered unverifiable, as it lacks sufficient evidence or reasoning to support the claim or suggestion.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the claim that the proposed algorithm produces \"better\" samples, indicating a need for clarification. It also suggests that a plot of the time complexity of the decoding scheme as a function of m would be beneficial. While the comment identifies a potential area for improvement, it lacks depth and does not provide specific guidance on how to address the issue or what aspects of the time complexity should be plotted. The feedback is somewhat helpful as it points out a potential area for clarification, but it could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the postprocessing effort mentioned in footnote 2, indicating that it is unclear. However, it does not provide any explicit guidance or suggestions on how the authors should clarify this point. The action is implicit, as the authors need to infer that they should provide more information about the postprocessing effort. The comment lacks concrete details on how to address the issue, making it vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"footnote 2\" and \"313,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the postprocessing effort mentioned in footnote 2. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the postprocessing effort mentioned in footnote 2, but it does not provide any supporting evidence, reasoning, or examples to justify why this effort is unclear. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the postprocessing effort mentioned in footnote 2. By pointing out the lack of clarity, the reviewer highlights a potential issue that the authors should address to improve the comprehensibility of their paper. However, the comment does not provide any suggestions or guidance on how the authors might clarify this point, such as by providing more detailed information or examples. While it directs the authors\\' attention to a specific area needing improvement, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks the authors to run the codes for multiple seeds and report the mean. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be done, making it highly actionable. The authors know exactly what action to take and how to implement it, ensuring that the feedback is actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the issue of running codes for multiple seeds and reporting the mean, allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it clearly specifies what needs to be addressed, namely, the need to run the codes for multiple seeds and report the mean. This provides clear guidance on how to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual question asking whether the authors have run the codes for multiple seeds and reported the mean. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and direct, asking the authors to run their codes for multiple seeds and report the mean. This feedback is actionable and provides a specific suggestion for improving the robustness and reliability of the results presented in the paper. By addressing this point, the authors can enhance the credibility and reproducibility of their work. However, the comment could be more helpful if it explained why reporting the mean across multiple seeds is important or how it impacts the overall analysis. Despite this, the feedback is mostly helpful as it offers a clear and actionable suggestion for improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the differences between the BCI and IHC4BC datasets and the experimental setup for each. It also points out a discrepancy in the results presented in Tables 2 and 3, specifically noting the absence of results for certain models like InceptionV3 and ResNet in Table 3. While the comment identifies areas that need clarification or explanation, it does not provide explicit instructions on how the authors should address these issues. The authors can infer that they need to provide a clear explanation of the dataset differences and experimental setup, as well as ensure consistency in the results presented across tables. However, the comment lacks concrete guidance on how to implement these changes, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the differences between the BCI and IHC4BC datasets and the experimental setup for each. It also points out a discrepancy in the results presented in Tables 2 and 3, specifically noting the absence of results for certain models like InceptionV3 and ResNet in Table 3. This provides specific guidance on what needs to be addressed, such as clarifying the dataset differences and ensuring consistency in the results. However, the comment does not explicitly mention which sections of the paper these issues are discussed in, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the differences between the BCI and IHC4BC datasets and the experimental setup for each. It also points out a discrepancy in the results presented in Tables 2 and 3, specifically noting the absence of results for certain models like InceptionV3 and ResNet in Table 3. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the questions and how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises important questions about the differences between the BCI and IHC4BC datasets and the experimental setup for each. It also points out a discrepancy in the results presented in Tables 2 and 3, specifically noting the absence of results for certain models like InceptionV3 and ResNet in Table 3. By highlighting these inconsistencies and gaps in the paper, the comment provides the authors with clear areas for improvement and clarification. However, it could be more helpful if it offered suggestions on how to address these issues or provided examples of how to present the results more consistently. Overall, the comment is mostly helpful as it directs the authors to important aspects of their work that need attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to provide a more thorough description of the results shown in Fig. 4. This is a direct and clear action that the authors can take to improve their draft. The comment specifies exactly what needs to be done, which is to enhance the description of the results in the figure. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is to provide a more thorough description of the results shown in the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point requests a more thorough description of the results shown in Fig. 4, which is a factual request for additional information. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the draft. By requesting a more thorough description of the results shown in Fig. 4, the reviewer offers a specific area for enhancement that can help the authors better communicate their findings to the readers. This feedback is direct and provides a clear path for the authors to improve their work, making it highly helpful. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their work more thoroughly with the literature, specifically mentioning reference [11]. It implies that the authors should include a more detailed comparison in the method section. However, the comment does not provide specific guidance on how to conduct this comparison or what aspects to focus on. While the action is implicit, it is somewhat concrete in suggesting a general direction for improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the work more thoroughly with the literature, specifically mentioning reference [11]. However, it does not specify which part of the paper should include this comparison or how it should be conducted. The authors can infer that it relates to the method section, but the comment lacks full grounding as it does not explicitly mention the section. It is specific in suggesting a comparison with the literature, but the lack of explicit grounding makes it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the literature reference [11] is more relevant and recommends comparing the work more thoroughly with it, particularly in the method section. However, the comment lacks specific details or examples to support why [11] is more relevant or how the comparison should be conducted. This makes the claim somewhat verifiable, as the authors would need to infer the relevance and details of the comparison themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should compare their work more thoroughly with the literature, specifically mentioning reference [11]. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper, namely the depth of literature comparison. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects to focus on. While it points out a relevant area for enhancement, it does not offer actionable steps for the authors to take, limiting its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the process of removing words with identical English counterparts in the class label translation and cleaning, suggesting that this process may not be fully justified. The reviewer references a specific paper, \"Ten Years of BabelNet: A Survey,\" which could provide additional context or justification for the concern. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to justify or modify their process. The action is implicit and somewhat vague, as the authors are left to infer that they should provide more justification for their method. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the process of removing words with identical English counterparts in the class label translation and cleaning, suggesting that this process may not be fully justified. However, it does not specify which part of the paper this process is described in, making it weakly grounded. The comment is specific in its critique, as it highlights a potential issue with the method and references a relevant external work, \"Ten Years of BabelNet: A Survey,\" which could provide additional context. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s process of removing words with identical English counterparts in the class label translation and cleaning may not be fully justified. The reviewer supports this claim by referencing a specific paper, \"Ten Years of BabelNet: A Survey,\" which could provide additional context or justification for the concern. However, the comment does not fully explain why this process is problematic or how it relates to the referenced paper, leaving some gaps in the justification. Therefore, the claim is mostly verifiable, as it provides some support but lacks detailed reasoning or examples to fully substantiate the critique.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the process of removing words with identical English counterparts in the class label translation and cleaning, suggesting that this process may not be fully justified. It references a specific paper, \"Ten Years of BabelNet: A Survey,\" which could provide additional context or justification for the concern. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their methodology. While it identifies a potential weakness, it lacks actionable feedback, making it somewhat helpful. The authors are left to infer that they should provide more justification for their process, but without detailed guidance, the comment does not fully support their improvement efforts. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the study should consider more models to verify the findings, implying that the authors should expand their analysis to include additional models. However, the comment does not provide specific guidance on which models to consider or how to incorporate them into the study. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the study should consider more models to verify the findings, implying that the current focus on LLaVA and InstructBLIP might be limited. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to specific sections or elements of the paper, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding which additional models should be considered or how they would enhance the study. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the study should consider more models to verify the findings, implying that the current focus on LLaVA and InstructBLIP might be limited. However, the comment does not provide any specific reasoning, examples, or references to support why additional models are necessary or how they would enhance the study. Without detailed justification or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the study should consider more models to verify the findings, implying that the current focus on LLaVA and InstructBLIP might be limited. This feedback is somewhat helpful as it points out a potential area for expansion, encouraging the authors to broaden their analysis to include additional models. However, the comment lacks specificity and does not provide guidance on which models to consider or how to incorporate them into the study. While it offers a direction for improvement, it does not fully support the authors in making those improvements. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the results presented in Figure 7 and Table 3, specifically noting that OpenCLIP shows a significant reduction in the norm but no significant improvement in object localization. The comment suggests that further explanation or exploration of the reason behind this discrepancy could be beneficial for the wider adoption of the work. While the comment implies that the authors should investigate and clarify this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the further explanation or exploration. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the discrepancy between the results in these figures and tables, particularly regarding the significant reduction for OpenCLIP and the lack of significant improvement for object localization. The comment suggests that further explanation or exploration of the reason behind this discrepancy could be beneficial for wider adoption. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between the results presented in Figure 7 and Table 3, specifically noting that OpenCLIP shows a significant reduction in the norm but no significant improvement in object localization. The comment suggests that further explanation or exploration of the reason behind this discrepancy could be beneficial for wider adoption. However, the comment does not provide specific reasoning or evidence to support why this discrepancy is significant or why it affects the adoption of the work. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the claim, rendering it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the results presented in Figure 7 and Table 3, specifically noting that OpenCLIP shows a significant reduction in the norm but no significant improvement in object localization. This observation highlights a potential inconsistency in the paper that could impact the interpretation and adoption of the results. The comment suggests that further explanation or exploration of the reason behind this discrepancy could be beneficial for wider adoption. While the comment points out a specific issue, it does not provide detailed guidance on how to address it or what specific aspects of the explanation or exploration should be focused on. Therefore, the comment is somewhat helpful, as it identifies a critical area for improvement but lacks depth and actionable suggestions. It aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a lack of clarity regarding the use of 3D renders along with G, specifically questioning how the point cloud is used in the process. It suggests that more details about the combination of 3D rendering and the GAN objective would be helpful. This feedback provides a clear and direct action for the authors to take, which is to provide additional details about the integration of 3D rendering and the GAN objective. The comment is explicit and concrete, offering a clear path for the authors to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the 3D renders are used along with G and requesting more details about the combination of 3D rendering and the GAN objective. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the clarity of the paper regarding the use of 3D renders along with G, specifically in Section 3.3. It requests more details about how the point cloud is used in this stage and how the 3D rendering and GAN objective are combined. This is a request for clarification rather than a claim, as it does not express an opinion or judgment. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper regarding the use of 3D renders along with G, particularly in Section 3.3. It questions how the point cloud is used in this stage and requests more details about the combination of 3D rendering and the GAN objective. This feedback is clear and actionable, as it directs the authors to provide additional information that would enhance the clarity and comprehensiveness of their work. By addressing this point, the authors can improve the transparency and coherence of their draft, making the comment mostly helpful. However, it could be more helpful if it provided specific suggestions on how to present this information or examples of what additional details might be included. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the increased complexity of hyperparameters in the QIF model compared to the traditional LIF model. It questions the claim of parameter insensitivity, suggesting that the supporting evidence is limited to simple architectures and datasets, which is not convincing. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their evidence. The action is implicit and vague, leaving the authors without clear direction on how to enhance their argument or provide more robust evidence. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of increased hyperparameter complexity in the QIF model compared to the traditional LIF model. It questions the claim of parameter insensitivity, suggesting that the supporting evidence is limited to simple architectures and datasets. However, the comment does not specify which part of the paper discusses these claims or provides evidence, making it weakly grounded. The authors can infer that it relates to the sections discussing the QIF model and its comparison to the LIF model, but this inference is not direct. The comment is specific in detailing the issue with the evidence provided, but without explicit references to sections or specific parts of the paper, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the QIF model introduces additional hyperparameters compared to the traditional LIF model, questioning the claim of parameter insensitivity. It suggests that the supporting evidence is limited to simple architectures and datasets, which is not convincing. However, the comment does not provide specific examples or detailed reasoning to substantiate this claim, making it somewhat verifiable. The authors would need to delve deeper into the paper to understand the basis of the claim and potentially address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by questioning the claim of parameter insensitivity in the QIF model compared to the traditional LIF model. It points out that the supporting evidence relies heavily on simple architectures and datasets, which may not be convincing. This feedback is somewhat helpful as it highlights an area where the authors might need to strengthen their argument or provide more robust evidence. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of more complex architectures or datasets that could be used to support the claim. Overall, the comment provides some direction for improvement but lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the marginal improvements over baselines achieved by the proposed method and suggests that further improvements might be possible with other pre-trained language models (PLMs) like RoBERTa, T5, vicuna, or llama-2. The reviewer also suggests discussing aspects such as computational costs or real-world scenarios in the context of large language models (LLMs). While the comment implies that the authors should consider these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss these aspects and consider alternative PLMs. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of marginal improvements over baselines and suggests that further improvements might be achievable with other pre-trained language models (PLMs) like RoBERTa, T5, vicuna, or llama-2. It also suggests discussing aspects such as computational costs or real-world scenarios in the context of large language models (LLMs). However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in suggesting areas for discussion and potential improvements, but without explicit references to sections or specific parts of the paper, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the marginal improvements over baselines achieved by the proposed method and suggests that further improvements might be possible with other pre-trained language models (PLMs) like RoBERTa, T5, vicuna, or llama-2. The reviewer provides a logical reasoning by questioning the necessity of a sophisticated framework to achieve the current level of performance and suggests discussing aspects like computational costs or real-world scenarios in the context of large language models (LLMs). However, the comment lacks specific examples or references to support the claim that other PLMs could lead to further improvements. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the marginal improvements over baselines achieved by the proposed method, questioning whether the sophistication of the framework is justified by the level of performance. It suggests that further improvements might be possible with other pre-trained language models (PLMs) like RoBERTa, T5, vicuna, or llama-2. The comment also prompts the authors to discuss aspects such as computational costs or real-world scenarios in the context of large language models (LLMs). While the comment identifies a potential area for improvement and suggests specific directions for further exploration, it lacks detailed guidance on how to address these points or what specific aspects of the method or experiments should be discussed. The feedback is somewhat helpful as it provides a direction for improvement but could be more actionable with additional details. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the explanation regarding the use of soft assignment instead of hard assignment in the methodology. It questions whether the authors have conducted an experiment to prove their conjecture. However, the comment does not provide explicit guidance on what the authors should do to address this issue. It lacks actionable steps or suggestions on how to improve the clarity or conduct experiments to support the conjecture. As a result, the authors are left without a clear understanding of how to proceed, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the explanation of using soft assignment instead of hard assignment in the methodology section. It questions whether the authors have reported an experiment to prove their conjecture, indicating that the authors should clarify this aspect. However, the comment does not specify which part of the methodology section this issue pertains to, making it weakly grounded. The comment is specific in its request for clarification on the experimental validation of the conjecture. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the clarity of the explanation regarding the use of soft assignment instead of hard assignment in the methodology. It expresses uncertainty about whether the authors have conducted an experiment to prove their conjecture. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the explanation of using soft assignment instead of hard assignment in the methodology. It questions whether the authors have conducted an experiment to prove their conjecture, indicating a lack of clarity or evidence in the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it highlights a potential weakness, it lacks actionable feedback, making it somewhat helpful. The authors are given some insight into an area that needs improvement but are not provided with detailed steps to enhance their draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the applicability of the methods presented, noting that they are mostly relevant in the cross-silo setting and may not be as beneficial for general federated learning problems with a larger number of clients. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this limitation or suggestions for potential improvements. As a result, the authors are left without a clear understanding of what steps to take to enhance the applicability of their methods. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the applicability of the methods presented in the paper, specifically mentioning the cross-silo setting and its limitations in general federated learning problems. However, it does not specify which part of the paper discusses these methods or their applicability, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the methods\\' applicability but lacks grounding, as it does not provide a clear reference to the relevant part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the methods presented are mostly applicable in the cross-silo setting, which limits their applicability to general federated learning problems. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the applicability of the methods presented, noting that they are mostly relevant in the cross-silo setting and may not be as beneficial for general federated learning problems with a larger number of clients. This feedback is somewhat helpful as it highlights a potential weakness in the paper\\'s scope and applicability. However, it lacks specific suggestions or guidance on how the authors might address this limitation or expand the applicability of their methods. While it provides some insight into the paper\\'s limitations, it does not offer actionable advice for improvement, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about what constitutes distributional generalization in the context of regression. It provides a momentary consideration of the phenomenon in the setting of regression, suggesting that a smooth regression model interpolating train data would exhibit distributional generalization. However, the comment does not offer any explicit or implicit actions for the authors to take. It lacks guidance on how to address the question or improve the draft based on this observation. As a result, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about what constitutes distributional generalization in the context of regression, providing a momentary consideration of the phenomenon. However, it does not specify which part of the paper this question pertains to, nor does it provide specific guidance on how to address the issue. The authors may infer that it relates to the methodology or results sections, but the lack of explicit grounding and specificity makes it challenging for them to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about what constitutes distributional generalization in the context of regression. It provides a momentary consideration of the phenomenon, suggesting that a smooth regression model interpolating train data would exhibit distributional generalization. However, the comment lacks specific examples, references, or detailed reasoning to support the claim or provide a clear understanding of the concept. The lack of supporting evidence or detailed explanation makes the claim difficult for the authors to verify or address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about what constitutes distributional generalization in the context of regression. It provides a momentary consideration of the phenomenon, suggesting that a smooth regression model interpolating train data would necessarily exhibit distributional generalization. However, the comment lacks depth and does not offer any specific suggestions or guidance for the authors to improve their work. It does not address any weaknesses or areas for improvement in the draft, leaving the authors without actionable feedback. Therefore, the comment is not helpful at all, aligning with a score of 1.\", 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the references and baselines are outdated and recommends covering more recent research. It also provides a specific suggestion to search for \"Item Frequencies of Data Streams\" to obtain additional results. This feedback is clear and provides concrete actions for the authors to take, such as updating the references and incorporating more recent research. The explicit nature of the suggestion and the specific guidance on how to implement it make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the references and baselines are outdated and recommends covering more recent research. It also provides a specific suggestion to search for \"Item Frequencies of Data Streams\" to obtain additional results. However, the comment does not specify which part of the paper these references and baselines are located in, making it weakly grounded. The authors can infer that it relates to the literature review or methodology sections, but this inference is not direct. The comment is specific in suggesting the need for more recent research and providing a search term, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the references and baselines are outdated and suggests that more recent research should be covered. It also provides a specific suggestion to search for \"Item Frequencies of Data Streams.\" However, the comment lacks detailed reasoning or examples to support why the references are outdated or how recent research could improve the paper. The suggestion to search for specific terms is vague and does not provide a clear path for the authors to follow. Therefore, the claim is considered borderline verifiable, as it provides some direction but lacks sufficient detail or evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the references and baselines being outdated, suggesting that more recent research should be covered. It also provides a concrete suggestion by recommending a search term, \"Item Frequencies of Data Streams,\" which could lead to additional relevant results. This feedback is clear and actionable, offering the authors a direct path to improve the comprehensiveness and relevance of their references. However, the comment could be more helpful if it provided specific examples of recent studies or detailed guidance on how to incorporate them into the paper. Overall, the comment is mostly helpful as it provides valuable guidance for enhancing the draft, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the introduction, which discusses the computational challenges of scaling quadratic programs to high-dimensional action spaces, and the experimental analysis in Section 5, which primarily explores action constraints in lower-dimensional spaces. The comment suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. While the comment identifies a gap in the analysis, it does not provide explicit instructions on how to conduct this analysis or what specific aspects should be explored. The action is implicit and somewhat vague, as the authors can infer that they need to expand their analysis to high-dimensional spaces but are not given concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction and Section 5, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the introduction\\'s focus on high-dimensional action spaces and the experimental analysis in Section 5, which primarily explores lower-dimensional spaces. The comment further suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental analysis in Section 5 primarily explores action constraints in relatively lower-dimensional spaces, which contrasts with the introduction\\'s focus on high-dimensional action spaces. The comment suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. While the comment highlights a potential gap in the analysis, it lacks specific examples or references to support the claim that the current analysis is insufficient for high-dimensional spaces. This makes the claim somewhat verifiable, as it provides a logical reasoning but lacks detailed evidence or examples to fully substantiate the suggestion for further analysis. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the introduction and the experimental analysis in Section 5, noting that the introduction highlights the computational challenges of scaling quadratic programs to high-dimensional action spaces, while the experimental analysis primarily explores action constraints in lower-dimensional spaces. The comment suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. This feedback is somewhat helpful as it points out a gap in the analysis and provides a direction for further exploration. However, it lacks specific suggestions or guidance on how to conduct this analysis or what aspects to focus on, which limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide information on the additional computation required to achieve the good experimental results. It implies that the extra performance might be due to the extra parameters or computation needed. The reviewer suggests that if the model had the same number of floats, the performance would likely be similar to the original transformers. While the comment implies that the authors should investigate and report on this aspect, it does not provide explicit instructions on how to conduct this analysis or what specific metrics to use. The action is implicit and somewhat vague, as the authors need to infer the steps to take and the details of the analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental results, suggesting that the authors should provide information on the additional computation required to achieve the good results. It implies that the extra performance might be due to the extra parameters or computation needed. However, the comment does not specify which part of the paper discusses the experimental results, making it weakly grounded. The comment is specific in suggesting that the authors should investigate and report on the additional computation, but it lacks detailed guidance on how to do so. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental results are good but lacks information on the additional computation required to achieve them. The reviewer suspects that the extra performance is due to extra parameters or computation, suggesting that the authors should investigate this further. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence and detailed justification makes the claim somewhat verifiable, as the authors would need to conduct additional analysis to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental results, noting that while they are good, there is no information on the additional computation required to achieve them. The reviewer suspects that the extra performance might be due to extra parameters or computation, suggesting that the authors should investigate and report on this aspect. This feedback is somewhat helpful as it points out a gap in the paper and encourages the authors to explore and address it. However, the comment could be more helpful if it provided specific suggestions on how to conduct this analysis or what metrics to use. Overall, the comment offers a direction for improvement but lacks detailed guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the evaluation and results, stating that they do not show consistent trends and that some improvements are not statistically significant. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to improve the evaluation or results, such as suggesting additional statistical tests or methods to enhance the consistency of the trends. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the evaluation and results, stating that they do not show consistent trends and that some improvements are not statistically significant. However, it does not specify which part of the paper these issues are discussed in, such as specific sections, figures, or tables. This lack of explicit reference makes it difficult for the authors to pinpoint the exact areas needing attention. Additionally, the comment does not provide specific guidance on how to address these issues, such as suggesting alternative statistical methods or ways to improve consistency. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the evaluation and results are not convincing due to inconsistent trends and lack of statistical significance in some improvements. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered borderline verifiable, as it lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a significant issue with the evaluation and results, noting that they do not show consistent trends and that some improvements are not statistically significant. This feedback is important as it highlights a potential flaw in the paper's conclusions. However, the comment lacks specificity and does not provide actionable suggestions on how the authors might address these issues, such as recommending additional statistical tests or methods to enhance the consistency of the trends. Without detailed guidance, the authors may find it challenging to improve their draft effectively. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but does not fully support the authors in making those improvements.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should highlight the percentage of the error rate attributed to subjective questions by examining agreement among humans. This implies an action for the authors to take, which is to provide a quantitative analysis of the subjective questions. However, the comment does not specify how to conduct this analysis or what specific metrics to use, leaving some ambiguity. The action is explicit but somewhat vague, as the authors know they need to analyze the subjective questions but may not be entirely clear on the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that \"several questions require subjective answers\" and implies that this could be problematic if a significant portion of the error rate is due to subjective questions. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that the authors should highlight the percentage of the error rate attributed to subjective questions by examining agreement among humans. This provides clear guidance on what needs to be addressed, making the comment weakly grounded but specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that \"several questions require subjective answers\" and implies that this could be problematic if a significant portion of the error rate is due to subjective questions. The reviewer provides a logical reasoning by suggesting that examining agreement among humans could help quantify the percentage of error rate attributed to subjective questions. This reasoning is sound and provides a clear direction for the authors to address the issue. However, the comment could be strengthened by providing specific examples or references to support the claim. Overall, the claim is mostly verifiable, as it offers a logical approach to addressing the issue but lacks detailed evidence or references. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment acknowledges that some questions in the paper require subjective answers and suggests that highlighting the percentage of the error rate attributed to these subjective questions could be useful. It proposes examining agreement among humans to quantify this percentage, which could help identify potential issues. This feedback is clear and actionable, as it provides a specific suggestion for improvement that could enhance the paper's credibility and robustness. However, the comment could be more helpful if it offered additional guidance on how to conduct this analysis or what specific metrics to use. Overall, the comment is mostly helpful, as it offers a constructive suggestion for improvement but could be more comprehensive with further details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a weakness in the evaluation, noting that it is limited to a single dataset and only includes intent recognition among NLP tasks. It suggests that the paper would benefit from considering additional NLP tasks, such as sentiment classification and named-entity recognition. While the comment implies that the authors should expand their evaluation to include more tasks, it does not provide specific guidance on which tasks to consider or how to implement this expansion. The action is implicit and somewhat vague, as the authors can infer the need for additional tasks but may not know exactly how to execute this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluation section of the paper, specifically mentioning the use of a single dataset and the limited scope of NLP tasks, such as intent recognition. It suggests that the paper would improve by considering additional NLP tasks like sentiment classification and named-entity recognition. However, the comment does not explicitly mention which section of the paper discusses the evaluation, making it weakly grounded. It is specific in detailing what needs to be addressed, namely the inclusion of more NLP tasks. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation is weak due to the use of only a single dataset and limited NLP tasks, specifically mentioning intent recognition. It suggests that the paper would improve by considering additional NLP tasks like sentiment classification and named-entity recognition. While the comment highlights a potential limitation, it lacks specific examples or references to support the claim about the limited scope of NLP tasks. The suggestion to include more tasks is logical, but without detailed justification or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation of the paper, noting that it is based on a single dataset and only includes intent recognition among NLP tasks. It suggests that the paper would benefit from considering additional NLP tasks, such as sentiment classification and named-entity recognition. This feedback is clear and actionable, as it provides specific areas for improvement that the authors can address to enhance the comprehensiveness and robustness of their evaluation. However, the comment could be more helpful if it offered guidance on which datasets or tasks to consider or how to integrate them into the evaluation framework. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests a change in the labeling of Figure 3, recommending that \"class semantic feature\" should be labeled as \"s\" instead of \"c\". This is a clear and direct action for the authors to take, providing specific guidance on how to modify their draft. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the labeling of \"class semantic feature\" as \"s\" instead of \"c.\" This provides clear guidance on what needs to be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual statement requesting a label change in Figure 3. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely descriptive and does not necessitate justification or evidence, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and specific, pointing out a labeling issue in Figure 3. It suggests a change from \"c\" to \"s\" for the label \"class semantic feature.\" This feedback is actionable and provides a direct improvement for the authors to make, enhancing the clarity and accuracy of their figure. However, the comment could be more helpful if it explained the reasoning behind the suggested change or its potential impact on the figure\\'s interpretation. Despite this, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a distinction between de-identification and face swapping, noting that the proposed method in the paper appears to be a form of face swapping, similar to deepfake technology. It suggests that the authors should compare their method with state-of-the-art face swapping algorithms to establish a clear boundary between the two approaches. While the comment implies that the authors should conduct a comparison, it does not provide specific guidance on how to perform this comparison or which algorithms to use. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the distinction between de-identification and face swapping, which allows the authors to identify the relevant part of the paper being discussed. It also specifies the issue by noting that the method proposed in the paper appears to be a form of face swapping, similar to deepfake technology, and suggests comparing the method with state-of-the-art face swapping algorithms to establish a clear boundary. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method proposed in the paper is essentially a form of face swapping, similar to deepfake technology, and suggests that the authors should compare their method with state-of-the-art face swapping algorithms. The reviewer provides a logical reasoning by explaining the distinction between de-identification and face swapping, noting that the target face in deepfake technology is a real individual, whereas in this work, it is derived from a 3DMM. This reasoning is clear and provides a basis for the claim. However, the comment could be strengthened by including specific references to state-of-the-art face swapping algorithms for a more comprehensive comparison. Therefore, the claim is mostly verifiable, as it provides a solid foundation but lacks detailed references for full verification.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the distinction between de-identification and face swapping, suggesting that the method proposed in the paper may be more akin to face swapping, similar to deepfake technology. It highlights the need for a clearer boundary between the two approaches and recommends comparing the method with state-of-the-art face swapping algorithms. This feedback is clear and actionable, as it provides a specific suggestion for improvement that could enhance the paper\\'s clarity and relevance. However, the comment could be more helpful if it offered additional guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement but could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point comments on the experimental results regarding word embeddings in Tables 1 and 2, stating that they are not very compelling compared to Gaussian embeddings, which are a chief baseline from the literature. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to improve the experimental results or what specific changes could be made to enhance their compellingness. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results on word embeddings, comparing them unfavorably to Gaussian embeddings, a chief baseline from the literature. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results on word embeddings in Tables 1 and 2 are not compelling compared to Gaussian embeddings, a chief baseline from the literature. However, the comment lacks specific details or references to support this claim. It does not provide examples of why the results are not compelling or how they compare unfavorably to Gaussian embeddings. Without such evidence or reasoning, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a specific issue with the experimental results, noting that the results on word embeddings in Tables 1 and 2 are not compelling compared to Gaussian embeddings, a chief baseline from the literature. This feedback identifies a potential weakness in the paper, suggesting that the authors should revisit their experimental approach or results to better compare with established baselines. However, the comment lacks depth and does not provide specific suggestions or guidance on how to improve the experimental results or address the issue. While it highlights an area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed method does not significantly differ from previous studies, except for a change in task and reward function. While it acknowledges the effectiveness of IRL in text summarization, it questions the contribution of the work. However, the comment does not provide explicit guidance or suggestions on how the authors might enhance their contribution or differentiate their work from existing studies. The feedback lacks actionable details, leaving the authors uncertain about how to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and references specific studies (\"Shi et al., 2018; Ghosh et al., 2021\") and another work (\"Ramakanth Pasunuru and Mohit Bansal. 2018\"), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of the proposed method not differing significantly from previous studies, except for the change in task and reward function, and questions the contribution of the work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method does not significantly differ from previous studies, except for a change in task and reward function. The reviewer supports this claim by referencing specific studies and mentioning the change in task and reward function. However, the comment could be strengthened by providing more detailed comparisons or examples of how the proposed method differs from the previous studies. This would enhance the verifiability of the claim. Therefore, the comment is mostly verifiable, as it provides some justification but lacks comprehensive evidence. The label is 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the proposed method does not significantly differ from previous studies, except for a change in task and reward function. It acknowledges the effectiveness of IRL in text summarization but questions the contribution of the work due to the lack of significant innovation. However, the comment does not provide specific suggestions or guidance on how the authors might enhance their contribution or differentiate their work from existing studies. While it highlights a critical area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the novelty of the paper is limited and that it consists of multiple pieces combined to create the paper. The reviewer suggests that the main contribution is a new IT-related dataset. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the perceived lack of novelty or how to enhance the contributions of the paper. Without specific suggestions or directions, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the paper, suggesting that it consists of multiple pieces combined and that the main contribution is a new IT-related dataset. However, it does not specify which parts of the paper these pieces refer to, making it difficult for the authors to pinpoint the exact sections that need attention. The comment lacks specificity regarding what aspects of the paper are considered novel or how the dataset contributes to the overall work. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, suggesting that it consists of multiple pieces combined and that the main contribution is a new IT-related dataset. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references to other works that demonstrate similar combinations of pieces, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a perceived limitation in the paper\\'s novelty, suggesting that it consists of multiple pieces combined and that the main contribution is a new IT-related dataset. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might enhance the novelty or contributions of their work. Without detailed guidance or examples, the authors are left without a clear understanding of what changes could be made to address the reviewer\\'s concerns. Therefore, the comment is barely helpful, as it identifies a potential issue but does not offer meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the paper lacks an ablation study related to query embedding, which would provide insights into the significance and impact of this component. The comment clearly states the action needed, which is to conduct an ablation study on query embedding. However, it does not provide specific guidance on how to conduct the study or what aspects to focus on. While the action is explicit, the lack of detailed instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Ablation study\" and \"query embedding,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014a study related to query embedding, which would provide insights into its significance and impact. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks an ablation study related to query embedding, which would provide insights into its significance and impact. This claim is somewhat verifiable as it logically follows that an ablation study would be beneficial for understanding the component\\'s importance. However, the comment does not provide specific examples or references to support the necessity of such a study, leaving the authors to infer the importance themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting the inclusion of an ablation study related to query embedding. This feedback is clear and actionable, as it provides a clear direction for the authors to enhance their paper by exploring the significance and impact of the query embedding component. However, the comment could be more helpful if it offered suggestions on how to design or conduct the ablation study, such as which parameters to test or what metrics to use. Despite this, the comment is mostly helpful as it directs the authors to a meaningful area for further investigation and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses an opinion that the contribution of the paper is marginal compared to previous works. However, it does not provide any specific guidance or suggestions on how the authors might address this perceived issue or improve their contribution. There is no explicit or implicit action for the authors to take, leaving them without any direction on how to enhance their work. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the marginal contribution of the paper compared to previous works, but it does not specify which part of the paper this assessment is based on. It does not mention specific sections, figures, or results that support this claim, making it difficult for the authors to identify the exact areas needing attention. Additionally, the comment lacks specificity regarding what aspects of the previous works are being compared or how the current work could be improved. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution of the paper is marginal compared to previous works. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence, the authors may find it challenging to understand the basis of the reviewer\\'s opinion or to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses an opinion that the contribution of the paper is marginal compared to previous works. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed analysis or examples of how the current work could be enhanced or differentiated from previous works, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question to the authors, seeking clarification on the reasons behind the loss of performance of w2gm compared to w2g in the analysis of SWCS. However, it does not provide any explicit or implicit actions for the authors to take. The question is phrased as a request for clarification, but it lacks any guidance or suggestions on how the authors might address this issue or improve their draft. As a result, the comment is unactionable, as it does not offer any actionable steps for the authors to follow.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question to the authors regarding the loss of performance of w2gm compared to w2g in the analysis of SWCS. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure, making it weakly grounded. The comment is specific in its request for clarification on the reasons behind the performance loss, but without clear grounding, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question posed to the authors, seeking clarification on the reasons behind the loss of performance of w2gm compared to w2g in the analysis of SWCS. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question to the authors regarding the loss of performance of w2gm compared to w2g in the analysis of SWCS. While it seeks clarification, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their draft. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be clarified. Therefore, it is barely helpful, as it identifies a potential area of confusion but does not offer any meaningful direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the paper should evaluate for overoptimization rather than calibration and human evaluation, as it claims the current works get away with overoptimization issues through early stopping. The reviewer provides a specific example of AlignProp and suggests that the authors should not use early stopping and discuss the tradeoffs with the proposed solutions. Additionally, the reviewer recommends discussing the benefits of not doing early stopping. This feedback is clear and provides concrete actions for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the motivation of the paper, which is overoptimization, and points out that the evaluation does not directly address this issue. It also references a specific work, AlignProp, and suggests that the authors should discuss the benefits of not using early stopping. This provides clear guidance on what needs to be addressed in the paper. The comment is specific in detailing what is missing and how it should be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not directly evaluate for overoptimization, despite mentioning it as a motivation. The reviewer suggests that current works address overoptimization through early stopping, citing AlignProp as an example. However, the comment lacks specific references or detailed comparisons to substantiate the claim about AlignProp or the benefits of not using early stopping. While the reviewer provides a logical reasoning for the claim, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper\\'s evaluation, noting that it discusses overoptimization as a motivation but does not directly evaluate for it. The reviewer points out that current works, such as AlignProp, address overoptimization through early stopping, which is not discussed in the paper. The comment provides a clear and actionable suggestion to evaluate the tradeoffs without early stopping and to discuss the benefits of not using early stopping. This feedback is highly helpful as it directs the authors to a critical area of improvement that could significantly enhance the paper\\'s contribution and relevance. By addressing this gap, the authors can strengthen their work and provide a more comprehensive evaluation of their proposed solutions. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed TW model is equivalent to TR and proposes an analysis to justify this equivalence. It implies that the authors should include this analysis in the paper and discuss why TW is preferred over TR. While the comment explicitly suggests an action, it lacks concrete guidance on how to conduct the analysis or what specific aspects to focus on. The authors are left with a general idea of what needs to be done but without detailed instructions on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed TW model\" and \"TR,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the equivalence between the TW model and TR, and suggests that the authors should include an analysis and discussion justifying the preference for TW over TR. This provides clear guidance on what needs to be improved in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed TW model is equivalent to TR, suggesting that the core tensor C can be represented by a TR, which can then be fused with the cores G_n to reach a TR representation equivalent to the former TW model. The reviewer would have liked to see this analysis in the paper and a discussion justifying TW over TR. While the claim is based on logical reasoning, it lacks specific examples or references to support the equivalence or the justification for preferring TW over TR. This makes the claim somewhat verifiable, as it provides a basis for the argument but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential equivalence between the proposed TW model and the TR model, suggesting that the core tensor C can be represented by a TR, which can then be fused with the cores G_n to reach a TR representation equivalent to the former TW model. This observation is valuable as it highlights a potential oversight in the paper, specifically the lack of analysis or discussion on this equivalence. The comment provides a clear direction for the authors to include this analysis and discussion, which could enhance the paper\\'s clarity and justification of the proposed TW model. However, the comment could be more helpful if it offered specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the feedback is mostly helpful as it guides the authors toward a significant improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should discuss the transferability of the toolset, noting that the toolsets for the VQA and reasoning tasks are not the same. It implies that the authors could experiment with creating a general toolset for all tasks to see the outcome. While the comment provides an explicit suggestion to discuss transferability and experiment with a general toolset, it lacks concrete guidance on how to conduct these experiments or what specific aspects to focus on. The action is explicit but somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests discussing the transferability of the toolset, specifically noting that the toolsets for the VQA and reasoning tasks are not the same. This implies that the authors should address this issue in the paper, likely in the sections discussing the toolsets or methodology. However, the comment does not explicitly mention which sections these toolsets are discussed in, making it weakly grounded. It is specific in identifying the issue of transferability and suggesting an experiment to create a general toolset, which provides clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the transferability of the toolset should be discussed, noting that the toolsets for the VQA and reasoning tasks are not the same. The reviewer implies that this discrepancy could be addressed by experimenting with a general toolset for all tasks. However, the comment lacks specific examples or references to support the claim that the current toolsets are not transferable or that a general toolset would be beneficial. This makes the claim somewhat verifiable, as it provides a logical suggestion but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the transferability of the toolset, noting that the toolsets for the VQA and reasoning tasks are not the same. It suggests that the authors should discuss this discrepancy and potentially experiment with creating a general toolset for all tasks. This feedback is somewhat helpful as it points out a specific area for improvement and provides a direction for further exploration. However, it lacks detailed guidance on how to conduct these experiments or what specific aspects to focus on, which limits its comprehensiveness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests evaluating the model\\'s performance using multiple random feature orders to assess the impact of feature order variability without needing a complex controller. This is an explicit suggestion that provides a clear action for the authors to take. The comment also offers a rationale for why this evaluation is important, which helps the authors understand the purpose of the suggestion. However, it does not provide specific guidance on how to implement this evaluation, such as which random orders to use or how to analyze the results. Despite this, the suggestion is clear and actionable, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests evaluating the model\\\\\\'s performance using multiple random feature orders to assess the impact of feature order variability. It provides a clear rationale for why this evaluation is important, suggesting that it could help determine if the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. However, the comment does not specify which part of the paper this suggestion should be implemented in, such as a specific section or experiment. While the authors can infer that it relates to the evaluation or results section, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing what needs to be addressed, so it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests evaluating the model\\\\\\'s performance using multiple random feature orders to assess the impact of feature order variability. It provides a logical reasoning for why this evaluation is necessary, suggesting that it could help determine if the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the importance of this evaluation based on the provided rationale, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests evaluating the model\\\\\\'s performance using multiple random feature orders to assess the impact of feature order variability. This is a valuable suggestion as it could help determine whether the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. By providing this feedback, the comment offers a clear and actionable direction for the authors to improve their evaluation methodology. However, the comment could be more helpful if it included specific guidance on how to implement this evaluation, such as the number of random orders to use or how to analyze the results. Overall, the comment is mostly helpful as it provides a valuable suggestion for improving the paper, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a lack in the related work section, specifically mentioning the omission of lexically constrained decoding methods. It also points out that these methods are missing both in the related work and as baselines for comparison. This feedback provides a clear and concrete action for the authors to take: they should include these methods in the related work section and consider them as baselines for comparison. The comment is explicit and provides specific guidance on what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"related work section\" and specifies the issue of missing references, particularly the omission of lexically constrained decoding methods. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly details what is missing in the related work section, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the related work section is \"severely lacking\" and specifically mentions the omission of lexically constrained decoding methods. However, it does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. The lack of specific examples or references makes it difficult for the authors to understand the extent of the omission and how it impacts the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the related work section, specifically noting the omission of lexically constrained decoding methods. It highlights that these methods are not only missing from the related work section but also as baselines for comparison. This feedback is clear and actionable, providing the authors with a specific area to address and expand upon in their draft. By including these methods, the authors can enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it suggested specific references or examples of lexically constrained decoding methods to consider. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that important baseline models and datasets are missing, which makes the comparison not comprehensive. It explicitly mentions two specific models, SimVLM and OFA, suggesting that these should be included in the comparison. However, the comment does not provide detailed guidance on how to incorporate these models or datasets into the comparison, nor does it specify which aspects of the models or datasets are particularly relevant. While the authors are given a clear direction to include these models, the lack of detailed instructions on how to do so makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of missing baseline models and datasets, allowing the authors to identify the specific part of the paper being addressed. It also specifies the models and datasets that are missing, such as SimVLM and OFA, providing clear guidance on what needs to be included in the comparison. This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison is not comprehensive due to the absence of important baseline models and datasets. It supports this claim by listing specific models, SimVLM and OFA, which are mentioned as examples of missing baseline models. However, the comment does not provide detailed reasoning or examples of how these models would enhance the comprehensiveness of the comparison. While the inclusion of these models is suggested, the lack of further explanation or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the comparison is not comprehensive due to the absence of important baseline models and datasets. It provides specific examples of missing models, such as SimVLM and OFA, which could enhance the comprehensiveness of the comparison. This feedback is clear and actionable, as it directs the authors to include these models in their analysis. However, the comment could be more helpful if it offered suggestions on how to incorporate these models or datasets into the comparison, such as providing guidance on data preparation or experimental setup. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides specific examples, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the manuscript for being framed as a dataset paper but lacking new data collection or release. It highlights that the paper presents derivative data, specifically 3D pose estimates from existing datasets, which is disappointing for readers seeking a new data source. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their manuscript. Without actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the manuscript for being framed as a dataset paper but lacking new data collection or release. It specifies that the paper presents derivative data, specifically 3D pose estimates from existing datasets, which is disappointing for readers seeking a new data source. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the introduction or methodology sections, but this inference is not direct. The comment is specific in detailing the issue with the data being derivative, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the manuscript is framed as a dataset paper but lacks new data collection or release, instead presenting derivative data. The reviewer argues that this is disappointing for readers seeking a new data source. The comment provides a logical reasoning by contrasting the expected content of a dataset paper with the actual presentation of derivative data. However, it lacks specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is somewhat verifiable, as it provides a clear rationale but requires additional evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the manuscript, noting that it is framed as a dataset paper but lacks new data collection or release. Instead, the paper presents derivative data, specifically 3D pose estimates from existing datasets. This critique is valuable as it highlights a discrepancy between the paper\\'s presentation and its actual content. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue, such as discussing the potential benefits of using existing datasets or offering guidance on how to present the derivative data in a more meaningful way. Without actionable advice, the comment remains somewhat helpful, as it points out a critical flaw but does not offer a clear path for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors for criticizing L-softmax and A-softmax for requiring an annealing-like training procedure, while the method itself has a specific learning rate schedule for experiments on CIFAR and Face Verification. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this critique or improve their draft. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors for criticizing L-softmax and A-softmax for requiring an annealing-like training procedure, while the method itself has a specific learning rate schedule for experiments on CIFAR and Face Verification. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its critique of the authors\\' criticism but lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the authors for criticizing L-softmax and A-softmax for requiring an annealing-like training procedure, while the method itself has a specific learning rate schedule for experiments on CIFAR and Face Verification. The comment provides a factual observation about the method\\'s learning rate schedule, which serves as a counterpoint to the authors\\' criticism. However, it does not offer any additional reasoning or evidence to support the claim or suggest how the authors might address the critique. The lack of detailed justification or examples makes the claim somewhat verifiable, as it provides a basis for the critique but lacks depth. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the authors for criticizing L-softmax and A-softmax for requiring an annealing-like training procedure, while the method itself has a specific learning rate schedule for experiments on CIFAR and Face Verification. This feedback highlights a potential inconsistency in the authors\\' critique and points out a specific aspect of the method that may not align with the criticism. However, the comment does not provide any suggestions or guidance on how the authors might address this critique or improve their draft. While it identifies a relevant issue, it lacks actionable advice or depth, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap in the analysis, suggesting that while the paper focuses on comparing AE to diffusion, it misses a deeper analysis of the results themselves. The reviewer questions what can be learned from the visualizations about the crucial elements for detecting a chair, such as the handle, and whether it is consistent across various chairs. This feedback implies that the authors should conduct a more in-depth analysis of their results to identify key features and their consistency. However, the comment does not provide explicit instructions on how to conduct this analysis or what specific aspects to focus on. While the action is implicit, it is somewhat concrete in suggesting a direction for further analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"quantitative and qualitative analysis\" and the focus on comparing AE to diffusion, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the analysis of the results themselves and the importance of visualizations in understanding which elements are crucial for detecting a chair. The comment provides specific questions about the consistency and prominence of features like the handle, which further clarifies the areas needing attention. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the depth of the analysis, suggesting that the paper focuses too much on comparing AE to diffusion and not enough on analyzing the results themselves. The reviewer provides specific examples, such as questioning the consistency of the handle across various chairs and its prominence as a feature. However, the comment lacks detailed reasoning or references to support the claim that the analysis is insufficient. While the examples are clear, the lack of broader context or evidence makes the claim somewhat verifiable, as the authors would need to infer the full extent of the issue based on the provided examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the analysis by pointing out that the paper focuses primarily on comparing AE to diffusion, rather than delving deeper into the analysis of the results themselves. It suggests that the authors should explore what can be learned from the visualizations about the crucial elements for detecting a chair, such as the handle, and whether it is consistent across various chairs. This feedback is clear and actionable, as it prompts the authors to conduct a more in-depth analysis of their results to identify key features and their significance. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or what aspects to focus on. Overall, the comment is mostly helpful, as it directs the authors to a significant area for improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests a correction to the text in Section 2.2, specifically changing \"at least\" to \"at most\" in the statement about the competitive ratio. The reviewer provides a detailed explanation of the reasoning behind this suggestion, including a specific example to illustrate the point. This level of detail provides clear guidance on what action the authors should take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Beginning of Section 2.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, suggesting a correction from \"at least\" to \"at most\" in the statement about the competitive ratio. The reviewer provides a detailed explanation and example to support the suggestion, making it clear what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a correction to the text in Section 2.2, specifically changing \"at least\" to \"at most\" in the statement about the competitive ratio. The reviewer provides a logical explanation and example to support the claim, demonstrating that the worst-case scenario would indeed be \"b/1=b\" when x=1, and in other cases, the ratio would be \"b/x\" or eventually \"b/b=1\" as soon as x>b. This reasoning is clear and provides a solid basis for the suggestion, making the claim fully verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific error in the text, suggesting a correction from \"at least\" to \"at most\" in the statement about the competitive ratio. The reviewer provides a detailed explanation and example to support the suggestion, which is clear and actionable. This feedback empowers the authors to make a precise correction, enhancing the accuracy and clarity of their draft. The level of detail and the logical reasoning behind the suggestion make this comment highly valuable for improving the manuscript.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point is a question seeking clarification about the notation used in Theorem 1, specifically asking if D^{alpha}_{x} denotes the derivatives of the probabilistic measure \u03bc. This comment does not provide any explicit or implicit actions for the authors to take, nor does it suggest any changes or improvements to the draft. It is purely a request for clarification, leaving the authors without any actionable steps to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification about the notation \"D^{alpha}_{x}\" and its relation to the probabilistic measure \u03bc, providing clear guidance on what needs to be clarified. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the notation used in Theorem 1, specifically asking if D^{alpha}_{x} denotes the derivatives of the probabilistic measure \u03bc. This is not a claim but rather a request for clarification, making it \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is a question seeking clarification about the notation used in Theorem 1, specifically asking if D^{alpha}_{x} denotes the derivatives of the probabilistic measure \u03bc. While it identifies a potential area of confusion, it does not provide any suggestions or guidance on how to address this issue or improve the clarity of the theorem. The comment is limited in its helpfulness as it does not offer actionable feedback or insights that could aid the authors in enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a missing element in Figure 2, specifically the proper expression for the third face image. This provides clear guidance on what the authors need to address in their draft. The comment is direct and concrete, leaving no ambiguity about the action required. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the missing proper expression for the third face image in Figure 2. This provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a missing proper expression for the third face image in Figure 2. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the missing proper expression for the third face image in Figure 2. This feedback is clear and actionable, as it directly points out a gap in the presentation of the figure. By addressing this issue, the authors can improve the clarity and completeness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to properly express the third face image. Overall, the comment is mostly helpful as it guides the authors toward a specific improvement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests including an example created by BERT and comparing it with one created by the proposed model. This is an explicit action that provides a clear direction for the authors to enhance their draft. The suggestion is concrete, as it specifies what needs to be done\u2014adding a comparison example\u2014and how to implement it. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including an example created by BERT and comparing it with one created by the proposed model. However, it does not specify which part of the paper this suggestion should be implemented in, such as a specific section or figure. This makes it difficult for the authors to pinpoint where the addition should be made. The comment is specific in suggesting a particular comparison, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including an example created by BERT and comparing it with one created by the proposed model would be helpful. However, the comment does not provide any reasoning or evidence to support why this comparison would be beneficial or how it would enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a specific improvement by recommending the inclusion of an example created by BERT and comparing it with one created by the proposed model. This feedback is actionable and provides a clear direction for enhancing the draft by offering a concrete way to demonstrate the effectiveness of the proposed model. However, the comment could be more helpful if it explained why this comparison would be beneficial or how it would address specific weaknesses in the paper. Despite this, the suggestion is clear and actionable, making the comment mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the dataset sizes for the code summarization task and the code search task should be the same for Vault and CSN to demonstrate that Vault is better in terms of data quality. However, it does not provide explicit instructions on how to achieve this, such as specifying the exact dataset sizes or how to adjust the experiments. The action is implicit and somewhat vague, as the authors can infer that they need to ensure the dataset sizes are consistent, but they may not know the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific tasks, \"code summarization task\" and \"code search task,\" and mentions the datasets \"Vault\" and \"CSN.\" However, it does not specify which part of the paper these tasks and datasets are discussed in, making it weakly grounded. The comment is specific in its request for the dataset sizes to be the same for a fair comparison, but without explicit references to sections or figures, the authors may struggle to identify the exact parts needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the dataset sizes for the code summarization task and the code search task should be the same for Vault and CSN to demonstrate that Vault is better in terms of data quality. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would demonstrate Vault\\'s superiority. Without additional context or explanation, the claim remains unverifiable, as the authors would need more information to understand the basis of the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the comparison between Vault and CSN, suggesting that the dataset sizes for the code summarization task and the code search task should be the same to fairly demonstrate Vault\\'s superiority in terms of data quality. This feedback is clear and actionable, as it provides a specific criterion for improvement that the authors can address to strengthen their argument. However, the comment could be more helpful if it offered suggestions on how to achieve this consistency or provided additional context on why this comparison is important. Overall, the comment is mostly helpful as it directs the authors to a critical aspect of their methodology that needs attention.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a lack of explanation for certain important concepts, such as \"action-repeat\" and \"dithering phenomenon,\" which are mentioned throughout the paper. The reviewer suggests that these terms should be explained more thoroughly. While the comment implies that the authors should provide clearer definitions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to add explanations but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a lack of explanation for certain important concepts, such as \"action-repeat\" and \"dithering phenomenon,\" which are mentioned throughout the paper. However, it does not specify which sections or parts of the paper these concepts are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the need for more thorough explanations of these terms. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"some important concepts are not explained well,\" specifically mentioning \"action-repeat\" and \"dithering phenomenon.\" However, it does not provide any supporting evidence, examples, or references to substantiate this claim. The lack of detailed explanation or examples makes it difficult for the authors to understand the specific issues with the concepts and how they could be improved. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that important concepts such as \"action-repeat\" and \"dithering phenomenon\" are not explained well. It highlights the need for more thorough explanations of these terms, which are mentioned throughout the paper. This feedback is clear and actionable, as it directs the authors to improve the clarity and comprehensibility of their work by providing detailed explanations of these concepts. However, the comment could be more helpful if it suggested specific ways to explain these concepts or provided examples of how they could be clarified. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests an alternative approach to the current method of generating text using an instruction model and then re-encoding it. The reviewer proposes creating an instruction embedding from the state encoding and passing it directly to the executor, rather than generating text first. Additionally, the reviewer suggests adding an auxiliary objective to bring the instruction encoding closer to the gold instruction encoding. This feedback provides a clear and concrete suggestion for improvement, offering a specific alternative method and a rationale for why it might be more effective. The authors know exactly what action to take and how to implement the suggested changes, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests an alternative approach to the current method of generating text using an instruction model and re-encoding it. It proposes creating an instruction embedding from the state encoding and passing it directly to the executor, rather than generating text first. The reviewer also suggests adding an auxiliary objective to bring the instruction encoding closer to the gold instruction encoding. While the comment provides a specific suggestion for improvement, it does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. However, it is specific in detailing the proposed alternative method and its potential benefits. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests an alternative approach to the current method of generating text using an instruction model and re-encoding it. The reviewer proposes creating an instruction embedding from the state encoding and passing it directly to the executor, rather than generating text first. This suggestion is based on logical reasoning, as it aims to avoid the potential issue of discretization failure due to a single wrong decoding. However, the comment lacks specific examples or references to support the claim that this approach might work better. While the reasoning is clear, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a constructive suggestion for improving the approach described in the paper. It proposes an alternative method of generating text by creating an instruction embedding from the state encoding and passing it directly to the executor, rather than generating text first. This suggestion is based on a logical reasoning that avoiding discretization might reduce the risk of failure due to a single wrong decoding. The comment also suggests adding an auxiliary objective to bring the instruction encoding closer to the gold instruction encoding, which could potentially improve the model's performance. While the feedback is clear and actionable, it could be more helpful if it included a detailed explanation of why this approach might be beneficial or how it could be implemented. Overall, the comment is mostly helpful as it offers a specific and constructive suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the novelty of the proposed model is not significant, but it does not provide any specific guidance or suggestions on how the authors could improve the novelty or address this concern. There is no explicit or implicit action for the authors to take, such as suggesting additional experiments, modifications, or comparisons to enhance the novelty. Without any actionable advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the novelty of the proposed model is not significant, but it does not specify which aspects of the model or where in the paper this lack of novelty is observed. Without explicit references to sections, figures, or specific elements of the model, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of novelty are lacking or how the model could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"the novelty of proposed model is not significant,\" but it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without specific details or references to what aspects of the model are lacking in novelty, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment claims that the novelty of the proposed model is not significant, but it does not provide any specific details or examples to support this claim. Without additional context or suggestions for improvement, the authors are left without a clear understanding of what aspects of the model are lacking in novelty or how they might enhance it. This lack of specificity and actionable feedback makes the comment unhelpful, as it does not offer any meaningful guidance for the authors to improve their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the dataset used for the pool subset, suggesting that the proportion of each class makes the dataset easier rather than harder. It provides specific examples of class imbalances, such as the scarcity of observations for certain numbers like 9, 6, and 7 compared to others like 1. The comment implies that the accuracy metric may not be a good measure of quality in this case, as it could be influenced by poor classification of smaller classes. However, the comment does not explicitly instruct the authors to address this issue or suggest how to improve the dataset or the evaluation metric. The action is implicit and somewhat vague, as the authors need to infer that they should consider the class imbalance and its impact on the accuracy metric. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the issue of class imbalance in the dataset used for the pool subset, providing specific examples of the proportions of each class. This allows the authors to accurately identify the part of the paper being discussed. The comment is also specific because it details the problem with the dataset, explaining how the class imbalance affects the accuracy metric. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the dataset used for the pool subset is easier rather than harder due to the class imbalance, specifically citing the scarcity of certain numbers like 9, 6, and 7 compared to others like 1. The reviewer provides specific examples to support their claim, which makes the argument somewhat verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to similar cases in the literature where class imbalance affects accuracy. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the dataset used for the pool subset, specifically highlighting the class imbalance and how it might make the dataset easier rather than harder. It provides specific examples of the class imbalance, such as the scarcity of observations for certain numbers like 9, 6, and 7 compared to others like 1. This feedback is valuable as it points out a critical aspect of the dataset that could impact the accuracy of the results. However, the comment could be more helpful if it suggested ways to address this issue, such as recommending data augmentation techniques or alternative evaluation metrics that might be more robust to class imbalance. Overall, the comment is somewhat helpful as it raises an important concern but lacks actionable guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part expresses agreement with the idea that prediction is not done in isolation but questions the main contribution of the paper regarding the strategic aspects of prediction. This part lacks explicit guidance or suggestions for improvement. The second part raises specific questions about the \"true\" payoff in Table 1 and suggests that the test set payoff should be included, or if it is the population empirical payoff. It also references Vapnik\\'s work on teaching a learner with side information, suggesting a potential similarity. While the second part provides some direction by questioning the payoff and referencing external work, the overall comment is somewhat actionable because it identifies specific areas for clarification and potential improvement but lacks detailed guidance on how to address these issues. Therefore, this comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also raises specific questions about the \"true\" payoff in Table 1, which provides clear guidance on what needs to be clarified or addressed. Additionally, the comment references Vapnik\\'s work, suggesting a potential similarity, which adds specificity to the feedback. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of multiple claims and questions. The first part agrees with the idea that prediction is not done in isolation but questions the main contribution of the paper regarding the strategic aspects of prediction. This part lacks specific evidence or reasoning to support the claim, making it unverifiable. The second part raises questions about the \"true\" payoff in Table 1, which could be clarified with more context or explanation. The reference to Vapnik\\'s work on teaching a learner with side information is a relevant external reference, but it is not fully integrated into the claim, making the comment mostly verifiable. Overall, the comment is rated as 3: Somewhat Verifiable, as it provides some support but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the idea that prediction is not done in isolation but questions the main contribution of the paper regarding the strategic aspects of prediction. It raises specific questions about the \"true\" payoff in Table 1, asking whether it refers to the test set payoff or the population empirical payoff. This feedback is somewhat helpful as it identifies a potential area of confusion and prompts the authors to clarify their presentation. Additionally, the comment references Vapnik\\'s work on teaching a learner with side information, suggesting a potential similarity, which could be a useful point for the authors to consider. However, the comment could be more helpful if it provided more detailed guidance on how to address the questions or if it offered suggestions for improving the clarity of the main contribution. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should explore another unsupervised domain adaptation (UDA) method based on self-training, as the proposed method solely focuses on domain-alignment methods. While the comment implies that the authors should consider alternative approaches, it does not provide specific guidance on which methods to explore or how to integrate them into their work. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take and may not know which specific methods to consider. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring another unsupervised domain adaptation (UDA) method based on self-training, as the current method focuses solely on domain-alignment methods. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or methodology discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, while the comment provides a general suggestion for improvement, it does not specify which alternative UDA method should be explored or how it could be integrated into the current work. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed method solely focuses on domain-alignment methods within the context of unsupervised domain adaptation (UDA) and suggests exploring another UDA method based on self-training. However, the comment lacks specific examples or references to support the claim that the current method is limited to domain-alignment methods or that self-training is a prominent and effective approach. Without detailed evidence or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the proposed method, noting that it solely focuses on domain-alignment methods within the context of unsupervised domain adaptation (UDA). It suggests that the authors should explore another UDA method based on self-training, which is a prominent and effective approach in the field. This feedback is clear and actionable, as it provides a specific direction for the authors to consider in expanding their work. However, the comment could be more helpful if it offered examples of alternative self-training methods or provided guidance on how to integrate them into the existing framework. Overall, the comment is mostly helpful as it directs the authors to a potential area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern with the reliability diagrams (Fig 1, top), specifically the accuracy vs confidence plots, which do not appear to favor the proposed methods. It notes the presence of high-accuracy spikes in low-confidence regimes, questioning whether this is due to dataset pathologies or variance/unpredictability in the proposed methods. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address it. The authors are left to infer that they should investigate the cause of these pathologies and potentially explore ways to mitigate them. However, the lack of specific suggestions or concrete steps makes the action implicit and somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 1, top,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the reliability diagrams, specifically the accuracy vs confidence plots, and notes the presence of high-accuracy spikes in low-confidence regimes. The comment raises a question about whether this is a property of dataset pathologies or reflects variance/unpredictability in the proposed methods, providing a clear direction for the authors to consider. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the reliability diagrams (Fig 1, top), specifically the accuracy vs confidence plots, which do not appear to favor the proposed methods. It notes the presence of high-accuracy spikes in low-confidence regimes and questions whether this is due to dataset pathologies or variance/unpredictability in the proposed methods. While the comment identifies an issue, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to investigate further to fully understand the basis of the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the reliability diagrams (Fig 1, top), noting that they do not make the proposed methods appear better and exhibit notable pathologies, such as high-accuracy spikes in low-confidence regimes. It raises a question about whether this is due to dataset pathologies or reflects variance/unpredictability in the proposed methods. This feedback is somewhat helpful as it points out a potential weakness in the presentation of the results and prompts the authors to consider the underlying causes of these issues. However, it lacks specific suggestions or guidance on how the authors might address these concerns, such as recommending additional analysis or modifications to the methods. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential vulnerability in the paper, suggesting that the attacker could perform more advanced attacks beyond those evaluated. It provides a specific example of fine-tuning on a partial subset of the dataset, which could still contain poisoned data, and notes that this scenario is not evaluated in the paper. Additionally, it points out that the paper only considers detection and not removal of backdoors, and that there are SOTA methods for backdoor removal that are not discussed. While the comment identifies areas for further exploration and evaluation, it does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors need to infer that they should consider these additional scenarios and methods in their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluation of advanced attacks and the consideration of backdoor removal methods, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a detailed example of a potential attack scenario and highlights the lack of evaluation of this scenario in the paper. Additionally, it points out the absence of discussion on backdoor removal methods, which is a clear area for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not evaluate advanced attacks beyond those mentioned, specifically mentioning the scenario of fine-tuning on a partial subset of the dataset. It provides a logical reasoning by explaining that even in this scenario, the backdoor may still be present due to the high chance of the partial subset containing poisoned data. The comment also points out the lack of discussion on backdoor removal methods, which is a relevant concern. However, the claim could be strengthened by providing specific examples or references to existing literature on advanced attacks or backdoor removal methods. Overall, the comment is mostly verifiable, as it provides a clear rationale but lacks detailed references or examples to fully substantiate the claim. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out that it only evaluates a limited set of attacks and does not consider more advanced scenarios, such as fine-tuning on a partial subset of the dataset. It provides a specific example of how the attacker could still introduce a backdoor in this scenario, highlighting a potential vulnerability that the paper does not address. Additionally, the comment notes that the paper focuses solely on detection and does not discuss backdoor removal methods, which is an important aspect of the topic. This feedback is clear and actionable, as it prompts the authors to consider these additional scenarios and methods in their work, potentially leading to a more comprehensive evaluation. However, the comment could be more helpful if it provided specific suggestions on how to address these gaps or examples of relevant literature on backdoor removal. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the choice of using the original adjacency matrix without explanation or an ablation study, unlike the original GCN (Kipf and Welling) which uses a normalized adjacency matrix with a renormalization trick. The reviewer questions whether there is a reason for not using the conventional graph convolutional operation. While the comment highlights a potential issue, it does not explicitly instruct the authors to address this concern or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they should provide an explanation or conduct an ablation study, but the comment lacks concrete details on how to implement these actions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the original GCN (Kipf and Welling) and the use of a normalized adjacency matrix with a renormalization trick, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of using the original adjacency matrix without explanation or an ablation study. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of using the original adjacency matrix without explanation or ablation study, contrasting it with the original GCN (Kipf and Welling) that uses a normalized adjacency matrix with a renormalization trick. The comment raises a logical concern about the potential impact of this choice on the results, but it does not provide specific evidence or references to support the claim. While the reasoning is sound, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the choice of using the original adjacency matrix without explanation or an ablation study, unlike the original GCN (Kipf and Welling) that uses a normalized adjacency matrix with a renormalization trick. This observation highlights a potential gap in the paper's methodology and encourages the authors to provide a rationale for their choice. However, the comment could be more helpful if it offered suggestions on how to address this issue, such as recommending an ablation study or providing a detailed explanation for the choice. Despite this, the comment provides a clear direction for improvement, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the inconsistency in providing links for WMT'15 training corpora but not for WMT'14. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on how to address this issue or what steps to consider in resolving the discrepancy. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the inconsistency in providing links for WMT\\'15 training corpora but not for WMT\\'14. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about the link, but it lacks grounding as it does not provide a clear reference to the part of the paper where this issue is discussed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the inconsistency in providing links for WMT\\'15 training corpora but not for WMT\\'14. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual inquiry, making it a \"No\" classification.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the inconsistency in providing links for WMT\\'15 training corpora but not for WMT\\'14. While it identifies a potential issue, it lacks depth and does not provide any guidance or suggestions on how the authors might address this inconsistency or clarify the rationale behind the different treatment of the corpora. Without actionable feedback or insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors need to determine the upper and lower bounds for adaptive matrices A t and B t in order to select other hyperparameters. However, it does not provide explicit guidance on how to determine these bounds or which hyperparameters should be adjusted. The action is implicit and somewhat vague, as the authors can infer that they need to find these bounds but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors need to determine the upper and lower bounds for adaptive matrices A t and B t in order to select other hyperparameters. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where these matrices are discussed. Without explicit references or context, the authors may find it challenging to identify the exact part of the paper that needs attention. The comment is specific in its request for bounds but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the upper and lower bounds for adaptive matrices A t and B t are necessary for selecting other hyperparameters. However, it does not provide any supporting evidence, reasoning, or examples to justify why these bounds are crucial or how they impact the selection of hyperparameters. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue related to the need for upper and lower bounds for adaptive matrices A t and B t in order to select other hyperparameters. This feedback is somewhat helpful as it points out a potential area for improvement in the paper, specifically regarding the determination of these bounds. However, the comment lacks depth and does not provide guidance on how to determine these bounds or which hyperparameters should be adjusted. While it highlights an important aspect, it does not offer actionable steps for the authors to take, limiting its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the novelty of the techniques used is not particularly high, as they were proposed and demonstrated before. It also implies that the authors should consider providing experimental results on the PDBbind dataset. However, the comment does not explicitly instruct the authors to include these results or provide specific guidance on how to conduct the experiments. The action is implicit and somewhat vague, as the authors can infer that they need to include experimental results but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of the techniques used in the paper, suggesting that most of them were proposed and demonstrated before. It also mentions the PDBbind dataset, implying that the authors should provide experimental results on this dataset. However, the comment does not specify which part of the paper discusses the techniques or where the PDBbind dataset is mentioned, making it weakly grounded. The authors can infer that the comment relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting the inclusion of experimental results on the PDBbind dataset, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the techniques used is not particularly high, as they were proposed and demonstrated before. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the novelty of the techniques used in the paper is not particularly high, as they were proposed and demonstrated before. It suggests that the authors should consider providing experimental results on the PDBbind dataset. While the comment identifies a potential weakness in the paper, it lacks specific guidance or suggestions on how the authors might enhance the novelty or improve the experimental results. The feedback is somewhat helpful as it directs the authors to a potential area for improvement but does not provide detailed actionable steps. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that adding error bars to the results comparing pairs of models would help demonstrate that the differences are significant and not due to noise. This is an explicit action that provides a clear direction for the authors to enhance their analysis. The comment is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding error bars to results comparing pairs of models to demonstrate that the differences are significant and not due to noise. However, it does not specify which part of the paper these results are presented in, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in its suggestion to add error bars, but it lacks grounding as it does not reference a particular section or figure. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that adding error bars to results comparing pairs of models would help demonstrate that the differences are significant and not due to noise. This claim is somewhat verifiable as it provides a logical reasoning for why error bars would be beneficial in this context. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand the necessity of adding error bars. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the presentation of results. It recommends adding error bars to the comparisons between pairs of models to demonstrate that the observed differences are statistically significant and not due to noise. This feedback is clear and provides a concrete way for the authors to enhance the clarity and robustness of their analysis. By addressing this suggestion, the authors can strengthen their conclusions and provide a more comprehensive understanding of their findings. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific issue on page 2, line 81, where the full state is not defined properly. It asks a direct question about what is included in a full state, providing a clear action for the authors to take. This feedback is explicit and concrete, as it specifies the exact location of the issue and what needs to be clarified. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 2, line 81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of the full state not being defined properly and asks for clarification on what is included in a full state. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the lack of definition of \"full state\" on page 2, line 81. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely descriptive and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the definition of \"full state\" on page 2, line 81, and asks for clarification on what is included in a full state. This feedback is clear and actionable, as it directs the authors to a particular part of the paper where a definition is missing. By addressing this point, the authors can improve the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it provided additional context or suggestions on how to define \"full state\" or its implications. Overall, the comment is mostly helpful as it highlights a specific area for improvement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the study as good but notes the lack of new proposals for neural architecture encoding. It suggests that a good empirical analysis should not only provide insightful observations but also include new initial proposals based on the analysis. However, the comment does not provide explicit guidance on how the authors might develop new proposals or what specific aspects of the analysis could be expanded to include new proposals. The action is implicit and vague, leaving the authors without clear direction on how to address the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment acknowledges the study as good but points out a lack of new proposals for neural architecture encoding. It suggests that a good empirical analysis should include new initial proposals based on the analysis. However, the comment does not specify which part of the paper lacks these proposals or how the authors might develop new proposals. This makes it difficult for the authors to identify the exact sections that need revision. The comment is not grounded as it does not reference specific parts of the paper, and it is also not specific in detailing what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the study is good but lacks new proposals for neural architecture encoding. It suggests that a good empirical analysis should include new initial proposals based on the analysis. However, the comment does not provide specific examples or references to support the claim that the study lacks new proposals or how it could be improved in this regard. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the specific areas where new proposals could be included. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges the study as good but points out a significant limitation: the lack of new proposals for neural architecture encoding. It suggests that a good empirical analysis should not only provide insightful observations but also include new initial proposals based on the analysis. This feedback is clear and actionable, as it highlights an area where the authors could enhance their work by developing new proposals. However, the comment could be more helpful if it provided specific guidance on how to develop these proposals or what aspects of the analysis could be expanded to include new ideas. Despite this, the comment offers a valuable direction for improvement, making it mostly helpful.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of multiple parts, each addressing different aspects of the paper. The first part suggests that the paper should include empirical comparisons with existing algorithms, which is an explicit action. However, it does not provide specific guidance on how to conduct these comparisons or which algorithms to use. The second part recommends evaluating the paper as \"Marginally above the acceptance threshold,\" which is a vague suggestion without concrete criteria for evaluation. The third part raises concerns about the practical usefulness of the algorithm, specifically mentioning the potential high communication cost due to the need for many iterations until convergence. This is a specific concern but does not provide actionable advice on how to address it. The final part points out that certain terms are not defined, which is an explicit action for the authors to clarify. Overall, the comment provides some explicit actions but lacks concrete guidance on how to implement them, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"p.5\" and refers to specific terms like \"\u0394_i, \u0394_med, and \u2207_i,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, such as the lack of empirical comparison with existing algorithms and the need for definitions of certain terms. The comment provides clear guidance on what the authors should focus on improving, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of multiple claims and suggestions. The first claim is that the paper lacks empirical comparison with existing algorithms, which is somewhat verifiable as it highlights a gap in the paper but does not provide specific examples or references to existing algorithms for comparison. The second claim suggests that the paper should be evaluated as \"Marginally above the acceptance threshold,\" which is a subjective judgment without detailed reasoning or evidence. The third point raises a concern about the practical usefulness of the algorithm, specifically mentioning the potential high communication cost due to the need for many iterations until convergence. This claim is somewhat verifiable as it provides a logical reasoning but lacks specific examples or references to support the assertion. The final point about undefined terms is factual and does not constitute a claim. Overall, the comment is mostly verifiable, as it provides some logical reasoning but lacks detailed evidence or examples to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper. It points out the lack of empirical comparison with existing algorithms, which is a significant gap in the paper. The reviewer also suggests that the paper should be evaluated as \"Marginally above the acceptance threshold,\" indicating that while the theoretical work is comprehensive, the absence of empirical results limits its practical usefulness. Additionally, the comment raises a concern about the practical applicability of the algorithm, specifically mentioning the potential high communication cost due to the need for many iterations until convergence. This is a valuable observation that could guide the authors in refining their work. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of existing algorithms for comparison. Overall, the feedback is mostly helpful as it highlights important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the proposed approach performing well in simulations but not in real data, questioning its practical advantage. It suggests that including more real data analyses or comparisons could help support the method. While the comment implies that the authors should include more real data analyses, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as the authors are not provided with specific guidance on how to conduct these analyses or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the performance of the proposed approach in simulations versus real data, questioning its practical advantage. However, it does not specify which part of the paper discusses these simulations or real data analyses, making it weakly grounded. The comment suggests including more real data analyses or comparisons to support the method, which provides some specificity about what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed approach performs well in simulations but poorly in real data, questioning its practical advantage. However, the comment does not provide specific examples, data, or references to support this claim. Without detailed evidence or reasoning, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the proposed approach, noting that it performs well in simulations but not in real data. This observation raises a critical question about the practical advantage of the method. The comment suggests that including more real data analyses or comparisons could help support the proposed method. While the feedback highlights an important area for improvement, it lacks specific guidance on how to conduct these analyses or what aspects to focus on. Providing more detailed suggestions or examples would enhance the comment\\'s helpfulness. Therefore, the comment is somewhat helpful, as it points out a significant issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the claim of low discrimination risk and improved fairness in the solution, as well as the impact of data distribution on model effectiveness. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns. The comment lacks actionable details, such as recommending specific methods to evaluate or improve fairness or suggesting ways to ensure the data distribution is maintained after imputation. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the authors\\' claim about the solution having a low discrimination risk and improving fairness, as well as the importance of maintaining the underlying data distribution after imputation. However, it does not specify which part of the paper these claims are made in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in detailing the concerns about fairness and data distribution but lacks grounding, as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the solution has a low discrimination risk and improves fairness, while also emphasizing the importance of maintaining the underlying data distribution after imputation. However, the comment does not provide specific evidence, examples, or references to support these claims. The lack of detailed reasoning or examples makes it difficult for the authors to understand and address the concerns. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the authors\\' claim regarding the low discrimination risk and improved fairness of their solution. It also highlights the importance of maintaining the underlying data distribution after imputation, which could affect the effectiveness of the models. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. Without actionable feedback or detailed advice, the authors are left with a general understanding of the issues but no clear path for improvement. Therefore, the comment is barely helpful, as it identifies areas for improvement but does not provide sufficient guidance for the authors to make meaningful changes.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors could further exploit the ReferIt dataset by using more of its data before moving on to other datasets. This is an explicit suggestion that provides a clear direction for the authors to improve their work. However, it lacks specific guidance on how to implement this suggestion, such as which aspects of the dataset to focus on or how to integrate more data into the analysis. While the action is explicit, the lack of concrete details makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"792 \\\"larger test sets\\\"\", allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests exploiting the ReferIt dataset more before moving on to other datasets, providing a clear direction for improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors could further exploit the ReferIt dataset by using more of its data before moving on to other datasets. However, the comment does not provide any reasoning or evidence to support why this would be beneficial or how it would improve the paper. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors could further exploit the ReferIt dataset by using more of its data before moving on to other datasets. This feedback is somewhat helpful as it identifies a potential area for improvement and provides a direction for the authors to enhance their work. However, the comment lacks specific guidance on how to implement this suggestion, such as which aspects of the dataset to focus on or how to integrate more data into the analysis. While it offers a clear direction, it could be more helpful with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests clarification on specific parts of the paper, namely the explanation in sections 243-245 and the choice of k-nn over other classifiers. It asks for elaboration on why the calculation is 5*3 and not 5*2, and it questions the use of k-nn and the choice of k and distance metric. These requests are direct and provide clear guidance on what the authors need to address in their draft. The feedback is explicit and concrete, giving the authors a clear understanding of what actions to take to improve their paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper (243-245 and 247), allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what is unclear and requests elaboration on the explanation, the choice of k-nn over other classifiers, and the specifics of k and the distance metric used. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of questions seeking clarification on specific aspects of the paper, such as the explanation in sections 243-245 and the choice of k-nn over other classifiers. These questions are factual and do not contain subjective claims or opinions that require verification. They are requests for clarification and do not present any claims that need to be substantiated. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific sections of the paper (243-245 and 247) where the explanation is unclear. It requests elaboration on the calculation of 5*3 and the choice of k-nn over other classifiers, including the specifics of k and the distance metric used. This feedback is clear and actionable, as it directs the authors to clarify these points, which could significantly improve the clarity and comprehensibility of their work. By addressing these questions, the authors can enhance the reader's understanding of their methodology and results. Therefore, the comment is rated as highly helpful, as it provides specific guidance for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to describe the background of Sharpness-Aware Minimization (SAM) in detail. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be addressed, making it highly actionable. The authors know exactly what they need to do to enhance their paper, which aligns with the criteria for a highly actionable comment.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the background of Sharpness-Aware Minimization (SAM) should be described in detail. However, it does not specify which part of the paper this background information should be included in, such as a specific section or chapter. This makes it difficult for the authors to pinpoint exactly where the addition should be made. The comment is specific in its request for more detailed background information but lacks grounding as it does not identify the specific part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the background of Sharpness-Aware Minimization (SAM) should be described in detail. However, it does not provide any reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the background of Sharpness-Aware Minimization (SAM) should be described in detail. While this feedback identifies a specific area for improvement, it lacks depth and does not provide guidance on what aspects of the background should be included or how they should be presented. The comment does not offer actionable suggestions or examples, leaving the authors with a general idea of what needs to be addressed but without a clear path forward. Therefore, the comment is somewhat helpful, as it points out a potential area for enhancement but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the experimental setup lacks comprehensive comparisons, particularly between language-assisted and vision-assisted approaches. It provides specific examples of how this could be addressed, such as incorporating image guidance by using related reference normal images or color-augmentation for the kNN baseline. The comment also suggests a thorough examination of both language-based and vision-based assistance to strengthen the evaluation of LAFT's efficacy. This feedback is clear and provides concrete actions for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental setup,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking comprehensive comparisons between language-assisted and vision-assisted approaches. The comment provides concrete suggestions, such as incorporating image guidance or color-augmentation for the kNN baseline, and suggests a thorough examination of both language-based and vision-based assistance. This level of detail helps the authors understand what needs to be addressed and how to improve their evaluation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental setup lacks comprehensive comparisons between language-assisted and vision-assisted approaches. It suggests incorporating image guidance or color-augmentation for the kNN baseline to provide valuable insights. The comment provides a logical reasoning for the claim by proposing specific methods to enhance the evaluation, such as examining both language-based and vision-based assistance. However, it lacks specific examples or references to existing literature that have successfully implemented these methods, which would strengthen the claim. Therefore, the comment is mostly verifiable, as it provides a clear direction for improvement but could benefit from more detailed evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the experimental setup, specifically the lack of comprehensive comparisons between language-assisted and vision-assisted approaches. It provides specific suggestions for enhancing the evaluation, such as incorporating image guidance or color-augmentation for the kNN baseline. By offering concrete examples and a clear direction for improvement, the comment empowers the authors to strengthen their experimental design and provide more robust insights into the efficacy of LAFT. This feedback is actionable, detailed, and constructive, making it highly helpful for the authors to improve their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missing aspect in the paper, specifically the lack of related work on collective entity linking, which the reviewer believes the proposed model is a special case of. However, the comment does not provide explicit guidance on how the authors should address this omission or suggest specific related works to include. The action is implicit and vague, as the authors are left to infer that they need to add related work but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the missing related work on \"collective entity linking\" and implies that the proposed model is a special case of this line of work. This allows the authors to accurately identify the part of the paper that needs attention. The comment is also specific because it clearly specifies what is missing, namely the mention of this related work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed model is a special case of collective entity linking, which is a closely related line of work. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to look into the literature to understand the connection and verify the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of related work on collective entity linking, which the reviewer believes the proposed model is a special case of. This is a valuable observation that could help the authors expand their literature review and contextualize their work more effectively. However, the comment could be more helpful if it provided specific examples or references to the collective entity linking literature, which would give the authors a clearer direction for inclusion. Despite this, the feedback is mostly helpful as it highlights an important area for improvement, prompting the authors to enhance the paper\\'s context and relevance. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part suggests that truncating the log likelihood function could lower sensitivity and proposes a comparison, which is an explicit and concrete action for the authors to consider. The second part raises a question about the consistency of query functions for different data sources, suggesting a potential inconsistency between the algorithm and the general framework. It also provides a suggestion to either design a customized query function for each data source or remove the subscript for clarity. While the first part is explicit and concrete, the second part is more implicit and less specific, as it does not provide detailed guidance on how to address the issue. Overall, the comment is mostly actionable, as it provides clear guidance on one aspect and suggests a potential improvement on another, but the latter is less detailed.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1\" and \"the general framework,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the query functions for different data sources, suggesting a potential inconsistency and offering a suggestion for improvement. The comment is specific in detailing what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts: a suggestion to compare the effect of truncating the log likelihood function on sensitivity and a minor comment about the consistency of query functions in algorithm 1. The first part is a suggestion for further analysis, which is not a claim requiring verification. The second part raises a question about the consistency of query functions, which is more of a request for clarification than a claim. Since it does not make a subjective claim or require verification, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides two distinct points of feedback. The first part suggests a potential issue with truncating the log likelihood function and its impact on sensitivity, which could be an interesting comparison to explore. This is a somewhat helpful suggestion as it prompts the authors to consider an additional analysis that could enhance the paper. However, it lacks specific guidance on how to conduct this comparison or what aspects to focus on. The second part raises a question about the consistency of query functions in algorithm 1, noting that they are the same for all data sources but the general framework suggests they can be different. This comment is somewhat helpful as it points out a potential inconsistency, but it does not provide detailed guidance on how to address this issue or suggest specific changes. Overall, the comment offers some insights but lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation should be expanded to include a larger and more diverse dataset, encompassing more complex molecules and materials. This is an explicit action that provides a clear direction for the authors to improve their draft. The comment specifies what needs to be done, namely, to evaluate the method on a broader dataset, which gives the authors a concrete step to take. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests expanding the evaluation to a larger and more diverse dataset, including more complex molecules and materials. However, it does not specify which part of the paper this suggestion pertains to, such as the results section or the discussion of limitations. Without explicit references to sections or specific elements of the paper, the authors may find it challenging to identify where this feedback should be addressed. The comment is specific in suggesting the need for a broader evaluation, but it lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the evaluation is limited to a small set of molecules from the MD17 dataset and recommends expanding it to a larger and more diverse dataset. This claim is somewhat verifiable as it provides a logical reasoning for the need to evaluate the method on a broader dataset. However, the comment lacks specific examples or references to support the claim that a larger and more diverse dataset would be beneficial. Providing such examples or references would strengthen the justification, making the claim more verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation of the method, noting that it is currently restricted to a small set of molecules from the MD17 dataset. It suggests that the evaluation should be expanded to include a larger and more diverse dataset, encompassing more complex molecules and materials. This feedback is clear and actionable, providing the authors with a specific direction for improving the robustness and generalizability of their results. By addressing this suggestion, the authors can enhance the validity and applicability of their findings, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should clarify the differences between their work and the StreamingLLM paper, which is similar in some aspects. While the comment implies that the authors should make these clarifications, it does not provide specific guidance on how to do so or what aspects of the paper need to be highlighted. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"StreamingLLM paper\" and references a specific paper by Xiao et al. [1], allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely clarifying the differences between the current work and the StreamingLLM paper. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the StreamingLLM paper is similar to the current work, noting that it sets sink tokens and performs local attention, which may correspond to $C_{special}$ and $C_{punct}$. The reviewer suggests that since the StreamingLLM paper has recently been uploaded, it is unlikely to be compared with the current paper, and that clarifying the differences would be beneficial. The claim is somewhat verifiable as it provides a logical reasoning for the similarity and suggests a potential area for improvement. However, it lacks specific examples or detailed comparisons to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential similarity between the current work and the StreamingLLM paper, noting that both involve setting sink tokens and performing local attention. It suggests that since the StreamingLLM paper has recently been uploaded, it might be challenging to compare the two works. The comment provides a constructive suggestion by recommending that the authors clarify the differences between their work and the StreamingLLM paper. This feedback is clear and actionable, as it directs the authors to a specific area where they can enhance the clarity and distinctiveness of their work. However, the comment could be more helpful if it provided specific examples or details on what aspects to focus on when clarifying the differences. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that there is no significant improvement in qualitative results compared to ConceptWeaver, which can handle more than two concepts. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or improve the qualitative results. The comment lacks actionable details, leaving the authors without a clear understanding of what changes are needed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the qualitative results and compares them to ConceptWeaver, which can handle more than two concepts. However, it does not specify which part of the paper discusses the qualitative results or how the comparison to ConceptWeaver should be addressed. The mention of \"ConceptWeaver\" and the reference to a specific paper provide some context, but the comment lacks full grounding as it does not explicitly mention the section or part of the paper being addressed. The comment is specific in detailing the comparison issue, but the lack of explicit grounding makes it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no significant improvement in qualitative results compared to ConceptWeaver, which can handle more than two concepts. The claim is supported by a reference to a specific paper, \"Concept Weaver: Enabling Multi-Concept Fusion in Text-to-Image Models,\" which provides a basis for the comparison. However, the comment could be strengthened by providing more detailed analysis or examples of how the qualitative results differ between the two approaches. Despite this, the inclusion of a reference adds a level of verifiability, making the claim mostly verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment points out a potential issue with the qualitative results, suggesting that there may not be a significant improvement compared to ConceptWeaver, which can handle more than two concepts. This feedback is somewhat helpful as it highlights a potential area for improvement in the paper. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their qualitative results. Without actionable advice or detailed analysis, the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the problem can be reduced to subspace clustering with missing data, which could be solved by alternating between matrix completion and subspace clustering. However, it does not provide explicit instructions or concrete steps on how to implement this approach. The authors are left to infer that they should explore this method, but without detailed guidance, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment refers to a specific part of the paper, \"1) above,\" which suggests that it is addressing the first point or section of the paper. However, it does not specify which part of the first point is being discussed, leaving the authors to make an educated guess. The comment provides a suggestion for solving the problem by alternating between matrix completion and subspace clustering, but it does not specify what aspects of the problem need to be addressed or how this suggestion would improve the paper. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the problem can be reduced to subspace clustering with missing data, which could be solved by alternating between matrix completion and subspace clustering. However, the comment lacks specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a potential approach to solving the problem by reducing it to subspace clustering with missing data, which could be addressed by alternating between matrix completion and subspace clustering. While this provides a direction for improvement, the comment lacks specificity and does not offer detailed guidance on how to implement this approach or what specific aspects of the problem need to be addressed. The feedback is somewhat helpful as it points out a possible solution but does not fully support the authors in making significant improvements to their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with CCKT-Det++\\'s reliance on the quality and alignment of teacher models, noting that limitations or biases in these models could affect performance and introduce unintended biases. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue. It lacks concrete actions or recommendations for improvement, leaving the authors uncertain about how to proceed. As a result, the comment is vague and does not offer a clear path for the authors to follow, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the reliance of CCKT-Det++ on the quality and alignment of teacher models, highlighting potential issues with performance and unintended biases. However, it does not specify which part of the paper discusses CCKT-Det++ or the teacher models, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in detailing the potential issue but lacks grounding, as it does not provide a clear reference to the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the reliance of CCKT-Det++ on the quality and alignment of teacher models, suggesting that limitations or biases in these models could affect performance and introduce unintended biases. This claim is somewhat verifiable as it provides a logical reasoning about the potential impact of teacher model limitations on the performance of CCKT-Det++. However, the comment lacks specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, specifically the reliance of CCKT-Det++ on the quality and alignment of teacher models. It highlights the risk of performance degradation and the introduction of unintended biases if the teacher models have limitations or biases. This feedback is somewhat helpful as it points out an area that needs attention, but it lacks specific suggestions or guidance on how the authors might address this issue. Providing more detailed advice or examples of how to mitigate these risks would enhance the helpfulness of the comment. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the comparison objects selected in the comparison experiment are outdated and that the performance has not significantly improved. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting newer comparison objects or methods to improve performance. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the comparison objects selected in the comparison experiment are very old and that the performance has not been greatly improved. However, it does not specify which part of the paper this issue is discussed in, such as a particular section or experiment. This makes it difficult for the authors to pinpoint the exact area that needs attention. Additionally, the comment lacks specificity regarding what specific improvements or updates are needed to address the issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the comparison objects selected in the comparison experiment are very old and that the performance has not been greatly improved. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains vague and unverifiable. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the comparison objects selected in the comparison experiment are outdated and that the performance has not been significantly improved. This feedback is relevant as it highlights a potential issue with the experimental setup, suggesting that the comparison might not be meaningful or relevant in the current context. However, the comment lacks specificity and does not provide actionable suggestions on how the authors might address this issue, such as recommending newer comparison objects or methods to improve performance. While it identifies a potential weakness, the lack of detailed guidance limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how masks are handled in CNN layers, specifically in the representation block. However, it does not provide any explicit or implicit guidance on what the authors should do to address this question. There is no suggestion for improvement or clarification, leaving the authors without a clear action to take. As a result, the comment lacks actionability and is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about how masks are handled in CNN layers, specifically in the representation block. However, it does not specify which part of the paper discusses this aspect, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its inquiry but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification on how masks are handled in CNN layers, specifically in the representation block. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about how masks are handled in CNN layers, particularly in the representation block. While it identifies a potential area of confusion or lack of clarity in the paper, it does not provide any suggestions or guidance on how the authors might address this issue. The comment lacks actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is rated as barely helpful, as it identifies a potential issue but does not offer any actionable advice or suggestions for resolution.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for an explanation regarding the observation that \"without dropout\" has a larger training loss, particularly in the context of activation clipping potentially reducing model capacity. This request is clear and direct, providing the authors with a specific action to take: providing an explanation for the observed phenomenon. The feedback is concrete, as it specifies what the authors need to address, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation regarding the observation that \"without dropout\" has a larger training loss, particularly in the context of activation clipping potentially reducing model capacity. This provides clear guidance on what needs to be addressed in the figure, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the observation in Figure 8 that \"without dropout\" has a larger training loss, suggesting that activation clipping may reduce model capacity. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this observation is significant or how it relates to the model capacity. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific observation in Figure 8 that warrants further explanation. It points out the discrepancy in training loss between \"with\" and \"without\" dropout, suggesting that activation clipping may reduce model capacity. This feedback prompts the authors to provide a clearer understanding of the results, which could lead to a more comprehensive analysis of the model's performance. However, the comment lacks depth and does not offer specific suggestions or guidance on how to address the issue, limiting its usefulness. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses an opinion about the significance of the paper, specifically highlighting its potential contribution to establishing a large-scale matting dataset. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this point or what specific changes should be made to the paper. The comment lacks actionable details, leaving the authors without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides an opinion about the significance of the paper, specifically mentioning its potential contribution to establishing a large-scale matting dataset. However, it does not specify which part of the paper this significance is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not detail what aspects of the paper are missing or how the authors could improve their discussion on this point. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses an opinion about the significance of the paper, specifically highlighting its potential contribution to establishing a large-scale matting dataset. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides an opinion about the significance of the paper, specifically highlighting its potential contribution to establishing a large-scale matting dataset. However, it does not offer any actionable feedback or suggestions for improvement. The comment lacks depth and does not provide any guidance on how the authors might enhance their work or address the mentioned significance. As a result, the comment is not helpful at all, as it does not offer any meaningful insights or directions for the authors to improve their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the number of adversarial examples is insufficient to demonstrate a distribution, but it does not provide any explicit or implicit guidance on how to address this issue. There is no suggestion on how to increase the number of examples, what specific distribution should be demonstrated, or how to improve the demonstration. Without any actionable advice or concrete steps, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the \"number of adversarial examples is too small to demonstrate some distribution,\" but it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This lack of explicit reference makes it difficult for the authors to identify the exact area needing attention. Additionally, the comment does not provide specific details on what distribution should be demonstrated or how the authors could improve the demonstration. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the number of adversarial examples is too small to demonstrate a distribution. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the number of adversarial examples being too small to demonstrate a distribution. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. Without actionable advice or examples, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it identifies a potential weakness but does not provide sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the appropriateness of the proposed channel-sparse gradients and suggests that they may not save time or memory in practice due to the limitations of most frameworks supporting dense gradients. It also critiques the analysis experiments in Section 5.2, suggesting that they should be conducted with the full set of common corruptions for thoroughness and comparability. While the comment identifies specific issues and areas for improvement, it does not provide explicit instructions on how to address these concerns. The authors are left to infer that they should conduct additional experiments with the full set of corruptions. The action is implicit and somewhat vague, as it lacks detailed guidance on how to implement the suggested changes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.2\" and \"the proposed channel-sparse gradients,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the proposed channel-sparse gradients, such as the potential lack of time or memory savings due to the limitations of most frameworks supporting dense gradients. Additionally, it suggests conducting analysis experiments with the full set of common corruptions for thoroughness and comparability. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the effectiveness of the proposed channel-sparse gradients, suggesting that they may not save time or memory in practice due to the limitations of most frameworks supporting dense gradients. It also critiques the analysis experiments in Section 5.2, noting that they are conducted with a subset of common corruptions and may not generalize to the full set. The comment provides a logical reasoning for the potential limitations of the proposed method and suggests a way to improve the analysis by conducting experiments with the full set of corruptions. However, it lacks specific examples or references to support the claim about the limitations of most frameworks. Therefore, the comment is mostly verifiable, as it provides a clear rationale but could be strengthened with additional evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper. First, it questions the effectiveness of the proposed channel-sparse gradients, suggesting that they may not save time or memory in practice due to the limitations of most frameworks supporting dense gradients. This critique is specific and provides a clear direction for the authors to consider the practical implications of their method. Second, the comment critiques the analysis experiments in Section 5.2, noting that they are conducted with a subset of common corruptions and may not generalize to the full set. The reviewer suggests conducting these experiments with the full set for thoroughness and comparability with other results. This feedback is actionable and provides a clear path for the authors to enhance the robustness and comprehensiveness of their analysis. Overall, the comment is highly helpful as it offers detailed and constructive feedback that can significantly improve the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several issues with the paper, including the lack of consideration for sparsity or low rank in the proof, which is claimed to be connected to concentration-of-measure. It also questions the originality of the results, suggesting they are a simple extension of existing results. However, the comment does not provide explicit or implicit actions for the authors to take. It lacks guidance on how to address these concerns or improve the draft. The authors are left without a clear understanding of what changes are needed or how to implement them. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proof and the claims made in the paper, specifically mentioning the lack of consideration for sparsity or low rank and the use of concentration-of-measure. However, it does not explicitly mention which part of the paper this critique is based on, making it weakly grounded. The comment is specific in detailing the issues with the proof and the claims, but without clear references to specific sections or elements of the paper, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims, including the lack of consideration for sparsity or low rank in the proof and the use of concentration-of-measure, which is connected to low rank. It also questions the originality of the results, suggesting they are a simple extension of existing results. However, the comment lacks specific references or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The lack of evidence and detailed justification renders the claims unverifiable, as the authors are left without a clear path to improve their work based on the feedback. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several concerns about the paper, including the lack of consideration for sparsity or low rank in the proof, which is claimed to be connected to concentration-of-measure. It also questions the originality of the results, suggesting they are a simple extension of existing results. However, the comment does not provide specific guidance or suggestions on how the authors might address these issues or improve their work. Without actionable feedback or detailed analysis, the authors are left without a clear understanding of how to enhance their draft. Therefore, the comment is barely helpful, as it identifies potential weaknesses but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the Limitations section is too concise compared to the detailed writing style in the main body of the paper. However, it does not provide any explicit or implicit suggestions on how to improve the conciseness or detail in the Limitations section. The authors are left without guidance on what specific changes or additions would enhance the section. Without actionable advice or examples, the comment lacks the necessary detail for the authors to make meaningful improvements. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the \"Limitations\" section, which provides full grounding as it explicitly mentions a specific part of the paper. However, the comment is not specific because it does not detail what aspects of the section are too concise or how it could be improved to match the detailed writing style of the main body. The authors are left without clear guidance on what changes are needed. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the \"Limitations\" section is too concise compared to the detailed writing style in the main body of the paper. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the \"Limitations\" section is too concise compared to the detailed writing style in the main body of the paper. This feedback identifies a potential area for improvement, as the authors may need to expand on the limitations to provide a more comprehensive understanding of the work. However, the comment lacks specific suggestions or guidance on how to enhance the detail in the Limitations section. While it highlights an important aspect, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a general direction for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the novelty of the proposed method is weak, suggesting it is a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the perceived lack of novelty or how to enhance the originality of the proposed method. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the proposed method, suggesting it is a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. However, it does not specify which part of the paper discusses the proposed method or PatchCore, making it weakly grounded. The comment is specific in identifying the issue with the novelty of the proposed method, but without clear references to specific sections or elements of the paper, the authors may struggle to pinpoint where to address this feedback. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the proposed method is weak, suggesting it is a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. This claim is somewhat verifiable as it provides a specific reference to PatchCore, indicating that the proposed method builds upon existing work. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as a comparison of the proposed method with PatchCore or an explanation of how the denoising process contributes to the novelty. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by questioning the novelty of the proposed method. It suggests that the method appears to be a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. This feedback is somewhat helpful as it prompts the authors to consider the originality of their work and potentially differentiate it from existing methods. However, the comment lacks specific guidance or suggestions on how the authors might enhance the novelty or distinguish their work from PatchCore. To be more helpful, the comment could include examples or references to specific aspects of PatchCore that the proposed method builds upon, or offer suggestions for how to improve the originality of the work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the authors should provide more detailed instructions on how to install and run the software, as well as list all the prompts used in the evaluation. It also suggests that these details should be included in an extensive version of Table 1 or in the appendix, similar to the binpwn example. This feedback is clear and provides concrete actions for the authors to take, ensuring they know exactly what steps to take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue with running the code due to a lack of clear instructions on installation and execution. It also provides specific suggestions for improvement, such as providing more details about each challenge in an extensive version of Table 1 or in the appendix, similar to the binpwn example. Additionally, it recommends listing all the prompts used in the evaluation in the appendix or on GitHub. This level of detail and specificity allows the authors to accurately identify the parts of the paper that need revision and understand the exact changes required. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the repository lacks clear instructions on how to install and run the software, which prevents the reviewer from running the code. The reviewer suggests providing more details about each challenge and listing all the prompts used in the evaluation. While the claim is based on the reviewer\\'s personal experience, it lacks specific examples or references to support the assertion that the instructions are unclear. The suggestion for improvement is logical and provides a clear path for the authors to follow, but the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of clear instructions on how to install and run the software, which prevents the reviewer from testing the code. It provides actionable feedback by suggesting that the authors include more detailed instructions, similar to those found in the binpwn example, and list all the prompts used in the evaluation. This feedback is clear and constructive, offering specific guidance on how to improve the reproducibility and usability of the paper. By addressing these issues, the authors can enhance the accessibility and credibility of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the model ablation results in Table 3 and the major claim of the paper regarding interpretable VQA. It suggests that the global representation g_v is more crucial than other components, which seems to contradict the claim that correct answers are anchored on correct visual content. However, the comment does not provide explicit guidance or suggestions on how the authors should address this discrepancy or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to reconcile the findings with their claims, but without specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the model ablation results and the major claim of the paper regarding interpretable VQA. The comment highlights the importance of the global representation g_v and its potential impact on the grounded QA aspect. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the global representation g_v is more crucial than other components, as indicated by the model ablation results in Table 3. It also suggests that this finding slightly departs from the major claim of the paper regarding interpretable VQA, where correct answers are anchored on correct visual content. However, the comment does not provide specific examples or detailed reasoning to support the claim that the global representation is more crucial or how it contradicts the major claim. The lack of detailed evidence or references makes the claim somewhat verifiable, as the authors would need to delve deeper into the paper to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential discrepancy between the model ablation results in Table 3 and the major claim of the paper regarding interpretable VQA. It highlights that the global representation g_v seems more crucial than other components, which could contradict the claim that correct answers are anchored on correct visual content. This observation is valuable as it points out a specific area where the paper\\'s claims may not align with the results, prompting the authors to reconsider their interpretation or provide further clarification. However, the comment could be more helpful if it offered suggestions on how to address this discrepancy or improve the paper\\'s claims. Overall, the feedback is somewhat helpful as it directs the authors\\' attention to a critical area for improvement but lacks detailed guidance on how to resolve the issue.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests avoiding the notation $f^{-1} = g$ in the notation paragraph of Section 3, as it implies that $f$ is an invertible function, which may not be the case when $d<D$. The reviewer recommends using the language of left inverses instead. While the comment provides a clear suggestion for improvement, it does not explicitly instruct the authors to make the change or offer detailed guidance on how to implement it. The action is somewhat vague, as the authors know they need to reconsider the notation but may not be entirely sure how to make the change. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the notation paragraph in sec 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the notation, specifically the use of $f^{-1} = g$ when $d<D$, and suggests using the language of left inverses instead. This provides clear guidance on what needs to be addressed in the notation paragraph. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the notation $f^{-1} = g$ should be avoided because $f$ cannot be an invertible function when $d<D$, given its domain is defined as $\\mathbb{R}^D$. The reviewer provides a logical explanation for the potential issue, noting that while $f$ might be injective on a manifold, the notation implies invertibility, which is not guaranteed. This reasoning is clear and provides a basis for the suggestion to use the language of left inverses. However, the comment could be strengthened by providing specific examples or references to support the claim. Therefore, the claim is mostly verifiable, as it provides a logical basis but lacks detailed evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the notation in the paper, specifically the use of $f^{-1} = g$ in the notation paragraph of Section 3. The reviewer points out that when $d<D$, $f$ cannot be an invertible function, as its domain is defined as $\\mathbb{R}^D$. This observation is relevant and could help the authors clarify their notation. However, the comment could be more helpful if it provided additional guidance on how to address this issue, such as suggesting alternative notations or explanations. While the feedback is somewhat helpful in pointing out a potential problem, it lacks depth and actionable suggestions, making it somewhat helpful but not fully comprehensive. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should include comparisons with state-of-the-art RVQ-VAE models, specifically mentioning MoMask [1], in the ablation studies on the motion tokenizer in Table 4. This provides a clear and concrete action for the authors to take, as it specifies the exact comparison that should be made to enhance the comprehensiveness of the study. The comment is highly actionable because it gives the authors a direct and detailed instruction on how to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the inclusion of comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1], in the ablation studies. This provides clear guidance on how to enhance the comprehensiveness of the study. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the ablation studies in Table 4 should include comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1], to provide a more comprehensive understanding of the model\\'s effectiveness. This claim is supported by the mention of a specific model, MoMask, which is a well-known reference in the field. However, the comment could be strengthened by providing more detailed reasoning or examples of how these comparisons would enhance the study. Overall, the claim is mostly verifiable, as it provides a clear suggestion with some supporting evidence, but it could benefit from additional justification or examples. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors include comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1], in the ablation studies on the motion tokenizer in Table 4. This recommendation is clear and constructive, as it would enhance the comprehensiveness of the study by providing a more nuanced understanding of the model\\'s relative effectiveness. By following this suggestion, the authors can improve the depth and rigor of their analysis, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the \"primary-secondary\" relationship and its distinction from nuclearity. However, it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment implies that the authors should clarify the distinction, but it lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the concept of the \"primary-secondary\" relationship, noting that its difference from nuclearity is unclear and not precisely defined. However, it does not specify which part of the paper discusses this relationship, making it weakly grounded. The comment is specific in identifying the issue of unclear definitions, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the \"primary-secondary\" relationship is mentioned frequently in the paper but its difference from nuclearity is unclear and not precisely defined. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the lack of clarity regarding the \"primary-secondary\" relationship and its distinction from nuclearity. This feedback is somewhat helpful as it points out a potential area of confusion that the authors should address to improve the clarity and comprehensiveness of their work. However, the comment does not provide specific suggestions or guidance on how to clarify this distinction, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, as it highlights an important issue but lacks detailed advice for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the effect of the mask ratio across different datasets, which is mentioned in the limitations section. It also notes the absence of an intuitive guide for choosing the mask ratio in the discussions. While the comment identifies a gap in the paper, it does not provide explicit instructions on how to address this issue or suggest specific steps for improving the discussion on mask ratio. The action is implicit and somewhat vague, as the authors can infer that they need to provide more guidance on choosing the mask ratio, but they are not given concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the mask ratio\\'s effect being different across various datasets, which is mentioned in the limitations section. It also points out the absence of an intuitive guide for choosing the mask ratio in the discussions. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the discussions or results sections where the mask ratio is discussed. The comment is specific in detailing what is missing, namely an intuitive guide for choosing the mask ratio. However, since the authors cannot pinpoint the exact section without explicit references, the comment is weakly grounded but specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the effect of the mask ratio varies across different datasets, which would lead to more tuning, as mentioned in the limitations. It also notes the absence of an intuitive guide for choosing the mask ratio in the discussions. While the comment highlights a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The mention of the limitations section provides some context, but without further elaboration or references, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the effect of the mask ratio varying across different datasets, which could lead to more tuning as mentioned in the limitations. It also points out the absence of an intuitive guide for choosing the mask ratio in the discussions. This feedback is somewhat helpful as it highlights a specific area for improvement, namely the need for a more detailed discussion on the impact of the mask ratio and a guide for choosing it. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue, such as proposing a method for selecting the mask ratio or suggesting additional experiments to explore its impact. Overall, the comment provides some direction for improvement but lacks depth and actionable advice, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from another round of proof-reading, indicating that there are sections that are difficult to follow. However, it does not specify which sections are problematic or provide guidance on how to improve clarity. The action is implicit and vague, as the authors are left to infer which sections need attention and how to address the issue. Without explicit instructions or examples, the authors may struggle to know exactly what changes to make. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from another round of proof-reading, indicating that there are sections that are difficult to follow. However, it does not specify which sections are problematic, making it difficult for the authors to identify the exact areas that need improvement. This lack of specificity and grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper could benefit from another round of proof-reading due to sections being difficult to follow. However, it does not provide specific examples or details about which sections are problematic or why they are difficult to follow. This lack of detailed justification or evidence makes the claim difficult for the authors to address or verify. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from another round of proof-reading, indicating that there are sections that are difficult to follow. While this feedback identifies a potential issue with the clarity of the paper, it lacks specificity and does not provide guidance on which sections are problematic or how to improve them. Without detailed suggestions or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is barely helpful, as it points out a potential problem but does not offer actionable advice for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential confusion regarding the term \"STG layer\" in Fig. 2, suggesting that it might refer to stochastic gates. However, the comment does not provide explicit guidance on how the authors should address this issue. It lacks concrete suggestions on whether to clarify the term in the manuscript, provide additional context, or make changes to the figure. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the confusion regarding the term \"STG layer\" and suggests that it might refer to stochastic gates. This provides clear guidance on what needs to be clarified or addressed in the manuscript. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the term \"STG layer\" in Fig. 2, suggesting that it might refer to stochastic gates but is unsure. This is a factual observation rather than a claim, as it does not express an opinion or judgment. It is a request for clarification, which is not considered a claim. Therefore, the label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a potential confusion in the manuscript regarding the term \"STG layer\" in Fig. 2. It points out that the term has not been mentioned throughout the manuscript, leading to uncertainty about its meaning. The reviewer provides a guess that it might refer to stochastic gates, which is a reasonable inference. However, the comment lacks specific guidance on how the authors should address this issue, such as suggesting where to clarify the term or how to provide additional context. While it highlights a potential area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the limited improvements and underperformance of the proposed methodology compared to the baseline in specific cases, such as FiQA and CONALA. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the methodology or what specific changes could be made to enhance its performance. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of the proposed methodology, specifically mentioning instances where it appears limited and underperforms compared to the baseline in cases like FiQA and CONALA. However, it does not specify which part of the paper discusses these instances or provide detailed feedback on how to address the underperformance. The authors can infer that it relates to the results or discussion sections, but the lack of explicit references or detailed guidance makes it weakly grounded. The comment is specific in identifying the issue of limited improvements and underperformance, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvements resulting from the proposed methodology are limited in some instances and that it underperforms compared to the baseline in cases like FiQA and CONALA. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without specific data or results to back up the assertion, the authors may find it challenging to understand the basis of the critique or to address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a specific issue with the proposed methodology, noting that it appears to have limited improvements and even underperforms compared to the baseline in certain cases, such as FiQA and CONALA. This feedback is valuable as it points out a potential weakness in the methodology, prompting the authors to investigate and address this issue. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might improve the methodology or address the underperformance. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of comparisons with a specific reference, [1], and asks for the contributions or advantages beyond what is presented in [1]. While the comment implies that the authors should clarify these aspects, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clear comparison and highlight their unique contributions. However, the comment does not specify what specific details should be included in the comparison or how to articulate the contributions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Comparisons with [1]\" and references a specific paper, \"[1] Differentially private model personalization. NeurIPS 2021,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of clarity in comparisons and the need to highlight contributions or advantages beyond those presented in the referenced paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of comparisons with a specific reference, [1], and asks for the contributions or advantages beyond what is presented in [1]. However, it does not provide any supporting evidence, reasoning, or examples to justify why these comparisons are unclear or what specific aspects need clarification. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of comparisons with a referenced paper, [1], which discusses differentially private model personalization. It prompts the authors to clarify their contributions and advantages beyond what is presented in [1]. This feedback is clear and actionable, as it directs the authors to provide a more detailed comparison and highlight their unique contributions. However, the comment could be more helpful if it offered suggestions on how to structure the comparison or what specific aspects to focus on. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a better explanation of the re-balancing step method used in multi-modal learning to make it less greedy. It specifically suggests that the authors should explain why using the average feature of previous samples can stop the training of the uni-modal branch. This feedback is clear and provides a concrete action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"re-balancing step method\" and the need for a better explanation of its use in making multi-modal learning less greedy. It also specifies the issue by asking for an explanation of why using the average feature of previous samples can stop the training of the uni-modal branch. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the re-balancing step method used in multi-modal learning is not well described and analyzed in the full text. It suggests that the authors should provide a better explanation of why using the average feature of previous samples can stop the training of the uni-modal branch. However, the comment does not provide specific examples or references to support the claim that the current explanation is inadequate. This makes the claim somewhat verifiable, as the authors would need to infer the specific issues and address them without explicit guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks clarity, namely the description and analysis of the re-balancing step method used in multi-modal learning. It suggests that the authors should provide a better explanation of why using the average feature of previous samples can stop the training of the uni-modal branch. This feedback is clear and actionable, as it directs the authors to a particular aspect of their work that requires further elaboration. By addressing this point, the authors can enhance the comprehensibility and rigor of their paper. Therefore, the comment is rated as mostly helpful, as it provides valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the differences and advantages of the \"Reduce\" part in Section 4.1 compared to EATA, as well as whether harmful OOD instances can be identified using an entropy metric instead of an energy metric. While the comment implies that the authors should provide more information or clarification on these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address these questions but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1\" and the \"Reduce\" part, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the differences and advantages of the \"Reduce\" part compared to EATA and whether harmful OOD instances can be identified using an entropy metric instead of an energy metric. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification and additional information about the \"Reduce\" part in Section 4.1, specifically regarding differences and advantages compared to EATA, and the use of an entropy metric instead of an energy metric for identifying harmful OOD instances. These are factual questions that do not contain subjective claims or opinions, making them purely descriptive and not requiring verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises specific questions about the differences and advantages of the \"Reduce\" part in Section 4.1 compared to EATA, as well as the use of an entropy metric versus an energy metric for identifying harmful OOD instances. While it does not provide detailed suggestions for improvement, it does prompt the authors to clarify these aspects, which could lead to a more comprehensive understanding of their work. However, the comment lacks depth and does not offer actionable guidance on how to address these questions or improve the draft. Therefore, it is somewhat helpful, as it provides some direction but could be more comprehensive.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it would be interesting to compare the proposed method against deterministic control, given the popularity of deterministic policies. However, the comment explicitly states that this comparison is not necessary to support the main claims of the paper. The action is explicit, as it suggests a potential comparison, but it is not mandatory. The comment provides a clear direction for further exploration, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed method against deterministic control, given the popularity of deterministic policies. However, it does not specify which part of the paper this suggestion should be addressed in, nor does it provide details on how this comparison should be conducted. The authors can infer that it relates to the experimental or results sections, but the lack of specificity and grounding makes it difficult for them to pinpoint exactly where to make the changes. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that it would be interesting to compare the proposed method against deterministic control, given the popularity of deterministic policies. However, the comment does not provide any reasoning or evidence to support why this comparison is necessary or beneficial. It lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an interesting comparison between the proposed method and deterministic control, given the popularity of deterministic policies. While it acknowledges that this comparison is not necessary to support the main claims of the paper, it still provides a valuable suggestion for further exploration. However, the comment lacks depth and does not offer specific guidance on how to conduct this comparison or what aspects to focus on. As a result, the feedback is somewhat helpful, as it identifies a potential area for improvement but does not provide detailed actionable steps. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies an issue with the naming of the third column in Table 4, suggesting that it should not be named \"ATE\" and clarifies that \"Corr\" is also \"Cau-Ant.\" This feedback provides a direct and concrete action for the authors to take, ensuring that the column names are accurate and consistent. The comment is explicit and provides clear guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the naming of the third column, suggesting that it should not be named \"ATE\" and clarifying that \"Corr\" is also \"Cau-Ant.\" This provides clear guidance on what needs to be corrected, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual observation about the naming of columns in Table 4, specifically questioning the naming of the third column as \"ATE\" and clarifying that \"Corr\" is also \"Cau-Ant.\" This is a descriptive statement without any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the naming of columns in Table 4, pointing out that the third column should not be named \"ATE\" and clarifying that \"Corr\" is also \"Cau-Ant.\" This feedback is clear and actionable, providing the authors with a precise correction to make in their draft. By addressing this issue, the authors can ensure the accuracy and consistency of their table, which is crucial for clarity and understanding. The comment is highly helpful as it offers a direct and concrete suggestion for improvement, making it a valuable contribution to the review process.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part suggests that the mechanism is not clearly anchored in prior work, even after the experiments section, and recommends providing more clarity on this aspect. The second part suggests annotating or zooming in on figures to help readers understand the differences in the curves. Both parts provide explicit actions for the authors to take: clarifying the mechanism in relation to prior work and enhancing the clarity of the figures. The feedback is clear and actionable, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"mechanism\" and the \"experiments section,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific suggestions for improvement, such as clarifying the mechanism in relation to prior work and annotating or zooming in on figures to enhance their clarity. This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts. The first part claims that the mechanism is not clearly anchored in prior work, which is a subjective opinion. However, the reviewer acknowledges that there is one exception where the methods are clearly described. This exception provides some basis for the claim, but the comment lacks detailed reasoning or references to specific prior work, making it somewhat verifiable. The second part suggests annotating or zooming in on figures to enhance their clarity, which is a factual statement and not a claim. Therefore, the overall comment is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two distinct points of feedback. The first part highlights a lack of clarity regarding the mechanism's anchoring in prior work, suggesting that more detailed references or explanations would be beneficial. This feedback is somewhat helpful as it identifies an area for improvement but lacks specific suggestions on how to enhance the anchoring. The second part addresses the clarity of figures, suggesting that annotating or zooming in on the curves could help readers understand the significance of the differences. This is a clear and actionable suggestion that could significantly improve the draft. Overall, the comment offers some helpful insights but could be more comprehensive in its suggestions. Therefore, it aligns with a score of 4, indicating that the comment is mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the limited novelty of the paper, suggesting that the key contribution is the pre-trained mechanism applied to few-shot graph learning. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to enhance the novelty or simplify the concept, leaving the authors without a clear path for improvement. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the limited novelty of the paper, specifically mentioning the pre-trained mechanism applied to few-shot graph learning. However, it does not specify which part of the paper discusses this contribution, making it difficult for the authors to pinpoint the exact section that needs attention. The comment provides some specificity by highlighting the novelty issue and the complexity of the main idea, but without explicit grounding, the authors cannot confidently determine which part of the paper is being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper has limited novelty, specifically mentioning the pre-trained mechanism applied to few-shot graph learning. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the limited novelty of the paper, specifically highlighting the pre-trained mechanism applied to few-shot graph learning as the key contribution. It acknowledges that the main idea seems plausible but notes that it is not exciting and feels complicated. However, the comment lacks specific suggestions or guidance on how the authors might enhance the novelty or simplify the concept. Without actionable feedback or detailed advice, the authors are left without a clear path for improvement. Therefore, the comment is barely helpful, as it identifies a potential issue but does not provide sufficient guidance for the authors to address it effectively.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper regarding the theoretical understanding of why certain setups or parameters do not lead to collapse during test-time training. However, it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment implies that the authors should explore theoretical explanations, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of theoretical understanding in the paper regarding why certain setups or parameters do not lead to collapse during test-time training. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the need for theoretical understanding, but without clear grounding, it is challenging for the authors to know where to focus their revisions. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper empirically validates certain setups or parameters for test-time training but lacks theoretical understanding of why they do not collapse. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the theoretical understanding of why certain setups or parameters do not lead to collapse during test-time training. While it highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this theoretical gap. The comment provides a clear direction for the authors to explore but does not offer detailed steps or examples to help them improve their draft. Therefore, the comment is somewhat helpful, as it points out a significant area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the clarity of the visual analysis in Section 4.4, specifically whether it is based on training or test images. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to clarify this point or what specific information should be added to the paper. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the clarity of the visual analysis in Section 4.4, specifically whether it is based on training or test images. It explicitly mentions \"Sec.4.4,\" which allows the authors to accurately identify the part of the paper being addressed, providing full grounding. The comment is also specific as it clearly specifies the issue of unclear visual analysis and the need for clarification on whether it pertains to training or test images. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the clarity of the visual analysis in Section 4.4, specifically whether it is based on training or test images. However, it does not provide any supporting evidence, reasoning, or references to justify the claim. The comment lacks specific details or examples that would help the authors understand the issue or how to address it. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to make improvements. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the clarity of the visual analysis in Section 4.4, specifically whether it is based on training or test images. This is a relevant observation that could help the authors clarify their methodology and results. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or improve the clarity of their analysis. While it identifies a potential area for improvement, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors apply the DEER method to other methods like LEM or UnICORNN to explore their performance and potential for better results. It implies that this could strengthen the paper and broaden its impact. While the comment provides a clear direction for further exploration, it does not specify which specific aspects of the DEER method should be applied or how to conduct the exploration. The action is explicit but somewhat vague, as it lacks detailed guidance on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring the application of the DEER method to other methods like LEM or UnICORNN, which could provide insights into their performance and potential for better results. However, it does not specify which part of the paper this suggestion should be addressed in, making it weakly grounded. The comment is specific in suggesting an area for exploration and potential benefits, such as maintaining performance or achieving better results with faster training and hyperparameter tuning. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that applying the DEER method to other methods like LEM or UnICORNN could provide interesting insights into their performance and potential for better results. The comment implies that this exploration could strengthen the paper and broaden its impact. However, the claim lacks specific examples or detailed reasoning to support why this exploration would be beneficial or how it would contribute to the paper\\'s impact. The suggestion is somewhat verifiable as it provides a logical basis for the claim, but it requires more detailed justification or examples to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests an interesting direction for further exploration by proposing the application of the DEER method to other methods like LEM or UnICORNN. It raises questions about the potential performance and benefits of using the DEER method with these other methods, such as faster training and hyperparameter tuning. This feedback is clear and actionable, as it provides a specific area for the authors to expand their study, which could strengthen the paper and broaden its impact. However, the comment could be more helpful if it included specific guidance on how to conduct this exploration or what aspects to focus on. Overall, the comment is mostly helpful, as it offers a valuable suggestion for enhancing the paper's scope and depth.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment indicates that the presentation is difficult to follow due to the excessive use of notations. However, it does not provide any explicit or implicit guidance on how to address this issue. The authors are left without a clear understanding of which notations are problematic or how to simplify the presentation. Without specific suggestions or examples, the authors cannot effectively improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the presentation is hard to follow due to the excessive use of notations. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. Without explicit references or detailed examples, the authors cannot confidently identify the specific sections that need attention. This makes the comment weakly grounded, as the authors can only make an educated guess about the parts being addressed. Additionally, the comment lacks specificity regarding what aspects of the notations are problematic or how they could be improved. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the presentation is hard to follow due to the excessive use of notations. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples of which notations are problematic, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the presentation of the paper, noting that it is hard to follow due to the excessive use of notations. However, it lacks depth and does not provide any suggestions or guidance on how to address this issue. Without actionable advice or examples of which notations are problematic, the authors are left without a clear understanding of how to improve the clarity of their presentation. This makes the comment barely helpful, as it highlights a potential problem but does not offer any constructive feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests including results from GPT-4V, even though its API is not yet released. The reviewer proposes conducting \"some quick experiments through ChatGPT's UI\" as a way to obtain these results. This comment provides a clear and explicit action for the authors to take, along with a concrete suggestion on how to implement it. The authors know exactly what they need to do to address the feedback, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including results from GPT-4V, but it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, while the comment provides a clear suggestion, it does not specify what aspects of the results should be included or how they would contribute to the paper. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests including results from GPT-4V, noting that the API is not yet released but proposing that quick experiments through ChatGPT\\'s UI could be sufficient. This comment is mostly verifiable as it provides a logical reasoning for why including results from GPT-4V would be beneficial, even in the absence of the official API. However, it lacks specific examples or references to support the claim, which could strengthen the justification. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests including results from GPT-4V, even though its API is not yet released. The reviewer proposes conducting \"some quick experiments through ChatGPT\\'s UI\" as a way to obtain these results. This feedback is clear and actionable, providing the authors with a specific suggestion on how to enhance their draft by incorporating additional data. However, the comment could be more helpful if it explained why including these results would be beneficial or how they would contribute to the paper\\'s overall impact. Despite this, the suggestion is concrete and offers a direct path for improvement, making the comment mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should discuss more about the meaning of their theoretical analysis and compare it with baselines to explain why CoPur could perform better. While the comment implies that the authors should provide additional discussion and comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add a discussion section and provide comparisons. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should discuss more about the meaning of their theoretical analysis and compare it with baselines to explain why CoPur could do better. However, it does not specify which part of the paper this discussion should be added to, making it weakly grounded. The comment is specific in suggesting what needs to be addressed, namely the discussion of the analysis and its comparison with baselines. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should discuss more about the meaning of their theoretical analysis and compare it with baselines to explain why CoPur could do better. However, the comment does not provide any specific examples, reasoning, or references to support why this discussion is necessary or how it would improve the paper. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide more discussion on the meaning of their theoretical analysis and compare it with baselines to explain why CoPur could perform better. This feedback is somewhat helpful as it identifies an area where the paper could be improved by providing more context and comparison. However, the comment lacks specificity and does not offer detailed guidance on how to conduct this comparison or what aspects to focus on. While it points out a potential area for enhancement, it does not provide actionable steps for the authors to take, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the evaluation metrics and protocol used in the paper. It points out that the reported metrics are mostly for 3D NVS and questions the relevance of the keypoint distance metric for assessing motion quality. Additionally, it raises a concern about the evaluation protocol, specifically asking whether the camera parameters are the same for all frames when generating videos. This could impact the keypoint distance metric. While the comment identifies specific issues, it does not provide explicit instructions on how to address these concerns or improve the evaluation protocol. The authors can infer that they need to clarify the evaluation metrics and protocol, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Result/eval,\" indicating that it addresses the evaluation section of the paper. It also specifies the issues with the reported metrics, particularly the use of keypoint distance as a metric for dynamics and the lack of clarity in the evaluation protocol, specifically regarding camera parameters. This provides clear guidance on what needs to be addressed in the evaluation section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the evaluation metrics and protocol used in the paper. It points out that the reported metrics are mostly for 3D NVS and questions the relevance of the keypoint distance metric for assessing motion quality. Additionally, it raises a concern about the evaluation protocol, specifically asking whether the camera parameters are the same for all frames when generating videos. This question is logical and based on common knowledge about the impact of camera motion on keypoint distance. However, the comment could be strengthened by providing specific examples or references to support the claim about the limitations of the current evaluation protocol. Therefore, the claim is mostly verifiable, as it provides a clear rationale but lacks detailed evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies specific issues with the evaluation metrics and protocol used in the paper. It points out that the reported metrics are mostly for 3D NVS and questions the relevance of the keypoint distance metric for assessing motion quality. Additionally, it raises a concern about the evaluation protocol, specifically asking whether the camera parameters are the same for all frames when generating videos. This feedback is clear and actionable, as it prompts the authors to clarify and improve their evaluation metrics and protocol. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered examples of alternative metrics or protocols that could be used. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the disjointed presentation of the two parts of pretraining and regularization, suggesting that they appear as incremental additions rather than naturally integrated components. The comment implies that the authors should address this issue to improve the coherence of the paper. However, it does not provide specific guidance on how to integrate these components or what changes should be made to achieve a more cohesive presentation. The action is implicit and somewhat vague, as the authors can infer that they need to improve the integration but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the presentation of pretraining and regularization in the paper, suggesting that they appear as incremental additions rather than naturally integrated components. However, it does not specify which sections or parts of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact areas needing revision. The comment is specific in its critique of the presentation but lacks grounding, as it does not provide clear references to the sections or elements being discussed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the two parts of pretraining and regularization appear as incremental additions rather than naturally integrated components, which detracts from the coherence of the paper. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of the paper, noting that the two parts of pretraining and regularization appear as incremental additions rather than naturally integrated components. This observation is relevant and could impact the coherence and clarity of the paper. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue, such as proposing ways to integrate these components more effectively or suggesting specific changes to the presentation. While it highlights a potential weakness, the feedback is incomplete and does not provide enough detail for the authors to make meaningful improvements. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of explanation regarding the importance of Renyi divergence, particularly for readers unfamiliar with differential privacy. However, it does not provide explicit guidance or suggestions on how to address this issue. The authors are left to infer that they need to provide a clearer explanation, but without specific instructions or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the explanation of Renyi divergence, specifically noting that its importance is not well-explained for readers unfamiliar with differential privacy. However, it does not specify which part of the paper discusses Renyi divergence, making it weakly grounded. The comment is specific in identifying the issue with the explanation of Renyi divergence, but without clear references to specific sections or examples, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the importance of Renyi divergence is not well explained, particularly for readers unfamiliar with differential privacy. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks clarity, namely the explanation of the importance of Renyi divergence, particularly for readers unfamiliar with differential privacy. This feedback is somewhat helpful as it points out a potential gap in the paper\\'s explanation, prompting the authors to consider how to better explain this concept. However, the comment does not provide specific suggestions or guidance on how to improve the explanation, leaving the authors to infer the necessary steps on their own. Therefore, the comment is rated as somewhat helpful, as it highlights an area for improvement but lacks detailed actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should focus more on simplicity and clarity in their work, rather than relying heavily on \"mathematical theories.\" However, it does not provide specific guidance on how to achieve this goal or what aspects of the paper should be simplified or clarified. The action is implicit and vague, as the authors are left to infer what changes are needed without concrete instructions. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should focus more on simplicity and clarity, rather than relying on \"mathematical theories.\" However, it does not specify which part of the paper is affected by this suggestion or where the authors should make these changes. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of simplicity and clarity should be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should focus more on simplicity and clarity, rather than relying on \"mathematical theories.\" However, it does not provide any specific examples, reasoning, or evidence to support why this shift is necessary or beneficial. The comment lacks detailed justification or references to substantiate the claim, making it difficult for the authors to understand and address the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should focus more on simplicity and clarity in their work, rather than relying heavily on \"mathematical theories.\" While this feedback identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on how to achieve this goal. The comment does not specify which aspects of the paper are overly complex or how the authors might simplify them. Without detailed suggestions or examples, the authors are left with a general direction but no clear path forward. Therefore, the comment is barely helpful, as it provides some insight but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the ablation study, specifically mentioning the need for further study on the impact of the pre-defined threshold \u03f5. While the comment identifies an area for improvement, it does not provide explicit guidance on how to conduct this additional study or what specific aspects should be explored. The action is implicit and somewhat vague, as the authors can infer that they need to conduct additional analysis but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the ablation study in the paper, specifically mentioning the need for further study on the impact of the pre-defined threshold \u03f5. This provides some grounding as it refers to a specific aspect of the paper, allowing the authors to identify the part being addressed. However, the comment lacks specificity because it does not detail what aspects of the impact of \u03f5 should be further studied or how this could be done. The authors are left with a general idea of what needs improvement but without clear guidance on how to address it. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the ablation study in the work is limited, specifically mentioning the need for further study on the impact of the pre-defined threshold \u03f5. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate why the ablation study is limited or how the impact of \u03f5 should be further studied. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the ablation study, specifically pointing out the need for further investigation into the impact of the pre-defined threshold \u03f5. This feedback is somewhat helpful as it highlights an area where the study could be improved, providing the authors with a direction for additional analysis. However, the comment lacks specificity and does not offer detailed guidance on how to conduct this additional study or what specific aspects should be explored. While it points out a potential weakness, it does not provide actionable steps for improvement, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the reliability of the evaluation using only Rouge-L, suggesting that it may not be sensitive enough for certain classification tasks. However, it does not provide explicit guidance on what alternative evaluation metrics should be used or how the authors might address this issue. The action is implicit, as the authors need to infer that they should consider additional evaluation metrics, but it lacks concrete details on how to implement this change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of Rouge-L for evaluation, suggesting that it may not be reliable, especially for classification tasks. However, it does not specify which part of the paper discusses the evaluation metrics or where the authors could consider alternative metrics. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in pointing out the potential unreliability of Rouge-L for certain tasks, but it does not provide detailed guidance on how to address this issue. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using only Rouge-L for evaluation makes the evaluation unreliable, particularly for classification tasks, where Rouge-L is not sensitive enough. However, the comment lacks specific examples or references to support this claim. It does not provide detailed reasoning or evidence to substantiate why Rouge-L is insufficient for classification tasks, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out a potential limitation in the evaluation methodology by noting that only Rouge-L is used, which may not be reliable, especially for classification tasks where Rouge-L is not sensitive enough. This feedback is somewhat helpful as it identifies a specific area for improvement in the evaluation process. However, it lacks detailed guidance or suggestions on how the authors might address this issue, such as recommending alternative evaluation metrics or providing examples of more sensitive metrics for classification tasks. To be more helpful, the comment could include specific recommendations or examples, which would empower the authors to make informed decisions about improving their evaluation methodology. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific issue with the definitions of variables not matching the formula in Equation 3, specifically mentioning the absence of \"n_k\" in the equation. This provides clear guidance on what needs to be addressed, which is to ensure that the definitions of variables align with the formulas used in the paper. The comment is explicit and concrete, as it directly points out the discrepancy and suggests a specific action for the authors to take. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 580-588,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the definitions of variables not matching the formula in Equation 3, particularly noting the absence of \"n_k\" in the equation. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the definitions of variables do not properly match the formula in Equation 3, specifically mentioning the absence of \"n_k\" in the equation. This is a factual observation that can be verified by checking the definitions and the equation. The comment provides a clear and specific claim that can be easily verified by the authors by examining the relevant sections of the paper. Therefore, the comment is categorized as fully verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the definitions of variables not matching the formula in Equation 3, particularly noting the absence of \"n_k\" in the equation. This feedback is clear and actionable, as it directs the authors to ensure that the definitions of variables align with the formulas used in the paper. By addressing this discrepancy, the authors can improve the accuracy and clarity of their work. However, the comment could be more helpful if it provided additional guidance on how to resolve the issue or suggested potential solutions. Overall, the comment is mostly helpful as it provides a clear direction for improvement but lacks depth in terms of detailed suggestions or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the sufficiency of a single vector for each class with large variances in the semantic space and whether this conflicts with the whole sample-specific assumption of the paper. It also mentions that some key experiments are missing. While the comment identifies potential issues and gaps in the paper, it does not provide explicit instructions or concrete suggestions on how to address these concerns. The authors are left to infer that they need to consider the implications of using a single vector for each class and that additional experiments are necessary. However, the lack of specific guidance on what experiments should be conducted or how to address the conflict makes the action vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the sufficiency of a single vector for each class with large variances in the semantic space and whether this conflicts with the whole sample-specific assumption of the paper. It also mentions that some key experiments are missing. However, the comment does not specify which part of the paper discusses the class-specific token or the experiments that are missing, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors can make an educated guess about the relevant parts, the comment lacks full grounding. The specificity is also limited because it does not provide detailed guidance on what experiments are missing or how to address the conflict. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the sufficiency of a single vector for each class with large variances in the semantic space and whether this conflicts with the whole sample-specific assumption of the paper. It also mentions that some key experiments are missing. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical question about the use of a single vector for each class with large variances in the semantic space, questioning whether this approach aligns with the whole sample-specific assumption of the paper. It also points out the absence of key experiments, which is a significant oversight. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or what experiments should be included. While it identifies important areas for consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight into potential weaknesses but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the work, specifically the assumption of a known number of intent classes during graph construction. It questions whether the IntenDD experiments reported in Table 1 are under this assumption and whether they are directly comparable to the cited baselines. The comment suggests that further clarification is needed on the intent discovery experiment setting to ensure a fair comparison with baselines. While the action is implicit, it is concrete in suggesting that the authors need to clarify the experiment setting to ensure a fair comparison. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"the intent discovery evaluation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of the assumption of known intent classes during graph construction and questions the comparability of the IntenDD experiments to the cited baselines. The comment suggests that further clarification is needed on the experiment setting to ensure a fair comparison. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the assumption of a known number of intent classes during graph construction is a limitation of the work. It questions whether the IntenDD experiments reported in Table 1 are under this assumption and whether they are directly comparable to the cited baselines. The comment acknowledges that the authors have identified this as a limitation but suggests that further clarification is needed on the experiment setting to ensure a fair comparison. While the comment highlights a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a key limitation in the work, specifically the assumption of a known number of intent classes during graph construction. It questions whether the IntenDD experiments reported in Table 1 are under this assumption and whether they are directly comparable to the cited baselines. The comment acknowledges that the authors have recognized this limitation but suggests that further clarification is needed on the experiment setting to ensure a fair comparison with baselines. This feedback is clear and actionable, as it directs the authors to provide additional details on the experiment setting to enhance the validity of their results. However, it could be more helpful if it offered specific suggestions on how to address this limitation or improve the comparability of the experiments. Overall, the comment is mostly helpful, as it provides valuable insights for improving the draft but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point appreciates the rigorous experimentation in the work but criticizes the limited significance of the results due to the application of d-separation criteria in a specific context. It also points out that the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which simplifies the problem. However, the comment does not provide explicit guidance or suggestions on how the authors might address these limitations or improve the significance of their results. The references provided are to external works, which may offer some context but do not directly instruct the authors on how to enhance their work. As a result, the comment is vague and lacks actionable advice, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment appreciates the rigorous experimentation in the work but criticizes the limited significance of the results due to the application of d-separation criteria in a specific context. It also points out that the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which simplifies the problem. However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The mention of specific references provides some context but does not fully ground the comment. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the significance of the results is limited due to the application of d-separation criteria in a specific context and the requirement of knowledge of corruption labels for experiments on corrupted CIFAR and ImageNet. The reviewer supports this claim by referencing two external works: \"Invariant risk minimization\" by Martin Arjovsky et al. and \"Last layer re-training is sufficient for robustness to spurious correlations\" by Polina Kirichenko et al. These references provide a basis for the claim, as they suggest that the application of d-separation criteria and the use of corruption labels are not novel or significant contributions. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced works to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a solid foundation for the claim but could benefit from more detailed explanation or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges the rigorous experimentation in the work but criticizes the limited significance of the results due to the application of d-separation criteria in a specific context. It also points out that the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which simplifies the problem. The inclusion of references to external works, such as \"Invariant risk minimization\" and \"Last layer re-training is sufficient for robustness to spurious correlations,\" provides some context and suggests that the work may not be as novel as claimed. However, the comment lacks specific guidance or suggestions on how the authors might address these limitations or enhance the significance of their results. While it identifies areas for improvement, the feedback is incomplete and does not provide actionable steps, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the alignment between the use of gradient-based saliency methods and the underlying feature selection mechanisms in the human brain. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for alternative methods, modifications, or further exploration to address this concern. As a result, the authors are left without any guidance on how to improve their draft in response to this comment. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the reliance on gradient-based saliency methods for evaluating the importance of feature map channels, suggesting that this may not align with the underlying feature selection mechanisms in the human brain. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in its critique of the method used, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the alignment between the use of gradient-based saliency methods and the underlying feature selection mechanisms in the human brain. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations that would help the authors understand the basis of the concern or how it could be addressed. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to evaluate or address the issue effectively.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the alignment between the use of gradient-based saliency methods and the underlying feature selection mechanisms in the human brain. This is a relevant observation that could impact the validity and applicability of the results. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or explore alternative methods. Without actionable feedback or detailed insights, the authors are left without a clear path for improvement. Therefore, the comment is barely helpful, as it identifies a potential issue but does not offer any actionable advice or depth of analysis.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the paper uses Pythia, which is not considered state-of-the-art (SOTA), despite having the advantage of available checkpoints. However, it does not provide any explicit or implicit suggestions for alternative models or actions for the authors to take. The comment lacks actionable guidance, such as recommending specific models or explaining how the authors might address the issue of using a non-SOTA model. Without any direction or concrete steps, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the model choice, specifically mentioning Pythia, which is not considered state-of-the-art (SOTA). However, it does not specify which part of the paper discusses the model choice, making it weakly grounded. The comment is specific in pointing out the issue with the model choice, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact area needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper uses Pythia, which is not considered state-of-the-art (SOTA), despite having the advantage of available checkpoints. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate why Pythia is not SOTA or how it compares to other models. Without this information, the authors may find it challenging to understand the basis of the claim or to address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment points out that the paper uses Pythia, which is not considered state-of-the-art (SOTA), despite having the advantage of available checkpoints. This feedback is somewhat helpful as it identifies a potential limitation in the model choice, prompting the authors to consider whether using a more current or advanced model could improve the paper's contributions. However, the comment lacks depth and does not provide specific suggestions or alternatives for the authors to consider. It does not offer actionable guidance on how to address the issue or improve the draft, limiting its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggests that more information or resources should be provided to challenge the community in solving the image observation version of the Franka Kitchen task. It questions whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning, and whether the task can be completed solely with the provided offline data. The comment also asks if there is an alternative data source that the community can leverage to address this challenge. While the comment implies that the authors should provide more information or resources, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these questions and provide additional resources. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the challenge of the image observation version of the Franka Kitchen task and suggests that more information or resources should be provided to challenge the community. It questions whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning, and whether the task can be completed solely with the provided offline data. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its questioning of the task's challenges but lacks grounding, as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the challenge of the image observation version of the Franka Kitchen task and suggests that more information or resources should be provided to challenge the community. It questions whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning, and whether the task can be completed solely with the provided offline data. However, the comment does not provide any specific evidence, examples, or references to support these claims, making it difficult for the authors to understand the basis of the questions. The lack of supporting information or references renders the claims unverifiable, as the authors are left without a clear path to address the concerns. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises important questions about the challenge of the image observation version of the Franka Kitchen task, specifically questioning whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning. It also asks if the task can be completed solely with the provided offline data and suggests considering alternative data sources. This feedback is valuable as it prompts the authors to clarify the limitations of their work and consider potential avenues for improvement. However, the comment could be more helpful if it provided specific suggestions or examples of alternative data sources or methods that could be explored. Overall, the comment is mostly helpful as it guides the authors toward a deeper analysis and potential enhancements of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point asks for insight into why the multilingual model is \"noticeably weaker\" on specific evaluations, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue or what specific information should be included to provide insight. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 236,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for insight into why the multilingual model is \"noticeably weaker\" on specific evaluations, providing clear guidance on what the authors need to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification, asking for insight into why the multilingual model is \"noticeably weaker\" on specific evaluations. It does not contain a claim or opinion that requires verification, as it is a factual question seeking additional information. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment requests clarification on why the multilingual model is \"noticeably weaker\" on specific evaluations, specifically ET\u2192En and LV\u2192EN. While it identifies a potential area of concern, it does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. The comment lacks actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of numbers in brackets in Tables 1 and 2. While it implies that the authors should clarify the meaning of these numbers, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide clarification but are not given specific guidance on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"tables #1,2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the meaning of the numbers in brackets (1) and (4) in these tables. This provides clear guidance on what the authors need to clarify or explain in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the meaning of numbers in brackets in Tables 1 and 2. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of numbers in brackets in Tables 1 and 2, indicating a potential area where the authors might need to clarify their work. While it identifies a specific aspect that could be clarified, it does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. The comment is somewhat helpful as it points out a potential area of confusion, but it lacks depth and actionable advice, making it incomplete for the authors to fully address the feedback. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the connection between the presented results on repeated distributionally robust optimization (RDRO) and the listed limitations of previous fairness notions. It questions how the results relate to long-term fairness, as claimed in the paper. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the clarity of the connection. The action is implicit and vague, leaving the authors to infer that they need to clarify the relationship between the results and the limitations, but without concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the connection between the presented results on repeated distributionally robust optimization (RDRO) and the listed limitations of previous fairness notions. It specifically questions how the results relate to long-term fairness, as claimed in the paper. This provides clear guidance on what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper discusses these limitations or the results, leaving the authors to infer that it relates to the sections discussing RDRO and fairness. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the connection between the presented results on repeated distributionally robust optimization (RDRO) and the listed limitations of previous fairness notions. It specifically asks how the results relate to long-term fairness, as claimed in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the connection is unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a valid concern about the connection between the presented results on repeated distributionally robust optimization (RDRO) and the listed limitations of previous fairness notions. It questions how the results relate to long-term fairness, as claimed in the paper. This feedback is somewhat helpful as it identifies a potential gap in the paper's explanation and prompts the authors to clarify the relationship between their results and the limitations discussed. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue. Overall, the feedback is clear but incomplete, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the accuracy of the results, specifically the 29 percent accuracy with table assembly tasks, and questions the normalization of the Euclidean distance error units in Table 1. It also questions the reasonableness of a 5 cm error with HDR-IL. While the comment identifies areas of concern, it does not provide explicit instructions or suggestions on how the authors should address these issues. The authors are left to infer that they need to clarify the normalization of the error units and potentially reevaluate the results. However, the lack of specific guidance makes the action vague, fitting the label of a borderline actionable comment.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the accuracy of the results, particularly the 29 percent accuracy with table assembly tasks, and questions the normalization of the Euclidean distance error units. Additionally, it raises a concern about the reasonableness of a 5 cm error with HDR-IL. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the accuracy of the results, specifically the 29 percent accuracy with table assembly tasks, and questions the normalization of the Euclidean distance error units in Table 1. It also questions the reasonableness of a 5 cm error with HDR-IL. While the comment highlights potential issues, it lacks specific evidence or references to support the claim that the accuracy is low or that the error units are unreasonably high. The comment provides some logical reasoning by questioning the normalization and the reasonableness of the error, but it does not fully substantiate the claims. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration or evidence to be fully verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the results presented in the paper, namely the low accuracy of 29 percent with table assembly tasks and the high Euclidean distance error units in Table 1. It questions whether these errors are normalized to per datapoint position errors, which could impact the interpretation of the results. Additionally, it raises a concern about the reasonableness of a 5 cm error with HDR-IL. While the comment highlights areas that need clarification or further explanation, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it points out potential weaknesses, but it lacks actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the article provides a fresh perspective but does not reach a conclusion, suggesting that existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the lack of a conclusion or how to improve the paper to better support its claims. Without actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a general observation about the paper not reaching a conclusion and suggests that existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the conclusion or the handling of combinatorial and uncombinatorial sentences need improvement. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the article does not reach a conclusion and suggests that existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, the comment lacks specific evidence or reasoning to support these claims. It does not provide examples or references to substantiate the assertion that the existing models are capable of handling these types of sentences, nor does it explain why the article does not reach a conclusion. Without such support, the claim remains unverifiable, as the authors would need to make significant efforts to understand and address the critique. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the article provides a fresh perspective but notes that it does not reach a conclusion. It further suggests that the article implies existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not guide the authors on how to address the lack of a conclusion or how to strengthen their claims about the capabilities of existing models. Without detailed guidance or constructive feedback, the comment is not particularly helpful for the authors in improving their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the theoretical results, suggesting they do not contribute significantly to the algorithm design. It implies that the algorithm's design is primarily based on a pre-defined labeler's strategy, which limits the contribution of the theoretical results. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the theoretical contributions. The action is implicit and vague, leaving the authors without clear direction on how to enhance their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the theoretical results, suggesting they do not contribute significantly to the algorithm design. It implies that the algorithm design is primarily based on a pre-defined labeler\\'s strategy, which limits the contribution of the theoretical results. However, the comment does not specify which part of the paper discusses the theoretical results or the algorithm design, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the theoretical results are lacking or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the theoretical results do not contribute significantly to the algorithm design, as the algorithm is primarily based on a pre-defined labeler\\'s strategy. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate why the theoretical results are not valuable or how they could be improved. Without such support, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the theoretical results, suggesting they do not contribute significantly to the algorithm design. It implies that the algorithm\\'s design is primarily based on a pre-defined labeler\\'s strategy, which limits the contribution of the theoretical results. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve the theoretical contributions. Without detailed guidance or examples, the authors are left without a clear path for improvement. Therefore, the comment is barely helpful, as it identifies a potential weakness but does not offer sufficient guidance for the authors to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two concerns: the lack of detailed explanation of how reverse chain proved to be effective in multi-API planning and the focus of the article on comparing multiple tools or methods in API calling and planning, which reduces the research contribution. However, the comment does not provide explicit or implicit actions for the authors to take. It lacks guidance on how to address these issues or improve the paper. Without specific suggestions or directions, the authors are left without a clear understanding of what changes are needed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises two concerns: the lack of detailed explanation of how reverse chain proved to be effective in multi-API planning and the focus of the article on comparing multiple tools or methods in API calling and planning, which reduces the research contribution. However, it does not specify which part of the paper these issues are addressed in, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in detailing the issues but lacks grounding, as it does not provide explicit references to sections or parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the article lacks a detailed explanation of how reverse chain proved to be effective in multi-API planning and that the focus on comparing multiple tools or methods in API calling and planning reduces the research contribution. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without specific examples or detailed justification, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper. First, it points out that the effectiveness of reverse chain in multi-API planning is not adequately explained, which could be a significant gap in the paper. Second, it critiques the focus of the article on comparing multiple tools or methods in API calling and planning, suggesting that this reduces the research contribution. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve the paper. Without actionable feedback or detailed recommendations, the authors are left with a general understanding of the problems but without a clear path forward for improvement. Therefore, the comment is somewhat helpful, as it highlights areas for improvement but does not provide comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly recommends rejecting the paper due to weaknesses in experimental rigor and the need for significant editing to address other issues. However, it does not provide specific guidance on how the authors might address these weaknesses or what changes would be necessary to improve the paper. The comment lacks concrete details on what aspects of the experimental rigor need improvement or how the editing process should be conducted. As a result, the authors are left without clear direction on how to proceed, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper the recommendation for rejection is based on. It mentions \"the weaknesses in the review above,\" but without referencing a specific section or issue, the authors cannot determine the exact areas needing attention. Additionally, the comment lacks specificity regarding what specific weaknesses in experimental rigor need to be addressed or how the editing process should be conducted. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a recommendation to reject the paper due to weaknesses in experimental rigor and the need for significant editing. However, it does not provide specific examples or detailed reasoning to support the claim that the weaknesses cannot be addressed. The comment lacks concrete evidence or references to substantiate the assertion that the issues are insurmountable, making it difficult for the authors to understand and address the concerns. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear recommendation to reject the paper due to significant weaknesses in experimental rigor and the need for substantial editing to address other issues. It acknowledges the challenges in addressing these weaknesses within the given time and content constraints. However, the comment lacks specific guidance or suggestions on how the authors might improve the experimental rigor or what aspects of the paper need more attention. While it highlights the major concerns, it does not offer actionable advice for improvement, making it somewhat helpful. The authors gain insight into the major issues but are left without detailed guidance on how to address them, limiting the comment\\'s usefulness.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue of unfair competition between the standalone Medusa and Medusa+ParallelSpec setups. It suggests that the draft model architecture change could be a significant factor in the speedup gain, rather than the parallel prediction of draft tokens. The reviewer recommends providing a baseline where the only alteration is the draft model architecture and suggests renaming the modified setting to avoid confusion. This feedback is explicit and provides concrete actions for the authors to take, such as creating a baseline and renaming the setting. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 266-267,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of unfair competition between the standalone Medusa and Medusa+ParallelSpec setups, and it suggests providing a baseline with only the draft model architecture change to clarify the contribution. Additionally, it recommends renaming the modified setting to avoid confusion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about unfair competition between the standalone Medusa and Medusa+ParallelSpec setups, questioning whether the speedup gain is due to the change in draft model architecture or the parallel prediction of draft tokens. The reviewer suggests providing a baseline with only the draft model architecture change to clarify the contribution. This claim is somewhat verifiable as it provides a logical reasoning for the need to separate the effects of the two changes. However, it lacks specific examples or references to support the claim fully, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue of unfair competition between the standalone Medusa and Medusa+ParallelSpec setups, highlighting a discrepancy in the draft model architecture between the two. It suggests that the speedup gain might be attributed to the change in draft model architecture rather than the parallel prediction of draft tokens. The reviewer provides a clear and actionable suggestion to address this issue by recommending the creation of a baseline with only the draft model architecture change. Additionally, the comment advises renaming the modified setting to avoid confusion regarding the draft model architecture. This feedback is detailed and offers specific guidance for improving the clarity and fairness of the comparison, making it highly helpful for the authors.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the focus on Masked Language Models (MLMs) and whether experiments with autoregressive Language Models (LMs) were unsuccessful. However, it does not provide any explicit or implicit actions for the authors to take. The authors are left without guidance on how to address this question or what steps to take to improve their draft. Without actionable advice or suggestions, the comment lacks utility for the authors, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the focus on Masked Language Models (MLMs) and whether experiments with autoregressive Language Models (LMs) were unsuccessful. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. Without explicit references or context, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the focus on MLMs are unclear or why experiments with autoregressive LMs might not have been successful. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification on the focus on Masked Language Models (MLMs) and whether experiments with autoregressive Language Models (LMs) were unsuccessful. It does not contain a claim or opinion that requires verification, as it is a request for information rather than a statement that needs justification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the focus on Masked Language Models (MLMs) and whether experiments with autoregressive Language Models (LMs) were unsuccessful. While it identifies a potential area of interest, it lacks depth and does not provide any specific suggestions or guidance on how the authors might address this question or improve their draft. The comment does not offer actionable feedback or insights that would help the authors enhance their work. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two separate questions. The first question, \"How is the map encoded?\", is a request for clarification and does not provide any explicit or implicit action for the authors to take. It lacks specificity and does not guide the authors on how to address the issue. The second part of the comment suggests that the authors should demonstrate the effectiveness of their method on the experiments proposed in YNet, which is an implicit action. However, it does not provide concrete guidance on how to implement this suggestion. Overall, the comment is vague and lacks actionable details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises two separate questions: \"How is the map encoded?\" and \"Second, the authors should have shown the effectiveness of their method on the experiments proposed in YNet.\" The first question is not grounded as it does not specify which part of the paper discusses the map encoding, leaving the authors uncertain about where to address this issue. The second question is also not grounded because it does not mention a specific section or experiment, making it difficult for the authors to identify the exact part of the paper being addressed. Both questions lack specificity as they do not provide detailed guidance on what needs to be addressed or how to improve the paper. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of two questions: \"How is the map encoded?\" and \"Second, the authors should have shown the effectiveness of their method on the experiments proposed in YNet.\" The first question is a request for clarification and does not contain a claim that requires verification. The second question suggests that the authors should demonstrate the effectiveness of their method on experiments proposed in YNet, but it does not provide any supporting evidence or reasoning for why this is necessary or how it would improve the paper. Without additional context or justification, the claim is not verifiable. Therefore, the comment is rated as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises two separate questions, one about the encoding of the map and another regarding the demonstration of the method\\'s effectiveness on experiments proposed in YNet. While the questions are clear and identify areas that need clarification or further explanation, they do not provide specific guidance or suggestions for improvement. The comment lacks actionable feedback or constructive advice, leaving the authors with a general understanding of what needs to be addressed but without a clear path forward. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point compares the proposed model to the MSA Transformer in terms of r2, suggesting that the proposed model is not significantly better. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the model or what specific aspects need to be addressed to enhance its performance. Without actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment compares the proposed model to the MSA Transformer in terms of r2, suggesting that the proposed model is not significantly better. However, it does not specify which part of the paper this comparison is based on, such as a specific section or table where the results are presented. Without explicit references to the paper, the authors may find it challenging to identify the exact part being addressed. Additionally, the comment lacks specificity regarding what aspects of the comparison are problematic or how the proposed model could be improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed model is not significantly better than the MSA Transformer in terms of r2. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a comparison between the proposed model and the MSA Transformer in terms of r2, suggesting that the proposed model is not significantly better. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects of the model need to be enhanced or how to address the comparison. This makes the comment barely helpful, as it identifies a potential issue but does not offer any actionable steps for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests more mathematical details to clarify the concept of \"an ensemble of independent measures on the full feature space\" and its relation to the scaling observed in Fig. 2. This provides a clear and direct action for the authors to take, which is to include more mathematical explanations to enhance the understanding of their hypothesis. The comment is explicit and concrete, as it specifies exactly what the authors need to add to their draft to improve its clarity. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Top of page 6,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for more mathematical details to clarify the concept of \"an ensemble of independent measures on the full feature space\" and its relation to the scaling observed in Fig. 2. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of a specific statement on page 6 regarding the interpretation of the behavior of wide DNNs. The reviewer expresses confusion about the concept of \"an ensemble of independent measures on the full feature space\" and its relation to the observed scaling. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim of confusion or to suggest how the authors might clarify the concept. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary justification or evidence to support the assertion of confusion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the explanation of \"an ensemble of independent measures on the full feature space\" and its relation to the observed scaling. It requests more mathematical details to clarify this concept, which is a clear and actionable suggestion for the authors. By providing this feedback, the reviewer helps the authors improve the clarity and comprehensibility of their work, making the comment mostly helpful. However, the comment could be more helpful if it offered specific suggestions on how to present the mathematical details or provided examples to illustrate the concept. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the authors have tried using BlenderBot 2.0 with incorporated knowledge and suggests that it would be interesting to see how dialogues can be improved using domain ontologies from the SGD dataset. While the comment implies that the authors should consider this approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to implement this suggestion. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about whether the authors have tried using BlenderBot 2.0 with incorporated knowledge and suggests exploring the use of domain ontologies from the SGD dataset to improve dialogues. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in suggesting a potential improvement but lacks grounding, as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking if the authors have tried using BlenderBot 2.0 with incorporated knowledge and suggests exploring the use of domain ontologies from the SGD dataset to improve dialogues. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information or clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an interesting question about whether the authors have explored using BlenderBot 2.0 with incorporated knowledge and suggests that it would be beneficial to see how dialogues can be improved using domain ontologies from the SGD dataset. This feedback is somewhat helpful as it points out a potential area for improvement and suggests a specific direction for further exploration. However, it lacks depth and does not provide detailed guidance on how to implement this suggestion or why it would be beneficial. While it offers some insight, it could be more helpful with additional context or specific suggestions for experimentation or analysis. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the number of samples rated by GPT-4 and whether they overlap with the samples used in the human evaluation. The reviewer assumes that the samples should overlap, as the paper calculates Krippendorff \\\\alpha. However, the comment does not explicitly instruct the authors to clarify or address this issue. While it implies that the authors should provide this information, the action is not directly stated, and the authors may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks explicit guidance on how to implement the suggested action.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific aspects of the paper being addressed, namely the number of samples rated by GPT-4 and whether they overlap with the samples used in the human evaluation. This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific because it clearly specifies what is missing or unclear, namely the overlap of samples and the calculation of Krippendorff \\\\alpha. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the paper regarding the number of samples rated by GPT-4 and whether they overlap with the samples used in the human evaluation. The reviewer assumes that the samples should overlap, as the paper calculates Krippendorff \\\\alpha. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this assumption. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of the paper, specifically the number of samples rated by GPT-4 and whether they overlap with the samples used in the human evaluation. The reviewer assumes that the samples should overlap, as the paper calculates Krippendorff \\\\alpha, which suggests a need for clarification. This feedback is somewhat helpful as it points out a potential gap in the paper that needs to be addressed. However, it lacks detailed guidance on how to clarify this information or what specific details should be included. To be more helpful, the comment could provide suggestions on how to present this information or what additional details are necessary. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the consistency and accuracy of the paper, specifically asking for clarification on the difference between arg-wise consistency and accuracy. It also provides an intuition that the label annotation agreement should be lower due to the low pred-wise consistency. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify the confusion. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed explanations or examples to clarify these concepts. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the consistency and accuracy of the paper, specifically asking for clarification on the difference between arg-wise consistency and accuracy. It also provides an intuition about the label annotation agreement. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The authors can make an educated guess that it relates to the methodology or results sections, but the comment lacks full grounding. Additionally, while the comment raises a specific question about the consistency and accuracy, it does not provide detailed guidance on how to address the issue. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the consistency and accuracy of the paper, specifically asking for clarification on the difference between arg-wise consistency and accuracy. It provides an intuition that the label annotation agreement should be lower due to the low pred-wise consistency. However, the comment lacks specific examples, references, or detailed reasoning to support the claim or question. Without additional context or evidence, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the consistency and accuracy of the paper, specifically asking for clarification on the difference between arg-wise consistency and accuracy. It also provides an intuition that the label annotation agreement should be lower due to the low pred-wise consistency. However, the comment does not offer any specific suggestions or guidance on how the authors might address this issue or clarify the confusion. While it identifies a potential area of confusion, it lacks actionable feedback or detailed advice, making it somewhat helpful. The authors are left to infer that they need to provide more detailed explanations or examples, but without explicit guidance, the comment does not fully support their improvement efforts. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two explicit actions for the authors to take. First, it suggests providing more details on the neural network parametrization of the reverse process, specifically regarding how position embeddings are being provided, to enhance reproducibility. Second, it requests that the authors provide the code for their implementation, which is considered essential for reproducibility. Both actions are clear and concrete, leaving no ambiguity for the authors on what steps to take to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing more details on the neural network parametrization of the reverse process, specifically regarding position embeddings, to enhance reproducibility. It also requests the code for their implementation. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where neural network details are discussed. The suggestion to provide more details on position embeddings and the request for code are specific, offering clear guidance on how to improve the paper. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that providing more details on the neural network parametrization of the reverse process, particularly regarding position embeddings, could enhance reproducibility. It also requests the code for their implementation. While the comment highlights important aspects for reproducibility, it lacks specific examples or references to support the claim that these details are crucial or how they would improve reproducibility. The request for code is a reasonable suggestion, but without further explanation or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two specific suggestions for improving the paper\\'s reproducibility. First, it recommends providing more details on the neural network parametrization of the reverse process, particularly regarding position embeddings. This is a clear and actionable suggestion that can help the authors enhance the transparency and reproducibility of their work. Second, it requests the code for their implementation, which is a crucial step in ensuring that others can replicate the results. While the comment could be more detailed in explaining why these aspects are important for reproducibility, it offers valuable guidance that is mostly helpful for the authors. Therefore, the comment aligns with a score of 4: Mostly Helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a repeated paragraph in the first paragraph of section 3.3, indicating that this is an issue that needs to be addressed. However, it does not provide guidance on how to resolve the issue, such as suggesting which paragraphs should be merged or how to rephrase the content to avoid duplication. The action is explicit but lacks concrete details on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the first paragraph of section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of a repeated paragraph, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first paragraph of section 3.3 contains a repeated paragraph. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the first paragraph of section 3.3 contains a repeated paragraph. This feedback is clear and actionable, as it directs the authors to a particular section where they need to make revisions to ensure original content. However, the comment lacks further guidance or suggestions on how to address the repetition or what specific changes should be made. While it highlights a critical area for improvement, the lack of detailed advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the reusability and sustainability of synthetic data generated on-the-fly, which saves storage costs and improves relevance. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what specific aspects of reusability and sustainability need to be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the reusability and sustainability of synthetic data generated on-the-fly, which is a relevant concern in the context of data generation. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not provide details on what aspects of reusability and sustainability are being questioned. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the reusability and sustainability of synthetic data generated on-the-fly, which is a valid concern in the context of data generation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or justification, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the reusability and sustainability of synthetic data generated on-the-fly, which is a critical aspect of data generation methods. However, it does not provide any specific suggestions or guidance on how the authors might address this concern or improve the sustainability of their approach. While the comment identifies an important area for consideration, it lacks actionable feedback or detailed advice, leaving the authors without a clear path for improvement. Therefore, the comment is barely helpful, as it highlights an issue but does not offer sufficient guidance for the authors to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two areas for improvement: the authors should examine the likelihood of alternative RNA structures arising due to biological circumstances and consider RNA abundance when building datasets. While the comment identifies these as important considerations, it does not provide explicit instructions or concrete steps on how to address these issues. The authors can infer that they need to incorporate these factors into their analysis, but the lack of detailed guidance makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the introduction of the ProbTransfomer model and its application to solving the challenge of RNA folding. It suggests that the authors should consider the likelihood of alternative RNA structures arising due to biological circumstances and the importance of RNA abundance when building datasets. However, the comment does not specify which part of the paper discusses the ProbTransfomer model or where these considerations should be integrated. While the authors can infer that it relates to the methodology or results sections, the lack of explicit references makes it weakly grounded. The comment is specific in suggesting additional considerations, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the likelihood of alternative RNA structures arising is mostly dictated by biological circumstances, which the authors do not examine. It also suggests considering RNA abundance when building datasets. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The absence of concrete evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies two areas for improvement in the paper. First, it points out that the authors do not examine the likelihood of alternative RNA structures arising due to biological circumstances, which is a critical aspect of RNA folding. Second, it suggests that the authors should consider RNA abundance when building datasets. While the comment highlights important considerations, it lacks specific guidance or suggestions on how the authors might address these issues. Without detailed advice or examples, the authors may find it challenging to implement these suggestions effectively. Therefore, the comment is somewhat helpful, as it provides some direction but lacks depth and actionable steps.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the use of a single entropic regularization coefficient (\\eta=1200) in the numerical results, suggesting that it might be a weak regularization term leading to sparse couplings, which could be favorable to the method. The reviewer acknowledges that this might not be an issue in the strong-regularization regime but emphasizes the need for the authors to acknowledge this in the paper. While the comment identifies a potential issue, it does not provide explicit instructions on how the authors should address it, such as suggesting alternative regularization coefficients or discussing the implications of this choice. The action is implicit and somewhat vague, as the authors need to infer that they should acknowledge this aspect in the paper. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the numerical results\" and \"the entropic regularization coefficient (\\eta=1200),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concern about the use of a single entropic regularization coefficient and its potential impact on the results, suggesting that this needs to be acknowledged in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the use of a single entropic regularization coefficient (\\eta=1200) in the numerical results, suggesting that it might be a weak regularization term leading to sparse couplings, which could be favorable to the method. The reviewer acknowledges that this might not be an issue in the strong-regularization regime but emphasizes the need for the authors to acknowledge this in the paper. The comment provides a logical reasoning for the concern, but it lacks specific examples or references to support the claim. While the reasoning is clear, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the numerical results, specifically the use of a single entropic regularization coefficient (\\eta=1200), which might lead to sparse couplings and favor the method being evaluated. The reviewer acknowledges that this might not be a problem in the strong-regularization regime but emphasizes the need for the authors to acknowledge this in the paper. This feedback is somewhat helpful as it points out a specific area for consideration and suggests that the authors should address this issue in their paper. However, it could be more helpful if it provided additional guidance on how to address this concern or suggested alternative approaches to consider. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the information presented in Table 1 and the text of the paper regarding the Vlachos and Riedel 2014 dataset. It points out that the table indicates the dataset has no evidence, whereas the paper mentions that sources were collected, including tables with statistics and reports. However, the comment does not provide explicit guidance on how the authors should address this discrepancy or suggest a way to reconcile the information. The action is implicit and vague, as the authors are left to infer that they need to clarify or correct the information in Table 1, but without specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the discrepancy between the information presented in the table and the text of the paper regarding the Vlachos and Riedel 2014 dataset. The comment clearly specifies what needs to be addressed, which is the inconsistency in the information provided. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between the information presented in Table 1 and the text of the paper regarding the Vlachos and Riedel 2014 dataset. It points out that the table indicates the dataset has no evidence, whereas the paper mentions collecting sources used by journalists, including tables with statistics and reports. This observation is factual and does not contain subjective claims or opinions that require verification. It is a request for clarification or correction, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the information presented in Table 1 and the text of the paper regarding the Vlachos and Riedel 2014 dataset. It points out that the table indicates the dataset has no evidence, whereas the paper mentions collecting sources used by journalists, including tables with statistics and reports. This feedback is clear and actionable, as it highlights a specific inconsistency that needs to be addressed. By pointing out this discrepancy, the comment provides the authors with a clear direction for improvement, helping them to ensure the accuracy and consistency of their data presentation. Therefore, the comment is mostly helpful, as it effectively guides the authors in refining their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include details about the parameters for each simulator used in the study. It specifies which parameters should be included, such as the use of the GPU or CPU pipeline, substeps for physics simulation, and the total number of vertices in the simulation. This provides clear and concrete guidance on what needs to be added to the draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to include details about the parameters for each simulator, such as the use of the GPU or CPU pipeline, substeps for physics simulation, and the total number of vertices in the simulation. This allows the authors to accurately identify the part of the paper that needs revision. The comment is also specific because it clearly specifies what details should be included, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that different simulators have varying parameters that can significantly impact performance, and it requests specific details about these parameters. However, the comment does not provide any evidence, examples, or references to support the claim that these parameters are crucial or how they might affect performance. Without additional context or justification, the authors may find it challenging to understand the importance of including these details. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific area for improvement in the paper. It points out the importance of including details about the parameters used in different simulators, which could significantly affect the overall performance. By suggesting the inclusion of specific details such as the use of the GPU or CPU pipeline, substeps for physics simulation, and the total number of vertices in the simulation, the comment provides clear and actionable feedback. However, it could be more helpful if it explained why these details are crucial or how they might impact the results. Overall, the comment effectively guides the authors to enhance the transparency and comprehensiveness of their work, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the importance of the hyperparameters $s$ and $k$ in the proposed sparse-CL and k-NL methods, emphasizing that their choice is crucial for the effectiveness of the method. However, it criticizes the empirical selection of these hyperparameters as $5$ based on cross-validation, noting that this reduces the generalizability of the proposed loss function. The comment suggests that the authors should provide more detailed justification or exploration of the hyperparameters to improve the generalizability of their method. While the action is implicit, as it does not explicitly instruct the authors to change their approach, it is concrete in suggesting a way to enhance the generalizability of the loss function. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Supplementary Material A.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the empirical selection of hyperparameters $s$ and $k$ and how this affects the generalizability of the proposed loss function. The comment provides a clear critique of the method's reliance on empirical selection, which is a specific area for improvement. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the empirical selection of hyperparameters $s$ and $k$ as $5$ based on cross-validation reduces the generalizability of the proposed loss function. The comment provides a logical reasoning by explaining that the choice of these hyperparameters is crucial for the effectiveness of the method. However, it lacks specific examples or references to support the claim about the impact on generalizability. While the reasoning is clear, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the empirical selection of hyperparameters $s$ and $k$ as $5$ based on cross-validation, which it claims reduces the generalizability of the proposed loss function. This feedback is valuable as it highlights a potential weakness in the methodology and suggests that the authors should provide more detailed justification or exploration of the hyperparameters. However, the comment could be more helpful if it offered specific suggestions on how to improve the selection process or provide additional evidence to support the claim. Overall, the comment is mostly helpful as it directs the authors to a significant area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare the optimization times of their approach with OpenTuner, which can adaptively use different search techniques. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to conduct the comparison or what specific aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"OpenTuner,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests comparing optimization times with OpenTuner, which can adaptively use different search techniques, and specifically mentions the use of simulated annealing. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a comparison of optimization times between the authors\\' approach and OpenTuner, which can adaptively use different search techniques. However, the comment does not provide any specific reasoning, examples, or references to support why this comparison is necessary or how it would improve the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a comparison of optimization times between the authors\\' approach and OpenTuner, which can adaptively use different search techniques. This feedback is clear and actionable, as it provides a specific area for improvement that could enhance the paper\\'s contribution and relevance. By suggesting a comparison, the reviewer offers a concrete way for the authors to strengthen their work and demonstrate its effectiveness. However, the comment could be more helpful if it included additional guidance on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the novelty of the work, stating that there are many existing works that have introduced diffusion models into anomaly detection. It highlights that the work may be the first to introduce NCSN, a branch of diffusion models, but notes that this is not an original idea. The comment also points out that the work makes only minor adjustments to NCSN by combining popular techniques like time step embedding and finding a correspondence relationship between the anomaly score and the score in the diffusion model. While the comment identifies areas where the work may lack originality, it does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the novelty of their work. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to proceed. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the work, specifically mentioning that there are many existing works that have introduced diffusion models into anomaly detection. It references specific examples ([1], [2], [3]) and notes that the work may be the first to introduce NCSN, a branch of diffusion models, but emphasizes that this is not an original idea. The comment also points out that the work makes only minor adjustments to NCSN by combining popular techniques like time step embedding and finding a correspondence relationship between the anomaly score and the score in the diffusion model. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the introduction or discussion of the novelty of the work. The comment is specific in detailing what is lacking in terms of originality and the minor adjustments made. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work lacks novelty, citing the existence of many works that have introduced diffusion models into anomaly detection. It references specific examples ([1], [2], [3]) to support this claim, providing a basis for the assertion. However, the comment could be strengthened by providing more detailed comparisons or specific examples of how the work builds upon or differs from these existing works. This would enhance the verifiability of the claim. As it stands, the comment is mostly verifiable, as it provides some evidence but could benefit from more detailed analysis or references. Therefore, it is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment critiques the novelty of the work, pointing out that there are many existing works that have introduced diffusion models into anomaly detection. It references specific examples ([1], [2], [3]) and notes that the work may be the first to introduce NCSN, a branch of diffusion models, but emphasizes that this is not an original idea. The comment also highlights that the work makes only minor adjustments to NCSN by combining popular techniques like time step embedding and finding a correspondence relationship between the anomaly score and the score in the diffusion model. While the comment identifies a lack of originality, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is somewhat helpful as it points out a weakness but lacks depth and actionable advice, making it somewhat helpful but not fully comprehensive. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two specific issues: grammar errors in the text and the lack of axis labels in Figure 2. While the comment explicitly identifies these issues, it does not provide guidance on how to address the grammar errors or how to label the axes in Figure 2. The actions are explicit but lack concrete details on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as grammar errors in the text and the lack of axis labels in Figure 2. This allows the authors to accurately identify the sections that need attention. The comment is also specific because it points out the exact errors in the text and the missing labels in Figure 2, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements about grammar errors and the lack of axis labels in Figure 2. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies two specific issues: grammar errors in the text and the lack of axis labels in Figure 2. While it highlights these problems, it does not provide suggestions or guidance on how to address them, such as offering examples of corrected grammar or advice on how to label the axes effectively. This lack of actionable feedback limits the comment\\'s usefulness, as it does not empower the authors to make meaningful improvements. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the error analysis in Section 5.2 is inadequate and suggests that a more quantitative error analysis would be beneficial. However, it does not provide specific guidance on how to conduct this quantitative analysis or what aspects of the error analysis should be improved. The action is explicit but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the error analysis, stating that it is \"crappy\" and suggests that a more quantitative error analysis would be helpful. This provides clear guidance on what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the error analysis in Section 5.2 is inadequate and suggests that a more quantitative error analysis would be beneficial. However, the comment does not provide any specific examples, reasoning, or references to support why the current analysis is considered \"crappy\" or how a more quantitative approach would improve it. This lack of detailed justification makes the claim difficult for the authors to address effectively, rendering it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the error analysis in Section 5.2, labeling it as \"crappy\" and suggesting that a more quantitative error analysis would be beneficial. While the comment highlights a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to enhance the error analysis or what specific aspects should be quantified. This limits the usefulness of the feedback, as the authors are left without clear direction on how to address the issue. Therefore, the comment is somewhat helpful, as it points out a weakness but does not offer actionable advice for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should not rely solely on t-SNE to evaluate distribution alignment and recommends measuring the Proxy-A distance between the distributions. It also points out a potential error in Figure 6c and 6d, suggesting a need to cross-check the Proxy-A distance. While the comment provides a clear action to take, it lacks specific guidance on how to implement the measurement of Proxy-A distance or how to address the issue with the figures. The action is explicit but somewhat vague in its execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 6c, 6d,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting the use of Proxy-A distance to evaluate distribution alignment and pointing out a potential error in the figures. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that relying solely on t-SNE to evaluate distribution alignment is not sufficient and recommends measuring the Proxy-A distance between the distributions. It also points out a potential error in Figure 6c and 6d, suggesting a need to cross-check the Proxy-A distance. The suggestion to use Proxy-A distance is a logical recommendation based on common practices in evaluating distribution alignment, and the reference to [6] provides some basis for the claim. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the evaluation of distribution alignment by recommending the use of Proxy-A distance in addition to t-SNE. This is a clear and actionable piece of feedback that could enhance the robustness of the analysis. Additionally, the comment points out a potential error in Figure 6c and 6d, suggesting a need to cross-check the Proxy-A distance. This feedback is helpful as it identifies a specific area for improvement and provides a concrete suggestion for addressing it. However, the comment could be more helpful if it offered further guidance on how to implement the suggested changes or provided more detailed reasoning for the recommendation. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the rationale behind using cross entropy for the first phrases and the performance when using a reinforcement algorithm for all phrases. While it does not explicitly instruct the authors to make changes, it implies that the authors should provide a justification or explanation for their choice of method. The action is implicit, as the authors need to infer that they should address these questions in their response. However, the comment is somewhat actionable because it provides a clear direction for the authors to follow, even if it does not specify exactly how to address the questions. Therefore, this comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 216-217, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for a rationale behind the use of cross entropy for the first phrases and inquires about the performance when using a reinforcement algorithm for all phrases. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the rationale behind using cross entropy for the first phrases and the performance when using a reinforcement algorithm for all phrases. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises specific questions about the rationale behind using cross entropy for the first phrases and the performance when using a reinforcement algorithm for all phrases. By asking for clarification on these points, the comment encourages the authors to provide a more detailed explanation of their methodology, which can help improve the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it offered suggestions or guidance on how to address these questions or provided examples of similar approaches in the literature. Overall, the comment is somewhat helpful as it prompts the authors to address important methodological aspects, but it could be more actionable with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed cross-modality adaptation has been validated in specific works (BEVDepth and 2DPASS) but notes that these references are not discussed in the related work section of the paper. While the comment implies that the authors should include these references in the related work section, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer the need to add these references but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the omission of references to BEVDepth and 2DPASS, which have validated the proposed cross-modality adaptation. This provides clear guidance on what needs to be addressed in the related work section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed cross-modality adaptation has been validated in BEVDepth and 2DPASS, but the paper does not discuss these references in the related work section. The claim is supported by the mention of specific references (BEVDepth [1] and 2DPASS [2]), which provides a clear basis for the assertion. However, the comment could be strengthened by explaining why these references are relevant or how they relate to the proposed adaptation. Overall, the claim is mostly verifiable, as it provides some evidence but could benefit from additional context or explanation. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment points out an omission in the related work section, specifically noting that the paper does not discuss the validation of the proposed cross-modality adaptation in BEVDepth and 2DPASS. This feedback is clear and actionable, as it directs the authors to include these references in the related work section to provide a more comprehensive overview of the existing literature. By addressing this gap, the authors can enhance the credibility and thoroughness of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate these references effectively. Overall, the comment is mostly helpful, as it identifies a specific area for improvement and offers a clear direction for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that Table 1 lacks generation results such as BLEU scores, which are necessary to assess the quality of output. This provides a clear and direct action for the authors to take: they should include generation results like BLEU scores in Table 1. The comment is explicit and concrete, as it specifies exactly what needs to be added to the table. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by pointing out the lack of generation results such as BLEU scores in the table, which are necessary to assess the quality of output. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 1 only presents test loss as a metric for performance degradation, without including generation results like BLEU scores to assess the quality of output. This claim is somewhat verifiable as it highlights a specific omission in the table, which is a factual observation. However, the comment does not provide detailed reasoning or examples of how including BLEU scores would enhance the assessment of output quality. While the authors can infer the importance of including such metrics, the comment could be strengthened by providing more context or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Table 1, noting that it only includes test loss as a metric for performance degradation without providing any generation results such as BLEU scores. This feedback is clear and actionable, as it highlights a critical omission that could impact the assessment of the model\\'s output quality. By suggesting the inclusion of generation results like BLEU scores, the comment provides a concrete step for the authors to enhance the comprehensiveness and usefulness of their results. However, the comment could be more helpful if it offered additional context or suggestions on how to interpret or present these results. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement that can significantly enhance the quality of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include experiments to validate their analysis, particularly for discussions on different regimes. This is an explicit action that the authors can take to improve their draft. However, the comment does not provide specific guidance on what kind of experiments should be conducted or how they should be structured. While the action is clear, the lack of detailed instructions on implementation makes the comment somewhat actionable. The authors know they need to include experiments but may not be entirely sure of the specifics of how to do so. Therefore, this comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that including experiments to validate the analysis, particularly for discussions on different regimes, would be beneficial. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or discussions. This makes it difficult for the authors to pinpoint the exact areas that need attention. The comment is specific in suggesting the inclusion of experiments but lacks grounding, as it does not clearly identify the sections or parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including experiments to validate the analysis, particularly for discussions on different regimes, would be beneficial. However, the comment does not provide any specific reasoning, examples, or references to support why experiments are necessary or how they would enhance the analysis. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that including experiments to validate the analysis, particularly for discussions on different regimes, would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft. By incorporating experiments, the authors can strengthen the validity of their analysis and provide more comprehensive insights into the different regimes discussed. However, the comment could be more helpful if it offered guidance on what types of experiments or specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement, but it could be more detailed to fully support the authors\\' efforts.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests including two naive baselines with only text and a single center frame to provide interesting insights about the benchmark. This is an explicit action with clear guidance on what the authors should do to improve their draft. The comment provides a specific suggestion, making it concrete and actionable. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including two naive baselines with only text and a single center frame to provide insights about the benchmark. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results section. Without explicit references or context, the authors may find it challenging to determine where to incorporate this suggestion. The comment is specific in its request for additional baselines but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including two naive baselines with only text and a single center frame to provide insights about the benchmark. However, it does not provide any reasoning or evidence to support why these baselines would be beneficial or how they would offer interesting insights. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including two naive baselines with only text and a single center frame to provide insights about the benchmark. This is a clear and actionable suggestion that could enhance the comprehensiveness and depth of the paper by offering a baseline for comparison. However, the comment could be more helpful if it provided specific guidance on how these baselines should be implemented or what insights they might offer. Despite this, the suggestion is valuable and provides a direction for improvement, making the comment mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the description of advantage-weighted regression in the preliminaries, noting that the Q function is with respect to \u03bc, which is crucial for solving the constrained optimization of Eq. 4. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to clarify the description. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the description of the Q function and its relation to \u03bc, but they are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"clarity of preliminaries\" and \"advantage-weighted regression,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the description of the Q function is missing a key piece, which is the relation to \u03bc. This provides clear guidance on what needs to be addressed in the preliminaries section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of advantage-weighted regression lacks a key piece, specifically the relationship between the Q function and \u03bc. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the preliminaries, specifically regarding the description of advantage-weighted regression. It points out that the Q function is with respect to \u03bc, which is crucial for solving the constrained optimization of Eq. 4. This feedback is clear and actionable, as it directs the authors to clarify this critical aspect of their work. However, the comment could be more helpful if it provided additional guidance on how to present this information or suggested specific changes to improve clarity. Overall, the comment is mostly helpful as it highlights a key area for improvement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that while each part of the proposed method is effective, the overall algorithm is cumbersome due to its multiple stages. It contrasts this with existing pruning methods that do not require fine-tuning. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or simplify their algorithm. The action is implicit and vague, as the authors are left to infer that they should simplify their method but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the overall algorithm of the proposed method, noting that it is cumbersome due to multiple stages, unlike existing pruning methods that do not require fine-tuning. However, it does not specify which part of the paper discusses the proposed method or the stages that make it cumbersome. This lack of explicit reference to specific sections or elements of the paper makes it weakly grounded. The comment is specific in its critique of the algorithm\\'s complexity and comparison with existing methods, but without clear grounding, the authors may struggle to identify the exact parts needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is cumbersome due to its multiple stages, contrasting it with existing pruning methods that do not require fine-tuning. However, the comment lacks specific examples or references to existing methods that do not need fine-tuning, making it difficult for the authors to understand the basis of the comparison. The claim is somewhat verifiable as it provides a general critique but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the proposed method, noting that while each part of the algorithm is effective, the overall algorithm is cumbersome due to its multiple stages. It contrasts this with existing pruning methods that do not require fine-tuning, suggesting that the proposed method could be improved by simplifying its structure. However, the comment lacks specific suggestions or guidance on how to achieve this simplification, such as recommending the removal of certain stages or suggesting alternative approaches. While it highlights an area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the justification for the new quantile function (3) compared to the existing function (2), specifically regarding the change from multiplicative to additive terms for the up and down tail parameters. The comment highlights that the paper does not provide supporting data on why this reduced sensitivity is desired. While the comment identifies a potential issue, it does not explicitly instruct the authors to provide such data or suggest how to address the concern. The action is implicit and somewhat vague, as the authors can infer that they need to provide supporting data but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the new quantile function (3) and the existing function (2), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the change from multiplicative to additive terms for the up and down tail parameters and questioning the justification for this change. The comment further highlights the lack of supporting data on why the reduced sensitivity is desired. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the advantage of the new quantile function (3) compared to the existing function (2) is unjustified. It provides a logical explanation by pointing out the change from multiplicative to additive terms for the up and down tail parameters, which reduces sensitivity to large tail parameters. However, the comment lacks specific examples or references to support why this reduced sensitivity is desired or beneficial. While the reasoning is clear, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the justification for the new quantile function (3) compared to the existing function (2). It points out that the change from multiplicative to additive terms for the up and down tail parameters may reduce sensitivity to large tail parameters, but the paper lacks supporting data on why this reduced sensitivity is desired. This feedback is somewhat helpful as it highlights a specific area where the authors need to provide more justification or evidence to support their claims. However, it could be more helpful if it offered suggestions on how to address this issue or provided examples of how to present the supporting data. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take, specifically asking them to improve Figure 3 and address the low contribution over SWE-Bench. It also provides detailed reasoning and examples to support the claim that the contribution is low, including the implicit testing of fault localization capabilities in repair benchmarks and the ability to use scripts to pass unit tests to an LLM. This feedback is clear and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, specifically the confusion it causes and the low contribution over SWE-Bench. The comment further provides reasoning and examples to support the claim, such as the implicit testing of fault localization capabilities in repair benchmarks and the use of scripts to pass unit tests to an LLM. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 3 is confusing and that the contribution over SWE-Bench is low. It provides specific reasoning and examples to support these claims, such as the implicit testing of fault localization capabilities in repair benchmarks and the ability to use scripts to pass unit tests to an LLM. This detailed explanation provides a clear and logical basis for the critique, making the claim mostly verifiable. However, the comment could be strengthened by referencing specific studies or benchmarks that support the claim about the low contribution over SWE-Bench. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying issues with Figure 3 and the contribution of the paper over SWE-Bench. It explains that the contribution is low because the benchmark already implicitly tests fault localization capabilities, and that using an LLM for issue generation is not a new contribution. The comment offers detailed reasoning and examples to support these claims, which can help the authors clarify and improve their work. By addressing these points, the authors can enhance the clarity and originality of their paper. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missing description in the paper, specifically regarding the selection of topics for the complementary attribute when conducting topic control experiments. It asks for clarification on how to select the topics to constitute the complementary attribute. While the comment identifies a gap in the description, it does not provide explicit guidance on how to address this issue or what specific information should be included. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed descriptions but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding missing descriptions in the paper, particularly in the context of topic control experiments. It mentions that there are five topics and asks for clarification on how to select topics to constitute the complementary attribute. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, which is the description of how to select topics for the complementary attribute. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about missing descriptions in the paper, specifically regarding the selection of topics for the complementary attribute in topic control experiments. However, it does not provide any supporting evidence, reasoning, or references to justify why these descriptions are missing or how they impact the paper. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, namely the lack of descriptions regarding the selection of topics for the complementary attribute in topic control experiments. It raises a question about how to select topics to constitute the complementary attribute, which is a critical aspect of the methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific information should be included in the descriptions. While it highlights an important area for clarification, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a weakness but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the limited scope of real-world manipulation, noting that it only includes a single case. The reviewer questions the general applicability of the described system identification method for sim-to-real policy deployment. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue or improve the paper. Without actionable suggestions or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of real-world manipulation, specifically noting that it only contains a single case. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique, as it questions the general applicability of the described system identification method for sim-to-real policy deployment. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the real-world manipulation only contains a single case, which is not convincing for generalizing the described system identification method to sim-to-real policy deployment. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically noting that the real-world manipulation section only includes a single case. It questions the general applicability of the described system identification method for sim-to-real policy deployment, suggesting that the current evidence may not be convincing. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the paper. While it highlights a potential weakness, it does not provide actionable feedback or detailed advice for improvement. Therefore, the comment is somewhat helpful, as it points out a concern but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses skepticism about the quality of ShortcutQA, questioning whether the manual verification of edits ensures that they do not introduce ambiguity, which could lead to performance degradation. The reviewer requests specific details about the \"answerable\" nature of distracted texts, asking for examples and qualitative results. While the comment implies that the authors should provide more information to address these concerns, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide additional details but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ShortcutQA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the quality of ShortcutQA, questioning whether the manual verification of edits ensures that they do not introduce ambiguity, which could lead to performance degradation. The comment further requests specific details about the \"answerable\" nature of distracted texts, asking for examples and qualitative results. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses skepticism about the quality of ShortcutQA, questioning whether the manual verification of edits ensures that they do not introduce ambiguity, which could lead to performance degradation. The reviewer requests specific details about the \"answerable\" nature of distracted texts, asking for examples and qualitative results. While the comment raises a valid concern, it lacks specific evidence or references to support the claim. The request for examples and qualitative results is a reasonable step towards verification, but without additional context or data, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the quality of ShortcutQA, questioning whether the manual verification of edits ensures that they do not introduce ambiguity, which could lead to performance degradation. It requests specific details about the \"answerable\" nature of distracted texts, asking for examples and qualitative results. This feedback is clear and actionable, as it prompts the authors to provide additional information that could help address the reviewer\\'s skepticism. By asking for examples and qualitative results, the comment offers a concrete way for the authors to enhance the transparency and robustness of their work. Therefore, the comment is mostly helpful, as it provides valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the text would be clearer with a forward pointer to the definition of \"deep.\" This is an explicit suggestion that provides a clear action for the authors to take, which is to include a forward pointer to the definition. The comment is specific and concrete, as it directly instructs the authors on how to improve the clarity of their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the text would be clearer with a forward pointer to the definition of \"deep.\" However, it does not specify which part of the paper this suggestion applies to, such as a particular section or paragraph. This makes it difficult for the authors to identify the exact location that needs improvement. While the comment is specific in its suggestion, it lacks grounding because it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the text would be clearer with a forward pointer to the definition of \"deep.\" However, it does not provide any reasoning or evidence to support why this would improve clarity or how it would benefit the reader. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the text would be clearer with a forward pointer to the definition of \"deep.\" This is a specific and actionable piece of feedback that can help the authors improve the clarity and readability of their draft. By providing a clear suggestion for enhancement, the comment offers valuable guidance for the authors to enhance the comprehensibility of their work. However, the comment could be more helpful if it explained why a forward pointer is necessary or how it would improve the text. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether there is a way to perform model selection to identify an appropriate number of archetypes (k) in the presented framework. While it implies that the authors should consider model selection, it does not provide explicit guidance on how to implement this or what specific methods to use. The action is implicit and somewhat vague, as the authors need to infer that they should explore model selection techniques but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the number of archetypes (k) and whether there is a way to perform model selection to identify an appropriate k in the presented framework. However, it does not specify which part of the paper this question pertains to, such as a specific section or methodology. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for model selection, but without clear grounding, it is challenging for the authors to know where to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification on whether there is a method for model selection to identify an appropriate number of archetypes (k) in the presented framework. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a relevant question about the practical interest in the number of archetypes (k) and whether there is a way to perform model selection to identify an appropriate k in the presented framework. This is a thoughtful and timely inquiry that could help the authors improve their work by considering how to select the optimal number of archetypes. However, the comment lacks specific suggestions or guidance on how to approach this issue, such as recommending particular model selection methods or techniques. While it highlights an important area for consideration, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include Theorem 1, which is missing from the paper. It also suggests keeping separate counts for assumptions, lemmas, and theorems. This feedback is clear and provides specific actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1\" and \"page 6,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of Theorem 1 and suggesting a way to keep separate counts for assumptions, lemmas, and theorems. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the absence of Theorem 1 and the presence of Theorem 2 on page 6. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and descriptive, seeking information that is already present in the paper. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, pointing out the absence of Theorem 1 and the presence of Theorem 2 on page 6. It also suggests keeping separate counts for assumptions, lemmas, and theorems, which is a practical suggestion for improving the organization and clarity of the paper. This feedback is specific and provides the authors with a clear direction for improvement, making it highly helpful. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the assumption made in the paper regarding the existence of a subsequence within a longer text that is necessary and sufficient for performing a target task. It questions whether this assumption generalizes to tasks like long document summarization. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the concern or whether the assumption should be tested or modified. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the assumption made in the paper regarding the existence of a subsequence within a longer text that is necessary and sufficient for performing a target task. It questions whether this assumption generalizes to tasks like long document summarization. However, the comment does not specify which part of the paper this assumption is discussed in, making it difficult for the authors to identify the exact section that needs attention. Additionally, while the comment highlights a potential issue with the assumption, it does not provide specific guidance on how to address it. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the assumption that a subsequence within a longer text is necessary and sufficient for performing a target task. It questions whether this assumption generalizes to tasks like long document summarization. The comment provides a logical reasoning by questioning the applicability of the assumption to a different task, which is a valid point. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider this critique and potentially provide evidence or counterarguments to substantiate their assumption. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the assumption made in the paper regarding the existence of a subsequence within a longer text that is necessary and sufficient for performing a target task. It questions the generalizability of this assumption to tasks like long document summarization, which is a valid point for consideration. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or explore the applicability of their assumption to different tasks. While it highlights an important area for further exploration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it prompts the authors to consider a critical aspect of their work but does not fully support them in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the novelty and clarity of the proposed method, specifically questioning how multiple different graphs can be obtained and whether learning different weights for edges would result in too many parameters. While the comment highlights areas of confusion, it does not provide explicit guidance or suggestions on how the authors might address these issues. The feedback is implicit and somewhat vague, as it does not offer concrete steps for improvement. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 180,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of obtaining multiple different graphs and the potential impact of learning different weights for edges. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method seems straightforward and that its novelty is marginal. It also raises specific questions about the clarity of certain aspects, such as how multiple different graphs are obtained and whether learning different weights for edges would result in too many parameters. However, the comment lacks detailed reasoning or evidence to support these claims, making it difficult for the authors to understand the basis of the reviewer\\'s concerns. The lack of specific examples or references to similar work in the field makes the claim somewhat verifiable, as it requires more detailed justification to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises concerns about the novelty and clarity of the proposed method, specifically questioning the straightforwardness of the approach and the marginal novelty. It also points out a specific area of confusion, such as the explanation of how multiple different graphs are obtained and the potential issue of learning different weights for edges. This feedback is somewhat helpful as it identifies areas where the authors need to clarify their methodology and provide more detailed explanations. However, the comment could be more helpful if it offered suggestions or guidance on how to address these issues, such as recommending additional examples or experiments to support the claims. Overall, the comment provides some direction for improvement but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the scope of the experiments, noting that they are restricted to a unit sphere, spiral curves, and time of travel by taxis. It suggests that it would be beneficial to include an example of learning geometry on a more complicated manifold. While the comment implies that the authors should expand their experimental scope, it does not provide specific guidance on how to achieve this or which manifolds to consider. The action is implicit and somewhat vague, as the authors can infer the need for more diverse experiments but may not know exactly how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific experiments being addressed, including the use of a unit sphere, spiral curves, and time of travel by taxis. It also specifies the issue with the experiments, noting that a unit sphere is a special case and suggesting the need for an example of learning geometry on a more complicated manifold. This provides clear guidance on what the authors should address in their work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are limited in scope, specifically mentioning the use of a unit sphere and spiral curves, and suggests that it would be beneficial to include an example of learning geometry on a more complicated manifold. The comment provides a logical reasoning by explaining that a unit sphere is a special case where geometry can be learned easily, implying that more complex manifolds would provide a more challenging and interesting example. However, the comment lacks specific examples or references to support the claim about the limitations of the current experiments. Therefore, the claim is somewhat verifiable, as it provides a logical basis but requires further elaboration or evidence to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the experiments, noting that they are restricted to a unit sphere, spiral curves, and time of travel by taxis. It suggests that including an example of learning geometry on a more complicated manifold would be beneficial. This feedback is somewhat helpful as it points out a specific area for expansion and improvement in the experimental scope. However, it lacks detailed guidance on how to select or design such a more complex manifold or what specific aspects of geometry learning should be explored. While it provides a clear direction for enhancement, the comment could be more helpful with additional suggestions or examples. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a weakness in the current knowledge reliance on a specific template that lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the naturalness of the template or how to better utilize the LLM. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to a point made by the authors regarding the current knowledge reliance on a specific template, which lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). However, it does not specify which part of the paper this point is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the current knowledge reliance on the template, but it lacks detailed guidance on how to address this weakness. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the current knowledge relies on a specific template that lacks naturalness and does not fully utilize the capabilities of the LLM, identifying this as an obvious weakness for the paper. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a weakness in the current knowledge reliance on a specific template that lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). This is a valid observation that could be relevant to the paper's methodology or results. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or detailed advice, the authors are left with a general understanding of the problem but no clear path for improvement. Therefore, the comment is somewhat helpful, as it highlights a potential area for improvement but lacks depth and specificity.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the number of baselines is small, which affects the universality and generality of the results. However, it does not provide any explicit or implicit suggestions on how to address this issue. The authors are left without guidance on whether to add more baselines, how to select them, or what specific aspects of the baselines are lacking. Without actionable advice or concrete steps, the authors are unable to effectively improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions the \"number of baselines,\" which suggests that it is addressing the section or part of the paper where the baselines are discussed. However, it does not specify which section this is, making it weakly grounded. The comment is specific in pointing out the issue with the number of baselines affecting the universality and generality of the results. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the number of baselines is small, which affects the universality and generality of the results. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential limitation in the paper, noting that the number of baselines is small, which could impact the universality and generality of the results. However, it does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional baselines or discussing potential implications. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of information about the tokenizer training, specifically mentioning the corpus size and software stack, which are known to be important in practice. However, it does not provide explicit guidance on what the authors should do to address this issue. The comment implies that the authors should include this information, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the lack of information about tokenizer training, specifically mentioning the mixture of corpus size and software stack, which are known to be important in practice. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where this information should be included. Without explicit references or context, the authors may find it challenging to identify the exact part of the paper that needs revision. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that there is no information about the tokenizer training, specifically mentioning the mixture of corpus size and software stack, which are known to be important in practice. The reviewer supports this claim by referencing external knowledge, indicating that these factors are known to matter in practice. However, the comment does not provide specific examples or detailed reasoning to fully substantiate the claim. Therefore, the claim is mostly verifiable, as it provides a logical basis but lacks detailed evidence or examples to fully support the assertion.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper regarding the lack of information about tokenizer training, including the mixture of corpus size and software stack. This is a relevant point that could impact the reproducibility and understanding of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what information should be included. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a weakness but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the additional complexity of the proposed method compared to a simple multi-view contrastive objective. It questions whether the additional complexity is warranted, suggesting that the authors should address this issue. However, the comment does not provide explicit guidance on how to address this concern or what specific aspects of the method should be evaluated. The action is implicit and somewhat vague, as the authors are left to infer that they need to justify the necessity of the co-training, positive mining, and alternate optimization steps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"positive mining framework\" and \"co-training, positive mining, and alternate optimization steps,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of whether the additional complexity of the proposed method is warranted, and it questions the necessity of the main contributions over prior work. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the additional complexity of the proposed method compared to a simple multi-view contrastive objective, questioning whether the added complexity is justified. The reviewer references a similar work, \"Audio-Visual Instance Discrimination with Cross-Modal Agreement,\" which provides some context for the claim. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to delve deeper into the paper to understand the basis of the critique and address it effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical point about the additional complexity of the proposed method compared to a simpler multi-view contrastive objective. It questions whether the added complexity is warranted, which is a valid concern that the authors should address. The comment also highlights the need for the authors to justify the necessity of the co-training, positive mining, and alternate optimization steps, which are the main contributions of the paper over prior work. This feedback is clear and actionable, as it prompts the authors to provide a clear justification for the added complexity and to demonstrate the value of their contributions. However, the comment could be more helpful if it provided specific suggestions on how to address these concerns. Overall, the comment is mostly helpful, as it directs the authors to a critical area that requires further explanation and justification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the computational cost of the multi-marginal OT and spline calculations, suggesting that it may limit the scalability of the approach for large datasets. It implies that a more comprehensive discussion is needed to address this concern. However, the comment does not provide explicit guidance on what aspects of the discussion should be included or how to address the scalability issue. The action is implicit and somewhat vague, as the authors can infer that they need to discuss computational complexity but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of computational cost, specifically mentioning \"multi-marginal OT and spline calculations.\" However, it does not specify which part of the paper discusses these calculations, making it weakly grounded. The comment is specific in suggesting that a more comprehensive discussion is required to address the scalability issue for large datasets. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the computational complexity of multi-marginal OT and spline calculations may limit the scalability of the approach for large datasets, which could be problematic for real-world applications. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of concrete evidence or detailed justification makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the approach related to computational cost, specifically mentioning the scalability issues with multi-marginal OT and spline calculations for large datasets. It suggests that a more comprehensive discussion is required to address this concern, which is a valuable insight for the authors. However, the comment lacks specific guidance on how to enhance the discussion or what aspects should be included, leaving the authors with a general direction but not a detailed roadmap for improvement. Therefore, the comment is somewhat helpful, as it points out an important area for improvement but could be more actionable with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point challenges the authors\\' claim that non-uniform label noise is not common in practice, citing evidence from a real-world dataset, Clothing1M, and a specific paper by Kun Yi and Jianxin Wu. While the comment provides a reference to support the claim, it does not explicitly instruct the authors to address this issue or suggest how to incorporate the evidence into their draft. The action is implicit, as the authors need to infer that they should reconsider their claim and potentially discuss the existence of non-uniform label noise in their work. However, the comment lacks concrete guidance on how to integrate this information or respond to the critique. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the authors\\' claim about non-uniform label noise not being common in practice and references a specific dataset, Clothing1M, and a paper by Kun Yi and Jianxin Wu. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the issue by referencing a real-world dataset and a relevant study, providing clear evidence to support the claim. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that non-uniform label noise is more common in practice than the authors suggest, citing the example of the Clothing1M dataset and a specific paper by Kun Yi and Jianxin Wu. The reference to a real-world dataset and a published study provides robust evidence to support the claim, making it fully verifiable. The inclusion of specific references and examples enhances the clarity and persuasiveness of the argument, allowing the authors to understand and address the critique effectively. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment challenges the authors\\' claim that non-uniform label noise is not common in practice. It provides evidence from a real-world dataset, Clothing1M, and a specific paper by Kun Yi and Jianxin Wu, which supports the existence of non-uniform label noise. This feedback is helpful as it prompts the authors to reconsider their claim and potentially discuss the prevalence of non-uniform label noise in their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or integrate the evidence into the paper. Overall, the comment is mostly helpful, as it provides valuable information that can guide the authors in improving their draft, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the limited sample size used in the evaluation in Section 6.2, suggesting that it may have led to biased findings. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches to improve the evaluation. The comment implies that the authors should consider increasing the sample size or discussing the limitations of the current sample size, but it does not offer concrete steps or suggestions. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 6.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the potential issue of a limited sample size (only 10 samples) and suggests that this might have resulted in biased findings due to the small scale of the experiment. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation in Section 6.2 is based on only 10 samples, which may lead to biased findings due to the small sample size. This claim is somewhat verifiable as it provides a logical reasoning about the potential impact of a small sample size on the results. However, the comment lacks specific examples or references to support the claim, such as comparisons with larger sample sizes or discussions of similar studies. Providing more detailed evidence or references would strengthen the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the limited sample size used in the evaluation in Section 6.2, suggesting that it may have resulted in biased findings. This is a clear and actionable feedback that highlights a critical aspect of the methodology that could impact the validity of the results. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending a larger sample size or discussing the implications of the current sample size. Despite this, the comment still offers valuable insight into a potential weakness in the paper, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of the method, noting that it is tailored to similar MILP tasks and may not be generalizable to significantly different combinatorial optimization problems. The comment acknowledges that the paper addresses this issue but does not provide experimental evidence to support the claim. While the comment identifies a potential area for improvement, it does not offer specific guidance on how the authors might address this issue or provide concrete suggestions for experimentation. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct experiments to demonstrate the method\\'s generalizability. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the generalizability of the method to different combinatorial optimization problems, acknowledging that the paper acknowledges this limitation but does not address it experimentally. However, it does not specify which part of the paper discusses this limitation or where the authors should provide experimental evidence to support the claim. The authors can infer that it relates to the experimental section, but the comment lacks full grounding as it does not explicitly mention the section. It is specific in identifying the issue of generalizability and the need for experimental evidence, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is tailored to similar MILP tasks, potentially limiting its generalizability to different combinatorial optimization problems. The comment acknowledges that the paper addresses this issue but does not provide experimental evidence to support the claim. While the comment highlights a potential limitation, it lacks specific examples or references to substantiate the claim, making it somewhat verifiable. The authors would need to infer the need for additional experimental evidence to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the method, noting that it is tailored to similar MILP tasks and may not be generalizable to significantly different combinatorial optimization problems. The comment acknowledges that the paper addresses this issue but does not provide experimental evidence to support the claim. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this limitation or conduct experiments to demonstrate the method\\'s generalizability. This makes the feedback somewhat helpful, as it points out a weakness but does not provide actionable steps for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity in the description of the baseline in the Results section, specifically mentioning the \"Rerank and Adv\" baselines. The reviewer expresses difficulty in understanding how these baselines work, their relation to InterFair, and whether they are sufficiently competitive. While the comment identifies a specific area needing clarification, it does not provide explicit guidance on how the authors should address these issues. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations of the baselines and their relationship to InterFair. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Results section, L256-261\" and refers to specific baselines (\"Rerank and Adv\"), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the description of the baselines, noting the difficulty in understanding how they work, their relation to InterFair, and whether they are sufficiently competitive. This provides clear guidance on what needs to be addressed to improve the clarity and comprehensiveness of the paper. Therefore, this comment is labeled as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have difficulty understanding the baselines described in the Results section, specifically \"Rerank and Adv.\" The reviewer expresses confusion about how these baselines work, their relation to InterFair, and whether they are sufficiently competitive. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the description of the baselines in the Results section, noting that the authors attempt to explain the \"Rerank and Adv\" baselines but that the explanation is unclear. The reviewer expresses difficulty in understanding how these baselines work, their relation to InterFair, and whether they are sufficiently competitive. This feedback is clear and actionable, as it highlights a critical area where the authors need to provide more detailed explanations to improve the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it offered suggestions on how to enhance the explanation or provide additional context. Overall, the comment is mostly helpful, as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of sufficient comparison to other baselines on cycle counting and ZINC. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete details on what specific comparisons should be made or how the authors might improve the current comparison. As a result, the authors are left without a clear understanding of what actions to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the comparison to other baselines on cycle counting and ZINC. However, it does not specify which part of the paper this comparison is presented in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the comparison are insufficient or how it could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the comparison to other baselines on cycle counting and ZINC is insufficient. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the comparison to other baselines on cycle counting and ZINC, indicating that it is insufficient. However, it does not provide any guidance or suggestions on how the authors might improve this aspect of their work. Without actionable feedback or specific recommendations, the authors are left without a clear understanding of how to address the issue. Therefore, the comment is not helpful at all, as it lacks the necessary depth and guidance to assist the authors in improving their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper would benefit from a clear explanation of why a specific combination of mask snippets is effective, while most similar ones are not. This is an explicit action that the authors need to take, as it provides a direct suggestion for improvement. However, the comment does not specify how to provide this explanation or what specific details should be included. While the action is explicit, the lack of concrete guidance on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from a clearer explanation of why a specific combination of mask snippets is effective, while most similar ones are not. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in its request for an explanation of the effectiveness of the specific combination of mask snippets, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a clearer explanation of why a specific combination of mask snippets is effective, while most similar ones are not. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, suggesting that the authors provide a clear explanation for why a particular combination of mask snippets is effective while most similar ones are not. This feedback is actionable and provides a clear direction for the authors to enhance their draft by addressing the lack of clarity in their explanation. However, the comment could be more helpful if it offered specific suggestions or examples on how to present this explanation. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point compares the performance of SLQ with previous methods, specifically CRD, and notes that SLQ appears to have limited competitiveness. It provides specific observations from Figures 3 and 4, indicating that SLQ performs worse than CRD in Figure 3 and shows only a small improvement over ACL in Figure 4. However, the comment does not provide explicit guidance or suggestions on how the authors might address these performance issues or improve the competitiveness of SLQ. The feedback highlights a problem but lacks actionable steps for the authors to take, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of limited competitiveness of SLQ compared to previous methods, such as CRD, and provides specific observations from the figures regarding performance. This level of detail helps the authors understand what needs to be addressed in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of SLQ, as quantified by F1 score and conductance values, appears to have limited competitiveness compared to previous CRD methods. It supports this claim by referencing specific figures, Figure 3 and Figure 4, which show worse performance of SLQ compared to CRD and a small improvement over ACL, respectively. This provides a clear and logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed analysis or references to specific studies or benchmarks for comparison. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific observations about the performance of SLQ compared to previous methods, such as CRD. It highlights that SLQ appears to have limited competitiveness, as evidenced by Figures 3 and 4, which show worse performance than CRD and only a small improvement over ACL. This feedback is clear and actionable, as it directs the authors\\' attention to areas where their method may need improvement. However, the comment could be more helpful if it offered suggestions on how to address these performance issues or provided additional context for understanding the implications of these findings. Overall, the comment is mostly helpful, as it effectively identifies a critical area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly encourages the authors to add more baselines to their selection, specifically suggesting the inclusion of more robust models beyond the current naive/old models. This provides a clear and direct action for the authors to take, ensuring that their performance comparisons are more comprehensive. The comment is explicit and concrete, offering a specific suggestion on how to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the selection of baselines in the paper, suggesting that it is limited to naive or old models. It encourages the authors to add more baselines for robust performance comparisons. However, the comment does not specify which part of the paper discusses the baselines or where the authors should add these new baselines. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific in its suggestion, it lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the selection of baselines is limited to naive or old models, suggesting that more robust models should be included for performance comparisons. However, the comment does not provide specific examples of these robust models or explain why the current selection is inadequate. This lack of detailed justification or references makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient evidence or examples to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s selection of baselines, noting that it is limited to naive or old models. It provides a clear and actionable suggestion for improvement by encouraging the authors to add more robust baselines for performance comparisons. This feedback is valuable as it highlights an area where the paper could be strengthened and offers a specific direction for enhancement. However, the comment could be more helpful if it provided examples of additional baselines that could be considered or explained why the current selection is insufficient. Overall, the comment is mostly helpful as it offers a clear path for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the choice of target structure in Table 2, questioning the authors\\' decision to evaluate only one target structure. It suggests that the authors should either justify this choice or provide additional experiments to demonstrate the method\\'s adaptability to various target structures. This feedback is explicit and provides a clear direction for the authors to either provide a justification or conduct additional experiments. The action is concrete, as it specifies what the authors need to do to address the concern. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"the choice of target structure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of target structure and suggests that the authors should either justify this choice or provide additional experiments to demonstrate the method\\'s adaptability to various target structures. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the choice of target structure in Table 2, questioning the authors\\' decision to evaluate only one target structure. The reviewer suggests that this choice limits the generalizability of the proposed method and recommends either justifying this choice or providing additional experiments to demonstrate adaptability to various target structures. While the comment highlights a potential issue, it does not provide specific examples or references to support the claim that the method is limited to a specific configuration. The reasoning is logical but lacks detailed evidence or examples, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding the choice of target structure in Table 2, questioning the authors\\' decision to evaluate only one target structure. It raises a valid point about the potential limitation of the proposed method to a specific configuration and suggests that the authors should either justify this choice or provide additional experiments to demonstrate the method\\'s adaptability to various target structures. This feedback is clear and actionable, as it provides a specific area for improvement and suggests a way to address it. By following this advice, the authors can enhance the comprehensiveness and generalizability of their work. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the research scope, noting that it primarily focuses on the knapsack problem and neglects more realistic scenarios like medical diagnosis. The reviewer suggests that exploring applications in critical areas like healthcare could increase the paper\\'s impact and relevance. While the comment identifies a potential area for expansion, it does not provide specific guidance on how to incorporate these additional applications or what aspects of healthcare should be explored. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to address this issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limited application scope of the research, specifically mentioning the focus on the knapsack problem and the neglect of more realistic scenarios like medical diagnosis. However, it does not specify which part of the paper discusses the knapsack problem or where the authors could explore applications in healthcare. This makes it weakly grounded, as the authors cannot confidently determine the exact sections being referred to. The comment is specific in suggesting that exploring applications in healthcare could increase the paper\\'s impact and relevance. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the research has a limited application scope, focusing primarily on the knapsack problem and neglecting more realistic scenarios like medical diagnosis. The reviewer suggests that exploring applications in critical areas like healthcare could increase the paper\\'s impact and relevance. While the comment highlights a potential limitation, it lacks specific examples or references to support the claim that medical diagnosis is a more realistic scenario or that healthcare applications would significantly enhance the paper\\'s impact. This makes the claim somewhat verifiable, as it provides a general direction for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the research scope, noting that the paper primarily focuses on the knapsack problem and neglects more realistic scenarios, such as medical diagnosis. It suggests that exploring applications in critical areas like healthcare could significantly increase the paper's impact and relevance. This feedback is clear and actionable, as it provides a specific direction for the authors to consider expanding their research scope. However, it could be more helpful if it offered suggestions on how to integrate these additional applications or provided examples of potential healthcare scenarios. Overall, the comment is mostly helpful as it guides the authors toward a meaningful expansion of their work, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the robustness and sensitivity of the method, suggesting that it does not improve as claimed. It also provides specific observations from Figure 3, noting that the new method is noisier in two domains and equally noisy as competitors in the rest. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve the robustness and sensitivity of their method. The feedback is implicit and lacks concrete details on what actions the authors should take to enhance their work. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the method\\'s robustness and sensitivity, noting that the new method is noisier in two domains and equally noisy as competitors in the rest. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method does not improve robustness and sensitivity as claimed, and it provides specific observations from Figure 3 to support this claim. The mention of \"noisier in 2 domains and equally noisy as the competitors in the rest\" offers a clear basis for the critique. However, the comment could be strengthened by providing more detailed analysis or references to support the claim. Overall, the claim is mostly verifiable, as it provides some evidence but could benefit from additional details or references to fully substantiate the critique. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely that the method does not seem to improve on robustness and sensitivity as claimed. It provides a detailed observation from Figure 3, noting that the new method is noisier in two domains and equally noisy as competitors in the rest. This feedback is clear and actionable, as it points out a potential weakness in the paper and suggests that the authors should address this issue. However, the comment could be more helpful if it offered suggestions on how to improve the robustness and sensitivity of the method. Overall, the comment is mostly helpful, as it provides valuable insights but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the robustness of the conclusion against more sophisticated or aggressive removal methods. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific steps to consider in their analysis. As a result, the authors are left without a clear understanding of what changes or additions are needed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the robustness of the conclusion against more sophisticated or aggressive removal methods. However, it does not specify which part of the paper this question pertains to, such as a specific section or analysis. Without explicit references or context, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the conclusion are being questioned or how the authors might address this concern. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification on the robustness of the conclusion against more sophisticated or aggressive removal methods. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the robustness of the conclusion, specifically asking whether it holds against more sophisticated or aggressive removal methods. This is a relevant concern that could impact the validity and applicability of the findings. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or what specific methods or analyses could be used to test the robustness of their conclusion. While it identifies a potential weakness, it lacks actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the introduction of explainable AI and the actual focus on interpretable methods. It points out the lack of explanation for the definition of interpretability and the difference between explainable AI and interpretable methods. Additionally, it notes the absence of relevant work in this area. While the comment identifies areas that need clarification and expansion, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the definitions and differences between explainable AI and interpretable methods, as well as include relevant work. However, the comment lacks concrete guidance on how to implement these changes, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the introduction of the paper, where explainable AI is mentioned, but the focus is on interpretable methods. It points out the lack of explanation for the definition of interpretability and the difference between explainable AI and interpretable methods. However, it does not specify which part of the introduction or the paper this issue is most relevant to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as explaining the definitions and differences between the concepts. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper introduces explainable AI in the introduction but focuses on interpretable methods, and it criticizes the lack of explanation for the definition of interpretability and the difference between these two concepts. The comment also notes the absence of relevant work in this line. While the claim highlights a potential confusion in the paper, it lacks specific examples or references to support the assertion about the lack of explanation or the absence of relevant work. This makes the claim somewhat verifiable, as it provides a general critique but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the paper's focus on interpretable methods while introducing explainable AI in the introduction. It points out the lack of explanation for the definition of interpretability and the difference between explainable AI and interpretable methods. Additionally, it notes the absence of relevant work in this area. This feedback is valuable as it highlights a significant conceptual gap in the paper and suggests areas where the authors need to clarify their focus and provide more context. However, the comment could be more helpful if it offered specific suggestions on how to address these issues, such as recommending references or providing examples of how to differentiate between the two concepts. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the training data for the probes in the compositionality and transitivity experiments. While it does not explicitly instruct the authors to provide this information, it implies that the authors should clarify or address this aspect in their response. The action is implicit, as the authors need to infer that they should provide more details about the training data. However, the comment is concrete in its request for clarification, providing a clear direction for the authors to follow. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a question about the training data for the probes in the compositionality and transitivity experiments. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental sections where these probes are discussed. The comment is specific in asking for clarification on the training data, which is a clear and actionable request. However, because the comment does not explicitly mention a specific section or part of the paper, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the training data for probes in specific experiments. It does not contain any claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the training data for the probes in the compositionality and transitivity experiments. While it does not provide detailed guidance or suggestions for improvement, it does identify a potential area of concern that the authors should address. By asking for clarification on the training data, the comment prompts the authors to provide more information, which could enhance the clarity and transparency of their work. However, the comment lacks depth and does not offer actionable advice on how to address the issue. Therefore, it is somewhat helpful, as it provides a direction for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific issue with the paper, namely the lack of clarity regarding the concept of \"not only the complete captions but also parts thereof\" and the argument around why filling in the blanks is hard. It also suggests that there are ways to do bi-directional beam search for fill-in-the-blanks applications, referencing a source \"[C]\" that is not specified. This provides a clear and concrete action for the authors to address the issue by clarifying the concept and exploring alternative methods. The reference to \"[C]\" offers a specific direction for further research or exploration. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 133-134, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the lack of clarity regarding the concept of \"not only the complete captions but also parts thereof\" and the argument around why filling in the blanks is hard. Additionally, the comment suggests that there are ways to do bi-directional beam search for fill-in-the-blanks applications, providing a specific direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the argument around filling in the blanks is unconvincing and suggests that there are ways to do bi-directional beam search for fill-in-the-blanks applications. However, the comment does not provide specific examples or detailed reasoning to support the claim that the argument is unconvincing. The reference to \"[C]\" is mentioned but not elaborated upon, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence or detailed explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the argument regarding filling in the blanks, particularly the concept of \"not only the complete captions but also parts thereof.\" It also points out that the argument around why filling in the blanks is hard is unconvincing. Additionally, the comment suggests that there are ways to do bi-directional beam search for fill-in-the-blanks applications, providing a potential direction for improvement. However, the comment could be more helpful if it offered specific examples or references to support the suggestion. Overall, the feedback is somewhat helpful as it highlights a critical area for improvement but lacks detailed guidance on how to address it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the use of the reverse KL for training flows, specifically mentioning the assumption of differentiability of the function $g$ and the mode-seeking nature of the reverse KL. It suggests that the authors should comment on the realism of this assumption and notes a recent line of work that addresses this limitation. While the comment implies that the authors should address these concerns, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to address the issues. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the flows\" and \"the reverse KL,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concerns about the assumption of differentiability of the function $g$ and the mode-seeking nature of the reverse KL, suggesting that these are limitations that need to be addressed. The comment further provides a reference to recent work that addresses this limitation, offering a direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the use of the reverse KL for training flows, specifically mentioning the assumption of differentiability of the function $g$ and the mode-seeking nature of the reverse KL. The reviewer suggests that this could be a limitation, particularly in rare event sampling, where covering all modes of a density is crucial. The comment references recent work that addresses this limitation, providing a basis for the claim. However, the comment could be strengthened by providing more detailed examples or references to support the claim about the mode-seeking nature of the reverse KL. Overall, the claim is mostly verifiable, as it provides a logical reasoning and some supporting evidence, but could benefit from more comprehensive justification. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a critical concern about the use of the reverse KL for training flows, specifically highlighting the assumption of differentiability of the function $g$ and the mode-seeking nature of the reverse KL. It suggests that this could be a limitation, particularly in rare event sampling, where covering all modes of a density is crucial. The comment also references recent work that addresses this limitation, providing a direction for the authors to explore. This feedback is clear and actionable, as it identifies a potential issue with the method and offers a specific area for improvement. However, it could be more helpful if it provided more detailed guidance on how to address the limitation or suggested specific alternatives. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft by addressing a critical methodological concern.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the annotations in the visual event detection stage of the ViStruct Suite, suggesting that they might contain noise due to the use of an off-the-shelf semantic role labeling system. The comment implies that a detailed analysis of the curated dataset is necessary to address this issue. However, it does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer the need for a detailed analysis but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the ViStruct Suite, specifically mentioning the potential noise in annotations obtained from an off-the-shelf semantic role labeling system in the visual event detection stage. It suggests that a detailed analysis of the curated dataset is needed. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the methodology or results sections where the ViStruct Suite is discussed. The comment is specific in detailing the issue with the annotations and the need for a detailed analysis, making it weakly grounded but specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the annotations in the visual event detection stage of the ViStruct Suite might contain noise due to the use of an off-the-shelf semantic role labeling system. The comment suggests that a detailed analysis of the curated dataset is needed to address this issue. However, the comment lacks specific examples or references to support the claim about the noise in the annotations or the need for a detailed analysis. This makes the claim somewhat verifiable, as it provides a general rationale but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the annotations in the visual event detection stage of the ViStruct Suite, suggesting that they might contain noise due to the use of an off-the-shelf semantic role labeling system. It implies that a detailed analysis of the curated dataset is necessary to address this concern. While the comment highlights a critical area for improvement, it lacks specific guidance or suggestions on how the authors might conduct this analysis or mitigate the noise in the annotations. Providing more detailed advice or examples would enhance the comment's helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the model implementation should be better justified, specifically questioning the stopping rule with n consecutive identical samples. It points out that this rule seems arbitrary and lacks discussion on its sensitivity to the parameter n. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific changes to the model implementation. The authors are left to infer that they need to provide a more detailed justification for the stopping rule and discuss its sensitivity to n. However, the lack of concrete instructions or examples makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Model implementation,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the stopping rule, particularly the use of \"n consecutive identical samples,\" and notes the lack of discussion on its sensitivity to \"n.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the model implementation should be better justified, specifically questioning the stopping rule with n consecutive identical samples. It suggests that this rule seems arbitrary and lacks discussion on its sensitivity to the parameter n. While the comment provides a logical critique, it does not offer specific examples or references to support the claim that the stopping rule is arbitrary or to substantiate the need for further discussion on sensitivity. This makes the claim somewhat verifiable, as it lacks detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the model implementation, namely the stopping rule with n consecutive identical samples. It questions the arbitrariness of this rule and suggests that the sensitivity to the parameter n is not discussed. This feedback is clear and actionable, as it directs the authors to provide a more detailed justification for the stopping rule and to explore its sensitivity to n. By addressing these points, the authors can enhance the robustness and clarity of their model implementation. However, the comment could be more helpful if it offered specific suggestions or examples on how to improve the justification or sensitivity analysis. Overall, the comment is mostly helpful, as it provides valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the lack of time complexity analysis or running time reports for the proposed algorithms, and the absence of a comparison with state-of-the-art algorithms in terms of search time. The reviewer suggests that it would be interesting to see whether the proposed method reduces search time compared to state-of-the-art algorithms as the number of nodes increases. While the comment implies that the authors should provide time complexity analysis and comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these analyses and comparisons. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"maximum common subgraph detection problem\" and the lack of time complexity analysis or running time reports for the proposed algorithms. It also references the \"heuristics node pair selection policy\" and the \"learn-to-search\" algorithm, allowing the authors to accurately identify the parts of the paper being addressed. The comment is specific in detailing what is missing, namely the time complexity analysis and comparisons with state-of-the-art algorithms. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should provide time complexity analysis or report the running time of the proposed method, as the maximum common subgraph detection problem is NP-hard. It also suggests comparing the proposed method with state-of-the-art algorithms in terms of search time. The comment provides a logical reasoning for the need for time complexity analysis and comparison, which is a common practice in computational complexity studies. However, it lacks specific examples or references to state-of-the-art algorithms, which would strengthen the claim. Therefore, the comment is mostly verifiable, as it provides a clear rationale but could be further supported with additional details or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies two key areas for improvement in the paper. First, it points out the lack of time complexity analysis or running time reports for the proposed algorithms, which is crucial given the NP-hard nature of the maximum common subgraph detection problem. Second, it suggests comparing the proposed method with state-of-the-art algorithms in terms of search time, particularly as the number of nodes increases. This feedback is clear and actionable, as it provides specific areas where the authors can enhance their work by including time complexity analysis and performance comparisons. However, the comment could be more helpful if it offered suggestions on how to conduct these analyses or comparisons. Overall, the comment is mostly helpful, as it directs the authors to important aspects that need attention to strengthen their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of quality control or manual evaluation on the quality of data collected through an automatic model-based approach. While it identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The comment lacks concrete suggestions or actions for the authors to take, such as recommending specific methods for quality control or evaluation. As a result, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of quality control or manual evaluation on the quality of data collected through an automatic model-based approach. However, it does not specify which part of the paper this issue pertains to, such as a particular section or methodology. Without explicit references or context, the authors may find it challenging to identify the exact area needing attention. The comment is specific in its critique of the data quality process but lacks grounding, making it weakly grounded and not specific. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that there is no quality control or manual evaluation on the quality of data collected through an automatic model-based approach. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. The lack of detailed reasoning or specific instances makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of quality control or manual evaluation on the quality of data collected through an automatic model-based approach. This is a critical concern that could impact the validity and reliability of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending methods for quality control or evaluation. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a significant issue but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests an interesting comparison between a confidence interval from a small dev set and the Frechet bound. It implies that the authors could explore this comparison to provide a bound on the performance of a classifier. However, the comment does not explicitly instruct the authors to conduct this comparison or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should explore this comparison and figure out how to execute it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment discusses the availability of labeled data for most tasks and mentions snorkel, which implies a specific context within the paper. However, it does not explicitly mention a particular section or part of the paper where this discussion is located, making it weakly grounded. The comment is specific in suggesting a comparison between a confidence interval from a small dev set and the Frechet bound, providing a clear direction for potential improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point discusses the availability of labeled data for most tasks and mentions snorkel, which relies on a small dev set to tune hyperparameters. It suggests comparing a confidence interval from a small dev set with the Frechet bound. While the comment provides some context and a suggestion for further analysis, it lacks specific examples or detailed reasoning to fully support the claim. The suggestion is somewhat verifiable as it provides a direction for exploration, but it requires more detailed justification or examples to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies an interesting aspect of the paper related to the availability of labeled data for most tasks and snorkel\\'s reliance on a small dev set for hyperparameter tuning. It suggests a potential comparison between a confidence interval from a small dev set and the Frechet bound, which could provide a bound on the performance of a classifier. This feedback is somewhat helpful as it offers a specific direction for further analysis or exploration, which could enhance the paper\\'s depth and relevance. However, the comment could be more helpful if it provided more detailed guidance on how to conduct this comparison or what specific insights it might yield. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed method, noting that it is only applicable to problems with low-dimensional input spaces. It provides a specific reason for this limitation, attributing it to the curse of dimensionality caused by the use of a finite set of points in the surrogate modeling of the shape constraint. However, the comment does not offer any suggestions or guidance on how the authors might address this limitation or improve the applicability of their method to higher-dimensional spaces. The feedback is explicit in identifying the issue but lacks concrete actions or suggestions for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the applicability of the proposed method to problems with low-dimensional input spaces and references the largest dimensionality in the experiments, which is 3. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue of the method\\'s applicability and provides a reason for this limitation, namely the curse of dimensionality caused by the use of a finite set of points in the surrogate modeling of the shape constraint. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is only applicable to problems with low-dimensional input spaces, citing the largest dimensionality in the experiments as 3. It provides a logical explanation for this limitation, attributing it to the curse of dimensionality caused by the use of a finite set of points in the surrogate modeling of the shape constraint. This reasoning is clear and provides a specific reason for the claim, making the comment mostly verifiable. However, the comment could be strengthened by referencing specific literature or examples that support the concept of the curse of dimensionality in this context. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the proposed method, noting that it is only applicable to problems with low-dimensional input spaces. It provides a specific reason for this limitation, attributing it to the curse of dimensionality caused by the use of a finite set of points in the surrogate modeling of the shape constraint. This feedback is valuable as it highlights a critical constraint of the method, allowing the authors to consider ways to address this limitation, such as exploring methods to handle higher-dimensional spaces or discussing the implications of this constraint. However, the comment could be more helpful if it offered suggestions or potential solutions to overcome this limitation. Overall, the comment is mostly helpful as it provides clear and actionable feedback on a key area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses skepticism about the claim that the presented method is significantly better than others, citing that the results are typically within their standard deviations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve their draft to better support their claims. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1 and Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the results, noting that they are usually within their standard deviations, which challenges the claim that the presented method is significantly better than others. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results presented in Table 1 and Table 2 are typically within their standard deviations, which challenges the claim that the presented method is significantly better than others. However, the comment does not provide any specific examples, data, or references to support this claim. Without detailed evidence or reasoning, the authors may find it difficult to understand the basis of the reviewer\\'s skepticism. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the results presented in Tables 1 and 2, noting that they are typically within their standard deviations. This suggests that the claim of the presented method being significantly better than others may not be substantiated by the data. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or improve their draft. It lacks actionable feedback, leaving the authors without a clear path to enhance their work. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the complexity of generating synthetic tabular data due to various factors, including the association of multiple entries in a table with the same entity. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address these complexities or suggestions for improving the generation of synthetic data. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the complexity of generating synthetic tabular data, mentioning two examples of factors that contribute to this challenge. However, it does not specify which part of the paper discusses this issue or provide guidance on how to address it. The authors can infer that the comment relates to the methodology or results sections, but without explicit grounding, it remains weakly grounded. The comment is specific in detailing the challenges of generating synthetic data, but it lacks specificity in terms of actionable advice or detailed guidance for improvement. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights the complexity of generating synthetic tabular data, citing two examples of factors that contribute to this challenge. However, it does not provide specific examples or detailed reasoning to support the claim, making it difficult for the authors to fully understand and address the issue. The comment lacks verifiable evidence or references, leaving the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights the complexity of generating synthetic tabular data, mentioning two specific examples of factors that contribute to this challenge. However, it does not provide any actionable advice or suggestions on how the authors might address these complexities or improve their approach. The comment identifies a relevant issue but lacks depth and guidance, leaving the authors without a clear path for improvement. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the paper\\'s focus on the AmbiQT benchmark, suggesting that an overemphasis on this specific benchmark without broader context or validation on other datasets could raise questions about its applicability and relevance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern. It lacks concrete actions or specific recommendations for improving the draft, leaving the authors uncertain about how to proceed. As a result, the comment is vague and does not offer actionable steps for the authors to take. Therefore, it is rated as a 2: Borderline Actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the creation of the AmbiQT benchmark and suggests that an overemphasis on this specific benchmark without broader context or validation on other datasets could lead to questions about its applicability and relevance. However, it does not specify which part of the paper discusses the AmbiQT benchmark, making it weakly grounded. The comment is specific in its critique, as it highlights the need for a broader context and validation on other datasets. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper\\'s focus on the AmbiQT benchmark might lead to questions about its applicability and relevance to other scenarios. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the concern. This lack of supporting information makes the claim difficult for the authors to address effectively, rendering it borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment highlights a potential issue with the paper's focus on the AmbiQT benchmark, suggesting that an overemphasis on this specific benchmark without broader context or validation on other datasets could raise questions about its applicability and relevance. This feedback is somewhat helpful as it points out a potential weakness in the paper's approach, encouraging the authors to consider a more comprehensive validation of their benchmark. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional datasets for validation or providing examples of broader contexts. While it identifies a relevant area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the lack of annotation training details and guidelines, which is important for professional translators who may struggle with non-standard tasks. It also mentions the absence of information about the tool used. While the comment identifies specific areas that need attention, it does not provide explicit instructions or suggestions on how to address these issues. The authors are left to infer that they should include these details, but the comment lacks concrete guidance on what specific information should be included or how to present it. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not provide detailed instructions on how to implement the changes.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of annotation training details and guidelines, which is an important aspect of the paper. However, it does not specify which part of the paper this issue pertains to, such as a specific section or methodology. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing what is missing, namely annotation training details and guidelines, as well as information about the tool used. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that no annotation training details and guidelines are shared, which is important for professional translators. However, it does not provide specific examples or references to support this claim, nor does it offer detailed reasoning on why these details are crucial. The lack of supporting evidence or examples makes it difficult for the authors to understand the significance of this issue or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of annotation training details and guidelines, which is crucial for professional translators who may struggle with non-standard tasks. It also mentions the absence of information about the tool used. This feedback is clear and actionable, as it highlights specific areas that need attention to improve the comprehensiveness and clarity of the paper. However, the comment could be more helpful if it provided suggestions on how to address these gaps or offered examples of what information should be included. Overall, the comment is mostly helpful as it directs the authors to important aspects that need improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions about Table 1: whether the EX/NORB values should be bold-faced and whether the difference between 0.59+/-0.12 and 0.58+/-0.11 is statistically significant. While the comment implies that the authors should address these questions, it does not provide explicit instructions or guidance on how to resolve them. The actions are implicit and somewhat vague, as the authors need to infer that they should investigate and potentially revise the formatting and statistical analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises two distinct questions: whether the EX/NORB values should be bold-faced and whether the difference between 0.59+/-0.12 and 0.58+/-0.11 is statistically significant. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two questions regarding Table 1: whether the EX/NORB values should be bold-faced and whether the difference between 0.59+/-0.12 and 0.58+/-0.11 is statistically significant. These are factual questions seeking clarification or verification, rather than subjective claims or opinions. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions about Table 1, questioning the formatting choice of bold-facing EX/NORB values and the statistical significance of the difference between 0.59+/-0.12 and 0.58+/-0.11. While the comment identifies potential issues, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address these concerns. The feedback is somewhat helpful as it points out areas for clarification, but it does not offer detailed advice on how to improve the draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the metric used for the video level supervision experiment, noting that it appears to be different from the tracklet-based metrics mentioned elsewhere in the paper. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or clarify the metric used. The comment lacks actionable details, leaving the authors uncertain about what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the metric used for the video level supervision experiment, noting that it seems to differ from the tracklet-based metrics mentioned elsewhere in the paper. However, it does not specify which part of the paper discusses the video level supervision experiment or where the tracklet-based metrics are mentioned, making it weakly grounded. The comment is specific in its request for clarification on the metric used, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the metric used for the video level supervision experiment, noting that it seems to differ from the tracklet-based metrics mentioned elsewhere in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the metric is not clearly described. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the metric used for the video level supervision experiment, noting that it seems to differ from the tracklet-based metrics mentioned elsewhere in the paper. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or clarify the metric used. The comment identifies a potential area of confusion but lacks actionable feedback, leaving the authors without a clear path for improvement. Therefore, the comment is barely helpful, as it highlights a potential issue but does not offer sufficient guidance for the authors to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about why \"person blocking\" affects the models, as shown in Fig.4. It provides a possible explanation, suggesting that the models might learn person-related features to classify the input image, which could be undesirable. The comment explicitly asks the authors to comment on this issue, providing a clear and direct action for the authors to take. The feedback is specific and actionable, as it guides the authors to address a particular concern and provide clarification on the impact of \"person blocking\" on the models. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about why \"person blocking\" affects the models and provides a possible explanation, asking the authors to comment on this issue. This level of detail guides the authors on what needs to be addressed in the paper, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the impact of \"person blocking\" on the models, as shown in Fig.4. It provides a possible explanation, suggesting that the models might learn person-related features, which could be undesirable. However, the comment does not provide any evidence, references, or detailed reasoning to support this claim. The lack of supporting information makes it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the impact of \"person blocking\" on the models, as depicted in Fig.4. It provides a possible explanation, suggesting that the models might learn person-related features, which could be undesirable. By asking the authors to comment on this issue, the reviewer encourages the authors to clarify the reasoning behind the models\\' behavior. This feedback is somewhat helpful as it prompts the authors to address a potential concern and provide additional insight into their work. However, it could be more helpful if it included suggestions on how to address this issue or further explore the implications of \"person blocking.\" Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point asks a question about whether the authors tried combining TF-IDF and dense retrieval for evidence sentence extraction. While it implies that the authors should consider this combination, it does not explicitly instruct them to do so or provide guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this combination without clear instructions on how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment asks about the combination of TF-IDF and dense retrieval for evidence sentence extraction but does not specify which part of the paper this question pertains to. The authors may infer that it relates to the methodology or results sections, but without explicit references, it is weakly grounded. The comment is specific in its inquiry about the combination of techniques, providing a clear direction for the authors to consider. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking if the authors tried combining TF-IDF and dense retrieval for evidence sentence extraction. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about whether the authors have explored the combination of TF-IDF and dense retrieval for evidence sentence extraction. While it prompts the authors to consider an alternative approach, it lacks depth and does not provide any guidance or suggestions on how to implement or evaluate this combination. The comment identifies a potential area for improvement but does not offer actionable advice or insights to help the authors enhance their work. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should include examples where the time-series prediction did not perform well. It provides specific examples, such as the COVID-19 dataset where the UK and Russia are highly correlated despite not being neighboring countries, and asks about countries where predictions were not great and how their trajectories relate to the top eigenvectors of the Laplacian. This feedback is explicit and provides concrete guidance on what the authors should include in their paper to enhance its content. The authors know exactly what additional information to add and how to implement it, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper should include examples where the time-series prediction did not perform well, specifically mentioning the COVID-19 dataset and the correlation between the UK and Russia. It also asks about countries where predictions were not great and how their trajectories relate to the top eigenvectors of the Laplacian. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the results or discussion sections where such examples and analyses are typically presented. The authors can infer that this comment relates to these sections, making it weakly grounded. However, the comment is specific in detailing what needs to be addressed, such as providing examples of poor predictions and their relation to the Laplacian. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include examples where the time-series prediction did not perform well, specifically mentioning the COVID-19 dataset and the correlation between the UK and Russia. It also asks about countries where predictions were not great and how their trajectories relate to the top eigenvectors of the Laplacian. While the comment provides a specific example and a direction for further analysis, it lacks detailed reasoning or evidence to fully substantiate the claim that these examples are relevant or significant. The suggestion is somewhat verifiable as it provides a clear direction for the authors to explore, but it could be strengthened with more detailed justification or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper should include examples where the time-series prediction did not perform well, providing a specific example from the COVID-19 dataset where the UK and Russia are highly correlated despite not being neighboring countries. It also asks about countries where predictions were not great and how their trajectories relate to the top eigenvectors of the Laplacian. This feedback is actionable and provides a clear direction for the authors to enhance their paper by including additional examples and analysis. By addressing these points, the authors can provide a more comprehensive understanding of their model\\'s limitations and strengths, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the claims made in the paper regarding the proposed \"learning framework,\" suggesting that it is not a new framework but rather a modified loss and architecture. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this critique or improve their claims. Without actionable suggestions or specific feedback, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the claims made in the paper about proposing a \"learning framework,\" suggesting that it is not a new framework but rather a modified loss and architecture. However, it does not specify which part of the paper these claims are made in, making it difficult for the authors to identify the exact sections that need revision. The comment lacks grounding as it does not provide a clear reference to the specific parts of the paper being addressed. Additionally, it is not specific about what aspects of the claims are overblown or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the \"learning framework\" proposed in the paper is \"overblown\" and suggests it is merely a modified loss and architecture. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the claims made in the paper regarding the proposed \"learning framework,\" suggesting that it is not a new framework but rather a modified loss and architecture. While the comment identifies a potential issue with the paper\\'s claims, it lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address this critique or enhance their claims. As a result, the comment is barely helpful, as it highlights a potential weakness but does not provide sufficient direction for the authors to improve their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation in the learned prompts, which are customized for specific transformer-based architectures like CLIP and DINOv2. It suggests that this specificity may limit cross-model generalization and proposes exploring the possibility of designing prompts with more universal features or optimizing them independently of model architecture. While the comment identifies a specific issue and suggests a direction for improvement, it does not provide explicit guidance on how to implement these suggestions. The authors are left with a clear understanding of the problem but may need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of learned prompts being customized for specific transformer-based architectures, such as CLIP and DINOv2, and how this might limit cross-model generalization. It suggests exploring the possibility of designing prompts with more universal features or optimizing them independently of model architecture. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion of learned prompts and their applicability. The comment is specific in detailing the potential limitation and suggesting a direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the learned prompts are customized for specific transformer-based architectures, which may limit their applicability to other models or even slight variations of the same architecture. The comment suggests that this specificity could be addressed by exploring prompts with more universal features or optimizing them independently of model architecture. While the claim is logical and based on a reasonable concern about the generalizability of the prompts, it lacks specific examples or references to support the assertion. The reasoning is somewhat verifiable, as it provides a clear direction for potential improvement but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the learned prompts, which are customized for specific transformer-based architectures. It highlights that this specificity may limit cross-model generalization and suggests that separate training of prompts for each new architecture could be required. The comment provides a clear and actionable suggestion by proposing the exploration of prompts with more universal features or optimized independently of model architecture. This feedback is valuable as it directs the authors to consider a broader applicability of their work, which could significantly enhance the impact and utility of their findings. However, the comment could be more helpful if it included specific examples or further guidance on how to approach this exploration. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the absence of baselines and the antiquated nature of the model architecture used in the paper. It suggests that without comparisons to other models, there is no evidence that the current methodology is more effective or novel for fMRI forecasting. The comment explicitly suggests evaluating the current methodology against advanced time-series forecasting models available in the \"Time-Series Library\" repository. This provides a clear and concrete action for the authors to take, which is to include comparisons with contemporary models to demonstrate the effectiveness and novelty of their approach. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises concerns about the absence of baselines and the antiquated nature of the model architecture used in the paper. It suggests that without comparisons to other models, there is no evidence that the current methodology is more effective or novel for fMRI forecasting. The reviewer provides a specific suggestion to evaluate the current methodology against advanced time-series forecasting models available in the \"Time-Series Library\" repository. However, the comment does not explicitly mention which part of the paper discusses the model architecture, making it weakly grounded. The suggestion to include comparisons with other models is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the absence of baselines and the antiquated nature of the model architecture used in the paper. It suggests that without comparisons to other models, there is no evidence that the current methodology is more effective or novel for fMRI forecasting. The comment provides a specific suggestion to evaluate the current methodology against advanced time-series forecasting models available in the \"Time-Series Library\" repository, which is a concrete and verifiable recommendation. However, the comment could be strengthened by providing more detailed reasoning or examples of why the current methodology is considered antiquated or how it compares to contemporary models. Overall, the claim is mostly verifiable, as it provides a clear direction for improvement but lacks detailed justification. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the absence of baselines in the paper, which makes it difficult to evaluate the effectiveness of the current methodology. It also points out that the model architecture used appears to be antiquated and suggests that comparisons with other models, such as those available in the \"Time-Series Library\" repository, would be beneficial. This feedback is clear and actionable, as it provides a specific suggestion for improvement by recommending the inclusion of contemporary time-series forecasting models as baselines. By addressing this feedback, the authors can strengthen their paper by demonstrating the novelty and effectiveness of their approach. Therefore, the comment is mostly helpful, as it offers constructive guidance for enhancing the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a strong baseline in one of the tasks, beyond the standard MLPs already presented. While the comment implies that the authors should add a baseline, it does not specify which task or type of baseline would be appropriate. The action is implicit and somewhat vague, as the authors are left to infer the exact nature of the baseline and the task it should be applied to. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of strong baselines in the paper, specifically mentioning that only standard MLPs are presented. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to include a strong baseline in one of the tasks, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks strong baselines, specifically mentioning that only standard MLPs are presented. However, the comment does not provide any specific examples or references to support the claim that other strong baselines should be included. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support to guide the authors in making improvements.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out a limitation in the paper, noting that only standard MLPs are presented as baselines, despite the paper being primarily theoretical. The reviewer suggests that including a strong baseline in one of the tasks would enhance the paper. While the comment identifies a potential area for improvement, it lacks specific guidance on which baseline to include or how it might be integrated into the paper. This limits the usefulness of the feedback, as the authors are left to infer the exact steps needed to address the issue. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to more clearly compare their proposed method to prior works cited in the paper and to include these prior works in the tables of experimental results. This feedback provides a direct and concrete action for the authors to take, ensuring they understand exactly what needs to be done to improve their draft. The comment is highly actionable as it specifies both the action and the details of how to implement it, leaving no ambiguity for the authors.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"two prior works cited by the authors [3, 5],\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, a clearer comparison of the proposed method to these prior works and the inclusion of these works in the tables of experimental results. This provides clear guidance on what needs to be improved, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is very similar to two prior works cited by the authors. However, it does not provide specific details or examples to support this claim, such as how the methods are similar or what specific aspects are identical. Without this additional information, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the proposed method is very similar to two prior works cited by the authors. It provides a clear and actionable suggestion for improvement by recommending that the paper should more clearly compare the proposed method to these prior works and include them in the tables of experimental results. This feedback is valuable as it highlights a potential weakness in the paper and offers a specific way for the authors to enhance the clarity and originality of their work. However, the comment could be more helpful if it provided additional context or examples of how the prior works are similar, which would further guide the authors in making the necessary comparisons. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the clarity of the broader goals identified in the paper, which are claimed to be addressed by visualization systems for interpretable reinforcement learning. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might clarify or specify these broader goals, leaving the authors without a clear path for improvement. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific claim made in the paper regarding the existence of visualization systems for interpretable reinforcement learning that address broader goals. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in questioning the clarity of the broader goals identified, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim about the existence of visualization systems for interpretable reinforcement learning that address broader goals. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The lack of detailed justification or examples makes it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the clarity of a specific claim made in the paper regarding the existence of visualization systems for interpretable reinforcement learning that address broader goals. It points out that the broader goals are not clearly defined, making it impossible to evaluate the claim. While the comment identifies a potential issue with the paper, it lacks specific suggestions or guidance on how the authors might clarify or address this point. The feedback is somewhat helpful as it highlights a need for clarification, but it does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the independence of AAL and SLS and questions whether applying them separately provides a stable improvement. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific changes should be made to the draft. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table (1-4),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the stability of improvements when applying AAL or SLS separately. However, the comment could be more specific by providing examples or further details on what constitutes a \"stable improvement.\" Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the independence of AAL and SLS and questions the stability of improvements when applying them separately. However, it does not provide any specific evidence, examples, or references to support this claim. The comment lacks detailed reasoning or justification, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the independence of AAL and SLS, suggesting that their improvements may not be stable when applied separately. It also questions the significance of the improvements shown in Table 1-4. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve their analysis. Without actionable feedback or detailed recommendations, the authors are left without a clear path for improvement. Therefore, the comment is barely helpful, as it highlights an area of concern but does not provide sufficient guidance for the authors to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments are limited to only one task (sentiment classification) and one dataset (SST2), and recommends exploring the effects on different tasks or utilizing multiple datasets for the same task. While the comment implies that the authors should expand their experiments, it does not provide specific guidance on which tasks or datasets to consider. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take without detailed instructions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limitation of the experiments being confined to only one task (sentiment classification) and one dataset (SST2). It suggests exploring the effects on different tasks or utilizing multiple datasets for the same task to gain deeper insights. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The suggestion to expand the experiments is specific, as it provides a clear direction for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are limited to only one task and one dataset, suggesting that exploring different tasks or datasets would provide deeper insights. This claim is somewhat verifiable as it highlights a potential limitation in the experimental scope. However, the comment lacks specific examples or references to support the claim that using multiple datasets or tasks would be beneficial. Providing such examples or references would strengthen the justification, making the claim more verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the paper's experimental scope, noting that it is confined to only one task (sentiment classification) and one dataset (SST2). It suggests that exploring different tasks or utilizing multiple datasets for the same task could provide deeper insights. This feedback is clear and actionable, as it directs the authors to expand their experimental scope, which could significantly enhance the comprehensiveness and generalizability of their findings. However, the comment could be more helpful if it provided specific examples of tasks or datasets that could be explored. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more detailed in its suggestions.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the use of simulated data in experiments, suggesting that real-world data would be more appropriate. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to incorporate real-world data into their experiments. The comment implies that the authors should consider using real-world data, but it lacks concrete details on how to implement this change. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the use of simulated data in experiments, specifically mentioning the Heat Equation, Damped Wave, and Navier-Stokes equations. However, it does not specify which part of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in its critique of using simulated data, suggesting that real-world data would be more appropriate and easier to fit. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of simulated data in experiments, specifically mentioning the Heat Equation, Damped Wave, and Navier-Stokes equations. It suggests that real-world data would be more appropriate and easier to fit. However, the comment lacks specific examples or references to support the claim that real-world data is more suitable or that simulated data is less effective. This makes the claim somewhat verifiable, as it provides a general critique but lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the use of simulated data in experiments, specifically mentioning the Heat Equation, Damped Wave, and Navier-Stokes equations. It questions whether these are real-world data or simulated data, suggesting that real-world data would be more appropriate and easier to fit. While the comment identifies a potential issue with the experimental setup, it lacks specific guidance or suggestions on how the authors might address this concern or improve their use of real-world data. The feedback is somewhat helpful as it points out a potential weakness, but it does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the study, specifically the absence of a dedicated image quality metric for evaluating the performance of image generation models. It suggests the inclusion of metrics like inter-class or intra-class Frechet Inception Distance (FID) to enhance the comprehensiveness of the evaluation and comparison between different models. This feedback is explicit and provides a clear action for the authors to take, which is to incorporate these metrics into their evaluation. The suggestion is concrete, as it specifies the type of metrics that could be used, making it highly actionable. Therefore, the comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights a limitation in the study, specifically the absence of a dedicated image quality metric for evaluating the performance of image generation models. It suggests the inclusion of metrics like inter-class or intra-class Frechet Inception Distance (FID) to enhance the comprehensiveness of the evaluation and comparison between different models. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the evaluation or results section, where such metrics would be relevant. The suggestion is specific, as it provides a clear example of what could be added to improve the evaluation. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the study lacks a dedicated image quality metric for evaluating the performance of image generation models. It suggests the inclusion of metrics like inter-class or intra-class Frechet Inception Distance (FID) to enhance the comprehensiveness of the evaluation. The comment provides a specific suggestion for improvement, which is a clear and logical step to enhance the evaluation. However, it does not provide detailed reasoning or examples of how the current evaluation is insufficient or how the suggested metrics would improve it. While the suggestion is mostly verifiable, the lack of detailed justification or examples makes it somewhat less robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the study by pointing out the absence of a dedicated image quality metric for evaluating the performance of image generation models. It suggests the inclusion of metrics like inter-class or intra-class Frechet Inception Distance (FID) to enhance the comprehensiveness of the evaluation and comparison between different models. This feedback is clear and actionable, providing the authors with a specific suggestion for improvement that could significantly enhance the rigor and depth of their evaluation. By offering a concrete example of what could be added, the comment empowers the authors to make a meaningful enhancement to their draft. Therefore, it is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the applicability of the mechanism to vision transformers, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should explore this possibility, conduct experiments, or discuss it in the paper. Without any actionable steps or suggestions, the authors are left without a clear direction on how to address this question. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the mechanism to vision transformers but does not specify which part of the paper it addresses. The authors cannot confidently determine the context or section being referred to, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide any details or suggestions on how to address the question or what aspects of the mechanism might be relevant to vision transformers. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point is a question seeking clarification on the applicability of the mechanism to vision transformers. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the mechanism to vision transformers, which could be an interesting area for exploration or discussion in the paper. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this question or what aspects of the mechanism might be relevant to vision transformers. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the precision of the proposed Adaptive IMLE compared to IMLE and asks if the authors have tried applying the method in different domains. While the comment implies that the authors should provide a comparison or application of their method in various domains, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the comparison and application aspects but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the precision of the proposed Adaptive IMLE compared to IMLE and asks if the authors have tried applying the method in different domains. However, it does not specify which part of the paper these questions relate to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed, resulting in weak grounding. The comment is specific in its questioning of the precision and applicability of the method, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification and additional information about the precision of the proposed Adaptive IMLE compared to IMLE, as well as its applicability to different domains. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the precision of the proposed Adaptive IMLE compared to IMLE and asks if the authors have applied their method to different domains. This feedback prompts the authors to consider the broader applicability and effectiveness of their method, which is a valuable insight for improving the draft. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these questions or expand their analysis. Despite this, the comment is somewhat helpful as it directs the authors to consider the applicability and precision of their method, offering a starting point for further exploration and improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experimental results are lacking and questions whether all the modules are necessary. While it implies that the authors should provide more detailed or focused experimental results, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to enhance their experimental section. However, the suggestion to question the necessity of all modules provides a concrete direction for improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the experimental results, specifically questioning whether all the modules are necessary. However, it does not specify which part of the paper these results are presented in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its questioning of the necessity of all modules but lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of all modules in the experimental results, suggesting that the results might be lacking. However, it does not provide any specific examples, reasoning, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental results, specifically questioning whether all the modules are necessary. This feedback is somewhat helpful as it prompts the authors to reconsider the relevance and necessity of each module in their experimental setup. However, the comment lacks specificity and does not provide detailed guidance on how to address this issue or what specific modules might be redundant. While it highlights an area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but lacks depth and detail.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises an interesting observation about the number of layers considered in the paper and suggests exploring the behavior of the network with more layers, such as 32 and 64. However, it does not provide explicit guidance or suggestions on how the authors should conduct this exploration or what specific aspects they should focus on. The action is implicit and somewhat vague, as the authors can infer that they need to consider more layers but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"9\" and \"a few number of layers, up to 8 layers,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the potential for oversmoothing in GNNs with more layers and suggests exploring the behavior with more layers like 32 and 64. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises an observation about the number of layers considered in the paper and suggests exploring the behavior of the network with more layers, such as 32 and 64. The claim is based on common knowledge about GNNs and their tendency to oversmooth with more layers. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim. While it provides a logical basis for the suggestion, it is not fully verifiable due to the absence of explicit evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the number of layers considered in the paper, noting that many GNNs tend to oversmooth as more layers are added. It suggests exploring the behavior of the network with more layers, such as 32 and 64, which could provide valuable insights into the model\\'s performance and robustness. This feedback is clear and actionable, as it directs the authors to consider a specific aspect of their model that could impact its effectiveness. However, the comment could be more helpful if it provided guidance on how to conduct this exploration or what specific metrics to focus on. Overall, the comment is mostly helpful, as it highlights an important area for further investigation and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the improvement of MT (Machine Translation) over ST (Statistical Translation) is very limited and recommends performing significance tests to ensure the reliability of the experimental results. This comment explicitly states an action for the authors to take, which is to conduct significance tests. However, it does not provide specific guidance on how to perform these tests or what statistical methods to use, leaving the authors with a clear but somewhat vague action to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the improvement of MT over ST is very limited and recommends performing significance tests to ensure the reliability of the experimental results. However, it does not specify which part of the paper this claim is based on, such as a particular section or figure, making it weakly grounded. The comment is specific in suggesting the need for significance tests, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvement of MT over ST is very limited and suggests performing significance tests to ensure the reliability of the experimental results. However, the comment lacks specific examples or detailed reasoning to support the claim about the limited improvement. It does not provide references or data to substantiate the assertion, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental results, suggesting that the improvement of Machine Translation (MT) over Statistical Translation (ST) is very limited. It provides a clear and actionable suggestion for the authors to perform significance tests to ensure the reliability of their experimental results. This feedback is valuable as it highlights a critical aspect of the paper that needs attention and offers a specific step for improvement. However, the comment could be more helpful if it provided additional context or examples of how significance tests could be applied or what specific aspects of the results might be questionable. Overall, the comment is mostly helpful as it directs the authors to a crucial area for improvement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the claim of the proposed framework being model-agnostic, as it is only evaluated under different GCN architectures. The reviewer suggests evaluating the framework on other GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, to demonstrate its model-agnostic nature. While the comment implies that the authors should conduct additional evaluations, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct these evaluations and figure out how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 5\" and refers to specific models (\"node and graph classification models employ similar GCN blocks\"), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim of model-agnosticism and suggests evaluating the framework on different GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is labeled as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim of the proposed framework being model-agnostic, as it is only evaluated under different GCN architectures. The reviewer suggests evaluating the framework on other GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, to demonstrate its model-agnostic nature. This claim is somewhat verifiable as it provides a logical reasoning for the need to evaluate the framework on different architectures to support the model-agnostic claim. However, the comment lacks specific examples or references to existing literature that could further substantiate the claim, making it mostly verifiable. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a valid concern about the claim of the proposed framework being model-agnostic, as it is only evaluated under different GCN architectures. The reviewer suggests evaluating the framework on other GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, to demonstrate its model-agnostic nature. This feedback is clear and actionable, providing the authors with a specific direction to enhance the robustness and generalizability of their framework. By addressing this point, the authors can strengthen their claim and improve the comprehensiveness of their evaluation. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the method has many components and recommends including error analysis to understand how the approach works if one of the components fails. It provides a specific example, such as what happens if GPT-4o misses some details. This feedback is explicit and concrete, as it clearly identifies the need for error analysis and provides a concrete example of what should be analyzed. The authors know exactly what action to take to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the method has many components and recommends including error analysis to understand how the approach works if one of the components fails. It provides a specific example, such as what happens if GPT-4o misses some details. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The suggestion for error analysis is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the method has many components and recommends including error analysis to understand how the approach works if one of the components fails. It provides a specific example, such as what happens if GPT-4o misses some details. This suggestion is based on logical reasoning and provides a clear direction for improvement, making it mostly verifiable. However, the comment could be strengthened by including examples or references to similar error analyses in the literature. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the method by noting that it has many components, which could lead to issues if one of them fails. It suggests that the authors include error analysis to understand how the approach works if one of the components makes a mistake. The comment provides a specific example, such as what happens if GPT-4o misses some details, which gives the authors a clear direction for improvement. This feedback is actionable and provides a constructive suggestion for enhancing the robustness of the method, making it mostly helpful. However, it could be more helpful if it included additional guidance on how to conduct the error analysis or what specific aspects to focus on. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part raises a concern about the practicality of the reversible version due to its higher computational cost during training, questioning its practicality despite cheap memory. However, it does not provide any explicit or implicit actions for the authors to take. The second part suggests including perplexity/BLEU scores for NF-Rev{GRU, LSTM} to verify the necessity of the gating mechanism. This suggestion is explicit and provides a clear action for the authors to take. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"reversible version\" and the \"perplexity/BLEU scores of a NF-Rev{GRU, LSTM}\" which allows the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the practicality of the reversible version and the inclusion of perplexity/BLEU scores to verify the necessity of the gating mechanism. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts. The first part raises a concern about the practicality of the reversible version due to its higher computational cost during training, questioning its practicality despite cheap memory. This claim is somewhat verifiable as it provides a logical reasoning based on the acknowledged higher computational cost, but it lacks specific examples or references to fully substantiate the claim. The second part suggests including perplexity/BLEU scores for NF-Rev{GRU, LSTM} to verify the necessity of the gating mechanism, which is a clear and actionable suggestion. However, the first part of the comment is not fully supported, making the overall comment somewhat verifiable. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the practicality of the reversible version due to its higher computational cost during training, questioning whether it is actually practical given the availability of cheap memory. This is a relevant point that could impact the paper\\'s applicability and is worth considering. Additionally, the comment suggests including perplexity/BLEU scores for NF-Rev{GRU, LSTM} to verify the necessity of the gating mechanism, which provides a clear and actionable suggestion for improvement. However, the comment could be more helpful if it offered specific guidance on how to address the practicality concern or provided more detailed suggestions for the inclusion of perplexity/BLEU scores. Overall, the comment is mostly helpful as it identifies a potential issue and offers a constructive suggestion, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an error analysis would be beneficial for understanding the limitations of SetCSE in certain scenarios. However, it does not provide explicit guidance on how to conduct this analysis or what specific aspects should be included. The action is implicit, as the authors need to infer that they should perform an error analysis, and it is vague because it lacks concrete details on how to execute this task. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that an error analysis would be beneficial for understanding the limitations of SetCSE in certain scenarios. However, it does not specify which part of the paper should include this analysis or where it is currently lacking. The authors might infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in suggesting the need for an error analysis but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an error analysis would be beneficial for understanding the limitations of SetCSE in certain scenarios. However, it does not provide any supporting evidence, reasoning, or references to justify why an error analysis is necessary or how it would improve the understanding of the limitations. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper by suggesting that an error analysis would be beneficial for understanding the limitations of SetCSE in certain scenarios. This feedback is somewhat helpful as it points out an area where the paper could be improved, providing the authors with a direction for further analysis. However, the comment lacks specificity and does not offer detailed guidance on how to conduct the error analysis or what aspects to focus on. While it highlights an important area for improvement, it does not provide actionable steps for the authors to take, limiting its helpfulness. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the sufficiency of using a prompting method to measure tool-knowledge, suggesting that shared model weights might lead to unintentional fine-tuning and that other prompts could elicit the model\\'s ability to use a tool. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or what specific actions they should take to improve their draft. The feedback is implicit and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the sufficiency of using a prompting method to measure tool-knowledge, suggesting that shared model weights might lead to unintentional fine-tuning and that other prompts could elicit the model\\'s ability to use a tool. However, it does not specify which part of the paper this concern pertains to, such as a specific section or experiment. Without explicit references or context, the authors cannot confidently determine where to address this issue. The comment is specific in its critique but lacks grounding, making it weakly grounded and not specific. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the sufficiency of using a prompting method to measure tool-knowledge, suggesting that shared model weights might lead to unintentional fine-tuning and that other prompts could elicit the model\\'s ability to use a tool. However, the comment lacks specific examples, references, or detailed reasoning to support the claim. The reasoning is somewhat vague and does not provide a clear path for the authors to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the sufficiency of using a prompting method to measure tool-knowledge, suggesting that shared model weights might lead to unintentional fine-tuning and that other prompts could elicit the model\\'s ability to use a tool. This feedback is somewhat helpful as it identifies a potential limitation in the current approach and encourages the authors to consider alternative methods or scenarios that might affect the results. However, the comment lacks specific suggestions or guidance on how to address this issue or what alternative methods might be more effective. While it provides some insight, it does not fully support the authors in making improvements to their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should find alternative tasks or even artificial tasks to demonstrate the effectiveness of HA3C, as the current MuJoCo control tasks may not be suitable for showcasing its benefits. This is an explicit suggestion with a clear action for the authors to take, providing concrete guidance on how to improve the draft. The comment is highly actionable as it directly instructs the authors on what steps to take to enhance their work.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experimental results\" and \"MuJoCo control tasks,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a detailed explanation of why the improvement of HA3C over baseline algorithms may not be indicative of its ineffectiveness, suggesting that the benefit of HA3C relies on the structure of the problem. The comment further suggests finding alternative tasks to demonstrate the effectiveness of HA3C, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the improvement of HA3C over baseline algorithms is marginal on MuJoCo control tasks, suggesting that this does not indicate HA3C is ineffective. The reviewer provides a logical explanation by suggesting that the benefit of HA3C may lie in its ability to handle causal relationships based on history, which might not be fully utilized in MuJoCo tasks. This reasoning is supported by the explanation of the potential limitations of HA3C in the context of MuJoCo tasks. However, the comment could be strengthened by providing specific examples or references to support the claim about the complexity of causal relationships in MuJoCo tasks. Overall, the claim is mostly verifiable, as it provides a logical basis but lacks detailed evidence or references to fully substantiate the argument.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a thoughtful analysis of the experimental results, noting that the improvement of HA3C over baseline algorithms is marginal on MuJoCo control tasks. The reviewer offers a nuanced perspective by suggesting that the benefit of HA3C may lie in its ability to handle causal relationships based on history, which could be more effectively demonstrated in tasks where this aspect is more relevant. This feedback is valuable as it encourages the authors to consider alternative tasks or environments that might better showcase the strengths of HA3C. However, the comment could be more helpful if it provided specific suggestions for alternative tasks or environments that could be explored. Overall, the comment is mostly helpful as it offers a constructive critique and a direction for further investigation, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that if the novelty of the paper does not lie in the dataset, then the key contributions should focus on the insights derived from the data to deepen our understanding of LLM capabilities. It implies that the authors should provide key insights or takeaways from their experiments that are generalizable and hold broader significance for the community. However, the comment does not explicitly instruct the authors to include these insights or provide specific guidance on how to present them. While the action is implicit, it is concrete in suggesting the type of content that should be added. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the issue of novelty and contributions in the paper, specifically questioning whether the insights derived from the data are adequately presented. It suggests that the authors should focus on key takeaways and insights from the experiments that are generalizable and hold broader significance for the community. However, the comment does not explicitly mention which part of the paper this critique pertains to, such as specific sections or figures, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the presentation of key insights and takeaways. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not fully address the aspect of insights derived from the data to deepen understanding of LLM capabilities. It suggests that the authors should focus on key takeaways and insights from the experiments that are generalizable and hold broader significance for the community. However, the comment lacks specific examples or references to support the claim that the paper does not adequately address this aspect. The reasoning is somewhat vague, as it does not provide detailed evidence or examples of what specific insights or takeaways are missing. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a critical area for improvement in the paper, specifically the lack of focus on insights derived from the data to deepen understanding of LLM capabilities. It suggests that if the novelty does not lie in the dataset, the key contributions should be based on the insights gained from the data. The comment provides a clear direction for the authors to enhance their paper by highlighting the need for key takeaways and insights that are generalizable and hold broader significance for the community. However, it could be more helpful if it offered specific examples or suggestions on how to present these insights effectively. Overall, the comment is mostly helpful as it provides actionable feedback that can guide the authors in improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the claim in Section 3.1 is false and ignores other important works in the community. It provides specific examples of alternative vocoder choices, such as WaveNet, WaveRnn, and diffusion-based approaches. This feedback is clear and actionable, as it directs the authors to correct the false claim and include a more comprehensive discussion of vocoder choices. The authors know exactly what needs to be done to address the issue, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that \"GAN has been the de facto choice for vocoders,\" pointing out that it is false and ignores other important works in the community. The comment provides specific examples of alternative vocoder choices, such as WaveNet, WaveRnn, and diffusion-based approaches, which further enhances its specificity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement \"GAN has been the de facto choice for vocoders\" is false and ignores other important works in the community. The reviewer provides specific examples of alternative vocoder choices, such as WaveNet, WaveRnn, and diffusion-based approaches, which supports the claim. This level of detail and reference to specific alternatives makes the claim fully verifiable, as it provides a clear and robust basis for the reviewer\\'s assertion. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the claim in Section 3.1 that \"GAN has been the de facto choice for vocoders,\" labeling it as false and pointing out the omission of other important works in the community. It provides specific examples of alternative vocoder choices, such as WaveNet, WaveRnn, and diffusion-based approaches, which is a clear and actionable suggestion for the authors to include in their draft. This feedback is highly helpful as it not only corrects a potential misrepresentation but also guides the authors on how to enhance the comprehensiveness of their discussion. By addressing this issue, the authors can improve the accuracy and depth of their paper, making this comment highly valuable.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the approach contains design choices that are not fully explained or empirically justified, specifically mentioning the choice of token similarity metric. While the comment identifies areas that need further explanation or justification, it does not provide explicit guidance on how the authors should address these issues. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations or empirical justifications for these design choices. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is weakly grounded as it does not specify which part of the paper discusses the design choices or the token similarity metric, making it difficult for the authors to pinpoint the exact sections that need attention. However, it is specific in identifying the issue of unexplained or unjustified design choices, particularly the choice of token similarity metric. This provides clear guidance on what needs to be addressed, even if the authors cannot determine the exact location of the issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the approach contains design choices that are not fully explained or empirically justified, specifically mentioning the choice of token similarity metric. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The lack of concrete evidence or references leaves the claim somewhat verifiable, as the authors would need to infer the specific design choices and their implications. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper, noting that while the approach is straightforward and sensible, it contains design choices that are not fully explained or empirically justified. It highlights the choice of token similarity metric as an example of this issue. This feedback is somewhat helpful as it points out a potential weakness in the paper's methodology, prompting the authors to provide more detailed explanations or empirical justifications for their design choices. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how similar choices have been justified in other works. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights specific inconsistencies in the notation used in Equations (4) and (6). It points out that the left-hand side (LHS) of Equation (4) includes \"T\" and \"W,\" but the right-hand side (RHS) does not. Similarly, it notes that the formulas for the mean and variance in Equation (6) include \"j\" on the LHS but not on the RHS. This feedback is explicit and provides clear guidance on what needs to be corrected, as it specifies the exact equations and inconsistencies that require attention. The authors know exactly what actions to take to address these issues, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific equations (Equations 4 and 6) and highlights inconsistencies in the notation, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the exact inconsistencies in the notation, such as the presence of \"T\" and \"W\" on the LHS of Equation (4) but not on the RHS, and the inclusion of \"j\" on the LHS of Equation (6) but not on the RHS. This level of detail provides clear guidance on what needs to be corrected, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights specific inconsistencies in the notation used in Equations (4) and (6), pointing out that the left-hand side (LHS) includes certain variables (\"T\" and \"W\" in Equation (4), and \"j\" in Equation (6)) that are not present on the right-hand side (RHS). This observation is factual and based on a direct comparison of the equations, making it verifiable. The comment provides clear and specific details about the inconsistencies, allowing the authors to easily verify and address the issue. Therefore, the comment is categorized as fully verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies specific inconsistencies in the notation used in Equations (4) and (6), pointing out that the left-hand side (LHS) includes variables (\"T\" and \"W\" in Equation (4), and \"j\" in Equation (6)) that are not present on the right-hand side (RHS). This feedback is clear and actionable, as it provides precise guidance on what needs to be corrected to ensure consistency in the notation. By addressing these inconsistencies, the authors can improve the clarity and accuracy of their equations, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the evaluation of the paper, including the insufficient number of models constructed during evaluation, the lack of evaluation regarding image distortion after warping, and the absence of discussion on potential countermeasures. While the comment identifies specific areas that need improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors can infer that they need to increase the number of models evaluated, conduct additional evaluations on image distortion, and discuss potential countermeasures, but the comment lacks detailed guidance on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Insufficient Evaluation,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the issues with the evaluation, including the insufficient number of models constructed, the lack of evaluation regarding image distortion after warping, and the absence of discussion on potential countermeasures. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation is insufficient due to the limited number of models constructed and the lack of evaluation regarding image distortion after warping. It also points out the absence of discussion on potential countermeasures. While the comment highlights specific areas for improvement, it does not provide detailed reasoning or examples to support these claims. The lack of specific references or detailed explanations makes it difficult for the authors to fully understand and address the issues. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several areas where the evaluation of the paper is insufficient, including the limited number of models constructed during evaluation, the lack of evaluation regarding image distortion after warping, and the absence of discussion on potential countermeasures against the proposed approach. This feedback is clear and actionable, as it provides specific points for the authors to address in order to strengthen their evaluation and discussion. However, the comment could be more helpful if it offered suggestions on how to expand the evaluation or discuss potential countermeasures. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the classification of elements in Table A3, specifically whether they are discourse particles or a combination of discourse and imported vocabulary. It suggests that if the latter, these elements should be separated into different tables, and provides a concrete suggestion to include glosses. While the action is explicit, the comment could be more actionable by providing specific guidance on how to categorize the elements or how to separate them into different tables. However, the suggestion to include glosses is clear and concrete. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table A3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the classification of elements in the table, suggesting that if they are a combination of discourse and imported vocabulary, they should be separated into different tables. Additionally, it recommends including glosses to provide further clarification. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the classification of elements in Table A3, specifically whether they are discourse particles or a combination of discourse and imported vocabulary. It suggests separating them into different tables and providing glosses for clarification. However, the comment does not provide any evidence, reasoning, or references to support the claim that the elements should be separated or that glosses are necessary. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the classification of elements in Table A3, asking whether they are discourse particles or a combination of discourse and imported vocabulary. It suggests that if the latter, these elements should be separated into different tables and provides a constructive suggestion to include glosses for clarification. This feedback is clear and actionable, offering the authors a concrete way to improve the organization and clarity of their work. However, it could be more helpful if it provided additional context or examples to further guide the authors in making these changes. Overall, the comment is mostly helpful as it provides valuable feedback that can enhance the clarity and organization of the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the understanding of formula (4) and the reasoning behind the \"max over all possible pieces for unoccupied squares.\" While it identifies a potential area of confusion, it does not provide explicit guidance or suggestions on how the authors might clarify or improve this part of the paper. The action is implicit, as the authors need to infer that they should provide additional explanation or clarification, but it lacks concrete details on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"formula (4),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the reasoning behind the \"max over all possible pieces for unoccupied squares.\" This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the reasoning behind a specific formula, \"formula (4),\" and the choice of \"max over all possible pieces for unoccupied squares.\" It does not contain a claim or opinion that requires verification. It is a request for clarification, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the understanding of a specific formula, \"formula (4),\" and the reasoning behind the \"max over all possible pieces for unoccupied squares.\" While it identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might clarify or improve this part of the paper. The comment lacks actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of comparison to state-of-the-art subset selection methods in the experiments. While it identifies an area for improvement, it does not provide specific guidance on which methods should be compared or how to conduct the comparison. The action is implicit and somewhat vague, as the authors can infer that they need to include comparisons but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experiments section, specifically mentioning the lack of comparison to state-of-the-art subset selection methods. This provides full grounding as it clearly identifies the part of the paper being addressed. However, the comment lacks specificity because it does not provide details on which state-of-the-art methods should be compared or how this comparison should be conducted. Therefore, this comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the experiments lack a comparison to state-of-the-art subset selection methods. However, it does not provide any specific examples or references to these state-of-the-art methods, nor does it explain why such a comparison is necessary or how it would improve the paper. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of comparison to state-of-the-art subset selection methods in the experiments. This is a critical observation that could impact the validity and relevance of the results presented. However, the comment does not provide specific suggestions on which state-of-the-art methods should be considered or how to conduct the comparison. While it highlights an important area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is somewhat helpful, as it directs the authors to a specific area for enhancement but lacks depth in its suggestions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the paper is vague and needs to be more concise. It mentions that the primary components integrate effective elements of previous works, including SCL, Aligned, and CLNN. However, the comment does not provide specific guidance on how to improve the novelty or suggest ways to make it more concise. The action is implicit, as the authors can infer that they need to clarify and enhance the novelty section, but it lacks concrete details on how to achieve this. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the novelty of the paper, suggesting that it is somewhat vague and needs to be more concise. It mentions that the primary components integrate effective elements of previous works, including SCL, Aligned, and CLNN. However, the comment does not specify which part of the paper this issue pertains to, such as the introduction, literature review, or results section. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing improvement. Additionally, while the comment identifies the need for more conciseness, it does not provide specific guidance on how to achieve this. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the novelty of the paper is \"somewhat vague\" and suggests that it integrates effective elements of previous works, such as SCL, Aligned, and CLNN. However, the comment lacks specific examples or detailed reasoning to support the claim of vagueness or to explain how the integration of previous works affects the novelty. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a weakness in the paper, noting that the novelty is somewhat vague and could be more concise. It mentions that the primary components integrate effective elements of previous works, such as SCL, Aligned, and CLNN. However, the comment lacks specific guidance or suggestions on how to enhance the novelty or provide more clarity. While it points out an area for improvement, it does not offer actionable advice or detailed feedback, leaving the authors with a general direction but no concrete steps to take. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should use evaluation benchmarks of the user simulator to demonstrate how smaller models perform as user simulators. This would make the benchmark more usable and available to the community. The comment explicitly states the action needed, which is to use evaluation benchmarks to demonstrate the performance of smaller models. However, it does not provide specific guidance on how to implement this suggestion, such as which benchmarks to use or how to present the results. While the action is clear, the lack of detailed instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests using evaluation benchmarks of the user simulator to demonstrate the performance of smaller models as user simulators. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. This makes it difficult for the authors to identify the exact area that needs attention. The comment is specific in its suggestion to use evaluation benchmarks, but it lacks grounding, as it does not clearly indicate where this should be implemented. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that using evaluation benchmarks of the user simulator would make the benchmark more usable and available to the community. However, it does not provide any specific examples, references, or detailed reasoning to support why this would be beneficial or how it would enhance the usability of the benchmark. The lack of supporting evidence or detailed justification makes the claim difficult for the authors to understand and address, rendering it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should use evaluation benchmarks of the user simulator to demonstrate how smaller models perform as user simulators. This feedback is clear and actionable, as it provides a specific direction for improving the usability and availability of the benchmark to the community. By following this suggestion, the authors can enhance the comprehensiveness and applicability of their work. However, the comment could be more helpful if it included examples of specific benchmarks or models to consider, which would further guide the authors in implementing the suggestion. Overall, the comment is mostly helpful, as it offers a constructive and actionable piece of feedback that can significantly improve the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of open-set detectors on the performance of the proposed method. While it identifies an area that needs clarification, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should investigate and report on the impact of open-set detectors. However, the comment lacks concrete details on how to conduct this investigation or what specific aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the impact of open-set detectors on the performance of the proposed method. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. Without explicit references or context, the authors cannot confidently determine where in the paper this issue should be addressed. Additionally, the comment lacks specificity regarding what aspects of the impact of open-set detectors need to be clarified. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification on the impact of open-set detectors on the performance of the proposed method. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a relevant question about the impact of open-set detectors on the performance of the proposed method. This is a critical aspect that could significantly affect the overall evaluation and understanding of the work. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this question or what specific aspects of the impact should be explored. Without actionable feedback or detailed guidance, the authors are left with a general area for improvement but without a clear path forward. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two separate issues: the first regarding the explanation of a symbol in Table 1, and the second regarding the interpretation of \"from-scratch\" in Table 5. For the first issue, the reviewer suggests that the authors clarify the meaning of the symbol. For the second issue, the reviewer questions the interpretation of \"from-scratch\" and suggests that the authors clarify or correct this in the text. Both suggestions are explicit and provide clear guidance on what the authors need to do to address the issues. The feedback is concrete and actionable, as it specifies exactly what needs to be clarified or corrected. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the tables, such as the lack of explanation for the symbol next to \"oracle goals\" in Table 1 and the confusion regarding the \"from-scratch\" setting in Table 5. The comment provides clear guidance on what needs to be clarified or corrected, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two separate claims. The first claim questions the absence of an explanation for the symbol (*) next to \"oracle goals\" in Table 1. The second claim questions the interpretation of \"from-scratch\" in Table 5, suggesting that it might imply random initialization but seems to contradict the text, which mentions pre-training on a text corpus. Both claims are somewhat verifiable as they provide a logical basis for questioning the clarity of the tables and the interpretation of the \"from-scratch\" setting. However, the comments lack specific references or detailed reasoning to fully substantiate the claims. Therefore, the feedback is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues in the paper: the absence of an explanation for the symbol (*) next to \"oracle goals\" in Table 1, and the confusion regarding the \"from-scratch\" setting in Table 5. The reviewer questions whether the model was randomly initialized or pre-trained on a text corpus, highlighting a potential inconsistency. By pointing out these issues, the comment provides clear and actionable feedback that can help the authors clarify and improve the clarity of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional context for the authors to consider. Overall, the feedback is mostly helpful as it directs the authors to specific areas needing clarification or correction, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the expected outcome of increasing noise intensity on transferability, suggesting that it should lead to increased misclassification. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this observation or improve their results. Without actionable suggestions or specific feedback, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the observation about transferability increasing with higher noise intensity and questions the expected outcome of this phenomenon. The comment provides a clear critique of the results, suggesting that the expected outcome should be increased misclassification due to the activation of different neurons in response to noise. This level of detail helps the authors understand what needs to be addressed in their analysis. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the expected outcome of increasing noise intensity on transferability, suggesting that it should lead to increased misclassification. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the expected outcome of increasing noise intensity on transferability, suggesting that it should lead to increased misclassification. However, it does not provide any specific suggestions or guidance on how the authors might address this observation or improve their results. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as not helpful at all, as it does not offer any meaningful insights or directions for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides several explicit actions for the authors to take. It suggests adding ablation studies with only importance weighting or rejection to better understand their effects, which is a clear and concrete action. Additionally, it points out issues with the font size in the figures, specifically mentioning Fig. 6 (a), and requests further explanation regarding the ChopperCommand results. These requests are direct and provide specific guidance on what needs to be addressed. The comment is highly actionable as it offers concrete steps for improvement, making it clear to the authors exactly what they need to do to enhance their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 6 (a)\" and \"the ChopperCommand results,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it details what needs to be addressed, such as adding ablation studies, improving the font size in figures, and providing further explanation for the observed results in Fig. 6 (a). The comment also includes a request for clarification regarding the ChopperCommand results, which adds to its specificity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of multiple claims and suggestions. The first claim suggests adding ablation studies to better understand the effects of importance weighting or rejection, which is a logical suggestion but lacks specific examples or references to support its necessity. The second claim points out issues with the font size in figures, which is a factual observation. The third claim questions the results in Fig. 6 (a), specifically the ChopperCommand results, and requests further explanation. While the comment raises valid points, it lacks detailed reasoning or references to fully substantiate the claims. Therefore, the comment is somewhat verifiable, as it provides some justification but requires more detailed evidence or examples to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several actionable suggestions for improving the paper. It recommends adding ablation studies to better understand the effects of importance weighting or rejection, which is a clear and specific suggestion for enhancing the paper\\'s analysis. Additionally, it points out issues with the font size in the figures, which is a practical concern that the authors can address. The comment also raises questions about the ChopperCommand results in Fig. 6 (a), prompting the authors to provide further explanation. This feedback is detailed and constructive, offering the authors specific areas to focus on for improvement. However, the comment could be more helpful if it provided additional context or examples to support the suggestions. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a lack of technical clarity in the paper, specifically mentioning that the main learning framework, Equation (18), is not explained. It also questions how to implement the balancing term and the penalty term. While the comment highlights areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide a clearer explanation of the learning framework and its components. However, the comment lacks concrete guidance on how to implement the balancing and penalty terms, making it somewhat actionable. The authors know they need to clarify the technical aspects, but the exact steps to take are not specified.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (18),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the explanation of the main learning framework and the implementation of the balancing and penalty terms. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical clarity is weak, specifically mentioning that Equation (18) is not explained. It questions how to implement the balancing term and the penalty term. However, the comment lacks specific examples or detailed reasoning to support the claim of weak technical clarity. Without additional context or references, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some basis for the critique but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area of weakness in the paper, namely the lack of technical clarity regarding the main learning framework, Equation (18). It questions the explanation of how to implement the balancing term and the penalty term, which are crucial components of the framework. This feedback is clear and actionable, as it directs the authors to provide a more detailed explanation of these technical aspects. However, the comment could be more helpful if it offered suggestions on how to improve the explanation or provided examples of similar frameworks that might be helpful for comparison. Overall, the comment is mostly helpful as it highlights a critical area for improvement and guides the authors toward enhancing the technical clarity of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the decision boundary generation, specifically noting that the projection results and Voronoi tessellations appear fixed across multiple rounds, despite the feature vectors updating during training. It suggests that the authors should clarify how these fixed tessellations align with the updated predictions and model behavior. Additionally, the comment questions the use of 2D projections to represent high-dimensional decision boundaries, highlighting potential variability based on the projection method and parameters. While the comment identifies areas for clarification and improvement, it does not provide explicit instructions on how to address these concerns. The actions are implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issues. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figures\" and \"projection results and the Voronoi tessellation results,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the concerns about the fixed nature of the projection results and Voronoi tessellations despite the updating feature vectors during training. Additionally, it raises questions about the use of 2D projections to represent high-dimensional decision boundaries and the potential variability based on the projection method and parameters. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the decision boundary generation, specifically noting that the projection results and Voronoi tessellations appear fixed across multiple rounds, despite the feature vectors updating during training. It questions how well these fixed tessellations align with the updated predictions and suggests that the use of 2D projections to represent high-dimensional decision boundaries may lead to variability based on the selected projection method and parameters. While the comment highlights potential issues, it lacks specific examples or references to support the claims, making it somewhat verifiable. The authors would need to provide additional evidence or clarification to fully understand and address the concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical concern about the decision boundary generation in the paper. It points out that the projection results and Voronoi tessellations appear fixed across multiple rounds, despite the feature vectors updating during training. This observation highlights a potential issue with the model's behavior and suggests that the authors should clarify how these fixed tessellations align with the updated predictions. Additionally, the comment questions the use of 2D projections to represent high-dimensional decision boundaries, noting that results can vary significantly based on the selected projection method and parameters. This feedback is mostly helpful as it identifies specific areas for improvement and provides a clear direction for the authors to address these concerns. However, it could be more helpful if it offered suggestions on how to address these issues or provided examples of alternative methods. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that there is no ablation study and no comparison to methods from the past decade. This provides clear and direct actions for the authors to take: conducting an ablation study and comparing their methods to those from the past decade. The feedback is explicit and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment points out the absence of an ablation study and a comparison to methods from the past decade. However, it does not specify which part of the paper this critique pertains to, such as the methodology or results sections. Without explicit references to these sections, the authors may find it challenging to identify the exact areas needing improvement. The comment is specific in its critique but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no ablation study and no comparison to methods from the past decade. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two significant gaps in the paper: the absence of an ablation study and the lack of comparison to methods from the past decade. This feedback is valuable as it highlights important areas for improvement that could strengthen the paper\\'s methodology and contributions. However, the comment does not provide specific suggestions or guidance on how to conduct the ablation study or which methods from the past decade should be compared. While it points out critical weaknesses, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include more theoretical results on more complicated models beyond SVC. However, it does not provide specific guidance on which models should be considered or how to incorporate these additional results. The action is implicit and vague, as the authors are left to infer which models are \"more complicated\" and how to integrate them into the paper. Without concrete details, the authors may struggle to determine the exact steps needed to address this feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper should include more theoretical results on more complicated models beyond SVC. However, it does not specify which part of the paper this suggestion pertains to, nor does it provide details on what specific models should be considered or how they should be integrated. This makes it difficult for the authors to identify the exact sections that need revision. The comment lacks both grounding and specificity, leaving the authors without clear guidance on how to address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper should include more theoretical results on more complicated models beyond SVC. However, it does not provide any specific examples, reasoning, or references to support why these additional results are necessary or how they would enhance the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the suggestion, rendering the claim unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should include more theoretical results on more complicated models beyond SVC. While it identifies a potential area for expansion, it lacks specificity and does not provide guidance on which models should be considered or how to integrate them into the paper. The comment does not offer actionable advice or detailed suggestions for improvement, leaving the authors with a general idea but no clear path forward. Therefore, the comment is barely helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion. It explicitly states that the existing results in Fig. 11 are insufficient for this purpose. This feedback is clear and provides a specific action for the authors to take, which is to conduct additional ablation studies. The comment is explicit and concrete, as it directly instructs the authors on what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 11,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely more ablation studies to demonstrate the necessity of the proposed DA Inversion. The comment provides a clear direction for improvement by suggesting additional studies to support the claim. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that more ablation studies are needed to demonstrate the necessity of the proposed DA Inversion. The reviewer provides a specific reference to Fig. 11, indicating that the existing results are insufficient. This claim is somewhat verifiable as it provides a clear suggestion for additional analysis but lacks detailed reasoning or examples of how the proposed DA Inversion could be further substantiated through ablation studies. The comment provides a direction for improvement but could be strengthened with more specific guidance or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that more ablation studies should be conducted to demonstrate the necessity of the proposed DA Inversion. It provides a clear and actionable suggestion by referencing Fig. 11, indicating that the existing results are insufficient. This feedback is valuable as it directs the authors to conduct additional analyses that can strengthen the paper\\'s claims and provide more robust evidence for the proposed method. However, the comment could be more helpful if it offered specific guidance on which aspects of the DA Inversion should be tested or how the ablation studies could be structured. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the necessity of clustering in the 2nd phase of training, given that a linear regressor is used for evaluation. It suggests that a clear ablation study should be presented to address this issue. While the comment implies that the authors should conduct an ablation study to clarify the importance of clustering, it does not explicitly instruct them to do so. The action is concrete in terms of what needs to be done (conducting an ablation study), but it is implicit in the sense that the authors need to infer the action from the question posed. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of whether the clustering in the 2nd phase of training is necessary and suggests that a clear ablation study should be presented to address this question. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of clustering in the 2nd phase of training, given that a linear regressor is used for evaluation. It suggests that a clear ablation study should be presented to address this issue. The comment provides a logical reasoning by questioning the purpose of clustering in this context, which is a valid point. However, it lacks specific examples or references to support the claim that an ablation study is necessary. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the suggestion but requires more detailed justification or evidence to be fully verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a pertinent question about the necessity of clustering in the 2nd phase of training, given that a linear regressor is used for evaluation. It suggests that a clear ablation study should be presented to address this issue, which is a valuable piece of feedback. By pointing out this potential redundancy, the comment encourages the authors to clarify the importance of clustering in their methodology. However, the comment could be more helpful if it provided specific guidance on how to conduct the ablation study or what aspects to focus on. Overall, the feedback is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the figures, specifically mentioning Fig2a, where the forgetting is not as drastic as in class incremental learning and shows a slight increase near epoch 150. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this observation or what changes should be made to improve the figures or the analysis. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig2a,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it details the issue with the forgetting in the figure, noting that it is not as drastic as in class incremental learning and that a slight increase is seen near epoch 150. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the forgetting observed in Fig2a is not as drastic as in class incremental learning and notes a slight increase near epoch 150. However, the comment lacks specific reasoning or evidence to support this claim, such as comparisons with other methods or detailed analysis of the forgetting rates. Without these elements, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out a specific observation regarding the forgetting in Fig2a, noting that it is not as drastic as in class incremental learning and that a slight increase is seen near epoch 150. While this feedback highlights a potential issue with the analysis or presentation of the results, it lacks depth and does not provide actionable suggestions for improvement. The authors are left with a general understanding of the issue but without specific guidance on how to address it or what changes to make. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should highlight the data-dependent nature of their approximation results, specifically mentioning the covariance spectrum. While the comment implies that this should be done in the abstract, it does not explicitly instruct the authors to make this change. The action is implicit and somewhat vague, as the authors are not provided with specific guidance on how to incorporate this information into the abstract. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should highlight the data-dependent nature of their approximation results, specifically mentioning the covariance spectrum. It implies that this should be done in the abstract, but it does not specify which part of the abstract or the paper this should be addressed in. While the authors can infer that it relates to the results section, the comment lacks full grounding as it does not explicitly mention a specific section or figure. The suggestion is specific, as it clearly identifies what needs to be addressed, but the lack of explicit grounding makes it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should highlight the data-dependent nature of their approximation results, specifically mentioning the covariance spectrum. The comment acknowledges that having a data-dependent bound is acceptable but emphasizes the importance of acknowledging this aspect. However, the comment does not provide specific examples, references, or detailed reasoning to support why this is crucial or how it impacts the results. The lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the significance of this point themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should highlight the data-dependent nature of their approximation results, specifically mentioning the covariance spectrum. This is a clear and actionable suggestion that could help the authors improve the clarity and transparency of their work. By emphasizing this aspect, the authors can provide a more accurate representation of their findings and their limitations. However, the comment could be more helpful if it provided additional context or examples of how this should be incorporated into the abstract or other sections of the paper. Overall, the comment is mostly helpful as it offers a specific and actionable piece of feedback that can enhance the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification regarding the meaning of RMSD in Figure 3. It provides two possible interpretations and requests that the authors clarify which one is correct. This feedback is direct and concrete, as it clearly identifies the action needed and provides specific guidance on how to address the issue. The authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified regarding the meaning of RMSD in Figure 3, providing two possible interpretations and asking the authors to clarify which one is correct. This level of detail guides the authors on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the meaning of RMSD in Figure 3, specifically asking whether it refers to the RMSD between a docking pose and the ground truth from PDB or between docking poses obtained with different methods to quantify consensus. This is a factual question seeking clarification rather than an opinion or claim that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area of confusion in the paper, namely the meaning of RMSD in Figure 3. By asking for clarification on whether it refers to the RMSD between a docking pose and the ground truth from PDB or between docking poses obtained with different methods, the reviewer provides a clear direction for the authors to improve their draft. However, the comment could be more helpful if it offered suggestions on how to present this information or why it is important for the reader to understand. Overall, the feedback is actionable but could be more comprehensive, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds. It explicitly asks the authors to consider whether there could be a smooth regret scaling without phase transitions that still holds the proven bounds. This provides a clear and direct action for the authors to take, as it specifies what aspect of the paper needs further exploration and analysis. The comment is explicit and concrete, offering a specific direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds. It explicitly mentions the need to address the question of whether there could be a smooth regret scaling without phase transitions that still holds the proven bounds. This provides clear guidance on what needs to be addressed, making the comment fully grounded as it specifies the part of the paper being addressed. The comment is also specific because it details what needs to be addressed, namely the necessity of phase transitions in the \"actual regret scaling.\" Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should provide a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds. It questions whether there could be a smooth regret scaling without phase transitions that still holds the proven bounds. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a specific area for improvement by recommending a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds. It poses a question about whether there could be a smooth regret scaling without phase transitions that still holds the proven bounds. This feedback is clear and actionable, as it directs the authors to explore and address a particular aspect of their work that could enhance the paper\\'s depth and rigor. However, the comment could be more helpful if it provided additional guidance on how to approach this analysis or what specific aspects to consider. Overall, the comment is mostly helpful, as it offers a valuable direction for improvement but could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a comparison to previous robust reinforcement learning (RL) methods, even though they are cited. It explicitly instructs the authors to be explicit about whether GAD or EG already include these prior works. This feedback is clear and provides a direct action for the authors to take, making it highly actionable. The authors know exactly what needs to be done to address the comment, which is to include a comparison or clarify the relationship with previous works. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks a comparison to previous robust reinforcement learning (RL) methods, despite citing them (e.g., RARL). It explicitly instructs the authors to be explicit about whether GAD or EG already include these prior works. This provides clear guidance on what needs to be addressed, making the comment fully grounded as it specifies the parts of the paper related to the comparison and the need for explicit inclusion. The comment is also specific because it details the issue of missing comparisons and requests explicit clarification. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison to previous robust reinforcement learning (RL) methods, despite citing them. The reviewer provides a specific example of RARL, which supports the claim. However, the comment could be strengthened by explaining why these comparisons are important or how they would enhance the paper. The mention of \"if either GAD or EG already include these prior works, please be explicit\" adds a request for clarification but does not fully address the initial claim. Overall, the comment is mostly verifiable, as it provides a clear basis for the claim but could benefit from additional reasoning or examples to fully substantiate it.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper by noting that comparisons to previous robust reinforcement learning (RL) methods are missing, despite these methods being cited. It suggests that the authors should either include these comparisons or clarify whether GAD or EG already incorporate these prior works. This feedback is clear and actionable, as it directs the authors to either expand their analysis or provide explicit connections to existing work. By addressing this point, the authors can enhance the comprehensiveness and rigor of their paper. Therefore, the comment is rated as mostly helpful, as it provides valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should provide more details about the choice of $k_1, k_2, k_3$, the networks, and the learning objectives. This is a clear and direct action for the authors to take, as it specifies exactly what additional information should be included in the draft. The comment provides concrete guidance on what needs to be addressed, making it highly actionable. Therefore, the comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more details should be provided about the choice of $k_1, k_2, k_3$, the networks, and the learning objectives. However, it does not specify which part of the paper these details should be added to, making it weakly grounded. The comment is specific in identifying what needs to be addressed, namely the lack of details about these specific elements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details should be provided about the choice of $k_1, k_2, k_3$, the networks, and the learning objectives. However, it does not provide any reasoning or evidence to support why these details are necessary or how they would improve the paper. Without additional context or justification, the authors may find it challenging to understand the importance of these details or how to address the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks detail, namely the choice of $k_1, k_2, k_3$, the networks, and the learning objectives. By pointing out this gap, the comment provides the authors with a clear direction for improvement, suggesting that they should include more information about these aspects. This feedback is actionable and helps the authors enhance the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it offered suggestions on how to present this information or why it is important. Overall, the comment is mostly helpful as it directs the authors to a specific area needing expansion, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relationship between HIS and the negative inverse of mean response time. However, it does not provide any explicit or implicit action for the authors to take. There is no suggestion for how the authors might address this question or clarify the relationship in their draft. Without guidance or direction, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the relationship between HIS and the negative inverse of mean response time, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to a specific section or figure discussing HIS, but without explicit grounding, it is challenging to pinpoint the exact location. The comment is specific in questioning the relationship, but it lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the relationship between HIS and the negative inverse of mean response time. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the relationship between HIS and the negative inverse of mean response time, indicating a potential misunderstanding or lack of clarity in the paper. However, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the relationship in their draft. Without actionable feedback or specific advice, the comment offers limited value to the authors in terms of improving their work. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and concerns about the choice of sparse representation learning method and the comparison of FTA in different settings. It explicitly asks for a justification of the chosen method and suggests comparing FTA as a baseline in both supervised learning and reinforcement learning settings. The comment also emphasizes the importance of a rigorous comparison in an empirical paper. While the feedback is clear in its requests for justification and comparison, it does not provide specific guidance on how to conduct these comparisons or what aspects to focus on. The action is explicit but somewhat vague in terms of execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several points, including the choice of sparse representation learning method and the comparison of FTA in different settings. It explicitly mentions the \"experiments part,\" providing full grounding as the authors can accurately identify the section being addressed. The comment is specific in its requests for justification of the chosen method and for a rigorous comparison of FTA in both supervised learning and reinforcement learning settings. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several claims, including the need for justification of the chosen sparse representation learning method and the necessity of comparing FTA as a baseline in both supervised and reinforcement learning settings. The reviewer provides logical reasoning by pointing out the importance of a rigorous comparison in an empirical paper. However, the comment lacks specific examples or references to support the claim that the current comparison is insufficient. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several important points that could help the authors improve their draft. It questions the choice of the particular sparse representation learning method, suggesting that a justification for this choice is necessary. Additionally, it points out the inconsistency in comparing FTA in a supervised learning setting but not in a reinforcement learning setting, emphasizing the need for a rigorous comparison. This feedback is clear and actionable, as it identifies specific areas for improvement and provides a logical rationale for why these comparisons are important. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to conduct a more comprehensive comparison. Overall, the comment is mostly helpful, as it directs the authors to important aspects of their work that require clarification and expansion.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific issue on page 4, line 154, where the authors describe a particular choice of shift and scaling but fail to explain why it is the more appropriate choice. The comment clearly instructs the authors to provide an explanation for this choice, which is a direct and concrete action. By specifying the exact location and the nature of the issue, the authors know exactly what needs to be addressed in their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"p.4, l.154,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of explanation for a particular choice of shift and scaling, which is described as \"the more appropriate.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors neglect to explain why a particular choice of shift and scaling is considered more appropriate. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, namely the lack of explanation for a particular choice of shift and scaling described on page 4, line 154. It points out that the authors claim this choice is more appropriate but do not provide any justification or reasoning for this assertion. This feedback is clear and actionable, as it directs the authors to address the gap in their explanation, which could enhance the clarity and credibility of their work. However, the comment could be more helpful if it suggested ways to provide this explanation or offered examples of how similar choices have been justified in other contexts. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests revising the use of \"partial inference of GFlowNets\" in the title and \"partial inference\" elsewhere. This is a direct and clear action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment leaves no ambiguity about what needs to be changed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of \"partial inference of GFlowNets\" in the title and \"partial inference\" elsewhere, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the terminology used, suggesting a revision to improve clarity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses a subjective opinion about the use of \"partial inference of GFlowNets\" in the title and elsewhere, suggesting that it should be revised. However, the comment does not provide any reasoning or justification for why this term is problematic or how it could be improved. Without supporting evidence or explanation, the claim remains unverifiable, as the authors are left without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the terminology used in the title and elsewhere in the paper, suggesting that \"partial inference of GFlowNets\" should be revised. This feedback is clear and actionable, as it provides a direct suggestion for improvement that can enhance the clarity and accuracy of the paper. However, the comment could be more helpful if it offered additional context or explanation for why this change is necessary or how it might impact the paper\\'s content. Despite this, the comment is mostly helpful as it guides the authors toward a specific improvement that can enhance the quality of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper, noting that it only measures BERTScore to assess the similarity of newly generated text and fails to discuss other metrics that could measure stealthiness. While the comment identifies a gap in the paper, it does not provide explicit guidance on which specific metrics should be considered or how to incorporate them into the analysis. The action is implicit and somewhat vague, as the authors are left to infer that they should explore additional metrics but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s reliance on BERTScore to measure the similarity of newly generated text and suggests that other metrics could be used to assess stealthiness. However, it does not specify which part of the paper this critique pertains to, such as a particular section or table where BERTScore is discussed. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in suggesting alternative metrics but lacks grounding, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper only uses BERTScore to measure the similarity of newly generated text and suggests that other metrics could be used to assess stealthiness. However, the comment does not provide specific examples or references to alternative metrics that could be used, nor does it explain why these metrics are more appropriate. This lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to conduct additional research to understand the suggested alternatives. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper by noting that it only uses BERTScore to measure the similarity of newly generated text, without discussing other metrics that could assess stealthiness. This feedback is somewhat helpful as it points out a gap in the analysis, suggesting that the authors should consider additional metrics to provide a more comprehensive evaluation. However, the comment lacks specific suggestions or examples of alternative metrics that could be used, which would make it more actionable and helpful. To be fully helpful, the comment could include recommendations or references to specific metrics that could enhance the analysis. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the notation and clarity of the paper. It explicitly states that the basic notation is not defined and that the authors need to clearly highlight the issues with existing estimators. The comment also provides specific examples of notation that are unclear, such as the dimensionality p, the unit ball S p, and the constant d 2. Additionally, it suggests that the authors should clarify the heuristic nature of Algorithm 1. While the comment identifies specific areas for improvement, it does not provide detailed guidance on how to address these issues. The actions are explicit but somewhat vague, as the authors know what needs to be clarified but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"p.2 or Eq. 3,\" \"Alg. 1,\" \"Alg. 2,\" \"Thm. 2, Eq. 5,\" and \"p. 2,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it details the issues with the notation, such as the lack of definition for \"p,\" \"S p,\" and \"d 2,\" and requests clarification on the heuristic nature of Algorithm 1. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several claims about the clarity and notation of the paper. It points out that the basic notation is not defined and that the authors need to clearly highlight the issues with existing estimators. The comment also questions the clarity of specific terms like \"dimensionality p,\" \"unit ball S p,\" and \"constant d 2,\" suggesting that these are not well-explained. Additionally, it requests clarification on the heuristic nature of Algorithm 1. While the comment identifies areas that need clarification, it does not provide specific examples or references to support these claims, making it somewhat verifiable. The authors would need to infer the exact issues and how to address them, which aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the clarity and notation of the paper, specifically pointing out that the basic notation is not defined. It provides examples of unclear terms, such as \"dimensionality p,\" \"unit ball S p,\" and \"constant d 2,\" and requests clarification on the heuristic nature of Algorithm 1. This feedback is valuable as it highlights specific areas where the authors need to improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to clarify the notation. Overall, the comment is mostly helpful as it directs the authors to focus on improving the clarity and notation of their paper, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should elaborate on which parts of the loss functions are new, as the paper claims that two of the perceptual loss functions are novel. This feedback is explicit, as it clearly states what action the authors need to take to improve their draft. However, it is somewhat vague because it does not provide specific guidance on how to elaborate on the new aspects of the loss functions. The authors know they need to provide more detail, but the comment does not specify what exactly should be included. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the claim is made, allowing the authors to accurately identify the section being addressed. It also specifies the issue by pointing out that the paper claims two perceptual loss functions are new, while the neural network and loss functions used are not novel in the field of medical imaging. The comment suggests that the authors should elaborate on which parts of the loss functions are new. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s assertion about new perceptual loss functions is not substantiated, as the neural network and loss functions used are not novel in the field of medical imaging. The comment suggests that the authors should elaborate on which parts of the loss functions are new. However, the review does not provide specific examples or references to support the claim that the loss functions are not novel, making it somewhat verifiable. The authors would need to investigate further to understand the basis of the claim and provide evidence to support their assertions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s claim about the novelty of the perceptual loss functions used. It points out that the neural network and loss functions mentioned are not entirely new in the field of medical imaging, which could undermine the paper\\'s assertion of novelty. The comment suggests that the authors should elaborate on which parts of the loss functions are indeed new, providing a clear and actionable direction for improvement. This feedback is valuable as it prompts the authors to clarify and substantiate their claims, which can enhance the credibility and originality of their work. However, the comment could be more helpful if it offered specific examples or references to support the claim of novelty. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the experimental results, noting that they justify theoretical statements but do not show significant improvements in real-life datasets. It also critiques the comparison on the ZINC dataset, specifically mentioning Table 5 in reference [1]. While the comment identifies areas for improvement, it does not provide explicit guidance on how the authors should address these issues or suggest specific changes to make the experimental results more meaningful. The action is implicit and somewhat vague, as the authors can infer that they need to enhance the experimental results and improve the comparison on the ZINC dataset, but they are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Experimental Results\" and references \"Table 5 in [1],\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental results, noting that they do not exhibit significant improvements in real-life datasets and critiques the comparison on the ZINC dataset. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results do not show significant improvements in real-life datasets, similar to many GNN papers. It also critiques the comparison on the ZINC dataset, specifically mentioning Table 5 in reference [1]. While the comment provides some context and references a specific table, it lacks detailed reasoning or examples to fully substantiate the claim. The mention of \"many GNN papers\" suggests a general trend, but without specific examples or references to those papers, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that they justify theoretical statements but do not demonstrate significant improvements in real-life datasets. It also critiques the comparison on the ZINC dataset, suggesting that it is lacking. This feedback is clear and actionable, as it directs the authors to enhance the experimental results and improve the comparison on the ZINC dataset. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of better comparisons. Overall, the comment is mostly helpful as it highlights important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the performance of the SLM (Small Language Model) is convincing only if it outperforms larger models due to data limitations. However, it provides an example from Figure 3, where larger models perform better than smaller ones. This feedback implies that the authors should consider the performance of larger models in comparison to the SLM, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should compare the performance of the SLM with larger models. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3 (b) LucaOne performs better than BSM models, and BSM-270M model performs better than BSM-110M model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear example of how larger models perform better than smaller ones, which is a critical point for the authors to consider in their analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that larger models perform better than smaller ones, citing specific examples from Figure 3. This claim is supported by the examples provided, which demonstrate that larger models outperform smaller ones. The inclusion of specific references to the figure and the models being compared provides a clear and logical basis for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides a specific critique of the paper\\'s claim that the Small Language Model (SLM) performs better than larger models due to data limitations. It challenges this assertion by referencing experiments shown in Figure 3, where larger models (such as LucaOne and BSM-270M) outperform smaller models (like BSM-110M). This feedback is helpful as it prompts the authors to reconsider their claims and potentially revise their conclusions based on the evidence presented. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context for the authors to improve their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights inconsistencies in the notation used in the paper, specifically mentioning issues with the notation \"nu\" and its usage across different figures and an algorithm. However, it does not provide explicit guidance on how to address these inconsistencies or suggest specific actions for the authors to take. The comment implies that the authors should ensure consistency in their notation, but it lacks concrete details on how to achieve this. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as Figures 2 & 3, Algorithm 1, Page 4, and Figure 4, allowing the authors to accurately identify the sections being addressed. It is also specific because it details the issue of inconsistent notation, particularly with the use of \"nu,\" and provides examples of where this inconsistency occurs. This level of detail helps the authors understand what needs to be addressed to improve the clarity and consistency of their notation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation is inconsistent, specifically mentioning issues with the notation \"nu\" across different figures and an algorithm. However, the comment does not provide specific examples or detailed explanations of where these inconsistencies occur, making it difficult for the authors to understand and address the issue. Without additional context or references, the claim lacks sufficient support, rendering it barely verifiable. Therefore, the comment is classified as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation used in the paper, pointing out inconsistencies in the use of \"nu\" across different figures and an algorithm. This feedback is clear and actionable, as it directs the authors to review and standardize their notation to ensure consistency throughout the paper. However, the comment could be more helpful if it provided suggestions on how to achieve this consistency or offered examples of how to present the notation in a more coherent manner. Despite this, the comment still provides valuable guidance for improving the clarity and readability of the paper, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting more experiments in challenging tasks, specifically mentioning dexterous manipulations in Adroit. While it implies that the authors should conduct additional experiments, it does not provide specific guidance on how to implement these experiments or what aspects to focus on. The suggestion is explicit but lacks concrete details, making it somewhat actionable. The authors know they need to conduct more experiments but may not be entirely sure of the exact steps to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments in challenging tasks, specifically mentioning dexterous manipulations in Adroit. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs revision. The comment is specific in suggesting the type of experiments to conduct, but without grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting more experiments in challenging tasks, such as dexterous manipulations in Adroit, to validate the effectiveness of the proposed method. The suggestion is based on a specific reference to Adroit, which provides a concrete example of a challenging task. However, the comment lacks detailed reasoning or examples of how these experiments would improve the paper or what specific aspects of the method need validation. While the reference to Adroit adds some context, the claim is mostly verifiable as it provides a clear direction for further experimentation but lacks detailed justification or examples. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests conducting more experiments in challenging tasks, such as dexterous manipulations in Adroit, to validate the effectiveness of the proposed method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the robustness and applicability of their work. By referencing a specific challenging task, the comment offers a concrete suggestion for improving the paper, which is highly beneficial for the authors. However, the comment could be more helpful if it included additional guidance on how to design or interpret these experiments. Overall, the comment is highly helpful as it provides a clear and actionable suggestion for improving the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the summary in the introduction, specifically regarding the assumptions made by certain papers. It questions whether the assumption about the feature direction acting as a perfect linear classifier is stronger than the assumption of linear separability. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the fairness of the summary. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"introduction\" and references specific papers (Williams et al., 2019; Lyu et al., 2021; Boursier et al., 2022; Wang & Ma, 2023), allowing the authors to accurately identify the part of the paper being addressed. It also raises a specific concern about the fairness of the summary, questioning the assumptions made by these papers and asking for clarification on a particular assumption. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the fairness of the summary in the introduction, specifically regarding the assumptions made by certain papers. It questions whether the assumption about the feature direction acting as a perfect linear classifier is stronger than the assumption of linear separability. The comment provides specific references to papers and asks for clarification on a particular assumption, which is a logical and reasonable request. However, it does not provide detailed reasoning or evidence to fully substantiate the claim of unfairness. Therefore, the comment is mostly verifiable, as it provides a clear direction for the authors to address but lacks comprehensive justification. This aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a specific concern about the fairness of the summary in the introduction, particularly regarding the assumptions made by certain papers. It points out that some papers assume linear separability, while others make an even stronger assumption about the feature direction acting as a perfect linear classifier. The comment questions whether this stronger assumption is being referred to as orthogonally separable data, providing a clear area for the authors to clarify or address in their summary. This feedback is mostly helpful as it identifies a potential issue with the summary and suggests a specific area for improvement, guiding the authors to ensure the accuracy and fairness of their summary. However, it could be more helpful if it provided additional context or examples to further clarify the issue. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the paper\\'s per-sample weight tuning method, which relies on the influence function. It explains that the influence function\\'s explanation holds only when the upweight is very close to 0, and otherwise, the theoretical approximation of each sample\\'s contribution is not valid. The reviewer suggests that if the weights are far away from 0 during training iterations, the influence function might not accurately reflect each sample\\'s influence, leading to unreliable weights. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this problem or suggest specific actions to take. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the impact of non-zero weights on the influence function and consider alternative methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"per-sample weight tuning method\" and the \"influence function,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the influence function, explaining that its explanation holds only when the upweight is very close to 0. The comment further specifies the potential problem with the influence function not reflecting each sample\\'s influence correctly when weights are far away from 0 during training iterations. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s per-sample weight tuning method relies on the influence function, but the explanation of the influence function is only valid when the upweight is very close to 0. The reviewer provides a logical explanation of why the influence function might not accurately reflect each sample\\'s influence when the weights are far away from 0 during training iterations. This reasoning is based on the theoretical approximation of each sample\\'s contribution from Taylor\\'s first-order expansion, which is a common mathematical concept. The comment provides a clear and logical argument, making it mostly verifiable. However, it could be strengthened by including specific examples or references to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s per-sample weight tuning method, which relies on the influence function. It explains that the influence function\\'s explanation is only valid when the upweight is very close to 0, and otherwise, the theoretical approximation of each sample\\'s contribution is not valid. This provides the authors with a clear understanding of a potential limitation in their method. However, the comment could be more helpful by suggesting alternative approaches or methods that might address this issue. While it highlights a critical area for improvement, the feedback lacks actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with centering in partial shapes or scenes, suggesting that it may not be well-defined in these contexts. The reviewer implies that the authors should address this issue, but does not provide specific guidance on how to do so. While the comment identifies a problem, it lacks concrete steps or suggestions for improvement, leaving the authors uncertain about how to address the issue. Therefore, the comment is somewhat actionable, as it points out a potential problem but does not provide detailed instructions on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of centering in partial shapes and scenes, suggesting that it may not be well-defined in these contexts. It implies that the authors should address this issue, but it does not specify which part of the paper this concern relates to, making it weakly grounded. However, the comment is specific in detailing the problem with centering in partial shapes and scenes, particularly in the context of training with partial shapes. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the applicability of centering in partial shapes or scenes, suggesting that it may not be well-defined in these contexts. The reviewer provides a logical reasoning by explaining that while centering can be effective for complete shapes, it may not be suitable for partial shapes or scenes. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to consider this issue and potentially provide additional evidence or reasoning to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the applicability of centering in partial shapes or scenes, suggesting that it may not be well-defined in these contexts. It highlights the need for the authors to address this concern, which is a valuable insight for improving the draft. However, the comment could be more helpful if it provided specific suggestions or examples on how the authors might address this issue, such as proposing alternative methods or discussing potential implications. While it points out a relevant area for improvement, the feedback is somewhat helpful as it lacks depth and actionable guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests an experiment to ensemble models trained with and without the proposed negative augmentations to see if it improves performance. While the comment implies an action, it does not provide explicit instructions on how to conduct this experiment or what specific metrics to use for evaluation. The authors can infer that they need to conduct an ensemble experiment, but the lack of detailed guidance makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment refers to the paper\\'s proposal to learn less about texture semantics by adding negative samples that share the texture semantics with anchor images. It suggests an experiment to ensemble models trained with and without the proposed negative augmentations to see if it improves performance. However, the comment does not specify which part of the paper discusses this proposal, making it weakly grounded. The suggestion to ensemble models is specific, as it provides a clear direction for potential improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper\\'s approach to learning less about texture semantics by adding negative samples may not be fully effective, as texture semantics can still be beneficial in certain cases. The reviewer references a similar approach in [1] and suggests trying to ensemble models trained with and without the proposed negative augmentations to see if it improves performance. While the comment provides a logical reasoning and a suggestion for further experimentation, it lacks specific details or references to support the claim fully. Therefore, the comment is somewhat verifiable, as it provides a basis for the suggestion but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a constructive suggestion for improving the paper by proposing an experiment to ensemble models trained with and without the negative augmentations. This feedback is actionable and offers a clear direction for the authors to explore, which could potentially enhance the performance of their approach. However, the comment could be more helpful if it provided additional context or reasoning behind why this ensemble approach might be beneficial or how it could address specific challenges in the paper. Despite this, the suggestion is clear and provides a valuable direction for the authors to consider, making the comment mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the guarantee of D_i sufficiently going through all possible transition probabilities, referencing page 6 and the claim of sample efficiency on page 5 and in Appendix B. While it highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The comment lacks concrete details on what steps the authors should take to ensure that D_i covers all transition probabilities, making it vague and implicit. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific pages (6, 5, and Appendix B) and equations (Eq. 7), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the guarantee that D_i sufficiently goes through all possible transition probabilities, which is a clear and specific concern. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the guarantee that D_i sufficiently goes through all possible transition probabilities, referencing specific pages and equations. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the question, rendering the comment unverifiable. Therefore, it aligns with a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the guarantee that D_i sufficiently goes through all possible transition probabilities, referencing specific pages and equations. This is a relevant concern that could impact the validity and reliability of the results presented in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their analysis. While it identifies a potential weakness, it lacks actionable feedback, making it somewhat helpful. The authors are left with a clear question to consider but without specific steps to take to resolve it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the method used to form clusters for tokens in Figure 1, noting that it is unclear in Section 3. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this lack of clarity. The action is implicit, as the authors need to infer that they should clarify the clustering method in Section 3. However, the comment lacks concrete details on how to improve the clarity, making it somewhat actionable. The authors know they need to clarify the clustering method but may not be entirely sure of the best way to do so. Therefore, this comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of unclear clustering methods for tokens, prompting the authors to clarify this aspect. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the method used to form clusters for tokens in Figure 1, noting that it is unclear in Section 3. This is a factual statement seeking clarification, as it does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the method used to form clusters for tokens in Figure 1, noting that it is unclear in Section 3. This feedback is clear and actionable, as it directs the authors to clarify a particular aspect of their methodology that may be confusing to readers. By addressing this question, the authors can improve the clarity and transparency of their work, making the comment mostly helpful. However, it could be more helpful if it provided additional guidance on how to clarify the clustering method or suggested potential sources of confusion. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of SimNPO, specifically the introduction of two additional hyperparameters that require manual adjustment for optimal performance. It notes that this increases the complexity and time cost of experiments, which could limit the method\\'s applicability in real-world settings for large language models. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue, such as recommending alternative methods for hyperparameter tuning or suggesting ways to simplify the process. Without actionable guidance, the authors are left without a clear path forward to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of SimNPO introducing two additional hyperparameters that require manual adjustment, which increases the complexity and time cost of experiments. However, it does not specify which part of the paper discusses these hyperparameters or where the authors should address this issue. The authors can make an educated guess that it relates to the methodology or experimental setup sections, but the comment lacks full grounding. It is specific in detailing the problem with the hyperparameters but does not provide guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that SimNPO introduces two additional hyperparameters that must be manually adjusted, increasing the complexity and time cost of experiments. This claim is somewhat verifiable as it provides a logical reasoning about the potential impact of additional hyperparameters on the complexity and time cost of experiments. However, the comment lacks specific examples or references to support the claim, such as detailed descriptions of the hyperparameters or examples of how they affect the experiments. Providing more detailed evidence or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant limitation of SimNPO, specifically the introduction of two additional hyperparameters that require manual adjustment for optimal performance. This increases the complexity and time cost of experiments, potentially limiting the method's applicability in real-world settings for large language models. While the comment highlights a critical issue, it does not provide specific suggestions or guidance on how the authors might address this problem, such as recommending alternative methods for hyperparameter tuning or suggesting ways to simplify the process. Without actionable feedback, the authors are left with a clear understanding of the issue but without a clear path forward to improve their draft. Therefore, the comment is somewhat helpful, as it identifies a significant weakness but lacks depth and actionable advice.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the emphasis on affordance prompting, suggesting that it is overengineered and does not adequately demonstrate its advantages. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve the demonstration of affordance prompting. The comment lacks explicit instructions or concrete details on what changes should be made, leaving the authors uncertain about how to implement the suggested improvements. As a result, the comment is vague and does not offer actionable steps for the authors to follow. Therefore, it is rated as a 2: Borderline Actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the emphasis on affordance prompting, suggesting that it is overengineered and does not adequately demonstrate its advantages. It provides a specific example, \"Pick&place example,\" which implies that the comment is addressing the section or example related to this topic. However, the comment does not explicitly mention the section or page number, making it weakly grounded. The comment is specific in detailing what is lacking in the demonstration of affordance prompting, but without explicit references, the authors may have difficulty pinpointing the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work places too much emphasis on affordance prompting, which is overengineered, and that the \"Pick&place example\" does not adequately demonstrate the advantage of affordance prompting. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the critique effectively. Therefore, the claim is considered borderline verifiable, as it provides some basis for the critique but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the emphasis on affordance prompting, suggesting that it is overengineered and does not adequately demonstrate its advantages. It provides a concrete example, \"Pick&place example,\" which highlights a particular instance where the advantage of affordance prompting is not sufficiently shown. This feedback is clear and actionable, as it directs the authors to revisit their approach to affordance prompting and ensure that it is effectively demonstrated. However, the comment could be more helpful if it offered suggestions on how to improve the demonstration or provided additional context for understanding the critique. Overall, the comment is mostly helpful, as it provides valuable insights for improving the draft, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that ablation studies are necessary to demonstrate the importance of each component in the proposed algorithmic pipeline. This is an explicit action that the authors need to take to improve their draft. The comment clearly indicates what needs to be done, which is to conduct ablation studies to validate the necessity of each part of the methodology. The action is concrete, as it specifies a particular type of study that should be performed, providing the authors with clear guidance on how to enhance their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that ablation studies are needed to demonstrate the necessity of each component in the proposed algorithmic pipeline. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs improvement. The comment is specific in its request for ablation studies, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that ablation studies are necessary to demonstrate the importance of each component in the proposed algorithmic pipeline. This claim is somewhat verifiable as it provides a logical reasoning for the need of ablation studies to validate the necessity of each part of the methodology. However, the comment lacks specific examples or references to support the claim, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that ablation studies are necessary to demonstrate the importance of each component in the proposed algorithmic pipeline. This is a clear and actionable suggestion that can help the authors strengthen their work by providing evidence for the necessity of each part of the methodology. By conducting ablation studies, the authors can better understand the impact of each component and make more informed decisions about their approach. However, the comment could be more helpful if it provided specific guidance on how to design and interpret the ablation studies. Overall, the feedback is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the necessity of the instruction-tuning stage in MoE models, suggesting that the performance improvement could be attributed to the additional training cost rather than the instruction-tuning stage itself. The reviewer asks a question about whether the performance improvement could come from the extra training cost, implying that the authors should consider this possibility and address it in their analysis. While the comment does not explicitly instruct the authors to conduct a specific analysis or experiment, it provides a clear direction for further investigation. The action is implicit but concrete, as the authors know they need to explore this possibility and consider its impact on their conclusions. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the conclusion about the necessity of the instruction-tuning stage in MoE models, suggesting that the performance improvement could be attributed to the additional training cost rather than the instruction-tuning stage itself. However, it does not specify which part of the paper discusses this conclusion, making it weakly grounded. The comment is specific in detailing the issue with the conclusion and suggesting an alternative explanation for the performance improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the necessity of the instruction-tuning stage in MoE models, suggesting that the performance improvement could be attributed to the additional training cost rather than the instruction-tuning stage itself. The reviewer provides a logical reasoning by pointing out the potential impact of extra training costs on performance. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to consider this perspective and potentially conduct additional analysis to address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the necessity of the instruction-tuning stage in MoE models, suggesting that the performance improvement could be attributed to the additional training cost rather than the instruction-tuning stage itself. This is a critical point that the authors should address to strengthen their argument. The comment provides a specific example of how the extra training cost could impact performance, which is a valuable insight for the authors to consider. However, the comment could be more helpful if it offered suggestions on how to differentiate between the effects of instruction-tuning and additional training costs. Overall, the comment is mostly helpful as it identifies a potential weakness in the paper and prompts the authors to consider an alternative explanation for their findings.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the evaluation setup is outdated and suggests updating it by testing the approach on more challenging and representative fine-tuning setups, such as instruction tuning on Alpaca/OASST or other instruction fine-tuning datasets. The comment provides specific examples of newer models and datasets that could be used for evaluation, offering concrete guidance on how to improve the draft. This level of detail and explicit suggestion makes the comment highly actionable, as the authors know exactly what steps to take to enhance their evaluation setup.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"evaluation setup\" and references specific models and datasets, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the evaluation setup being outdated and suggests updating it by testing the approach on more challenging and representative fine-tuning setups, such as instruction tuning on Alpaca/OASST or other instruction fine-tuning datasets. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation setup is outdated, citing the release of newer models (Llama-3, Llama-3.1, Qwen-2.5, gemma-2) and the advancement in quality since the last evaluation. The suggestion to test the approach on a more challenging and representative fine-tuning setup, such as instruction tuning on Alpaca/OASST, is also provided. While the comment provides some justification by referencing the release of newer models, it lacks specific examples or detailed reasoning to fully substantiate the claim about the outdated evaluation setup. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the evaluation setup, noting that it is outdated due to the release of newer models and advancements in quality. It suggests updating the evaluation by testing the approach on more challenging and representative fine-tuning setups, such as instruction tuning on Alpaca/OASST or other instruction fine-tuning datasets. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance the validity and comprehensiveness of their evaluation. By addressing this feedback, the authors can significantly improve the robustness and relevance of their results, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of logical coherence in the second section, which results in a somewhat disorganized content. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the logical coherence or organize the content, leaving the authors without a clear path for improvement. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions the \"second section\" where many related works are presented, indicating that it is addressing a specific part of the paper. However, it does not specify what aspects of the content are disorganized or how the lack of logical coherence manifests. This makes it weakly grounded, as the authors can infer the general area but not the exact parts needing attention. The comment is also not specific because it lacks detailed guidance on how to improve the organization or logical coherence. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the second section lacks logical coherence, resulting in disorganized content. However, it does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the logical coherence is lacking, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the organization of the second section, noting that while many related works are presented, the content lacks logical coherence, resulting in a somewhat disorganized presentation. However, it does not provide any actionable suggestions or guidance on how the authors might improve the logical coherence or organization of the content. Without specific advice or examples, the authors are left without a clear path for improvement, making the comment somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to mention the language they focus on for retrieving Reddit posts. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be added, making it highly actionable. The authors know exactly what to do to address the comment, which aligns with the criteria for a highly actionable comment.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to specify the language used for retrieving Reddit posts, allowing the authors to accurately identify the part of the paper that needs revision. It is also specific because it clearly specifies what needs to be addressed, which is the mention of the language used for retrieval. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification, asking the authors to specify the language used for retrieving Reddit posts. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and direct, requesting that the authors specify the language they focus on for retrieving Reddit posts. This feedback is actionable and provides a specific point for the authors to address, which can help improve the clarity and completeness of their draft. However, the comment could be more helpful if it provided additional context or explained why specifying the language is important. Despite this, the feedback is mostly helpful as it guides the authors toward a specific improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of comparisons with recent works, specifically mentioning reference [1]. However, it does not provide explicit guidance on how the authors should incorporate these comparisons or which specific aspects of the recent works should be considered. The action is implicit, as the authors need to infer that they should include comparisons, but it lacks concrete details on how to execute this action. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment mentions the lack of comparisons with recent works, specifically referencing \"[1],\" which suggests that the reviewer is pointing out a specific area for improvement. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table where comparisons should be included. The authors can infer that it relates to the discussion or results sections, but the comment lacks full grounding. It is specific in identifying the need for comparisons with recent works, but without explicit references to sections or specific elements, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks comparisons with recent works, specifically mentioning reference [1]. However, the comment does not provide any further explanation or justification for why these comparisons are necessary or how they would enhance the paper. Without additional context or reasoning, the claim remains vague and lacks sufficient support, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a significant gap in the paper by noting the lack of comparisons with recent works, specifically mentioning reference [1]. This feedback is important as it highlights an area where the paper could be strengthened by incorporating relevant comparisons to contextualize the findings and contributions. However, the comment lacks specificity and does not provide guidance on which aspects of the recent works should be compared or how these comparisons could be integrated into the paper. While it identifies a critical area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but requires more detailed guidance to be fully actionable.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether TSG (Temporal Scheduling Graph) would work in diffusion models that do not embed class labels into timesteps, specifically mentioning UViT as an example. However, it does not provide any explicit or implicit actions for the authors to take. The question is posed without suggesting any modifications or improvements to the draft, leaving the authors without a clear path forward. As a result, the comment lacks actionability and is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of TSG in diffusion models that do not embed class labels into timesteps, specifically mentioning UViT as an example. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry but lacks grounding, as it does not reference a particular section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification on the applicability of TSG in diffusion models that do not embed class labels into timesteps, specifically mentioning UViT as an example. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the applicability of TSG (Temporal Scheduling Graph) in diffusion models that do not embed class labels into timesteps, specifically mentioning UViT as an example. While it highlights a potential limitation or area for further exploration, it does not provide any specific guidance or suggestions for the authors to address this issue. The comment lacks depth and actionable feedback, leaving the authors with a vague understanding of what needs to be considered. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the authors should release their training code, dialogue dataset, and model checkpoints to improve reproducibility. It also suggests attaching these materials via anonymous repositories in the paper submission. This provides clear and concrete guidance on what the authors need to do to address the issue of limited reproducibility. The comment is explicit and detailed, leaving no ambiguity about the actions required. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of limited reproducibility, specifically mentioning the need for the authors to release their training code, dialogue dataset, and model checkpoints. It suggests attaching these materials via anonymous repositories in the paper submission. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these elements are typically discussed. The comment is specific in detailing what needs to be addressed to improve reproducibility, making it weakly grounded but specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper has \"very limited reproducibility\" due to the lack of availability of the training code, dialogue dataset, and model checkpoints. The reviewer suggests that releasing these materials via anonymous repositories would allow reviewers to verify the claims and try out the model. This claim is somewhat verifiable as it provides a logical reasoning for the need for reproducibility and suggests a specific action to improve it. However, the comment lacks specific examples or references to support the claim of limited reproducibility, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s reproducibility, noting that the lack of access to the training code, dialogue dataset, and model checkpoints makes it challenging for reviewers to verify the claims. The reviewer provides a clear and actionable suggestion by encouraging the authors to release these materials via anonymous repositories in the paper submission. This feedback is highly valuable as it directly addresses a critical aspect of the paper\\'s quality and provides a concrete step for improvement. By following this advice, the authors can significantly enhance the transparency and credibility of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the main result is obvious because gradient boosting minimizes objectives in functional space. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or improve the clarity of the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the main result is obvious because gradient boosting minimizes objectives in functional space. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to identify the exact section or result being addressed. Additionally, the comment lacks specificity regarding what aspects of the result are considered obvious or how this observation could be improved. Without clear grounding or specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the main result is \"a bit obvious\" because gradient boosting minimizes objectives in functional space. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without further explanation or examples, the authors may find it challenging to understand the basis of the reviewer\\'s assertion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the main result is obvious because gradient boosting minimizes objectives in functional space. However, it does not provide any specific feedback or suggestions on how the authors could address this observation or improve the clarity of their results. Without actionable guidance or constructive feedback, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point criticizes the paper for insufficient contribution, lack of explicit expression of the contribution, and inadequate explanation of the proposed model. It also mentions limited related work and the absence of appropriate analysis. However, the comment does not provide specific guidance or suggestions on how the authors might address these issues. It lacks actionable details, such as recommending additional sections or analyses to include, or suggesting ways to better articulate the contribution. As a result, the authors are left without a clear understanding of what changes they should make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the paper for insufficient contribution, lack of explicit expression of the contribution, and inadequate explanation of the proposed model. It also mentions limited related work and the absence of appropriate analysis. However, the comment does not specify which parts of the paper these issues pertain to, making it difficult for the authors to identify the exact sections that need improvement. The lack of specific references to sections, figures, or tables means the authors cannot pinpoint the areas needing revision. Therefore, the comment is not grounded, as it does not provide clear guidance on where the issues lie, and it is also not specific, as it does not detail what needs to be addressed. This aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution of the work is insufficient and not explicitly expressed within the paper. It further states that the details provided do not adequately explain the specifics of the proposed model, and there is limited related work mentioned with no appropriate analysis. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence renders the claim unverifiable, as the authors are left without a clear understanding of what aspects need improvement. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies several significant issues with the paper, including the insufficient contribution, lack of explicit expression of the contribution, inadequate explanation of the proposed model, limited related work, and absence of appropriate analysis. However, it does not provide specific suggestions or guidance on how the authors might address these issues. While it highlights areas that need improvement, the comment lacks actionable feedback, such as recommending additional sections or analyses to include, or suggesting ways to better articulate the contribution. Without detailed guidance, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the results in Figure 2a should be given with iterations or training steps as the x-axis, rather than wall-time. It also questions the labeling of the x-axis in Figure 2b, suggesting that it should be clarified whether it refers to outer-loop iterations or raw experience. This feedback provides clear and specific actions for the authors to take, ensuring that the results are accurately represented and clarified. The comment is explicit and concrete, offering precise guidance on how to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2a\" and \"Figure 2b,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the x-axis labeling in Figure 2b and suggests that Figure 2a should use iterations or training steps as the x-axis. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the results presented in Figures 2a and 2b, specifically questioning the labeling of the x-axis in Figure 2b and suggesting that Figure 2a should use iterations or training steps as the x-axis. The comment provides a logical reasoning for the suggestion, as it points out the potential confusion caused by the current labeling. However, it does not provide specific examples or references to support the claim, which could strengthen the argument. Overall, the comment is somewhat verifiable, as it provides a clear rationale but lacks detailed evidence or examples to fully substantiate the claim. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Figures 2a and 2b, pointing out that the x-axis is labeled as \"item\" in Figure 2b, which is unclear. It suggests that Figure 2a should be given with iterations or training steps as the x-axis, rather than wall-time. This feedback is clear and actionable, providing the authors with a direct way to improve the clarity and interpretability of their results. By addressing these issues, the authors can enhance the comprehensibility of their findings, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the use of different metrics (flops, latency, and 1/FPS) for different devices, suggesting that the same cost metric could be used instead. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make. The action is implicit, as the authors need to infer that they should reconsider their cost metrics, but it lacks concrete details on how to implement this change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the use of different metrics (flops, latency, and 1/FPS) for different devices, suggesting that the same cost metric could be used instead. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its suggestion but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of different metrics (flops, latency, and 1/FPS) for different devices, suggesting that the same cost metric could be used instead. However, the comment does not provide any reasoning, examples, or references to support why using the same cost metric would be beneficial or how it would impact the analysis. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the use of different metrics (flops, latency, and 1/FPS) for different devices, suggesting that using the same cost metric could be more consistent. While the comment identifies a potential inconsistency, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. It does not offer actionable advice or insights that would help the authors improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the maximum iterations set in the experiment using the Sinkhorn algorithm for the two-dimensional Wasserstein distance. It also inquires whether these iterations significantly slow down the training speed. While the comment does not explicitly instruct the authors to provide this information, it implies that the authors should address this question by including details about the iterations used in their experiments. The action is implicit but concrete, as the authors know exactly what information is needed to improve their draft. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"two-dimention Wasserstein distance\" and the \"Sinkhorn algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the maximum iterations set in the experiment and whether these iterations significantly slow down the training speed. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the maximum iterations used in the experiment with the Sinkhorn algorithm for the two-dimensional Wasserstein distance. It seeks clarification on whether these iterations significantly slow down the training speed. However, the comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the implementation of the Sinkhorn algorithm for the two-dimensional Wasserstein distance, asking for clarification on the maximum iterations used in the experiment and whether these iterations significantly slow down the training speed. This feedback is clear and actionable, as it prompts the authors to provide additional details about their experimental setup, which could be crucial for understanding the computational efficiency of their method. By addressing this question, the authors can gain insights into potential bottlenecks in their approach and make informed decisions about optimization. Therefore, the comment is mostly helpful, as it provides a clear direction for improvement that can enhance the comprehensiveness and clarity of the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a major weakness in the paper regarding the soundness of the approach. It highlights that the teacher policy is trained to maximize distribution matching between the student policy and the expert, but it is unclear whether the student policy can still perform correct distribution matching. The reviewer suggests that theoretical results are needed to address this issue. While the comment implies that the authors should provide theoretical support, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a major weakness in the paper regarding its soundness, specifically questioning whether the student policy can still perform correct distribution matching after being trained with a teacher policy that maximizes distribution matching between the student and expert policies. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the soundness of the approach and suggesting the need for theoretical results. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s approach lacks theoretical soundness, specifically questioning whether the student policy can still perform correct distribution matching after being trained with a teacher policy. The reviewer suggests that the method appears more like a heuristic than a theoretically sound approach and requests theoretical results to address this concern. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim, making it somewhat verifiable. The authors would need to infer the exact nature of the theoretical results required to address the issue, which adds to the complexity of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically questioning the soundness of the approach. It highlights a potential issue with the teacher policy being trained to maximize distribution matching between the student policy and the expert, and whether the student policy can still perform correct distribution matching. The reviewer suggests that the method appears more like a heuristic than a theoretically sound approach and requests theoretical results to address this concern. This feedback is clear and actionable, as it directs the authors to focus on developing theoretical foundations to support their method. However, the comment could be more helpful if it provided specific suggestions on how to achieve this theoretical soundness. Overall, the comment is mostly helpful, as it effectively points out a critical area for improvement and guides the authors toward a more robust theoretical framework.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed method does not perform well in some classes and recommends that the authors analyze and discuss the reasons behind this performance. While the comment implies that the authors should investigate and address this issue, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to analyze the performance but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the proposed method does not perform well in some classes and suggests that the authors should analyze and discuss the reasons behind this performance. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method does not perform well in some classes and suggests that the authors should analyze and discuss the reasons behind this performance. However, the comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of the proposed method in certain classes, as observed in Table 3. It suggests that the authors should analyze and discuss the reasons behind this performance, which is a clear and actionable piece of feedback. By addressing this point, the authors can gain a deeper understanding of their method\\'s limitations and potentially improve it. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional suggestions or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the experimental settings, specifically mentioning that MTT should be tested on unseen tasks. It also suggests that the experimental results could be further discussed or explained, particularly regarding the variation of model behavior under different datasets/settings. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to design more rigorous experiments and discuss their results more thoroughly, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific experimental settings, mentioning that MTT should be tested on unseen tasks and that the experimental results could be further discussed or explained, particularly regarding the variation of model behavior under different datasets/settings. This provides clear guidance on what aspects of the paper need improvement. However, it does not specify which sections of the paper these issues are located in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as testing on unseen tasks and discussing the variation of model behavior. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some experimental settings are not rigorously designed, specifically mentioning that MTT should be tested on unseen tasks. It also suggests that the experimental results could be further discussed or explained, particularly regarding the variation of model behavior under different datasets/settings. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of concrete evidence or references makes the claim somewhat verifiable, as the authors would need to infer the specific issues and how to address them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental settings, noting that some settings are not rigorously designed. It provides a concrete suggestion by recommending that MTT be tested on unseen tasks, which could help improve the robustness of the results. Additionally, the comment suggests that the experimental results could be further discussed or explained, particularly regarding the variation of model behavior under different datasets/settings. This feedback is clear and actionable, offering the authors specific guidance on how to enhance the rigor and clarity of their experimental design and results. However, the comment could be more helpful if it provided examples or detailed guidance on how to implement these suggestions. Overall, the comment is mostly helpful, as it provides valuable insights for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the randomness of data collection for the 5 layouts, suggesting that the data might have been collected in the same order, potentially leading to learning effects. However, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment implies that the authors should investigate the randomness of their data collection process, but it lacks concrete steps or recommendations on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the randomness of data collection for the 5 layouts, suggesting that the data might have been collected in the same order, which could lead to learning effects. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its concern about the data collection process but lacks grounding, as it does not provide a clear reference to the relevant part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential for learning effects due to the order of data collection for the 5 layouts. However, it does not provide any evidence or reasoning to support this claim, such as specific examples or references to similar studies that have encountered similar issues. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the concern. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the potential for learning effects due to the order of data collection for the 5 layouts. It questions whether the data collection was randomized, suggesting that the data might have been collected in the same order, which could lead to biased results. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or ensure the randomness of their data collection process. While it identifies a potential problem, it lacks actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the relevance of node ordering in the context of covering the random ordering of atoms in a specific point in the composition space. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or clarify the role of node ordering. The comment lacks actionable guidance, leaving the authors without a clear understanding of what changes or clarifications are needed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"node ordering\" and \"composition space,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the relevance of node ordering in the context of covering the random ordering of atoms, providing a clear direction for the authors to address this issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the relevance of node ordering in the context of covering the random ordering of atoms in a specific point in the composition space. However, it does not provide any supporting evidence, reasoning, or references to justify why node ordering should not play a role. The lack of explanation or evidence makes it difficult for the authors to understand the basis of the claim, rendering it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the relevance of node ordering in the context of covering the random ordering of atoms in a specific point in the composition space. While it identifies a potential area of confusion or misunderstanding, it does not provide any specific suggestions or guidance on how the authors might address this issue or clarify the role of node ordering. The comment lacks actionable feedback, leaving the authors without a clear understanding of what changes or improvements are needed. Therefore, it is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point mentions that the previous work [5] presents a dexterous manipulation benchmark with musculoskeletal hands, which detracts from the novelty of the current work. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of novelty or how to differentiate the current work from the previous one. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the previous work [5],\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that this previous work detracts from the novelty of the current work, providing a clear direction for the authors to address. However, the comment could be more specific by explaining how the previous work detracts from the novelty or suggesting ways to differentiate the current work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the previous work [5] detracts from the novelty of the current work by presenting a dexterous manipulation benchmark with musculoskeletal hands. However, the comment does not provide any specific reasoning or evidence to support this claim. It includes references to external works, but these are not used to substantiate the claim about the novelty of the current work. Without detailed justification or examples, the claim remains unverifiable, as the authors would need additional information to understand and address the critique effectively.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the previous work [5] presents a dexterous manipulation benchmark with musculoskeletal hands, which it claims detracts from the novelty of the current work. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or differentiate their work from the previous one. Without actionable feedback or constructive advice, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful at all, as it lacks any meaningful insights or suggestions for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the selection process of the datasets should be made more clear, including the pool of datasets and the criteria for selection. It provides examples of works that have detailed their dataset selection processes, such as OpenML100 and OpenML CC-18, and references specific papers for further guidance. Additionally, it points out the need for more detail on the selection of the splitting procedure and split ratios. This feedback is explicit and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the selection of datasets and the need for clarity in the selection process, allowing the authors to accurately identify the part of the paper being addressed. It also provides specific examples of works that have detailed their dataset selection processes, such as OpenML100 and OpenML CC-18, and references specific papers for further guidance. Additionally, it highlights the need for more detail on the selection of the splitting procedure and split ratios. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the selection of datasets should be made more clear, suggesting that the current process is not detailed enough. It provides examples of works that have detailed their dataset selection processes, such as OpenML100 and OpenML CC-18, and references specific papers for further guidance. This level of detail and reference to established practices makes the claim mostly verifiable, as it provides a clear basis for the authors to improve their dataset selection process. However, the comment could be strengthened by providing more specific examples or detailed reasoning on why the current process is inadequate. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the selection process of the datasets should be made more clear. It questions the pool of datasets used and the criteria for their selection, offering examples of works that have detailed their dataset selection processes, such as OpenML100 and OpenML CC-18. Additionally, it points out the need for more detail on the selection of the splitting procedure and split ratios, which are described as \"ad-hoc\" and lacking in detail. This feedback is clear and actionable, guiding the authors on how to improve the transparency and rigor of their dataset selection and analysis. By addressing these points, the authors can enhance the credibility and reproducibility of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a missing aspect in the ablation study, specifically the lack of a critical comparison involving a baseline where an unconditional diffusion model is refined using the suggested efficient architectural changes, followed by either consistency distillation or progressive distillation. It suggests that comparing the proposed method to these conventional baselines under the same computational constraints would be valuable. The comment provides a clear and concrete action for the authors to take, which is to include this comparison in the ablation study. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the ablation study, namely a critical comparison involving a baseline where an unconditional diffusion model is refined using the suggested efficient architectural changes, followed by either consistency distillation or progressive distillation. The comment provides a clear direction for improvement by suggesting a comparison to conventional baselines under the same computational constraints. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study lacks a critical comparison and suggests that including a baseline where an unconditional diffusion model is refined using the suggested efficient architectural changes, followed by either consistency distillation or progressive distillation, would be valuable. The comment provides a logical reasoning for the importance of this comparison, emphasizing the need to determine if the proposed method outperforms conventional baselines under the same computational constraints. However, it does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the relevance of this comparison and its potential impact on the study. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the ablation study, specifically the lack of a critical comparison involving a baseline where an unconditional diffusion model is refined using the suggested efficient architectural changes, followed by either consistency distillation or progressive distillation. It highlights the importance of comparing the proposed method to conventional baselines under the same computational constraints to determine its effectiveness. This feedback is clear and actionable, providing the authors with a specific direction to enhance their study by including a more comprehensive comparison. By addressing this gap, the authors can strengthen their findings and improve the overall quality of their draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the tasks in the paper are based on grasping and that their difficulties are too homogeneous. It implies that the authors should consider designing more tasks, referencing specific projects like [1] and [2]. However, the comment does not explicitly instruct the authors to include these references or to design new tasks, leaving the action somewhat vague. The authors can infer that they need to diversify their tasks and consider external projects, but the comment lacks concrete guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the tasks in the paper are based on grasping and that their difficulties are too homogeneous. It implies that the authors should consider designing more tasks, referencing specific projects like [1] and [2]. However, the comment does not specify which part of the paper these tasks are discussed in, making it weakly grounded. The suggestion to refer to other projects is specific, as it provides a clear direction for potential improvements. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that all tasks in the paper are based on grasping and that their difficulties are too homogeneous. It suggests referring to specific projects ([1] and [2]) to design more tasks. However, the comment lacks detailed reasoning or examples to support why the tasks are too homogeneous or how the referenced projects could provide a solution. Without specific evidence or examples, the claim is difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper, noting that all tasks are based on grasping and that their difficulties are too homogeneous. It suggests that the authors consider designing more tasks by referencing specific projects, such as [1] and [2]. This feedback is somewhat helpful as it points out a specific area for improvement and provides a direction for expanding the scope of the paper. However, the comment could be more helpful if it included specific examples or detailed guidance on how to incorporate these new tasks or projects. The suggestion to refer to other projects is a good starting point, but the authors may need additional guidance to fully understand and implement the recommendation. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the comparison in Table 2 is unfair because the LEPA\\'s training data is likely larger than the \"Without Plan/Without Self-Reflection\" settings. However, it does not provide explicit guidance on how to address this issue or suggest a way to make the comparison fair. The comment implies that the authors should consider the size of the training data in their comparison, but it lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"lines 349-360,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the comparison in Table 2 is unfair due to the likely larger training data for LEPA compared to the \"Without Plan/Without Self-Reflection\" settings. The reference to the external work \"LUMOS: LEARNING AGENTS WITH UNIFIED DATA, MODULAR DESIGN, AND OPEN-SOURCE LLMS\" provides additional context, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison in Table 2 is unfair due to the likely larger training data for LEPA compared to the \"Without Plan/Without Self-Reflection\" settings. The reviewer supports this claim by referencing lines 349-360, suggesting that the settings are aligned with these lines. However, the comment lacks specific details or examples to fully substantiate the claim, making it somewhat verifiable. The reference to an external work, \"LUMOS: LEARNING AGENTS WITH UNIFIED DATA, MODULAR DESIGN, AND OPEN-SOURCE LLMS,\" is not directly related to the claim and does not provide additional evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the comparison in Table 2, suggesting that the LEPA\\'s training data is likely larger than the \"Without Plan/Without Self-Reflection\" settings. This observation is relevant and could impact the validity of the results presented. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the fairness of the comparison. Without actionable advice or detailed feedback, the comment provides some insight but is incomplete, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the use of synthetic datasets in the experiments and suggests using real datasets from the GLUE benchmark or real-world diversity datasets. While the comment implies that the authors should consider using these datasets, it does not explicitly instruct them to do so. The suggestion is concrete in terms of the specific datasets mentioned, but the action is implicit, as the authors need to infer that they should include results from these datasets. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a concern about the use of synthetic datasets in the experiments and suggests using real datasets from the GLUE benchmark or real-world diversity datasets. It provides specific examples of datasets that could be used, such as QQP for computing similarity between sentence pairs. However, the comment does not explicitly mention which part of the paper discusses the experiments or datasets, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not as direct as it could be. The comment is specific in suggesting the use of real datasets, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the use of synthetic datasets in the experiments and suggests using real datasets from the GLUE benchmark or real-world diversity datasets. The comment provides a logical reasoning by questioning the relevance of synthetic datasets and suggesting alternative datasets that could be used. However, it lacks specific examples or references to support the claim that using real datasets would be beneficial or necessary. This makes the claim somewhat verifiable, as it provides a rationale but lacks detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the paper, specifically the use of synthetic datasets for experimentation. It suggests that the authors should consider using real datasets, such as those from the GLUE benchmark or real-world diversity datasets, to enhance the validity and applicability of their results. This feedback is clear and actionable, as it provides specific examples of datasets that could be used, offering the authors a concrete path to improve their work. However, the comment could be more helpful if it included additional guidance on how to integrate these datasets into the experimental setup or what specific benefits might be expected from using real-world data. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to add details on how to solve the optimization in the main paper, indicating that this information is currently lacking. The comment provides a clear and direct action for the authors to take, which is to include additional details on optimization. This feedback is concrete and actionable, as it specifies exactly what needs to be addressed in the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding details on how to solve the optimization in the main paper, indicating that this information is currently lacking. However, it does not specify which part of the paper this information should be added to, making it weakly grounded. The comment is specific in identifying the need for additional details on optimization, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should add details on how to solve the optimization in the main paper, as this information is currently lacking. However, the comment does not provide any specific reasoning, examples, or references to support why this information is crucial or how it would enhance the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks detail, namely the optimization process. It suggests that the authors should include additional information on how to solve the optimization in the main paper, which is an important piece of information currently missing. This feedback is clear and actionable, as it provides a direct suggestion for improvement that can enhance the comprehensiveness and clarity of the paper. However, the comment could be more helpful if it offered specific guidance on what aspects of the optimization process should be detailed or how to present this information effectively. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the exclusion of LLaVA-series and Qwen-VL from the evaluation, suggesting that including these models would provide a more comprehensive comparison. While the comment implies that the authors should consider including these models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should include these models but are not provided with specific guidance on how to integrate them into the evaluation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the exclusion of LLaVA-series and Qwen-VL from the evaluation, suggesting that including these models would provide a more comprehensive comparison. However, it does not specify which part of the paper discusses the evaluation or the models being compared. The authors can infer that it relates to the sections discussing the evaluation or the models used, but this inference is not direct. The comment is specific in suggesting the inclusion of these models for a more comprehensive comparison, but it lacks grounding as it does not explicitly mention the relevant sections. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the exclusion of LLaVA-series and Qwen-VL from the evaluation, suggesting that including these models would provide a more comprehensive comparison. The claim is based on the common adoption of these models in LVLMs, implying that their inclusion would enhance the evaluation. However, the comment lacks specific references or detailed reasoning to support the claim that these models are \"commonly adopted\" or how their inclusion would significantly impact the evaluation. This makes the claim somewhat verifiable, as it provides a general rationale but lacks concrete evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid point by questioning the exclusion of LLaVA-series and Qwen-VL from the evaluation, suggesting that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. This feedback is clear and actionable, as it identifies a specific area for improvement and provides a rationale for why these models should be included. However, the comment could be more helpful if it offered suggestions on how to incorporate these models into the evaluation or provided examples of how their inclusion would enhance the comparison. Despite this, the comment is mostly helpful as it directs the authors to a significant enhancement of their evaluation methodology.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a caption or description, as well as OCR heavy datasets, in addition to the previous point. However, it does not specify which previous point is being referred to or how these elements should be integrated into the paper. The action is implicit and somewhat vague, as the authors are not provided with clear guidance on what specific content should be included or how it should be formatted. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should include a caption or description, as well as OCR heavy datasets, but it does not specify which part of the paper this should be added to. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in its suggestion to include additional content, such as captions or descriptions, and OCR heavy datasets. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include a caption or description, as well as OCR heavy datasets, but it does not provide any reasoning or justification for why these elements are necessary or how they would enhance the paper. Without supporting evidence or explanation, the claim lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include a caption or description, as well as OCR heavy datasets, in addition to the previous point. However, it does not specify which previous point is being referred to or provide detailed guidance on how these elements should be integrated into the paper. The comment lacks clarity and actionable feedback, making it barely helpful. The authors are given a general direction but no specific steps to follow, which limits the usefulness of the feedback. Therefore, the comment is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between Assumption 3.1 and Equation 7 regarding the loss of TKD compared to IYOR. However, it does not provide any explicit or implicit guidance on how the authors should address this discrepancy. There is no suggestion for clarification, correction, or further explanation. As a result, the authors are left without a clear understanding of what action to take to resolve the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Assumption 3.1\" and \"eqn.7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy between the assumption and the equation, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between Assumption 3.1 and Equation 7 regarding the loss of TKD compared to IYOR. However, it does not provide any supporting evidence, reasoning, or references to explain why this discrepancy is significant or how it affects the paper. Without additional context or justification, the claim remains unverifiable, as the authors would need more information to understand the basis of the critique. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a discrepancy between Assumption 3.1 and Equation 7 regarding the loss of TKD compared to IYOR. This is a specific observation that highlights a potential inconsistency in the paper, which could be important for the authors to address. However, the comment does not provide any guidance or suggestions on how to resolve this discrepancy or why it might be significant. While it identifies a potential issue, it lacks actionable feedback or depth, making it somewhat helpful. The authors are left with a clear identification of a problem but without a clear path forward for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the clarity of whether question 3 indicates other limitations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to clarify this point or what specific information should be added to address the question. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to \"question 3\" and \"weakness 2 and 4,\" which suggests that it is addressing a specific part of the paper. However, it does not provide explicit references to sections, tables, or figures, making it weakly grounded. The comment is specific in questioning the clarity of whether question 3 indicates other limitations, but it does not specify what needs to be addressed or how to clarify this point. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the clarity of whether question 3 indicates other limitations, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the clarity of whether question 3 indicates other limitations. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or clarify the relationship between question 3 and other limitations. Without actionable feedback or detailed advice, the comment lacks utility for the authors in improving their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of using the last-layer hidden states for the classifier, suggesting that middle layers might be more effective based on other works. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what alternative approaches they could consider. The action is implicit and vague, as the authors are left to infer that they should explore using middle layers, but without concrete steps or examples, it remains unclear how to implement this change. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the choice of using the last-layer hidden states for the classifier, suggesting that middle layers might be more effective based on other works. However, it does not specify which part of the paper discusses this choice or where the authors could find information about the effectiveness of middle layers. The authors can make an educated guess that it relates to the methodology or results sections, but the comment lacks full grounding. It is specific in questioning the choice of last-layer hidden states, but without explicit references or detailed guidance, it remains somewhat vague. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of using the last-layer hidden states for the classifier, suggesting that middle layers might be more effective based on other works. However, the comment does not provide specific references or examples of these works that have identified middle layers as more effective. This lack of supporting evidence or detailed reasoning makes the claim somewhat verifiable, as the authors would need to conduct additional research to understand the basis of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the choice of using the last-layer hidden states for the classifier, suggesting that middle layers might be more effective based on other works. This feedback is somewhat helpful as it prompts the authors to reconsider their approach and potentially explore alternative methods that have been identified as more effective in other studies. However, the comment lacks specific references or examples of these works, which would be beneficial for the authors to fully understand the context and make informed decisions. Additionally, it does not provide detailed guidance on how to implement this change or what specific middle layers might be more effective. Therefore, while the comment identifies a potential area for improvement, it could be more helpful with additional details and references.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the motivation behind using GUE to determine tokenization, model architecture, and training objectives for the generative model. It suggests that these decisions seem arbitrary and potentially incongruous, which could limit the generalizability of the representations learned. However, the comment does not provide explicit guidance on how the authors should address these concerns or suggest alternative approaches. The action is implicit and vague, as the authors are left to infer that they need to provide more motivation or justification for their choices. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"my first question,\" which likely refers to a previous comment or question raised by the reviewer. This allows the authors to identify the part of the paper being addressed. The comment is also specific because it details the issue with the motivation behind using GUE to determine tokenization, model architecture, and training objectives for the generative model. It highlights concerns about the arbitrariness and potential incongruity of these decisions and their impact on the generalizability of the representations learned. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of GUE to determine tokenization, model architecture, and training objectives for the generative model is poorly motivated and potentially incongruous. The reviewer provides a logical reasoning by stating that the representations learned using these modeling decisions may have limited generalizability due to being optimized for a relatively narrow set of tasks presented in GUE. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider the reasoning and potentially conduct further analysis to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the motivation behind using GUE to determine tokenization, model architecture, and training objectives for the generative model. It highlights that these decisions seem arbitrary and potentially incongruous, which could limit the generalizability of the representations learned. This feedback is valuable as it points out a potential weakness in the paper's methodology and suggests that the authors should provide more justification or motivation for their choices. However, the comment could be more helpful if it offered specific suggestions or examples of how to address this issue or improve the generalizability of the model. Overall, the comment is somewhat helpful as it provides a clear direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper needs a major editing pass due to significant grammar and spelling errors, which is a clear and direct action for the authors to take. However, it does not provide specific guidance on how to address these errors or suggest tools or resources that could aid in the editing process. While the action is explicit, the lack of concrete details on how to implement the editing pass makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment mentions that the paper \"reads clunkily due to significant grammar and spelling errors\" and suggests a \"major editing pass.\" However, it does not specify which parts of the paper are affected by these errors or provide examples of the specific issues. This makes it difficult for the authors to pinpoint the exact sections that need attention. The comment is not grounded as it does not identify specific parts of the paper, and it is also not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper \"reads clunkily due to significant grammar and spelling errors\" and suggests a \"major editing pass.\" However, the comment does not provide specific examples or evidence of these errors, making it difficult for the authors to understand and address the issues. Without detailed examples or references, the claim lacks sufficient justification, rendering it unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that it \"reads clunkily due to significant grammar and spelling errors.\" This feedback is clear and actionable, as it directly points out a major problem that needs to be addressed. However, the comment could be more helpful if it provided specific examples of the errors or suggested resources for improving the writing clarity. Despite this, the comment effectively guides the authors to focus on editing and proofreading, which is a crucial step in enhancing the overall quality of the paper. Therefore, the comment is rated as mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and concerns about the consistency of the SITE estimator and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implications of the objective function being defined only over minibatches. While the comment identifies areas that need clarification or further exploration, it does not provide explicit instructions or suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations or analyses to address the concerns raised. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several questions and concerns about the SITE estimator, specifically regarding its consistency as an estimator of the true average ITE and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implications of the objective function being defined only over minibatches. However, the comment does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. While the comment is specific in its questioning, it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several questions and concerns about the SITE estimator, including its consistency as an estimator of the true average ITE and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implications of the objective function being defined only over minibatches. While the comment identifies potential issues, it does not provide specific evidence, examples, or references to support these claims. The reasoning is logical but lacks detailed justification or examples, making the claims somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several important questions and concerns about the SITE estimator, specifically regarding its consistency as an estimator of the true average ITE and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implications of the objective function being defined only over minibatches. By highlighting these areas of uncertainty, the comment prompts the authors to clarify and address these critical aspects of their work. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these questions or if it offered guidance on how to improve the clarity of the objective function. Despite this, the comment is mostly helpful as it directs the authors to important areas that need further exploration and clarification, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the ability of OIS to handle interactive segmentation for multiple objects simultaneously. It suggests that the method may struggle to shift focus to a new target object if the target changes between clicks, due to constraints from the previous mask. While the comment identifies a potential limitation, it does not provide explicit guidance on how the authors might address this issue or improve the method\\'s practical utility. The action is implicit and somewhat vague, as the authors are left to infer that they should explore ways to enhance the method\\'s adaptability to changing targets. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"OIS\" and \"interactive segmentation for multiple objects simultaneously,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by explaining the potential limitation of the method in handling changes in the target object between clicks, due to constraints from the previous mask. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the ability of OIS to handle interactive segmentation for multiple objects simultaneously. It suggests that the method may struggle to shift focus to a new target object if the target changes between clicks, due to constraints from the previous mask. The comment references \"Object Aware Contrastive Prior for Interactive Image Segmentation\" as a source, which provides some level of support for the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how this limitation affects the method\\'s practical utility. Therefore, the claim is mostly verifiable, as it has some supporting evidence but could be further substantiated.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the OIS method's ability to handle interactive segmentation for multiple objects simultaneously. It highlights a specific issue where the method may struggle to shift focus to a new target object if the target changes between clicks, due to constraints from the previous mask. This feedback is valuable as it points out a practical limitation that could impact the method's utility. However, the comment could be more helpful if it provided suggestions or ideas on how the authors might address this limitation or improve the method's adaptability. Despite this, the comment still offers a clear direction for the authors to consider, making it mostly helpful.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the realism of the assumption that anomalies are aligned with concepts, suggesting that this might not be realistic given the complexity of real-world scenarios. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve their draft. The comment implies that the authors should consider the limitations of their assumption, but it lacks concrete steps or actions for the authors to take. As a result, the comment is vague and does not provide a clear path for improvement, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the realism of the assumption that anomalies are aligned with concepts, particularly in scenarios where the type of anomalies is unknown. However, it does not specify which part of the paper this assumption is made in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique, questioning the assumption and its implications, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the realism of the assumption that anomalies are aligned with concepts, suggesting that this might not be realistic given the complexity of real-world scenarios. The comment provides a logical reasoning by contrasting the typical use of anomaly detection systems in unknown scenarios with the proposed system\\'s assumption. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider the context and evidence to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the assumption that anomalies are aligned with concepts, which is a key aspect of the proposed system. It highlights a potential limitation by pointing out that this assumption might not be realistic, especially in scenarios where the type of anomalies is unknown. This feedback is valuable as it prompts the authors to consider the practical implications of their assumption and potentially revise their approach to better align with real-world scenarios. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue. Overall, the comment is somewhat helpful as it identifies a critical area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the authors should include a discussion on the current limitations and challenges of HLOP, as well as the potential downsides of HLOP and limitations of the evaluation process. This provides a clear and direct action for the authors to take, which is to expand their discussion to address these gaps. The comment is specific in its request, offering concrete guidance on what needs to be added to the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of discussion on the current limitations and challenges of HLOP and the experimental design, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the inclusion of a discussion on the potential downsides of HLOP and limitations of the evaluation process. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a lack of discussion on the current limitations and challenges of HLOP and the experimental design, making it difficult to judge the tradeoffs between using HLOP versus other approaches. The reviewer suggests that the authors should include a discussion on the potential downsides of HLOP and limitations of the evaluation process. While the comment highlights an important gap in the paper, it does not provide specific examples or detailed reasoning to support the claim. The lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the specific issues and how to address them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by noting the lack of discussion on the current limitations and challenges of HLOP, as well as the experimental design. It suggests that the authors should include a discussion on the potential downsides of HLOP and limitations of the evaluation process. This feedback is clear and actionable, providing the authors with a specific area to address in order to enhance the comprehensiveness and depth of their paper. By incorporating this discussion, the authors can better contextualize their work and provide a more balanced view of the trade-offs involved. Therefore, the comment is mostly helpful, as it offers constructive guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should evaluate the effectiveness of their proposed gating scheme on recently released language models, such as FlanT5 and Llama, to enhance the prominence of their contribution. This is an explicit action that provides a clear direction for the authors to follow. The comment specifies the models to consider and the goal of evaluating their effectiveness, offering concrete guidance on how to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests evaluating the proposed gating scheme on recently released language models, such as FlanT5 and Llama, to enhance the contribution of the work. However, it does not specify which part of the paper this suggestion should be addressed in, making it weakly grounded. The comment is specific in suggesting the inclusion of these models for evaluation, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should evaluate their proposed gating scheme on recently released language models, such as FlanT5 and Llama, to enhance the contribution of their work. The claim is based on the observation that many more language models have been released after GPT-2, which have not been studied in the current work. This reasoning is logical and provides a clear rationale for why evaluating these models would be beneficial. However, the comment could be strengthened by providing specific examples or references to these models, which would make the claim more fully verifiable. Therefore, the comment is mostly verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential gap in the work by suggesting that the authors evaluate their proposed gating scheme on recently released language models, such as FlanT5 and Llama. This feedback is clear and actionable, as it provides specific models for the authors to consider, which could enhance the prominence of their contribution. However, the comment could be more helpful if it offered additional guidance on how to integrate these models into the evaluation or provided specific suggestions for experimental design. Overall, the comment is mostly helpful as it directs the authors to a relevant area for improvement, but it could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should cite and compare their work with more recent studies that might be highly correlated. It provides a specific example of a work by Wang et al. from CVPR 2020, which shares some similarity with the proposed method and should be discussed in context. This feedback is explicit and provides a concrete example of a work to consider, making it clear what action the authors should take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should cite and compare their work with more recent studies that might be highly correlated. It provides a specific example of a work by Wang et al. from CVPR 2020, which shares some similarity with the proposed method and should be discussed in context. This provides clear guidance on what needs to be addressed, specifically mentioning a relevant work that should be considered for comparison. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should consider more recent works that might be highly correlated with their own and provide a specific example of a work by Wang et al. from CVPR 2020. The suggestion is based on the observation that the proposed method might share similarities with this work, which should be discussed in context. However, the comment lacks detailed reasoning or evidence to fully substantiate the claim that the proposed method is similar to the work by Wang et al. or why it is relevant to the current paper. While the suggestion is logical, it requires more elaboration to be fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should consider citing and comparing their work with more recent studies that might be highly correlated. It provides a specific example of a work by Wang et al. from CVPR 2020, which shares some similarity with the proposed method and should be discussed in context. This feedback is clear and actionable, as it directs the authors to expand their literature review and provide a more comprehensive discussion of their work in relation to existing research. By doing so, the authors can enhance the depth and relevance of their paper. Therefore, the comment is rated as mostly helpful, as it provides valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests adding more detail about how UNKs are handled by the neural decoder or providing a citation for the dictionary-based replacement strategy being used. This feedback is explicit, as it clearly states what needs to be done to improve the draft. However, it lacks concrete guidance on how to add the detail or which specific aspects of the UNK handling should be elaborated upon. The action is mostly actionable because it provides a clear direction but lacks detailed instructions on execution. Therefore, this comment is rated as mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests adding more detail about how UNKs are handled by the neural decoder or providing a citation for the dictionary-based replacement strategy. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the neural decoder is discussed. The comment is specific in suggesting what additional information should be included, such as more detail on UNK handling or a citation for the dictionary-based replacement strategy. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should provide more detail about how UNKs are handled by the neural decoder or include a citation for the dictionary-based replacement strategy. However, the comment does not provide any specific reasoning, examples, or references to support the claim that additional detail is necessary or that the current handling is insufficient. Without such evidence or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from additional detail about how UNKs (unknown tokens) are handled by the neural decoder. It also recommends including a citation for the dictionary-based replacement strategy being used. This feedback is clear and actionable, as it identifies a specific area where the paper could be improved and provides a concrete suggestion for enhancement. By addressing this point, the authors can enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided specific examples or further guidance on how to incorporate the suggested details. Overall, the comment is mostly helpful, as it offers valuable insights for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their method with other state-of-the-art (SOTA) code summarization methods, specifically mentioning the use of pre-trained models. This is an explicit action that provides a clear direction for the authors to follow. However, the comment does not specify which pre-trained models should be used or how the comparison should be conducted, leaving some room for interpretation. Despite this, the action is concrete in its suggestion to include additional comparisons, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests comparing the current method with other state-of-the-art (SOTA) code summarization methods, specifically mentioning the use of pre-trained models. However, it does not specify which part of the paper this suggestion should be implemented in, such as the experimental section or the results discussion. This lack of explicit reference to a specific section makes it weakly grounded. The comment is specific in suggesting a comparison with other methods, but without clear guidance on how to implement this, it remains somewhat vague. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the current method with other state-of-the-art (SOTA) code summarization methods, specifically mentioning the use of pre-trained models. However, the comment does not provide any reasoning, examples, or references to support why this comparison is necessary or beneficial. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a comparison with other state-of-the-art (SOTA) code summarization methods, specifically mentioning the use of pre-trained models. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their experimental section by including additional comparisons. However, the comment could be more helpful if it specified which pre-trained models should be considered or how the comparison should be conducted. Despite this, the suggestion is mostly helpful as it guides the authors toward a meaningful improvement in their draft. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the results presented in Table 3, specifically regarding the performance of Scheduled Bernoulli compared to AttendOut. It asks for the reason behind AttendOut having lower variance and requests the statistical significance value when comparing Scheduled Bernoulli and AttendOut. While the comment does not explicitly instruct the authors to provide this information, it implies that the authors should address these questions to clarify the results. The action is implicit but concrete, as the authors know exactly what information is needed to improve the clarity of their results. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the results presented in the table, specifically the performance of Scheduled Bernoulli compared to AttendOut, and requests information on the reason for AttendOut\\'s lower variance and the statistical significance value when comparing the two. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the results presented in Table 3, specifically regarding the performance of Scheduled Bernoulli compared to AttendOut. It asks for the reason behind AttendOut having lower variance and requests the statistical significance value when comparing Scheduled Bernoulli and AttendOut. However, the comment does not provide any supporting evidence, reasoning, or references to justify these questions. Without additional context or explanation, the authors may find it challenging to address these questions effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises specific questions about the results presented in Table 3, particularly regarding the performance of Scheduled Bernoulli compared to AttendOut. It asks for the reason behind AttendOut having lower variance and requests the statistical significance value when comparing Scheduled Bernoulli and AttendOut. These questions are clear and actionable, providing the authors with a direct path to improve the clarity and comprehensiveness of their results. By addressing these questions, the authors can enhance the transparency and robustness of their analysis, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experimental results show long-term forecasting but questions the appropriateness of the prediction lengths used. It explicitly recommends following the same settings as the original dataset, which are specified as {96, 192, 336, 720}. This provides clear and concrete guidance on how to improve the draft by aligning the prediction lengths with the original dataset. The authors know exactly what action to take to enhance their work, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experimental results\" and \"prediction lengths,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the prediction lengths and suggests following the same settings as the original dataset. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results show long-term forecasting but questions the appropriateness of the prediction lengths used. It suggests following the same settings as the original dataset, which are specified as {96, 192, 336, 720}. The comment provides a clear and logical reasoning for the suggestion, as it contrasts the provided prediction lengths with the original dataset settings. This reasoning is robust and provides a clear path for the authors to follow, making the claim fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental results, specifically questioning the appropriateness of the prediction lengths used for long-term forecasting. It suggests that the authors should follow the same settings as the original dataset, which are specified as {96, 192, 336, 720}. This feedback is clear and actionable, providing the authors with a specific suggestion to improve the alignment of their experimental settings with the original dataset. By addressing this point, the authors can enhance the validity and comparability of their results. Therefore, the comment is rated as mostly helpful, as it offers a constructive suggestion for improvement but could be further enhanced by explaining why the original settings are more appropriate.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the difference between confidence and accuracy for one sample when used in a specific equation. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion for improvement, clarification, or specific actions to take. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to a specific equation where the difference between confidence and accuracy for one sample is mentioned. However, it does not specify which equation this is, making it weakly grounded. The comment is specific in identifying the issue with the difference between confidence and accuracy, but without explicit references to sections or equations, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the difference between confidence and accuracy for one sample is not reasonable when used in a specific equation. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the difference between confidence and accuracy for one sample when used in a particular equation. However, it does not provide any further explanation, context, or suggestions on how this issue might be addressed or improved. Without additional guidance or actionable feedback, the authors are left without a clear understanding of how to resolve the problem or enhance their draft. Therefore, the comment is barely helpful, as it highlights a potential issue but lacks depth and specificity to be fully beneficial.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the approach used to calculate the divergence between a sample and the data, specifically noting that it may fail when the sample is shifted from the data distribution. It poses a question about whether there is a way to adapt the method to account for this shift. While the comment identifies a potential issue and suggests a direction for improvement, it does not provide explicit guidance on how to address the problem or what specific steps the authors should take. The action is implicit and somewhat vague, as the authors need to infer that they should explore ways to adapt the method to account for shifts in the data distribution. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the calculation of divergence between a sample and the data, and the potential failure of this approach when the sample is shifted from the data distribution. However, it does not specify which part of the paper discusses this calculation, making it weakly grounded. The comment is specific in its concern about the approach and suggests a potential adaptation to account for shifts in the data distribution. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the approach used to calculate the divergence between a sample and the data, specifically noting that it may fail when the sample is shifted from the data distribution. The reviewer questions whether there is a way to adapt the method to account for this shift. While the comment identifies a potential issue, it does not provide specific examples, references, or detailed reasoning to support the claim. The lack of supporting evidence or detailed explanation makes the claim somewhat verifiable, as the authors would need to infer the potential impact and possible solutions on their own. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the approach used to calculate the divergence between a sample and the data, specifically noting that it may fail when the sample is shifted from the data distribution. It raises a question about whether there is a way to adapt the method to account for this shift, which is a thoughtful and relevant concern. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or explore adaptations to their method. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it prompts the authors to consider a potential limitation but does not fully support them in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the replacement of words in the context of the paper, specifically asking if replacing a word independently of its context could lead to incoherent text. The reviewer suggests that it might be better to replace the whole phrase instead of individual words. While the comment implies that the authors should consider this aspect, it does not explicitly instruct them to make changes. The action is implicit and somewhat vague, as the authors are left to infer that they should address the potential issue of incoherent text. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 076-079,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the replacement of words in the context and suggests that replacing individual words could lead to incoherent text. The reviewer provides a concrete example by asking what happens to neighboring words (w_{i-1} and w_{i+1}) when a word (w_i) is replaced. This level of detail helps the authors understand what needs to be addressed in the specified part of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the replacement of words in the context of the paper, specifically asking if replacing a word independently of its context could lead to incoherent text. The reviewer suggests that it might be better to replace the whole phrase instead of individual words. However, the comment does not provide any evidence, examples, or references to support this claim. It lacks detailed reasoning or specific instances where this issue might occur, making it difficult for the authors to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the replacement of words in the context of the paper, specifically asking if replacing a word independently of its context could lead to incoherent text. The reviewer suggests that it might be better to replace the whole phrase instead of individual words. This feedback is somewhat helpful as it identifies a potential issue with the methodology or implementation of the paper. However, it lacks depth and does not provide specific guidance on how to address this concern or suggest alternative approaches. The authors are left with a general idea of what might need improvement but without detailed instructions on how to resolve it. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it would be desirable to include a runtime comparison of different deep learning-based methods. While the comment implies that the authors should conduct this comparison, it does not provide explicit instructions or guidance on how to perform the comparison or what specific aspects should be considered. The action is implicit and somewhat vague, as the authors can infer that they need to include a runtime comparison but may not know exactly how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including a runtime comparison of different deep learning-based methods but does not specify which part of the paper this suggestion pertains to. The authors may infer that it relates to the experimental or results sections, but without explicit guidance, it is difficult to pinpoint the exact area needing attention. The comment is specific in suggesting a particular type of comparison but lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including a runtime comparison of different deep learning-based methods would be desirable. However, it does not provide any reasoning, evidence, or examples to support why this comparison is necessary or beneficial. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that including a runtime comparison of different deep learning-based methods would be desirable. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to conduct the comparison or what aspects should be considered. The comment does not offer actionable steps or detailed suggestions, leaving the authors with a general idea of what could be improved but without a clear path forward. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the ECG encoder in the MEIT framework could be improved by using ECG-specific architectures that incorporate SSL or transformer-based architectures. It explicitly recommends comparing and exploring these architectures, similar to how different methods were explored for the other parts of the framework. This feedback provides a clear and concrete action for the authors to take, as it specifies what needs to be done to enhance the ECG encoder. The suggestion is explicit and detailed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ECG encoder, modality alignment, and LLM backbone\" within the MEIT framework, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the ECG encoder, suggesting that it only uses 1-D CNN layers and average pooling, and recommends comparing and exploring ECG-specific architectures that use SSL or transformer-based architectures. This provides clear guidance on what needs to be addressed and how to improve the ECG encoder. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ECG encoder in the MEIT framework could be improved by using ECG-specific architectures that incorporate SSL or transformer-based architectures. The reviewer suggests comparing and exploring these architectures, similar to how different methods were explored for the other parts of the framework. This claim is somewhat verifiable as it provides a logical reasoning for the potential improvement and suggests a specific area for exploration. However, the comment lacks specific examples or references to ECG-specific architectures that could be used, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the MEIT framework, namely the simplicity of the ECG encoder, which only uses 1-D CNN layers and average pooling. It suggests that this could be improved by incorporating ECG-specific architectures that utilize SSL or transformer-based architectures. The comment provides a clear and actionable suggestion by recommending the comparison and exploration of these architectures, similar to how different methods were explored for the other parts of the framework. This feedback is highly helpful as it offers a concrete direction for enhancing the ECG encoder and improving the overall framework. However, it could be more helpful if it included specific examples or references to these architectures, which would further guide the authors in their improvement efforts. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to rephrase the abstract to accurately reflect the focus on model-agnostic explainability for deep neural networks, rather than suggesting a defense methodology. This feedback is clear and direct, providing a specific action for the authors to take to improve their draft. The comment also specifies what needs to be changed, ensuring that the authors know exactly how to apply the feedback. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the abstract, allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it clearly specifies the issue with the abstract, which is the inaccurate suggestion of a defense methodology when the paper actually presents a model-agnostic explainability technique. The comment provides a clear direction for improvement by suggesting a rephrasing of the abstract to reflect the correct focus on explainability. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract inaccurately suggests a defense methodology is proposed, when in fact, the paper presents a model-agnostic explainability technique for deep neural networks. The reviewer provides a clear and logical reasoning for the claim by explaining the discrepancy between the abstract\\'s claim and the actual content of the paper. This reasoning is supported by the specific suggestion to rephrase the abstract to reflect the correct focus on explainability. The comment is fully verifiable as it provides a clear and logical explanation of the issue, making it easy for the authors to understand and address the concern. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the abstract, where it inaccurately suggests that the paper proposes a defense methodology when, in fact, it presents a model-agnostic explainability technique for deep neural networks. This is a clear and actionable feedback that the authors can use to improve their draft by rephrasing the abstract to accurately reflect the focus of the paper. The comment provides a direct suggestion for improvement, which is valuable for the authors. However, it could be more helpful if it offered additional guidance on how to rephrase the abstract or suggested alternative wording. Overall, the comment is mostly helpful as it effectively points out a critical error and provides a clear path for correction.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of comparison to recent methods, specifically mentioning FINER, Incode, and SL2A-INR, which propose new activation functions for INRs. While the comment identifies a gap in the comparison, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they should include comparisons with these recent methods, but the comment lacks concrete details on how to implement this comparison or which aspects to focus on. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a lack of comparison to recent methods, specifically mentioning FINER, Incode, and SL2A-INR, which propose new activation functions for INRs. However, it does not specify which part of the paper this comparison should be included in, such as the introduction, results section, or discussion. This makes it difficult for the authors to pinpoint the exact area that needs revision. The comment is specific in identifying the missing comparisons but lacks grounding, as it does not direct the authors to a particular section. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks comparisons to recent methods, specifically mentioning FINER, Incode, and SL2A-INR, which propose new activation functions for INRs. The comment provides specific examples of recent methods that should be included in the comparison, which is a clear and logical justification for the claim. However, the comment could be strengthened by explaining why these specific methods are relevant or how they differ from the methods already compared in the paper. Overall, the claim is mostly verifiable, as it provides a clear direction for improvement but lacks detailed reasoning or references to fully substantiate the need for these comparisons. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a gap in the paper's comparison to recent methods, specifically mentioning FINER, Incode, and SL2A-INR, which propose new activation functions for INRs. This feedback is valuable as it highlights an area where the paper could be strengthened by including comparisons to more recent and relevant works. However, the comment does not provide specific guidance on how to incorporate these comparisons or what aspects of these methods should be evaluated. While it points out a clear area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and actionable steps.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a straightforward method, such as the one referenced in https://arxiv.org/abs/2309.16039, works well in practice and challenges the value of research on length extrapolation, especially when models are fine-tuned. The comment implies that the evaluation setting could be improved, but it does not provide explicit guidance on how to make these improvements. The action is implicit and somewhat vague, as the authors are left to infer that they should consider alternative methods or evaluation settings, but without specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a straightforward method, such as the one referenced in https://arxiv.org/abs/2309.16039, works well in practice and challenges the value of research on length extrapolation, especially when models are fine-tuned. However, it does not specify which part of the paper this comment addresses, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in suggesting an improvement to the evaluation setting, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that a straightforward method, such as the one referenced in https://arxiv.org/abs/2309.16039, works well in practice and challenges the value of research on length extrapolation, especially when models are fine-tuned. The comment provides a specific reference to support the claim, which is a clear and robust form of evidence. This makes the claim fully verifiable, as it offers a direct link to external work that substantiates the assertion. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment suggests that a straightforward method, such as the one referenced in https://arxiv.org/abs/2309.16039, works well in practice and challenges the value of research on length extrapolation, especially when models are fine-tuned. This feedback implies that the evaluation setting could be improved by considering alternative methods or approaches. However, the comment lacks specific guidance or suggestions on how to address this issue or improve the evaluation setting. While it identifies a potential area for improvement, it does not provide actionable steps or detailed advice, making it somewhat helpful. The authors are left with a general idea of what might need attention but without clear direction on how to proceed. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for clarification regarding the training and testing environments for the autoencoder. It also suggests performing cross-validation testing to demonstrate the robustness of the results. The comment provides a clear and specific action for the authors to take, which is to clarify the training and testing environments and consider implementing cross-validation testing. This feedback is explicit and concrete, giving the authors a direct path to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the training and testing environments for the autoencoder and suggests performing cross-validation testing to demonstrate the robustness of the results. This provides clear guidance on what needs to be addressed in the section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the training and testing environments for the autoencoder and suggests performing cross-validation testing to demonstrate robustness. However, it does not provide any evidence, examples, or references to support the claim that cross-validation is preferable or necessary. The comment lacks specific reasoning or justification, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific area of concern regarding the training and testing environments for the autoencoder. It asks for clarification on which environment the autoencoder is trained on and tested on, and suggests performing cross-validation testing to demonstrate the robustness of the results. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by addressing the robustness of their results. However, the comment could be more helpful if it included additional suggestions or examples on how to implement cross-validation testing effectively. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of comparison to demonstrate how refinement during inference improves generation quality. It suggests that while the statistic of the number of refinements is provided, it only confirms the change rather than indicating an improvement. However, the comment does not explicitly instruct the authors to conduct a comparison or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to conduct a comparison but are not given concrete steps on how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of a comparison to show how refinement during inference improves generation quality. It mentions the statistic of the number of refinements, suggesting that this only confirms the change rather than indicating an improvement. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or figure, making it weakly grounded. The comment is specific in detailing what is missing, namely a comparison to demonstrate the improvement in generation quality. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison to demonstrate how refinement during inference improves generation quality. It suggests that while the number of refinements is provided, it only confirms the change rather than indicating an improvement. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed explanation makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting the lack of a comparison to demonstrate how refinement during inference improves generation quality. It acknowledges the provision of statistics on the number of refinements but points out that this only confirms the change rather than indicating an improvement. This feedback is somewhat helpful as it highlights a gap in the paper that could be addressed by including a comparison to demonstrate the effectiveness of the refinement process. However, the comment could be more helpful if it provided suggestions on how to conduct such a comparison or what specific metrics could be used to evaluate the improvement. Overall, the comment offers a clear direction for improvement but lacks detailed guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two separate comments. The first comment, \"336 \"with... PMI\": something missing (threshold?)\", implies that there is a missing element, likely a threshold, in the context of PMI. However, it does not specify what action the authors should take to address this issue. The second comment, \"371 did you do this partitions randomly?\", raises a question about the method of partitioning, but it does not provide any guidance on how the authors should respond or what action to take. Both comments lack explicit instructions or concrete suggestions, leaving the authors uncertain about how to address the issues raised. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific line numbers (\"336\" and \"371\"), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what is missing or unclear, such as the threshold in the context of PMI and the method of partitioning. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two separate comments. The first comment, \"336 \"with... PMI\": something missing (threshold?)\", raises a question about the presence of a threshold in the context of PMI, but it does not provide any supporting evidence or reasoning to justify the claim. The second comment, \"371 did you do this partitions randomly?\", is a question seeking clarification on the method of partitioning, which is not a claim requiring verification. Since the first part lacks justification, the overall comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment consists of two separate points. The first point raises a question about the presence of a threshold in the context of PMI, suggesting that something is missing. However, it does not provide any further guidance or context on what this threshold might be or how it relates to the paper. The second point questions whether the partitions were done randomly, but again, it lacks depth and does not offer any actionable advice or suggestions for improvement. Both points are vague and do not provide the authors with clear directions for enhancing their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the training time of the MDP and requests a comparison with ImageNet pretraining and individual dataset fine-tuning. While it implies that the authors should provide this information, the action is not explicitly stated. The comment lacks concrete guidance on how to conduct the comparison or what specific metrics to use, leaving the authors to infer the necessary steps. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the training time of the MDP and requests a comparison with ImageNet pretraining and individual dataset fine-tuning. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where this information might be discussed. Without explicit references or context, the authors may find it challenging to determine where to address this inquiry. The comment is specific in its request for information but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a request for clarification and additional information, specifically asking about the training time of the MDP and requesting a comparison with ImageNet pretraining and individual dataset fine-tuning. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the training time of the MDP and requests a comparison with ImageNet pretraining and individual dataset fine-tuning. While it identifies a potential area for improvement by suggesting additional information that could enhance the paper, it lacks depth and does not provide specific guidance on how to conduct the comparison or what metrics to use. The comment is somewhat helpful as it points out a gap in the paper but does not offer detailed suggestions for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the authors\\' claim and the actual structure of G-PDE, noting that it is an incremental improvement upon GraphCON[1] rather than a combination of spike ODE and graph ODE. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or what changes they should make to their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific claim made by the authors regarding the design of G-PDE, noting that it is an incremental improvement upon GraphCON[1] rather than a combination of spike ODE and graph ODE. This provides full grounding as it explicitly mentions the claim and the reference to GraphCON[1], allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the authors\\' claim, providing a detailed explanation of the actual relationship between G-PDE and GraphCON[1]. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the author\\'s assertion about G-PDE being designed to leverage the advantages of both spike ODE and graph ODE is incorrect. It supports this claim by noting that G-PDE is actually an incremental improvement upon GraphCON[1], where the static encoder is substituted by SNN. This provides a clear and logical reasoning for the claim, making it fully verifiable. The reference to GraphCON[1] adds specificity and robustness to the argument, allowing the authors to understand and address the issue effectively. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment addresses a specific claim made by the authors regarding the design of G-PDE, pointing out that it is actually an incremental improvement upon GraphCON[1], rather than a combination of spike ODE and graph ODE as claimed. This feedback is valuable as it highlights a potential misrepresentation of the work, prompting the authors to correct their claim and provide a more accurate description of their contribution. However, the comment could be more helpful if it offered suggestions on how to address this discrepancy or provided additional context to support the correction. Overall, the comment is somewhat helpful as it identifies a critical issue but lacks depth in terms of actionable guidance or further explanation.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed method does not significantly outperform Jiang et al. in certain metrics, specifically mentioning a small margin of improvement in one case and a worse performance in another. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these issues or improve their method. Without actionable suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific metrics (\"Penetration(Dep)\", \"In CR\", \"Sim-Disp(Mean)\") and references the work of Jiang et al., allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the performance differences between the proposed method and Jiang et al. in these metrics, providing clear information on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method does not outperform Jiang et al. significantly, providing specific metrics and values to support this claim. It highlights a small margin of improvement in one case and a worse performance in another, which provides a clear basis for the claim. However, the comment could be strengthened by including more detailed analysis or references to similar studies for comparison. Overall, the claim is mostly verifiable, as it provides sufficient evidence but lacks comprehensive references or additional context. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment highlights a specific issue with the performance of the proposed method compared to Jiang et al., noting that the proposed method does not outperform significantly in certain metrics. It provides specific numerical values to support this claim, such as a 0.03% improvement in one case and a worse performance in another. This feedback is clear and actionable, as it directs the authors\\' attention to areas where their method may need improvement. However, the comment could be more helpful if it offered suggestions on how to address these performance gaps or provided additional context for understanding the implications of these results. Overall, the comment is mostly helpful, as it effectively identifies a critical area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two separate issues. First, it suggests that the term \"vFSAD\" refers to OOD detection in time-series data, implying that there is a significant body of work not mentioned in the paper. The reviewer provides an example of a relevant work, \"CODiT: Conformal Out-of-Distribution Detection in Time-Series Data\" by Kaur et al., which could guide the authors in expanding their literature review. This provides a concrete action for the authors to take, which is to include this work and others like it in their discussion. Second, the comment critiques the related work subtitles \"Policy\" and \"Evaluation tasks\" as not descriptive and unrelated to the actual content. While the comment identifies a problem, it does not provide specific guidance on how to improve these subtitles. The action is implicit and somewhat vague, as the authors need to infer that they should make the subtitles more descriptive and relevant. Overall, the comment is mostly actionable, as it provides a clear direction for expanding the literature review but lacks detailed guidance on improving the related work subtitles.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the term \"vFSAD\" and the related work subtitles \"Policy\" and \"Evaluation tasks,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the lack of comparison with a large quantity of work related to OOD detection in time-series data, providing an example of a relevant work by Kaur et al. Additionally, it critiques the related work subtitles for being non-descriptive and unrelated to the actual content. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts. The first part claims that the term \"vFSAD\" refers to OOD detection in time-series data, which includes a large quantity of work not mentioned in the paper. The reviewer provides an example of a relevant work, \"CODiT: Conformal Out-of-Distribution Detection in Time-Series Data\" by Kaur et al., which supports the claim. This provides a clear and specific reference, making the claim mostly verifiable. The second part critiques the related work subtitles as non-descriptive and unrelated to the actual content. However, it lacks specific examples or detailed reasoning to substantiate this claim, making it somewhat verifiable. Overall, the comment is mostly verifiable, as the first part is well-supported, but the second part requires more detailed justification. Therefore, the score is 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies two distinct issues. First, it points out that the term \"vFSAD\" refers to OOD detection in time-series data, which includes a significant body of work not mentioned in the paper. The reviewer provides an example of a relevant work, \"CODiT: Conformal Out-of-Distribution Detection in Time-Series Data\" by Kaur et al., which could guide the authors in expanding their literature review. This feedback is valuable as it highlights a gap in the paper and suggests a specific work to consider. Second, the comment critiques the related work subtitles \"Policy\" and \"Evaluation tasks\" for being non-descriptive and unrelated to the actual content. While this critique is valid, it lacks specific suggestions on how to improve the subtitles, which would make the feedback more actionable. Overall, the comment is mostly helpful as it provides clear guidance on expanding the literature review but could be more comprehensive with additional suggestions for improving the related work section.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that an ablation study should be added to justify the memory size selection, which is a clear and direct action for the authors to take. The comment provides a specific and concrete suggestion on how to improve the draft, making it highly actionable. The authors know exactly what needs to be done to address the issue, which is to conduct an ablation study to clarify the impact of memory size on the results.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the effect of memory size is ambiguous and recommends adding an ablation study to justify the memory size selection. However, it does not specify which part of the paper discusses memory size, making it weakly grounded. The comment is specific in suggesting the addition of an ablation study to address the ambiguity, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the effect of memory size is ambiguous and suggests adding an ablation study to justify the memory size selection. However, the comment does not provide any specific reasoning or evidence to support why the effect of memory size is ambiguous or why an ablation study is necessary. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the ambiguity surrounding the effect of memory size. It provides a clear and actionable suggestion by recommending the inclusion of an ablation study to justify the memory size selection. This feedback is valuable as it directs the authors to a concrete step that can enhance the clarity and robustness of their results. However, the comment could be more helpful if it offered additional guidance on how to design and interpret the ablation study or what specific aspects of memory size should be explored. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the consistency of notation in the paper, specifically the use of the abbreviation \"GNN\" at the beginning of the paper without a full definition until later in Section 2. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should ensure consistency in notation throughout the paper, but it lacks concrete steps or recommendations on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific locations where the abbreviation \"GNN\" appears, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the inconsistency in the notation, noting that the full definition \"Graph Neural Network (GNN)\" is provided much later in Section 2. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abbreviation \"GNN\" is used without a full definition until later in the paper. This is a factual observation that does not require subjective interpretation or justification. It is a straightforward statement about the consistency of notation in the paper, making it a normal statement rather than a claim. Therefore, the label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the consistency of notation in the paper, noting that the abbreviation \"GNN\" is used without a full definition until later in Section 2. This feedback is clear and actionable, as it points out a potential source of confusion for readers and suggests that the authors should ensure that all abbreviations are defined at their first use. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending a specific placement for the definition or suggesting a way to clarify the notation. Despite this, the comment is mostly helpful as it directs the authors to a specific area for improvement, making it a 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the performance of baseline methods on the DAVIS dataset, noting that it is lower compared to state-of-the-art results. It suggests that the effectiveness of the proposed loss function on baseline methods does not necessarily guarantee its effectiveness on top-performing ones. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their results. The action is implicit and vague, as the authors are left to infer that they should investigate the performance of their method on top-performing algorithms or consider alternative approaches. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"DAVIS dataset\" and \"baseline methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear comparison with state-of-the-art results, citing a specific percentage (65.6% J mean on 2019-val) and referencing a relevant study by Luiten et al. (2020). This provides detailed information on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of baseline methods on the DAVIS dataset is low compared to state-of-the-art results, citing a specific example of 65.6% J mean on 2019-val from a reference. This provides a clear comparison and supports the claim with a reference to external work. However, the comment could be strengthened by providing more detailed analysis or examples of how the proposed loss function might not be effective on top-performing algorithms. Overall, the claim is mostly verifiable due to the inclusion of a specific reference, but it could be more robust with additional supporting evidence. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment highlights a concern about the performance of baseline methods on the DAVIS dataset, noting that it is lower compared to state-of-the-art results. It suggests that the effectiveness of the proposed loss function on baseline methods does not guarantee its effectiveness on top-performing ones. This feedback is somewhat helpful as it points out a potential weakness in the paper's results and encourages the authors to consider the performance of their method on more advanced algorithms. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address this issue or improve the performance of the proposed method. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the results for the proposed two-step decoding method, specifically asking if the results in Table 1 with decoder downsampling are obtained with or without the two-step method. It also requests information on how much worse the two-step method performs if it is not used. While the comment does not explicitly instruct the authors to include this information, it implies that the authors should clarify or provide additional details about the results. The action is implicit but concrete, as the authors know exactly what information is needed to address the question. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a question about the results for the proposed two-step decoding method, specifically asking if the results in Table 1 with decoder downsampling are obtained with or without the two-step method. It also requests information on how much worse the two-step method performs if it is not used. While the comment does not explicitly mention a specific section or table, the authors can infer that it relates to the results section, particularly Table 1. The comment is specific in detailing what needs to be clarified or addressed regarding the results. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the results for the proposed two-step decoding method, specifically asking if the results in Table 1 with decoder downsampling are obtained with or without the two-step method. It also requests information on how much worse the two-step method performs if it is not used. The comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a critical question about the results section of the paper, specifically regarding the proposed two-step decoding method. It questions whether the results in Table 1 with decoder downsampling are obtained with or without the two-step method and requests information on how much worse the two-step method performs if it is not used. This feedback is clear and actionable, as it prompts the authors to clarify or provide additional details about the results, which could significantly impact the understanding and interpretation of the paper. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on presenting the results in a more comprehensive manner. Overall, the comment is mostly helpful as it directs the authors to a critical area that needs clarification, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to increase the font size in the figures to improve readability. This is a direct and concrete action that the authors can take to address the issue. The comment provides clear guidance on what needs to be done, making it highly actionable. Therefore, the comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the figures,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the font size being too small, and provides a direct action for improvement by suggesting an increase in font size to enhance readability. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for improvement, suggesting that the font size in the figures is too small and should be increased for better readability. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual statement asking for a change, making it a \"No\" classification.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, identifying a specific issue with the font size in the figures being too small, which affects readability. It provides a direct suggestion to increase the font size, offering a straightforward way for the authors to improve their draft. This feedback is valuable as it addresses a tangible aspect of the paper that can be easily corrected, enhancing the overall readability and usability of the figures. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that only synthetic problems are considered in the experiments, but it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether this is a concern, whether it should be addressed, or how the authors might consider including real-world problems in their experiments. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that only synthetic problems are considered in the experiments, but it does not specify which part of the paper this observation is based on. The authors may infer that it relates to the experimental section, but without explicit mention, it is weakly grounded. The comment is specific in identifying the issue of considering only synthetic problems, but it lacks detailed guidance on how to address this or what specific aspects of the experiments should be revised. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that only synthetic problems are considered in the experiments, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion or how it affects the validity of their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential limitation in the experiments by suggesting that only synthetic problems are considered. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or expand their experiments to include real-world problems. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer sufficient guidance to be fully beneficial.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the authors should compare their explainer, which generates natural language explanations, with other NLE interpretability tools. This is a clear and direct action for the authors to take, as it specifies the type of comparison that should be made. The comment provides concrete guidance on how to improve the draft by suggesting a specific comparison that would enhance the evaluation of the explainer. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"NLE baselines\" and \"feature attribution type of explanations,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely comparisons with other NLE interpretability tools. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should compare their explainer, which generates natural language explanations, with other NLE interpretability tools. This claim is based on the observation that the authors only compared their work to feature attribution type of explanations, which is not sufficient given the nature of their explainer. The comment logically reasons that a comparison with other NLE interpretability tools would provide a more comprehensive evaluation. However, it does not provide specific examples of these tools or detailed reasoning, which would strengthen the claim. Therefore, the comment is mostly verifiable, as it provides a logical basis for the suggestion but lacks detailed evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, noting that the authors have only compared their explainer to feature attribution type of explanations, whereas their explainer generates natural language explanations. It suggests that the authors should compare their work with other NLE interpretability tools, which would provide a more comprehensive evaluation. This feedback is clear and actionable, offering a concrete suggestion for improvement that could enhance the validity and robustness of the paper. However, the comment could be more helpful if it provided specific examples of NLE interpretability tools that the authors should consider for comparison. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for expansion, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the use of only one pertinent positive data point in Eq. (5), while there are many other data points that satisfy Eqs. (1) and (2). It suggests that these additional data points contribute equally to Eq. (3) but are not included in the exhaustive test. The comment implies that the authors should consider including these data points in their analysis to provide a more comprehensive evaluation. However, it does not explicitly instruct the authors to do so, leaving the action implicit. The suggestion is concrete, as it specifies the need to include additional data points, but the lack of explicit instruction makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. (5),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the use of only one pertinent positive data point, highlights the existence of other data points that satisfy Eqs. (1) and (2), and notes that these additional data points contribute equally to Eq. (3) but are not included in the exhaustive test. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that only one pertinent positive data point is used in Eq. (5), while there are many other data points that satisfy Eqs. (1) and (2). The reviewer suggests that these additional data points contribute equally to Eq. (3) but are not included in the exhaustive test. This claim is somewhat verifiable as it provides a logical reasoning about the potential oversight in the analysis. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the analysis presented in the paper, specifically regarding the use of only one pertinent positive data point in Eq. (5). It points out that there are many other data points that satisfy Eqs. (1) and (2) and contribute equally to Eq. (3), but these are not included in the exhaustive test. This feedback is clear and actionable, as it highlights a potential limitation in the analysis and suggests that the authors should consider including these additional data points to provide a more comprehensive evaluation. However, the comment could be more helpful if it provided specific guidance on how to incorporate these data points or why they are important. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their results using both supervision data and document augmentation to demonstrate the additional performance boost of the latter. It implies that the authors should conduct an experiment that combines both methods to show their effectiveness. While the action is implicit, it is concrete in suggesting a specific experiment to conduct. The authors know exactly what they need to do to address the comment, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the comparison of results without using supervision data, specifically mentioning InPars-V2 and Promptagator. It suggests that the authors should demonstrate how document augmentation can enhance performance on top of existing supervised retrievers. However, it does not specify which part of the paper this comparison should be made in, leaving the authors to infer the relevant sections. The comment is specific in its suggestion but lacks full grounding, as it does not explicitly mention the sections or figures where this comparison should be included. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the results should be compared using both supervision data and document augmentation to demonstrate the additional performance boost of the latter. The reviewer provides a logical reasoning by stating that the trained retrievers can be used directly out-of-the-box (OOTB) for other domains, implying that the augmentation could provide an additional performance boost. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the potential benefits of combining supervision data and document augmentation to fully understand the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the comparison of results, noting that the evaluation is conducted without using supervision data, which excludes InPars-V2 and Promptagator from the comparison. It suggests that the authors should demonstrate how document augmentation can enhance performance on top of existing supervised retrievers. This feedback is clear and actionable, as it provides a specific direction for the authors to explore and potentially improve their work. However, the comment could be more helpful if it offered additional guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the discussion regarding the cache hierarchy, specifically the order of dimensions, shared data, and how the individual levels are applied together. While it identifies a missing aspect of the paper, it does not provide explicit guidance on how the authors should address this issue. The comment suggests that the authors should discuss the cache hierarchy in more detail, but it lacks concrete steps or examples on how to do so. This makes the action implicit and somewhat vague, as the authors can infer that they need to discuss the cache hierarchy but are not provided with specific instructions on how to do it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"cache hierarchy\" and the \"order in which the three dimensions are applied,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what is missing in the discussion, namely the application of the individual levels together and how they share data. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the cache hierarchy is not discussed in the paper, specifically regarding the order of dimensions, shared data, and how individual levels are applied together. The reviewer points out a contradiction between the initial hierarchy claim and the independence of individual levels in terms of memory benefits. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact issues and how they relate to the hierarchy claim, which could be challenging without further elaboration. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the discussion regarding the cache hierarchy, specifically the order of dimensions, shared data, and how individual levels are applied together. It points out a contradiction between the initial hierarchy claim and the independence of individual levels in terms of memory benefits. This feedback is clear and actionable, as it highlights a specific area where the authors need to provide more detailed information to support their claims. By addressing this gap, the authors can enhance the comprehensiveness and accuracy of their paper. However, the comment could be more helpful if it provided suggestions on how to structure the discussion or what specific details to include. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the authors managed their GPU memory to prevent an out-of-memory (OOM) issue during pretraining, given that they need to forward propagate three times before one backpropagation. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to manage GPU memory or prevent OOM issues. The action is implicit and somewhat vague, as the authors can infer that they need to address the memory management issue but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about how the authors managed their GPU memory to prevent an out-of-memory (OOM) issue during pretraining, given the specific propagation steps mentioned. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the management of GPU memory during pretraining, given the specific propagation steps mentioned. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, making it a normal statement. Therefore, the label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the management of GPU memory during pretraining, given the need for three forward propagations before one backpropagation, as indicated in Figure 2. This question highlights a potential issue that could impact the feasibility of the proposed method, particularly in terms of computational resources. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or optimize their approach to prevent out-of-memory (OOM) errors. While it identifies a critical concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential problem but does not offer a clear path for resolution.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the Abstract is not well written and recommends rewriting it to better present the contributions. This provides a clear and direct action for the authors to take, which is to revise the Abstract. However, the comment does not offer specific guidance on how to improve the writing or what aspects of the contributions should be emphasized. While the action is explicit, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the Abstract, which is that it is not well written and does not effectively convey the contributions. The comment provides a clear action for the authors to take, which is to rewrite the Abstract to better present their contributions. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Abstract is not well written and difficult to understand the contributions. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed feedback or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the Abstract, noting that it is not well written and does not effectively convey the contributions of the paper. It provides a clear and actionable suggestion for the authors to rewrite the Abstract to better present their contributions. This feedback is valuable as it directs the authors to a critical area that needs improvement, which can enhance the clarity and impact of their work. However, the comment could be more helpful if it offered specific guidance on how to improve the writing or what aspects of the contributions should be emphasized. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more detailed.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the ADE dataset may be biased and favor the performance of the proposed method. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how to address the potential bias or whether it should be considered in the evaluation. Without actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the ADE dataset, which is mentioned in the context of image parsing. However, it does not specify which part of the paper discusses the ADE dataset, making it weakly grounded. The comment suggests that the dataset may be biased and favor the performance of the proposed method, but it does not provide specific details or examples to support this claim. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the ADE dataset may be biased and favor the performance of the proposed method. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The lack of detailed justification or examples makes it difficult for the authors to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the ADE dataset may be biased and favor the performance of the proposed method. While it identifies a potential issue with the dataset, it does not provide any specific guidance or suggestions on how the authors might address this bias or consider alternative datasets. The comment lacks actionable feedback, leaving the authors without a clear understanding of how to improve their work. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of two matrices (A and B) to represent each relation (edge type) in section 2.1.2, suggesting that the two matrices might be the same. It also mentions that many matrices are not used in the following text. While the comment implies that the authors should clarify the purpose of using two matrices and potentially address the issue of unused matrices, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation for the use of two matrices and consider the relevance of the unused matrices. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.1.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of two matrices (A and B) to represent each relation and noting that many matrices are not used in the following text. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of two matrices (A and B) to represent each relation in section 2.1.2, suggesting that they might be the same. It also mentions that many matrices are not used in the following text. While the comment raises a valid point about potential redundancy or inconsistency, it lacks specific reasoning or evidence to support the claim. The authors are left to infer the issue and address it without clear guidance or examples. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks detailed justification or references.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a specific question about the use of two matrices (A and B) to represent each relation in section 2.1.2, suggesting that they might be the same. It also points out that many matrices are not used in the following text. This feedback is clear and actionable, as it prompts the authors to clarify the purpose of using two matrices and to address the issue of unused matrices. By addressing these points, the authors can improve the clarity and coherence of their work. However, the comment could be more helpful if it provided additional guidance on how to resolve these issues or suggested potential improvements. Overall, the comment is mostly helpful, as it identifies specific areas for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses confusion about a specific statement in Section 2, indicating that the meaning of \"the semantics of the upsampled feature map can be stronger than the original one\" is unclear. However, it does not provide any explicit or implicit guidance on how the authors should address this confusion or clarify the statement. There is no suggestion for additional information, examples, or explanations that could help resolve the issue. As a result, the comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the end of Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the confusion about the statement \"the semantics of the upsampled feature map can be stronger than the original one.\" This provides clear guidance on what needs to be clarified or explained in the paper. Therefore, this comment is labeled as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses confusion about a specific statement in Section 2, indicating that the meaning of \"the semantics of the upsampled feature map can be stronger than the original one\" is unclear. However, the comment does not provide any supporting evidence, reasoning, or examples to clarify the confusion or suggest how the authors might address it. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion or how to improve the clarity of the statement. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific point of confusion in the paper, namely the statement \"the semantics of the upsampled feature map can be stronger than the original one\" at the end of Section 2. By pointing out this confusion, the reviewer highlights an area where the authors need to clarify their explanation to ensure that the reader understands the concept. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of the statement. While it identifies a weakness, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors need to clarify the differences between their method and other methods for predicting user personality. It explicitly mentions a reference, [1], which provides a specific example of a related work. However, the comment does not provide detailed guidance on how to clarify these differences or what specific aspects should be highlighted. While the action is explicit, the lack of concrete details on how to implement the suggestion makes it somewhat actionable. The authors know they need to clarify the differences but may not be entirely sure of the exact steps to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests clarifying the differences between the proposed method and other methods for predicting user personality, specifically mentioning a reference [1] by Yang et al. However, it does not specify which part of the paper should include this clarification, making it weakly grounded. The comment is specific in suggesting the need to differentiate the method from others, but it lacks detailed guidance on how to achieve this differentiation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors need to clarify the differences between their method and other methods for predicting user personality. It references a specific paper, [1], which provides a basis for the claim. However, the comment does not elaborate on how the referenced paper relates to the authors\\' work or what specific differences need to be clarified. This lack of detailed explanation or examples makes the claim somewhat verifiable, as the authors would need to delve deeper into the referenced work to fully understand the basis of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors need to clarify the differences between their method and other methods for predicting user personality. It provides a specific reference, [1], which could serve as a basis for comparison. However, the comment lacks depth and does not offer detailed guidance on how to clarify these differences or what specific aspects should be highlighted. While it identifies a potential area for improvement, the feedback is somewhat vague and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a necessary clarification but does not fully support the authors in making the necessary improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the theoretical justification for imposing specific constraints in LoRA tuning, specifically why constraining B to be the basis and A to be the coordinate would accelerate convergence. It also suggests that vanilla LoRA parameters might have more freedom to change compared to the constrained version. Additionally, the comment questions the necessity of step size tuning despite theoretical claims that a constant step size is sufficient. While the comment identifies areas of confusion and potential improvements, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should provide a clearer theoretical justification and consider step size tuning. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"LoRA tuning\" and \"imposing B to be the basis and A to be coordinate,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical justification for the constraints in LoRA tuning and suggests that the authors should provide a clearer explanation. Additionally, it questions the necessity of step size tuning, which further specifies the areas needing attention. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the theoretical justification for imposing specific constraints in LoRA tuning, specifically why constraining B to be the basis and A to be the coordinate would accelerate convergence. The reviewer provides a logical reasoning by pointing out that, theoretically, both B and A should cover the same space (X = BA), and that constraining B to be on B^TB=I might limit its freedom to change compared to vanilla LoRA parameters. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to delve deeper into the theoretical aspects to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the theoretical justification for imposing specific constraints in LoRA tuning, specifically why constraining B to be the basis and A to be the coordinate would accelerate convergence. It points out that, theoretically, both B and A should cover the same space (X = BA), and suggests that vanilla LoRA parameters might have more freedom to change compared to the constrained version. Additionally, the comment questions the necessity of step size tuning despite theoretical claims that a constant step size is sufficient. While the comment identifies areas of confusion and potential improvements, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it prompts the authors to clarify their theoretical justification and consider additional experimentation, but it could be more actionable with detailed recommendations. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct more ablation studies or analyses on problems other than the shortest path problem, as most experimental environments are related to this problem and the architecture (PathGNN) is biased towards it. This feedback is explicit, as it clearly states what action the authors should take to improve their draft. It is also concrete, as it provides a specific suggestion for additional analysis that could enhance the paper\\'s credibility. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the experimental environments are closely related to the shortest path problem and that the design of the architecture (PathGNN) is biased towards this kind of problem. It implies that the authors should conduct more ablation studies or analyses on problems other than shortest path problems. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting additional analyses, but without clear grounding, it is challenging for the authors to know where to make these changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experimental environments are closely related to the shortest path problem and that the design of the architecture (PathGNN) is biased towards this kind of problem. The reviewer recommends conducting more ablation studies or analyses on problems other than shortest path problems to make the results more convincing. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the assertion about the bias in the architecture. Providing more detailed evidence or examples would strengthen the claim, making it more verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the experimental setup, noting that most experimental environments are related to the shortest path problem and that the architecture (PathGNN) is biased towards this kind of problem. It suggests that conducting more ablation studies or analyses on problems other than shortest path problems would make the results more convincing. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it offered examples of alternative problems or suggested specific analyses to conduct. Overall, the comment is mostly helpful, as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper could include more recent models, particularly in multilingual settings or other languages beyond English. While the comment implies that the authors should expand their comparison to include more recent models, it does not provide specific guidance on which models to include or how to incorporate them into the comparison. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could include more recent models, particularly in multilingual settings or other languages beyond English. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to specific sections or elements of the paper, the authors may find it challenging to determine where to make these additions. The comment is specific in suggesting the inclusion of more recent models, but it lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could include more recent models, particularly in multilingual settings or other languages beyond English. However, it does not provide specific examples or references to recent models that should be included, nor does it explain why these models are relevant or how they would enhance the paper. This lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the relevance and necessity of including these models based on the general suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper could be improved by including more recent models, particularly in multilingual settings or other languages beyond English. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by expanding the comparison to include more contemporary models. However, the comment could be more helpful if it included specific examples of models that should be considered or detailed guidance on how to incorporate them into the comparison. Despite this, the suggestion is mostly helpful as it offers a clear path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of visualization of the learned context token, which is crucial for understanding the differences between context tokens of different groups. It also mentions that the paper is simple and effective but lacks novelty and analysis for the insight of the approach. However, the comment does not provide explicit guidance on how to address these issues or suggest specific visualizations or analyses that could be included. The action is implicit and vague, leaving the authors to infer that they need to enhance the visualization and analysis sections but without concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a lack of visualization of the learned context token, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper this issue pertains to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue of missing visualization and the limitation of the paper\\'s novelty and analysis. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks visualization of the learned context token, which is necessary to show the differences between context tokens of different groups. It also suggests that the paper is simple and effective but lacks novelty and analysis for the insight of the approach. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence renders the claim somewhat verifiable, as the authors would need to infer the specific issues and address them without clear guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of visualization of the learned context token, which is crucial for understanding the differences between context tokens of different groups. It also highlights the simplicity and effectiveness of the paper but notes that its novelty is limited due to the absence of analysis for the insight of the approach. While the comment provides some insight into areas that need attention, it lacks detailed guidance or suggestions on how to enhance the visualization or analysis sections. The feedback is somewhat helpful as it directs the authors to areas that require further development, but it could be more actionable with specific recommendations or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should report results for other models beyond MetaOptNet to demonstrate the generality of their method and its ability to improve multiple baseline models. This is a clear and direct action for the authors to take, providing a specific and concrete step to enhance the paper. The comment also explains why this action is important, which further supports the authors in understanding the rationale behind the suggestion. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current results, which show only small benefits over the baseline model, and suggests that reporting results for other models, such as MetaOptNet, would strengthen the paper by demonstrating its generality and effectiveness across multiple baseline models. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the current results show only small benefits over the baseline model and suggests that reporting results for other models would strengthen the paper. However, the comment does not provide specific examples of other models that could be used or detailed reasoning on why these models would be beneficial. This lack of supporting evidence or detailed justification makes the claim somewhat verifiable, as the authors would need to infer the potential benefits and identify suitable models on their own. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern with the experimental section, noting that the current results show only small benefits over the baseline model. It suggests that reporting results for other models, such as MetaOptNet, would strengthen the paper by demonstrating the generality of the method and its ability to improve multiple baseline models. This feedback is clear and actionable, providing the authors with a concrete suggestion to enhance the robustness and impact of their findings. However, the comment could be more helpful if it included specific examples of other models that could be used or detailed guidance on how to present the results. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper could benefit from a more extensive comparison by including well-established methods like FTML and LFW. While it implies that the authors should add these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to include these comparisons without specific guidance on how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from a more extensive comparison by including well-established methods like FTML and LFW. However, it does not specify which part of the paper this comparison should be included in, such as the results section or the discussion. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper the comment addresses. The comment is specific in suggesting the inclusion of FTML and LFW for a broader comparison, which provides clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a more extensive comparison by including well-established methods like FTML and LFW. The claim is somewhat verifiable as it provides a logical reasoning for the need for a broader comparison, which would offer a more comprehensive evaluation of the proposed method. However, the comment lacks specific examples or references to these methods, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s comparison with recent baselines, suggesting that a more extensive comparison with well-established methods like FTML and LFW would provide a more comprehensive evaluation of the proposed method\\'s strengths and weaknesses. This feedback is clear and actionable, as it directs the authors to expand their comparison to include these specific methods. However, the comment could be more helpful if it provided additional guidance on how to incorporate these comparisons or suggested specific aspects to focus on. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed CRF variants underperform compared to hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. It suggests downgrading the focus of the paper on using CRFs for modeling the task due to this underperformance. Additionally, it notes that location embeddings provide additional information on the main dataset but not in the extra dataset, suggesting that they might be useful for specific types of datasets. However, the comment does not provide specific guidance on how the authors should address these issues or improve their work. While it identifies areas for improvement, it lacks concrete actions or suggestions, making it somewhat actionable. The authors are left to infer that they should reconsider their focus and discuss the limitations of location embeddings, but they are not provided with explicit steps to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed CRF variants\" and \"hierarchical transformers (HiTRF),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the datasets involved, including the main dataset and the dataset discussed in Appendix D. The comment is specific in detailing the underperformance of the CRF variants compared to HiTRF and the limited utility of location embeddings in certain datasets. This provides clear guidance on what needs to be addressed in the paper, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed CRF variants underperform compared to hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. It also suggests that location embeddings provide additional information on the main dataset but not in the extra dataset, implying that they might be useful for specific types of datasets. However, the comment lacks specific numerical results or detailed comparisons to substantiate these claims. While it provides some logical reasoning, the absence of concrete evidence or references makes the claims somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a detailed analysis of the performance of the proposed CRF variants compared to hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. It highlights that the CRF variants underperform in both cases, suggesting that the focus of the paper on using CRFs for modeling the task should be downgraded. Additionally, the comment notes that location embeddings provide additional information on the main dataset but not in the extra dataset, which may indicate their utility for specific types of datasets. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their work. While it identifies important areas for consideration, the feedback could be more actionable and detailed to be highly helpful. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the impact of training-testing inconsistency but does not provide any explicit or implicit guidance on how the authors should address this issue. It lacks specific suggestions or actions for the authors to take, such as recommending a way to resolve the inconsistency or suggesting additional experiments to evaluate its impact. Without concrete steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the impact of training-testing inconsistency but does not specify which part of the paper this issue is discussed in. Without explicit references to sections, tables, or figures, the authors cannot confidently determine where this comment pertains to. Additionally, the comment lacks specificity regarding what aspects of the training-testing inconsistency are unclear or how they could be clarified. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the impact of training-testing inconsistency but does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the training-testing inconsistency, which could be a critical aspect of the paper\\'s methodology or results. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this inconsistency or its impact. Without actionable feedback or examples, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is barely helpful, as it highlights a potential issue but does not offer any actionable steps for resolution.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the unclear condition for y membership and the lack of backing for some claims. However, it does not provide explicit guidance on how to address these issues. The comment implies that the authors should clarify the condition for y membership and provide evidence for their claims, but it does not specify how to do so. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the condition for y membership and mentions that the sets S are disjoint, as defined above. However, it does not specify which part of the paper discusses the condition for y membership or where the sets S are defined, making it weakly grounded. The comment is specific in pointing out that some claims are not backed up, particularly referencing the second line after an equation. This provides some guidance on what needs to be addressed, but the lack of explicit grounding limits the comment\\'s effectiveness. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the condition for y membership is unclear due to the disjoint sets S, as defined above. It also mentions that some claims are not backed up, specifically referencing the second line after an equation. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The lack of detailed justification or references makes the claim somewhat verifiable, as the authors would need to infer the specific problems and address them independently. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the unclear condition for y membership and the lack of backing for some claims. It points out that the sets S are disjoint, which may contribute to the confusion regarding the condition for y membership. Additionally, it highlights that some claims are not supported, specifically mentioning the second line after an equation. However, the comment does not provide detailed guidance or suggestions on how to clarify the condition for y membership or how to support the claims. While it highlights important areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that a few key references are not compared and explained, suggesting that the authors should include these comparisons and explanations in their draft. However, the comment does not specify which references are missing or how they should be integrated into the paper. While the action is implicit, the authors can infer that they need to add comparisons and explanations for these references. However, the lack of specificity about which references or how to integrate them makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a few key references are not compared and explained, implying that this is an area that needs attention. However, it does not specify which references are missing or where in the paper these comparisons should be made. This lack of specificity and explicit mention of sections or references makes it difficult for the authors to pinpoint the exact parts of the paper that need revision. The comment is not grounded as it does not identify a specific part of the paper, and it is also not specific about what needs to be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"a few key references that are highly related are not compared and explained.\" However, it does not provide specific examples of these references or explain why they are important or relevant. Without detailed justification or examples, the authors may find it challenging to understand which references are being referred to and why they are significant. This lack of specificity makes the claim difficult for the authors to address, rendering it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that a few key references are not compared and explained. This feedback is relevant and actionable, as it points out a gap in the analysis or discussion that could be addressed to enhance the paper\\'s comprehensiveness. However, the comment lacks specificity regarding which references are missing or how they should be integrated into the paper. Providing more detailed guidance on which references to include and how to incorporate them would make the feedback more helpful. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the analysis of SCL in section 5.2 regarding few-shot ability, questioning the claim that a more regularized representation space by SCL leads to better generalization in few-shot scenarios. It points out that the results in Figure 7(c) and (d) do not support this claim, as COCO-LM achieves more improvements with fewer labels, which then diminish with more labels. The comment also suggests checking if COCO-LM benefits sentence retrieval tasks with the learned anisotropy text representations. While the comment identifies specific issues with the analysis and suggests additional checks, it does not provide explicit instructions on how to address these concerns or improve the analysis. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issues. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.2\" and \"Figure 7(c) and (d),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the analysis of SCL regarding few-shot ability, questioning the claim that a more regularized representation space leads to better generalization. The comment further specifies that the results do not meet expectations and suggests checking if COCO-LM brings benefits to sentence retrieval tasks. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis of SCL in section 5.2 regarding few-shot ability is not convincing. It provides specific examples from Figure 7(c) and (d), stating that COCO-LM achieves more improvements with fewer labels, which then diminish with more labels. This detailed critique offers a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to support the claim about the benefits of COCO-LM in sentence retrieval tasks. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific feedback on the analysis of SCL in section 5.2 regarding few-shot ability. It questions the claim that a more regularized representation space by SCL leads to better generalization in few-shot scenarios, pointing out that the results in Figure 7(c) and (d) do not support this claim. The comment also suggests checking if COCO-LM brings benefits to sentence retrieval tasks with the learned anisotropy text representations. This feedback is clear and actionable, as it identifies a potential weakness in the analysis and suggests a specific area for further investigation. However, it could be more helpful if it provided additional guidance on how to address the issue or improve the analysis. Overall, the comment is mostly helpful, as it directs the authors to a specific area needing improvement and offers a constructive suggestion for further exploration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting more experiments on other Large Language Models (LLMs) to demonstrate the generalization of the proposed framework. While the comment implies that additional experiments are needed, it does not provide specific guidance on which LLMs to choose, how to design the experiments, or what metrics to use for evaluation. The action is implicit and somewhat vague, as the authors can infer the need for more experiments but lack detailed instructions on how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments on other Large Language Models (LLMs) to demonstrate the generalization of the proposed framework. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of results. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding which LLMs should be tested or what aspects of generalization should be explored. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests conducting more experiments on other Large Language Models (LLMs) to demonstrate the generalization of the proposed framework. However, the comment lacks specific reasoning or evidence to support why additional experiments are necessary or which LLMs would be appropriate for this purpose. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting more experiments on other Large Language Models (LLMs) to demonstrate the generalization of the proposed framework. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide guidance on which LLMs to choose, how to design the experiments, or what metrics to use for evaluation. The comment is somewhat helpful as it points out a direction for further research, but it does not offer detailed actionable advice, leaving the authors with a general idea of what to consider without a clear path forward. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two separate comments. The first part suggests that the authors need to clarify what is considered \"short\" and \"long\" video to determine the downsample layers. This is an explicit request for clarification, providing a clear action for the authors to take. The second part suggests an \"apple-apple comparison\" of SOTA VLM/Video-LLM outputs for qualitative examples. While this is also an explicit suggestion, it lacks specific guidance on how to conduct this comparison. Overall, the comment is mostly actionable because it provides clear actions but could be more detailed in its second part.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific suggestions for improvement, such as clarifying what is considered \"short\" and \"long\" video and suggesting an \"apple-apple comparison\" of SOTA VLM/Video-LLM outputs for qualitative examples. This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two separate comments. The first part requests clarity on what is considered \"short\" and \"long\" video for determining downsample layers, which is a factual request for clarification and does not contain a claim. The second part suggests an \"apple-apple comparison\" of SOTA VLM/Video-LLM outputs for qualitative examples, which is a suggestion for improvement. Since the first part is a factual request and the second part is a suggestion, neither part contains a claim that requires verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides two distinct suggestions for improvement. The first part requests clarity on what is considered \"short\" and \"long\" video for determining downsample layers, which is a specific and actionable feedback that can help the authors clarify their methodology. The second part suggests an \"apple-apple comparison\" of SOTA VLM/Video-LLM outputs for qualitative examples, which could enhance the paper\\'s evaluation and comparison with existing models. However, the comment could be more helpful if it provided additional guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the feedback is mostly helpful as it identifies areas for improvement and offers some direction, but it could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation in the paper regarding the efficiency of generating multiple objects, particularly in scenes with a high number of objects or complex interactions. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no suggestion on how to improve the efficiency or what specific changes could be made to mitigate this limitation. As a result, the authors are left without any guidance on how to proceed, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper discusses the generation of multiple objects and the potential limitation in terms of efficiency. The authors cannot confidently determine which section or figure this comment refers to. Additionally, the comment is not specific because it does not provide detailed guidance on how to address the potential limitation or suggest improvements. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that generating multiple objects takes longer, depending on the number of objects, which indicates a potential limitation in terms of efficiency. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper regarding the efficiency of generating multiple objects, particularly in scenes with a high number of objects or complex interactions. This is a relevant observation that could impact the practical application of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or improve the efficiency of their approach. Without actionable advice or detailed feedback, the authors are left with a general awareness of the issue but no clear path for improvement. Therefore, the comment is somewhat helpful, as it highlights a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the technical contribution is thin and incremental, as the interpolative decomposition used is not novel. It recommends that the authors focus on finding additional applications and deeply evaluating the approach to uncover more properties of the representation. While the comment implies that the authors should take these actions, it does not provide explicit instructions on how to implement them. The suggestion is concrete in terms of the actions to be taken, but the lack of detailed guidance on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the technical contribution of the paper, specifically mentioning that the algorithm proposed may be considered incremental since it uses interpolative decomposition, which is not novel. However, it does not specify which part of the paper discusses the algorithm or the contribution, making it weakly grounded. The comment is specific in suggesting that the authors focus on finding additional applications and evaluating the approach to uncover more properties of the representation, which could enhance the manuscript\\'s value. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical contribution is thin and incremental, as the interpolative decomposition used is not novel. The reviewer suggests that the authors focus on finding additional applications and evaluating the approach to uncover more properties of the representation. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the contribution is incremental. This makes the claim somewhat verifiable, as the authors would need to further investigate the novelty of the decomposition and the potential applications to fully understand and address the feedback.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper's technical contribution, suggesting that the algorithm proposed may be considered incremental because it uses interpolative decomposition, which is not novel. The reviewer provides a constructive suggestion by recommending that the authors focus on finding additional applications and deeply evaluating the approach to uncover more properties of the representation. This feedback is actionable and offers a clear direction for the authors to enhance the value of their manuscript. However, the comment could be more helpful if it provided specific examples or guidance on how to identify and explore these additional applications. Overall, the comment is mostly helpful as it directs the authors toward a meaningful area for improvement, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the neural network library used for implementing the system and notes the lack of details on the implementation. While it implies that the authors should provide this information, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to include details about the library and implementation, but the comment does not specify how to do this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the neural network library used for implementing the system and notes the lack of details on the implementation. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in its request for details on the implementation, but without explicit references to sections or figures, the authors may find it challenging to pinpoint where this information should be added. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the neural network library used for implementation and a statement noting the lack of details on the implementation. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the neural network library used for implementing the system and notes the lack of details on the implementation. While it identifies a gap in the paper, it does not provide specific guidance or suggestions on how the authors might address this issue or improve the clarity of their implementation details. The comment lacks actionable feedback, leaving the authors with a general idea of what is missing but without a clear path for improvement. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific issues with clarity, mentioning that some math notations are undefined and some details in Figure illustrations are missing. However, it does not provide explicit instructions or suggestions on how to address these issues. The comment implies that the authors should clarify these points, but it lacks concrete guidance on what specific actions to take or how to improve the clarity. As a result, the authors may infer that they need to define the math notations and provide more details in the figure illustrations, but the comment does not provide enough detail to be considered actionable. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies specific issues with clarity, mentioning that some math notations are undefined and some details in Figure illustrations are missing. However, it does not specify which sections or figures these issues pertain to, making it weakly grounded. The comment is specific in detailing what is unclear, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"some of the descriptions are unclear\" and provides specific examples, such as \"some math notations are undefined\" and \"some details in Figure illustrations are missing.\" However, it does not provide detailed explanations or examples of these unclear descriptions, making it difficult for the authors to understand the exact issues. The comment is somewhat verifiable as it highlights areas of potential confusion, but it lacks specific evidence or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with clarity in the paper, noting that some math notations are undefined and details in Figure illustrations are missing. This feedback is clear and actionable, as it directs the authors to address these specific areas of confusion. However, the comment could be more helpful if it provided additional guidance on how to clarify the math notations or what specific details are missing in the figure illustrations. Despite this, the comment still offers valuable insights that can help the authors improve the clarity and comprehensibility of their draft. Therefore, it is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should mention the meaning of the notation \\\\nu in the text, in addition to its explanation in Algorithm 1. This provides a clear and direct action for the authors to take, ensuring that the notation is fully explained throughout the paper. The comment is specific and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by suggesting that the meaning of the notation \\\\nu should be mentioned in the text, in addition to its explanation in Algorithm 1. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification, suggesting that the meaning of the notation \\\\nu should be mentioned in the text, in addition to its explanation in Algorithm 1. This is a factual statement asking for additional information and does not contain an opinion or claim that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the explanation of the notation \\\\nu is only found in Algorithm 1 and suggesting that it should also be mentioned in the text. This feedback is clear and actionable, as it provides a direct suggestion for improvement that can enhance the clarity and comprehensibility of the paper. By addressing this comment, the authors can ensure that all relevant information is accessible to readers, making the paper more readable and understandable. Therefore, the comment is rated as highly helpful, as it offers a specific and constructive suggestion that can significantly improve the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises an interesting observation from appendix A.4, noting that using noise robust loss on pseudo-labels performs lower than using positive learning from Eq 9. It questions whether the model underfit is caused by pseudo-labels being very accurate, which would make positive learning more effective than a toned-down robust loss. While the comment highlights an intriguing finding and poses a question, it does not provide explicit guidance or suggestions for the authors to address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate the cause of underfitting and potentially explore ways to improve the robustness of the model. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"appendix A.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the observation that using noise robust loss on pseudo-labels performs lower than using positive learning from Eq 9, and it raises a question about whether the model underfit is caused by pseudo-labels being very accurate. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises an observation from appendix A.4 regarding the performance of noise robust loss on pseudo-labels compared to positive learning from Eq 9. It questions whether the model underfit is caused by pseudo-labels being very accurate, which would make positive learning more effective than a toned-down robust loss. While the comment provides a logical reasoning and a specific observation, it lacks detailed evidence or references to support the claim fully. The authors would need to explore this further to fully understand and address the issue. Therefore, the comment is somewhat verifiable, as it provides a basis for further investigation but requires additional evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies an interesting observation from appendix A.4, noting that using noise robust loss on pseudo-labels performs lower than using positive learning from Eq 9. It raises a question about whether the model underfit is caused by pseudo-labels being very accurate, which would make positive learning more effective than a toned-down robust loss. This feedback is somewhat helpful as it points out a potential issue with the model's performance and encourages the authors to explore the cause of underfitting. However, it lacks specific suggestions or guidance on how to address this issue, such as recommending experiments or analyses to further investigate the underfitting. Therefore, the comment is somewhat helpful, as it provides insight but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses confusion about a claim made in the paper regarding the impact of an additional exponential operation on runtime. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for clarification, additional explanation, or modification of the claim. The comment lacks actionable guidance, leaving the authors without a clear understanding of how to address the reviewer\\'s concern. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L248\" and \"requires an extra exponential,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly expresses confusion about the claim made regarding the impact of an additional exponential operation on runtime, questioning why it would be a consideration for the attacker. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses confusion about a claim regarding the impact of an additional exponential operation on runtime. However, it does not provide any supporting evidence, reasoning, or references to justify why this claim might be problematic or misleading. The comment lacks specific examples or detailed explanations that would help the authors understand the basis of the reviewer\\'s confusion. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to address the issue effectively.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses confusion about a specific claim made in the paper regarding the impact of an additional exponential operation on runtime. However, it does not provide any suggestions or guidance on how the authors might clarify or address this issue. The comment lacks actionable feedback, leaving the authors without a clear understanding of what needs to be improved or clarified. Without specific advice or suggestions, the comment does not contribute meaningfully to the authors\\' understanding of how to enhance their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the lack of comparison with existing methods, specifically mentioning \"Rubi: Reducing unimodal biases in visual question answering\" and \"Removing bias in multi-modal classifiers: Regularization by maximizing functional entropies.\" It questions the improvements of the proposed methods and suggests that the experiments are lacking in comparison with state-of-the-art (SOTA) methods. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific comparisons should be made. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed comparisons, but they are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction and abstract, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the improvements of the proposed methods and the lack of comparison with existing methods, such as \"Rubi: Reducing unimodal biases in visual question answering\" and \"Removing bias in multi-modal classifiers: Regularization by maximizing functional entropies.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are lacking in comparison with state-of-the-art (SOTA) methods, specifically mentioning two related works. However, the comment does not provide detailed reasoning or examples of how the proposed methods could be improved or compared to these works. The mention of specific related works is a good starting point, but without further elaboration or evidence, the claim remains somewhat vague. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some basis for the claim but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of comparison with existing methods, specifically mentioning \"Rubi: Reducing unimodal biases in visual question answering\" and \"Removing bias in multi-modal classifiers: Regularization by maximizing functional entropies.\" It questions the improvements of the proposed methods and suggests that the experiments are lacking in comparison with state-of-the-art (SOTA) methods. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work by providing comparisons with relevant existing methods. However, the comment could be more helpful if it offered specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment is mostly helpful, as it highlights a key area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point comments on the experiments showing that the proposed method enhances performance, but notes that this is not surprising given the introduction of more learnable parameters, including the temperature, which has been proven effective in previous works. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this observation or improve their draft. Without actionable suggestions or questions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experimental results and the introduction of more learnable parameters, including the temperature, which has been proven effective in previous works. However, it does not specify which experiments or sections of the paper are being referred to, making it difficult for the authors to pinpoint the exact part of the paper that needs attention. The comment provides some specificity by mentioning the introduction of more learnable parameters and the effectiveness of the temperature parameter, but it lacks full grounding as it does not explicitly mention the sections or figures being discussed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the enhancement in performance by the proposed method is not surprising, given the introduction of more learnable parameters, including the temperature, which has been proven effective in previous works. This claim is somewhat verifiable as it references a common practice in machine learning where introducing more parameters can lead to improved performance. However, the comment lacks specific references or examples of previous works that have demonstrated the effectiveness of the temperature parameter, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out that the enhancement in performance by the proposed method is not surprising, given the introduction of more learnable parameters, including the temperature, which has been proven effective in previous works. While this observation highlights a potential limitation in the paper, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer any guidance on how the authors might address this issue or enhance their draft. As a result, the comment is barely helpful, as it identifies a potential weakness but does not provide any actionable insights for the authors to improve their work.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the inspiration from neuroscience research is unnecessary and distracting to the main work. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to integrate the neuroscience inspiration more effectively or explaining why it is necessary. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the inspiration from neuroscience research, suggesting it is unnecessary and distracting to the main work. However, it does not specify which part of the paper this critique pertains to, such as a particular section or figure. Without explicit references or clear indicators, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the neuroscience inspiration are considered unnecessary or distracting. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the inspiration from neuroscience research is unnecessary and distracting to the main work. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to the neuroscience research or its relevance to the main work, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the inspiration from neuroscience research, suggesting that it is unnecessary and distracting to the main work. However, it does not provide any specific examples or detailed reasoning to support this claim, nor does it offer suggestions on how the authors might address this issue or integrate the neuroscience inspiration more effectively. Without actionable feedback or constructive guidance, the comment lacks value for the authors in improving their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to update the caption of Table 3 by adding information about the source dataset. It also provides a broader suggestion to ensure that all necessary information is included in the captions, such as the experiment details, so that readers do not have to search for it in the main text. This feedback is clear and provides concrete steps for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: adding information about the source dataset in the caption. Additionally, it provides a broader suggestion about including all necessary information in the captions to avoid confusion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the caption of Table 3 is unclear about the source dataset used. It provides a clear and specific request for the authors to update the caption by adding this information. This feedback is verifiable as it directly points out a specific issue and offers a concrete solution, making it easy for the authors to address. Therefore, the comment is categorized as fully verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the caption in Table 3, noting that it is unclear about the source dataset used. It provides a clear and actionable suggestion to update the caption by adding this information, ensuring that readers have all the necessary details without needing to search the main text. This feedback is valuable as it directly addresses a potential source of confusion and offers a straightforward way for the authors to improve the clarity of their work. However, the comment could be more helpful if it provided additional context or examples of how to effectively include this information in the caption. Overall, the comment is mostly helpful, as it provides actionable guidance that can significantly enhance the clarity of the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper lacks an explicit description of the specific architectures of value networks, policy networks, and uncertainty-aware networks. This lack of description is identified as a barrier to replication and evaluation of the approach. The comment provides a clear action for the authors to take: include explicit descriptions of these architectures. However, it does not specify how detailed these descriptions should be or what specific information should be included. While the action is explicit, the lack of concrete guidance on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of explicit descriptions of specific architectures, such as value networks, policy networks, and uncertainty-aware networks. This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific because it clearly specifies what is missing\u2014explicit descriptions of these architectures, which would help readers replicate and evaluate the approach. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks explicit descriptions of specific architectures, such as value networks, policy networks, and uncertainty-aware networks, which makes it difficult for readers to replicate and evaluate the approach. This claim is somewhat verifiable as it highlights a potential gap in the paper\\'s clarity. However, the comment does not provide specific examples or references to support the claim, which would strengthen the justification. The authors are left to infer the importance of detailed architectural descriptions, making the claim somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper, specifically the lack of explicit descriptions of the specific architectures used for value networks, policy networks, and uncertainty-aware networks. This omission is noted as a barrier to replication and evaluation of the approach. The comment provides a clear and actionable suggestion for improvement by emphasizing the need for detailed descriptions of these architectures. However, it could be more helpful if it offered specific guidance on what aspects of the architectures should be described or suggested ways to present this information. Despite this, the comment is mostly helpful as it directs the authors to a critical area that needs attention, enabling them to enhance the clarity and reproducibility of their work. Therefore, the comment aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several assumptions made in the paper that might render EMCTS inapplicable to real complex problems. It specifically mentions the assumption that the transition model P is true, the requirement for $Q^\\\\pi$ to be linear in Theorem 1, and the assumption that the learned models are consistent. However, the comment does not provide explicit guidance on how the authors should address these concerns or suggest alternative approaches. The action is implicit and vague, as the authors are left to infer that they need to reconsider these assumptions but are not given concrete steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1\" and \"P,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the assumptions made, such as the transition model P being true and the requirement for $Q^\\\\pi$ to be linear, as well as the assumption of consistent learned models. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some assumptions made in the paper might render EMCTS inapplicable to real complex problems. It specifically mentions three assumptions: the transition model P being true, the requirement for $Q^\\\\pi$ to be linear in Theorem 1, and the assumption that the learned models are consistent. The reviewer argues that these assumptions are not reasonable in many cases, providing a logical reasoning for the claim. However, the comment could be strengthened by providing specific examples or references to support the claim that these assumptions are problematic. Overall, the claim is mostly verifiable, as it provides a clear rationale but lacks detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific assumptions made in the paper that might limit the applicability of EMCTS to real-world complex problems. It highlights three assumptions: the transition model P being true, the requirement for $Q^\\\\pi$ to be linear in Theorem 1, and the assumption that the learned models are consistent. By pointing out these assumptions, the comment provides the authors with a clear direction for potential improvements, such as reconsidering these assumptions or providing evidence for their validity. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how these assumptions might impact the applicability of EMCTS. Despite this, the feedback is mostly helpful as it directs the authors to areas that need further exploration or justification. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the explicitness (E) and size (S) of the model may be highly related to the given dataset. It implies that the different capacity requirements mentioned in the 3rd paragraph could be due to input modality differences. The comment also suggests that when evaluating disentanglement, the evaluation should provide enough capacity and training time to achieve the DCI evaluation. Additionally, it recommends considering training time, cost, and learning rate when evaluating the capacity of probing. While the comment provides some guidance on what aspects to consider, it lacks specific instructions on how to implement these suggestions, such as which metrics to use or how to adjust the training parameters. The action is mostly actionable because it provides a clear direction for improvement but lacks detailed guidance on execution. Therefore, this comment is rated as mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"3rd paragraph,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the potential relationship between explicitness (E) and size (S) and the dataset, and it suggests considering factors like training time, cost, and learning rate when evaluating disentanglement. The comment provides clear guidance on what aspects need to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a potential relationship between explicitness (E) and size (S) and the given dataset, and it implies that the different capacity requirements mentioned in the 3rd paragraph could be due to input modality differences. The comment also suggests that the evaluation of disentanglement should provide enough capacity and training time to achieve the DCI evaluation. While the comment provides some logical reasoning, it lacks specific examples or references to support the claims fully. The suggestion to consider training time, cost, and learning rate is also not fully elaborated. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a thoughtful analysis of the relationship between explicitness (E) and size (S) in the context of the given dataset. It suggests that the different capacity requirements mentioned in the 3rd paragraph may be due to input modality differences. The comment also offers a constructive suggestion by recommending that the evaluation of disentanglement should provide enough capacity and training time to achieve the DCI evaluation. Additionally, it advises considering factors like training time, cost, and learning rate when evaluating the capacity of probing. This feedback is clear and actionable, providing the authors with specific areas to focus on and improve their draft. However, it could be more helpful if it included examples or further elaboration on how to implement these suggestions. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper title should not include abbreviations. This is a clear and direct action for the authors to take, providing them with a specific instruction on how to improve their draft. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the paper title, allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of abbreviations in the title. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper title should not include abbreviations. However, the comment does not provide any reasoning or justification for this claim, such as explaining why abbreviations are unnecessary or how they might affect the clarity of the title. Without supporting evidence or rationale, the claim remains unverifiable, as the authors are left without a clear understanding of why this change is necessary. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion by advising the authors to avoid including abbreviations in the paper title. This feedback is straightforward and directly addresses a specific aspect of the paper that can be improved. By following this advice, the authors can enhance the clarity and accessibility of their title, making it more appealing to readers. However, the comment could be more helpful if it explained why abbreviations are problematic or suggested alternative ways to present the information. Despite this, the feedback is mostly helpful as it offers a clear direction for improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two aspects: the ability of the discriminator to transfer to other tasks and domains without further training, and its effectiveness with very little data. It also mentions an important insight at line 400 regarding the discriminator\\'s size. However, the comment does not provide explicit or implicit actions for the authors to take. It lacks guidance on how to address these points or what specific changes should be made to the draft. The authors are left without a clear understanding of what steps to take to improve their work based on this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L400,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the insight that the discriminator can be small, which is an important point. However, the comment does not provide specific guidance on how this insight should be developed or integrated into the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of statements and suggestions without any claims or opinions that require verification. It describes observations and insights about the discriminator\\'s capabilities and mentions an important point at line 400. Since it does not contain subjective claims or suggestions, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a positive observation about the discriminator\\'s ability to be small, as mentioned at line 400, which is an important insight. However, it lacks depth and does not offer any actionable suggestions or guidance on how the authors might further develop or utilize this insight in their work. The comment highlights a positive aspect but does not provide constructive feedback for improvement, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the current SOTA GNN-QE should be included in the baselines and compared, as it is the closest work in terms of components to the approach being discussed. This provides a clear and direct action for the authors to take, ensuring that the authors know exactly what needs to be done to improve their draft. The comment is specific and concrete, offering a straightforward path for the authors to enhance their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"current SOTA GNN-QE,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the omission of the SOTA GNN-QE from the baselines and the need to include it for comparison. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the current SOTA GNN-QE is omitted from the baselines, despite being the closest work in terms of components. This claim is somewhat verifiable as it provides a logical reasoning for why the SOTA GNN-QE should be included in the baselines. However, the comment lacks specific examples or references to support the claim that the SOTA GNN-QE is the closest work in terms of components. Providing more detailed justification or references would strengthen the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant omission in the paper, specifically the lack of inclusion of the current SOTA GNN-QE in the baselines. It highlights that this work is the closest in terms of components to the approach being discussed, making it a crucial baseline for comparison. By pointing out this gap, the comment provides clear and actionable feedback that can help the authors improve their draft by including this baseline and conducting a comparison. This feedback is specific, detailed, and constructive, making it highly helpful for the authors. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the pretraining data used for GPT-2 and its ability to understand language. It suggests that if the pretraining data is sufficient, it may not be necessary for the paper to prove its findings, and if not, the setting is not reasonable. The reviewer expresses a willingness to raise their score to strong accept if the authors address these concerns successfully. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific steps they should take to resolve them. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without clear instructions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the pretraining data used for GPT-2 and its ability to understand language. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in detailing the concerns about the pretraining data and its implications for the paper\\'s findings, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the pretraining data used for GPT-2 and its ability to understand language. The reviewer suggests that if the pretraining data is sufficient, it may not be necessary for the paper to prove its findings, and if not, the setting is not reasonable. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The reviewer also mentions that addressing these concerns could lead to a higher score, but without further elaboration, the claim remains vague. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises concerns about the pretraining data used for GPT-2 and its potential impact on the paper\\'s findings. It questions whether the pretraining data is sufficient for GPT-2 to understand language and suggests that if it is, the paper may not need to prove its findings. The reviewer also acknowledges the interest of the topic but emphasizes the importance of addressing these concerns to ensure the correctness of the findings. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address these concerns. The feedback is somewhat helpful as it points out a critical area for improvement but does not provide detailed actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of thorough explanation in the proposed method, specifically mentioning the computation of terms in equation (4) and the optimization algorithm. The reviewer suggests that every term should be clearly explained, except for cases where it is extremely obvious. This feedback provides a clear action for the authors to take, which is to ensure that all mathematical terms and algorithms are thoroughly explained. The comment is explicit in its request for clarification and provides a concrete guideline on how to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the computation of terms in equation (4) and the optimization algorithm, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing in the explanation, namely the computation of terms and the optimization algorithm, particularly the calculation of $p(x_k|d)$. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is labeled as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is not thoroughly explained, specifically mentioning the lack of explanation for the computation of terms in equation (4) and the optimization algorithm. The reviewer provides a logical reasoning by stating that if mathematical expressions are used, every term should be clearly explained, except for obvious cases. This reasoning is sound and provides a clear basis for the claim. However, the comment could be strengthened by providing specific examples or references to similar works that have detailed explanations. Overall, the claim is mostly verifiable, as it provides a logical framework but lacks detailed examples or references to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area where the proposed method lacks thorough explanation, namely the computation of terms in equation (4) and the optimization algorithm. It provides a clear and actionable suggestion by emphasizing the importance of explaining every term, except for those that are extremely obvious. This feedback is valuable as it directs the authors to a particular aspect of their work that requires clarification, allowing them to improve the comprehensibility of their draft. However, the comment could be more helpful if it offered specific guidance on how to explain these terms or suggested alternative ways to present the information. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the authors need to provide implementation details for the RAMP algorithm, the algorithms compared with, the discretization used in the state coverage metric, and other aspects of the experiments. It also emphasizes the importance of these details for reproducibility and assessing the fairness of comparisons with existing methods. The comment provides a clear and concrete action for the authors to take, which is to include a thorough description of the implementation details. This makes the comment highly actionable, as the authors know exactly what steps to take to address the issues raised.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific aspects of the paper that lack implementation details, such as the RAMP algorithm, algorithms compared with, discretization used in the state coverage metric, and other aspects of the experiments. This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific because it clearly specifies what is missing and why it is important for reproducibility and assessing the fairness of comparisons. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the lack of implementation details makes the experimental results non-reproducible and hinders the assessment of the fairness of comparisons with existing methods. The comment logically reasons that without detailed implementation information, it is challenging to evaluate the significance of the experimental results. However, it does not provide specific examples or references to support the claim about the lack of implementation details. While the reasoning is sound, the absence of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to infer the specific issues from the general statement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of implementation details for the RAMP algorithm, the algorithms compared with, and the discretization used in the state coverage metric. It highlights that this lack of detail makes the experimental results non-reproducible and hinders the assessment of the fairness of comparisons with existing methods. The comment provides a clear and actionable suggestion for improvement by recommending a thorough description of the implementation details. This feedback is valuable as it directly addresses a significant weakness in the paper and offers a concrete step for the authors to take to enhance the reproducibility and credibility of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the concept of employing a mixture of experts (MoE) is not unusual, given its extensive application in various tasks. It notes that while the application of MoE in text detection is relatively new, it is not a groundbreaking concept in terms of its fundamental idea. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might improve their work or address the issue of the concept not being groundbreaking. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the concept of employing a mixture of experts (MoE) in various tasks, including text detection, and notes that while it is not a groundbreaking concept, its application in text detection is relatively new. However, the comment does not specify which part of the paper this discussion is based on, nor does it provide specific guidance on how the authors might address the issue of the concept not being groundbreaking. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the concept of employing a mixture of experts (MoE) is not unusual, given its extensive application in various tasks. It provides examples such as general LLM, summarization, and machine translation, which supports the claim. However, the comment could be strengthened by providing more specific references or examples of how MoE has been applied in these tasks, especially in the context of text detection. This would enhance the verifiability of the claim. As it stands, the comment is mostly verifiable, as it provides a logical reasoning and examples, but lacks detailed references. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges that the concept of employing a mixture of experts (MoE) is not unusual, given its extensive application in various tasks. It notes that while the application of MoE in text detection is relatively new, it is not a groundbreaking concept in terms of its fundamental idea. However, the comment does not provide any specific suggestions or feedback on how the authors might improve their work or address the issue of the concept not being groundbreaking. Without actionable advice or detailed guidance, the authors are left without a clear understanding of how to enhance their draft. Therefore, the comment is barely helpful, as it identifies a potential issue but lacks depth and actionable feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of statistical analysis to support the claim of significant performance improvement by SpaceTGN compared to other baselines. While it identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue or what specific statistical analysis should be conducted. The action is implicit and somewhat vague, as the authors are left to infer that they need to include a statistical analysis to support their claim. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about SpaceTGN achieving significant performance improvement compared to other baselines. It also specifies the issue by pointing out the lack of statistical analysis to support this claim. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not provide a statistical analysis to support the claim of significant performance improvement by SpaceTGN compared to other baselines. However, the comment does not provide any specific examples or references to substantiate this claim, nor does it offer a detailed explanation of what kind of statistical analysis would be necessary. This lack of supporting evidence or detailed reasoning makes the claim difficult for the authors to address effectively, rendering it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of statistical analysis to support the claim of significant performance improvement by SpaceTGN compared to other baselines. This is a critical point that could impact the validity of the authors\\' claims. However, the comment does not provide specific guidance on how the authors might conduct this analysis or what statistical methods could be used to support their claim. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, as it points out a significant gap but lacks depth in suggesting how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential source of confusion regarding the excerpting versus reproducing of certain scores. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific changes to clarify the reasoning behind the excerpting or reproduction of scores. As a result, the authors are left without a clear understanding of what steps to take to resolve the confusion. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that there is confusion regarding why certain scores are excerpted versus reproduced, but it does not specify which part of the paper this issue pertains to. The authors may have an idea of where this confusion might arise, but the comment lacks full grounding as it does not explicitly mention sections, tables, or figures. Additionally, the comment is specific in identifying the issue of confusion but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the excerpting versus reproducing of certain scores may cause confusion. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential source of confusion in the paper regarding the excerpting versus reproducing of certain scores. However, it does not provide specific guidance or suggestions on how the authors might clarify this issue or address the confusion. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more explanation on how their consistency model achieves something that previous generative models cannot. This is an implicit action, as it does not explicitly instruct the authors to add a specific section or detail, but it provides a clear direction on what needs to be addressed. The comment is somewhat actionable because it gives the authors a concrete idea of what they need to focus on, but it lacks explicit guidance on how to implement this suggestion. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of the method by suggesting that it is somewhat simplistic in applying consistency models instead of other generative models. It implies that the authors should provide more explanation on how their consistency model achieves something that previous generative models cannot. However, the comment does not specify which part of the paper this critique pertains to, making it weakly grounded. It is specific in its request for additional explanation regarding the novelty of the method. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is \"somewhat simply applying consistency models in place of other generative models for learning target distributions,\" suggesting that there is limited novelty. The reviewer provides a logical reasoning by contrasting the method with previous generative models, implying that the novelty lies in the application of consistency models. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to consider this critique and provide additional context or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by suggesting that the method is somewhat simplistic in its application of consistency models, which may not offer significant novelty compared to other generative models. It provides a clear direction for the authors to address this issue by asking them to comment on how their consistency model achieves something that previous generative models cannot. This feedback is actionable and offers a specific area for the authors to improve their draft, making it mostly helpful. However, the comment could be more helpful if it included additional suggestions or examples to further guide the authors in enhancing their work. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the evaluation metric used in Table 2, specifically noting that MSE (Mean Squared Error) does not reflect the accuracy of nowcasting. However, it does not provide any explicit or implicit suggestions for alternative metrics or improvements. The authors are left without guidance on how to address this issue or what specific changes they should make to their evaluation approach. As a result, the comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation metric, noting that MSE does not reflect the accuracy of nowcasting. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation metric, MSE (Mean Squared Error), in Table 2 does not reflect the accuracy of nowcasting. However, the comment does not provide any supporting evidence, reasoning, or references to justify why MSE is insufficient for evaluating nowcasting accuracy. Without additional context or explanation, the claim remains unverifiable, as the authors would need more information to understand and address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation metric used in Table 2, noting that MSE (Mean Squared Error) does not accurately reflect the accuracy of nowcasting. This feedback is clear and actionable, as it points out a potential limitation in the evaluation approach. However, the comment could be more helpful if it suggested alternative metrics or methods that could better capture the accuracy of nowcasting. Despite this, the comment provides a valuable insight that the authors can use to improve their evaluation methodology, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the empirical evaluation of the benefits of FFA-LoRA on differential privacy (DP). It notes that the performance gap between vanilla LoRA and FFA-LoRA remains the same across various privacy budgets, including epsilon = 0, suggesting that the impact of DP noise is the same on both methods. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their empirical evaluation. The action is implicit and vague, as the authors are left to infer that they need to revisit their empirical evaluation but are not given specific steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"benefit of FFA-LoRA on differential privacy (DP)\" and the \"empirical evaluation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the empirical evaluation, noting that the performance gap between vanilla LoRA and FFA-LoRA remains the same across various privacy budgets, including epsilon = 0. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the benefit of FFA-LoRA on differential privacy (DP) is not well-supported by empirical evaluation. It provides specific details about the performance gap between vanilla LoRA and FFA-LoRA remaining the same across various privacy budgets, including epsilon = 0. This reasoning is logical and provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by including references to specific studies or experiments that demonstrate this lack of benefit, which would further support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the empirical evaluation of the benefits of FFA-LoRA on differential privacy (DP). It points out that the performance gap between vanilla LoRA and FFA-LoRA remains the same across various privacy budgets, including epsilon = 0, suggesting that the impact of DP noise is the same on both methods. This feedback is clear and actionable, as it highlights a potential weakness in the paper\\'s empirical evaluation and suggests that the authors should revisit their analysis to better understand the benefits of FFA-LoRA. However, the comment could be more helpful if it provided specific suggestions on how to improve the empirical evaluation or what additional analyses might be necessary. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to add specific components to the ablation study of ENGINE, namely \"Cap-CapNE-ClipNE-EA\" and \"Cap-CapNE-ClipNE-NE-EA,\" based on the overview model of ENGINE. It also suggests that the authors should provide a more detailed analysis of the ablation results. This feedback is clear and direct, providing the authors with specific actions to take to improve their draft. The instructions are concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study of ENGINE,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be added to the ablation study, namely \"Cap-CapNE-ClipNE-EA\" and \"Cap-CapNE-ClipNE-NE-EA,\" and suggests providing a more detailed analysis of the ablation results. This level of detail provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study of ENGINE is incomplete and suggests adding specific components and providing a more detailed analysis of the ablation results. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these additions are necessary or how they would improve the study. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the ablation study of ENGINE, noting that it is incomplete. It provides clear and actionable feedback by suggesting the addition of specific components, such as \"Cap-CapNE-ClipNE-EA\" and \"Cap-CapNE-ClipNE-NE-EA,\" based on the overview model of ENGINE. Additionally, the comment advises the authors to provide a more detailed analysis of the ablation results. This feedback is detailed and constructive, offering the authors specific guidance on how to enhance their study. By addressing these points, the authors can significantly improve the comprehensiveness and clarity of their ablation study, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of GAN optimization in different datasets, specifically why it produces poor mode coverage in GDIM but good mode coverage in DDGAN. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the paper more convincing. While the comment implies that the authors should include results on these datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include additional results to address the concern. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the performance of GAN optimization in different datasets, specifically why it produces poor mode coverage in GDIM but good mode coverage in DDGAN. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the paper more convincing. The comment is specific in its request for additional results on specific datasets, which provides clear guidance on what the authors need to address. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the performance of GAN optimization in different datasets, specifically why it produces poor mode coverage in GDIM but good mode coverage in DDGAN. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the paper more convincing. The comment references common knowledge that methods performing well on smaller datasets like CIFAR-10/Celeb-64 might struggle with larger datasets like LSUN/ImageNet. However, it lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the reasoning and provide additional evidence to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the performance of GAN optimization in different datasets, specifically why it produces poor mode coverage in GDIM but good mode coverage in DDGAN. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the paper more convincing. The comment also references common knowledge that methods performing well on smaller datasets might struggle with larger ones, offering a logical basis for the suggestion. However, the comment could be more helpful if it provided specific guidance on how to conduct these additional experiments or what aspects to focus on. Despite this, the feedback is somewhat helpful as it identifies a potential area for improvement and offers a direction for enhancing the paper\\'s credibility. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of a specific statement in Section 5.1, asking for clarification on what \"each attribute of the table feature represents a scene\" means. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on how to address the question or what changes might be needed to clarify the statement. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.1\" and the specific phrase \"Each attribute of the table feature represents a scene,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly questions the meaning of the statement, prompting the authors to clarify or provide further explanation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification on a specific statement in the paper, \"Each attribute of the table feature represents a scene.\" It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of a specific statement in Section 5.1, asking for clarification on what \"each attribute of the table feature represents a scene\" means. While it identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the statement. The comment lacks actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the lack of an ablation study comparing the impact of token reweighting versus the logsumexp aggregation scheme. It suggests that the authors should conduct such a study to understand the relative effectiveness of these methods. The comment also questions the compatibility of the token reweighting scheme with existing token-to-token classifiers and asks for clarification on how the logsumexp aggregator compares. While the comment implies that the authors should conduct an ablation study and provide more information on the compatibility and comparison of the methods, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of an ablation study comparing the impact of token reweighting versus the logsumexp aggregation scheme. It suggests that the authors should conduct such a study to understand the relative effectiveness of these methods. The comment also questions the compatibility of the token reweighting scheme with existing token-to-token classifiers and asks for clarification on how the logsumexp aggregator compares. While the comment does not explicitly mention specific sections or figures, it is clear that it pertains to the methodology or results sections where such comparisons would be discussed. The authors can infer that this comment relates to the experimental setup or results sections. The comment is specific in detailing what is missing and what needs to be addressed, making it weakly grounded but specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the lack of an ablation study comparing the impact of token reweighting versus the logsumexp aggregation scheme. It suggests that such a study would help understand the relative effectiveness of these methods. The comment also questions the compatibility of the token reweighting scheme with existing token-to-token classifiers and asks for clarification on how the logsumexp aggregator compares. While the comment provides a logical reasoning for the need of an ablation study, it lacks specific examples or references to support the claim about the compatibility of the token reweighting scheme with existing classifiers. This makes the claim somewhat verifiable, as it provides a clear direction for improvement but requires more detailed evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of an ablation study comparing the impact of token reweighting versus the logsumexp aggregation scheme. It suggests that such a study would help understand the relative effectiveness of these methods and provide insights into their compatibility with existing token-to-token classifiers. The comment also raises a question about the comparison of the logsumexp aggregator with direct addition, which would correspond to basic prototype comparison with reweighted averages on each prototype. This feedback is clear and actionable, as it directs the authors to conduct a specific study to improve the comprehensiveness and clarity of their work. However, it could be more helpful if it provided additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is mostly helpful, as it effectively points out a critical area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the limitation of using only five datasets to evaluate the effectiveness of ECGs and suggests considering large-scale datasets mentioned in [2]. While the comment implies that the authors should expand their dataset evaluation, it does not explicitly instruct them to do so. The suggestion is concrete in terms of the datasets to consider, but the action is implicit and lacks direct guidance on how to implement the suggestion. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the limitation of using only five datasets to evaluate the effectiveness of ECGs, providing a clear reference to the issue. It also suggests considering large-scale datasets mentioned in [2], which gives the authors a specific direction for improvement. The comment is specific because it identifies the problem and offers a concrete solution, making it clear what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that using only five datasets is insufficient for evaluating the effectiveness of ECGs and suggests considering large-scale datasets mentioned in [2]. The comment provides specific references to [1] and [2], which are relevant to the topic of graph neural networks and large-scale learning on non-homophilous graphs. This provides a solid basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how these datasets could improve the evaluation. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically the use of only five datasets to evaluate the effectiveness of ECGs. It suggests that the authors should consider larger-scale datasets mentioned in [2], which could provide more comprehensive evaluation. This feedback is clear and actionable, as it directs the authors to a specific area for improvement and offers a concrete suggestion for enhancing the robustness of their evaluation. However, the comment could be more helpful if it provided additional context or examples of how these larger datasets could be integrated or why they are more suitable for the evaluation. Overall, the comment is mostly helpful, as it provides a valuable direction for the authors to improve their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the paper should acknowledge the limitation of only analyzing fully connected ResNets, which is a common practice in ResNets. It also recommends including this limitation in the Broader Impact section. This feedback provides a clear and direct action for the authors to take, ensuring that they address the limitation and its implications. The comment is explicit and concrete, offering specific guidance on how to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the analysis of fully connected ResNets and the typical use of convolutional layers in ResNets, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the limitation of the paper and suggests that it should be acknowledged and included in the Broader Impact section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper only analyzes fully connected ResNets, which is a limitation since ResNets typically use convolutional layers in practice. The comment suggests that the paper should acknowledge this limitation and include it in the Broader Impact section. While the claim is logical and based on common knowledge about ResNets, it lacks specific examples or references to support the assertion about the typical use of convolutional layers. This makes the claim somewhat verifiable, as it provides a reasonable basis for the critique but could be strengthened with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the paper, noting that it only analyzes fully connected ResNets, whereas ResNets typically use convolutional layers in practice. This is a critical observation that highlights a gap in the study\\'s scope and applicability. The comment provides a clear and actionable suggestion by recommending that the paper should acknowledge this limitation and include it in the Broader Impact section. This feedback is valuable as it prompts the authors to address a crucial aspect of their work, enhancing the paper\\'s comprehensiveness and relevance. However, the comment could be more helpful if it offered additional guidance on how to frame this limitation or its implications. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a comparison of the performance of a student model trained on the training set, specifically mentioning that standard KD methods have surpassed the reported KD performance. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how to improve the performance of the student model or suggestions for addressing the comparison with standard KD methods. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it addresses, such as a particular section or experiment. It also lacks specificity, as it does not detail what needs to be addressed or improved regarding the training of a student model or the comparison with standard KD methods. The authors cannot confidently determine which part of the paper this comment pertains to, and it does not provide clear guidance on how to address the issues raised. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point makes a claim about the performance of a student model trained on the training set, specifically mentioning that standard KD methods have surpassed the reported KD performance. However, the comment lacks specific references or detailed comparisons to support this claim, making it difficult for the authors to understand the basis of the comparison. Without additional context or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a comparison of the performance of a student model trained on the training set, specifically mentioning that standard KD methods have surpassed the reported KD performance. However, it lacks specific suggestions or guidance on how the authors might address this issue or improve their work. The comment highlights a potential weakness in the paper but does not offer actionable advice or detailed feedback to help the authors enhance their draft. As a result, the comment is barely helpful, as it identifies a potential area for improvement but does not provide sufficient guidance for the authors to act upon. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the assumption made by the authors regarding the causal factors and their relationship with node attributes. It questions whether the assumption holds when certain GCN variants, such as Geniepath or Gated GNN, learn both the message and passing routes in a coupled manner, similar to LSTM. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or whether it affects the proposed framework. The action is implicit and vague, as the authors are left to infer that they should consider this issue but are not given specific steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the assumption about node attributes and the causal factors, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the applicability of the proposed framework to certain GCN variants, such as Geniepath and Gated GNN, and questions whether the coupled learning of message and passing routes would break the causal graph assumption. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the assumption made by the authors regarding the causal factors and their relationship with node attributes. It questions whether the assumption holds when certain GCN variants, such as Geniepath or Gated GNN, learn both the message and passing routes in a coupled manner, similar to LSTM. The comment provides a logical reasoning by pointing out the potential impact of coupled learning on the causal graph assumption. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to explore this issue further to fully understand the implications. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical concern about the assumption made by the authors regarding the causal factors and their relationship with node attributes. It questions whether the assumption holds when certain GCN variants, such as Geniepath or Gated GNN, learn both the message and passing routes in a coupled manner, similar to LSTM. This is a relevant and important point that could significantly impact the validity and applicability of the proposed framework. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or whether it affects the overall framework. While it highlights a potential weakness, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider listing the performance of state-of-the-art (SOTA) algorithms in each dataset discussed in Table 1. This would help readers understand the gap between NAS models and human-engineered SOTA architectures. The comment provides a clear and explicit action for the authors to take, which is to include this additional information. The suggestion is concrete, as it specifies what needs to be done to enhance the clarity and comprehensiveness of the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"pre-processing, message-passing, post-processing\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the limitation of focusing solely on message-passing layers and suggests listing the performance of SOTA algorithms in each dataset to better understand the gap between NAS models and human-engineered architectures. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' focus on message-passing layers as the most important part of GNNs is not convincing, given that different tasks use different pre- and post-processing modules. The reviewer suggests listing the performance of SOTA algorithms in each dataset to help readers understand the gap between NAS models and human-engineered architectures. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the importance of pre- and post-processing modules. This makes the claim somewhat verifiable, as it requires more detailed evidence to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s focus on message-passing layers as the most important part of GNNs, suggesting that this claim may not be convincing given the diversity of pre- and post-processing modules across different tasks. It provides a constructive suggestion to list the performance of state-of-the-art (SOTA) algorithms in each dataset discussed in Table 1, which would help readers understand the gap between NAS models and human-engineered SOTA architectures. This feedback is clear and actionable, offering a specific way for the authors to enhance the comprehensiveness and clarity of their paper. However, it could be more helpful if it included additional guidance on how to present this information or why it is crucial for the paper\\'s contribution. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should demonstrate whether learning the advantage directly is beneficial. It implies that the authors should provide evidence to support the importance of learning the advantage directly with their method compared to other methods. However, the comment does not specify how to conduct this demonstration or what specific evidence is needed. The action is implicit and somewhat vague, as the authors can infer that they need to provide evidence but are not given concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should demonstrate the usefulness of learning the advantage directly. It implies that the current paper does not provide sufficient evidence for why learning the advantage is important compared to other methods. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The authors can infer that it relates to the sections discussing the advantage and its learning, but without explicit references, it is challenging to pinpoint the exact parts. The comment is specific in suggesting the need for evidence on the importance of learning the advantage directly, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks evidence for why learning the advantage directly is important compared to other methods. However, it does not provide specific examples or references to support this claim, making it somewhat verifiable. The reviewer offers a logical reasoning by questioning the importance of learning the advantage directly, but without detailed evidence or examples, the authors may find it challenging to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should demonstrate the usefulness of learning the advantage directly, as the current paper does not provide sufficient evidence for why this is important compared to other methods. This feedback is somewhat helpful as it identifies a potential gap in the paper and encourages the authors to provide evidence or reasoning to support their claims. However, the comment lacks specific guidance on how to address this issue or what kind of evidence would be most relevant, which limits its usefulness. To be more helpful, the comment could include suggestions on what specific aspects of the advantage should be explored or how to present the evidence. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests adding explanations about the meaning of variable symbols such as \u03c2, r_i, \u03b1_i, and others in the appended algorithms. This is an explicit action that the authors can take to improve their draft. The comment clearly indicates what needs to be added, providing a concrete step for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding explanations about the meaning of variable symbols such as \u03c2, r_i, \u03b1_i, and others in the appended algorithms. While it does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the algorithms section, providing some level of grounding. The comment is specific in its request for additional explanations about the variable symbols, which would help clarify the paper for readers. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding explanations about the meaning of variable symbols in the appended algorithms. However, it does not provide any specific examples or context regarding which symbols are unclear or why their meanings are not well-explained. Without detailed justification or examples, the authors may find it challenging to understand which symbols require clarification or how to address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding explanations about the meaning of variable symbols in the appended algorithms. This is a clear and actionable piece of feedback that can help the authors improve the clarity and accessibility of their work. By providing additional explanations, the authors can ensure that readers understand the context and significance of these variables, which is crucial for the paper\\'s comprehensibility. However, the comment could be more helpful if it specified which symbols are unclear or provided examples of how the explanations could be improved. Overall, the feedback is mostly helpful as it directs the authors to enhance the clarity of their work, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method lacks innovation and may only represent incremental changes to established methods, implying that the performance gains are limited. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the innovation or what specific changes could be made to advance the field meaningfully. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the method lacks innovation and may only represent incremental changes to established methods, implying that the performance gains are limited. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what specific aspects of the method are lacking in innovation. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the method are considered incremental or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the limited performance gains suggest the method lacks innovation and may only represent incremental changes to established methods. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the method lacks innovation and may only represent incremental changes to established methods, implying that the performance gains are limited. However, it does not provide specific examples or detailed feedback on what aspects of the method are lacking in innovation or how the authors could improve it. Without actionable suggestions or guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This would provide a clearer picture of the relative strengths and weaknesses of the proposed system. While the comment implies that the authors should conduct a more comprehensive comparison, it does not specify which existing methods or systems should be included or how the comparison should be structured. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take and the level of detail required. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. However, it does not specify which part of the paper this suggestion pertains to, such as the results section or the discussion. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing improvement. Additionally, while the comment provides a clear idea of what is missing, it does not specify which existing methods or systems should be included in the comparison. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. However, the comment does not provide specific examples of existing methods or systems that should be included in the comparison, nor does it offer detailed reasoning or references to support the claim. This lack of specificity and supporting evidence makes the claim somewhat verifiable, as the authors would need to infer the relevance and importance of such a comparison. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by comparing their proposed system with others in the field. By doing so, the authors can gain a clearer understanding of the relative strengths and weaknesses of their system, which is crucial for evaluating its effectiveness and relevance. However, the comment could be more helpful if it included specific examples of methods or systems to consider for comparison. Overall, the feedback is mostly helpful as it offers a constructive suggestion for improving the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the practical usefulness of \\\\(\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}\\\\) due to its limited performance on the real dataset compared to existing methods. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting improvements to the model or experimental setup. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the performance of \\\\(\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}\\\\) on the real dataset (long-range graph benchmark). However, it does not specify which part of the paper discusses this performance, making it weakly grounded. The comment is specific in detailing the issue with the performance of \\\\(\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}\\\\) compared to existing methods, but it lacks grounding as it does not direct the authors to a particular section or figure. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the prediction performance of \\\\(\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}\\\\) does not outperform existing methods on the real dataset, which limits its practical usefulness. However, the comment does not provide specific examples of existing methods or detailed comparisons to support this claim. Without such evidence or references, the authors may find it challenging to understand the basis of the critique or to address it effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment highlights a concern about the practical usefulness of \\\\(\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}\\\\) due to its limited performance on the real dataset compared to existing methods. This feedback is somewhat helpful as it identifies a potential weakness in the paper, specifically the lack of outperformance by \\\\(\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}\\\\) on the long-range graph benchmark. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the performance of their method. While it points out a critical area for improvement, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the comparison between the proposed algorithm and offline RL algorithms for single agents, arguing that the latter\\'s target is not to find an equilibrium. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what changes they should make to their draft. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the comparison between the proposed algorithm and offline RL algorithms for single agents, arguing that the target of the latter is not to find an equilibrium. However, it does not specify which part of the paper this comparison is made in, nor does it provide details on what specific issues or aspects of the comparison are problematic. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or how the comparison should be revised. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that it is unfair to compare the proposed algorithm with offline RL algorithms for single agents because the target of those algorithms is not to find an equilibrium. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison between the proposed algorithm and offline RL algorithms for single agents. It points out that the target of offline RL algorithms is not to find an equilibrium, which could make the comparison unfair. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. Without actionable feedback or specific recommendations, the authors are left without a clear path to enhance their work. Therefore, the comment is barely helpful, as it highlights a potential problem but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper could clarify its unique contributions in methodology and purpose by providing more detailed comparisons to similar works. While the comment implies that the authors should make these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given specific guidance on how to conduct these comparisons or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of overlap with prior work, specifically mentioning three tasks that have been partially covered in prior benchmarks. It suggests that the paper should clarify its unique contributions in methodology and purpose by providing more detailed comparisons to similar works. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in its suggestion to provide detailed comparisons, but without clear grounding, the authors may find it challenging to identify the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the three tasks\u2014unanswerable, inconsistent, and counterfactual\u2014have been partially covered in prior benchmarks. It suggests that the paper should clarify its unique contributions by providing more detailed comparisons to similar works. However, the comment lacks specific examples or references to these prior works, making it difficult for the authors to understand the basis of the claim or how to address it. This lack of detailed support or references renders the claim somewhat verifiable, as the authors would need to invest additional effort to identify the relevant prior work and make the necessary comparisons. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s originality, noting that the three tasks\u2014unanswerable, inconsistent, and counterfactual\u2014have been partially covered in prior benchmarks. It suggests that the paper could clarify its unique contributions by providing more detailed comparisons to similar works. This feedback is somewhat helpful as it points out an area where the paper could be improved by providing clearer distinctions from existing work. However, the comment could be more helpful if it offered specific examples of how the paper could differentiate itself or provided guidance on what aspects to focus on for comparison. Overall, the comment provides a direction for improvement but lacks depth, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that Section 1 lacks support materials for the claim that \"human perception is usually invariant to the texture resampling.\" This provides a clear and direct action for the authors to take, which is to provide additional support or evidence for this claim. However, the comment does not specify what kind of support materials are needed or how the authors should present them. While the action is explicit, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the claim \"human perception is usually invariant to the texture resampling\" lacks support materials. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a statement in Section 1 lacks support materials. However, it does not provide any specific reasoning, examples, or references to substantiate this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in Section 1, where it points out that the claim \"human perception is usually invariant to the texture resampling\" lacks support materials. This feedback is clear and actionable, as it directs the authors to provide evidence or additional information to substantiate the claim. However, the comment could be more helpful if it suggested specific types of evidence or examples that could be used to support the claim. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should demonstrate the applicability of MiPKD to other computer vision (CV) tasks beyond super-resolution (SR) tasks. It encourages additional experiments on a broader range of tasks to enhance the method\\'s perceived generalizability. While the comment implies that the authors should conduct these experiments, it does not provide specific guidance on which tasks to consider or how to design the experiments. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the generality of the paper, specifically discussing the applicability of MiPKD to super-resolution (SR) tasks and suggesting that it should be tested on a broader range of computer vision (CV) tasks. However, it does not explicitly mention which part of the paper this discussion is based on, making it weakly grounded. The comment is specific in suggesting additional experiments to enhance the method\\'s perceived generalizability, providing a clear direction for improvement. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that MiPKD is not specifically designed for super-resolution (SR) tasks, implying that its applicability to other computer vision (CV) tasks should be demonstrated. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or evidence, the claim is somewhat verifiable, as it provides a general direction for improvement but lacks concrete justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper by noting that MiPKD is primarily discussed in the context of super-resolution (SR) tasks, but its applicability to other computer vision (CV) tasks is not fully explored. The reviewer suggests that conducting additional experiments on a broader range of tasks could enhance the method\\'s perceived generalizability. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their work and improve its applicability. However, the comment could be more helpful if it offered specific suggestions on which tasks to consider or how to design the experiments. Overall, the comment is mostly helpful, as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that Equations 21 and 22, which describe an alternative scheme not used in the paper, could be omitted without affecting the flow of the section. This is an explicit action, as it directly instructs the authors to consider removing these equations. However, the comment does not provide specific guidance on how to determine whether their removal would indeed not impact the flow of the section or offer suggestions on alternative ways to present the information. The action is explicit but somewhat vague in terms of execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equations 21 and 22,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the potential omission of these equations without affecting the flow of the section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Equations 21 and 22 describe an alternative scheme that is not used in the paper and could be omitted without affecting the flow of the section. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion to omit the equations. However, the comment lacks specific examples or detailed justification to fully substantiate the claim, making it somewhat verifiable. The authors would need to consider the context and content of the equations to fully understand the suggestion. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that Equations 21 and 22 describe an alternative scheme that is not used in the paper. It suggests that these equations may be omitted without affecting the flow of the section, providing a clear and actionable piece of feedback. This feedback is valuable as it helps the authors streamline their content and focus on the most relevant information. However, the comment could be more helpful if it offered additional context or suggestions on how to integrate the information from these equations into the rest of the paper. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement with a clear suggestion.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a view that the optimization module applies a simple iteration strategy and that the overall model builds upon traditional approaches, suggesting it is somewhat incremental. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the optimization strategy, address the incremental nature, or provide more context about the traditional approaches being referenced. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the optimization module and its application of a simple iteration strategy to optimize two loss functions. It also mentions that the overall model builds upon traditional approaches, suggesting it is somewhat incremental. However, the comment does not specify which part of the paper discusses the optimization module or provide details on how the model is incremental. The authors can infer that it relates to the methodology or results sections, but the lack of explicit references makes it weakly grounded. The comment is specific in its critique of the optimization strategy and the model\\'s reliance on traditional approaches, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the optimization module applies a simple iteration strategy and that the overall model builds upon traditional approaches, suggesting it is somewhat incremental. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a general observation about the optimization module, noting that it applies a simple iteration strategy and suggesting that the overall model builds upon traditional approaches, which might make it seem somewhat incremental. However, the comment lacks specificity and does not offer any actionable feedback or suggestions for improvement. It does not provide details on how the authors might enhance the optimization strategy or address the incremental nature of their model. Without concrete guidance or constructive criticism, the comment does not effectively assist the authors in improving their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing of the paper can be improved, specifically questioning the choice of F(X) for the E(d) case. It asks for clarification on the 2^d O(d) matrices and requests that the authors elaborate on how to construct F(X) in the main paper, with the option to provide examples in the appendix. This feedback is explicit and provides a clear action for the authors to take, which is to elaborate on the construction of F(X) and provide examples. The suggestion is concrete, as it specifies what needs to be done and where, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the writing of the paper can be improved, specifically questioning the choice of F(X) for the E(d) case. It asks for clarification on the 2^d O(d) matrices and requests that the authors elaborate on how to construct F(X) in the main paper, with the option to provide examples in the appendix. This provides clear guidance on what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper this issue pertains to, leaving the authors to infer that it relates to the sections discussing F(X) and E(d). Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the writing of the paper can be improved, specifically questioning the choice of F(X) for the E(d) case. It requests clarification on the 2^d O(d) matrices and suggests elaborating on how to construct F(X) in the main paper, with the option to provide examples in the appendix. However, the comment lacks specific reasoning or evidence to support why the choice of F(X) is problematic or how it affects the paper. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper\\'s writing can be improved, namely the choice of F(X) for the E(d) case. It questions the 2^d O(d) matrices and suggests that the authors provide more detailed examples of how to construct F(X) in the main paper, with the option to include additional examples in the appendix. This feedback is clear and actionable, as it directs the authors to clarify a particular aspect of their work that may be confusing to readers. By providing a specific suggestion for improvement, the comment is mostly helpful, as it guides the authors in enhancing the clarity and comprehensibility of their paper. However, it could be more helpful if it included additional context or examples to further support the suggestion. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implicit assumptions the paper makes for few-shot learning to be successful, specifically mentioning meta-distribution and distribution-closeness assumptions. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific assumptions should be considered. The action is implicit and vague, as the authors are left to infer that they need to clarify or discuss these assumptions but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the implicit assumptions the paper makes for few-shot learning to be successful, specifically mentioning meta-distribution and distribution-closeness assumptions. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about the assumptions but lacks grounding, as it does not provide a clear reference to the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the implicit assumptions the paper makes for few-shot learning to be successful, specifically mentioning meta-distribution and distribution-closeness assumptions. However, it does not provide any supporting evidence, reasoning, or references to justify why these assumptions are relevant or how they relate to the paper\\'s claims. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the question. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the implicit assumptions the paper makes for few-shot learning to be successful. It mentions specific assumptions like meta-distribution and distribution-closeness, which are relevant to the topic. However, the comment lacks depth and does not provide guidance on how the authors might address this issue or what specific aspects of the paper need clarification. While it identifies a potential area for improvement, the feedback is incomplete and does not offer actionable suggestions, making it somewhat helpful. The authors are left to infer that they need to clarify these assumptions, but without explicit guidance, the comment does not fully support their improvement efforts. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should make their comparison to prior work more thorough by considering other tasks and large-scale models. It also recommends providing results for more standard benchmarks in the literature to facilitate easier comparison. While the comment implies that the authors should expand their comparison, it does not provide specific guidance on which tasks or benchmarks to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the comparison to prior work should be more thorough, specifically by considering other tasks and large-scale models. It also recommends providing results for more standard benchmarks in the literature to facilitate easier comparison. However, the comment does not specify which parts of the paper need to be revised or where the current comparison is lacking. The authors can infer that it relates to the discussion or results sections, but the lack of explicit references makes it weakly grounded. The comment is specific in suggesting improvements to the comparison, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the comparison to prior work could be more thorough by considering other tasks and large-scale models, and by providing results for more standard benchmarks in the literature. This claim is somewhat verifiable as it provides a logical suggestion for improving the comparison, but it lacks specific examples or references to support the claim. The authors would need to infer which tasks or benchmarks are missing and how they could be included. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that the comparison to prior work could be more thorough by considering other tasks and large-scale models. It also recommends providing results for more standard benchmarks in the literature to facilitate easier comparison. This feedback is clear and actionable, as it identifies specific areas for improvement in the paper's methodology and results sections. By following this advice, the authors can enhance the comprehensiveness and relevance of their work, making it more comparable to existing literature. However, the comment could be more helpful if it provided examples of specific tasks or benchmarks that should be considered. Overall, the comment is mostly helpful as it offers constructive guidance for improving the draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, it does not provide any explicit or implicit actions for the authors to take to improve their contribution. There is no guidance on how to enhance the manuscript or what specific aspects need to be addressed. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a general critique of the manuscript, suggesting that it is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, it does not specify which part of the paper this critique is based on, nor does it provide detailed feedback on what aspects of the manuscript need improvement. The authors cannot confidently determine which sections or elements of the paper are being addressed, making the comment not grounded. Additionally, the comment lacks specificity regarding what specific aspects of the contribution need improvement. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. The lack of detailed reasoning or specific comparisons makes it difficult for the authors to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a general critique of the manuscript, suggesting that it is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, it does not offer any specific suggestions or guidance on how the authors might improve their contribution or address the perceived limitations. Without actionable feedback or detailed insights, the comment does not provide the authors with a clear path for enhancing their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the clarity and specificity of the three claimed benefits of understanding the agent\\'s performance post-training. It identifies Benefit 1 as too abstract and lacking contextual detail, and Benefit 3 as including broad statements unsupported by references. However, the comment does not provide explicit guidance or suggestions on how the authors might improve these benefits or address the issues raised. The feedback implies that the authors should clarify and substantiate their claims, but it lacks concrete actions or examples to follow. As a result, the comment is vague and does not offer actionable steps for the authors to take, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses specific aspects of the paper, namely the three claimed benefits of understanding the agent\\'s performance post-training. It critiques Benefit 1 as too abstract and lacking contextual detail, and Benefit 3 for including broad statements unsupported by references. This provides clear guidance on what needs to be addressed in the paper, specifically the need for more detailed and substantiated claims. However, the comment does not explicitly mention which section or part of the paper these benefits are discussed in, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the clarity and specificity of the three claimed benefits of understanding the agent\\'s performance post-training. It specifically points out that Benefit 1 is too abstract and lacks contextual detail, and Benefit 3 includes broad statements unsupported by references. The comment provides a logical reasoning by highlighting the lack of specificity and the absence of supporting references, which makes the claims difficult to grasp. However, it does not provide specific examples or references to further substantiate the critique. Therefore, the claim is somewhat verifiable, as it provides a clear critique but lacks detailed evidence or examples to fully support the argument.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies specific issues with the clarity and specificity of the three claimed benefits of understanding the agent's performance post-training. It points out that Benefit 1 is too abstract and lacks contextual detail, and Benefit 3 includes broad statements unsupported by references. This feedback is valuable as it highlights areas where the authors need to provide more detailed and substantiated claims to enhance the clarity and credibility of their work. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided examples of how to better support the claims. Overall, the comment is somewhat helpful as it directs the authors' attention to areas needing improvement but lacks detailed guidance for implementation.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the lack of quantitative results for the Human Shape Bases Synchronization problem, suggesting that qualitative results alone are insufficient for evaluating effectiveness. However, it does not provide explicit guidance on how the authors should address this issue or what specific quantitative results are needed. The comment implies that the authors should include quantitative results, but it lacks concrete details on how to implement this suggestion. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the lack of quantitative results for the Human Shape Bases Synchronization problem, noting that qualitative results alone are insufficient for evaluating effectiveness. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in its request for quantitative results, but without clear grounding, the authors may struggle to identify the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the lack of quantitative results for the Human Shape Bases Synchronization problem, suggesting that qualitative results alone are insufficient for evaluating effectiveness. The reviewer acknowledges the qualitative results as \"impressive\" but emphasizes the need for quantitative results to fully assess the approach\\'s effectiveness. This claim is somewhat verifiable as it provides a logical reasoning for the need for quantitative results, but it lacks specific examples or references to support the assertion that qualitative results are insufficient. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the lack of quantitative results for the Human Shape Bases Synchronization problem, noting that qualitative results alone are insufficient for evaluating effectiveness. This feedback is clear and actionable, as it directs the authors to include quantitative results to strengthen their evaluation. However, the comment could be more helpful by suggesting specific metrics or methods for quantifying the results. Additionally, the reviewer provides a positive assessment of the paper\\'s novel approach and experimental evidence, which is helpful for the authors. Overall, the comment is mostly helpful as it identifies a key area for improvement and provides a positive evaluation of the paper\\'s contributions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the categorization of the paper under Fairness/Accountability/Transparency, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on what the authors should do to address this question or how they might clarify the categorization. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the categorization of the paper under Fairness/Accountability/Transparency, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to the introduction or abstract, but without explicit mention, it is weakly grounded. The comment is specific in questioning the categorization, but it lacks detailed guidance on what aspects of the paper might be relevant to this question. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification on the categorization of the paper under Fairness/Accountability/Transparency. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, the correct label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the categorization of the paper under Fairness/Accountability/Transparency, suggesting that the authors may be missing something. However, it does not provide any specific guidance or suggestions on how the authors might address this question or clarify the categorization. Without actionable feedback or detailed insights, the comment lacks utility for the authors in improving their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a machine learning 2-step baseline to compare with the heuristic methods presented in the paper. This is an explicit action, as it clearly instructs the authors on what additional comparison should be made to strengthen their claims. The comment also provides a rationale for why this comparison is necessary, highlighting the potential for the improvement to be attributed to the different class of algorithm rather than the authors' specific approach. This feedback is concrete and provides a clear direction for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the comparison to baselines should include a machine learning 2-step baseline to better evaluate the improvement of NaviFormer. However, it does not specify which part of the paper this suggestion should be addressed in, such as the methodology or results sections. This makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in its suggestion to include a particular type of baseline, but it lacks grounding, as it does not direct the authors to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the comparison to baselines is limited because all approaches are heuristic methods, and the improvement could be due to the different class of algorithm rather than the authors\\' assertion that NaviFormer beats baselines due to its joint tackling of routing and path planning. The comment implies that including a machine learning 2-step baseline would provide a more comprehensive evaluation. However, it does not provide specific examples or references to support the claim that the current baselines are insufficient or that a machine learning 2-step baseline would be beneficial. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the necessity of the suggested comparison based on the reasoning provided.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper\\'s comparison to baselines, suggesting that all approaches are heuristic methods and that the improvement could be due to the different class of algorithm rather than the authors\\' assertion that NaviFormer beats baselines due to its joint tackling of routing and path planning. This feedback is somewhat helpful as it points out a gap in the evaluation and suggests a way to strengthen the comparison by including a machine learning 2-step baseline. However, the comment could be more helpful if it provided specific guidance on how to implement this suggestion or offered additional insights into why this comparison is important. Overall, the feedback is clear but incomplete, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the results appear better than other compared methods but questions whether this is due to the better image generative model. It recommends a fair comparison by applying the planning and layering method to the design image generated by other image generative models. This feedback is explicit and provides a clear action for the authors to take, which is to conduct a more comprehensive comparison. The suggestion is concrete, as it specifies the type of comparison that should be made. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the results section, questioning whether the better performance is due to the better image generative model. It suggests a fair comparison by applying the planning and layering method to the design image generated by other image generative models. While the comment implies that it is discussing the results section, it does not explicitly mention it, making the grounding weak. However, it is specific in suggesting a way to improve the comparison. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions whether the better results are due to the better image generative model, suggesting a need for a fair comparison. The reviewer recommends applying the planning and layering method to the design image generated by other image generative models. This suggestion is based on logical reasoning, as it implies that the current results might be biased by the choice of image generative model. However, the comment lacks specific examples or references to support the claim that other image generative models should be used for comparison. Therefore, the claim is somewhat verifiable, as it provides a logical basis but requires further elaboration or evidence to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of results, questioning whether the better performance is due to the better image generative model rather than the method itself. It provides a clear and actionable suggestion to address this concern by recommending a fair comparison, such as applying the planning and layering method to the design image generated by other image generative models. This feedback is specific and offers a concrete way for the authors to improve their draft by ensuring a more comprehensive and unbiased comparison. Therefore, the comment is rated as highly helpful, as it effectively guides the authors in enhancing the validity and robustness of their results.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the comparative study should include more advanced baselines, specifically mentioning several SOTA methods. It implies that the authors should expand their comparison to include these methods to strengthen their claims. However, the comment does not explicitly instruct the authors to include these specific methods or provide detailed guidance on how to incorporate them. While the action is clear, the lack of explicit instructions and detailed guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparative study and the lack of inclusion of SOTA methods, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of more advanced baselines in the comparative study. Additionally, it provides specific examples of SOTA methods that should be considered, such as Ma et al. (2021b), Tran et al. (2017), Chen & Zhang (2020), Liu et al. (2021), and Suo et al. (2019). This level of detail provides clear guidance for the authors on how to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparative study should include more advanced baselines, specifically mentioning several SOTA methods. The reviewer provides specific references to these methods, which supports the claim. However, the comment also questions the justification of the authors\\' claim about exploiting modality-missing data, suggesting that this claim may not be valid without a comprehensive comparison. While the suggestion to include SOTA methods is well-supported, the critique of the authors\\' claim is somewhat vague and lacks detailed reasoning or evidence. Therefore, the comment is mostly verifiable, as it provides some justification but could be strengthened with more detailed analysis or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the comparative study in the paper. It points out that the current comparison with simpler baselines like zero padding is insufficient and recommends including more advanced baselines, such as SOTA methods like Ma et al. (2021b), Tran et al. (2017), Chen & Zhang (2020), Liu et al. (2021), and Suo et al. (2019). This feedback is valuable as it highlights a gap in the current study and offers specific examples of methods that could be included to strengthen the claims made by the authors. However, the comment could be more helpful if it provided additional guidance on how to incorporate these methods or why they are relevant to the study. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific section of the paper (lines 329-334) where the discussion of the dataset is considered confusing. It suggests that the authors should clarify the relevance of terms like \"opinion holder\" and \"opinion targets\" to the experiments conducted in the paper. The comment provides a clear action for the authors to take, which is to ensure that only relevant information is included in the discussion. This feedback is explicit and concrete, as it specifies the exact lines to focus on and the action to take. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 329-334,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the confusion regarding the discussion of the dataset, specifically mentioning the terms \"opinion holder\" and \"opinion targets.\" The comment clearly specifies what needs to be addressed, which is the relevance of these terms to the experiments. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion of the dataset is confusing, specifically mentioning the terms \"opinion holder\" and \"opinion targets.\" The reviewer suggests that if these terms are not relevant to the experiments, they should not be mentioned. However, the comment does not provide specific examples or detailed reasoning to support why the inclusion of these terms is confusing or unnecessary. This lack of detailed justification makes the claim somewhat verifiable, as the authors may need to infer the exact issues and address them accordingly. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the discussion of the dataset in the paper, noting that the terms \"opinion holder\" and \"opinion targets\" are mentioned but not clearly explained. It suggests that if these terms are not relevant to the experiments, they should not be included in the discussion. This feedback is clear and actionable, as it directs the authors to clarify the relevance of these terms or remove them if they are not pertinent. By addressing this point, the authors can improve the clarity and coherence of their discussion, making the comment mostly helpful. However, it could be more helpful if it provided additional guidance on how to clarify the discussion or suggested alternative ways to present the information. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the restriction imposed by the capsule networks and questions the necessity of this restriction. It also points out that the authors do not provide the number of parameters in the group CapNet, which makes it difficult to assess the benefits of enforcing equivariance. While the comment highlights an issue and suggests that the authors should provide more information, it does not explicitly instruct the authors to include the number of parameters or to address the restriction. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the previous comment,\" which allows the authors to identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of restricting capsule networks and points out the lack of information about the number of parameters in the group CapNet. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the restriction imposed by the capsule networks and questions the necessity of this restriction. It points out that the group CapNet is deeper than the simple CapNet and that the authors do not provide the number of parameters in the group CapNet, which makes it difficult to assess the benefits of enforcing equivariance. The comment also notes that the original CapNet captures some variations in the data. While the comment provides some reasoning, it lacks specific examples or references to support the claim that the restriction is unnecessary or that the lack of parameter information hinders evaluation. The reasoning is somewhat verifiable, as it highlights a potential issue but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment continues the discussion from the previous point, questioning the necessity of restricting the capsule networks. It highlights a potential issue with the experimental setup, noting that the group CapNet is deeper than the simple CapNet and that the authors do not provide the number of parameters in the group CapNet. This lack of information makes it difficult to assess the benefits of enforcing equivariance. The comment also points out that the original CapNet captures some variations in the data, which further complicates the evaluation. While the comment identifies a specific issue and provides some context, it lacks detailed guidance or suggestions on how the authors might address this concern or improve their experimental setup. The feedback is somewhat helpful as it prompts the authors to consider these aspects, but it could be more actionable with additional guidance. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point discusses the challenge of obtaining meaningful gradients with respect to noisy (intermediate) images, referencing a discussion on page 4. It mentions that this issue has been addressed in various approaches, such as DiME, and notes the existence of more efficient implementations like FastDiME and the Tweedie approach by He et al. However, the comment does not provide explicit guidance or suggestions for the authors to address this issue in their own work. It lacks actionable advice on how the authors might incorporate these approaches or improve their own method. As a result, the comment is unactionable, as it does not offer any concrete steps for the authors to take.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of obtaining meaningful gradients with respect to noisy (intermediate) images and references specific approaches like DiME, FastDiME, and the Tweedie approach by He et al. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point discusses the challenge of obtaining meaningful gradients with respect to noisy (intermediate) images, referencing a discussion on page 4. It mentions that this issue has been addressed in various approaches, such as DiME, and notes the existence of more efficient implementations like FastDiME and the Tweedie approach by He et al. The comment provides specific references to external works, which supports the claim and makes it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or examples of how these approaches address the challenge, which would further enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment addresses a specific challenge in the paper, namely the difficulty of obtaining meaningful gradients with respect to noisy (intermediate) images. It references a discussion on page 4 and provides context by mentioning that this issue has been addressed in various approaches, such as DiME, and more efficient implementations like FastDiME and the Tweedie approach by He et al. This feedback is somewhat helpful as it informs the authors about existing solutions to the challenge they are facing, potentially guiding them to explore these alternatives. However, the comment could be more helpful if it offered specific suggestions or comparisons to these approaches, or if it provided more detailed guidance on how to integrate these solutions into their work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors include an evaluation of inference speed on the hardware. While the comment explicitly states the action to be taken, it does not provide specific guidance on how to conduct this evaluation or what aspects of inference speed should be considered. The authors are left with a general idea of what needs to be done but without detailed instructions on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including an evaluation of inference speed on the hardware, but it does not specify which part of the paper this evaluation should be added to. The authors may infer that it relates to the experimental or results sections, but without explicit guidance, it is difficult to pinpoint the exact location. The comment is specific in its suggestion to include an evaluation of inference speed, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors include an evaluation of inference speed on the hardware. However, it does not provide any reasoning, examples, or references to support why this evaluation is necessary or beneficial. The comment lacks specific details or evidence to justify the claim, making it difficult for the authors to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors include an evaluation of inference speed on the hardware, which is a relevant aspect of the paper\\'s methodology or results. This feedback is clear and actionable, as it provides a specific area for improvement that could enhance the comprehensiveness and practicality of the study. However, the comment could be more helpful if it offered guidance on how to conduct this evaluation or what specific metrics to consider. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for expansion, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly questions the absence of the SDP formulation for the modified problem, which is stated to be convex. This comment clearly indicates that the authors should include the SDP formulation in their draft. However, it does not provide specific guidance on how to present this formulation or what aspects of it should be included. While the action is explicit, the lack of detailed instructions on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"This modified problem,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the absence of the SDP formulation, clearly specifying what is missing in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the absence of the SDP formulation for the modified problem, which is stated to be convex. However, the comment does not provide any reasoning or evidence to support why the SDP formulation is necessary or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable, as the authors are left without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a specific gap in the paper by questioning the absence of the SDP formulation for the modified problem, which is stated to be convex. This feedback is clear and actionable, as it directs the authors to include the SDP formulation in their draft. However, the comment could be more helpful if it provided guidance on how to present the SDP formulation or what aspects of it should be included. Despite this, the comment effectively identifies a critical omission and prompts the authors to address it, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies two issues: the lack of information on the number of new task combinations used to evaluate compositional generalizability and the limited scope of the test results in Table 7, which are only from 30 composite instructions. The reviewer provides clear guidance by specifying the exact line number (558) where the information is missing and the specific issue with the test results in Table 7. This feedback is explicit and concrete, giving the authors direct actions to take to address these issues. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 558\" and \"Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing: the number of new task combinations used to evaluate compositional generalizability and the limited scope of the test results in Table 7. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of information regarding the number of new task combinations used to evaluate compositional generalizability and the limited scope of the test results in Table 7, which are only from 30 composite instructions. This is a factual observation that does not express an opinion or claim requiring verification. It is a request for clarification or additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the lack of information on the number of new task combinations used to evaluate compositional generalizability and the limited scope of the test results in Table 7, which are only from 30 composite instructions. By pointing out these gaps, the comment provides clear and actionable feedback that can help the authors improve their draft by addressing these areas. However, the comment could be more helpful if it suggested ways to address these issues or provided additional context for why this information is important. Overall, the feedback is mostly helpful as it directs the authors to specific areas needing clarification or expansion.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the paper, particularly the figures, are not well-formatted in terms of layout. However, it does not provide any specific guidance or suggestions on how to improve the layout or what aspects of the layout are problematic. The comment lacks explicit or implicit actions, leaving the authors without a clear understanding of what changes are needed. As a result, the authors are unable to take any meaningful steps to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the paper, especially the figures, is not well-formatted in terms of layout. However, it does not specify which figures are affected or provide any details about the layout issues. This makes it difficult for the authors to identify the exact parts of the paper that need improvement. The comment lacks grounding as it does not mention specific sections or figures, and it is also not specific about the nature of the layout issues. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper, particularly the figures, is not well-formatted in terms of layout. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a specific issue with the layout of the paper, particularly the figures, indicating that it is not well-formatted. However, it lacks detailed guidance or suggestions on how to improve the layout or what specific aspects need attention. Without actionable advice or examples, the authors are left without a clear understanding of how to address the issue. This makes the comment barely helpful, as it identifies a problem but does not provide sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern that the paper\\'s contributions may be perceived as incremental or lacking novelty without a clear differentiation from existing works and a detailed comparison with similar techniques. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should include a detailed comparison with existing works and highlight the novelty of their contributions, but it does not specify how to do so. This makes the action vague and leaves the authors uncertain about the exact steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of the paper\\'s contributions being perceived as incremental or lacking novelty due to a lack of differentiation from existing works and a detailed comparison with similar techniques. However, it does not specify which part of the paper this issue pertains to, such as specific sections or comparisons mentioned. This makes it difficult for the authors to pinpoint the exact areas needing revision. The comment is specific in its critique but lacks grounding, as it does not direct the authors to a particular part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s contributions may be perceived as incremental or lacking novelty due to a lack of clear differentiation from existing works and a detailed comparison with similar techniques. This claim is somewhat verifiable as it provides a logical reasoning about the potential impact of the paper\\'s presentation on its perceived value within the NLP community. However, the comment lacks specific examples or references to existing works that could support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the paper's contributions, noting that without clear differentiation from existing works and a detailed comparison with similar techniques, the paper's contributions may be perceived as incremental or lacking substantial novelty. This feedback is valuable as it highlights a potential weakness in the paper's presentation and suggests a way to enhance its impact by providing a more detailed comparison with existing works. However, the comment could be more helpful if it offered specific examples of how to conduct this comparison or suggested particular aspects to focus on. Despite this, the feedback provides a clear direction for improvement, making it mostly helpful.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests an explanation for the difference in baseline results between Table 2 and those reported in Table 3 of reference [3]. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be addressed in the paper. The comment provides a concrete step for the authors to follow, ensuring they understand what is expected of them. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3 in [3],\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it requests an explanation for the difference in baseline results between these two tables, providing clear guidance on what needs to be clarified. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the difference in baseline results between Table 2 and those reported in Table 3 of reference [3]. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment requests an explanation for the difference in baseline results between Table 2 and those reported in Table 3 of reference [3]. This feedback is clear and actionable, as it directs the authors to clarify a specific discrepancy in their results. By addressing this point, the authors can provide a more comprehensive understanding of their findings and potentially resolve any confusion in the interpretation of their results. However, the comment could be more helpful if it provided additional context or suggestions on how to present the explanation. Overall, the comment is mostly helpful as it guides the authors toward a specific improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a misleading use of \"execution feedback\" in the title and Figure 2, clarifying that no actual execution feedback is used but rather approximated based on structural perturbations in the Abstract Syntax Tree (AST). It also points out a specific issue with the assumption that any perturbation results in a failure as execution feedback, as stated in Lines 233-238. Additionally, it critiques the definition of EF in Equation 1, noting that there is no guarantee that such perturbations will make the tests fail. This feedback provides clear and specific guidance on what needs to be addressed, such as clarifying the terminology and ensuring that the assumptions are valid. The authors know exactly what actions to take to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the title and Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the use of \"execution feedback,\" explaining that it is misleading and not actually used in the work. The comment further specifies the problem by pointing out the incorrect assumption in Lines 233-238 and the definition of EF in Equation 1. This provides clear guidance on what needs to be addressed to improve the clarity and accuracy of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of \"execution feedback\" is misleading, as it is not actually used in the work but rather approximated based on structural perturbations in the Abstract Syntax Tree (AST). The reviewer provides specific references to Lines 233-238 and Equation 1 to support this claim, offering detailed reasoning and evidence. This level of detail and reference to specific parts of the paper makes the claim fully verifiable, as it provides a clear and logical explanation of the issue. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a critical issue with the terminology used in the paper, specifically the concept of \"execution feedback.\" It points out that the term is misleading because it implies the use of actual execution feedback, whereas the work approximates it based on structural perturbations in the Abstract Syntax Tree (AST). The comment provides specific references to Lines 233-238 and Equation 1, where the authors make incorrect assumptions about the relationship between perturbations and execution feedback. This feedback is highly helpful as it highlights a significant error in the paper\\'s terminology and assumptions, providing the authors with clear guidance on how to correct and improve their draft. By addressing this issue, the authors can enhance the accuracy and clarity of their work, making this comment highly valuable.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several areas where the paper lacks information, specifically regarding the use of \"40 target words\" and \"a sequence of dots\" to remove bias in the model. It also points out the absence of details on how many games are sampled to demonstrate the severity of the bias problem. While the comment identifies these gaps, it does not provide explicit instructions or suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors can infer that they need to provide more details but are not given concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of information regarding \"40 target words\" and \"a sequence of dots\" used to remove bias in the model, as well as the absence of details on how many games are sampled to demonstrate the severity of the bias problem. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in detailing what information is missing, but it lacks grounding as it does not reference specific sections or parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the lack of information regarding \"40 target words\" and \"a sequence of dots\" used to remove bias in the model, as well as the absence of details on how many games are sampled to demonstrate the severity of the bias problem. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper lacks information, such as the use of \"40 target words\" and \"a sequence of dots\" to remove bias in the model, and the absence of details on how many games are sampled to demonstrate the severity of the bias problem. While the comment highlights these gaps, it does not provide suggestions or guidance on how the authors might address these issues or improve the clarity of their work. The feedback is somewhat helpful as it points out areas for improvement, but it lacks actionable advice or detailed suggestions, making it incomplete. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the use of simple datasets and the unrealistic scenario of uniformly random missing data in the experiments. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on which datasets should be used or how the experimental setup should be improved. The comment lacks actionable details, leaving the authors without a clear understanding of what changes are needed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the use of simple datasets and the unrealistic scenario of uniformly random missing data in the experiments. However, it does not specify which datasets are considered simple or provide examples of more realistic scenarios. The authors may infer that the comment pertains to the experimental section, but without explicit references, it is weakly grounded. The comment is specific in its critique of the experimental setup, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are conducted on \"some simple datasets\" and that the \"uniformly random missing\" scenario is \"unrealistic in practice.\" However, the comment lacks specific examples or references to support these claims. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies two issues with the experiments: the use of simple datasets and the unrealistic scenario of uniformly random missing data. While it highlights areas for improvement, the comment lacks specificity and actionable guidance. It does not suggest alternative datasets or provide examples of more realistic scenarios for missing data. Without detailed feedback or recommendations, the authors are left with a general understanding of what needs to be addressed but without a clear path forward. Therefore, the comment is barely helpful, as it provides some insight but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that Figure 4 lacks legends for the plots, making them difficult to interpret. It suggests that the authors should include what each data point or plot corresponds to. This feedback is clear and provides a direct action for the authors to take, ensuring that the plots are properly labeled and easier to understand. The comment is highly actionable as it specifies exactly what needs to be done to improve the draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which is the lack of legends for the plots, and suggests that the authors include what each data point or plot corresponds to. This provides clear guidance on what needs to be addressed to improve the figure\\'s interpretability. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 4 lacks legends for the plots, making them hard to interpret. This is a factual statement that describes an issue with the figure, but it does not contain an opinion, judgment, or suggestion that requires verification. It is purely descriptive and does not present a claim that needs justification or evidence. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 4, noting that it lacks legends for the plots, which makes them difficult to interpret. It provides a clear and actionable suggestion for improvement by recommending that the authors include what each data point or plot corresponds to. This feedback is direct and helpful as it guides the authors on how to enhance the clarity and usability of their figure, allowing them to better communicate their results. However, the comment could be more helpful if it suggested specific ways to label the plots or provided examples of how to effectively include legends. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the specific focus of the paper on sequence-to-sequence models and suggests that the general quantization-aware training strategy could be extended to other models. It also requests clarification on whether the proposed robustness-aware quantization scheme offers any benefits specifically for seq2seq models. While the comment implies that the authors should clarify or highlight any specific contributions related to seq2seq models, it does not provide explicit instructions on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification or highlight specific benefits. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the specific focus of the paper on sequence-to-sequence models and suggests that the general quantization-aware training strategy could be extended to other models. It also requests clarification on whether the proposed robustness-aware quantization scheme offers any benefits specifically for seq2seq models. However, the comment does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The authors can make an educated guess that it relates to the methodology or results sections, but the comment lacks full grounding. It is specific in its request for clarification, but the lack of grounding limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the specific focus of the paper on sequence-to-sequence models and suggests that the general quantization-aware training strategy could be extended to other models. It also requests clarification on whether the proposed robustness-aware quantization scheme offers any benefits specifically for seq2seq models. The comment is based on logical reasoning, as it questions the specificity of the paper\\'s focus and suggests that the strategy could be more broadly applicable. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to provide additional information or evidence to fully substantiate the claim, hence the score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the specific focus of the paper on sequence-to-sequence models and suggests that the general quantization-aware training strategy could be extended to other models. It also requests clarification on whether the proposed robustness-aware quantization scheme offers any benefits specifically for seq2seq models. While the comment identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their draft. The feedback is somewhat helpful as it prompts the authors to consider the broader applicability of their work, but it lacks depth and actionable advice, making it barely helpful. Therefore, it aligns with a score of 2.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests additional ablation studies to explore how the algorithm\\'s behavior and the accuracy of its Q estimates change as the hyperparameter lambda varies. This provides a clear and direct action for the authors to take, as it specifies what additional analysis is needed to improve the draft. The comment is concrete in its request for more detailed experimentation, giving the authors a clear understanding of what is required to enhance their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 2\" and \"lambda,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: more ablation studies on how the algorithm\\'s behavior and the accuracy of its Q estimates change as lambda varies. This provides clear guidance on what the authors need to add to their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for additional information or analysis, specifically asking for more ablation studies on how the algorithm\\'s behavior and the accuracy of its Q estimates change as the hyperparameter lambda varies. This is not a claim that requires verification but rather a suggestion for further exploration. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting the need for more ablation studies on the hyperparameter lambda in Algorithm 2. It requests additional analysis on how the algorithm\\'s behavior and the accuracy of its Q estimates change as lambda varies. This feedback is clear and actionable, providing the authors with a specific direction to enhance their draft by exploring the impact of this hyperparameter. However, the comment could be more helpful if it offered suggestions on how to conduct these ablation studies or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for further investigation, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the base encoder of the proposed model, asking whether it is a pre-trained model or if the authors train it from scratch. While the question implies that the authors should clarify this aspect in their paper, it does not provide explicit guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information about the base encoder. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly asks about the base encoder of the proposed model, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified or addressed, namely, whether the model uses a pre-trained encoder or is trained from scratch. This provides clear guidance for the authors on what information to include in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the base encoder of the proposed model, asking whether it is pre-trained or trained from scratch. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the base encoder of the proposed model, seeking clarification on whether it is pre-trained or trained from scratch. While it identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. The comment lacks actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the Ethical Statement is well-written but suggests that it should be extended to include a more concrete discussion of challenges not addressed in the dataset. The reviewer provides specific examples, such as gender beyond the binary, races other than Black, and other sources of social bias, indicating what should be included in the extension. This feedback is explicit and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Ethical Statement,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, namely, extending the discussion to include challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. This level of detail gives the authors a clear understanding of what needs to be improved. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges that the Ethical Statement is well-written but suggests that it should be extended to include a more concrete discussion of challenges not addressed in the dataset. The reviewer provides specific examples of these challenges, such as gender beyond the binary, races other than Black, and other sources of social bias. This level of detail provides a clear and logical reasoning for the suggestion, making the claim mostly verifiable. However, the comment could be strengthened by referencing specific studies or literature that highlight these challenges, which would further enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges that the Ethical Statement is well-written but suggests that it should be extended to include a more concrete discussion of challenges not addressed in the dataset. The reviewer provides specific examples of these challenges, such as gender beyond the binary, races other than Black, and other sources of social bias. This feedback is clear and actionable, as it gives the authors a concrete direction on how to enhance their ethical considerations. By addressing these specific areas, the authors can improve the comprehensiveness and depth of their ethical discussion, making the comment mostly helpful. However, it could be more helpful if it included suggestions on how to incorporate these discussions effectively into the paper. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the transformation of variables in equations (13) and (14), specifically asking how $$\\\\hat{m}_t$$ and $$g_t$$ become $$x$$. While the comment highlights a potential area of confusion, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the transformation process. However, the comment lacks concrete details on how to clarify this point, making it somewhat actionable. The authors know they need to address the confusion but may not be entirely sure how to do so without further guidance.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (13)\" and \"equation (14),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue by asking for clarification on how the variables $$\\\\hat{m}_t$$ and $$g_t$$ become $$x$$ in equation (14). This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the transformation of variables in equations (13) and (14). It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the transformation of variables in equations (13) and (14), specifically asking how $$\\\\hat{m}_t$$ and $$g_t$$ become $$x$$ in equation (14). This is a clear and specific request for clarification, which can help the authors improve the clarity and transparency of their work. However, the comment does not provide any additional context or suggestions on how to address this issue, which limits its helpfulness. While it identifies a potential area for improvement, it lacks depth and actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the length of mini-batches, specifically noting that it may be non-integer values. The reviewer suggests clarifying this aspect to ensure there are no side effects, such as when the value is significantly small (e.g., $\\tau_t << 1$). While the comment implies that the authors should address this issue, it does not provide explicit instructions on how to clarify or address the potential side effects. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and clarify the impact of non-integer mini-batch lengths. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the length of the mini-batches tau_t,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of non-integer values and suggests that the analysis may not be valid if the value is significantly small (e.g., $\\tau_t << 1$). The comment provides a clear direction for the authors to clarify this aspect, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the length of mini-batches being non-integer values and suggests that this should be clarified to ensure there are no side effects. The reviewer provides a specific example by asking what happens if $\\tau_t << 1$. This question prompts the authors to consider the implications of non-integer mini-batch lengths on their analysis. However, the comment lacks detailed reasoning or references to support the claim that non-integer values could affect the analysis. While the suggestion is logical, it requires further elaboration to be fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the length of mini-batches being non-integer values, which could have side effects on the analysis. It suggests clarifying this aspect, particularly when the value is significantly small (e.g., $\\tau_t << 1$). This feedback is clear and actionable, as it prompts the authors to investigate and address the potential implications of non-integer mini-batch lengths. However, the comment could be more helpful if it provided specific guidance on how to clarify or address this issue. Overall, the comment is mostly helpful as it directs the authors to a critical area that needs attention, but it could be more comprehensive with additional suggestions or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the importance of examining the computational cost associated with the inference process of the SCALE model, specifically mentioning the two types of decoding involved: STM decoding and LLM decoding. However, it does not provide explicit guidance or suggestions on how to conduct this examination or what specific aspects of the computational cost should be considered. The action is implicit and somewhat vague, as the authors are left to infer that they need to investigate the computational cost but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the inference cost associated with the SCALE model, specifically mentioning two types of decoding: STM decoding and LLM decoding. However, it does not specify which part of the paper discusses these decoding processes, making it weakly grounded. The comment is specific in its request to examine the computational cost, providing a clear direction for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests examining the computational cost associated with the inference process of the SCALE model, specifically mentioning two types of decoding: STM decoding and LLM decoding. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this examination is important or how it would impact the paper. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights an important aspect of the SCALE model, specifically the inference cost associated with the two types of decoding: STM decoding and LLM decoding. It suggests that the authors should examine the computational cost of the inference process, which is a relevant and actionable feedback. However, the comment lacks depth and does not provide specific guidance on how to conduct this examination or what metrics to consider. While it identifies a potential area for improvement, it does not offer detailed suggestions or examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the use of a subset of the complete dataset and the lack of performance comparisons with state-of-the-art models, which makes it difficult to demonstrate the effectiveness of the proposed methods. Additionally, it points out peculiar experimental results, such as an unsupervised result outperforming a supervised result in Table 2. While the comment identifies these issues, it does not provide explicit guidance on how to address them, such as suggesting which additional data or comparisons should be included or how to interpret the peculiar results. The actions are implicit and somewhat vague, as the authors can infer that they need to expand their dataset and comparisons, but the comment lacks concrete steps or examples to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the dataset used and the lack of performance comparisons with state-of-the-art models, as well as the peculiar experimental results, such as the unsupervised result outperforming the supervised result. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the article only uses a subset of the complete dataset and lacks performance comparisons with state-of-the-art models, making it difficult to demonstrate the effectiveness of the proposed methods. It also points out peculiar experimental results, such as an unsupervised result outperforming a supervised result in Table 2. The claim is somewhat verifiable as it provides a logical reasoning for the potential limitations of the study, but it lacks specific examples or references to support the claim about the peculiar experimental results. Additionally, the comment does not provide detailed reasoning or evidence to fully substantiate the claim about the dataset and performance comparisons. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two significant issues with the paper. First, it points out that the article only uses a subset of the complete dataset, which limits the demonstration of the proposed methods' effectiveness. Second, it notes the lack of performance comparisons with state-of-the-art models, further complicating the evaluation of the proposed methods. Additionally, the comment highlights peculiar experimental results, such as an unsupervised result outperforming a supervised result in Table 2, which suggests a need for further investigation or clarification. While the comment effectively identifies areas for improvement, it could be more helpful by providing specific suggestions on how to address these issues, such as recommending additional datasets or comparisons to include. Overall, the feedback is mostly helpful as it directs the authors to important aspects of their work that require attention, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the phrase \"lacks inherent semantic meaning\" is used but not further elaborated upon. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on what additional information or elaboration is needed to clarify the meaning of the phrase. Without specific instructions or examples, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper the phrase \"lacks inherent semantic meaning\" is used in. Without this information, the authors cannot confidently determine where to address the issue. Additionally, the comment lacks specificity because it does not provide any details on what needs to be elaborated or how the authors should clarify the meaning of the phrase. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the phrase \"lacks inherent semantic meaning\" is used but not further elaborated upon. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this phrase is problematic or how it could be clarified. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the phrase \"lacks inherent semantic meaning\" is used but not further elaborated upon. However, it does not provide any additional context, explanation, or suggestions on how the authors might clarify or expand on this concept. Without specific guidance or examples, the authors are left without a clear understanding of what needs to be addressed or how to improve their draft. This lack of actionable feedback makes the comment barely helpful, as it identifies a potential issue but does not offer any meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the lack of sufficient details or justification for using a large number of hidden units and an additional elementwise function, and the potential bias introduced by treating unobserved ratings as zeros. While the comment identifies these issues, it does not provide explicit guidance on how the authors should address them. The authors are left to infer that they need to provide more detailed justification and potentially explore alternative methods to mitigate bias. However, the comment lacks concrete steps or suggestions on how to implement these changes, making it somewhat actionable. The authors know what needs to be addressed but may struggle with the specifics of how to do so.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of a large number of hidden units and an additional elementwise function, as well as the treatment of unobserved ratings as zeros. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the lack of justification for these choices and the potential bias introduced by treating unobserved ratings as zeros. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not provide sufficient details or justification for using a large number of hidden units and an additional elementwise function. It also suggests that treating unobserved ratings as zeros may introduce bias, which is not justified. The comment provides a logical reasoning for the first part, noting the lack of details, and highlights a potential issue with the second part. However, it lacks specific examples or references to support the claim about the bias introduced by treating unobserved ratings as zeros. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two specific areas where the authors could improve their draft: the lack of justification for using a large number of hidden units and an additional elementwise function, and the potential bias introduced by treating unobserved ratings as zeros. By pointing out these issues, the comment provides the authors with clear areas to focus on for improvement. However, it does not offer specific suggestions or guidance on how to address these concerns, such as recommending alternative methods or providing examples of how to justify the choices made. While the comment highlights important weaknesses, it lacks actionable advice, making it somewhat helpful. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the robustness of the claim regarding motivation, suggesting that MathGLM\\'s high accuracy of 93.03% on a constructed dataset for complex computations could be achieved with 100% accuracy using other tools. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue of robustness or how to improve the motivation claim. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the claim regarding motivation, specifically questioning the robustness of the claim. However, it does not specify which part of the paper this claim is made in, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area needing revision. The comment provides some specificity by questioning the robustness of the claim and offering a counterpoint, but without clear grounding, the authors may struggle to identify where to make changes. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation for MathGLM is not robust, suggesting that the high accuracy achieved by MathGLM could be replicated with 100% accuracy using other tools. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains somewhat verifiable, as the authors would need to conduct further research to fully address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the robustness of the claim regarding the motivation for MathGLM, suggesting that the high accuracy achieved by MathGLM could be replicated with 100% accuracy using other tools. This feedback identifies a potential weakness in the paper\\'s argument and prompts the authors to reconsider their claims. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the robustness of their claim. While it highlights an area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant weakness in the paper, noting that the authors rely on synthetic datasets and real-world settings for evaluating event-based dense tracking, which does not accurately reflect the true nature of event-based dense tracking. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might improve their evaluation or what specific changes could be made to better reflect event-based dense tracking. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a significant weakness in the paper, specifically regarding the evaluation of event-based dense tracking. It mentions that the authors rely on synthetic datasets and real-world settings, which does not accurately reflect event-based dense tracking. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. Additionally, while the comment identifies the problem, it does not provide specific guidance on how to address it. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that relying on synthetic datasets and real-world settings for evaluating event-based dense tracking does not accurately reflect the true nature of event-based dense tracking, which is considered a significant weakness. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate why synthetic datasets and real-world settings are insufficient for evaluating event-based dense tracking. Without this additional information, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically that the evaluation of event-based dense tracking relies on synthetic datasets and real-world settings, which does not accurately reflect the true nature of event-based dense tracking. This is a critical observation that highlights a gap in the evaluation methodology. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their evaluation approach. Without actionable advice or examples, the feedback, while insightful, remains somewhat helpful as it points out a key area for improvement but lacks depth and practical guidance. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the motivation of the paper, suggesting that it opposes a widely recognized understanding without sufficient justification. It also criticizes the experiments as weak due to limited dataset and LLM size, questioning the persuasiveness and potential misleading nature of the results. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback lacks actionable details, leaving the authors uncertain about what specific changes or additions are needed to strengthen their paper. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the motivation of the paper, questioning its alignment with existing research on the importance of diversity in instruction-tuning data. It also critiques the experiments, noting their limitations in dataset and LLM size, which affects the persuasiveness of the results. However, the comment does not specify which sections of the paper discuss the motivation or experiments, making it difficult for the authors to pinpoint the exact parts that need revision. While the authors can infer that the motivation and experimental sections are the focus, the lack of explicit references to these sections limits the comment\\'s grounding. The comment is specific in detailing the issues with the motivation and experiments, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s motivation is unclear and that it opposes a widely recognized understanding without strong justification. It also criticizes the experiments as weak due to limited dataset and LLM size, questioning the persuasiveness and potential misleading nature of the results. The comment provides some logical reasoning by referencing the importance of diversity in instruction-tuning data and the limitations of the experiments. However, it lacks specific examples or references to support the claim that the results could mislead the community. This makes the claim somewhat verifiable, as it provides a general critique but requires more detailed evidence to fully substantiate the concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s motivation, suggesting that it contradicts a widely recognized understanding without providing strong justification. It also critiques the experiments, noting their limitations in dataset and LLM size, which affects the persuasiveness of the results. The comment highlights a potential concern that the results could mislead the community if not thoroughly validated. However, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. While it points out important areas for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly questions the absence of confidence intervals on the substitution ASR in Table 3. This provides a clear and direct action for the authors to take, which is to include confidence intervals in the table. The comment is explicit and concrete, as it specifies exactly what needs to be added to the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by asking for the inclusion of confidence intervals on the substitution ASR. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual question asking for clarification on the absence of confidence intervals in Table 3. It does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and specific, questioning the absence of confidence intervals on the substitution ASR in Table 3. This feedback is actionable and provides a direct suggestion for improvement, which is to include confidence intervals in the table. By addressing this point, the authors can enhance the clarity and robustness of their results. However, the comment could be more helpful if it provided additional context or explained why confidence intervals are important in this context. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of estimating the mean element mu_g for different kernel spaces. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue. The comment lacks concrete details or actionable steps, leaving the authors uncertain about what changes they should make to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the clarity of estimating the mean element mu_g for different kernel spaces. However, it does not specify which part of the paper this issue pertains to, such as a particular section or equation where this estimation is discussed. Without explicit references or context, the authors may find it challenging to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what is unclear or how the estimation could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the clarity of estimating the mean element mu_g for different kernel spaces. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the estimation of the mean element mu_g for different kernel spaces. However, it does not provide any guidance or suggestions on how the authors might clarify this aspect or improve the clarity of their work. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests considering datasets with a larger number of clusters, such as ImageNet with reduced samples and feature dimensions, to make the story more complete. While the comment implies that the authors should include these datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not provided with specific guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests considering datasets with a larger number of clusters, such as ImageNet with reduced samples and feature dimensions, to make the story more complete. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of such datasets, but without clear grounding, the authors may struggle to identify where this feedback is most relevant. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that considering datasets with a larger number of clusters, such as ImageNet with reduced samples and feature dimensions, would make the story more complete. However, the comment does not provide any reasoning or evidence to support why these specific datasets would be beneficial or how they would enhance the completeness of the story. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that while some baselines may not work on larger datasets, considering datasets with a larger number of clusters, such as ImageNet with reduced samples and feature dimensions, could enhance the completeness of the story. This feedback is somewhat helpful as it provides a direction for the authors to consider additional datasets that could strengthen their analysis. However, the comment lacks specificity and does not offer detailed guidance on how to incorporate these datasets or what specific aspects of the story would be improved. While it points out a potential area for expansion, it does not fully support the authors in making meaningful improvements to their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the cosine similarity score would be more effective than the Euclidean distance when computing the Decidability. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion to conduct an experiment, compare the two methods, or discuss the implications of using cosine similarity. The comment lacks actionable guidance, leaving the authors without a clear path to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the use of cosine similarity score versus Euclidean distance in computing the Decidability, but it does not specify which part of the paper this issue pertains to. The authors may infer that it relates to the methodology or results section, but without explicit grounding, it is difficult to pinpoint the exact location. The comment is specific in questioning the choice of metric, but it lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of cosine similarity score versus Euclidean distance in computing the Decidability, suggesting that cosine similarity might be more appropriate. However, the comment does not provide any supporting evidence, reasoning, or references to justify why cosine similarity would be better. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of metric for computing the Decidability, suggesting that cosine similarity might be more appropriate than Euclidean distance. While this comment identifies a potential area for improvement, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. It does not offer actionable advice or examples to help the authors evaluate or implement the suggested change. As a result, the comment is somewhat helpful, as it prompts the authors to consider an alternative approach but does not fully support them in making improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point criticizes the experiments as weak, noting that the paper only conducts a toy experiment and an experiment on a real-world dataset, and that the proposed method does not compare with other counterpart methods. It also states that the experimental results are insufficient to validate the effectiveness of the proposed method. While the comment identifies several issues with the experimental setup, it does not provide explicit guidance on how to address these issues or suggest specific actions for improvement. The authors are left to infer that they should conduct more comprehensive experiments and comparisons, but the comment lacks concrete details on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the experiments, specifically mentioning that the paper only conducts a toy experiment and an experiment on a real-world dataset, and that the proposed method does not compare with other counterpart methods. It also notes that the experimental results are insufficient to validate the effectiveness of the proposed method. However, the comment does not specify which sections of the paper these experiments are described in, making it difficult for the authors to pinpoint the exact parts that need revision. While the authors can infer that the experiments are the focus, the lack of explicit references to sections or figures makes the comment weakly grounded. The comment is specific in detailing the issues with the experiments, but the lack of grounding limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are weak, citing the lack of comparison with other methods and insufficient experimental results to validate the proposed method. However, the comment does not provide specific examples of other methods that should be compared or detailed reasoning on why the current results are insufficient. This lack of supporting evidence or detailed justification makes the claim somewhat verifiable, as the authors would need to infer the specific issues and potential solutions based on the general critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several weaknesses in the experimental section of the paper, including the limited scope of the experiments (only a toy experiment and an experiment on a real-world dataset) and the lack of comparison with other counterpart methods. It also points out that the experimental results are insufficient to validate the effectiveness of the proposed method. While the comment highlights important areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues, such as recommending additional experiments or comparisons. This limits the comment\\'s usefulness, as it offers a clear identification of weaknesses but lacks actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the figures related to completion errors are not referenced in the relevant analysis sections of the appendix. This provides a clear and direct action for the authors to take: they should ensure that these figures are properly referenced in the appendix. The comment is explicit and concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figures related to completion errors,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the reference to these figures in the relevant analysis sections of the appendix. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual statement describing an omission in the paper, specifically that figures related to completion errors are not referenced in the relevant analysis sections of the appendix. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that figures related to completion errors are not referenced in the relevant analysis sections of the appendix. This feedback is clear and actionable, as it directs the authors to ensure that these figures are properly referenced, which is crucial for the reader\\'s understanding and for maintaining the integrity of the analysis. However, the comment could be more helpful if it provided additional context or suggested how the authors might address this issue, such as recommending specific sections where the references should be included. Overall, the comment is mostly helpful as it highlights a critical oversight and guides the authors toward a necessary correction.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether perplexity is measured on consistent validation sets across levels, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what steps to take to clarify the measurement of perplexity. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the consistency of validation sets across levels in the measurement of perplexity. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where perplexity is discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing attention. Additionally, the comment does not provide specific guidance on how to address the issue of inconsistent validation sets. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the consistency of validation sets across levels in the measurement of perplexity. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the consistency of validation sets across levels in the measurement of perplexity. While it identifies a potential issue, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this concern. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it highlights a potential problem but does not offer any actionable steps for resolution.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses an opinion that the setting and algorithm lack originality, suggesting they are incremental combinations of existing methods. However, it also acknowledges that the algorithm for graph labelings is efficient and new. The comment does not provide any explicit or implicit actions for the authors to take, nor does it offer suggestions for improvement. It lacks actionable guidance, leaving the authors without a clear understanding of what changes might be necessary to address the perceived lack of originality. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides an opinion about the originality of the setting and algorithm, suggesting they are incremental combinations of existing methods. However, it does not specify which parts of the paper this opinion pertains to, making it difficult for the authors to identify the exact sections that need attention. Additionally, while the comment acknowledges the efficiency and novelty of the algorithm for graph labelings, it does not provide specific guidance on how to address the perceived lack of originality. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses an opinion about the originality of the setting and algorithm, suggesting they are incremental combinations of existing methods. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides an opinion about the originality of the setting and algorithm, suggesting that they may be incremental combinations of existing methods. However, it also acknowledges the efficiency and novelty of the algorithm for graph labelings. While the comment identifies a potential issue with originality, it lacks specific guidance or suggestions on how the authors might address this concern or enhance the originality of their work. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with using the state action of the current policy in the target environment as regularization, suggesting that it could harm learning. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what alternatives they could consider. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the use of the state action of the current policy in the target environment as regularization. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential harm of using a suboptimal policy for regularization, but it lacks grounding as it does not direct the authors to a particular section or figure. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using the state action of the current policy in the target environment as regularization can harm learning. It provides a logical explanation by stating that a suboptimal policy would result in a suboptimal state action distribution used for regularization. This reasoning is clear and provides a sound basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential issue with using the state action of the current policy in the target environment as regularization, suggesting that it could harm learning due to the use of a suboptimal policy. This feedback is somewhat helpful as it points out a specific area that could be problematic in the learning process. However, the comment lacks depth and does not provide actionable suggestions or alternatives for addressing this issue. While it highlights a potential weakness, it does not offer enough guidance for the authors to make meaningful improvements. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential negative impact of the feature compactness loss and sharpness-aware minimization on the model\\'s performance on base classes. It suggests that if such degradation occurs, the authors should discuss how to mitigate this issue to maintain performance. While the comment implies that the authors should address this potential issue, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss mitigation strategies but are not given specific steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the objective of the feature compactness loss and sharpness-aware minimization, which is to reduce distances among base classes. It raises a concern about the potential negative impact on the model\\'s performance on base classes and suggests discussing mitigation strategies if such degradation occurs. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing the concern and suggesting a potential area for improvement, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential negative impact of the feature compactness loss and sharpness-aware minimization on the model\\'s performance on base classes. It suggests that if such degradation occurs, it is important to discuss how this issue could be mitigated. However, the comment does not provide specific evidence, examples, or references to support the claim that this operation could negatively impact the model\\'s performance. The reasoning is logical, but it lacks detailed justification or examples, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the feature compactness loss and sharpness-aware minimization, which is intended to reduce distances among base classes. It raises a concern that this operation might negatively impact the model\\'s performance on the base classes and suggests that the authors should discuss how to mitigate this issue to maintain performance. This feedback is clear and actionable, as it highlights a specific area of concern and provides a direction for the authors to address it. However, the comment could be more helpful if it offered specific suggestions or examples on how to mitigate the potential degradation. Overall, the comment is mostly helpful, as it directs the authors to a critical area that needs further exploration and discussion.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses questions about the insight and potential for developing new methods, as well as how to prevent attention collapse in CL. While it highlights areas that need clarification or further explanation, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The questions are implicit and lack specific guidance, making it difficult for the authors to know exactly what actions to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the insight and potential for developing new methods, as well as how to prevent attention collapse in CL. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections that need attention. The lack of explicit references to specific sections or elements of the paper results in weak grounding. Additionally, the comment is specific in its request for clarification on the insight and prevention of attention collapse, but without grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification on the insight and potential for developing new methods, as well as how to prevent attention collapse in CL. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the originality and contribution of the work, specifically asking for clarification on the insight that this work provides for developing new methods and how it addresses the issue of attention collapse in CL. While the comment identifies areas that need further explanation, it lacks specific suggestions or guidance on how the authors might address these questions or improve their work. The feedback is somewhat helpful as it prompts the authors to consider the novelty and impact of their work, but it does not provide actionable steps or detailed advice for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of the CHC model on the capabilities of MLLMs, specifically asking for clarification on the attributes or behaviors a powerful MLLM grounded in CHC theory would exhibit. It also requests case studies or pilot experiments to illustrate the significance of this influence. While the comment identifies a gap in the paper and suggests areas for further exploration, it does not provide explicit instructions on how to address these questions or conduct the requested experiments. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information or examples to clarify the impact of the CHC model. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the impact of the CHC model on the capabilities of MLLMs, specifically asking for clarification on the attributes or behaviors a powerful MLLM grounded in CHC theory would exhibit. It also requests case studies or pilot experiments to illustrate the significance of this influence. However, the comment does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. While the authors can infer that it relates to the introduction or discussion of the CHC model, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the impact on MLLMs and the need for case studies. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the impact of the CHC model on the capabilities of MLLMs, specifically asking for clarification on the attributes or behaviors a powerful MLLM grounded in CHC theory would exhibit. It also requests case studies or pilot experiments to illustrate the significance of this influence. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the impact of the CHC model is unclear. Without additional context or justification, the authors may find it challenging to address the question effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the impact of the CHC model on the capabilities of MLLMs. It raises a question about the attributes or behaviors a powerful MLLM grounded in CHC theory would exhibit and requests case studies or pilot experiments to illustrate the significance of this influence. This feedback is clear and actionable, as it directs the authors to provide additional information or examples to clarify the impact of the CHC model. However, the comment could be more helpful if it offered suggestions on how to structure these case studies or experiments. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors consider integrating more up-to-date pretraining models to demonstrate the significance and practical usage of their approach. The reviewer provides specific examples of recent works, such as \"UniCorn: A Unified Contrastive Learning Approach for Multi-view Molecular Representation Learning\" and \"Adapting Differential Molecular Representation with Hierarchical Prompts for Multi-label Property Prediction,\" which could be used as references. This feedback is explicit and provides concrete guidance on how to enhance the paper by incorporating more recent models. The authors know exactly what action to take and can easily implement it by exploring these references. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"pretraining model, Pre-GNN (Hu et al., 2020),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests considering more up-to-date pretraining models and provides examples of recent works, such as \"UniCorn: A Unified Contrastive Learning Approach for Multi-view Molecular Representation Learning\" and \"Adapting Differential Molecular Representation with Hierarchical Prompts for Multi-label Property Prediction.\" This provides clear guidance on what needs to be addressed and how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the pretraining model, Pre-GNN (Hu et al., 2020), is outdated and encourages the authors to consider more recent models. The reviewer provides specific examples of recent works, such as \"UniCorn: A Unified Contrastive Learning Approach for Multi-view Molecular Representation Learning\" and \"Adapting Differential Molecular Representation with Hierarchical Prompts for Multi-label Property Prediction,\" which supports the claim that more powerful models have emerged. This provides a clear and logical reasoning for the suggestion, making the claim mostly verifiable. However, the comment could be strengthened by a more detailed explanation of why these recent models are more powerful or how they relate to the authors\\' work. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by suggesting that the pretraining model, Pre-GNN (Hu et al., 2020), is outdated and encourages the authors to consider more recent and powerful models. This feedback is valuable as it prompts the authors to update their approach to showcase its significance and practical usage. The comment also provides specific examples of recent works, such as \"UniCorn: A Unified Contrastive Learning Approach for Multi-view Molecular Representation Learning\" and \"Adapting Differential Molecular Representation with Hierarchical Prompts for Multi-label Property Prediction,\" which could be integrated into the paper. This guidance is clear and actionable, offering the authors a concrete path to enhance their draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential challenge in the model\\'s approach, specifically the difficulty in object segmentation and pose tracking in the real world. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion on how to address this challenge or improve the documentation. The comment lacks actionable guidance, leaving the authors without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. A.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the challenge of using the difference between current and target object poses as input and notes the difficulty in object segmentation and pose tracking in the real world. The comment provides a clear critique of the approach and acknowledges the thorough documentation in the specified section. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a potential challenge in the model\\'s approach, specifically the difficulty in object segmentation and pose tracking in the real world. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. The comment acknowledges that the authors have documented their approach well, but it lacks detailed reasoning or justification for why this challenge is significant. As a result, the claim is considered unverifiable, as it does not provide sufficient evidence or reasoning to support the assertion.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential challenge in the model\\'s approach, specifically the difficulty in object segmentation and pose tracking in the real world. It acknowledges that the authors have documented their approach well in Section A.3, which is a positive note. However, the comment does not provide any suggestions or guidance on how the authors might address this challenge or improve their approach. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more evidence of the downstream performance of their controllable text generation models, particularly in real NLG applications. It explicitly recommends considering style transfer as a potential area to explore. While the comment provides a clear direction for improvement, it does not offer detailed guidance on how to implement this suggestion or what specific metrics or evaluations should be used. The action is explicit but somewhat vague, as it lacks concrete steps for execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 116-117,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should provide more evidence of the downstream performance of their controllable text generation models, particularly in real NLG applications. The comment further recommends exploring style transfer as a potential area to demonstrate the advantage of the proposed model. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide more evidence of the downstream performance of their controllable text generation models, particularly in real NLG applications. The reviewer recommends exploring style transfer as a potential area to demonstrate the advantage of the proposed model. However, the comment lacks specific examples or references to support the claim that style transfer is a good starting point or how it could be applied. This makes the claim somewhat verifiable, as it provides a general direction but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It identifies a gap in the current draft by pointing out the need for more evidence of the downstream performance of the controllable text generation models, particularly in real NLG applications. The reviewer offers a specific recommendation to explore style transfer as a potential area to demonstrate the advantage of the proposed model. This feedback is valuable as it guides the authors on how to enhance the practical relevance and impact of their work. However, the comment could be more helpful if it included additional suggestions or examples of how to implement style transfer or other potential applications. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses confusion about the test set performance on the GLUE datasets and questions whether the labels to these sets are available to the public. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address the confusion or clarify the availability of labels, making it unactionable. The authors are left without a clear understanding of what steps to take to improve their draft based on this feedback.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses confusion about the test set performance on the GLUE datasets and questions the availability of labels to the public. However, it does not specify which part of the paper this confusion pertains to, such as a particular section or figure discussing the GLUE datasets. Without explicit references or context, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what needs to be clarified or addressed regarding the test set performance or label availability. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses confusion about the test set performance on the GLUE datasets and questions the availability of labels to the public. However, it does not provide any supporting evidence, reasoning, or references to justify the confusion or the need for clarification. The comment lacks specificity and does not offer any actionable steps for the authors to address the issue. As a result, the claim is considered unverifiable, as it does not provide sufficient information for the authors to understand or address the concern. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses confusion about the test set performance on the GLUE datasets and questions whether the labels to these sets are available to the public. However, it does not provide any specific suggestions or guidance on how the authors might clarify this issue or address the confusion. The comment lacks actionable feedback, leaving the authors without a clear understanding of what steps to take to improve their draft. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests shortening Section 3.2 because many equations are well-known in the community and not original to the work. This implies that the authors should remove or condense the section to save space, which could then be used to include \"missing important details.\" While the action is explicit, it lacks concrete guidance on which specific details should be included or how to prioritize them. The authors know they need to shorten the section, but the comment does not provide detailed instructions on how to do so effectively. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests shortening the section due to the presence of well-known equations that are not original to the work, and it implies that this would allow for the inclusion of \"missing important details.\" This provides clear guidance on what needs to be addressed in the section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Section 3.2 could be shortened because many equations are well-known in the community and not original to the work. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion to shorten the section. However, the comment lacks specific examples or references to the well-known equations, which would strengthen the justification. The authors might need to look up the equations to understand the basis of the suggestion, making the claim somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that Section 3.2 could be shortened since many of the equations presented are well-known in the community and not original to the work. This feedback is somewhat helpful as it identifies an area where the paper could be condensed to focus on more original contributions. However, the comment lacks specific guidance on which details are missing or how the authors should prioritize the content to be included. While it provides a direction for improvement, it does not offer detailed actionable steps, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the evaluation methods used in Figures 3, Table 3, and Figure 5, specifically asking whether automatic or human evaluation was used. While the comment does not provide explicit instructions or suggestions for improvement, it implies that the authors should clarify this information in their draft. The action is implicit, as the authors need to infer that they should provide this clarification. However, the comment is somewhat actionable because it provides a clear direction for the authors to follow, even if it does not specify how to implement the change. Therefore, this comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3, Table 3, and Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly asks for clarification on the evaluation method used between automatic and human evaluation. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual question asking for clarification on the evaluation methods used in Figures 3, Table 3, and Figure 5. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the evaluation methods used in Figures 3, Table 3, and Figure 5, specifically asking whether automatic or human evaluation was used. While it does not provide a critique or suggestion for improvement, it does prompt the authors to clarify an important aspect of their methodology. This feedback is somewhat helpful as it directs the authors to address a potential gap in their explanation, but it lacks depth and does not offer specific guidance on how to improve the clarity or presentation of this information. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the average coverage rate being larger than the bound provided by a theorem. It questions the reviewer\\'s understanding and asks for clarification or additional assumptions to achieve the desired coverage rate. While the comment identifies a potential issue, it does not provide explicit instructions on how to address it or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the discrepancy and potentially revise their assumptions or analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific time points (\"1 -> 0.9, t=5: 0.9 -> 1\") and refers to the variable \"\u03b8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the average coverage rate being larger than the bound provided by a theorem and asks for clarification or additional assumptions to achieve the desired coverage rate. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the average coverage rate being larger than the bound provided by a theorem. It provides specific examples from the paper (\"1 -> 0.9, t=5: 0.9 -> 1\") to support the claim that the adversary can generate a datum to make an error at odd times, leading to an average coverage rate of 0.5. The comment questions the reviewer\\'s understanding and asks for clarification or additional assumptions to achieve the desired coverage rate. This provides a clear and logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed references or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the average coverage rate being larger than the bound provided by a theorem. It provides specific examples from the paper to support the claim, such as \"1 -> 0.9, t=5: 0.9 -> 1,\" which helps the authors understand the problem. The comment also raises a question about the reviewer\\'s understanding and asks for clarification or additional assumptions to achieve the desired coverage rate. This feedback is clear and actionable, as it prompts the authors to investigate and address the discrepancy between the observed coverage rate and the theoretical bound. However, the comment could be more helpful if it offered suggestions on how to resolve the issue or provided additional context. Overall, the comment is mostly helpful, as it directs the authors to a specific area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that using a single translator per language may not be sufficient for producing annotations, as different translators may have different choices. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative methods for ensuring consistency in annotations. The action is implicit and vague, leaving the authors to infer that they need to consider using multiple translators or other strategies to improve annotation consistency. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that using a single translator per language may not be sufficient for producing annotations, as different translators may have different choices. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results section where annotations are discussed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which part needs attention. Additionally, the comment lacks specificity regarding what needs to be addressed or how the issue could be resolved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that using a single translator per language may not be sufficient for producing annotations, as different translators may have different choices. This claim is based on a logical reasoning that different translators may have varying preferences, which could impact the consistency of annotations. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to consider this reasoning and potentially conduct further analysis to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights a potential issue with the methodology of using a single translator per language for producing annotations. It suggests that this approach may not be sufficient due to the subjective nature of translation choices among different translators. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue or suggest alternative methods for ensuring consistency in annotations. Without detailed suggestions or examples, the feedback is somewhat helpful as it identifies a potential weakness but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about why people wear a hat and play guitar, rather than the other way around. However, it does not provide any explicit or implicit action for the authors to take. There is no suggestion for improvement, clarification, or further explanation that the authors could act upon. The comment lacks any actionable guidance, leaving the authors without a clear understanding of how to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the order of actions (\"people wear a hat and play guitar not vice-versa;\") but does not specify which part of the paper this question pertains to. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the context of the comment. Additionally, the comment lacks specificity as it does not provide any details or context about what this observation implies or how it relates to the paper. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question, \"people wear a hat and play guitar not vice-versa; why not?\", which does not contain a claim or opinion that requires verification. It is a factual inquiry seeking clarification, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review point raises a question about the order of actions, specifically why people wear a hat and play guitar rather than the other way around. However, it does not provide any context, explanation, or suggestion for improvement. Without additional information or guidance, the authors are left without a clear understanding of what aspect of their work is being questioned or how to address it. This lack of clarity and actionable feedback makes the comment unhelpful, as it does not contribute to the authors\\' understanding of their draft or suggest ways to enhance it. Therefore, the comment is rated as 1: Not Helpful at All.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that 2000 examples may be insufficient for the model to learn a specific transformation correctly. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting additional data collection, increasing the number of examples, or exploring alternative methods. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that 2000 examples may be insufficient for the model to learn a specific transformation correctly. However, it does not specify which part of the paper this claim is based on, such as a particular section or experiment. Without explicit references or context, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the transformation are problematic or how the authors might address this issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that 2000 examples may be insufficient for the model to learn a specific transformation correctly. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the number of examples (2000) may be insufficient for the model to learn a specific transformation correctly. While this feedback identifies a potential issue with the dataset size, it lacks specificity and does not provide actionable guidance on how the authors might address this concern. The comment does not offer suggestions for increasing the dataset size, exploring alternative methods, or discussing the implications of this limitation. As a result, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about Algorithm 1, specifically asking how it differs from variational inference and what advantages it offers. While the comment implies that the authors should provide a comparison or explanation of their approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address these questions but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about how Algorithm 1 differs from variational inference and what advantages it offers. This provides clear guidance on what needs to be addressed in the paper, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about Algorithm 1, specifically asking how it differs from variational inference and what advantages it offers. However, the comment does not provide any supporting evidence, reasoning, or references to justify these questions. Without additional context or explanation, the authors may find it challenging to address these questions effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about Algorithm 1, specifically asking how it differs from variational inference and what advantages it offers. This inquiry prompts the authors to clarify their approach and its benefits, which could lead to a more comprehensive understanding of their method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these questions or improve their explanation. While it identifies an area for improvement, it does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the entailment exercise lacks basic details, making it difficult to assess the efficacy of the technique. It provides a clear action for the authors to either remove the exercise from the paper or provide more empirical and analyzed information. The comment is specific and direct, offering concrete guidance on how to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"entailment exercise,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the exercise, namely that it lacks basic details, making it difficult to assess the efficacy of the technique. The comment provides a clear suggestion to either remove the exercise or provide more empirical and analyzed information. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the entailment exercise lacks basic details, making it difficult to assess the efficacy of the technique. However, the comment does not provide specific examples or details about what information is missing or how it would improve the assessment. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the missing details and their importance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the entailment exercise, noting that it lacks basic details, which makes it difficult to assess the efficacy of the technique. It provides a clear and actionable suggestion for improvement, recommending either removing the exercise or providing more empirical and analyzed information. This feedback is valuable as it directs the authors to a critical area that needs enhancement, offering a concrete path for improvement. However, the comment could be more helpful if it included specific examples of what details are missing or how they could be incorporated. Overall, the comment is mostly helpful, as it effectively guides the authors toward enhancing the clarity and effectiveness of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with the mathematical expression of the Gaussian distribution in lines 225 and 227, labeling it as ambiguous. However, it does not provide any guidance or suggestions on how to clarify or improve the expression. The authors are left without a clear understanding of what changes are needed to address the ambiguity. Without explicit instructions or examples, the comment lacks actionability, leaving the authors uncertain about how to proceed. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 225 and line 227,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the mathematical expression of the Gaussian distribution, indicating that it is ambiguous. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the mathematical expression of the Gaussian distribution in lines 225 and 227 is ambiguous. However, the comment does not provide any explanation or justification for why the expression is considered ambiguous, nor does it offer specific examples or references to support the claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the mathematical expression of the Gaussian distribution in lines 225 and 227, labeling it as ambiguous. This feedback is clear and actionable, as it directs the authors to a precise part of the paper where the ambiguity exists. By pointing out this issue, the comment provides the authors with a clear area for improvement, allowing them to clarify the mathematical expression and enhance the clarity of their work. However, the comment could be more helpful if it offered suggestions on how to resolve the ambiguity or provided examples of clearer expressions. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the current testing is insufficient because it only uses specific tokens and implies that additional types of responses should be considered. However, it does not provide explicit guidance on which additional types of responses should be included or how to implement them. The action is implicit and somewhat vague, as the authors can infer that they need to expand their testing but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the current testing is insufficient because it only uses specific tokens and implies that additional types of responses should be considered. However, it does not specify which part of the paper this critique is based on, such as a particular section or experiment. This makes it difficult for the authors to pinpoint the exact area that needs attention. The comment is specific in its suggestion to consider additional types of responses, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the current testing is insufficient because it only uses specific tokens, implying that additional types of responses should be considered. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without further explanation or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the testing approach by suggesting that it is insufficient because it only uses specific tokens. It implies that additional types of responses should be considered, which is a valuable insight for the authors to explore. However, the comment lacks specificity and does not provide detailed guidance on which additional types of responses should be considered or how to incorporate them into the testing framework. While it highlights an area for improvement, the feedback could be more actionable and helpful if it included concrete suggestions or examples. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and detail.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the privacy protection capability of the paper, specifically questioning the effectiveness of using chatGPT for text paraphrasing and manipulating the temperature (T) for text privacy protection. However, it does not provide explicit guidance or suggestions on how the authors might improve the privacy protection capability or address the issue. The comment implies that the current approach may not be sufficient, but it lacks concrete actions or detailed advice for the authors to follow. As a result, the authors are left without a clear understanding of what steps to take to address the concern. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the privacy protection capability of the paper, specifically questioning the effectiveness of using chatGPT for text paraphrasing and manipulating the temperature (T) for text privacy protection. However, it does not specify which part of the paper discusses these methods, making it weakly grounded. The comment is specific in detailing the issue with the privacy protection capability, but without clear references to specific sections or examples, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the privacy protection capability is insufficient, specifically questioning the effectiveness of using chatGPT for text paraphrasing and manipulating the temperature (T) for text privacy protection. The comment provides a logical reasoning by pointing out that relying solely on these methods may not effectively achieve text sanitization. However, it lacks specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is somewhat verifiable, as it provides a logical basis but requires more detailed evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific concern regarding the privacy protection capability of the paper, questioning the effectiveness of using chatGPT for text paraphrasing and manipulating the temperature (T) for text privacy protection. It highlights a potential weakness in the approach, suggesting that merely relying on these methods may not adequately achieve text sanitization. However, the comment lacks actionable suggestions or guidance on how the authors might improve the privacy protection capability or address the issue. While it points out a critical area for improvement, it does not provide detailed advice or examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the approach described in the manuscript is not significant enough, particularly regarding the use of word embeddings to define the weight of each lexicon term. However, it does not provide any explicit or implicit suggestions for improvement. There is no guidance on how the authors might enhance the novelty of their approach or what specific aspects could be modified to increase its significance. Without actionable advice or concrete steps, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the manuscript discusses the approach in sentimental analysis or the use of word embeddings. Without explicit references to sections or figures, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity as it does not detail what aspects of the novelty are insufficient or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the approach described in the manuscript is not significant enough, particularly regarding the use of word embeddings to define the weight of each lexicon term. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or comparisons to other works, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment acknowledges that the manuscript describes an approach in sentimental analysis using a relatively new method involving word embeddings to define the weight of each lexicon term. However, it criticizes the novelty of this approach as not being significant enough. While the comment identifies a potential weakness in the manuscript, it lacks specific suggestions or guidance on how the authors might enhance the novelty or address this critique. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper would benefit from comparing its method to non-NeRF methods on the mentioned tasks. This comparison is proposed to help readers understand the proposed method's advantages relative to conventional methods. While the comment implies that the authors should include this comparison, it does not explicitly instruct them to do so. The action is concrete in terms of what needs to be done, but it is implicit in the sense that the authors need to infer the specific steps to take. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from comparing its method to non-NeRF methods on the mentioned tasks. However, it does not specify which tasks or sections of the paper this comparison should be made in, making it weakly grounded. The comment is specific in suggesting that such a comparison would help readers understand the proposed method\\'s advantages relative to conventional methods. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from comparing its method to non-NeRF methods on the mentioned tasks. This claim is somewhat verifiable as it provides a logical reasoning for why such a comparison would be beneficial, namely to help readers understand the proposed method\\'s advantages relative to conventional methods. However, the comment lacks specific examples or references to non-NeRF methods that could be used for comparison, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from comparing its method to non-NeRF methods on the mentioned tasks. This comparison is proposed to help readers better understand how the proposed method stands in relation to conventional methods and the extent of its advantages. While the comment identifies a potential area for improvement, it does not provide specific guidance on which non-NeRF methods should be compared or how to conduct the comparison. This lack of detail limits the comment\\'s usefulness, as it does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it provides a general direction for improvement but lacks specificity and depth.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential confusion in the paper regarding the categorization of tasks as NLU (Natural Language Understanding) or syntactic tasks. It mentions a rich literature on morphological and syntactic probing tasks, such as LINSPECTOR, and questions whether some lower-level tasks are considered NLU or syntactic tasks. However, the comment does not provide explicit guidance on how the authors should address this issue or clarify the terminology in their paper. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the categorization of tasks in their paper. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the page numbers \"178:181,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether some lower-level tasks are considered NLU or syntactic tasks, providing a clear direction for the authors to clarify their terminology. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the categorization of tasks as NLU (Natural Language Understanding) or syntactic tasks, referencing a rich literature on morphological and syntactic probing tasks, such as LINSPECTOR. However, the comment does not provide specific examples or detailed reasoning to support the claim that the tasks are not clearly categorized. This lack of detailed evidence or references makes the claim somewhat verifiable, as the authors would need to delve deeper into the literature to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential confusion in the paper regarding the categorization of tasks as NLU (Natural Language Understanding) or syntactic tasks. It references a rich literature on morphological and syntactic probing tasks, such as LINSPECTOR, which could help the authors clarify their terminology. However, the comment does not provide specific guidance on how to address this issue or suggest ways to clarify the categorization of tasks in the paper. While it highlights an area for improvement, the feedback lacks depth and actionable suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should discuss the relationship of their idea to traditional attempts in computer vision, specifically regarding long-term motion trajectories. While the comment implies that this discussion would enhance the theoretical and academic value of their approach, it does not provide explicit guidance on how to incorporate this discussion or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the relationship to traditional ideas and how it strengthens their contribution. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"long-term motion trajectories\" and \"Eulerian vs. Lagrangian views,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests that the authors should discuss the relationship of their idea to traditional attempts in computer vision, such as motion segmentation, and provides a reference to support this suggestion. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that using long-term motion trajectories is a traditional idea in computer vision, particularly for motion segmentation. It supports this claim by referencing a specific paper, \"Motion trajectory segmentation via minimum cost multicuts\" by Keuper et al. (2015), which is a relevant external reference. This provides a clear and logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how the authors\\' approach relates to traditional ideas, which would further enhance the verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges that using long-term motion trajectories is a traditional idea in computer vision, particularly for motion segmentation. It suggests that while the introduction of Eulerian vs. Lagrangian views is a nice addition, the authors could further enhance their work by discussing the relationship of their idea to these traditional attempts. This feedback is somewhat helpful as it provides a direction for the authors to consider, suggesting a way to strengthen the theoretical and academic value of their approach. However, the comment could be more helpful if it offered specific guidance on how to integrate this discussion or what aspects to focus on. Overall, the feedback is somewhat helpful, as it identifies a potential area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the problem formalization section, specifically regarding the description of task types addressed on graph data. It notes that the section focuses more on formalizing challenges rather than conveying the authors' task objectives. While the comment identifies an issue, it does not provide explicit guidance on how to address it or suggest specific changes to improve clarity. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the task objectives but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"problem formalization section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the section, namely that it lacks a clear description of the specific task types addressed on graph data and focuses more on formalizing challenges. The comment further highlights the inconsistency between the section\\'s purpose and its content. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the problem formalization section lacks a clear description of specific task types addressed on graph data and instead focuses on formalizing challenges. The comment suggests that this makes the purpose of the section unclear and inconsistent with its intended purpose. However, the review does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the exact issues based on the general critique, which could be challenging. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the problem formalization section, noting that it lacks a clear description of the specific task types addressed on graph data. It points out that the section focuses more on formalizing challenges rather than conveying the authors\\' task objectives, making it inconsistent with its intended purpose. This feedback is clear and actionable, as it directs the authors to clarify the task objectives and ensure that the section aligns with its purpose. However, the comment could be more helpful if it provided specific suggestions on how to improve the clarity or structure of the section. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the clarity and coherence of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a lack of an ablation study on training techniques, specifically mentioning Informative Prior Initialization (IPI) and v-prediction. It suggests that an ablation study would help assess the specific impact of these techniques and facilitate direct comparisons with other models. This feedback provides a clear and concrete action for the authors to take, which is to conduct an ablation study on the training techniques introduced in the paper. The comment is explicit and provides specific guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of an ablation study on training techniques, such as Informative Prior Initialization (IPI) and v-prediction. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing, namely an ablation study to assess the impact of these techniques and to compare YOSO\\'s performance with other models. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the lack of an ablation study on training techniques, specifically Informative Prior Initialization (IPI) and v-prediction, makes it difficult to assess their impact and compare YOSO\\'s performance with other models. The comment provides a logical reasoning by explaining the importance of an ablation study for evaluating the specific contributions of these techniques. However, it lacks specific examples or references to other models that could leverage these techniques, which would strengthen the claim. Therefore, the comment is mostly verifiable, as it provides a clear rationale but could be further supported with additional details or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of an ablation study on training techniques, specifically Informative Prior Initialization (IPI) and v-prediction. It highlights the importance of such a study to assess the specific impact of these techniques and to compare YOSO\\'s performance with other models that might leverage these methods. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by conducting an ablation study. However, the comment could be more helpful if it suggested specific techniques or models to include in the ablation study or offered guidance on how to structure the study. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies two issues: the limited content of the paper and redundant descriptions. It provides a specific example of redundant descriptions, pointing out that two paragraphs from line 229 to line 272 repeat information already covered in the introduction. The reviewer also suggests conducting a small-scale validation experiment to address the lack of domain knowledge in LLMs for specific tasks. While the comment highlights areas for improvement, it does not provide detailed guidance on how to conduct the suggested experiment or how to address the redundancy. The action is mostly implicit and somewhat vague, as the authors know they need to address these issues but may not be entirely sure of the exact steps to take. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific paragraphs (from line 229 to line 272) where redundant descriptions are found, allowing the authors to accurately identify the parts of the paper being addressed. It also provides a clear suggestion to conduct a small-scale validation experiment to address the lack of domain knowledge in LLMs for specific tasks. This specificity helps the authors understand what needs to be improved and how to address it. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper has limited content and redundant descriptions, specifically pointing out that two paragraphs from line 229 to line 272 repeat information already covered in the introduction. This claim is somewhat verifiable as it provides a specific example of redundancy, allowing the authors to identify and address the issue. However, the comment could be strengthened by providing more detailed reasoning or examples of other redundant sections. Additionally, the suggestion to conduct a small-scale validation experiment is a logical step to address the lack of domain knowledge in LLMs, but it lacks specific guidance or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper: the limited content and redundant descriptions. It provides a specific example of redundant descriptions, pointing out that two paragraphs from line 229 to line 272 repeat information already covered in the introduction. This feedback is actionable as it directs the authors to remove redundant content and improve the clarity of their work. Additionally, the comment suggests conducting a small-scale validation experiment to address the lack of domain knowledge in LLMs for specific tasks, which is a constructive suggestion for enhancing the paper. However, the comment could be more helpful if it offered specific guidance on how to conduct the validation experiment or provided examples of datasets that could be used. Overall, the comment is mostly helpful as it provides clear and actionable feedback, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to \"re-write this section to make its connections with the proposed method clearer.\" This provides a direct and clear action for the authors to take, ensuring they understand exactly what needs to be done to improve their draft. The feedback is specific and concrete, offering a clear path forward for the authors. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the \"theoretical contributions\" section, allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it clearly specifies the issue with the theoretical contributions, namely that they seem too abstract and unclear in their connection to the proposed method. The comment provides a clear suggestion to re-write this section to make its connections clearer, which further enhances its specificity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical contributions are too abstract and unclear in their connection to the proposed method, specifically mentioning the use of segregated feature vectors for backdoored vs. clean data. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The lack of concrete evidence or references limits the verifiability of the claim, rendering it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the theoretical contributions of the paper, noting that they seem too abstract and unclear in their connection to the proposed method. It highlights the use of segregated feature vectors for backdoored vs. clean data as being too artificial and not directly related to EigenGuard. The comment provides a clear and actionable suggestion to re-write the section to make its connections with the proposed method clearer. This feedback is valuable as it directs the authors to a critical area that needs clarification, offering a concrete step to improve the draft. However, the comment could be more helpful if it provided additional guidance on how to make these connections clearer. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of whether the code will be released, specifically mentioning that the GCN implementation might be difficult to reproduce without the original code. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they should clarify their stance on code release or provide additional details to facilitate reproducibility. However, the comment lacks concrete steps or suggestions on how to improve the clarity or provide the necessary information. Therefore, the action is implicit and somewhat vague, making this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the clarity of whether the code will be released, specifically mentioning the GCN implementation. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the GCN implementation is discussed. The comment is specific in its concern about the reproducibility of the GCN implementation without the original code, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of whether the code will be released, specifically regarding the GCN implementation. The comment acknowledges that the author\\'s descriptions are detailed and that there is more information in the supplement, but it still expresses uncertainty about reproducibility. However, the comment does not provide specific examples or detailed reasoning to support the claim that the code is hard to reproduce. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to provide additional context or evidence to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the clarity of whether the code will be released, specifically regarding the GCN implementation. It acknowledges that the author\\'s descriptions are detailed and that there is additional information in the supplement, but still expresses uncertainty about reproducibility. This feedback is somewhat helpful as it identifies a potential issue with the paper\\'s reproducibility, but it lacks specific suggestions or guidance on how the authors might address this concern. To be more helpful, the comment could provide recommendations on how to clarify the code release or suggest ways to enhance reproducibility. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the use of second-order Taylor expansions in Equations (9) and (10) and asks why the differential functions themselves are not used. This comment implies that the authors should consider using the differential functions instead of the Taylor expansions, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their choice of method. However, the comment provides a clear direction for the authors to explore alternative approaches, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equations (9) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the use of second-order Taylor expansions and asks why the differential functions themselves are not used. This provides clear guidance on what aspect of the paper needs to be addressed or clarified. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of second-order Taylor expansions in Equations (9) and (10) and asks why the differential functions themselves are not used. This is a logical question that prompts the authors to justify their methodological choice. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that using differential functions would be preferable. Without additional context or justification, the authors may find it challenging to address the question effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the use of second-order Taylor expansions in Equations (9) and (10, and asks why the differential functions themselves are not used. This feedback is somewhat helpful as it prompts the authors to consider an alternative approach and provides a clear direction for potential improvement. However, the comment lacks depth and does not offer any suggestions or rationale for why the differential functions might be preferable. To be more helpful, the comment could include a brief explanation or reference to support the suggestion. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a missing aspect in Table 3, specifically the recall on lemmas/forms seen in training for the en-cs BPE to character results. It provides references to relevant literature, which could guide the authors in understanding the importance of this aspect and how to address it. However, the comment does not provide specific instructions on how to incorporate this information into the table or the paper. While the authors are directed to a relevant area for improvement, the lack of detailed guidance on implementation makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the missing information, namely the recall on lemmas/forms seen in training for the en-cs BPE to character results. The inclusion of references to relevant literature further supports the specificity of the comment. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the recall on lemmas/forms seen in training is missing from Table 3. It supports this claim by referencing relevant literature, such as [1] Pourdamghani, Nima, and Kevin Knight. \"Deciphering related languages.\" EMNLP 2017, [2] He, Junxian, et al. \"A Probabilistic Formulation of Unsupervised Text Style Transfer.\" ICLR 2019, and [3] Ryskina, Maria, et al. \"Comparative Error Analysis in Neural and Finite-state Models for Unsupervised Character-level Transduction.\" SIGMORPHON 2021. These references provide a logical basis for the claim, as they relate to the topic of language processing and error analysis, which is relevant to the missing recall information. However, the comment could be strengthened by providing more detailed reasoning or examples of how these references support the claim. Therefore, the comment is mostly verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 3, noting that the recall on lemmas/forms seen in training is missing for the en-cs BPE to character results. It provides references to relevant literature, such as [1] Pourdamghani, Nima, and Kevin Knight. \"Deciphering related languages.\" EMNLP 2017, [2] He, Junxian, et al. \"A Probabilistic Formulation of Unsupervised Text Style Transfer.\" ICLR 2019, and [3] Ryskina, Maria, et al. \"Comparative Error Analysis in Neural and Finite-state Models for Unsupervised Character-level Transduction.\" SIGMORPHON 2021, which could guide the authors in understanding the importance of this aspect and how to address it. However, the comment could be more helpful if it provided specific guidance on how to incorporate this information into the table or the paper. Despite this, the feedback is mostly helpful as it directs the authors to a critical area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of the proposed method on the MLSC setup, given the claim that better word-alignment improves many-to-many translation. It points out that Section 4 touches on this point but lacks an explanation. While the comment implies that the authors should provide an explanation for the lack of impact, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the lack of explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the claim that better word-alignment improves many-to-many translation and noting that the proposed method has no impact on the MLSC setup. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that better word-alignment improves many-to-many translation, given that the proposed method has no impact on the MLSC setup. It suggests that Section 4 touches on this point but lacks an explanation. While the comment raises a valid concern, it does not provide specific evidence or references to support the claim that better word-alignment should have an impact on the MLSC setup. The lack of detailed reasoning or examples makes the claim somewhat verifiable, as the authors would need to provide additional context or evidence to fully address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the impact of the proposed method on the MLSC setup, given the claim that better word-alignment improves many-to-many translation. It points out that Section 4 touches on this point but lacks an explanation, which is a clear area for improvement. By highlighting this gap, the comment provides the authors with a specific direction for enhancing their draft by addressing the lack of explanation. However, the comment could be more helpful if it offered suggestions on how to provide this explanation or what specific aspects of the impact should be discussed. Overall, the comment is mostly helpful as it identifies a critical area for improvement and guides the authors toward a more comprehensive explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the method, noting that it requires pre-collected offline datasets and cannot be applied in an online setting where policies interact with the environment. This comment identifies a potential issue with the method\\'s applicability but does not provide explicit guidance on how the authors might address this limitation. The action is implicit, as the authors need to infer that they should consider expanding the method\\'s applicability to online settings or discuss the offline assumption in more detail. However, the comment lacks concrete suggestions on how to achieve this, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limitation of the method being restricted to an offline setting, implying that it cannot be applied in an online setting where policies interact with the environment. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the offline assumption and its impact on applicability. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is restricted to an offline setting and cannot be applied in an online setting where policies interact with the environment. This claim is somewhat verifiable as it highlights a potential limitation of the method, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The comment does not provide references or detailed explanations of how the offline assumption limits applicability, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant limitation of the method, specifically that it is restricted to an offline setting and cannot be applied in an online setting where policies interact with the environment. This is a critical observation that highlights a potential drawback of the method's applicability. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or expand the method's applicability to online settings. While it points out a key area for improvement, the lack of actionable advice or detailed feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight into a critical issue but lacks depth and specificity in its suggestions.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the evaluation of the learned representation is insufficient because it is only evaluated in the linear evaluation setting. It implies that the authors should consider other downstream tasks, such as fine-tuning, detection, and segmentation, as reported in the literature. While the comment identifies a potential area for improvement, it does not explicitly instruct the authors to conduct these evaluations. The action is implicit and somewhat vague, as the authors need to infer that they should expand their evaluation to include these additional tasks. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluation of the learned representation, specifically mentioning the linear evaluation setting. It suggests that the evaluation is insufficient and implies that other downstream tasks, such as fine-tuning, detection, and segmentation, should be considered. However, it does not specify which part of the paper discusses the evaluation of the learned representation, making it weakly grounded. The comment is specific in suggesting alternative evaluation methods, but without explicit references to sections or specific parts of the paper, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation of the learned representation is insufficient because it is only evaluated in the linear evaluation setting. The reviewer suggests that other downstream tasks, such as fine-tuning, detection, and segmentation, should be considered. While the comment provides a logical reasoning for the need to evaluate the representation in multiple settings, it lacks specific references or examples from the literature to support the claim. This makes the claim somewhat verifiable, as the authors would need to conduct additional research to fully understand the basis of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation of the learned representation, noting that it is only assessed in the linear evaluation setting. It suggests that this is insufficient and recommends considering other downstream tasks, such as fine-tuning, detection, and segmentation, as reported in the literature. This feedback is clear and actionable, providing the authors with a specific direction for improving their evaluation methodology. By suggesting additional tasks, the comment offers a concrete way for the authors to enhance the comprehensiveness and robustness of their evaluation. However, it could be more helpful if it included specific examples or references to guide the authors in implementing these suggestions. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the novelty of the paper is low, as stage-wise and progressive training methods have been widely used for a long time. However, it does not provide any specific suggestions or guidance on how the authors could enhance the novelty of their work. The comment lacks actionable details, such as recommending specific ways to innovate or differentiate the approach from existing methods. Without explicit or implicit guidance, the authors are left without a clear understanding of what changes they should make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the paper, specifically mentioning the use of stage-wise and progressive training methods, which have been widely used for a long time. However, it does not specify which part of the paper discusses these methods or how they are used, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the lack of novelty but lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the paper is low, citing that stage-wise and progressive training methods have been widely used for a long time. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the novelty of the paper, stating that stage-wise and progressive training methods have been widely used for a long time and do not exhibit anything novel in the way they are used. However, the comment lacks specific examples or suggestions on how the authors could enhance the novelty of their work. Without actionable feedback or guidance, the authors are left without a clear understanding of what changes they should make to improve their draft. The comment identifies a potential weakness but does not provide sufficient detail or direction for improvement, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the applicability and generality of the analysis, specifically asking how it extends to more general cases, whether it can handle more general Markov chains, and what happens if there is FFN and nonlinearity on top of the attention layer. While the questions imply that the authors should consider these aspects, they do not provide explicit instructions or suggestions on how to address them. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information or examples, but they are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the applicability and generality of the analysis, specifically asking how it extends to more general cases, whether it can handle more general Markov chains, and what happens if there is FFN and nonlinearity on top of the attention layer. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its questioning of the analysis\\'s scope and applicability but lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification on the applicability and generality of the analysis, specifically asking about its extension to more general cases, handling of more general Markov chains, and the impact of FFN and nonlinearity on top of the attention layer. These questions are factual and do not express opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the applicability and generality of the analysis, specifically asking how it extends to more general cases, whether it can handle more general Markov chains, and what happens if there is FFN and nonlinearity on top of the attention layer. These questions prompt the authors to consider the broader implications and limitations of their work, which is valuable for improving the draft. However, the comment does not provide specific suggestions or guidance on how to address these questions, leaving the authors with a general direction but without detailed actionable steps. Therefore, the comment is somewhat helpful, as it identifies areas for improvement but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the clarity of the paper regarding the use of a Fine state automaton in reference [19]. It suggests that the authors should clarify whether [19] uses the same Fine state automaton or if there is a difference. However, the comment does not explicitly instruct the authors to make this clarification or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the reference but are not given explicit instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.1\" and \"line 57,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether reference [19] uses the same Fine state automaton or if there is a difference, providing clear guidance on what needs to be clarified. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the paper regarding the use of a Fine state automaton in reference [19], specifically in section 3.1 and line 57. The comment raises a logical concern about the consistency of the reference with the content, but it does not provide any additional information or evidence to support the claim. Without further context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the paper regarding the use of a Fine state automaton in reference [19]. It points out that while the authors discuss [19], it is not clear in section 3.1 whether [19] uses the same Fine state automaton or if there is a difference. This feedback is somewhat helpful as it highlights a specific area where the paper may lack clarity, prompting the authors to clarify this point. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered additional context to aid the authors in improving the clarity of their discussion. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the auto_weight scheme in Algorithm 1, noting that it requires intermediate gradients for each domain, which might consume a lot of memory. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue, such as suggesting ways to optimize memory usage or proposing alternative methods. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the auto_weight scheme, noting that it requires intermediate gradients for each domain, which might consume a lot of memory. The comment provides references to external works, which further supports the specificity of the feedback. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the auto_weight scheme in Algorithm 1 requires intermediate gradients for each domain, which might consume a lot of memory. The comment supports this claim by referencing two external works: \"FedGP: Buffer-based Gradient Projection for Continual Federated Learning\" by Dai et al. (2023) and \"FLamby: Datasets and Benchmarks for Cross-Silo Federated Learning in Realistic Healthcare Settings\" by Terrail et al. (2022). These references provide a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how these references support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the auto_weight scheme in Algorithm 1, noting that it requires intermediate gradients for each domain, which might consume a lot of memory. This is a specific and relevant observation that could impact the practicality and efficiency of the proposed method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as proposing alternative methods or optimizations to reduce memory usage. While it highlights a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a significant concern but does not offer a clear path for resolution.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper, specifically that the backbone is constrained to a double LSTM while popular transformers are not involved. It also mentions that pre-trained language models are not covered and that the application to more extensive model structures is a concern. The comment suggests that the limitations mentioned in Section 6 are not sufficient, implying that the authors should expand on these limitations or address the concerns raised. However, the comment does not provide explicit guidance on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed information on the limitations and potential applications, but they are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of a double LSTM as the backbone and the lack of involvement of popular transformers, as well as the limited coverage of pre-trained language models. It also mentions the application to more extensive model structures as a potential concern. The authors can infer that this comment relates to the methodology or experimental setup sections, but it does not explicitly mention these sections, making it weakly grounded. The comment is specific in detailing the limitations and concerns regarding the model structures and their applications. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the backbone is constrained to a double LSTM, while popular transformers are not involved, and that pre-trained language models are not covered. It also mentions that the application to more extensive model structures is a concern. The comment provides a logical reasoning by pointing out the limitations in the current approach, but it lacks specific examples or references to support the claim. While the authors can infer the potential issues, the comment could be strengthened with more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional support for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the paper's methodology, specifically the use of a double LSTM as the backbone while popular transformers are not involved. It also points out that pre-trained language models are not covered, which could be a concern for more extensive model structures. The comment acknowledges that limitations are mentioned in Section 6 but suggests that these are not sufficient. This feedback is somewhat helpful as it highlights a specific area for improvement and encourages the authors to expand on the limitations and potential applications. However, it could be more helpful if it provided specific suggestions or examples on how to address these limitations. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the paper for having limited contribution and novelty, stating that it combines existing techniques without adding significant value. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the contribution or novelty of the paper, nor are there suggestions for potential improvements or changes. As a result, the comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the paper for having limited contribution and novelty, stating that it combines existing techniques without adding significant value. However, it does not specify which part of the paper this critique is based on, such as a particular section or methodology. This makes it difficult for the authors to identify the exact area that needs improvement. Additionally, the comment lacks specificity in terms of what aspects of the paper are lacking in terms of novelty or contribution. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper has limited contribution and novelty, stating that it combines existing techniques without adding significant value. However, the comment does not provide specific examples or references to support this claim, such as comparing the proposed model to existing literature or explaining how the combination of techniques is not innovative. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the paper for having limited contribution and novelty, stating that it combines existing techniques without adding significant value. However, it does not provide specific examples or suggestions on how the authors could enhance the contribution or novelty of their work. Without actionable feedback or guidance, the comment lacks depth and does not offer a clear path for the authors to improve their draft. As a result, it is barely helpful, as it identifies a potential issue but does not provide sufficient detail or direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises an interesting comparison between using MSLR (Multi-Source Learning Rate) and directly tuning a late-fusion model with separate learning rates for each modality. It suggests exploring how this comparison would play out with a similar or less compute budget. While the comment implies that the authors should consider this comparison, it does not explicitly instruct them to conduct the comparison or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer the need for a comparison but may not know exactly how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"MSLR,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a comparison between using MSLR and directly tuning a late-fusion model with separate learning rates for each modality, providing a clear direction for potential improvement. The comment specifies what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the inefficiency of MSLR, suggesting that it requires knowing the unimodal optimal learning rates in advance, which necessitates resource expenditure on tuning unimodal models only to discard them. The comment further proposes a comparison with directly tuning a late-fusion model with separate learning rates for each modality, suggesting it could be done with a similar or less compute budget. While the comment provides a logical reasoning for the inefficiency of MSLR, it lacks specific examples or references to support the claim or the proposed comparison. This makes the claim somewhat verifiable, as it requires more detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential inefficiency in the MSLR approach, noting that it requires knowing the unimodal optimal learning rates in advance, which involves resource expenditure on tuning unimodal models only to discard them. The comment suggests a comparison with directly tuning a late-fusion model with separate learning rates for each modality, which could be done with a similar or less compute budget. This feedback is clear and actionable, as it provides a specific area for improvement and a potential alternative approach to consider. However, it could be more helpful if it included specific suggestions on how to conduct this comparison or what metrics to use. Overall, the comment is mostly helpful, as it offers valuable insights for the authors to consider in improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the ambiguity of the notation for L_{flow}(X) and suggests that L_{flow}(F) or L_{flow}(F,S) might be more appropriate to reflect the actual inputs. While the comment identifies a potential issue, it does not provide explicit guidance on how to resolve the ambiguity or which notation is preferred. The action is implicit and somewhat vague, as the authors need to infer that they should clarify or specify the notation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the notation for L_{flow}(X), specifically questioning the ambiguity and suggesting alternatives like L_{flow}(F) or L_{flow}(F,S). This provides clear guidance on what needs to be clarified or specified in the paper. However, it does not explicitly mention which part of the paper this notation is used in, making it weakly grounded. The comment is specific in detailing the issue with the notation, so it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the notation for L_{flow}(X), suggesting that L_{flow}(F) or L_{flow}(F,S) might be more appropriate. However, the comment does not provide any reasoning or evidence to support why these alternatives are preferred or how they might improve clarity. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the notation for L_{flow}(X), questioning its ambiguity and suggesting alternative notations like L_{flow}(F) or L_{flow}(F,S). This feedback is clear and actionable, as it directs the authors to clarify or specify the notation to improve the clarity and accuracy of their work. However, the comment could be more helpful if it provided additional context or examples of how the suggested notations might be used in the paper. Overall, the comment is mostly helpful as it guides the authors toward a specific improvement, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the novelty of the work by pointing out that 8-bit batch norm has been proposed before in literature. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of novelty or whether the authors should reconsider their approach. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the novelty of representing the input using 8 bits, referencing a previous work on 8-bit batch norm. However, it does not specify which part of the paper discusses this representation, making it weakly grounded. The comment is specific in questioning the novelty of the work and referencing a specific paper, but without clear grounding, the authors may struggle to identify the exact section being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty of the work by pointing out that 8-bit batch norm has been proposed before in literature, referencing a specific paper. This provides a clear and specific claim that is supported by an external reference, making the claim fully verifiable. The reference to a specific paper in the literature adds robustness to the argument, allowing the authors to understand the basis of the critique and address it effectively. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment raises a valid concern about the novelty of the work by pointing out that 8-bit batch norm has been proposed before in literature. This is a relevant observation that could impact the originality and contribution of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. While it highlights a potential weakness, it lacks actionable feedback, making it somewhat helpful. The authors are informed of a potential problem but are not given clear steps to resolve it, limiting the comment\\'s utility. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practical relevance of the proposed framework due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not provide any explicit or implicit actions for the authors to take in response to this concern. There is no guidance on how the authors might address this issue or improve the practical relevance of their framework. As a result, the comment lacks actionability and does not offer any direction for the authors to enhance their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the practical relevance of the proposed framework due to the dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not specify which part of the paper this concern relates to, nor does it provide specific details on how the framework might be improved or what aspects need to be addressed. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where to focus their revisions. Additionally, the comment lacks specificity regarding what needs to be addressed or how the authors might enhance the practical relevance of their framework. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, the comment lacks specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the practical relevance of the proposed framework, noting the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. While this observation is relevant, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or enhance the practical relevance of their framework. Without actionable feedback or detailed insights, the authors are left without a clear path for improvement. Therefore, the comment is rated as not helpful at all, as it lacks actionable feedback and does not contribute to the authors\\' understanding of how to enhance their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding an experiment to demonstrate the necessity of variable $X$ by calculating $M_{t}$ using only $C$ without $X$. This is an explicit action with clear guidance on what the authors should do to improve their draft. The comment provides a specific suggestion for an additional experiment, which gives the authors a concrete step to take. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding an experiment to demonstrate the necessity of variable $X$ by calculating $M_{t}$ using only $C$ without $X$. While it does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the experimental setup or methodology section, as it involves calculations and variables. The comment is specific in suggesting the addition of an experiment to test the necessity of $X$, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding an experiment to demonstrate the necessity of variable $X$ by calculating $M_{t}$ using only $C$ without $X$. This claim is somewhat verifiable as it provides a logical suggestion for an additional experiment to test the importance of $X$. However, the comment lacks specific reasoning or references to support why this experiment would be beneficial or how it would demonstrate the necessity of $X$. Providing more detailed justification or examples would strengthen the claim, making it more verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests adding an experiment to demonstrate the necessity of variable $X$ by calculating $M_{t}$ using only $C$ without $X$. This feedback is clear and actionable, as it provides a specific suggestion for an additional experiment that could enhance the paper by showing the importance of $X$. By following this advice, the authors can gain a deeper understanding of the role of $X$ and potentially improve the robustness of their results. However, the comment could be more helpful if it included a rationale for why this experiment is necessary or how it would impact the overall findings. Despite this, the suggestion is mostly helpful as it offers a concrete step for improvement. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point is a statement that provides an observation about the complexity of problems involving different types of neural networks. It does not offer any explicit or implicit actions for the authors to take in their draft. There is no suggestion for improvement, clarification, or additional information that the authors need to consider. As a result, the comment lacks any actionable guidance, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not refer to any specific part of the paper, making it difficult for the authors to determine which section or aspect of the paper is being addressed. Additionally, the comment is not specific, as it does not provide any details or examples about the complexity of problems involving MLPs compared to FBDDs and perceptrons. Without specific guidance or references, the authors are left without a clear understanding of what needs to be addressed or improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a statement of fact or observation, as it describes a perceived relationship between the complexity of problems involving different types of neural networks. It does not express an opinion, suggestion, or claim that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides an observation about the complexity of problems involving different types of neural networks, specifically noting that problems involving MLPs have higher complexity than those involving FBDDs and perceptrons. However, the comment lacks any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address this observation or how it could impact their work. Without specific advice or suggestions, the comment does not provide much value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should discuss the generalizability of their observations, specifically those presented in Figure 4. It also implies that various hyperparameters, such as optimization algorithms, weight initialization methods, batch size, learning rate, and scheduling, could influence implicit biases in the algorithm, affecting neural representations, geometric metrics, and learning stages. While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues or which specific aspects of generalizability should be discussed. The action is implicit and somewhat vague, as the authors can infer that they need to discuss generalizability but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests discussing the generalizability of observations, specifically those in Figure 4, and mentions various hyperparameters that could influence implicit biases in the algorithm. While it does not explicitly mention a specific section of the paper, the reference to Figure 4 provides a clear indication of where the discussion should be focused. The comment is specific in detailing the aspects that need to be addressed, such as the influence of hyperparameters on neural representations, geometric metrics, and learning stages. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the generalizability of the observations, particularly those in Figure 4, should be discussed. It highlights various hyperparameters that could influence implicit biases in the algorithm, affecting neural representations, geometric metrics, and learning stages. While the comment provides a logical reasoning about the potential impact of hyperparameters, it lacks specific examples or references to support the claim. This makes the claim somewhat verifiable, as the authors would need to conduct further analysis to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that the authors should discuss the generalizability of their observations, particularly those presented in Figure 4. It highlights the potential impact of various hyperparameters, such as optimization algorithms, weight initialization methods, batch size, learning rate, and scheduling, on implicit biases in the algorithm. This feedback is clear and actionable, as it directs the authors to consider the broader implications of their findings and how they might be influenced by different experimental settings. However, the comment could be more helpful if it provided specific examples or guidance on how to address these issues. Overall, the comment is mostly helpful, as it offers a valuable direction for improving the draft, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the paper\\'s lack of organization and the use of non-standard terminology. It specifically mentions the term \"semi-honst\" in section 4, suggesting that the correct term should be \"honest-but-curious.\" However, the comment does not provide explicit guidance on how to improve the organization of the paper or suggest alternative terminology. The action is implicit and somewhat vague, as the authors are left to infer that they need to reorganize their paper and use standard terminology. While the comment identifies specific issues, it lacks concrete steps for the authors to take, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4\" and the term \"semi-honst,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the use of non-standard terminology and suggests a correction, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not well-organized and uses non-standard terminology, specifically pointing out the term \"semi-honst\" in section 4. The reviewer suggests that the correct term should be \"honest-but-curious,\" which is a common term in the field. This claim is somewhat verifiable as it provides a specific example of the non-standard terminology and suggests a correction. However, the comment lacks detailed reasoning or references to support the claim about the paper\\'s organization, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two issues with the paper: its lack of organization and the use of non-standard terminology. It specifically points out the term \"semi-honst\" in section 4, suggesting that the correct term should be \"honest-but-curious.\" This feedback is somewhat helpful as it highlights areas for improvement, such as ensuring the paper is well-organized and using standard terminology. However, the comment could be more helpful if it provided additional guidance on how to improve the organization or suggested alternative terminology for other non-standard terms used in the paper. Overall, the comment offers some direction but lacks depth and specificity, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly lists several experimental details that are missing from the paper, specifically asking for information about the optimizer, initialization, and PPO-zero. This provides clear and direct actions for the authors to take, as they know exactly what details need to be included in their draft. The comment is explicit and concrete, offering a straightforward path for the authors to improve their paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lots of experimental details,\" which allows the authors to identify the part of the paper being addressed. It is also specific because it lists three specific details that are missing: the optimizer, initialization, and PPO-zero. This provides clear guidance on what needs to be addressed in the experimental section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of questions asking for specific details about the experimental setup, such as the optimizer, initialization, and PPO-zero. These questions are factual and do not express opinions or judgments, making them purely descriptive. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a significant gap in the experimental details of the paper, specifically asking for clarification on the optimizer, initialization, and PPO-zero. This feedback is clear and actionable, as it directly points out missing information that the authors need to include to enhance the comprehensiveness and transparency of their experimental setup. By addressing these questions, the authors can improve the clarity and reproducibility of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to present these details effectively. Overall, the comment is mostly helpful as it provides clear guidance on what needs to be improved, but it could be more comprehensive with additional suggestions or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need for a detailed comparison of the proposed method\\'s efficiency and complexity with existing works. It specifically suggests that a comparison in terms of total model parameter, FLOPs, and memory usage is necessary, particularly with and without the detector and LaVIT. While the comment implies that the authors should conduct this analysis, it does not provide explicit instructions on how to perform the comparison or what specific metrics to use. The action is implicit and somewhat vague, as the authors can infer the need for a detailed analysis but may not know exactly how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Efficiency and Complexity,\" indicating that it addresses the section of the paper discussing these aspects. It also specifies the components being discussed, such as the use of LaVIT and Eva-CLIP for image encoding, and the need for a detector in the Region Sampler. This provides clear guidance on what needs to be addressed in terms of efficiency analysis. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method requires multiple additional components compared to existing works, specifically mentioning LaVIT and Eva-CLIP for image encoding and a detector for prior information in the Region Sampler. The reviewer suggests that a detailed comparison of efficiency, including model parameters, FLOPs, and memory usage, is needed. While the claim highlights a potential area for improvement, it lacks specific examples or references to existing works that do not require these additional components. This makes the claim somewhat verifiable, as it provides a general direction for improvement but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method, specifically noting that it requires multiple additional components compared to existing works. It suggests that a detailed comparison of efficiency, including model parameters, FLOPs, and memory usage, is necessary to better understand the method\\'s complexity. This feedback is clear and actionable, as it provides a specific area for improvement and suggests a concrete analysis that the authors should conduct. However, the comment could be more helpful if it offered guidance on how to conduct this analysis or provided examples of existing works for comparison. Overall, the comment is mostly helpful, as it directs the authors to a critical area that needs further exploration, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the paper for claiming that extrapolation error is a major issue in Multi-Agent Reinforcement Learning (MARL) without providing evidence to support this claim. It also questions the relevance of the proposed techniques to addressing extrapolation error, as they are described as methods for bias/variance reduction. The comment highlights a lack of evidence that the proposed method mitigates extrapolation error, which is crucial for better performance. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide evidence and clarify the relevance of their methods to extrapolation error. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the claim that extrapolation error is a major issue in MARL and questions the evidence provided to support this claim. It also critiques the relevance of the proposed techniques to addressing extrapolation error, noting that they are described as methods for bias/variance reduction. However, the comment does not specify which part of the paper makes this claim or where the proposed techniques are discussed, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in its critique, it lacks grounding, as it does not clearly identify the sections or parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s assertion about extrapolation error being a major issue in MARL lacks evidence. It further questions the relevance of the proposed techniques to addressing extrapolation error, as they are described as methods for bias/variance reduction. The comment highlights a gap in the paper\\'s argumentation and evidence, which is a valid critique. However, it does not provide specific examples or references to support the claim that the proposed methods do not address extrapolation error. This makes the claim somewhat verifiable, as the authors would need to provide additional evidence or clarification to fully address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the paper's claim that extrapolation error is a major problem in Multi-Agent Reinforcement Learning (MARL). It points out that the authors do not provide evidence to support this claim and questions the relevance of the proposed techniques to addressing extrapolation error. This feedback is valuable as it highlights a significant gap in the paper's argumentation and suggests that the authors need to provide evidence or clarify the relationship between their methods and extrapolation error. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of evidence that could be used to support the claim. Overall, the comment is somewhat helpful as it directs the authors' attention to a critical area for improvement but lacks detailed guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should include detailed on-device results across ablation and comparison studies to substantiate claims about SCHEME\\'s efficiency over conventional FFNs. It also specifies the need for details on benchmark configurations, hardware, and input shapes to ensure fair comparisons. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 4 and 8,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need for detailed on-device results across ablation and comparison studies, as well as details on benchmark configurations, hardware, and input shapes to ensure fair comparisons. This provides clear guidance on how to improve the paper. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that SCHEME shows theoretical complexity advantages but lacks detailed on-device efficiency analysis. It suggests that including detailed on-device results across ablation and comparison studies would substantiate claims about SCHEME\\'s efficiency over conventional FFNs. The comment provides a logical reasoning by highlighting the need for detailed analysis to support the claims, but it does not include specific examples or references to support the claim about the theoretical complexity advantages. Therefore, the comment is somewhat verifiable, as it provides a clear direction for improvement but lacks detailed evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the on-device efficiency of SCHEME, noting that while it shows theoretical complexity advantages, only limited throughput comparisons are presented. It suggests that including detailed on-device results across ablation and comparison studies would substantiate claims about SCHEME\\'s efficiency over conventional FFNs. Additionally, the comment emphasizes the need for details on benchmark configurations, hardware, and input shapes to ensure fair comparisons. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance the comprehensiveness and rigor of their analysis. By addressing these points, the authors can strengthen their argument and improve the overall quality of their draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential confusion with Long Short Term Memory (LSTM). However, it does not provide explicit guidance on what alternative name should be considered or how the authors should proceed with the name change. The action is implicit and somewhat vague, as the authors are left to infer that they should rename the strategy but without specific suggestions on what the new name should be. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential confusion with Long Short Term Memory (LSTM). However, it does not specify which part of the paper this suggestion pertains to, such as the introduction, methodology, or results section. Without explicit references to these sections, the authors may find it challenging to identify where the name change should be made. The comment is specific in its suggestion to reconsider the name but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the name \"LongShortTerm Strategy\" may be confusing due to its similarity to \"Long Short Term Memory (LSTM).\" However, the comment does not provide any further reasoning or evidence to support why this similarity is problematic or how it might mislead readers. Without additional context or examples, the claim remains vague and lacks sufficient justification. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the name \"LongShortTerm Strategy\" may be confusing due to its similarity to \"Long Short Term Memory (LSTM),\" which could lead to incorrect guidance. This feedback is somewhat helpful as it identifies a potential issue with the naming of the strategy, prompting the authors to reconsider the name to avoid confusion. However, the comment lacks specific suggestions or alternatives for a new name, which would make it more actionable and helpful. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the proposed method does not perform well in both robustness and fidelity, as evidenced by the experimental results. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the method or what specific changes should be made to enhance its performance. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"the experiments results\" but does not specify which experiments or sections of the paper these results are from. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed, rendering the comment weakly grounded. Additionally, the comment does not specify what aspects of robustness and fidelity are lacking or how the proposed method could be improved. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the proposed method is not the best performer in both robustness and fidelity, as evidenced by the experimental results. However, the comment does not provide any specific details or examples from the experimental results to support this claim. Without additional context or references to the experiments, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the proposed method does not perform well in both robustness and fidelity, as indicated by the experimental results. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might improve the method or address these issues. Without detailed guidance or examples, the authors are left without a clear understanding of what changes could be made to enhance their work. Therefore, the comment is not helpful at all, as it does not offer any actionable insights for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the paper regarding the motivation and logical connection between the concepts of isometry, OT (optimal transport), and disentanglement. The reviewer suggests that the authors need to explain more clearly how disentanglement connects to isometry and why OT is required for isometry. While the comment identifies areas that need clarification, it does not provide specific guidance on how to improve the explanation or what additional details should be included. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the concepts of \"isometry,\" \"OT,\" and \"disentanglement,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of clarity in the logical connection between these concepts, particularly the relationship between disentanglement and isometry, and the necessity of OT for isometry. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation and logical connection between isometry, OT, and disentanglement are not clear. It provides a logical explanation by questioning the necessity of OT for isometry, suggesting that an isometry mapping could be sufficient. However, the comment lacks specific examples or references to support the claim that the connection is not well-explained. While the reasoning is sound, the absence of detailed evidence or examples makes the claim somewhat verifiable. The authors would need to delve deeper into the paper to understand the exact issues and provide additional context to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of clarity in the motivation and logical connection between the concepts of isometry, OT, and disentanglement. It highlights the need for a clearer explanation of how disentanglement connects to isometry and why OT is required for isometry. The reviewer suggests that the authors should provide a more detailed explanation of these connections, which is a valuable and actionable piece of feedback. However, the comment could be more helpful if it offered specific suggestions on how to improve the explanation or provided examples of what additional details could be included. Overall, the comment is mostly helpful as it directs the authors to a critical area that needs improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the results on regular languages as great but questions their relevance to understanding real-world language models. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific aspects of the results should be improved or clarified. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the results on regular languages as great but questions their relevance to understanding real-world language models. However, it does not specify which part of the paper discusses these results or how they relate to real-world language models. The authors may infer that it relates to the results section, but the comment lacks full grounding as it does not explicitly mention a specific section or element of the paper. Additionally, the comment is not specific about what aspects of the results are lacking or how they could be improved to explain real-world language models. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the relevance of the results on regular languages to understanding real-world language models. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the results on regular languages as great but questions their relevance to understanding real-world language models. While it identifies a potential gap in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the relevance of their results. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their work. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the novelty of the paper, specifically asking for clarification on the differences between the current paper and the Venom paper. It does not provide any explicit or implicit actions for the authors to take, nor does it suggest any changes or improvements. The authors are left without guidance on how to address the issue or improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the novelty of the paper, specifically asking for clarification on the differences between the current paper and the Venom paper. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification on the differences between the papers, but without a clear reference to a specific section or part of the paper, the authors may find it challenging to address the issue directly. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the novelty of the paper, specifically asking for clarification on the differences between the current paper and the Venom paper. It does not make a claim or provide an opinion that requires verification. It is a factual question seeking information, which aligns with the label \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the novelty of the paper, specifically asking for clarification on the differences between the current paper and the Venom paper. It questions whether the V:N:M proposal was not already introduced in the Venom paper and how it differs from it. While the comment identifies a potential issue with the paper\\'s originality, it does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address the concern or enhance the novelty of their work. Therefore, the comment is barely helpful, as it highlights a potential issue but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the qualitative interpretability of the attribution maps in Figure 2, suggesting that the attended areas do not seem to be related to the actual task. It also mentions clusters of attended pixels without a clear semantic meaning. However, the comment acknowledges that the quantitative analysis using the attribution maps appears to be effective. While the comment identifies a potential issue with the qualitative value of the attribution maps, it does not provide explicit guidance on how to address this issue or suggest specific improvements. The action is implicit and somewhat vague, as the authors are left to infer that they should improve the qualitative interpretability of the attribution maps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 2\" and \"sec 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the attribution maps, noting that the attended areas do not seem to be related to the actual task and that there are clusters of attended pixels without a clear semantic meaning. The comment further acknowledges that the quantitative analysis using the attribution maps appears to be effective, but it highlights the lack of qualitative value. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the attribution maps in Figure 2 are not qualitatively intuitive, as the attended areas do not seem to be related to the actual task. The reviewer provides specific examples, such as the lack of attention to 3D pixels in 3D tasks, and mentions clusters of attended pixels without clear semantic meaning. However, the comment acknowledges that the quantitative analysis using the attribution maps appears to be effective, which adds a layer of complexity to the claim. While the reviewer provides some reasoning and examples, the claim could be strengthened with more detailed analysis or references to similar studies. Therefore, the comment is mostly verifiable, as it provides a solid foundation for the claim but could benefit from additional evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed critique of the attribution maps presented in Figure 2, questioning their qualitative interpretability. It highlights specific issues, such as the lack of relation between the attended areas and the actual task, and the presence of clusters of attended pixels without clear semantic meaning. However, the comment also acknowledges that the quantitative analysis using the attribution maps appears to be effective, which suggests that there is some value in the work. This feedback is somewhat helpful as it identifies a potential weakness in the qualitative interpretation of the results but does not provide specific suggestions for improvement. The authors are left with a general understanding of the issue but without detailed guidance on how to address it. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the title overclaiming the contribution of the paper, specifically noting that the results are only shown on two language models, BERT and RoBERTa, without evidence of scalability to larger models like Llama2-70b. The reviewer suggests that the authors should provide empirical justification for the scalability of their method to larger language models. Additionally, the comment points out a minor issue with the consistency of the term \"ROBERTA\" in Section 3.3 and \"RoBerta\" in the Introduction. While the comment identifies specific areas for improvement, it does not provide detailed guidance on how to address the scalability issue or the consistency issue. The action is mostly implicit, as the authors need to infer that they should provide empirical justification for scalability and correct the term consistency. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the title and the specific results presented in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue with the title, questioning the overclaim of contributions and suggesting that the results should be shown for larger language models like Llama2-70b. Additionally, it provides a minor comment about the consistency of the term \"ROBERTA\" in Section 3.3 and \"RoBerta\" in the Introduction. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the title overclaims the contribution of the paper, specifically noting that the results are only shown on two language models, BERT and RoBERTa, without evidence of scalability to larger models like Llama2-70b. The reviewer questions whether the proposed method can be scalable to LLMs and requests empirical justification. This claim is somewhat verifiable as it provides a logical reasoning about the potential limitation of the paper\\'s claims and suggests a specific area for further investigation. However, the comment lacks specific examples or references to support the claim fully, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the title of the paper, suggesting that it overclaims the contribution by only showing results on two language models, BERT and RoBERTa, without evidence of scalability to larger models like Llama2-70b. This is a valid concern that could impact the paper\\'s credibility. The reviewer also points out a minor inconsistency in the use of \"ROBERTA\" and \"RoBerta\" in different sections of the paper. While the comment highlights important issues, it could be more helpful by providing specific suggestions on how to address the overclaim or by offering examples of how to demonstrate scalability to larger models. Additionally, it could suggest ways to improve the consistency of terminology throughout the paper. Overall, the comment is somewhat helpful as it directs the authors\\' attention to critical areas for improvement but lacks detailed guidance on how to address these issues.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the paper for lacking motivation for choosing specific variables (date and country) as potential spurious correlating variables with gender. It suggests that the paper only speculates about their potential for showing spurious correlations. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their motivation. The action is implicit and vague, as the authors are left to infer that they need to provide a clearer rationale for their choices. Without specific instructions or examples, the authors may struggle to know exactly how to enhance their motivation. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the paper for lacking motivation in choosing specific variables (date and country) as potential spurious correlating variables with gender. It suggests that the paper only speculates about their potential for showing spurious correlations. However, the comment does not specify which part of the paper this critique is based on, such as a particular section or figure, making it weakly grounded. The comment is specific in detailing what is missing, namely a clear motivation for the choice of variables. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks motivation for choosing specific variables (date and country) as potential spurious correlating variables with gender. The reviewer suggests that the paper only speculates about their potential for showing spurious correlations. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the paper, namely the lack of motivation for choosing date and country as potential spurious correlating variables with gender. It points out that the paper only speculates about their potential for showing spurious correlations, without providing a clear rationale for these choices. This feedback is somewhat helpful as it highlights an area where the authors could improve their draft by providing a more detailed explanation for their methodological decisions. However, the comment could be more helpful if it offered suggestions or examples on how to enhance the motivation or provide a clearer rationale. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the contribution of exchanging channels, suggesting that it is only achieved using batch normalization (BN) and questioning its incremental nature. Additionally, it critiques Theorem 1, stating that its rationale is mostly based on an external reference ([38]) and that it seems like a simple fact. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the concerns or improve the draft, leaving the authors without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the authors\\' point about exchanging channels and questions the incremental nature of this contribution, suggesting that it is only achieved through batch normalization (BN). It also critiques Theorem 1, stating that its rationale is mostly based on an external reference ([38]) and that it seems like a simple fact. However, the comment does not specify which part of the paper discusses the exchange of channels or where Theorem 1 is presented, making it difficult for the authors to pinpoint the exact sections that need attention. The lack of explicit references to specific sections or elements of the paper results in weak grounding. The comment is specific in its critique of the contribution and the basis of Theorem 1, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the contribution of exchanging channels, questioning its incremental nature and suggesting that it is only achieved through batch normalization (BN). It also critiques Theorem 1, stating that its rationale is mostly based on an external reference ([38]) and that it seems like a simple fact. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the concerns. The lack of detailed justification or references makes the claim somewhat verifiable, as it provides a general direction for the authors to explore but does not fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the contribution of exchanging channels, suggesting that it is only achieved through batch normalization (BN) and questioning its incremental nature. It also critiques Theorem 1, stating that its rationale is mostly based on an external reference ([38]) and that it seems like a simple fact. While the comment identifies potential weaknesses in the paper, it lacks specific guidance or suggestions on how the authors might address these issues or improve their work. The feedback is somewhat helpful as it points out areas for improvement, but it does not provide actionable advice or detailed insights to help the authors enhance their draft. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part suggests that if the contribution is considered a main contribution and a practical method, more in-depth studies are needed to establish its effectiveness in improving damping in second-order methods. This is an implicit action, as it does not explicitly instruct the authors to conduct these studies but suggests a direction for further research. The second part is a clarification question about the notation \"K\" and whether it equals \"NC.\" While the question is specific, it is not an action but rather a request for clarification. Overall, the comment provides some guidance but lacks explicit instructions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific feedback by questioning the notation \"K\" and asking if it equals \"NC.\" This level of detail helps the authors understand what needs clarification or further explanation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts: a suggestion for further study and a question about notation. The first part suggests that more in-depth studies are needed to establish the effectiveness of the contribution in improving damping in second-order methods. This claim is somewhat verifiable as it provides a logical reasoning for the need for further study, but it lacks specific examples or references to support the claim. The second part is a factual question about the notation \"K,\" which does not contain a claim. Therefore, the overall comment is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two distinct points of feedback. The first part suggests that if the contribution is considered a main contribution and a practical method, more in-depth studies are needed to establish its effectiveness in improving damping in second-order methods. This is a clear and actionable suggestion that could guide the authors in enhancing their work. The second part is a minor clarification question about the notation \"K,\" which is important for ensuring clarity and consistency in the paper. While the comment is helpful in identifying areas for improvement and providing a specific question, it could be more comprehensive by addressing the first point in more detail. Overall, the comment is mostly helpful, as it offers valuable insights and guidance for the authors to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an in-depth analysis of the parameters k and N in the ablation study would enhance readers' understanding of the algorithm. It also recommends analyzing the running time or complexity, specifically the impact of k and N on the running time. Additionally, it raises a minor comment about a potential mismatch between Figure 2 and its description. While the first part of the comment is explicit and provides a clear action for the authors to take, the second part is more of a suggestion and lacks specific guidance on how to address the issue. The comment is mostly actionable because it provides a clear direction for the analysis but could be more detailed in its suggestions. However, the minor comment about Figure 2 is explicit and actionable, making the overall comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2\" and the description \"the dimensionality reduction is only performed on $s_{k\u22121,t\u22121}$,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential mismatch between the figure and its description, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that an in-depth analysis of the parameters k and N in the ablation study would enhance readers\\' understanding of the algorithm. It also recommends analyzing the running time or complexity, specifically the impact of the parameters k and N on the running time. The comment provides a logical reasoning for why this analysis would be beneficial, but it lacks specific examples or references to support the claim. While the suggestion is clear, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two distinct points of feedback. First, it suggests that an in-depth analysis of the parameters k and N in the ablation study would enhance readers\\' understanding of the algorithm. This is a clear and actionable suggestion that could significantly improve the clarity and comprehensiveness of the paper. Second, it recommends analyzing the running time or complexity, specifically the impact of the parameters k and N on the running time, which is another valuable suggestion for enhancing the paper\\'s depth. Additionally, the comment raises a minor point about a potential mismatch between Figure 2 and its description, which could be a simple correction to make. Overall, the comment is highly helpful as it offers detailed and actionable feedback that could lead to substantial improvements in the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the details provided in Appendix B regarding the averaging of results over 10 runs. It questions the absence of standard deviation and whether the 10 runs were conducted with random hyperparameter configurations for all baselines or with the best selected hyperparameter values. While the comment implies that the authors should provide more detailed information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address these questions but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix B,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the absence of standard deviation in the results and whether the 10 runs were conducted with random hyperparameter configurations or the best selected values. This provides clear guidance on what needs to be clarified or addressed in the appendix. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the details provided in Appendix B, specifically regarding the averaging of results over 10 runs and the absence of standard deviation. It also questions whether the 10 runs were conducted with random hyperparameter configurations for all baselines or with the best selected hyperparameter values. While the comment identifies potential issues, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The lack of detailed justification or examples makes the claims difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises important questions about the methodology and presentation of results in Appendix B. It points out the absence of standard deviation in the results, which is a critical piece of information for understanding the variability and reliability of the findings. Additionally, it questions whether the 10 runs were conducted with random hyperparameter configurations for all baselines or with the best selected hyperparameter values. These questions highlight potential gaps in the presentation of the results and suggest that the authors should provide more detailed information to enhance the clarity and robustness of their analysis. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how to present the results more effectively. Overall, the comment is mostly helpful as it identifies areas for improvement and prompts the authors to provide more detailed information, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that more details about the task generation process should be included in the main text, rather than just in the appendix section. This provides a clear and direct action for the authors to take, which is to expand the main text to include these details. The comment specifies exactly what needs to be done, making it highly actionable. The authors know exactly how to apply this feedback to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more details about the task generation process should be included in the main text, rather than just in the appendix section. This provides a clear direction for improvement, but it does not specify which part of the paper currently lacks these details. The authors can infer that it relates to the experimental setup, but the comment lacks full grounding as it does not explicitly mention sections or figures. However, it is specific in suggesting what needs to be addressed. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details about the task generation process should be included in the main text, rather than just in the appendix. This claim is based on a logical reasoning that providing more details would enhance the readers\\' understanding of the experimental setup and strengthen the paper\\'s presentation. However, the comment lacks specific examples or references to support why these details are crucial or how they would improve the paper. Therefore, the claim is somewhat verifiable, as it provides a rationale but lacks detailed evidence or examples to fully substantiate the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that more details about the task generation process should be included in the main text, rather than just in the appendix. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper\\'s presentation and clarity. By incorporating these details into the main text, the authors can better inform readers about the experimental setup, which is crucial for understanding the paper\\'s contributions. However, the comment could be more helpful if it provided specific examples or guidance on what details to include. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should clarify that entropy depends on a datapoint by using notation like $H(p^a|x)$. This provides a specific and concrete action for the authors to take, as it indicates exactly how to improve the clarity of their formulas. The comment is explicit and detailed, leaving no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Individual-level entropy\" and \"Group-level entropy,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the authors clarify the notation for entropy, providing a concrete example of how to improve the clarity of the formulas. This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should clarify the notation for entropy by specifying that it depends on a datapoint, such as $H(p^a|x)$. This claim is somewhat verifiable as it provides a logical reasoning for the improvement, but it lacks specific examples or references to support the necessity of this clarification. The suggestion is based on a reasonable assumption about the importance of clarity in mathematical notation, but it could be strengthened with additional context or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting a notation improvement in the representation of entropy. It recommends clarifying that entropy depends on a datapoint, such as $H(p^a|x)$, to enhance the understandability of formulas like $\\text{argmax}_{x \\in U, a \\in A} H^a$. This feedback is clear and constructive, offering a direct way for the authors to improve the clarity and precision of their mathematical expressions. By addressing this suggestion, the authors can enhance the readability and comprehensibility of their work, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a descriptive statement about the method of connecting tokens beyond local windows by forming new groups across previous local windows. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how to improve the draft or what specific aspects need attention. As a result, the authors are left without any actionable steps to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it addresses, leaving the authors uncertain about where to focus their attention. It also lacks specificity, as it does not detail what needs to be addressed or improved regarding the connection of tokens beyond local windows. Without clear guidance or references to specific sections or elements of the paper, the authors cannot effectively respond to the comment. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a factual statement describing a method used in the paper, specifically how tokens are connected beyond local windows. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review point provides a descriptive statement about the method of connecting tokens beyond local windows by forming new groups across previous local windows. However, it lacks any actionable feedback or suggestions for improvement. Without specific guidance or critique, the authors are left without a clear understanding of how to enhance their work based on this comment. Therefore, the comment is not helpful at all, as it does not provide any actionable insights or suggestions for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the advantage of using a specific distance metric in the proposed DD risk, compared to other metrics used in Distributionally Robust Optimization (DRO). It suggests that the authors provide a more comprehensive illustration of this aspect. While the comment implies that the authors should address this gap in their work, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to provide this illustration. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Relationship with Distributionally Robust Optimization,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue by comparing the proposed DD risk with DRO risk and questioning the advantage of using a specific distance metric. The comment suggests that the authors provide a more comprehensive illustration of this aspect, which further specifies what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the advantage of using a specific distance metric in the proposed DD risk compared to others used in Distributionally Robust Optimization (DRO). It suggests that the authors provide a more comprehensive illustration of this aspect. The comment is somewhat verifiable as it references existing works using different distance metrics in DRO and implies that the authors should explain the benefits of their chosen metric. However, it lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a pertinent question about the relationship between the proposed DD risk and Distributionally Robust Optimization (DRO), specifically highlighting the similarity in formulation and the use of entropy to capture distributional differences. It points out that various distance metrics are used in DRO literature and suggests that the authors provide a more comprehensive illustration of the advantages of their specific distance metric. This feedback is mostly helpful as it prompts the authors to clarify and justify the choice of their distance metric, which could lead to a better understanding of its benefits and potential improvements in generalization performance. However, the comment could be more helpful if it provided specific examples or references to guide the authors in their explanation. Therefore, the comment is rated as mostly helpful.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the nature of the T-REx dataset, suggesting it might be a distantly supervised dataset without human labels. It also asks if it would be possible to evaluate the dataset over an annotated dataset, such as TACRED or FewRel. While the comment implies that the authors should clarify the nature of the T-REx dataset and consider evaluating it over annotated datasets, it does not provide explicit instructions or concrete steps on how to address these points. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the dataset's nature and consider alternative evaluation methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the nature of the T-REx dataset, suggesting it might be a distantly supervised dataset without human labels. It also asks if it would be possible to evaluate the dataset over an annotated dataset, such as TACRED or FewRel. However, the comment does not specify which part of the paper discusses the T-REx dataset, making it weakly grounded. The comment is specific in its request for clarification and suggestion of alternative evaluation methods, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the nature of the T-REx dataset, suggesting it might be a distantly supervised dataset without human labels. It also asks if it would be possible to evaluate the dataset over an annotated dataset, such as TACRED or FewRel. The comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, making it a normal statement. Therefore, the label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the nature of the T-REx dataset, suggesting it might be a distantly supervised dataset without human labels. It also asks if it would be possible to evaluate the dataset over an annotated dataset, such as TACRED or FewRel. This feedback is somewhat helpful as it prompts the authors to clarify the nature of their dataset and consider alternative evaluation methods. However, the comment lacks depth and does not provide specific guidance on how to address these issues or why they are important. While it identifies a potential area for improvement, it does not offer detailed suggestions or actionable steps, limiting its helpfulness. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part explicitly instructs the authors to give the appendix a proofread, as it is not using the NeurIPS 2021 style files. This is a clear and direct action for the authors to take. The second part provides specific examples of errors in the appendix, such as \"poster mean,\" \"peicewise-linear,\" and \"sugggest,\" which the authors need to correct. Additionally, it suggests expanding on the discussion of potential negative societal impacts. While the action is explicit, the feedback could be more detailed by providing a clearer explanation of how to address the societal impacts. Overall, the comment is mostly actionable as it provides concrete steps for the authors to follow, but it could be more detailed in its suggestions.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the appendix and provides specific examples of errors, such as \"poster mean,\" \"peicewise-linear,\" and \"sugggest,\" allowing the authors to accurately identify the parts of the paper that need attention. It also specifies what needs to be addressed, including a proofread of the appendix and an expansion on the discussion of potential negative societal impacts. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of multiple claims and suggestions. The first claim about the appendix not using NeurIPS 2021 style files is verifiable as it is a factual observation that can be easily verified by checking the appendix. The second part of the comment provides specific examples of errors (\"poster mean,\" \"peicewise-linear,\" \"sugggest\") and suggests a proofread, which is also verifiable. The suggestion to expand on the discussion of potential negative societal impacts is a logical request for improvement, but it lacks specific examples or references to support the claim. Overall, the comment is mostly verifiable, as it provides clear evidence and suggestions, but could be strengthened with more detailed examples or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies several specific issues with the appendix, including the use of incorrect style files and typographical errors (\"poster mean,\" \"peicewise-linear,\" \"sugggest\"). It also suggests a proofread to ensure consistency with the NeurIPS 2021 style. Additionally, the comment points out that while the paper discusses limitations and societal impacts, it could further elaborate on the potential negative societal impacts. This feedback is clear and actionable, providing the authors with concrete steps to improve the clarity and professionalism of their work. However, the comment could be more helpful by offering suggestions on how to address the societal impacts or providing examples of how to expand on this discussion. Overall, the comment is mostly helpful as it effectively guides the authors in improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should examine the training and validation curves of the different losses to understand if the model can simultaneously reduce all three losses. It also asks about any tricks related to weighing these losses. While the comment implies that the authors should investigate this aspect, it does not provide explicit instructions on how to conduct the analysis or what specific metrics to use. The action is implicit and somewhat vague, as the authors need to infer the steps to take and may not be entirely sure of the exact approach. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests examining the training and validation curves of different losses and inquiring about the model\\'s ability to reduce all three losses simultaneously. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where these curves are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing attention. Additionally, while the comment provides a clear direction for analysis, it does not specify what specific aspects of the losses or their weighing should be examined. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests examining the training and validation curves of different losses and inquiring about the model\\'s ability to reduce all three losses simultaneously. However, it does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would improve the paper. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a specific analysis that could enhance the understanding of the model\\'s performance, namely examining the training and validation curves of different losses. It also raises questions about the model\\'s ability to reduce all three losses simultaneously and whether there are any tricks related to weighing these losses. While the comment provides a clear direction for further analysis, it lacks detailed guidance on how to conduct this analysis or what specific metrics to focus on. This limits the comment\\'s usefulness, as the authors may still need to infer the exact steps to take. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the paper\\'s claim of NP-hardness for computing the GOSPA metric, noting that it lacks a rigorous theoretical argument or proof. The reviewer points out that the statement is not generally true for assignment problems and suggests that the paper may be able to reduce GOSPA to an exact polynomial-time computable assignment problem. Additionally, the reviewer questions the applicability of the paper\\'s assumptions about access to the optimal assignment matrix. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rigorous theoretical argument or proof for the NP-hardness claim and address the applicability concerns. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"NP-hardness\" and \"the paper claims,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the claim, pointing out the lack of a rigorous theoretical argument or proof for NP-hardness. The comment further specifies that the statement is not generally true for assignment problems and questions the applicability of the paper\\'s assumptions. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s assertion of NP-hardness for computing the GOSPA metric is not supported by a rigorous theoretical argument or proof. The reviewer critiques the statement by pointing out that it is not generally true for assignment problems and suggests that the paper may be able to reduce GOSPA to an exact polynomial-time computable assignment problem. The comment also questions the applicability of the paper\\'s assumptions about access to the optimal assignment matrix. While the reviewer provides some logical reasoning and examples, the claim could be further supported by specific references or detailed explanations of the theoretical arguments or proofs that are lacking. Therefore, the comment is mostly verifiable, as it provides a solid foundation for the claim but could benefit from additional evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it thoroughly critiques the paper\\'s claim of NP-hardness for computing the GOSPA metric. It points out the lack of a rigorous theoretical argument or proof, which is a critical oversight in the paper. The reviewer also challenges the generality of the claim by noting that it may not be true for all assignment problems and suggests that the paper could potentially reduce GOSPA to an exact polynomial-time computable assignment problem. Additionally, the comment questions the applicability of the paper\\'s assumptions about access to the optimal assignment matrix, which could limit the paper\\'s applicability. By providing detailed and specific feedback, the comment empowers the authors to address these weaknesses and improve the rigor and validity of their claims, making it highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an algorithmic writeup of the solution to the pricing problem would be beneficial. However, it does not provide specific guidance on how to achieve this or what aspects of the algorithmic writeup should be included. The action is explicit in suggesting a writeup, but it lacks concrete details on how to implement it, leaving the authors uncertain about the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that an algorithmic writeup of the solution to the pricing problem would be helpful. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or chapter where the pricing problem is discussed. Without explicit references or context, the authors may find it challenging to identify the exact area that needs improvement. Additionally, the comment lacks specificity regarding what aspects of the algorithmic writeup are needed or how it would enhance the paper. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that an algorithmic writeup of the solution to the pricing problem would be beneficial. However, it does not provide any reasoning, examples, or references to support why this would be helpful or how it would improve the paper. The comment lacks specific details or justification, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that an algorithmic writeup of the solution to the pricing problem would be beneficial. While it identifies a potential area for improvement, the comment lacks specificity and does not provide detailed guidance on how to implement this suggestion. It does not offer examples of what an algorithmic writeup might entail or how it could enhance the paper. As a result, the feedback is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the lack of clarity regarding how model averaging helps balance the trade-off between KL divergence and reward. It suggests that achieving this trade-off effectively requires intelligent exploration and gradual updates during initialization, but it does not provide specific guidance on how the authors should address this issue. The comment implies that the authors should provide a clearer explanation of the relationship between model averaging and the proposed technique, as well as explore other possible mechanisms and explanations. However, it does not explicitly instruct the authors to do so, leaving the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of model averaging and its role in balancing the trade-off between KL divergence and reward. However, it does not specify which part of the paper discusses model averaging or the trade-off, making it weakly grounded. The comment is specific in detailing the concern about the lack of clarity regarding how model averaging achieves this balance and suggests that the policy should explore intelligently and update gradually during initialization. This provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the lack of clarity regarding how model averaging helps balance the trade-off between KL divergence and reward. The reviewer provides a logical explanation that achieving this trade-off effectively requires intelligent exploration and gradual updates during initialization. However, the comment does not provide specific examples or references to support the claim that model averaging is the correct approach or that other mechanisms might be more effective. While the reasoning is sound, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the lack of clarity in the paper about how model averaging helps balance the trade-off between KL divergence and reward. It provides a logical explanation that achieving this balance effectively requires intelligent exploration and gradual updates during initialization. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or provide a clearer explanation. While it highlights an important area for improvement, the feedback lacks actionable details, making it somewhat helpful. The authors are given some insight into what needs clarification but are not provided with a clear path forward for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors consider discussing a possible generalization with a different distribution for the size of the batches. While the comment implies that this is an area worth exploring, it does not provide explicit guidance on how to approach this discussion or what specific aspects should be considered. The action is implicit and somewhat vague, as the authors can infer that they need to discuss generalization but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests discussing a possible generalization with a different distribution for the size of the batches. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. Without explicit references or context, the authors may find it challenging to determine where this discussion should be integrated. The comment is specific in suggesting a topic for discussion but lacks grounding, making it weakly grounded and not specific. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that a discussion regarding a possible generalization with a different distribution for the size of the batches could be included. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors consider discussing a possible generalization with a different distribution for the size of the batches. While this is a relevant suggestion, it lacks specificity and does not provide detailed guidance on how to approach this discussion or what aspects should be explored. The comment identifies a potential area for improvement but does not offer actionable steps or examples, leaving the authors with a general idea but limited direction for enhancement. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the analysis, noting that it only considers the case of batch size = 1 and questions how batch size affects the effective initialization scale. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or conduct further analysis. The action is implicit, as the authors need to infer that they should explore the impact of different batch sizes, but it lacks concrete details on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the analysis, noting that it only considers the case of batch size = 1 and questioning how batch size affects the effective initialization scale. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the analysis, but without clear grounding, the authors may struggle to identify the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the analysis only considers the case of batch size = 1 and questions how batch size affects the effective initialization scale. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the analysis by noting that it only considers the case of batch size = 1 and questions how batch size affects the effective initialization scale. This feedback highlights a specific area where the analysis could be expanded or improved, providing the authors with a clear direction for enhancing their work. However, the comment lacks detailed guidance or suggestions on how to address this issue, such as recommending specific batch sizes to consider or methods to analyze the impact of batch size. While it points out a relevant area for improvement, it could be more helpful with additional guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the results presented in Figure 7, specifically why more data leads to lower results on the ImageNet linear evaluation. It provides an example by mentioning that sampling 50% of the data seems to yield better results than sampling 100% of the data. While the comment highlights an inconsistency or unexpected outcome, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should investigate and clarify the discrepancy in the results. However, the comment lacks concrete details on how to resolve the issue, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the results presented in Figure 7, specifically why more data leads to lower results on the ImageNet linear evaluation, and provides an example by comparing the results of sampling 50% and 100% of the data. This provides clear guidance on what needs to be addressed or clarified in the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the results presented in Figure 7, specifically why more data leads to lower results on the ImageNet linear evaluation. It provides an example by comparing the results of sampling 50% and 100% of the data. This observation is based on a factual analysis of the data presented in the figure, and the reviewer is seeking clarification or explanation for the observed trend. However, the comment does not make a subjective claim or suggestion that requires justification or evidence. It is a factual observation seeking clarification, making it a normal statement. Therefore, the label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the results presented in Figure 7, questioning why more data leads to lower results on the ImageNet linear evaluation. It provides an example by comparing the results of sampling 50% and 100% of the data, which could help the authors understand and potentially address the discrepancy. However, the comment does not offer any suggestions or guidance on how to resolve this issue or improve the clarity of the results. While it identifies a potential problem, it lacks actionable feedback, making it somewhat helpful. The authors are left with a clear question to address but without specific steps to take, limiting the comment\\'s utility. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of comprehensive evaluation in the paper, specifically noting the absence of quantitative results on mainstream metrics like FVD. It suggests that including FVD would enhance the paper\\'s credibility and make it more comparable to other video generation methods. While the comment implies that the authors should include FVD in their evaluation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should include FVD without specific guidance on how to integrate it into their evaluation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lack of Comprehensive Evaluation,\" which allows the authors to identify the part of the paper being addressed. It also specifies the issue by mentioning the absence of quantitative results on mainstream metrics like FVD, which is widely recognized and robust for evaluating temporal video prediction. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks comprehensive evaluation, specifically mentioning the absence of quantitative results on mainstream metrics like FVD. The reviewer provides a logical reasoning by stating that including FVD would enhance the paper\\'s credibility and make it more comparable to other video generation methods. This reasoning is supported by the mention of FVD as a widely recognized and robust metric for evaluating temporal video prediction. However, the comment could be strengthened by providing specific examples or references to studies that use FVD, which would make the claim more fully verifiable. Therefore, the comment is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the lack of comprehensive evaluation using mainstream metrics like FVD. It provides a clear and actionable suggestion to include FVD, which would enhance the paper\\'s credibility and make it more comparable to other video generation methods. Additionally, the comment highlights the limited novelty and insufficient methodological depth of the work, which detracts from its overall impact. However, the comment could be more helpful if it offered specific guidance on how to incorporate FVD into the evaluation or provided examples of other metrics that could be used. Overall, the feedback is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional suggestions or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the technical details in section 2.2 are difficult to follow, but it does not provide any specific guidance or suggestions on how to improve this aspect. There is no explicit or implicit action for the authors to take, such as revising the section, adding explanations, or providing examples. Without actionable advice, the authors are left without a clear path to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"2.2,\" which suggests that it addresses a specific section of the paper. However, it does not provide further details or specify what aspects of the technical details are hard to follow, making it difficult for the authors to pinpoint the exact issues. The comment lacks specificity regarding what needs to be clarified or improved in section 2.2. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the technical details in section 2.2 are hard to follow. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the technical details in section 2.2, noting that they are hard to follow. However, it lacks any actionable suggestions or guidance on how the authors might improve the clarity or presentation of these details. Without specific advice or examples, the authors are left without a clear path to address the issue, making the comment barely helpful. It highlights a problem but does not provide the necessary support for the authors to make meaningful improvements.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the improvements offered by EVA over the backbone models, specifically OT-Flow, in terms of designability and success rates on the RFDiffusion benchmark. It also questions whether the addition of geometry information and motif-interpolation benefits over prior backbones. While the comment highlights areas where the authors should provide more clarity and justification for their contributions, it does not explicitly instruct the authors to address these points or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed comparisons and justifications but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"RFDiffusion benchmark\" and \"in-silico vaccine design benchmark,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the improvements offered by EVA over the backbone models, such as OT-Flow, and asks whether the addition of geometry information and motif-interpolation provides benefits over prior backbones. This provides clear guidance on what aspects of the paper need further clarification or justification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the improvements offered by EVA over the backbone models, specifically OT-Flow, in terms of designability and success rates on the RFDiffusion benchmark. It questions whether the addition of geometry information and motif-interpolation provides benefits over prior backbones. However, the comment does not provide any evidence, examples, or references to support the claim that the backbone models are better for designability and success rates. Without such supporting information, the claim remains unverifiable, as it lacks the necessary justification or evidence to be substantiated. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical question about the improvements offered by EVA over the backbone models, specifically OT-Flow, in terms of designability and success rates on the RFDiffusion benchmark. It questions whether the addition of geometry information and motif-interpolation provides benefits over prior backbones. This feedback is somewhat helpful as it prompts the authors to clarify and justify their contributions, particularly in relation to the improvements over existing models. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might demonstrate these improvements. Overall, the feedback is clear but incomplete, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a problem with the repetition of identical sentences in the Abstract, Introduction, and Conclusion. However, it does not provide any explicit or implicit guidance on how to address this issue. The authors are left without a clear understanding of what changes need to be made or how to improve the draft. Without specific suggestions or examples, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the repetition of identical sentences in the Abstract, Introduction, and Conclusion. However, it does not specify which sentences are identical or where exactly they appear in these sections, making it difficult for the authors to pinpoint the exact parts of the paper that need revision. This lack of specificity and detailed guidance makes it weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that there are too many identical sentences in the Abstract, Introduction, and Conclusion. However, it does not provide any specific examples or reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or explanation, the claim is not verifiable, as the authors cannot effectively address or improve the draft based on this feedback. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the repetition of identical sentences in the Abstract, Introduction, and Conclusion. This feedback is clear and actionable, as it highlights a potential problem with the paper\\'s structure and suggests that the authors should revise the text to avoid repetition. However, the comment could be more helpful if it provided specific examples of the repeated sentences or offered guidance on how to rephrase them to improve the draft. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement, making it a 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two questions regarding the reward function used in the ablation studies. It asks if the reward function used is \"sEH\" and seeks clarification on this aspect. While the comment implies that the authors should provide more information about the reward function, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the reward function but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Reward Function,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by asking about the reward function used in the ablation studies and whether it is \"sEH.\" This provides clear guidance on what information is missing or unclear, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two questions regarding the reward function used in the ablation studies, specifically asking if it is \"sEH.\" This is a factual inquiry seeking clarification, rather than a claim or opinion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area of the paper that requires clarification, namely the reward function used in the ablation studies. By asking if the reward function is \"sEH,\" the reviewer prompts the authors to provide more detailed information about their methodology. However, the comment lacks depth and does not offer suggestions on how to address this issue or why it is important. While it directs the authors to a specific area needing clarification, it does not provide comprehensive guidance for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the comparison between the current work and previous studies, specifically regarding the use of self-generated code versus a placeholder. It suggests that using self-generated code may not be a fair comparison due to the model being sampled 2x for each generation, whereas the placeholder code was only generated once. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative methods for comparison. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider their comparison methodology but are not given concrete steps to follow. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the comparison between the current work and previous studies, specifically regarding the use of self-generated code versus a placeholder. It provides a clear explanation of the potential unfairness in the comparison due to the model being sampled 2x for each generation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the comparison, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location for revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using self-generated code instead of a placeholder is not a fair comparison to previous work, as it samples the model 2x for each generation. The reviewer provides a logical explanation for why this might be unfair, noting that the original technique intended to generate the code only once. However, the comment lacks specific references or examples to support the claim, making it somewhat verifiable. The authors would need to consider the reasoning and potentially look into the original technique to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison between the current work and previous studies, specifically regarding the use of self-generated code versus a placeholder. It highlights that using self-generated code may not be a fair comparison due to the model being sampled 2x for each generation, whereas the placeholder code was only generated once. This feedback is somewhat helpful as it points out a potential flaw in the methodology, prompting the authors to reconsider their comparison approach. However, the comment could be more helpful if it provided suggestions on how to address this issue or alternative methods for comparison. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the main contributions of the paper, specifically Sections 3 and 4, which are condensed into a single page. It also points out the absence of precise mathematical definitions for the quantum states in Eq (4), making it difficult to follow. While the comment identifies areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should expand these sections and include the missing definitions, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed steps for execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sections 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that these sections should be the main contributions but are condensed into a single page, and it highlights the absence of precise mathematical definitions for the quantum states in Eq (4), which makes it hard to follow. This provides clear guidance on what needs to be addressed in these sections. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Sections 3 and 4, which should be the main contributions of the paper, are condensed into a single page, making it difficult to follow. It specifically mentions the absence of precise mathematical definitions for the quantum states in Eq (4), which supports the claim that the sections are not well-developed. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the specific issues and how they impact the paper\\'s clarity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that Sections 3 and 4, which should be the main contributions, are condensed into a single page. It highlights the absence of precise mathematical definitions for the quantum states in Eq (4), which makes it difficult to follow. This feedback is clear and actionable, as it points out specific areas where the paper lacks depth and suggests that the authors should expand these sections to improve the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided additional guidance on how to expand these sections or what specific details should be included. Overall, the comment is mostly helpful, as it directs the authors to focus on improving the main contributions of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fairness of the results regarding under-represented groups, specifically asking if females or blacks are discriminated by the recommendations of LLMs. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address this concern or what specific steps to consider in evaluating fairness. As a result, the authors are left without a clear understanding of what changes or analyses are needed to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the fairness of the results regarding under-represented groups, specifically asking if females or blacks are discriminated by the recommendations of LLMs. However, it does not specify which part of the paper this concern relates to, such as a particular section or analysis. Without explicit references or context, the authors cannot confidently determine which part of the paper this comment addresses. Additionally, the comment lacks specificity regarding what aspects of fairness need to be addressed or how the authors might evaluate fairness. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the fairness of the results regarding under-represented groups, specifically asking if females or blacks are discriminated by the recommendations of LLMs. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an important question about the fairness of the results regarding under-represented groups, specifically asking if females or blacks are discriminated by the recommendations of LLMs. This is a critical concern that the authors should address to ensure the ethical implications of their work are thoroughly considered. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might investigate or address this issue. Without actionable feedback or detailed advice, the authors are left with a general awareness of a potential problem but without a clear path forward. Therefore, the comment is somewhat helpful, as it identifies a significant concern but lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides several explicit suggestions for improvement. It recommends shortening the paragraph in Section 1 to enhance legibility, adding more details to the experiments on long-tailed datasets, and potentially allocating more space for these experiments. These suggestions are clear and direct, providing the authors with concrete actions to take. The comment is highly actionable as it offers specific guidance on how to address the issues raised, ensuring the authors know exactly what steps to take to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1\" and \"the paragraph that describes Co-variance,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the length of the paragraph, which reduces legibility. Additionally, it provides specific suggestions for improvement, such as adding more details to the experiments on long-tailed datasets and potentially allocating more space for these experiments. The comment is clear and detailed in its guidance, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of minor comments regarding the length of a paragraph in Section 1, the need for more illustrations of long-tailed dataset generation, and the suggestion to allocate more space for experiments on long-tailed datasets. These are factual statements and do not contain subjective opinions, claims, or suggestions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides several specific and actionable suggestions for improving the draft. It identifies a minor issue with the length of a paragraph in Section 1, which could affect legibility, and suggests shortening it. Additionally, it points out the importance of experiments on long-tailed datasets and recommends adding more details and illustrations to support this aspect. The comment also suggests allocating more space for these experiments, which is a constructive suggestion. However, the comment could be more helpful if it provided specific examples or guidance on how to enhance the illustrations or experiments. Overall, the feedback is mostly helpful as it directs the authors to areas that need improvement and provides some actionable steps, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the necessary changes to make EC-Diffusers work on real-world data. While it implies that the authors should consider this aspect, it does not provide explicit guidance or suggestions on how to address the issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore modifications or adjustments to make the model applicable to real-world data. However, the comment lacks concrete details on what specific changes might be necessary or how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the necessary changes to make EC-Diffusers work on real-world data. However, it does not specify which part of the paper this question pertains to, nor does it provide any details on what specific changes are being referred to. This makes it difficult for the authors to identify the exact section that needs attention or to understand what aspects need to be addressed. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification on the necessary changes to make EC-Diffusers work on real-world data. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the necessary changes to make EC-Diffusers work on real-world data. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. The comment does not offer actionable feedback or insights that could help the authors improve their draft. As a result, it is barely helpful, as it points out a potential area for improvement but does not provide enough detail or direction for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the reliability of the evaluation and whether there is a human study to gauge the efficacy of the evaluation protocol. However, it does not provide explicit instructions or suggestions on how the authors should address these concerns. The authors are left to infer that they need to provide more information or evidence regarding the evaluation protocol, but the comment lacks concrete guidance on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the reliability of the evaluation and whether there is a human study to gauge the efficacy of the evaluation protocol. However, it does not specify which part of the paper this concern pertains to, such as a specific section or methodology. Without explicit references or context, the authors may find it challenging to identify the exact areas needing attention. The comment is specific in its questioning of the evaluation protocol but lacks grounding, making it weakly grounded and not specific. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the reliability of the evaluation and asks if there is a human study to gauge the efficacy of the evaluation protocol. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical question about the reliability of the evaluation and whether there is a human study to gauge the efficacy of the evaluation protocol. This is an important concern that the authors should address to ensure the validity and robustness of their findings. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. Without actionable advice or examples, the authors are left to infer what steps to take, making the feedback somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the novelty of the work, suggesting that the technical contribution is somewhat incremental compared to prior work. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to enhance the novelty of the work or what specific aspects need improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the novelty of the work, comparing it to prior work by von Kugelgen et al. (2021) and Daunhawer et al. (2023). However, it does not specify which part of the paper this concern relates to, such as the introduction, literature review, or results section. This lack of grounding makes it difficult for the authors to identify the exact area needing attention. The comment is specific in its critique of novelty but lacks grounding, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution of the work is somewhat incremental compared to prior work. However, it does not provide specific examples or detailed comparisons to support this claim. The mention of prior work by von Kugelgen et al. (2021) and Daunhawer et al. (2023) is a starting point, but without further elaboration or analysis, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the novelty of the work, suggesting that the technical contribution is somewhat incremental compared to prior work. While it identifies a potential issue, it lacks specific examples or detailed analysis to support this claim. Without actionable suggestions or guidance on how to enhance the novelty or address the incremental nature of the contribution, the comment provides limited value to the authors. It highlights an area for improvement but does not offer a clear path forward, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the performance of PromptMix depends on the quality of questions/answers generated by the LLM and recommends an analysis on this aspect. It explicitly suggests considering open-source LLMs that could work with this approach and proposes a parameter count cutoff (7B) below which performance might degrade. This provides clear and concrete actions for the authors to take, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the performance of PromptMix depends on the quality of questions/answers generated by the LLM and recommends an analysis on this aspect. It provides specific suggestions, such as considering open-source LLMs or a parameter count cutoff, to help the authors improve their work. However, it does not explicitly mention which part of the paper this comment addresses, making it weakly grounded. The comment is specific in detailing what needs to be addressed, so it aligns with the label \"Weakly Grounded and Specific.\"', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the performance of PromptMix depends on the quality of questions/answers generated by the LLM, implying that a high-quality model is essential for success. The comment provides a logical reasoning by stating that an analysis of this dependency would be beneficial, such as identifying suitable open-source LLMs or a parameter count cutoff below which performance might degrade. This reasoning is clear and provides a direction for further investigation, making the claim mostly verifiable. However, the comment could be strengthened by including specific examples or references to support the claim, which would align it with a higher level of verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical aspect of the performance of PromptMix, noting that its success depends on the quality of questions/answers generated by the LLM. It suggests that an analysis of this dependency would be beneficial, including an examination of open-source LLMs that could work with this approach and a parameter count cutoff below which performance might degrade. This feedback is clear and actionable, providing the authors with specific directions for improving their draft by addressing a key factor influencing the performance of their method. The comment is highly helpful as it offers detailed guidance on how to enhance the paper\\'s content and analysis, making it a valuable resource for the authors.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should comment on the feasibility of the submodularity approach subroutine, specifically the SATURATE algorithm by Krause et al. (2008), which is claimed to scale with N^5. The comment implies that the authors should provide more information about the runtimes of the simulations for large models in Section 6. While the action is implicit, it is concrete in suggesting what specific information should be included to address the feasibility concern. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"appendix D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests commenting on the feasibility of the submodularity approach subroutine, particularly the SATURATE algorithm, and requests information about the runtimes of simulations for large models in Section 6. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the complexity of the submodularity approach subroutine, specifically the SATURATE algorithm, and its scalability. It suggests that the authors should comment on the feasibility of this approach, particularly in the context of large models. The comment is somewhat verifiable as it provides a specific reference to the algorithm and its claimed scalability, but it lacks detailed evidence or examples of how the scalability issue might impact the simulations in Section 6. While the suggestion is logical, it could be strengthened with more detailed reasoning or references to support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the complexity of the submodularity approach subroutine, specifically the use of the SATURATE algorithm, which is claimed to scale with N^5. It suggests that the authors should comment on the feasibility of this approach, particularly in the context of large models. The comment also requests specific information about the runtimes of simulations for large models in Section 6. This feedback is clear and actionable, as it directs the authors to address a specific concern about the scalability of their approach and provides a concrete suggestion for additional information to include. However, the comment could be more helpful if it offered further guidance on how to address the scalability issue or provided examples of similar approaches that have been successfully scaled. Overall, the comment is mostly helpful, as it provides valuable insights and actionable feedback for the authors to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the explanation of inference at test time is brief and could be improved with more details. However, it does not provide specific guidance on what additional details should be included or how the authors might enhance the explanation. The action is implicit, as the authors need to infer that they should add more details, and it is vague, as the comment lacks concrete suggestions on what those details should be. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"594,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need for more detailed explanation of inference at test time. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the explanation of inference at test time is brief and could benefit from more details. However, it does not provide any specific examples or reasoning to support why additional details are necessary or how they would improve the paper. Without such evidence or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting that the explanation of inference at test time is brief and could benefit from more details. This feedback is clear and actionable, as it directs the authors to enhance their explanation to provide a better understanding of the inference process. However, the comment could be more helpful if it offered specific suggestions on what additional details should be included or how to present them. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the correctness and soundness of the paper, specifically regarding the evaluation of programs generated by CodeChain, the effectiveness of sub-module generation, and the analysis of self-revision performance. However, it does not provide explicit or implicit actions for the authors to take to address these concerns. The comments are more descriptive of issues rather than prescriptive of how to improve the draft. As a result, the authors are left without clear guidance on how to address these concerns, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses several specific aspects of the paper, including the evaluation of programs generated by CodeChain, the effectiveness of sub-module generation, and the analysis of self-revision performance. However, it does not explicitly mention which sections of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what is unclear or lacking in each of these areas, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims about the evaluation of programs generated by CodeChain, the effectiveness of sub-module generation, and the analysis of self-revision performance. However, it lacks specific evidence or references to support these claims, such as detailed comparisons or examples of how the evaluation aligns with human preference or how the effectiveness of sub-module generation is measured. The comment provides some logical reasoning, but it is not fully verifiable due to the absence of concrete data or references. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several areas of concern regarding the evaluation and effectiveness of the CodeChain system. It questions the alignment of the evaluation with human preference, the clarity of sub-module generation effectiveness, and the analysis of self-revision performance, which shows a slight drop in performance after the 5th iteration. While the comment highlights important issues that need to be addressed, it lacks specific suggestions or guidance on how the authors might improve these aspects. The feedback is somewhat helpful as it points out areas for improvement but does not provide detailed actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the interpretation of the results presented in lines 306-307, specifically regarding the accuracy and fairness of the deferring classifier. It prompts the authors to clarify whether the observed higher overall accuracy at a given minimum subgroup accuracy (MSA) implies that the error rates are less evenly distributed among subgroups, potentially indicating less fairness. While the comment does not explicitly instruct the authors to make changes, it provides a clear direction for further analysis and clarification. The authors can infer that they need to address this interpretation and potentially provide additional analysis or discussion to clarify the fairness implications. The action is implicit but concrete, as it guides the authors toward a specific area of investigation. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 306-307,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the interpretation of the results regarding the accuracy and fairness of the deferring classifier, prompting the authors to clarify whether the observed higher overall accuracy at a given minimum subgroup accuracy (MSA) implies that the error rates are less evenly distributed among subgroups, potentially indicating less fairness. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the interpretation of the results presented in lines 306-307, specifically regarding the accuracy and fairness of the deferring classifier. It questions whether the observed higher overall accuracy at a given minimum subgroup accuracy (MSA) implies that the error rates are less evenly distributed among subgroups, potentially indicating less fairness. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or analysis, the authors may find it challenging to address the question effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical question about the interpretation of the results presented in lines 306-307, specifically regarding the accuracy and fairness of the deferring classifier. It challenges the authors to clarify whether the observed higher overall accuracy at a given minimum subgroup accuracy (MSA) implies that the error rates are less evenly distributed among subgroups, potentially indicating less fairness. This feedback prompts the authors to reconsider their interpretation and potentially provide additional analysis or discussion to address the fairness implications. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how to analyze the fairness of the deferring classifier. Overall, the comment is somewhat helpful as it identifies a potential area for clarification and improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should report the improvement in object classification results in addition to the overall scene graph results. This is a clear and direct action for the authors to take, as it provides a specific suggestion on how to strengthen the paper\\'s case. The comment is concrete in its guidance, leaving no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L107,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim about the relational embedding module improving object classification, noting the lack of results to support this claim. The comment suggests that reporting the improvement on object classification directly, in addition to the overall scene graph results, would strengthen the paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks evidence to support the claim that the relational embedding module significantly improves object classification. The reviewer suggests that reporting the improvement on object classification directly, in addition to the overall scene graph results, would strengthen the paper. This claim is somewhat verifiable as it highlights a potential gap in the paper\\'s presentation of results. However, the comment lacks specific examples or references to support the claim that the current results are insufficient. Providing more detailed reasoning or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely that it claims the relational embedding module significantly improves object classification without providing any results to support this claim. The reviewer suggests that reporting the improvement on object classification directly, in addition to the overall scene graph results, would strengthen the paper. This feedback is clear and actionable, providing the authors with a specific area to address and a concrete suggestion for improvement. By following this advice, the authors can enhance the credibility and comprehensiveness of their results, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a critique of the paper\\'s scope, noting that while the idea is interesting, it is relatively narrow and builds upon existing work in hypergraph attention networks for multimodal learning. The reviewer suggests that the novelty of the manuscript lies in adding self-supervised learning on top of existing work, but this novelty is considered small. However, the comment does not offer any explicit or implicit actions for the authors to take to address these concerns or improve their work. It lacks guidance on how to enhance the scope or novelty of the paper, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a general critique of the paper\\'s scope and novelty, comparing it to existing work in hypergraph attention networks for multimodal learning. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure. The authors can make an educated guess that it relates to the methodology or results sections, but the comment lacks full grounding. Additionally, while it highlights the lack of novelty, it does not specify what aspects of the paper could be improved or expanded upon. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the novelty of the manuscript is relatively small, as it primarily adds self-supervised learning on top of existing work in hypergraph attention networks for multimodal learning. The reviewer supports this claim by referencing a specific paper from CVPR 2020, which explores hypergraph attention networks for multimodal learning. This reference provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or examples of how the current work builds upon or differs from the referenced paper. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a critique of the paper\\'s scope and novelty, noting that while the idea is interesting, it is relatively narrow and builds upon existing work in hypergraph attention networks for multimodal learning. The reviewer references a specific paper from CVPR 2020, which explores similar concepts, and suggests that the novelty of the manuscript lies in adding self-supervised learning on top of existing work. However, the comment does not offer any actionable suggestions or guidance on how the authors might enhance the scope or novelty of their work. While it highlights a potential weakness, it lacks depth and does not provide constructive feedback for improvement. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the difficulty of finding intuitive attention examples, as illustrated in Figure 4. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or suggestions for improvement. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the difficulty of finding intuitive attention examples, specifically referencing Figure 4. However, it does not specify what aspect of Figure 4 is being questioned or what specific issue needs to be addressed. The authors can infer that it relates to the visual representation or interpretation of attention examples, but the comment lacks detailed guidance on how to improve this aspect. Therefore, the comment is weakly grounded as it does not explicitly mention a specific section or part of the paper, and it is not specific in detailing what needs to be addressed. This aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point is a question asking about the difficulty of finding intuitive attention examples, as illustrated in Figure 4. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the difficulty of finding intuitive attention examples, as illustrated in Figure 4. While it identifies a potential issue with the clarity or effectiveness of the examples, it does not provide any specific suggestions or guidance on how the authors might address this concern. The comment lacks actionable feedback, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, it is barely helpful, as it identifies a potential issue but does not offer any actionable advice for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the difference between \"01\" and \"10\" in Figure 1, but it does not provide any explicit or implicit action for the authors to take. It lacks guidance on how the authors should address this question or what specific changes they should make to their draft. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the difference between \"01\" and \"10\" in the figure, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the difference between \"01\" and \"10\" in Figure 1. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the difference between \"01\" and \"10\" in Figure 1, indicating a potential area of confusion or lack of clarity in the figure. While it highlights a specific issue that the authors should address, it does not provide any suggestions or guidance on how to clarify or improve the figure. The feedback is somewhat helpful as it points out a specific area for improvement, but it lacks depth and actionable advice, making it incomplete. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to keep a separate \"Related Work\" section and suggests shifting three bullet points (\"Traditional AES\", \"Deep Neural AES\", and \"Pre-training AES\") from the \"Introduction\" section to the \"Related Work\" section. This feedback is clear and provides a direct action for the authors to take, ensuring they know exactly what changes to make to their draft. The suggestion is concrete and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Introduction\" section and the specific bullet points (\"Traditional AES\", \"Deep Neural AES\", and \"Pre-training AES\") that need to be moved to the \"Related Work\" section. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the relocation of the related work bullet points. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the \"Introduction\" section should be separated from the \"Related Work\" section, as it currently contains a mix of introductory paragraphs and bullet points of related work. The reviewer provides specific examples of the related work bullet points (\"Traditional AES\", \"Deep Neural AES\", and \"Pre-training AES\") that should be moved to the \"Related Work\" section. This feedback is clear and actionable, providing a concrete suggestion for improvement. However, it does not include any additional reasoning or evidence beyond the suggestion itself. Therefore, the comment is mostly verifiable, as it provides a clear direction for improvement but lacks further elaboration or references to support the claim.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting that the \"Introduction\" section should be separated from the \"Related Work\" section. It identifies a specific issue where the current structure mixes introductory paragraphs with bullet points of related work, and it offers a concrete suggestion to move the related work bullet points to a dedicated \"Related Work\" section. This feedback is helpful as it guides the authors on how to improve the organization and clarity of their paper, making it easier for readers to follow. However, the comment could be more helpful if it provided additional context or examples of how this reorganization might enhance the paper\\'s structure and readability. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper spends a significant amount of space describing rules and data augmentation methods for constructing the benchmark, but suggests that the overall process and rationale for construction could be presented more clearly. While the comment implies that the authors should improve the clarity of the process and rationale, it does not provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer that they need to enhance the clarity of the process and rationale without detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could present the overall process and rationale for constructing the benchmark more clearly, despite dedicating significant space to describing rules and data augmentation methods. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in its suggestion to improve clarity, but without clear grounding, the authors may find it challenging to identify the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could present the overall process and rationale for constructing the benchmark more clearly, despite dedicating significant space to describing rules and data augmentation methods. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it somewhat verifiable. The authors would need to infer the exact areas that require clarification, which could be challenging without further guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the paper, specifically noting that while it dedicates significant space to describing rules and data augmentation methods, the overall process and rationale for constructing the benchmark could be presented more clearly. This feedback is somewhat helpful as it points out an area where the paper could be improved, suggesting that the authors should enhance the clarity of their explanation. However, the comment lacks specific suggestions or guidance on how to achieve this clarity, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant lack of content in the paper, specifically mentioning the absence of a comprehensive literature review of recent advances in active learning communities, particularly in the context of Bayesian learning. It points out the omission of relevant works like Bayesian Coreset, which is directly relevant to the paper, and suggests discussing how the current setup is more advanced than related studies. While the comment identifies areas that need improvement, it does not provide explicit instructions on how to incorporate these suggestions into the draft. The authors are left to infer that they should expand the literature review and discuss the advancements in the field. The action is implicit and somewhat vague, as it lacks concrete guidance on how to implement these changes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of content in the paper, specifically highlighting the absence of a comprehensive literature review of recent advances in active learning communities, particularly in the context of Bayesian learning. It also references specific works like Bayesian Coreset, which is directly relevant to the paper, and suggests discussing how the current setup is more advanced than related studies. This provides clear guidance on what needs to be addressed in the literature review section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks content, specifically citing the absence of a comprehensive literature review of recent advances in active learning communities, particularly in the context of Bayesian learning. It mentions the omission of relevant works like Bayesian Coreset and suggests discussing how the current setup is more advanced than related studies. The comment provides specific examples and references to external works, such as [1] and [2], which supports the claim and provides a clear direction for improvement. However, the comment could be strengthened by providing more detailed reasoning or examples of how the current setup is more advanced. Overall, the claim is mostly verifiable, as it is well-supported but could benefit from additional details. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of a comprehensive literature review of recent advances in active learning communities, particularly in the context of Bayesian learning. It highlights the omission of relevant works like Bayesian Coreset, which is directly relevant to the paper, and suggests discussing how the current setup is more advanced than related studies. This feedback is valuable as it points out a critical area for improvement, providing the authors with a clear direction to enhance the literature review and contextualize their work within the existing body of research. However, the comment could be more helpful if it offered specific suggestions on how to incorporate these references or discussed potential ways to differentiate the current work from existing studies. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the depth and relevance of their literature review.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific issue with Figure 2, noting that the \"one-to-many relationship\" in the plot makes it difficult to understand the presented trends and that the plots contain a considerable amount of noise. This feedback provides a clear and direct action for the authors to take: they should improve the clarity of Figure 2 by addressing the noise and ensuring that the trends are more easily understandable. The comment is explicit and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the \"one-to-many relationship\" in the plot, which makes it hard to understand the presented trends, and notes that the plots contain a considerable amount of noise. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"one-to-many relationship\" in Figure 2 makes it difficult to understand the presented trends and that the plots contain a considerable amount of noise. However, the comment does not provide any specific examples, reasoning, or references to support these claims. Without detailed justification or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 2, noting that the \"one-to-many relationship\" in the plot makes it difficult to understand the presented trends and that the plots contain a considerable amount of noise. This feedback is clear and actionable, as it provides a direct suggestion for improvement by indicating that the authors should address the noise and ensure the trends are more easily understandable. However, the comment could be more helpful if it offered suggestions on how to achieve this, such as recommending data smoothing or filtering techniques. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of comparing the speedup of DFSSATTEN with existing algorithms like Performer and Reformer, given that these algorithms are not deeply optimized. It also questions whether DFSSATTEN supports training from scratch, a significant direction in the field, and suggests that it would be beneficial if DFSSATTEN could accelerate training from scratch. However, the comment does not provide explicit instructions or concrete suggestions on how the authors should address these issues or conduct further research. The action is implicit and somewhat vague, as the authors are left to infer that they should explore the possibility of training from scratch and potentially compare it with existing methods. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"introduction\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of fairness in comparing DFSSATTEN with existing algorithms like Performer and Reformer, and it raises a question about whether DFSSATTEN supports training from scratch, a significant direction in the field. The comment provides a clear suggestion for further study, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the speedup of DFSSATTEN being mostly due to low-level optimization and hardware support, and questions the fairness of comparing it with existing algorithms like Performer and Reformer. The reviewer also points out that the authors argue these methods are usually trained from scratch, which is a significant direction in the field, and suggests that DFSSATTEN should be evaluated for its ability to accelerate training from scratch. While the comment provides some logical reasoning and references to existing methods, it lacks specific examples or detailed evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed support for a stronger justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the fairness of comparing the speedup of DFSSATTEN with existing algorithms like Performer and Reformer, given that these algorithms are not deeply optimized. It also questions whether DFSSATTEN supports training from scratch, a significant direction in the field, and suggests that it would be beneficial if DFSSATTEN could accelerate training from scratch. This feedback is somewhat helpful as it identifies a potential weakness in the comparison and suggests a direction for further research. However, it lacks specific guidance on how the authors might address these issues or conduct the additional research, which would make the feedback more actionable. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point mentions that VMI-SI-TI-DI-FDSM was evaluated on a black-box setting when their method was evaluated on a defended model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or what changes should be made to the draft. As a result, the authors are left without any actionable steps to improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to \"VMI-SI-TI-DI-FDSM\" and mentions that it was evaluated on a black-box setting when their method was evaluated on a defended model. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in detailing the evaluation setting, but without clear grounding, the authors may struggle to identify the exact section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that VMI-SI-TI-DI-FDSM was evaluated on a black-box setting when their method was evaluated on a defended model. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a specific evaluation setting for VMI-SI-TI-DI-FDSM, noting that it was examined on a black-box setting when their method was evaluated on a defended model. However, the comment does not provide any context, explanation, or suggestions for improvement. It lacks depth and does not offer actionable feedback or guidance for the authors to address the issue or enhance their draft. As a result, the comment is barely helpful, as it identifies a potential area of concern but does not provide sufficient information for the authors to make meaningful improvements.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the clarity of the proposed method\\'s description could be improved, and it directs the authors to refer to the questions section for details. While the comment implies that the authors should enhance the clarity of their method\\'s description, it does not provide specific guidance on how to achieve this improvement. The action is implicit and somewhat vague, as the authors are not given explicit instructions on what changes to make or how to improve the clarity. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the clarity of the proposed method\\'s description could be improved, but it does not specify which part of the paper this issue pertains to. It directs the authors to refer to the questions section for details, but without explicit references or specific guidance, the authors cannot confidently determine which sections need improvement. This makes the comment weakly grounded, as the authors cannot pinpoint the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the description need improvement. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the clarity of the proposed method\\'s description could be improved, but it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the clarity of the proposed method\\'s description could be improved, directing the authors to refer to the questions section for details. However, it lacks specificity and does not provide actionable guidance on how to enhance the clarity or what specific aspects of the description need improvement. Without detailed feedback or suggestions, the authors may find it challenging to address the issue effectively. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer sufficient guidance for the authors to make meaningful changes.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the independence of pruning strategies across different layers in the GNN and suggests that if an edge is pruned in one layer, it should also be considered for pruning in other layers. The comment asks for an explanation or observation regarding this potential correlation in the empirical evaluations. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation or discuss the correlation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the independence of pruning strategies across different layers in the GNN and suggests that if an edge is pruned in one layer, it should also be considered for pruning in other layers. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for an explanation or observation regarding the potential correlation in the empirical evaluations. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the independence of pruning strategies across different layers in the GNN and suggests that if an edge is pruned in one layer, it should also be considered for pruning in other layers. The comment is based on a logical inference and does not contain subjective opinions or claims that require verification. It is a factual question seeking clarification or an explanation, making it a normal statement. Therefore, the label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the independence of pruning strategies across different layers in the GNN. It suggests that if an edge is pruned in one layer, it should also be considered for pruning in other layers, which is a logical and intuitive observation. The comment prompts the authors to consider whether such correlations are addressed in the empirical evaluations or if there is an explanation for why they are not considered. This feedback is clear and actionable, as it directs the authors to explore and discuss this potential correlation, which could enhance the comprehensiveness and depth of their analysis. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or examples of how it might impact the results. Overall, the comment is mostly helpful, as it provides a valuable direction for improvement but could be more detailed in its guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the experimental validation, noting that it only considers CIFAR-10/100 as in-distribution data and questions whether the conclusions would generalize to other in-distribution datasets. The reviewer acknowledges that this might be customary, framing their comment as a genuine question rather than a weakness. While the comment highlights an area of concern, it does not provide explicit guidance or suggestions on how the authors might address this issue or expand their experimental validation. The action is implicit and somewhat vague, as the authors are left to infer that they should consider broader in-distribution datasets but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental validation section, specifically mentioning the use of CIFAR-10/100 as in-distribution data. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment raises a concern about the generalizability of the conclusions to other in-distribution datasets, which is specific and provides a clear direction for the authors to consider. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the experimental validation, noting that it only considers CIFAR-10/100 as in-distribution data and questions whether the conclusions would generalize to other in-distribution datasets. The reviewer acknowledges that this might be customary, framing their comment as a genuine question rather than a weakness. However, the comment lacks specific examples or references to support the claim that the conclusions might not generalize. This makes the claim somewhat verifiable, as it provides a logical reasoning but lacks detailed evidence or examples to fully substantiate the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the experimental validation, noting that it only considers CIFAR-10/100 as in-distribution data. It questions whether the conclusions would generalize to other in-distribution datasets, which is a critical point for the authors to consider. The comment is framed as a genuine question rather than a weakness, which is helpful in encouraging the authors to explore this aspect further. However, the comment could be more helpful if it provided specific suggestions or examples of other datasets that could be used for validation. Overall, the comment is somewhat helpful as it prompts the authors to consider a potential limitation in their experimental setup, but it could be more actionable with additional guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should show the gradient conflicts ratio for AlphaNets trained with alpha-divergence to provide insights. This is an explicit action with a clear suggestion on what additional information should be included in the paper. The comment provides a specific and concrete direction for the authors to follow, making it highly actionable. The authors know exactly what they need to do to address the comment, which is to include the gradient conflicts ratio for AlphaNets trained with alpha-divergence. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests showing the gradient conflicts ratio for AlphaNets trained with alpha-divergence to provide insights. This provides clear guidance on what additional information could be included to address the issue. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that AlphaNets trained with alpha-divergence do not benefit from the method, and it recommends showing the gradient conflicts ratio to provide insights. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that AlphaNets do not benefit from the method. Without additional context or justification, the claim remains unverifiable, as the authors would need more information to understand and address the issue effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results presented in Table 8, suggesting that AlphaNets trained with alpha-divergence do not benefit from the method. It provides a constructive suggestion by recommending that the authors show the gradient conflicts ratio for this specific case to offer insights. This feedback is actionable and offers a clear direction for the authors to improve their analysis and presentation of results. However, the comment could be more helpful if it provided additional context or examples of how the gradient conflicts ratio could be used to better understand the results. Overall, the comment is mostly helpful as it guides the authors toward a specific improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the explicit SDF supervision in Section 3.2, specifically questioning the need for occlusion handling and view-awareness. The reviewer suggests that a simpler approach could be used, where a subset of the sparse point cloud is sampled and the loss is applied without occlusion reasoning. The comment implies that the authors should provide a good reason or conduct an ablation study to justify the current complicated setup. While the action is implicit, it is concrete in suggesting a potential simplification and the need for justification or an ablation study. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 3.2\" and specific line numbers (\"L. 165\", \"L. 173\", and \"L. 177 - 178\"), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the explicit SDF supervision, questioning the need for occlusion handling and view-awareness, and suggesting a simpler approach. The comment further suggests that a good reason or ablation study is missing to justify the current setup. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of explicit SDF supervision with occlusion handling and view-awareness, suggesting a simpler approach. The reviewer provides a logical reasoning by stating that the current setup seems complicated and that a subset of the sparse point cloud could be sampled without occlusion reasoning. However, the comment lacks specific references or examples to support the claim that the current setup is overly complicated or that the suggested alternative is simpler. This makes the claim somewhat verifiable, as it provides a logical argument but requires further elaboration or evidence to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the explicit SDF supervision in Section 3.2, questioning the necessity of occlusion handling and view-awareness. It suggests a simpler approach where a subset of the sparse point cloud is sampled and the loss is applied without occlusion reasoning. The comment also implies that a good reason or ablation study is missing to justify the current complicated setup. This feedback is clear and actionable, as it provides a specific suggestion for simplification and highlights the need for additional justification or analysis. However, it could be more helpful if it included specific examples or further elaboration on how the suggested approach could be implemented. Overall, the comment is mostly helpful, as it directs the authors to a potential area of improvement with a clear suggestion for simplification and additional analysis.', 'helpfulness_label': '4'}"}
