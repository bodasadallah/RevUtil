{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the choice of operators used in the paper, specifically asking why the \"and\" operator or elementwise max were not considered. While the comment does not explicitly instruct the authors to include these operators or explain their reasoning, it implies that the authors should provide a justification for their choice. The action is implicit and somewhat vague, as the authors need to infer that they should address the question of why certain operators were chosen over others. However, the comment provides a clear direction for the authors to consider alternative operators and their implications, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 261 and 272, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the choice of operators and suggests considering the \"and\" operator or elementwise max, providing a clear direction for improvement. The comment explains the reasoning behind the suggestion, noting the correspondence between these operators and the concepts of union and intersection. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of operators used in the paper, specifically asking why the \"and\" operator or elementwise max were not considered. The reviewer provides a logical reasoning by suggesting that these operators correspond to the ideas of union and intersection from the \"or\" operator and elementwise min, respectively. However, the comment lacks specific examples or references to support the claim that these operators were overlooked or would have been better choices. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3, as the authors may need to infer the relevance of these operators based on the provided logic.", "helpfulness_rationale": "The review comment raises a specific question about the choice of operators used in the paper, specifically asking why the \"and\" operator or elementwise max were not considered. It provides a logical connection between these operators and the concepts of union and intersection, suggesting that the chosen operators may not be the best options. This feedback is clear and actionable, as it prompts the authors to consider alternative operators and provide a justification for their choice. By addressing this point, the authors can enhance the clarity and comprehensiveness of their work. Therefore, the comment is 4, as it offers a constructive suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential inconsistency in the paper regarding the source of the data used. It suggests that the authors should clarify the origin of the data by mentioning Li et al. (2019a) earlier in the description. This feedback provides a clear and explicit action for the authors to take, which is to revise the description to ensure clarity and precision. The suggestion is concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (226238 and 242244) where the issue is identified, allowing the authors to accurately pinpoint the parts of the paper being addressed. It is also specific because it details the inconsistency regarding the source of the data and suggests a revision to clarify the description by mentioning Li et al. (2019a) earlier. This provides clear guidance on what needs to be addressed to improve the clarity and precision of the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point identifies a potential inconsistency in the paper regarding the source of the data. It suggests that the description could be clarified by mentioning Li et al. (2019a) earlier. The comment provides a logical reasoning for the suggestion, pointing out the apparent contradiction between the lines mentioned. However, it does not provide specific examples or references to support the claim further. While the reasoning is clear, the lack of additional evidence or detailed examples makes the claim 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the paper regarding the source of the data used. It points out that the authors seem to suggest selecting sentences from raw data, but later mention that the data already has syntactic information. The reviewer suggests revising the description to clarify this by mentioning Li et al. (2019a) earlier. This feedback is clear and actionable, providing the authors with a specific direction to improve the clarity and precision of their paper. By addressing this inconsistency, the authors can enhance the readability and accuracy of their work. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the purpose of the average duration reported in Table 1 and asks for clarification on whether it includes time spent by the user waiting for the model to generate a response. While the comment implies that the authors should provide an explanation for the average duration, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide an explanation but are not given specific guidance on how to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of the average duration reported in Table 1 and asks for clarification on whether it includes time spent by the user waiting for the model to generate a response. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the purpose of the average duration reported in Table 1 and asks for clarification on whether it includes time spent by the user waiting for the model to generate a response. This is a factual question seeking clarification, rather than a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the purpose of the average duration reported in Table 1, seeking clarification on whether it includes time spent by the user waiting for the model to generate a response. This feedback is clear and actionable, as it prompts the authors to provide an explanation for the reported average duration, which could be crucial for understanding the results. However, the comment could be more helpful if it suggested potential ways to address this issue or provided additional context for the authors to consider. Overall, the comment is 4 as it directs the authors to clarify an important aspect of their results, but it could be more comprehensive with further guidance or suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the interpretation of results presented in Table 3, specifically regarding the comparison of NVSB to GT Mel A for Chinese MOSQ and the overlap of 95% CI between Baseline and NVSB for Chinese and English MOSV. However, it does not provide any explicit or implicit actions for the authors to take. The questions are more about seeking clarification rather than suggesting changes or improvements to the draft. As a result, the comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to address the issues raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the interpretation of the results presented in the table, specifically regarding the comparison of NVSB to GT Mel A for Chinese MOSQ and the overlap of 95% CI between Baseline and NVSB for Chinese and English MOSV. This provides clear guidance on what aspects of the results need further clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification on the interpretation of results presented in Table 3. It does not contain any subjective opinions, claims, or suggestions that require verification. The questions are factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment raises specific questions about the interpretation of results presented in Table 3, specifically regarding the comparison of NVSB to GT Mel A for Chinese MOSQ and the overlap of 95% CI between Baseline and NVSB for Chinese and English MOSV. While it identifies areas where clarification is needed, it does not provide suggestions or guidance on how the authors might address these questions or improve the clarity of their results. The feedback is 3 as it points out areas that need further explanation, but it lacks actionable advice or depth, making it incomplete for the authors to fully address the issues. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a formatting issue in Tables 2 and 3, noting that some items have spaces between accuracy and standard deviation, while others do not. This inconsistency affects the appearance of the tables. However, the comment does not provide explicit guidance on how to address this issue, such as suggesting a consistent formatting approach or offering examples of how to standardize the layout. The action is implicit and somewhat vague, as the authors can infer that they need to standardize the formatting but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of inconsistent spacing between accuracy and standard deviation in these tables, which affects their appearance. This provides clear guidance on what needs to be addressed to improve the presentation of the data. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the inconsistent spacing between accuracy and standard deviation in Tables 2 and 3 affects the appearance of the tables. However, it does not provide any reasoning or evidence to support why this inconsistency is problematic or how it impacts the reader\"s understanding of the data. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting of Tables 2 and 3, noting that some items have spaces between accuracy and standard deviation, while others do not. This observation affects the appearance of the tables, which is an important aspect of presenting data effectively. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the formatting. While it highlights a potential problem, it lacks actionable feedback or constructive advice, making it 3. The authors are informed of a specific area for improvement but are left without detailed guidance on how to implement the change. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the organization of Section 3.2, noting that the explanations for features are intertwined and confusing. It suggests a clear and actionable solution by recommending the use of separate paragraphs for each type of feature, such as lexical features and sentencelevel features. This feedback provides explicit guidance on how to improve the organization and clarity of the section, making it 5. The authors know exactly what changes to make to enhance the coherence and readability of their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the explanations being intertwined and suggests a solution by recommending separate paragraphs for each type of feature. This provides clear guidance on how to improve the organization and clarity of the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanations for features in Section 3.2 are \"somewhat intertwined and thus confusing.\" However, it does not provide specific examples or detailed reasoning to support this claim. The suggestion to organize the section with separate paragraphs for each type of feature is a logical step, but without further elaboration or evidence, the claim remains somewhat vague. Therefore, the comment is rated as 3, as it provides some justification but lacks detailed support or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of Section 3.2, noting that the explanations for features are intertwined and confusing. It provides a clear and actionable suggestion by recommending the use of separate paragraphs for each type of feature, such as lexical features and sentencelevel features. This feedback is valuable as it offers a concrete way for the authors to improve the clarity and coherence of their draft. However, the comment could be more helpful if it included additional guidance on how to structure these separate paragraphs or provided examples of effective organization. Overall, the comment is 4, as it directs the authors toward a meaningful improvement but could be more comprehensive with further details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a positive assessment of the abstract, noting that it is wellwritten and intriguing. It suggests that the abstract could be improved by including an example of the inconsistency between evaluating with gold answers and human evaluation, such as models getting ranked differently. While the comment implies that the authors should add an example to enhance the abstract, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include an example to improve the abstract. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a suggestion for improvement by recommending the inclusion of an example to illustrate the inconsistency between evaluating with gold answers and human evaluation. The comment specifies what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point praises the abstract for being wellwritten and intriguing, suggesting that it could be improved by including an example of the inconsistency between evaluating with gold answers and human evaluation. However, the comment does not provide any specific examples or detailed reasoning to support the claim that the abstract could be improved in this manner. Without additional context or evidence, the authors may find it challenging to understand and address the suggestion. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a positive assessment of the abstract, noting that it is wellwritten and engaging. It suggests a potential improvement by recommending the inclusion of an example to illustrate the inconsistency between evaluating with gold answers and human evaluation. This feedback is clear and actionable, as it directs the authors to enhance the abstract by providing a concrete example to support their claims. However, the comment could be more helpful if it offered specific guidance on how to present the example or what kind of example would be most effective. Overall, the comment is 4 as it provides a constructive suggestion for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides two explicit actions for the authors to take. First, it instructs the authors to discuss the results for the task of inferring knowledge on objects, which is a clear and concrete action. Second, it suggests including results for model (B) and recommends using consistent terminology across tables. Additionally, the comment points out a specific issue with the terminology used in Tables 1 and 2, providing a concrete suggestion for improvement. The feedback is explicit and provides detailed guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific line numbers (\"681\" and \"778\") and references specific parts of the paper, allowing the authors to accurately identify the sections being addressed. It also provides specific suggestions for improvement, such as discussing results for the task of inferring knowledge on objects and including results for model (B), as well as recommending consistent terminology across tables. The comment is specific in detailing what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two separate claims. The first claim suggests that the authors should discuss results for the task of inferring knowledge on objects and include results for model (B). The second claim questions why objects are not mentioned in the context of \"latent in verbs.\" Both claims are factual and do not express opinions or judgments that require verification. They are descriptive in nature, making them \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback, addressing two distinct areas for improvement. First, it reminds the authors to discuss the results for the task of inferring knowledge on objects, which is a crucial aspect of the paper. Second, it suggests including results for model (B) and points out the inconsistency in terminology used across tables, recommending a correction. Additionally, the comment questions the absence of objects in the context of \"latent in verbs,\" prompting the authors to consider this aspect. The feedback is clear, specific, and provides concrete suggestions for enhancing the paper, making it 5 for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific sentence in line 212 that is not strictly correct and suggests a correction. It provides a clear and explicit action for the authors to take, which is to change the sentence to accurately reflect the use of a bidirectional encoder. The comment also offers a concrete suggestion by referencing Figure 2, providing a clear direction for the authors to follow. This level of detail and specificity makes the comment 5, as the authors know exactly what needs to be changed and how to implement the correction.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 212,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the sentence, suggesting a correction by explaining that a bidirectional encoder should be used to encode the source sentence into a set of vectors, rather than a single vector. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the sentence in line 212 is not strictly correct and suggests a correction. The reviewer provides a specific suggestion for improvement by recommending the use of a bidirectional encoder to encode the source sentence into a set of vectors, as seen in Figure 2. This feedback is clear and provides a logical basis for the claim, making it 4. However, the comment could be strengthened by explaining why the original statement is incorrect or providing additional context. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording of a sentence in the paper, pointing out that it is not strictly correct. It provides a clear and actionable suggestion for improvement by recommending the use of a bidirectional encoder to encode the source sentence into a set of vectors, as opposed to a single vector. This feedback is valuable as it helps the authors correct a potential misunderstanding and ensures the accuracy of their description. However, the comment could be more helpful if it explained why the original statement was incorrect or provided additional context. Overall, the comment is 4, as it offers a clear direction for improvement but could be expanded for greater impact."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part critiques the adopted baseline models as weak and suggests that the authors should compare their work with Campos et al. (2020), which also uses feedback in QA tasks. This is an explicit suggestion for improvement, as it clearly identifies a missing comparison that the authors should make. The second part points out a grammatical error in the text, suggesting a correction. Both parts provide concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 277,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a grammatical error and suggests a correction, providing clear guidance on what needs to be addressed. Additionally, the comment critiques the adopted baseline models, suggesting comparisons with Campos et al. (2020) and other domain adaptation methods, which further specifies the areas needing improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the adopted baseline models are weak and suggests comparisons with Campos et al. (2020) and other domain adaptation methods. However, the comment does not provide specific reasons or evidence to support why the baseline models are weak or why these comparisons are necessary. The mention of Campos et al. (2020) and other domain adaptation methods is a suggestion for improvement, but it lacks detailed justification or examples to substantiate the claim. Therefore, the comment is 3, as it provides a direction for improvement but lacks sufficient evidence or reasoning to fully support the claim.", "helpfulness_rationale": "The review comment identifies two main issues with the paper. First, it critiques the adopted baseline models as weak, suggesting that the authors should compare their work with Campos et al. (2020), which also uses feedback in QA tasks. This is a valuable suggestion for improving the paper by providing a more comprehensive comparison. Second, the comment points out a grammatical error in the text, suggesting a correction. Additionally, it highlights the absence of comparisons with other domain adaptation methods, which is an important aspect to address for a robust evaluation. However, the comment could be more helpful if it provided specific examples or references for the domain adaptation methods to be compared. Overall, the feedback is 4 as it identifies areas for improvement and offers actionable suggestions, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a specific change to the yaxis label in Figure 5, recommending the use of \"Exact Match ratio\" directly. This is an explicit action with clear guidance on what needs to be done to improve the draft. The authors know exactly what modification to make, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improving the figure by recommending the use of \"Exact Match ratio\" directly as the yaxis label. This level of detail gives the authors a precise understanding of what needs to be changed, making the comment 5.", "verifiability_rationale": "The review point suggests a change to the yaxis label in Figure 5, recommending the use of \"Exact Match ratio\" directly. However, the comment does not provide any reasoning or justification for why this change is necessary or how it would improve the clarity or accuracy of the figure. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of Figure 5 by recommending the use of \"Exact Match ratio\" directly as the yaxis label. This feedback is clear and concise, offering a straightforward way for the authors to enhance the readability and understanding of their results. However, the comment could be more helpful if it explained why this change is necessary or how it would impact the interpretation of the figure. Despite this, the suggestion is actionable and provides a clear direction for improvement, making the comment 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the lack of strong baselines in Table 3, specifically mentioning the baselines in reference 1. It asks the authors to justify the reason for not including these baselines. While the comment implies that the authors should provide a justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification and are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of strong baselines in the table, such as those mentioned in reference 1, and asks for a justification for this omission. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the absence of strong baselines in Table 3, specifically mentioning the baselines in reference 1. This is a claim that requires justification, as it suggests that the current set of baselines is incomplete. However, the comment does not provide any reasoning or evidence to support why these baselines should be included or why their absence is significant. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting that it lacks strong baselines, such as those mentioned in reference 1. It asks the authors to justify the reason for this omission, which is a clear and actionable request for improvement. By pointing out the absence of relevant baselines, the comment provides the authors with a specific area to address and a direction for enhancing the comprehensiveness of their work. However, the comment could be more helpful if it suggested which specific baselines should be included or how they could be integrated into the analysis. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides two explicit actions for the authors to take. First, it suggests adding information about the input being word embeddings, similar to Lample et al., in section 2.3. This is a clear and concrete action that the authors can take to enhance their draft. Second, it questions whether the KNs in Figure 3 are in the source language or in English, as the mentions have been translated to English. This is also a direct and actionable suggestion that the authors can address by clarifying the figure. Additionally, the comment acknowledges that the authors have already stated they will correct the figure, which is a positive note. Overall, the comment is 5 as it provides explicit and concrete actions for the authors to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2.3\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as adding information about the input being word embeddings and clarifying whether the KNs in Figure 3 are in the source language or in English. The comment provides clear guidance on what needs to be improved, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should add information about the input being word embeddings, similar to Lample et al., in section 2.3. It also questions whether the KNs in Figure 3 are in the source language or in English, as the mentions have been translated to English. The comment provides a logical suggestion for improvement and raises a question that requires clarification. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the importance of this suggestion and the potential impact on the clarity of their work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback, addressing two distinct areas for improvement. First, it suggests adding information about the input being word embeddings, similar to Lample et al., in section 2.3, which could enhance the clarity of the paper. Second, it questions whether the KNs in Figure 3 are in the source language or in English, as the mentions have been translated to English. This feedback is clear and actionable, guiding the authors on how to improve the accuracy and comprehensiveness of their work. Additionally, the comment acknowledges that the authors have already stated they will correct the figure, which is a positive note. Overall, the comment is 5 as it offers detailed and constructive suggestions for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the text, indicating that lines 102106 are misleading. It points out that while the intersection and probabilities are true, the phrase \"such distribution\" cannot refer to the discussion above. However, the comment does not provide explicit guidance on how to address this issue or suggest specific changes to clarify the text. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the reference, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 102106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, indicating that the phrase \"such distribution\" cannot refer to the discussion above. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that lines 102106 are misleading, specifically regarding the phrase \"such distribution.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why this claim is valid. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the text, pointing out that lines 102106 are misleading. It highlights that while the intersection and probabilities are true, the phrase \"such distribution\" cannot refer to the discussion above. This feedback is clear and actionable, as it directs the authors to clarify the reference to \"such distribution\" to ensure accuracy and coherence in their text. However, the comment could be more helpful if it provided suggestions on how to rephrase or clarify the text. Overall, the comment is 4 as it effectively points out a potential issue and guides the authors toward improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that a number of claims in the paper would benefit from more indepth analysis. However, it does not specify which claims are in need of further analysis or provide guidance on how the authors might conduct this analysis. The action is implicit and vague, as the authors are left to infer which claims require more depth and how to achieve it. Without explicit instructions or examples, the authors may struggle to determine the exact steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that a number of claims in the paper would benefit from more indepth analysis. However, it does not specify which claims are being referred to or provide any details on what aspects of the analysis are lacking. This makes it difficult for the authors to identify the exact parts of the paper that need improvement. The comment lacks both grounding and specificity, as it does not provide any clear guidance or reference to specific sections or elements of the paper. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a number of claims in the paper would benefit from more indepth analysis. However, it does not specify which claims are being referred to or provide any supporting evidence or reasoning to justify this claim. Without specific examples or detailed explanation, the authors may find it challenging to understand which claims need further analysis and how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that several claims in the paper would benefit from more indepth analysis. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which claims are in need of further analysis or how the authors might conduct this analysis. Without detailed suggestions or examples, the authors are left with a general idea of what might need more attention but without actionable steps to take. Therefore, the comment is 2, as it provides minimal guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies two areas that need improvement in the presentation of the model. It asks for clarification on the pooling method used for embedding features (line 397) and requests a clearer definition of the variables in Equation (7), specifically whether E_i represents the type or identity of AC i. Additionally, it suggests that the lefthand side of Equation (7) should be a conditional probability. These explicit requests provide clear and concrete actions for the authors to take, ensuring they know exactly what needs to be addressed and how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (lines 397 and 472) and equations (Equation 7), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, such as clarifying the pooling method used for embedding features and defining the variables in Equation (7). Additionally, it suggests that the lefthand side of Equation (7) should be a conditional probability. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several specific questions and concerns about the presentation of the model, including the pooling method used for embedding features and the clarity of Equation (7). It provides detailed requests for clarification, such as defining whether E_i represents the type or identity of AC i and suggesting that the lefthand side of Equation (7) should be a conditional probability. These requests are logical and provide a clear basis for the reviewer\"s concerns, making the comment 4. However, the comment could be strengthened by providing more context or references to support the claims, which would make it 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies two specific areas that need improvement in the presentation of the model. It asks for clarification on the pooling method used for embedding features, which is a clear and actionable request. Additionally, it raises a question about the clarity of Equation (7), specifically whether E_i represents the type or identity of AC i, and suggests that the lefthand side of the equation should be a conditional probability. These points are welldefined and provide the authors with concrete guidance on how to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional context. Overall, the feedback is 4 as it directs the authors to specific areas that require attention, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the hypotheses presented in the paper and the actual content of the paper. It suggests that the hypotheses are not optimally phrased and could be tested as given, but notes that the paper does not actually study these hypotheses. The reviewer also expresses a desire for the paper to delve deeper into the respective topics. While the comment identifies an issue and suggests a potential improvement, it does not provide explicit guidance on how to address the problem or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer that they should rephrase the hypotheses and potentially expand the discussion on the topics. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 078086,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the phrasing of the hypotheses about multilinguality and country/languagespecific bias, and the lack of actual study or discussion of these hypotheses. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper raises hypotheses about multilinguality and country/languagespecific bias but does not actually study these hypotheses. The reviewer suggests that the hypotheses are not optimally phrased and could be tested as given. However, the comment lacks specific examples or references to support the claim that the hypotheses are not studied or discussed further in the paper. This makes it 3, as the authors would need to review their paper to understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it raises hypotheses about multilinguality and country/languagespecific bias but does not actually study or discuss these hypotheses further. The reviewer points out that this is misleading and suggests that the paper should delve deeper into these topics. This feedback is valuable as it highlights a critical gap in the paper\"s content and provides a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to address this issue, such as proposing additional experiments or analyses. Overall, the comment is 4 as it directs the authors\" attention to a crucial area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include the maximum number of tasks done by any annotator. This is an explicit action that provides clear guidance on what needs to be added to the draft. The comment is specific and concrete, as it directly instructs the authors to include a particular piece of information. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"241,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added, which is the maximum number of tasks done by any annotator. This provides clear guidance on what the authors should include to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it would be beneficial to include the maximum number of tasks done by any annotator. However, the comment does not provide any reasoning or justification for why this information is important or how it would enhance the paper. Without supporting evidence or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors include the maximum number of tasks done by any annotator, which is a specific and actionable piece of feedback. This recommendation can help improve the clarity and completeness of the paper by providing additional context about the annotation process. However, the comment could be more helpful if it explained why this information is important or how it would impact the reader\"s understanding of the study. Despite this, the feedback is clear and provides a concrete suggestion for improvement, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests including the hard prompt baseline in Table 1 to compare the performance increase of each method. This is an explicit action that provides a clear direction for the authors to follow. The comment specifies what needs to be added to the table, giving the authors a concrete step to take to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including the hard prompt baseline in Table 1 to compare the performance increase of each method. It explicitly mentions \"Table 1,\" providing full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be added to the table, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including the hard prompt baseline in Table 1 to compare the performance increase of each method. However, it does not provide any reasoning or evidence to support why this comparison is necessary or how it would enhance the paper. Without additional context or justification, the claim lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests including the hard prompt baseline in Table 1 to compare the performance increase of each method. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the paper by adding a relevant baseline for comparison. By incorporating this suggestion, the authors can gain a better understanding of the performance differences between methods and improve the comprehensiveness of their results. However, the comment could be more helpful if it explained why this comparison is important or how it would impact the overall analysis. Despite this, the feedback is 4 as it offers a concrete way to enhance the draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of numerical results and expresses curiosity about applying the method to popular algorithms and comparing its performance with existing differential privacy (DP) algorithms. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include numerical results and comparisons, but it lacks concrete details on what specific algorithms to use or how to conduct the comparisons. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment highlights the lack of numerical results and expresses curiosity about applying the method to popular algorithms and comparing its performance with existing differential privacy algorithms. However, it does not specify which part of the paper lacks numerical results or which algorithms are being referred to. This makes it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its request for numerical results and comparisons but lacks grounding, as it does not identify the specific parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses a curiosity about the application of the method to popular algorithms and its performance compared to existing differential privacy algorithms. However, it does not provide any specific examples, references, or reasoning to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the reviewer\"s interest in this aspect. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a significant gap in the paper, specifically the lack of numerical results. It expresses curiosity about how the method could be applied to popular algorithms and compared with existing differential privacy algorithms. While the comment identifies an important area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue. It does not provide actionable steps or examples of algorithms to consider, leaving the authors with a general idea of what is missing but without detailed direction on how to improve their draft. Therefore, the comment is 3, as it points out a critical area for enhancement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experimental comparisons are insufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7), similar to methods like MoCo and SimCLR. This provides a clear and explicit action for the authors to take, which is to conduct additional experiments with these wider backbones. The suggestion is concrete, as it specifies the exact experiments that should be performed to enhance the comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the experimental comparisons are insufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7), similar to methods like MoCo and SimCLR. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental results or methodology section. The comment is specific in suggesting a particular aspect of the experiments that could be improved, namely the use of wider backbones. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the experimental comparisons are insufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7), similar to methods like MoCo and SimCLR. This claim is 3 as it provides a logical suggestion for enhancing the experimental comparisons. However, it lacks specific examples or references to support the claim that MoCo and SimCLR have tested with these wider backbones, which would strengthen the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental comparisons, suggesting that the authors should test their proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7), similar to methods like MoCo and SimCLR. This feedback is clear and actionable, providing the authors with a concrete suggestion to enhance the robustness and comprehensiveness of their experimental results. By following this advice, the authors can gain a deeper understanding of their method\"s performance and its comparison to other approaches. However, the comment could be more helpful if it included additional guidance on how to implement these wider backbones or why this comparison is important. Overall, the comment is 4, as it offers a valuable direction for improvement but could be more comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies two issues that need to be addressed: the incorrect callout to table 5, which should be table 3, and the improper direction of the callout to figure 6 on page 7, section 5. The comment provides clear and specific actions for the authors to take, ensuring that the callouts are corrected to accurately direct the reader. This level of detail provides the authors with concrete steps to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 5\" and \"table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the callout, indicating that it should refer to table 3 instead of table 5. Additionally, it mentions \"page 7, section 5, last par.\" to address the issue with the callout to figure 6. This provides clear guidance on what needs to be corrected, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements regarding the incorrect callout to table 5 and the improper direction of the callout to figure 6. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies two specific issues that need to be addressed in the paper. First, it points out that the callout to table 5 should be corrected to refer to table 3. Second, it notes that the callout to figure 6 on page 7, section 5, is not directing properly. By highlighting these errors, the comment provides clear and actionable feedback that can help the authors improve the accuracy and clarity of their draft. However, the comment could be more helpful if it offered suggestions on how to correct these issues or provided additional context for the authors to understand the impact of these errors. Overall, the comment is 4 as it directs the authors to specific areas needing correction, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern with the experiments, specifically noting that the paper only includes selfcomparisons and lacks explanation for this choice. It suggests that comparisons with SketchRNN could be performed in a generative setting. While the comment identifies a potential issue and provides a specific suggestion for improvement, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should include comparisons with SketchRNN and provide a rationale for their experimental choices. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experiments section of the paper, specifically mentioning the lack of comparisons with other models like SketchRNN. It highlights the issue of only reporting selfcomparisons and the need for a better explanation of this choice. However, it does not specify which part of the experiments section this critique pertains to, such as specific figures or tables. While the authors can infer that it relates to the experimental methodology, the comment lacks full grounding. It is specific in detailing the issue with selfcomparisons and suggesting a comparison with SketchRNN, but without explicit references to sections or figures, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the paper\"s experiments are a major concern due to the lack of comparisons with other models, specifically mentioning SketchRNN. The comment provides a logical reasoning by pointing out the absence of comparative analyses, which is a common practice in experimental sections. However, it lacks specific examples or references to support the claim that comparisons with SketchRNN would be beneficial. This makes the claim 3, as it provides a general direction for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern with the paper\"s experiments, noting that it only includes selfcomparisons and lacks explanations for this choice. It suggests that comparisons with SketchRNN could be performed in a generative setting, which would enhance the paper\"s motivation and provide a more comprehensive evaluation of the proposed method. This feedback is clear and actionable, as it directs the authors to consider additional comparisons that could strengthen their experimental section. However, the comment could be more helpful if it provided specific guidance on how to incorporate these comparisons or why they are important. Overall, the comment is 4, as it highlights a critical area for improvement and offers a constructive suggestion for enhancing the paper\"s experimental rigor."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly recommends additional analysis and comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It also challenges the authors\" viewpoint that both CNNs and ViTs benefit similarly from increased model capacity, providing specific examples and data to support the disagreement. The comment suggests that the authors should address the discrepancy in performance between DeiT models and CNNs as capacity increases. While the action is explicit, the comment could be more actionable by providing specific guidance on how to conduct the additional analysis or what aspects to focus on. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the performance trending of increasing the number of parameters for ViT (DeiT) and challenges the authors\" viewpoint on the benefit of increased model capacity. The comment provides specific examples and data to support the disagreement, such as the performance of DeiTB models compared to DeiTT and DeiTS on various datasets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" viewpoint on the benefit of increased model capacity for both CNNs and ViTs is incorrect. It provides specific examples and data from Figure 3 to support this claim, such as the performance of DeiTB models compared to DeiTT and DeiTS on various datasets. This detailed analysis and evidence make the claim 4, as it provides a clear rationale for the disagreement. However, the comment could be strengthened by including more detailed reasoning or references to support the claim fully. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by recommending additional analysis and comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It challenges the authors\" viewpoint that both CNNs and ViTs benefit similarly from increased model capacity, offering detailed examples and data to support the disagreement. This feedback is valuable as it prompts the authors to revisit their analysis and potentially revise their conclusions based on the provided evidence. However, the comment could be more helpful if it included suggestions on how to conduct the additional analysis or what specific aspects to focus on. Overall, the comment is 4, as it directs the authors to a critical area that requires further exploration and clarification."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests making a distinction between hard prompt work updates that update the frozen model and those that do not. While the comment implies an action, it does not provide explicit guidance on how to make this distinction or what specific changes should be made to the draft. The authors can infer that they need to differentiate between these types of updates, but the comment lacks concrete details on how to implement this differentiation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 148,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests making a distinction between hard prompt work updates that update the frozen model and those that do not, providing a clear direction for improvement. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests making a distinction between hard prompt work updates that update the frozen model and those that do not. However, it does not provide any supporting evidence, reasoning, or references to justify why this distinction is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests making a distinction between hard prompt work updates that update the frozen model and those that do not. This is a specific and actionable suggestion that could help clarify the paper and provide a clearer understanding of the experimental setup. However, the comment could be more helpful if it provided additional context or examples of how this distinction might be made or why it is important. Despite this, the feedback is clear and provides a direction for improvement, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly requests the authors to conduct an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It also asks for a specific experiment regarding the performance of ATT(+H) in figure 4 left, without considering the relevant attention retrieval from the attention memory. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what experiments to conduct and what results to report. The level of detail and specificity in the request makes the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 4 left,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely conducting an ablation study on the visDial dataset and exploring the performance of ATT(+H) without considering relevant attention retrieval from the attention memory. This level of detail provides clear guidance on what the authors need to do to improve their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It also asks for a specific experiment regarding the performance of ATT(+H) without considering relevant attention retrieval from the attention memory. While the comment provides a clear suggestion for additional experiments, it lacks detailed reasoning or references to support why these experiments are necessary or how they would contribute to the paper\"s validity. The request for an ablation study is logical, but the lack of supporting evidence or detailed explanation makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting an additional experiment to further validate the proposed visual reference resolution model. It requests an ablation study on the visDial dataset, which would help to strengthen the paper\"s claims. Additionally, the comment asks for a specific experiment regarding the performance of ATT(+H) without considering relevant attention retrieval from the attention memory. This level of detail and focus on specific areas for improvement makes the comment 5, as it guides the authors on how to enhance the robustness and validity of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide a deeper explanation of why WPA works, particularly with respect to the model\"s predictions when given np.ones input. It also questions whether any input could serve as a white paper and why Gaussian noise input does not work as well as WPA. The comment highlights the importance of understanding how WPA works, as it could lead to future research directions. While the comment implies that the authors should provide more insight into the workings of WPA, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should delve deeper into the explanation of WPA\"s functionality. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the effectiveness of WPA with different inputs, such as np.ones and Gaussian noise, and suggests that the authors should provide more insight into how WPA works. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions and observations about the paper, including the effectiveness of WPA with different inputs and the lack of insight into how WPA works. While the comment highlights areas that could be explored further, it does not provide specific evidence, examples, or references to support the claims. The reasoning is logical, but it lacks detailed justification or examples, making it 3. The authors would need to infer the potential issues and explore them further to address the comment effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several important points that could significantly enhance the paper. It suggests that the authors should provide a deeper explanation of why WPA works, particularly with respect to the model\"s predictions when given np.ones input. This is a valuable suggestion as it could help clarify the underlying mechanisms of WPA and potentially lead to future research directions. Additionally, the comment questions whether any input could serve as a white paper and why Gaussian noise input does not work as well as WPA, which are relevant and actionable questions. The comment also highlights the importance of understanding how WPA works, as it could spark future research directions. However, the feedback could be more helpful if it provided specific guidance on how to address these questions or offered examples of how to explore these areas further. Overall, the comment is 4 as it identifies important areas for improvement and provides some direction for the authors to enhance their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper regarding the setting of two important parameters/thresholds, specifically the minimum cluster size and the conductance threshold. It notes that these parameters are not discussed in the experimental section (Sec. 3), which is crucial for understanding the sensitivity of performance with respect to these parameters. The comment implies that the authors should address this gap by discussing how these parameters are set and how they affect the results. While the action is implicit, it is concrete in suggesting what needs to be done to improve the draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"End of Sec.2\" and \"Sec. 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out the absence of discussion on the setting of two important parameters/thresholds (minimum cluster size and conductance threshold) in the experimental section. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experimental section does not discuss how the parameters/thresholds (minimum cluster size and conductance threshold) are set and how sensitive the performance is to these parameters. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to investigate the experimental section to understand the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that the experimental section (Sec. 3) does not discuss how the important parameters/thresholds (minimum cluster size and conductance threshold) are set and how sensitive the performance is to these parameters. This is a critical oversight that could impact the validity and reliability of the results. The comment provides clear guidance by highlighting the need for this discussion, which is essential for understanding the robustness and generalizability of the findings. However, it could be more helpful if it suggested specific ways to address this issue, such as providing examples or discussing potential methods for setting these parameters. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the potential weakness of using reinforcement learning for a static VQA task, suggesting it may make the approach less dataefficient and harder to train models that use gradient descent. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this potential weakness or suggestions for alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the potential weakness of using reinforcement learning for a static VQA task, suggesting it may make the approach less dataefficient and harder to train models that use gradient descent. However, it does not specify which part of the paper this concern relates to, such as a particular section or experiment. Without explicit references or context, the authors cannot confidently determine where in the paper this issue is discussed, making the comment weakly grounded. Additionally, the comment lacks specificity regarding what aspects of the approach are problematic or how the authors might address these concerns. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the need for reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train models that use gradient descent. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The statement is based on a subjective opinion and does not provide sufficient evidence or justification to be considered verifiable. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment raises a concern about the potential weakness of using reinforcement learning for a static VQA task, suggesting it may make the approach less dataefficient and harder to train models that use gradient descent. While the comment identifies a potential issue, it lacks specificity and does not provide actionable guidance or suggestions for the authors to address this concern. Without detailed feedback or recommendations, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests clarifying the differences between the implemented bilinear layer and other approaches that use bilinear pooling. It asks specific questions about the dimensionality of embeddings, the swapping of the bilinear layer with other approaches, and whether the compression of representations using Equation (3) is still done. While the comment provides clear guidance on what needs to be clarified, it does not explicitly instruct the authors to make these clarifications. The action is implicit but concrete, as the authors can infer that they need to address these points. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L290,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: the differences between the implemented bilinear layer and other approaches that use bilinear pooling, particularly regarding the dimensionality of embeddings and the swapping of the bilinear layer with other approaches. Additionally, it questions whether the compression of representations using Equation (3) is still done in this case. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the differences between the implemented bilinear layer and other approaches that use bilinear pooling. It asks specific questions about the dimensionality of embeddings, the swapping of the bilinear layer with other approaches, and whether the compression of representations using Equation (3) is still done. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these questions. Without additional context or justification, the authors may find it challenging to address these points effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for clarification regarding the implemented bilinear layer and its differences from other approaches that use bilinear pooling. It raises questions about the dimensionality of embeddings, the swapping of the bilinear layer with other approaches, and whether the compression of representations using Equation (3) is still done. This feedback is clear and actionable, as it directs the authors to provide additional details that could enhance the understanding and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of how similar approaches have been discussed in the literature. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the similarity in preactivation values of two networks and suggests that the output cosine similarity will be high. It then asks why the results of the latter loss term of Eqn 13 are not directly illustrated. While the comment implies that the authors should provide more detailed results or explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include more detailed results or explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 3 e,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the results of the latter loss term of Eqn 13 are not directly illustrated, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the similarity in preactivation values of two networks and suggests that their output cosine similarity will be high. It then asks why the results of the latter loss term of Eqn 13 are not directly illustrated. The comment provides a logical reasoning for the expected outcome of the similarity in preactivation values, but it lacks specific examples or references to support the claim about the results of the latter loss term. This makes the claim 3, as it provides a basis for the question but requires further elaboration or evidence to fully substantiate the suggestion for improvement.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results, questioning why the results of the latter loss term of Eqn 13 are not directly illustrated. It provides a logical explanation for the expected outcome of the similarity in preactivation values of two networks, suggesting that their output cosine similarity will be high. This feedback is clear and actionable, as it prompts the authors to include more detailed results or explanations that could enhance the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it offered suggestions on how to present these results or what specific aspects to focus on. Overall, the comment is 4, as it directs the authors to a specific area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper regarding the comparison with testtime adaptation (TTA) methods, specifically mentioning the need to compare data processing with model parameter adjustment. The reviewer suggests that a comparison based on experimental results would be beneficial. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to conduct the comparison or what specific aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the topic of \"robustness in video action recognition\" and the lack of comparison with testtime adaptation (TTA) methods, such as those mentioned in \"AB\". This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the need for a comparison between data processing and model parameter adjustment, suggesting that experimental results should be used to support this comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks comparison with testtime adaptation (TTA) methods, which are relevant for adapting to outofdistribution data. The reviewer suggests that a comparison should be made based on experimental results to prove the superiority of data processing over model parameter adjustment. While the comment highlights a potential gap in the paper, it does not provide specific examples or references to TTA methods, making the claim 3. The authors would need to conduct additional research to fully understand the claim and its implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the comparison with testtime adaptation (TTA) methods, which are relevant for adapting to outofdistribution data. It suggests that a comparison between data processing and model parameter adjustment should be made based on experimental results. This feedback is clear and actionable, as it provides a specific area for improvement and a method for addressing it. However, the comment could be more helpful if it included examples of TTA methods or specific experimental setups to consider. Overall, the comment is 4, as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies an error in the first expression for J(\u03b8) in Section 3.2.1, stating that it should be Q(s_t0, \u03c0\u03b8(s_t0)). This provides clear and direct guidance on what needs to be corrected in the draft. The action is explicit and concrete, as the authors know exactly what needs to be changed to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error in the first expression for J(\u03b8), indicating that it should be Q(s_t0, \u03c0\u03b8(s_t0)). This provides clear guidance on what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first expression for J(\u03b8) is incorrect and should be Q(s_t0, \u03c0\u03b8(s_t0)). However, the comment does not provide any reasoning or evidence to support this claim, such as explaining why the current expression is incorrect or how Q(s_t0, \u03c0\u03b8(s_t0)) is the correct form. Without additional context or justification, the claim remains 1, as the authors would need more information to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific error in the first expression for J(\u03b8) in Section 3.2.1, stating that it should be Q(s_t0, \u03c0\u03b8(s_t0)). This feedback is clear and actionable, providing the authors with precise guidance on what needs to be corrected in their draft. By addressing this error, the authors can improve the accuracy and validity of their work. However, the comment could be more helpful if it explained why the current expression is incorrect or how the correction impacts the overall analysis. Despite this, the feedback is 4 as it directly points out a critical mistake that needs to be corrected."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of multiple explicit actions, including correcting specific typos and ensuring proper capitalization in references. Each correction is clearly stated, providing the authors with precise instructions on what needs to be done. The comment is 5 as it offers concrete steps for improvement, allowing the authors to directly apply these changes to their draft. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as page numbers (p.8) and references, allowing the authors to accurately identify the sections being addressed. It is also specific because it details the corrections needed, including typos and capitalization issues in references. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements regarding typos and capitalization issues in the references. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a list of specific corrections, including typos and capitalization issues in references. It highlights the need for proper capitalization in words like \"ai,\" \"bayesian,\" and \"Advances in neural information processing systems.\" Additionally, it corrects the formatting of references, such as ensuring that \"Dusenberry et al. (2020)\" was published in ICML 2020, and \"Osawa et al. (2019)\" was published in NeurIPS 2019. These detailed corrections are actionable and help the authors improve the accuracy and professionalism of their references. However, the comment could be more helpful if it provided additional context or explained why these corrections are important. Overall, the feedback is 4 as it offers clear and actionable guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions about the parameter values and their selection process for the model, specifically for task 1 and the Boltzmann policy. It explicitly asks for the model parameters, the lambda value chosen, and how the parameters were chosen, suggesting that maximum likelihood estimates might be used. These questions are direct and provide clear guidance on what information the authors need to provide to clarify their methodology. The feedback is explicit and concrete, giving the authors a clear understanding of what actions to take to address the reviewer\"s concerns. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment raises questions about the parameter values and their selection process for task 1 and the Boltzmann policy. It explicitly asks for the model parameters, the lambda value chosen, and how the parameters were chosen, suggesting maximum likelihood estimates. This provides clear guidance on what specific information is missing from the paper. However, the comment does not specify which part of the paper these questions relate to, making it weakly grounded. The authors can infer that it pertains to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification on specific details about the model parameters and their selection process. It does not contain any subjective opinions, claims, or suggestions that require verification. The questions are factual and aim to gather information, making the comment a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the parameter values and their selection process for task 1 and the Boltzmann policy. It explicitly asks for the model parameters, the lambda value chosen, and how the parameters were chosen, suggesting maximum likelihood estimates. This feedback is clear and actionable, as it directs the authors to provide specific details that are currently missing from the paper. By addressing these questions, the authors can enhance the transparency and clarity of their methodology, which is crucial for the paper\"s credibility and reproducibility. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear path forward for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the performance of applying Conditional Batch Norm (CBN) to different layers in the model, specifically asking why applying CBN to layer 2 in addition to layers 3 and 4 might deteriorate performance for the GuessWhat?! task. The comment explicitly requests the authors to provide an explanation for this observation, which is a clear and direct action. However, it does not specify how the authors should approach this explanation or what specific aspects to focus on. While the action is explicit, the lack of detailed guidance on how to address the issue makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the performance impact of applying Conditional Batch Norm to different layers, providing a clear direction for the authors to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance impact of applying Conditional Batch Norm (CBN) to different layers in the model, specifically asking why applying CBN to layer 2 in addition to layers 3 and 4 might deteriorate performance for the GuessWhat?! task. The comment does not make a claim or provide an opinion but rather seeks clarification from the authors. It is a request for explanation and does not contain any subjective claims or suggestions, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the performance impact of applying Conditional Batch Norm (CBN) to different layers in the model, as observed in Table 2. It points out a potential issue where applying CBN to layer 2 in addition to layers 3 and 4 might deteriorate performance for the GuessWhat?! task. The comment requests the authors to provide an explanation for this observation, which is a clear and actionable request for clarification. By addressing this question, the authors can gain a deeper understanding of their model\"s behavior and potentially identify areas for improvement. However, the comment could be more helpful if it provided additional context or suggestions on how to approach the explanation. Overall, the comment is 4 as it directs the authors to a specific area needing further clarification, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a similarity between the spurious features in Sections 3.1 and 3.2 and backdoor triggers, noting that they are artificial patterns appearing only a few times in the training set. It references examples from Chen et al. (2017) and Gu et al. (2019) to illustrate the concept. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue in their draft. While it identifies a potential problem, it lacks actionable advice on how to mitigate it or improve the draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the spurious features being similar to backdoor triggers and provides examples from Chen et al. (2017) and Gu et al. (2019) to support the claim. This level of detail helps the authors understand what needs to be addressed in the sections mentioned. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the spurious features in Sections 3.1 and 3.2 are similar to backdoor triggers and notes that these artificial patterns can have a significant impact on the trained model. The comment supports this claim by referencing examples from Chen et al. (2017) and Gu et al. (2019), which use random noise patterns and singlepixel triggers, respectively. This provides a logical basis for the claim, as it highlights the potential vulnerability of the model to such triggers. However, the comment could be strengthened by providing more detailed analysis or examples from the current paper to fully substantiate the claim. Therefore, the comment is 4, as it provides a solid foundation for the claim but could benefit from additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the spurious features in Sections 3.1 and 3.2, noting their similarity to backdoor triggers. It provides examples from existing literature, such as Chen et al. (2017) and Gu et al. (2019), to illustrate the concept. This feedback is 3 as it highlights a specific area of concern and offers references that could help the authors understand the issue better. However, the comment could be more helpful if it provided suggestions on how to address this issue or improve the robustness of the model against such triggers. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify the distinction between when the proposed method is trained using only weak supervision and when it is semisupervised trained. It provides a specific suggestion for renaming a column in Table 1 to better reflect the semisupervised version of the method. Additionally, it offers a more comprehensive approach by suggesting the use of two columns to specify the data used for training each model. This feedback is clear and provides concrete steps for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and the \"proposed framework row,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the distinction between weak supervision and semisupervised training, and suggests renaming a column in Table 1. Additionally, it provides a detailed suggestion for improving the clarity of the table by using two columns to specify the data used for training each model. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify the distinction between weak supervision and semisupervised training in their proposed method. It provides a specific example from Table 1, where the authors are advised to rename a column to better reflect the semisupervised version of the method. The suggestion to use two columns to specify the data used for training each model is also offered. While the comment provides a clear and logical reasoning for the suggested changes, it lacks specific references or examples from the literature to fully substantiate the claim. Therefore, the comment is 4, as it provides a solid basis for the suggestion but could benefit from additional references or detailed explanations.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by identifying a specific area where the authors can improve the clarity and organization of their paper. It suggests that the authors should distinguish between when the proposed method is trained using only weak supervision and when it is semisupervised trained. The comment offers a concrete suggestion for renaming a column in Table 1 to better reflect the semisupervised version of the method. Additionally, it proposes a more comprehensive approach by suggesting the use of two columns to specify the data used for training each model. This feedback is detailed and provides the authors with specific guidance on how to enhance the clarity and presentation of their work, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the tables do not include cases where both dependency tree and RL are not used. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this problem or what specific changes they should make to their tables. The action is implicit and somewhat vague, as the authors can infer that they need to include these missing cases in their tables, but they are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the ablation experiment\" and \"the two tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the tables, which is the lack of cases where both dependency tree and RL are not used. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance without reinforcement learning dropped lower than without dependency tree and points out that the tables do not include cases where both dependency tree and RL are not used. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the tables do not include cases where both dependency tree and RL are not used. This feedback is clear and actionable, as it highlights a gap in the experimental setup and suggests that the authors should include these missing cases in their tables. However, the comment could be more helpful if it provided additional context or suggestions on how to interpret or address the observed performance differences. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a weakness in the paper, specifically the limited scope of the experiments, which are only conducted on the CIFAR10 dataset without considering other datasets from Federated learning benchmarks. The reviewer suggests that the authors should consult relevant works like FedProx and FedMAX for details on different datasets and model types. This feedback provides a clear direction for the authors to expand their experimental evaluation, making it 4. The authors know exactly what needs to be done to improve their draft, which is to broaden the scope of their experiments by considering additional datasets and referencing relevant works. Therefore, this comment is rated as 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the limited scope of the experiments, which are only conducted on the CIFAR10 dataset without considering other datasets from Federated learning benchmarks. The comment further suggests consulting specific works like FedProx and FedMAX for details on different datasets and model types. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments section is a weakness because it only presents results on the CIFAR10 dataset and does not consider other datasets from Federated learning benchmarks. The reviewer suggests that the authors should consult relevant works like FedProx and FedMAX for details on different datasets and model types. This claim is 3 as it provides a logical reasoning for the limitation in the experiments and suggests a specific direction for improvement. However, the comment lacks specific examples or detailed references to support the claim fully, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the limited scope of the experiments, which are only conducted on the CIFAR10 dataset without considering other datasets from Federated learning benchmarks. It suggests that the authors should consult relevant works like FedProx and FedMAX for details on different datasets and model types, providing a clear direction for improvement. This feedback is actionable and constructive, as it highlights a critical area for expansion and offers specific references to enhance the comprehensiveness of the experimental evaluation. By addressing this feedback, the authors can significantly improve the depth and relevance of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for nonstochastic networks and how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. While it highlights a potential inconsistency or lack of clarity in the paper, it does not provide explicit instructions or suggestions for the authors to address this issue. The authors are left to infer that they need to clarify or provide more information on this point, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it identifies an area for clarification but does not provide detailed steps for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 182183 and Figure 2.c, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the construction of clean exemplar manifolds for nonstochastic networks and how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for nonstochastic networks and the computation of the denominator in Figure 2.c for ResNet50 and ATResNet50 networks. The comment highlights a potential inconsistency or lack of clarity in the paper, but it does not make a subjective claim or suggestion that requires verification. It is a factual observation seeking clarification, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment raises a question about the construction of clean exemplar manifolds for nonstochastic networks, pointing out a potential inconsistency in the paper. It also questions how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. While the comment identifies a specific area of confusion, it does not provide detailed guidance or suggestions on how the authors might address this issue or clarify the methodology. The feedback is 3 as it highlights a potential weakness in the paper, but it lacks actionable advice or depth, making it less comprehensive than it could be. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential source of confusion in the paper, specifically the notation and the explicit split between \"static\" and temporal features. The reviewer suggests that more information is needed to clarify this point, mentioning the variables \"S\" and \"Xt.\" However, the comment does not provide explicit guidance on how to address this issue or what specific information should be added to clarify the notation. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a potential source of confusion regarding the notation and the explicit split between \"static\" and temporal features. It mentions the variables \"S\" and \"Xt,\" indicating that the authors need to provide more information to clarify these aspects. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in detailing what needs to be clarified, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a subjective opinion about the notation and the explicit split between \"static\" and temporal features, suggesting that it is confusing and requires more information. However, the comment does not provide specific examples or references to support why this notation is confusing or how it could be clarified. The lack of detailed reasoning or evidence makes the claim difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper, specifically regarding the notation and the explicit split between \"static\" and temporal features. It highlights the need for more information, such as what \"S\" and \"Xt\" represent, to clarify this aspect. While the comment points out a specific area that needs clarification, it does not provide detailed guidance on how to address this issue or suggest specific ways to improve the clarity of the notation. The feedback is 3 as it directs the authors to a specific area that requires attention, but it lacks depth and actionable suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the claim that INRs operate on a perdatainstance basis, suggesting that this characteristic is not an advantage. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or whether the authors should reconsider their claim. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that INRs operate on a perdatainstance basis and suggesting that this characteristic is not an advantage. The comment provides a clear critique of the claim, making it specific. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that INRs operate on a perdatainstance basis, suggesting that this characteristic is not an advantage. The reviewer provides a logical reasoning by stating that a model that can only handle a single time series data is almost useless. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider the implications of this limitation and potentially provide additional context or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the claim that INRs operate on a perdatainstance basis, suggesting that this characteristic is not an advantage. The reviewer argues that a model that can only handle a single time series data is almost useless, which provides a clear critique of the paper\"s claim. However, the comment lacks depth and does not offer any suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential weakness, it does not provide actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a limitation in the experiments, noting that most experiments are limited to RoBERTabase and raises concerns about the generalizability of the results to other models with learnable APEs. It suggests investigating the results\" generalizability to differences in model size, objective function, and architecture, and specifically recommends including more analysis and discussion for GPT2. The comment provides explicit actions for the authors to take, such as conducting additional experiments and including more analysis, and offers specific examples like including results for Figure 2 for GPT2. This level of detail and guidance makes the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1.1\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the experiments, namely the limited scope to RoBERTabase and the need to investigate generalizability to other models. The comment further suggests including more analysis and discussion for GPT2, providing a concrete example of what additional information could be included. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited to RoBERTabase and questions the generalizability of the results to other models with learnable APEs. It suggests investigating the results for differences in model size, objective function, and architecture, and specifically recommends including more analysis for GPT2. While the comment raises a valid concern about the scope of the experiments, it lacks specific examples or references to support the claim that the results cannot be generalized. The suggestion to include more analysis for GPT2 is a logical step, but without detailed reasoning or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper\"s experiments, noting that most experiments are limited to RoBERTabase and questioning the generalizability of the results to other models with learnable APEs. It suggests that the authors should investigate whether the results can be generalized to differences in model size, objective function, and architecture, such as GPT2. The comment provides specific and actionable feedback by recommending additional analysis and discussion for GPT2, including results for Figure 2. This feedback is clear and constructive, offering the authors a clear path to improve the comprehensiveness and robustness of their experimental results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the applicability of the parameters and experiments presented in the paper, suggesting that they are limited to image data and ViT. It questions whether the authors have explored applying these principles to other areas, such as NLP or simpler models in the image domain (CNNs). While the comment implies that the authors should consider broader applicability, it does not explicitly instruct them to do so. The suggestion is implicit and somewhat vague, as it lacks specific guidance on how to conduct these explorations or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"the model and the experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the applicability of the parameters and experiments to other areas, such as NLP or simpler models in the image domain. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the applicability of the parameters and experiments presented in the paper, suggesting that they are limited to image data and ViT. The reviewer questions whether the authors have explored applying these principles to other areas, such as NLP or simpler models in the image domain. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim that the method cannot generalize to different architectures and tasks. This makes the claim 3, as it provides a basis for the concern but requires further elaboration or evidence to fully substantiate it.", "helpfulness_rationale": "The review comment raises a valid concern about the limited scope of the paper\"s experiments and applicability, suggesting that the parameters and experiments are only suitable for image data and ViT. It questions whether the authors have explored applying these principles to other areas, such as NLP or simpler models in the image domain. This feedback is 3 as it prompts the authors to consider broader applicability and generalizability of their method, which could enhance the paper\"s impact. However, the comment could be more helpful if it provided specific suggestions or examples of how to explore these other areas or what benefits this might bring. Overall, the comment provides a useful direction for the authors to consider, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors evaluate TTA methods on more conditions of natural distribution shift, specifically mentioning WILDS as a potential benchmark. While the comment implies an action for the authors to take, it does not provide explicit instructions on how to conduct this evaluation or what specific aspects of WILDS should be considered. The action is inferred and somewhat vague, as the authors need to deduce the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Performance of TTA methods,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors evaluate TTA on more conditions of natural distribution shift, such as WILDS, which provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that using nonstandard benchmarks breaks many popular TTA methods and recommends evaluating TTA on more conditions of natural distribution shift, such as WILDS. The claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or detailed references to support the assertion about the performance of TTA methods on nonstandard benchmarks. While the suggestion to use WILDS is a good starting point, the comment could be strengthened by providing more detailed evidence or examples to substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies an interesting observation regarding the performance of TTA methods on nonstandard benchmarks and suggests that evaluating TTA on more conditions of natural distribution shift, such as WILDS, could strengthen the paper. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by exploring additional benchmarks. However, the comment could be more helpful if it included specific guidance on how to implement this suggestion or what aspects of WILDS should be considered. Overall, the comment is 4 as it offers a valuable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should use a more realistic setting by sampling unlabeled data from millions of reviews, as done in the Adaptive Semisupervised Learning for Crossdomain Sentiment Classification paper by He et al. (EMNLP 2018). This implies an action for the authors to take, which is to modify their approach to better align with realworld applications. The suggestion is explicit and provides a concrete example of how to implement the change, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the impracticality of perfectly balanced unlabeled data in realworld applications and suggests using a more realistic setting by sampling unlabeled data from millions of reviews, as done in a referenced paper. This provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the use of perfectly balanced unlabeled data from the preprocessed Amazon review dataset is impractical in realworld applications. It suggests using a more realistic setting by sampling unlabeled data from millions of reviews, as done in the Adaptive Semisupervised Learning for Crossdomain Sentiment Classification paper by He et al. (EMNLP 2018). The comment provides a specific reference to support the claim, which is a clear and logical reasoning. However, the comment could be strengthened by providing more detailed comparisons or examples of how the current approach differs from the suggested one. Overall, the claim is 4 due to the reference provided, but it could be more robust with additional details.", "helpfulness_rationale": "The review comment identifies a practical issue with the use of perfectly balanced unlabeled data from the preprocessed Amazon review dataset, noting that this is impractical in realworld applications where label distribution cannot be controlled. It suggests using a more realistic setting by sampling unlabeled data from millions of reviews, as done in a referenced paper. This feedback is clear and actionable, providing the authors with a specific direction to improve their approach by aligning it with more realistic scenarios. The reference to a similar work in the field adds context and helps the authors understand the potential benefits of the suggested change. Therefore, the comment is 5, as it offers constructive guidance that can significantly enhance the draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the contribution of different modalities across instances, noting that some instances may perform well with one modality (e.g., modality A) while others perform well with another (e.g., modality B). It questions how to address this problem, specifically referencing Equation 3, which removes the modal subset of all instances. However, the comment does not provide explicit guidance or suggestions on how to deal with this issue. The action is implicit and vague, as the authors are left to infer that they need to address the problem but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential difference in contributions of different modalities across instances and questioning how to deal with this problem. The comment provides a clear direction for the authors to address the concern, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the contribution of different modalities across instances, noting that some instances may perform well with one modality while others perform well with another. It questions how to address this issue, specifically referencing Equation 3. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim or explain why this is a problem. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the contribution of different modalities across instances, noting that some instances may perform well with one modality while others perform well with another. It questions how to address this problem, specifically referencing Equation 3, which removes the modal subset of all instances. This feedback highlights a specific area where the authors may need to clarify or address the implications of their method, particularly in terms of modality performance. However, the comment lacks detailed guidance or suggestions on how to resolve this issue, which limits its helpfulness. Therefore, it is 3, as it points out a potential problem but does not provide comprehensive feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights confusion in the description of the MFDA setting in the first paragraph of the Method Section. It points out inconsistencies in the notation and questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper. While the comment identifies specific areas of confusion and references the original paper for context, it does not provide explicit instructions on how to clarify or address these issues. The authors are left to infer that they need to clarify the notation and the use of unlabeled data in source domains. The action is implicit and somewhat vague, as it lacks detailed guidance on how to resolve the confusion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first paragraph of the Method Section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the description of the MFDA setting, including the confusion caused by the notation for the target domain and the use of labeled and unlabeled data. The comment provides specific examples and references to the original MFDA paper, which helps the authors understand what needs to be clarified or addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the MFDA setting is confusing, specifically mentioning inconsistencies in notation and the use of labeled and unlabeled data. The reviewer references the original MFDA paper (Yue et al., 2021a) to support their claim, noting that the target data is unlabeled. This provides a clear basis for the claim, as it highlights a potential misunderstanding in the paper\"s description. However, the comment could be strengthened by providing more detailed examples or explanations of the specific issues with the notation. Overall, the claim is 4, as it is supported by a reference to the original paper, but it could benefit from additional details to fully substantiate the critique. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of the MFDA setting in the first paragraph of the Method Section, pointing out confusion in the notation and the use of labeled and unlabeled data. It references the original MFDA paper (Yue et al., 2021a) to highlight the inconsistency and questions whether the unlabeled data in source domains are used during training, as in the original paper. This feedback is clear and actionable, as it directs the authors to clarify the notation and the use of data in their setting, which could significantly improve the clarity and accuracy of their description. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of how to clarify the notation. Overall, the comment is 4, as it effectively points out a critical area for improvement and guides the authors toward a solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that an epochwise analysis, particularly for finite sum settings, could provide valuable insights into the behavior of optimization algorithms. It proposes investigating the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it suggests that this analysis could aid in comparative studies of deterministic and stochastic methods. While the comment implies that the authors should consider conducting an epochwise analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests an epochwise analysis, particularly for finite sum settings, to gain insights into the behavior of optimization algorithms. It proposes investigating the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. This suggestion is specific in terms of what could be analyzed, but it does not specify which part of the paper should include this analysis. The authors can infer that it relates to the experimental or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that an epochwise analysis could provide insights into the behavior of optimization algorithms, particularly in finite sum settings. It proposes investigating the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. While the comment provides a logical reasoning for the potential benefits of such an analysis, it lacks specific examples or references to support the claim. The suggestion is 3 as it offers a clear direction for improvement, but the lack of detailed evidence or examples makes it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a potential area for improvement by proposing an epochwise analysis, particularly for finite sum settings, to gain insights into the behavior of optimization algorithms. It provides specific examples of what could be investigated, such as the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it suggests that this analysis could aid in comparative studies of deterministic and stochastic methods. While the comment offers a clear and actionable suggestion, it could be more helpful if it provided additional guidance on how to implement this analysis or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a valuable area of exploration, but it could be more comprehensive with further details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the paper, namely the difficulty in distinguishing between derogatory and exclusionary extreme speech. It provides a concrete example from the sample data file, questioning the classification of a particular instance. The reviewer also raises a question about the role of local regulation in annotations and its impact on zeroshot crosscountry classification. While the comment identifies a problem and provides specific examples, it does not explicitly instruct the authors to address these issues or suggest how to improve the clarity of the distinction between the two types of extreme speech. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definitions and address the concerns raised. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Paper Summary\" and refers to specific instances and lines in the sample data file, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of difficulty in differentiating between derogatory and exclusionary extreme speech, providing a concrete example from the sample data file. Additionally, it raises questions about the role of local regulation in annotations and its impact on zeroshot crosscountry classification. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the distinction between derogatory and exclusionary extreme speech, as mentioned in the paper summary. It provides a specific example from the sample data file, questioning the classification of an instance and suggesting that local regulation may play a role in annotations. The reviewer also asks about the impact of local regulation on zeroshot crosscountry classification. While the comment raises valid points, it lacks specific references or detailed reasoning to fully substantiate the claim. The authors would need to delve deeper into the paper to understand the context and rationale behind the classification. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clear distinction between derogatory and exclusionary extreme speech. It provides a concrete example from the sample data file, questioning the classification of a particular instance and suggesting that local regulation may play a role in annotations. The comment also raises a question about the impact of local regulation on zeroshot crosscountry classification. This feedback is actionable as it points out a critical area for clarification and improvement, allowing the authors to refine their definitions and annotations. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional context. Overall, the comment is 4, as it directs the authors to a specific area needing attention and improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the importance of studying the effect of noise accumulation in the context of homomorphic encryption for sequential ensembling. It also mentions a limitation that prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific steps they should take to improve their work. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of noise accumulation in the context of homomorphic encryption for sequential ensembling, but it does not specify which part of the paper this concern is related to. The authors may infer that it pertains to the methodology or results sections, but without explicit grounding, it is difficult to pinpoint the exact part of the paper being addressed. The comment is specific in detailing the issue of noise accumulation and its impact on the use of homomorphically encrypted data, but it lacks grounding. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that studying the effect of noise accumulation in the context of homomorphic encryption is important for sequential ensembling. It also mentions a limitation that prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights an important consideration for sequential ensembling in the context of homomorphic encryption, specifically the issue of noise accumulation. It points out a limitation that prevents the use of even single deep neural networks on homomorphically encrypted data. While the comment identifies a critical area for further study, it lacks specific suggestions or guidance on how the authors might address this limitation or explore potential solutions. The feedback is 3 as it directs the authors to a specific area needing attention, but it could be more beneficial with additional actionable advice or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Fig. 3. This provides a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the figure for comparison. The comment is 5 because it gives precise guidance on how to enhance the draft, allowing the authors to know exactly what to do to improve their work.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added to the left graph in Fig. 3, namely, the learning curve for a model without mean teacher or pi regularization. This provides clear guidance on how to enhance the figure for better comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Fig. 3 to compare the effect of these components on learning. This claim is 3 as it provides a logical reasoning for the suggestion, which is to better understand the impact of mean teacher and pi regularization on the learning process. However, the comment lacks specific examples or references to support the claim that including this comparison would be beneficial. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the draft. It recommends including a learning curve for a model without mean teacher or pi regularization in the left graph of Fig. 3, which would allow for a direct comparison of the effects of these components on the learning process. This feedback is clear and constructive, offering a concrete way for the authors to enhance their analysis and presentation. By addressing this suggestion, the authors can gain a deeper understanding of the impact of mean teacher and pi regularization, which is crucial for the validity and comprehensiveness of their findings. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the proposed objective equation (Eq. 2) in line 128, noting that it requires optimization over both the transformation parameters and the shared model parameters. It also points out that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019), has not been discussed clearly. While the comment identifies a gap in the discussion, it does not provide explicit guidance on how the authors should address this issue or what specific aspects should be included in the discussion. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the impact on the number of parameters and possibly compare it with prior work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 2 in line 128,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the need for a clearer discussion on the effect of the proposed objective equation on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed objective equation (Eq. 2) requires optimization over both the transformation parameters and the shared model parameters, and that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019), has not been discussed clearly. The comment provides a specific reference to AlignFlow, which supports the claim by indicating a relevant work for comparison. However, the comment could be strengthened by providing more detailed reasoning or examples of how the proposed objective equation differs from prior work. Overall, the claim is 4, as it provides a clear reference but lacks additional supporting details. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed objective equation (Eq. 2) in line 128, noting that it requires optimization over both the transformation parameters and the shared model parameters. It also points out that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019), has not been discussed clearly. This feedback is clear and actionable, as it highlights a gap in the discussion that the authors need to address. By suggesting that the authors should discuss the impact on the number of parameters, the comment provides a specific direction for improvement. However, it could be more helpful if it offered suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is 4, as it effectively guides the authors toward improving their draft by addressing a critical aspect of their methodology."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implications of Eq. 4 and the value of u^l in Eq. 3. It also critiques the improvement in the designed solutions presented in Table 5, specifically noting that the proposed solution achieves only a marginal improvement on the OfficeHome dataset. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the questions or improve the results, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the implications of Eq. 4 and the value of u^l in Eq. 3, indicating that it is related to the equations and their analysis. It also critiques the improvement in the designed solutions presented in Table 5, specifically mentioning the marginal improvement on the OfficeHome dataset. However, the comment does not explicitly mention which part of the paper these equations or tables are located in, making it weakly grounded. The authors can infer that it relates to the results or analysis sections, but this inference is not direct. The comment is specific in detailing the issue with the improvement, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the implications of Eq. 4 and the value of u^l in Eq. 3, suggesting a potential inference about the behavior of u^l. It also critiques the improvement in the designed solutions presented in Table 5, specifically noting that the proposed solution achieves only a marginal improvement on the OfficeHome dataset. However, the comment lacks specific reasoning or evidence to support the claim that the improvement is marginal or to justify the inference about u^l. Without detailed analysis or references, the claim remains 3, as it provides a basis for questioning but lacks comprehensive evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the implications of Eq. 4 and the value of u^l in Eq. 3, which could be an important clarification for the authors to address. Additionally, it critiques the improvement in the designed solutions presented in Table 5, specifically noting that the proposed solution achieves only a marginal improvement on the OfficeHome dataset. This feedback is 3 as it points out a potential area for improvement and encourages the authors to consider the significance of their results. However, the comment could be more helpful if it provided specific suggestions on how to address the marginal improvement or offered additional insights into what might be causing this issue. Overall, the comment is 3, as it identifies a potential weakness but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights the absence of certain stateoftheart references in the experiment on face recognition, specifically mentioning a work by Baidu that uses the triplet loss and reports results on a dataset similar to Webface. The reviewer also compares the results of the VRF with those in Table 3 of the paper, noting that the VRF achieves a better result on LFW. While the comment identifies a gap in the references and provides a specific example, it does not explicitly instruct the authors to include these references or to address the comparison with the mentioned work. The action is implicit and somewhat vague, as the authors need to infer that they should include these references and consider the comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment of face recognition\" and references a specific work by Baidu, \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding,\" along with a link to the results. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out the missing stateoftheart references and provides a comparison with the results in Table 3, indicating what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some stateoftheart references are missing in the experiment on face recognition, specifically mentioning a work by Baidu that uses the triplet loss and reports results on a dataset similar to Webface. The reviewer provides a specific reference to the Baidu work and compares the results of the VRF with those in Table 3 of the paper, noting that the VRF achieves a better result on LFW. This provides a clear and specific comparison, making the claim 4. However, the comment could be strengthened by providing more detailed analysis or examples of how the missing references impact the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific gap in the references used in the experiment on face recognition, pointing out the omission of a stateoftheart work by Baidu that uses the triplet loss and reports results on a dataset similar to Webface. The reviewer provides a detailed reference to the work, including a link to the results, and compares the results of the VRF with those in Table 3 of the paper, noting that the VRF achieves a better result on LFW. This feedback is clear and actionable, as it directs the authors to include these references and consider the comparison with the mentioned work. By addressing this gap, the authors can enhance the credibility and relevance of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two specific issues: the lack of change in the range of ID and OOD by sparsification, as observed in Figure 4, and the requirement for Lemma 2 to have an approximately identical mean as the assumption. The comment emphasizes that these conditions are crucial for DICE but notes that they are not well discussed. While the comment identifies areas that need attention, it does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to improve the discussion. The action is implicit and somewhat vague, as the authors can infer that they need to discuss these conditions further but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Lemma 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the range of ID and OOD does not change much by sparsification and that the conditions for Lemma 2 are not well discussed. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the range of ID and OOD does not change much by sparsification, as observed in Figure 4, and that Lemma 2 requires an approximately identical mean as the assumption. The comment suggests that these conditions are crucial for DICE but are not well discussed. However, the comment lacks specific examples or detailed reasoning to support the claim that these conditions are not met or how they impact the paper. The absence of concrete evidence or references makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, particularly regarding Figure 4 and Lemma 2. It points out that the range of ID and OOD does not change much by sparsification, which is a crucial condition for DICE. Additionally, it notes that Lemma 2 requires an approximately identical mean as the assumption, which is not well discussed. The comment highlights the importance of these conditions and suggests that the authors should discuss how to ensure DICE meets these conditions. While the comment provides clear areas for improvement, it could be more helpful by offering specific suggestions or examples on how to address these issues. Overall, the feedback is 4 as it directs the authors to important aspects of their work that need further clarification and discussion."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two parts. The first part raises a question about the integration of the update over all possible environments, which is an implicit action for the authors to clarify or address this point in their draft. However, it does not provide specific guidance on how to do so, making it vague. The second part explicitly suggests breaking out bolded sections into paragraphs to improve readability, providing a clear and concrete action for the authors to take. Overall, the comment is 3 due to the explicit suggestion for formatting improvement, but the first part is vague and lacks concrete guidance.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 6\" and the \"bolded sections,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the bolded sections should be broken out into paragraphs to improve readability, which is a clear and actionable suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part raises a question about the integration of the update over all possible environments, which is a logical inquiry that seeks clarification. However, it does not contain a claim that requires verification. The second part suggests breaking out bolded sections into paragraphs for better readability, which is a factual statement and not a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the integration of the update over all possible environments, which could be a critical aspect of the methodology. However, it does not provide any further guidance or suggestions on how the authors might address this issue or clarify their approach. Additionally, the comment suggests breaking out bolded sections into paragraphs for better readability, which is a minor but actionable piece of feedback. Overall, the comment identifies a potential area for clarification but lacks depth and specificity, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several concerns about the experiments, including the strength and fairness of the results, the use of position kernels, and the absence of certain baselines. It also suggests that the paper should compare its proposed approach with these missing baselines and discuss limitations and societal impacts. While the comment identifies several areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to strengthen their experiments, use default settings for baselines, include missing baselines, and discuss limitations and societal impacts. However, the lack of specific guidance on how to implement these changes makes the comment 3. The authors know what needs to be done but may struggle with the exact steps to take.", "grounding_specificity_rationale": "The comment raises several concerns about the experiments, including the strength and fairness of the results, the use of position kernels, and the absence of certain baselines. It also mentions the need to discuss limitations and societal impacts. However, the comment does not specify which sections of the paper these issues relate to, making it difficult for the authors to pinpoint the exact parts that need revision. While the authors can make an educated guess about the general areas being addressed, the comment lacks full grounding. It is specific in detailing the issues but 1 in terms of identifying the exact parts of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises several claims about the experiments, including concerns about their strength and fairness, the use of position kernels, and the absence of certain baselines. The reviewer questions the choice of baselines and suggests that the paper should use default settings from the literature. Additionally, the comment points out the lack of discussion on limitations and societal impacts. While the reviewer provides some reasoning for their concerns, such as questioning the use of position kernels and the absence of certain baselines, the comment lacks specific examples or references to support these claims. The reasoning is 3, as it highlights potential issues but requires more detailed evidence or examples to fully substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including concerns about the strength and fairness of the experiments, the use of position kernels, and the absence of certain baselines related to Bayesian optimization with discrete and categorical variables. It also suggests that the paper should compare its proposed approach with these missing baselines and discuss limitations and societal impacts. These points are actionable and provide clear guidance for the authors to enhance the rigor and comprehensiveness of their work. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of relevant baselines to include. Overall, the feedback is 4 as it directs the authors to important areas for improvement, but it could be more detailed to fully support the authors in enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the derivation from Eqn. 3 to Eqn. 4 is missing the temperature \u03c4 and suggests that it should be shown in a rigorous way or mentioned in the paper. This provides a clear and direct action for the authors to take, which is to include the temperature \u03c4 in the derivation or mention it in the paper. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqn. 3 to Eqn. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of missing the temperature \u03c4 in the derivation and suggests that it should be shown in a rigorous way or mentioned in the paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the derivation from Eqn. 3 to Eqn. 4 is missing the temperature \u03c4 and suggests that it should be shown in a rigorous way or mentioned in the paper. This claim is 3 as it points out a potential gap in the derivation, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The reviewer provides a clear suggestion for improvement, but without additional context or references, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the derivation of the paper, noting that the temperature \u03c4 is missing in the transition from Eqn. 3 to Eqn. 4. It provides a clear and actionable suggestion by recommending that the temperature should be shown in a rigorous way or mentioned in the paper. This feedback is valuable as it directs the authors to a precise area where the paper may lack clarity or completeness, allowing them to make targeted improvements. However, the comment could be more helpful if it offered additional context or examples of how the temperature should be integrated into the derivation. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to add a citation on differential privacy, specifically suggesting a standard work like 2. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The suggestion is concrete, as it specifies the type of citation needed and provides a reference point. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 156,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a citation on differential privacy, providing a clear action for the authors to take. This makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a citation on differential privacy, specifically recommending a standard work like 2. This is a factual statement that does not express an opinion or require justification, as it is a straightforward suggestion for improvement. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, suggesting that the authors add a citation on differential privacy, specifically recommending a standard work like 2. This feedback is valuable as it directs the authors to enhance the paper by providing a relevant reference, which can improve the reader\"s understanding of the topic. However, the comment could be more helpful if it explained why this citation is necessary or how it would benefit the paper. Despite this, the suggestion is 4 as it provides a concrete step for improvement. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part questions the claim that \"this methodology requires significant additional assumptions,\" suggesting that the assumption of the test set being drawn from the same distribution as the query set is natural in many machine learning settings. This part of the comment does not provide explicit guidance or suggestions for the authors to address. The second part points out an error in the inequality on line 310, suggesting a comparison with line 227. While this part is more actionable, it still lacks detailed guidance on how to correct the inequality. Overall, the comment is 3 as it identifies specific issues but does not provide concrete steps for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2\" and \"line 310,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the claim about additional assumptions and the error in the inequality on line 310, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a claim about the methodology requiring significant additional assumptions and a factual statement about an inequality error. The first part is subjective and lacks specific evidence or references to support the claim that the assumption is too extreme. The second part is factual and does not require verification. Since the first part lacks sufficient justification, the comment is considered 1.", "helpfulness_rationale": "The review comment addresses two distinct issues. First, it questions the claim that the methodology requires significant additional assumptions, suggesting that the assumption of the test set being drawn from the same distribution as the query set is natural in many machine learning settings. This feedback prompts the authors to reconsider their claim and potentially provide more context or justification. Second, it points out an error in the inequality on line 310, suggesting a comparison with line 227. This feedback is actionable as it identifies a specific mistake that needs correction, providing clear guidance for the authors to improve their draft. However, the comment could be more helpful if it offered suggestions on how to address the claim about additional assumptions or provided more detailed guidance on correcting the inequality. Overall, the comment is 4, as it identifies important issues that need attention, but could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights several writing issues, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or guidance on how to address these issues. The comment lacks explicit instructions or suggestions for improvement, leaving the authors uncertain about what steps to take to rectify the problems. As a result, the comment is vague and does not offer a clear path for the authors to follow, making it barely actionable.", "grounding_specificity_rationale": "The comment highlights \"severe writing issues\" such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which parts of the paper these issues are found in, making it difficult for the authors to identify the exact sections that need attention. The comment lacks grounding as it does not mention specific sections, tables, or figures, and it is also not specific about what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper contains \"severe writing issues\" such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or evidence to support these claims, making it difficult for the authors to understand and address the issues. Without detailed examples or references, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies several writing issues, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or guidance on how to address these issues, leaving the authors without actionable feedback. Without detailed suggestions or examples, the comment lacks depth and does not offer a clear path for improvement. As a result, it is 2, as it identifies a problem but does not provide sufficient guidance for the authors to address it effectively."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take. It instructs them to run experiments for untrained networks and add the results to the figures and Table 1. Additionally, it requests clarification on the use of random data in Figures 3c and 3, specifically asking whether the network was trained on random data or if the dotted lines represent networks trained on unaltered data evaluated with random data. The comment also suggests clarifying whether the nonrandom data was normalized and, if so, whether the additional \"unitball\" noise is small or large compared to the data. Finally, it recommends showing examples of the random data in the appendix. These instructions are clear and concrete, providing the authors with specific steps to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figures 3c and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific requests for clarification and additional experiments, such as running experiments for untrained networks and adding results to the figures and Table 1. Additionally, it asks for clarification on the use of random data in Figures 3c and 3, and suggests showing examples of the random data in the appendix. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of requests for clarification and additional information, such as running experiments for untrained networks, clarifying the use of random data in Figures 3c and 3, and providing examples of random data in the appendix. These requests are factual and do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback, addressing several areas for improvement in the paper. It requests additional experiments to include results for untrained networks, which would enhance the comprehensiveness of the figures and Table 1. Additionally, it seeks clarification on the use of random data in Figures 3c and 3, asking whether the network was trained on random data or if the dotted lines represent networks trained on unaltered data evaluated with random data. The comment also suggests clarifying whether the nonrandom data was normalized and recommends showing examples of the random data in the appendix. These suggestions are clear and detailed, offering the authors concrete steps to improve the clarity and comprehensiveness of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the meaning of \"100 steps\" in the context of search models comparison in section 5.1. It asks whether this refers to 100 sampled strategies. While the comment does not provide explicit instructions for the authors, it implies that clarification is needed regarding this specific detail. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the meaning of \"100 steps\" in their draft. However, the comment provides a clear direction for what needs to be addressed, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"100 steps,\" which is a clear and direct question that requires a specific response. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the meaning of \"100 steps\" in the context of search models comparison. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"100 steps\" in the context of search models comparison in section 5.1, specifically asking if it refers to 100 sampled strategies. While the comment identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might clarify this point or improve their draft. The feedback is limited in its actionable nature, offering only a question without any constructive advice or direction for improvement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should repeat the experiments and conduct statistical significance analysis on the numbers, as the current results do not provide enough information to determine the significance of the improvements. This is a clear and direct action for the authors to take, providing concrete guidance on how to improve their draft. The comment also suggests rejecting the paper due to limited novelty and marginal improvement, which is an explicit recommendation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Fig.5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the results, such as the lack of mean and standard deviation, and the difficulty in determining statistical significance. The suggestion to repeat the experiments and conduct statistical significance analysis provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the improvement over previous methods is small, about 0.2%1%, and questions the statistical significance of the results. It also points out that the results in Table 1 and Fig.5 do not report the mean and standard deviation, making it difficult to assess the significance of the differences. The reviewer suggests repeating the experiments and conducting statistical significance analysis to address these issues. While the claim about the small improvement is supported by the percentage range, the comment lacks specific examples or references to substantiate the claim further. Additionally, the suggestion to repeat experiments and conduct statistical analysis is logical but could be more detailed. Therefore, the comment is 4, as it provides a clear direction for improvement but could benefit from more detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the improvement over previous methods is small, ranging from 0.2% to 1%. It also points out that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to determine the statistical significance of the differences. The reviewer provides a clear and actionable suggestion to repeat the experiments and conduct statistical significance analysis to address these concerns. Additionally, the comment suggests rejecting the paper due to limited novelty and marginal improvement. This feedback is 5 as it not only identifies specific areas for improvement but also provides a clear path forward for the authors to enhance their work. However, the suggestion to reject the paper could be more nuanced, as it might not be the only outcome based on the improvements made. Overall, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the \"approach section\" is missing from the main paper and suggests that the supplementary material should be used as additional information rather than an extension. The reviewer also references a specific paper by Timothy Nguyen, Zhourong Chen, and Jaehoon Lee, which implies that the authors should consider including a similar approach section in their paper. However, the comment does not provide specific guidance on how to incorporate this section or what it should contain. While the action is explicit, the lack of detailed instructions on implementation makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"approach section\" in the main paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by noting that the supplementary material should be used as additional information rather than an extension. Additionally, the comment references a specific paper, providing a clear direction for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"approach section\" is missing from the main paper and suggests that the supplementary material should be used as additional information rather than an extension. The reviewer provides a reference to a specific paper, \"Dataset metalearning from kernel ridgeregression,\" which supports the claim that the approach section is missing. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The addition of the reference provides some support, but the comment could be strengthened with more explicit justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant omission in the paper, specifically the absence of an \"approach section\" in the main paper. It highlights that the supplementary material is being used as an extension rather than additional information, which is not appropriate. The comment also references a relevant paper, \"Dataset metalearning from kernel ridgeregression,\" which provides a basis for the authors to consider including a similar approach section in their paper. This feedback is clear and actionable, as it directs the authors to a specific area for improvement and provides a reference for further exploration. However, the comment could be more helpful if it offered suggestions on how to integrate the approach section or what specific aspects should be included. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the statement in the introduction regarding the biological plausibility of backpropagation is too weak and contradicts the widely accepted view that backpropagation is biologically implausible. However, it does not provide explicit guidance on how the authors should revise this statement or what specific changes should be made to strengthen the argument. The action is implicit, as the authors need to infer that they should revise the statement to align with the accepted view, but it lacks concrete details on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"statement in the introduction regarding the biological plausibility of backpropagation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, indicating that it may be too weak and contradicts the widely accepted view that backpropagation is biologically implausible. This provides clear guidance on what needs to be addressed in the introduction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement regarding the biological plausibility of backpropagation is too weak, as it is widely accepted that backpropagation is biologically implausible. The reviewer provides a logical reasoning by stating that the current statement contradicts the accepted view, which is a clear and straightforward justification. However, the comment could be strengthened by providing specific references or examples to support the claim that backpropagation is widely considered biologically implausible. Despite this, the claim is 4 due to the logical reasoning provided, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction, questioning the statement regarding the biological plausibility of backpropagation. It points out that the current phrasing may be too weak, as it contradicts the widely accepted view that backpropagation is biologically implausible. This feedback is clear and actionable, as it prompts the authors to reconsider and strengthen their argument regarding the biological plausibility of backpropagation. However, the comment could be more helpful if it provided suggestions on how to revise the statement or offered additional context to support the claim. Overall, the comment is 4, as it directs the authors to a critical area that needs improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the implications of the necessary conditions for robust memorization and generalization bounds. It suggests that the constructions of ReLU networks for robust memorization may not necessarily lead to robust generalization, which is acknowledged in the conclusion but considered a serious question. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve their draft. The action is implicit and vague, as the authors are left to infer that they should explore this connection further but are not given specific steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the implications of the necessary conditions for robust memorization and generalization bounds, specifically questioning whether the constructions of ReLU networks for robust memorization would lead to robust generalization. While the authors acknowledge this in the conclusion, the comment suggests it is a serious question. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing the concern about the connection between robust memorization and generalization, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the implications of the necessary conditions for robust memorization and generalization bounds. It suggests that the constructions of ReLU networks for robust memorization may not necessarily lead to robust generalization, which is acknowledged in the conclusion. However, the comment does not provide specific evidence, examples, or references to support this claim, making it 3. The authors are left to infer the reasoning behind the concern, which could be clarified with more detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the relationship between the necessary conditions for robust memorization and generalization bounds. It points out that while the paper acknowledges this issue in the conclusion, it is a serious question that warrants further exploration. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or improve their draft. While it highlights an important area for consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it identifies a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should mention the use of untrained neural networks (like deep image prior) for solving inverse problems across a wide class of images, as shown in recent papers. It also recommends comparing the current method with these types of methods. While the comment implies that the authors should include this information and comparison, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss and compare their method with existing work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"OOD experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a suggestion to mention the use of untrained neural networks (like deep image prior) for solving inverse problems and to place the current method in context by comparing it with those methods. This level of detail guides the authors on what needs to be addressed and how to improve their work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the novelty of the OOD experiments and suggests that the authors should mention the use of untrained neural networks for solving inverse problems. The reviewer supports this claim by referencing a specific paper (Ulyanov et al., CVPR 2018) that demonstrates the effectiveness of untrained neural networks for this purpose. This provides a clear and specific reference that helps substantiate the claim, making it 4. However, the comment could be strengthened by providing more detailed comparisons or examples of how the current method differs from or improves upon existing approaches. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment acknowledges the interest of the OOD experiments, noting that the trained network provides strong OOD generalization. However, it suggests that the authors should place their method in context by mentioning the use of untrained neural networks (like deep image prior) for solving inverse problems, as demonstrated in recent papers. This feedback is valuable as it encourages the authors to position their work within the broader literature and consider comparisons with existing methods. While the comment provides a clear direction for improvement, it could be more helpful by offering specific suggestions on how to integrate this information into the paper or what aspects to focus on in the comparison. Overall, the comment is 4, as it guides the authors toward a more comprehensive and contextual presentation of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This implies that the authors should explore this reformulation to improve the proxlinear algorithms for solving the stochastic problem in Eq.(1). However, the comment does not provide explicit instructions on how to implement this reformulation or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer the steps to take and how to apply the suggested reformulation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq.(1)\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the proxlinear subproblem can be reformulated using the conjugate function, which makes the motivation of Algorithm 1 unclear. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This claim is 3 as it provides a logical reasoning for the equivalence, but it lacks specific examples or references to support the assertion fully. The authors would need to explore the reformulation to understand the claim\"s validity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation of Algorithm 1, suggesting that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This observation implies that the motivation for Algorithm 1 may be unclear or unnecessary. However, the comment does not provide specific guidance on how to address this issue or improve the clarity of the motivation. While it highlights a potential weakness, it lacks actionable suggestions or detailed feedback, making it 3. The authors are given some insight into a potential area for improvement but are left without a clear path forward. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks the authors to provide an explanation for the degradation in performance when using additional information about missing, wrong, or redundant data in the FBN results. This request is clear and direct, leaving no ambiguity about what the authors need to do to address the comment. The action is explicit and concrete, as it specifies exactly what information is needed to clarify the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FBN results (table 5),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks the authors to clarify why the performance degrades when using additional information about missing, wrong, or redundant data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the performance degradation in FBN results when using additional information about missing, wrong, or redundant data. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual question seeking information, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of concern regarding the performance degradation in FBN results when using additional information about missing, wrong, or redundant data. By asking the authors to provide clarification on this issue, the comment prompts the authors to address a potential weakness in their analysis. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their results. While it points out an area for improvement, it does not provide actionable feedback, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a gap in the analysis regarding the flatness of the minima found by the proposed method. It explicitly states that the authors need to provide an analysis on the losses of the noiseinjected models after training to ensure that the minima found are indeed flat. This feedback is clear and provides a specific action for the authors to take, making it 5. The authors know exactly what additional analysis is required to strengthen their claim, and the comment offers concrete guidance on how to address the issue.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the analysis about flatness\" and \"the loss used for training base model,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing in the analysis regarding the flatness of the minima and provides a detailed explanation of why the current approach does not ensure flatness. The comment suggests that the authors need to analyze the losses of the noiseinjected models after training to support their claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis about flatness is missing, specifically addressing the use of averaged loss for training the base model. The reviewer provides a logical explanation by pointing out that minimizing the averaged loss does not ensure the flatness of the minima. This reasoning is clear and provides a basis for the claim. However, the comment could be strengthened by referencing specific studies or examples that demonstrate the importance of analyzing the losses of noiseinjected models after training. Overall, the claim is 4, as it provides a solid foundation for the argument but could benefit from additional references or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical gap in the analysis regarding the flatness of the minima found by the proposed method. It points out that the analysis provided does not ensure the flatness of the minima, as minimizing the averaged loss across noiseinjected models does not guarantee flatness. The comment provides a clear and actionable suggestion for the authors to conduct an analysis on the losses of the noiseinjected models after training to support their claim. This feedback is 5 as it directs the authors to a specific area where they need to strengthen their argument, offering a clear path for improvement. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the presentation of the model in section 4 is complicated and requires careful reading, possibly with reference to the supplement. It provides specific and concrete actions for improvement, such as replacing natural language descriptions with notation and adding breakout diagrams to show the attention mechanisms. These suggestions are explicit and provide clear guidance on how to enhance the clarity of the presentation. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific suggestions for improving the presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to show the attention mechanisms. This level of detail helps the authors understand what needs to be addressed in the presentation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the model\"s presentation in section 4 is complicated and requires careful reading, possibly with reference to the supplement. It provides a specific suggestion to improve the presentation by replacing natural language descriptions with notation and adding breakout diagrams to show the attention mechanisms. However, the comment does not provide any evidence or examples to support the claim that the current presentation is complicated or how the suggested changes would improve clarity. This lack of detailed justification makes the claim 3, as the authors would need to infer the necessity of the suggested changes based on the reviewer\"s feedback.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the model in section 4, noting that it is somewhat complicated and requires careful reading. It provides actionable feedback by suggesting ways to improve the presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to show the attention mechanisms. These suggestions are clear and concrete, offering the authors a direct path to enhance the clarity and accessibility of their work. However, the comment could be more helpful if it included specific examples or further elaboration on how to implement these suggestions. Overall, the feedback is 4 as it provides valuable guidance for improving the draft, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the red line in Figure 3, specifically asking where the test data comes from and whether there is a ground truth. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they need to clarify the source of the test data and the existence of a ground truth, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the red line, asking about the source of the test data and the existence of a ground truth. This provides clear guidance on what needs to be clarified or addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the red line in Figure 3, specifically asking about the source of the test data and the existence of a ground truth. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about Figure 3, asking about the source of the test data and whether there is a ground truth associated with the red line. While it identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might clarify this point or improve the figure. The comment is 3 as it points out a potential issue, but it lacks actionable feedback or detailed advice on how to address it. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the goal of the paper, specifically the lack of comparison with existing DAS earthquake detectors like PhaseNetDas. It suggests that if the claim is about the paper being a foundation model with a proofofconcept test, it should be clearer and justified with a future useful application. While the comment identifies a gap in the paper, it does not provide explicit instructions on how to address this issue, such as suggesting specific comparisons or justifications to include. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context and justification for their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"goal of the paper\" and references a specific existing work, \"PhaseNetDas, Zhu et al. 2023,\" which helps the authors identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of comparison with existing DAS earthquake detectors and the need for a clearer justification of the benefit of the proposed method. Additionally, it suggests that if the claim is about the paper being a foundation model, it should be clearer and should include a future useful application. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the paper\"s goal, specifically the lack of comparison with existing DAS earthquake detectors like PhaseNetDas. It suggests that if the claim is about the paper being a foundation model, it should be clearer and justified with a future useful application. The comment provides a specific reference to PhaseNetDas, which supports the claim that such detectors exist. However, it lacks detailed reasoning or examples to fully substantiate the claim that the paper\"s goal is unclear or that comparisons are necessary. The reference to PhaseNetDas is a good starting point, but more detailed justification or examples would strengthen the argument. Therefore, the comment is 3, as it provides a basis for the claim but requires additional evidence or explanation to be fully substantiated.", "helpfulness_rationale": "The review comment raises a critical concern about the paper\"s goal, specifically the lack of comparison with existing DAS earthquake detectors like PhaseNetDas. It points out that no comparison was made, nor was there a justification for the benefit of the proposed method over existing ones. The comment suggests that if the paper claims to be a foundation model, it should be clearer and should include a future useful application. This feedback is clear and actionable, as it identifies a significant gap in the paper and provides guidance on how to address it. However, it could be more helpful if it offered specific suggestions on how to conduct the comparison or what aspects to focus on. Overall, the comment is 4, as it directs the authors to a critical area that needs improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the alignment of results between Table 6 and Table 1 (MCTpair), as well as the ablation studies of MCT without adaptive metrics. While it identifies areas of potential concern, it does not provide explicit instructions or suggestions on how the authors should address these issues. The authors can infer that they need to investigate and clarify these discrepancies, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it points out areas for investigation but does not provide detailed steps for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6\" and \"Table 1 (MCTpair),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the alignment of results and the absence of ablation studies for MCT without adaptive metrics. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the alignment of results between Table 6 and Table 1 (MCTpair), as well as the absence of ablation studies for MCT without adaptive metrics. However, it does not provide any supporting evidence, reasoning, or references to justify these claims. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the questions, rendering the comment 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises two specific questions about the results presented in the paper. It questions the alignment of results between Table 6 and Table 1 (MCTpair), which could indicate a discrepancy or inconsistency in the data. Additionally, it asks about the absence of ablation studies for MCT without adaptive metrics, suggesting that this could be an important aspect to explore. While the comment identifies potential issues, it does not provide detailed guidance or suggestions on how the authors might address these concerns. The feedback is 3 as it points out areas for further investigation, but it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the inclusion of AccNet as part of a larger predictor, such as for semantic segmentation, that utilizes similar operators. While it suggests exploring this idea, it does not provide explicit instructions or concrete steps for the authors to take. The comment implies that the authors should consider this possibility, but it lacks specificity and detail on how to implement or evaluate this suggestion. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 126,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides a specific suggestion by asking whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. This level of detail provides clear guidance on what the authors should consider, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the inclusion of AccNet as part of a larger predictor, such as for semantic segmentation, that utilizes similar operators. However, it does not provide any supporting evidence, reasoning, or references to justify why this would be beneficial or how it relates to the current work. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the inclusion of AccNet as part of a larger predictor, such as for semantic segmentation, that utilizes similar operators. This suggests a potential extension or application of the current work, which could be valuable for the authors to consider. However, the comment lacks depth and does not provide specific guidance or suggestions on how to explore this idea or what benefits it might bring. While it identifies a possible area for expansion, it does not offer actionable steps or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies two issues: undefined abbreviations and superscript notation in an equation that is not defined until later in the paper. The reviewer provides specific examples, such as \"NE\" on line 73 and the superscript notation in equation 6, which are not defined until much later. This feedback is clear and actionable, as it directs the authors to define these abbreviations and notation at the point of their first appearance. The inclusion of references to relevant literature adds context and supports the need for clarity in the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"L73\" and \"Eq 6,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issues, namely undefined abbreviations and superscript notation, which need to be addressed. Additionally, the comment provides references to relevant literature, which further supports the need for clarity in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some abbreviations are not defined and that superscript notation in an equation is not defined until later in the paper, which hinders understanding. The reviewer provides specific examples, such as \"NE\" on line 73 and the superscript notation in equation 6, and references relevant literature to support the need for clarity. This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or explanations of how these issues impact the paper\"s clarity. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies two specific issues that hinder the understanding of the paper: undefined abbreviations and superscript notation in an equation that is not defined until later. By providing examples, such as \"NE\" on line 73 and the superscript notation in equation 6, the reviewer offers clear and actionable feedback. Additionally, the comment includes references to relevant literature, which can help the authors understand the context and importance of addressing these issues. This feedback is detailed and provides concrete steps for improvement, making it 5 for the authors to enhance the clarity and readability of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point consists of two separate issues. The first part addresses a potential inaccuracy in the Related Work section regarding the Walkman algorithm, suggesting that it is not accurate to state that all works are based on simple SGD for decentralized optimization. This is an explicit action for the authors to correct the statement. The second part points out a lack of clarity in the reference to \"it\" in Section 3, suggesting that the authors should clarify the reference. Both parts provide explicit actions with clear guidance on how to address the issues. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 2, second paragraph in Related Work\" and \"Section 3, first paragraph,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the inaccuracies in the statements regarding the Walkman algorithm and the lack of clarity in the reference to \"it.\" The comment provides clear guidance on what needs to be corrected or clarified, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two separate claims. The first claim challenges the statement that all works are based on simple SGD for decentralized optimization, pointing out that the Walkman algorithm (Mao et al., 2020) uses ADMM with two versions. This claim is 4 as it provides specific details about the algorithm used, which supports the argument. However, the comment could be strengthened by providing more context or examples of other works that use different methods. The second claim points out a lack of clarity in the reference to \"it\" in Section 3, which is a factual observation and not a claim. Therefore, the first part of the comment is rated as 4, and the second part is factual, so it is labeled as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by addressing two distinct issues in the paper. First, it corrects an inaccuracy in the Related Work section regarding the Walkman algorithm, pointing out that it uses ADMM with two versions, not just simple SGD. This feedback is clear and helps the authors improve the accuracy of their work. Second, it identifies a lack of clarity in the reference to \"it\" in Section 3, suggesting that the authors should clarify the reference. This feedback is also actionable, as it directs the authors to enhance the clarity of their writing. By addressing these specific issues, the comment is 5, as it provides detailed guidance for improving the draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should present the average results on the test set with clearly defined error bars under different random seeds. This is a direct and concrete action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be done, making it clear and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: presenting the average results on the test set with clearly defined error bars under different random seeds. This provides clear guidance on how to improve the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results presented in Tables 1 and 2, which are based on the dev set, are not convincing. The reviewer suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This claim is 3 as it provides a logical reasoning for why the current presentation of results may not be sufficient for convincing the audience. However, the comment lacks specific examples or references to support the claim that the current results are not convincing, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in Tables 1 and 2, noting that the best results are reported on the dev set after hyperparameter search and model selection on the dev set. The reviewer suggests that presenting average results on the test set with clearly defined error bars under different random seeds would be more convincing. This feedback is clear and actionable, providing the authors with a specific direction to enhance the credibility and robustness of their results. By addressing this suggestion, the authors can improve the transparency and reliability of their findings, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the methodology and dataset used in the paper. It asks for the number of topics used, how topicword parameters were obtained for the \"real\" dataset, and the size of the AG news dataset. Additionally, it requests that the main paper describe the number of documents in the train and test sets and the number of vocabulary words. While the comment does not explicitly instruct the authors to provide this information, it implies that the authors should include these details in the paper. The action is implicit but concrete, as the authors know exactly what information is missing and can easily address it. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises several questions about the methodology and dataset used in the paper, specifically asking about the number of topics used, how topicword parameters were obtained, the size of the AG news dataset, and the number of documents in the train and test sets, as well as the number of vocabulary words. While it does not explicitly mention a specific section of the paper, the authors can infer that these questions relate to the methodology and results sections. The comment is specific in detailing what information is missing, providing clear guidance on what the authors need to address. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification on specific aspects of the methodology and dataset used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and aim to gather information, making the comment a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions about the methodology and dataset used in the paper. It asks for specific details such as the number of topics used, how topicword parameters were obtained, the size of the AG news dataset, and the number of documents in the train and test sets, as well as the number of vocabulary words. These questions are relevant and could help the authors clarify and improve their methodology and presentation. However, the comment could be more helpful if it provided suggestions on how to address these questions or offered guidance on what information should be included in the paper. Overall, the comment is 3 as it identifies areas for clarification but lacks depth and actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that to evaluate the claim of reducing exposure bias, the authors should train a discriminator on generations from the learned model, similar to Figure 1. It also notes a difference between this approach and Figure 4, where the discriminator is coadapting with the generator and might get stuck at a local optimum. While the comment implies that the authors should conduct this evaluation, it does not explicitly instruct them to do so. The action is somewhat inferred and lacks detailed guidance on how to implement the suggested evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that training a discriminator on generations from the learned model is needed to confirm the claim of reducing exposure bias. This provides clear guidance on what needs to be addressed in the evaluation section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that training a discriminator on generations from the learned model is necessary to confirm the claim of reducing exposure bias. It provides a logical reasoning by comparing this approach to Figure 1 and noting the difference with Figure 4, where the discriminator is coadapting with the generator. This comparison helps to clarify the need for the suggested evaluation. However, the comment could be strengthened by providing more detailed examples or references to support the claim. Overall, the comment is 4, as it provides a clear rationale but lacks specific references or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a specific suggestion for evaluating the claim of reducing exposure bias in the paper. It recommends training a discriminator on generations from the learned model, similar to Figure 1, to confirm the claim. This feedback is clear and actionable, as it offers a concrete step the authors can take to strengthen their evaluation. However, the comment could be more helpful if it included additional guidance on how to implement this evaluation or why this approach is necessary. Despite this, the suggestion is valuable and provides a clear direction for improvement, making the comment 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the organization of prompts in Table 6 and 7, noting that the sentences are squeezed together. However, it does not provide explicit guidance on how to address this issue, such as suggesting ways to reorganize the prompts or improve their presentation. The action is implicit and somewhat vague, as the authors can infer that they need to improve the layout, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6 and 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the prompts, noting that they are not wellorganized and that all sentences are squeezed together. This provides clear guidance on what needs to be addressed to improve the presentation of the prompts. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the prompts in Table 6 and 7 are not wellorganized, specifically noting that all sentences are squeezed together. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of prompts in Tables 6 and 7, noting that the sentences are squeezed together. This feedback is clear and actionable, as it directs the authors to improve the layout and organization of their prompts. However, the comment could be more helpful if it provided suggestions on how to reorganize the prompts or offered examples of better formatting. Despite this, the feedback is still valuable as it highlights a tangible area for improvement, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies issues with the clarity of the figures, specifically mentioning that figure 2 is confusing due to the relation of its subfigures and that some modules, such as CMAF, L_BT, and VoLTA, are not labeled. This provides clear and direct actions for the authors to take, which is to improve the clarity of the figures and ensure all components are labeled. The feedback is explicit and concrete, giving the authors a clear understanding of what needs to be done to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 2\" and \"some modules,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the figures, such as the confusion in the relation of subfigures and the lack of labels for certain modules like CMAF, L_BT, and VoLTA. This provides clear guidance on what needs to be addressed to improve the clarity of the figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the figures are not clear, specifically mentioning that figure 2 is confusing due to the relation of its subfigures and that some modules are not labeled. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity of the figures, particularly in figure 2, where the relation between subfigures is confusing. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled. This feedback is clear and actionable, as it provides the authors with direct guidance on how to improve the visual presentation of their work. By addressing these issues, the authors can enhance the readability and comprehensibility of their figures, which is crucial for the understanding and impact of their research. Therefore, the comment is 4, as it offers specific and actionable feedback that can significantly improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about questionable design choices, specifically the use of perplexity as a measure of the model retaining semantic information after finetuning. It highlights the need to consider domain drift and catastrophic forgetting, suggesting that these factors should be controlled. However, the comment does not provide explicit guidance on how to address these concerns or control these factors. The authors are left to infer that they need to explore alternative measures or methods to mitigate these issues, but without concrete suggestions, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about \"questionable design choices\" related to the use of perplexity as a measure of the model retaining semantic information after finetuning. It mentions the need to consider domain drift and catastrophic forgetting, suggesting that these factors should be controlled. However, the comment does not specify which part of the paper discusses these design choices or where the authors should address these concerns. The authors can make an educated guess that it relates to the methodology or results sections, but the lack of explicit references makes it weakly grounded. The comment is specific in identifying the issues with the design choices, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises concerns about the use of perplexity as a measure of the model retaining semantic information after finetuning, suggesting that it may not fully account for domain drift and catastrophic forgetting. The comment questions how these factors are controlled, implying that the authors should provide a more comprehensive explanation or justification for their design choices. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional context or evidence to fully address the concern, which aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a valid concern about the use of perplexity as a measure of the model\"s ability to retain semantic information after finetuning. It highlights the potential issue of domain drift and catastrophic forgetting, which are separate from the original task. The comment prompts the authors to consider how these factors are controlled, which is a relevant and important aspect of their methodology. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these concerns, such as recommending alternative measures or methods to mitigate domain drift and catastrophic forgetting. Despite this, the comment still offers valuable insight into a potential weakness in the paper, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide a more comprehensive overview of existing methods and their limitations in the Related Work section, specifically mentioning several types of methods that should be discussed. It also suggests positioning SSMs appropriately within this context. The comment provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Related Work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed guidance on what is lacking in the section, specifically suggesting the inclusion of a more comprehensive overview of existing methods and their limitations, including specific types of methods such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This level of detail provides clear direction for the authors on how to improve the section. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Related Work section lacks details, specifically regarding longcontext language models. It suggests that the authors should provide a more comprehensive overview of existing methods and their limitations, including specific types of methods such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. The comment provides a clear and detailed list of what is missing, which is a strong basis for the claim. However, it does not include specific references or examples to fully substantiate the claim, making it 4. The authors would need to consult the references provided to fully understand the context and justify the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the Related Work section, which is deemed lacking in details. It provides a clear and actionable suggestion by specifying the types of methods that should be discussed, such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This feedback is valuable as it guides the authors on how to enhance the comprehensiveness and depth of their Related Work section, particularly in the context of longcontext language models. However, the comment could be more helpful if it offered additional guidance on how to integrate these methods or provided examples of how to effectively position SSMs within the existing literature. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with further details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it does not provide specific guidance on what aspects of the writing need improvement or which points are unclear. The comment lacks explicit or implicit actions that the authors can take to address the issue. Without concrete suggestions or examples, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it does not specify which points are unclear or provide any guidance on how to improve the writing. This makes it difficult for the authors to identify the exact areas that need attention. The comment lacks both grounding and specificity, as it does not mention a specific section or part of the paper and does not provide detailed feedback on what needs to be clarified. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"The writing should be improved\" and mentions that \"some points in the paper are unclear.\" However, it does not provide any specific examples or details about what aspects of the writing are unclear or how they could be improved. Without supporting evidence or examples, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it lacks specificity and does not provide any detailed guidance or examples on what aspects of the writing need improvement or which points are unclear. Without actionable feedback or suggestions, the authors are left without a clear understanding of how to address the issues identified. This makes the comment 2, as it identifies a general area for improvement but does not provide enough detail to be actionable."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point mentions that the writing and annotations are \"a little hard to follow,\" but it does not provide any specific guidance or suggestions on how to improve the clarity or readability of the text. There is no explicit or implicit action for the authors to take, such as revising certain sections or providing additional explanations. Without actionable advice, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"poor writing and annotations,\" but it does not specify which part of the paper is affected by these issues. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which areas need improvement. Additionally, the comment lacks specificity regarding what aspects of the writing or annotations are problematic, such as clarity, organization, or consistency. This makes it difficult for the authors to address the feedback effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"poor writing and annotations are a little hard to follow,\" but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed feedback or suggestions on how to improve the clarity, the authors may find it challenging to address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a general issue with the writing and annotations being \"a little hard to follow,\" which is a common problem in academic papers. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might improve the clarity or readability of their work. Without detailed guidance or examples, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, the comment is 2, as it identifies a problem but does not offer any actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the performance of the proposed method in Table 2, specifically noting that only 8 out of 14 evaluation metrics achieve stateoftheart (SOTA) performances. It also questions the discrepancy in the overall F1 score versus the F1 score for single types under the \"Twitter2017 \u2192 Twitter2015\" setting. While the comment highlights areas of concern, it does not provide explicit instructions or suggestions for the authors to address these issues. The authors are left to infer that they should investigate and clarify these discrepancies, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it identifies areas for further investigation but does not provide detailed steps for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proposed method\"s performance, noting that only 8 out of 14 evaluation metrics achieve stateoftheart performances. Additionally, it raises a question about the discrepancy in the overall F1 score versus the F1 score for single types under a specific setting. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the performance of the proposed method in Table 2, specifically noting that only 8 out of 14 evaluation metrics achieve stateoftheart (SOTA) performances. It also questions the discrepancy in the overall F1 score versus the F1 score for single types under a specific setting. While the comment highlights areas of concern, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the critique, rendering the comment 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a specific concern about the performance of the proposed method in Table 2, noting that only 8 out of 14 evaluation metrics achieve stateoftheart (SOTA) performances. It also questions the discrepancy in the overall F1 score versus the F1 score for single types under a specific setting. This feedback is 3 as it identifies a potential issue with the method\"s performance and prompts the authors to investigate and clarify these discrepancies. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these concerns. To be more helpful, the comment could include recommendations for improving the method or suggestions for further analysis. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the proposed solution as an incremental step based on the relaxation proposed by Guzman et al. However, it does not provide any explicit or implicit suggestions for improvement. There is no guidance on what specific aspects of the solution need to be addressed or how the authors might enhance their work. Without actionable feedback, the authors are left without a clear understanding of what changes to make to their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the proposed solution as an incremental step based on the relaxation proposed by Guzman et al. However, it does not specify which part of the paper this incremental step is discussed in, nor does it provide any specific feedback or suggestions for improvement. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not detail what needs to be addressed or improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point acknowledges the proposed solution as an incremental step based on the relaxation proposed by Guzman et al. However, it does not provide any further explanation, evidence, or reasoning to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the comment or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the proposed solution as an incremental step based on the relaxation proposed by Guzman et al. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance or critique, the authors are left without a clear understanding of how to enhance their work. The comment is vague and does not offer any constructive advice, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests several improvements to the results presentation, including labeling the yaxis in Figures 2 and 3 as \"runtime\" instead of \"performance,\" and adding a scatter plot with runtime and performance on the x and y axes, respectively. It also recommends highlighting the best results in tables. These suggestions are explicit and provide concrete guidance on how to enhance the clarity and effectiveness of the results presentation. The comment is 5 as it clearly outlines specific actions for the authors to take, ensuring they know exactly what changes to make to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the yaxis labels, suggests a change to the figure to include runtime, and recommends highlighting the best results in tables. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the results presentation can be improved by labeling the yaxis in Figures 2 and 3 as \"runtime\" instead of \"performance,\" and by adding a scatter plot with runtime and performance on the x and y axes. It also recommends highlighting the best results in tables. While the comment provides a logical suggestion for improving the clarity of the results, it lacks specific examples or references to support the claim that the current presentation is ambiguous. The suggestion is 3 as it offers a clear direction for improvement but lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on improving the presentation of results in the paper. It identifies issues with the labeling of the yaxis in Figures 2 and 3, suggesting that \"performance\" is an ambiguous label, and recommends labeling it as \"runtime\" instead. Additionally, it suggests creating a scatter plot with runtime and performance on the x and y axes, respectively, to enhance the reader\"s understanding of the results. The comment also recommends highlighting the best results in tables. These suggestions are clear and concrete, offering the authors a direct path to enhance the clarity and effectiveness of their results presentation. However, the comment could be more helpful if it provided additional context or examples of how to effectively present the results. Overall, the feedback is 4, as it provides valuable guidance for improving the draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the appropriateness of the term \"Unsupervised Online Adaptation\" given that the model requires a training set with documents, queries, and labels, which implies the need for annotations. This comment highlights a potential inconsistency in the terminology used in the paper. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or clarify the terminology. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider the terminology or provide additional clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the appropriateness of the term \"Unsupervised Online Adaptation\" due to the requirement of a training set with documents, queries, and labels, which implies the need for annotations. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the appropriateness of the term \"Unsupervised Online Adaptation\" due to the requirement of a training set with documents, queries, and labels, which implies the need for annotations. This claim is 3 as it provides a logical reasoning for the potential inconsistency in the terminology. However, the comment lacks specific examples or references to support the claim fully, making it 3. The authors would need to consider the context and rationale behind the terminology choice to fully address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the terminology used in the paper, specifically questioning the label \"Unsupervised Online Adaptation\" given that the model requires a training set with documents, queries, and labels, which implies the need for annotations. This observation highlights a critical issue that could impact the clarity and accuracy of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or clarify the terminology. While it points out a significant problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it prompts the authors to reconsider their terminology but does not fully support them in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the results are presented in a convoluted manner, specifically noting that the safety violations of the agent in the first 1000 episodes are disregarded. It questions the reason for presenting the results in this way, implying that the authors should clarify or justify their approach. However, the comment does not provide explicit guidance on how to address this issue or suggest specific changes to improve the presentation of results. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the reasoning behind their presentation of results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"results\" and the specific issue of disregarding safety violations in the first 1000 episodes, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the problem with the presentation of results, namely the disregard for safety violations, and questions the reason for this presentation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are presented in a convoluted manner and questions the reason for disregarding safety violations in the first 1000 episodes. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The lack of evidence or detailed explanation renders the claim 3, as the authors would need to infer the basis of the critique and potentially conduct additional analysis to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results, noting that the safety violations of the agent in the first 1000 episodes are disregarded. It questions the reason for this presentation, which is a clear and actionable point for the authors to address. By highlighting this discrepancy, the comment prompts the authors to reconsider their approach to presenting results and to provide a justification for their method. However, the comment could be more helpful if it offered suggestions on how to improve the presentation or provided examples of alternative approaches. Overall, the feedback is 4 as it directs the authors to a critical area that needs clarification and improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. However, it does not provide explicit guidance on how to correct these errors or suggest specific actions for the authors to take. The comment implies that the authors should review their manuscript for such errors and correct them, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment identifies specific writing errors on pages 5 and 1, providing full grounding as the authors can accurately pinpoint these sections. It specifies the issues, such as \"informative informative\" and the lack of a title for \"performance,\" which are clear and actionable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are writing errors in the paper, specifically mentioning \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. However, the comment does not provide any further explanation or evidence to support these claims, such as examples of other errors or how these specific errors impact the paper\"s clarity. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This feedback is clear and actionable, as it directs the authors to review their manuscript for such errors and correct them. However, the comment could be more helpful if it provided suggestions on how to improve the writing or offered examples of better phrasing. Despite this, the comment is 4 as it highlights a specific area for improvement, allowing the authors to make targeted revisions. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two parts: a comment about a statement on line 134 and a suggestion regarding Theorem 4.1. The first part points out a limitation related to the standard sigmoid function and its dependence on the maximum slope. While it highlights an issue, it does not provide explicit guidance on how to address it. The second part suggests elaborating on Theorem 4.1 in the main text, providing an intuitive explanation of why the RNN converges to the nearest fixed point. This suggestion is explicit and provides a clear direction for improvement. However, the comment could be more actionable if it included specific details on what aspects of Theorem 4.1 need elaboration. Overall, the comment is 4, as it provides a clear direction for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 134\" and \"Theorem 4.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the elaboration of the statement on line 134 and the explanation of Theorem 4.1 in the main text. The comment provides clear guidance on how to improve the clarity and comprehensiveness of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a comment about a statement on line 134 and a suggestion regarding Theorem 4.1. The first part critiques the statement by pointing out its limitation to the standard sigmoid function and its dependence on the maximum slope. This critique is 3 as it provides a logical reasoning about the limitation but lacks specific references or examples to fully substantiate the claim. The second part suggests elaborating on Theorem 4.1, providing an intuitive explanation of why the RNN converges to the nearest fixed point. This suggestion is more verifiable as it offers a clear direction for improvement. However, the comment could be strengthened by providing more detailed reasoning or references. Overall, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment provides two distinct points of feedback. First, it critiques a statement on line 134, pointing out that it is only true for the standard sigmoid function and depends on the maximum slope. This feedback is 3 as it highlights a potential limitation in the statement, but it does not offer specific guidance on how to address this issue. Second, the comment suggests elaborating on Theorem 4.1 in the main text, providing an intuitive explanation of why the RNN converges to the nearest fixed point. This suggestion is more actionable, as it offers a clear direction for improvement by explaining a theoretical concept in more detail. However, the comment could be more helpful if it included specific examples or further elaboration on what aspects of Theorem 4.1 need clarification. Overall, the comment is 3, as it identifies areas for improvement but lacks depth and specificity in its suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the planbased method, noting that it requires manual design of a plan based on ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to those with predefined plans, as indicated by Table 2. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve the generalizability of their method. The feedback lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the planbased method and its requirement for manual design of a plan based on ground truth, which is unrealistic in realworld scenarios. It also mentions the comparison with learned plan methods and the difficulty in generalizing to new datasets without ground truth summaries, as indicated by Table 2. However, the comment does not specify which part of the paper discusses these issues or where Table 2 is located, making it weakly grounded. The comment is specific in detailing the concerns about the planbased method and its limitations, but without clear grounding, it is challenging for the authors to pinpoint the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the planbased method requires manual design of a plan based on ground truth, which is unrealistic in realworld scenarios. It also suggests that the learned plan methods are not comparable to those with predefined plans, as indicated by Table 2. The comment provides a logical reasoning by highlighting the impracticality of manual plan design and the lack of comparability with predefined plans. However, it lacks specific examples or references to support the claim fully, making it 3. The authors would need to consider the implications of this claim and potentially provide additional evidence or comparisons to strengthen their argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the planbased method, specifically that it requires manual design of a plan based on ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to those with predefined plans, as indicated by Table 2. This feedback highlights a critical issue with the generalizability of the proposed method, suggesting that it may struggle to adapt to new datasets without access to ground truth summaries. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or improve the generalizability of their method. While it raises an important concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct experiments using multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance. While the comment encourages the authors to perform this exercise, it does not provide specific guidance on how to implement it or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the details of the suggested experiment. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental setup, specifically mentioning the use of a single heldout test set in nearly all experiments. It suggests that the authors should consider using multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental methodology section. The suggestion is specific, as it provides a clear direction for improvement by recommending a standard practice in the field. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should use multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance, as is standard practice in most papers on Gaussian Processes (GPs). The reviewer acknowledges that the size of the datasets might make this process timeconsuming but encourages the authors to carry out this exercise. The comment is 4 as it provides a logical reasoning for the suggestion and references common practice in the field. However, it lacks specific examples or references to support the claim fully, making it 4. Therefore, the comment aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experimental setup, noting that the results are reported for a single heldout test set. It suggests that using multiple train/test splits or folds would provide a more accurate illustration of the method\"s performance. While the comment acknowledges the potential timeconsuming nature of this process due to the size of the datasets, it encourages the authors to consider this approach. This feedback is clear and actionable, providing the authors with a specific suggestion for improving the robustness and comprehensiveness of their experimental results. However, it could be more helpful if it offered guidance on how to implement this suggestion or addressed potential challenges. Overall, the comment is 4, as it directs the authors toward a meaningful improvement in their experimental methodology."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the method appears more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, it does not provide explicit guidance or suggestions on how to simplify the method or identify the underlying principle. The action is implicit and vague, as the authors are left to infer that they should explore simplification but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the method is more complex than it needs to be and implies the existence of a simpler underlying principle. However, it does not specify which part of the paper this observation pertains to, nor does it provide details on what aspects of the method are overly complex or how the simpler principle could be identified. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what needs to be addressed or how the authors might simplify the method. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the method appears more complex than necessary and implies the existence of a simpler underlying principle. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without concrete evidence or examples of how the method could be simplified, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the method appears more complex than it needs to be, implying that there might be a simpler underlying principle driving the quality gains. However, it does not provide specific guidance or suggestions on how to simplify the method or identify this underlying principle. The comment lacks actionable feedback, as it does not offer concrete steps for the authors to take to address the complexity issue. Without detailed guidance, the authors are left without a clear path for improvement, making the comment 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a specific question about the use of \"s_n\" instead of \"s_t\" in Algorithm 1, Line 8. It also expresses curiosity about the asymptotic performance of the proposed method and requests average return results with more environment steps. The comment provides a reference to a GitHub repository, which could be useful for further exploration. While the comment identifies a potential issue and suggests a specific action (using \"s_n\" instead of \"s_t\"), it lacks detailed guidance on how to implement the change or conduct the requested analysis. The action is explicit but somewhat vague, as the authors know what needs to be addressed but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1 Line 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of \"s_n\" instead of \"s_t\" and expresses curiosity about the asymptotic performance of the proposed method. Additionally, it requests average return results with more environment steps and provides a reference to a GitHub repository. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the use of \"s_n\" instead of \"s_t\" in Algorithm 1, Line 8, and expresses curiosity about the asymptotic performance of the proposed method. It also requests average return results with more environment steps and provides a reference to a GitHub repository. While the comment raises valid points and questions, it lacks detailed reasoning or evidence to fully substantiate the claims. The reference to the GitHub repository is a starting point for further exploration but does not provide comprehensive support for the claims. Therefore, the comment is 3, as it provides a basis for inquiry but requires more detailed justification or evidence to be 5.", "helpfulness_rationale": "The review comment raises a specific question about the use of \"s_n\" instead of \"s_t\" in Algorithm 1, Line 8, which could be a critical error in the implementation. It also expresses curiosity about the asymptotic performance of the proposed method and requests average return results with more environment steps. Additionally, the comment provides a reference to a GitHub repository, which could be useful for further exploration. While the comment identifies a potential issue and suggests a specific action, it could be more helpful if it provided a detailed explanation of why the use of \"s_n\" might be incorrect or how the asymptotic performance could be improved. However, the feedback is 4 as it directs the authors to a specific area of concern and offers a potential resource for further investigation. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point provides several explicit actions for the authors to take. First, it suggests toning down a specific statement regarding the neural network memorizing \"critical points.\" Second, it advises compressing the method section to focus on essential definitions, indicating that this could improve clarity. Lastly, it instructs the authors to doublecheck for grammatical errors, particularly with respect to plurals and articles. These actions are clear and concrete, providing the authors with specific steps to enhance their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"to force the neural network to memorize them\" and the reference to TopoNet 24, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests toning down a particular statement and provides feedback on the method section, suggesting it could be compressed to focus on essential definitions. Additionally, it points out grammatical errors, offering a specific example. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple claims and suggestions. The first claim about the neural network memorizing \"critical points\" is not supported by any evidence or references, making it 1. The suggestion to tone down the statement is vague and lacks justification. The second claim about the method section being wordy is not substantiated with specific examples or reasoning. The comment also mentions grammatical errors without providing examples, which further reduces its verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides several points of feedback that could be helpful for the authors. It suggests toning down a statement regarding the neural network memorizing \"critical points,\" which could help clarify the language and avoid potential misinterpretations. Additionally, it advises compressing the method section to focus on essential definitions, which could improve the clarity and concision of the paper. The comment also points out grammatical errors, specifically mentioning plurals and articles, and provides an example, which is a practical suggestion for improving the paper\"s readability. However, the comment could be more helpful if it provided specific examples of the grammatical errors or offered more detailed guidance on how to compress the method section. Overall, the feedback is 4, as it identifies areas for improvement and offers actionable suggestions, but it could be more comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests a clarification to improve the clarity of the paper. It explicitly recommends updating the definition of uncertainty to include the representation of epistemic model uncertainty in the prior distribution and its update to a posterior distribution upon observing data. This provides a clear and concrete action for the authors to take, ensuring they understand exactly what needs to be done to enhance the clarity of their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the definition of uncertainty, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improving the clarity of the definition by explaining the relationship between the prior and posterior distributions. This feedback is detailed and actionable, guiding the authors on how to enhance the clarity of their work. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a clarification to improve the clarity of the paper by explaining the relationship between the prior and posterior distributions in the context of epistemic model uncertainty. This suggestion is based on logical reasoning and provides a clear explanation of how the uncertainty is defined and updated. However, it does not include specific references or examples to further substantiate the claim, which could enhance the verifiability of the suggestion. Therefore, the comment is 4, as it provides a solid foundation for the claim but lacks additional supporting evidence.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the clarity of the paper. It identifies a specific area where the definition of uncertainty could be clarified by explaining the relationship between the prior and posterior distributions. This feedback is valuable as it guides the authors on how to enhance the comprehensibility of their work, particularly in the context of epistemic model uncertainty. By suggesting a more detailed explanation, the comment empowers the authors to make a significant improvement in the clarity and depth of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the comparison with Megatron, suggesting that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar sizes. It questions the claim of parameter efficiency for COCOLM and suggests that the conclusion could be applicable to other related works. Additionally, the comment poses two questions: one about the experimental setup regarding the switch from uncased to cased BPE vocabulary and another about the potential impact of this change on performance variance. While the comment raises valid points and questions, it does not provide explicit instructions or concrete actions for the authors to take. The questions are implicit and require the authors to infer the need for clarification or further explanation. Therefore, the comment is 3, as it provides guidance but lacks detailed instructions on how to address the issues.", "grounding_specificity_rationale": "The comment addresses the comparison with Megatron and questions the claim of parameter efficiency for COCOLM. It suggests that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar sizes. This provides specific feedback on the comparison and the claim of parameter efficiency. However, the comment does not explicitly mention which part of the paper discusses the comparison with Megatron, making it weakly grounded. The authors can infer that it relates to the experimental results or discussion sections, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison with Megatron is \"a little overrated\" and suggests that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar sizes. This claim is 3 as it provides a logical reasoning based on the similarity in performance and model sizes. However, the comment lacks specific examples or detailed comparisons to fully substantiate the claim, making it 3. The authors would need to consider this feedback and potentially provide more detailed comparisons to strengthen their argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the comparison with Megatron, suggesting that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar sizes. This feedback is 3 as it points out a potential issue with the claim of parameter efficiency for COCOLM. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered alternative ways to present the comparison. Additionally, the comment poses questions about the experimental setup and the impact of switching BPE vocabulary types, which could be beneficial for the authors to clarify. Overall, the comment identifies a potential weakness but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the analysis from line 128 to 149, suggesting that it is not convincing enough. It provides a specific observation about the histogram in Fig 3, noting that the GSP50 model has a smaller class selectivity score, indicating it shares more features, while ResNet50 learns more classspecific features. The reviewer questions the reasoning behind the observation that this indicates GSP50 learns better representations. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their analysis. The action is implicit and vague, as the authors are left to infer what changes might be needed without clear direction. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific lines (128149) and references a figure (Fig 3), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the analysis, questioning the reasoning behind the observation that GSP50 learns better representations. The comment provides a clear critique of the analysis and suggests that the authors should explain why this observation supports the claim. Additionally, it references external works, which could help the authors understand the context and improve their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the analysis from line 128 to 149, questioning the conclusion that GSP50 learns better representations based on the observation that it shares more features. The reviewer provides a logical explanation by referencing the histogram in Fig 3 and the class selectivity score, which suggests that GSP50 shares more features and ResNet50 learns more classspecific features. However, the comment lacks specific references or detailed examples from the provided references (1 and 2) to fully substantiate the claim. While the reasoning is somewhat logical, the lack of detailed references or examples makes the claim 4, as the authors would need to delve deeper into the references to fully understand the critique. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment critiques the analysis from line 128 to 149, questioning its convincingness. It provides a specific observation from the histogram in Fig 3, noting that the GSP50 model has a smaller class selectivity score, which suggests it shares more features, while ResNet50 learns more classspecific features. The reviewer challenges the authors\" hypothesis that additional context may allow the network to reduce its dependency, asking for a clearer explanation of why this observation supports the claim that GSP50 learns better representations. While the comment identifies a specific area for improvement and provides some context, it lacks detailed guidance or suggestions on how the authors might address the critique. The feedback is 3 as it points out a weakness in the analysis but could be more comprehensive with additional guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that some conclusions in the paper are not convincing, specifically mentioning the claim about continuous learning with unlabeled data accumulating noise. It implies that the results might be due to the limited exploration of combination methods and references recent works that have shown potential in featurereplay methods for continual learning. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The authors are left to infer that they should explore more combination methods or consider the referenced works, but the comment lacks concrete details on how to implement these suggestions. Therefore, the comment is 3, as it provides a direction for improvement but lacks specific instructions on how to execute it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific conclusions that are not convincing, allowing the authors to identify the exact parts of the paper being addressed. It also provides specific examples and references to recent works that have shown potential in featurereplay methods for continual learning, such as R1, R2, and R3. This level of detail helps the authors understand what needs to be addressed and how to improve their work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some conclusions in the paper are not convincing, specifically questioning the claim that continuous learning with unlabeled data accumulates noise. The reviewer provides a rationale by suggesting that the results might be due to the limited exploration of combination methods and references recent works that have shown potential in featurereplay methods for continual learning. This provides a logical reasoning and some supporting evidence, making the claim 4. However, the comment could be strengthened by providing more detailed comparisons or specific examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the conclusions drawn in the paper, questioning their convincingness. It provides a detailed critique by suggesting that the results might be due to the limited exploration of combination methods, particularly in the context of rehearsalfree continual learning. The comment references recent works that have shown great potential in featurereplay methods, such as R1, R2, and R3, which could be valuable for the authors to consider. This feedback is clear and actionable, as it directs the authors to explore more combination methods and consider the referenced works to strengthen their conclusions. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these references or methods into the paper. Overall, the comment is 4, as it offers valuable insights and references that can guide the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point provides several explicit actions for the authors to take. It suggests exploring other bit operations, which is a direct request for additional analysis. It also asks for more explanations regarding Fig. 5a, providing a clear action for the authors to enhance the clarity of their work. Additionally, it requests an explanation of how the input is handled when it is in the \"aer format\" and how DVS input is dealt with, which are specific areas needing clarification. Finally, it suggests analyzing energy consumption as a reference did, offering a concrete suggestion for improvement. Each of these actions is explicit and provides clear guidance on what the authors need to do to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"11,\" \"Fig. 5 a,\" and \"aer format,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear requests for additional explanations and analysis, such as exploring other bit operations, clarifying the appearance of Fig. 5a, and explaining how the input is handled in the \"aer format.\" Additionally, it suggests analyzing energy consumption as a reference did, which provides a specific direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple claims and suggestions, but it lacks specific evidence or detailed reasoning to support each claim. The comment suggests exploring other bit operations, questions the appearance of Fig. 5a, and asks for explanations regarding the handling of \"aer format\" inputs and DVS inputs. It also suggests analyzing energy consumption as a reference did, but without providing the reference or detailed guidance on how to implement this suggestion. The lack of specific examples, references, or detailed reasoning makes the claims difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides several specific and actionable suggestions for improving the paper. It starts by expressing appreciation for the work on bit operations, suggesting that the authors explore other bit operations, which could enhance the depth of their analysis. The comment also questions the appearance of Fig. 5a, prompting the authors to provide more explanations, which could clarify any confusion or ambiguity in the figure. Additionally, it raises a question about how the input is handled when it is in the \"aer format\" and how DVS input is dealt with, indicating areas where the authors might need to provide more detailed explanations. Finally, the comment suggests analyzing energy consumption as a reference did, which could strengthen the paper by providing a more comprehensive analysis. These suggestions are clear and actionable, offering the authors specific directions for enhancing their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests combining the first two bullets about contributions at the end of the introduction. This is an explicit action that the authors can take to improve their draft. However, the comment does not provide specific guidance on how to combine these bullets or what changes should be made to ensure clarity and coherence. The action is explicit but somewhat vague, as it lacks detailed instructions on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first two bullets about contributions\" at the end of the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to combine these two bullets, which gives the authors a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests combining the first two bullets about contributions at the end of the introduction. However, it does not provide any reasoning or justification for why this combination is necessary or beneficial. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests combining the first two bullets about contributions at the end of the introduction. While this feedback identifies a potential improvement in the organization and clarity of the contributions section, it lacks depth and does not provide specific guidance on how to effectively combine these bullets or what benefits this change might bring. The comment is 3 as it points out a possible improvement, but it does not offer detailed suggestions or rationale to support the change, leaving the authors with limited actionable feedback. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to define the dashed lines in figures 2AB and 4B. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be clarified, leaving no ambiguity about the action required. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 2AB and 4B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the definition of the dashed lines in these figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking the authors to define the dashed lines in specific figures. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is clear and specific, requesting that the authors define the dashed lines in figures 2AB and 4B. This feedback is actionable and provides a direct way for the authors to improve their draft by clarifying an aspect that may be unclear to readers. However, the comment could be more helpful if it provided additional context or explained why defining these dashed lines is important. Despite this, the comment is 4 as it guides the authors toward a specific improvement that can enhance the clarity and comprehensibility of their work. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should focus more on the pretraining method in the main paper, as it is a key factor in the performance gain. While the comment implies that the authors should provide a more detailed discussion on the unsupervised pretraining, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more discussion on the pretraining method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the lack of detailed discussion on unsupervised pretraining and its importance compared to other modules. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the unsupervised pretraining is a key factor in the performance gain, as indicated by the data in Table 4. It also suggests that the main paper lacks a detailed discussion on this aspect, which is a problem. The reviewer further supports this claim by comparing the importance of unsupervised pretraining with other modules presented in the paper, as shown in Table 5. This comparison provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more specific examples or references to support the claim about the importance of unsupervised pretraining. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of detailed discussion on unsupervised pretraining in the main paper, despite its importance as indicated by the data in Table 4. It suggests that the authors should focus more on the pretraining method in the main paper, which is a clear and actionable piece of feedback. By highlighting the significance of unsupervised pretraining, the comment provides the authors with a specific direction for improvement, making it 4. However, the comment could be more helpful if it offered additional suggestions on how to incorporate this discussion or provided examples of what a detailed discussion might entail. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the writing is difficult to follow in many places and suggests that it can be simplified. However, it does not provide any specific guidance or examples on how to achieve this simplification. The action is implicit, as the authors can infer that they need to make their writing clearer, but it is vague because it lacks concrete details on how to simplify the writing. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the writing is difficult to follow in many places and can be simplified. However, it does not specify which parts of the paper are problematic or provide examples of where the writing is unclear. This makes it difficult for the authors to identify the exact areas that need improvement. The comment lacks both grounding and specificity, as it does not provide any details or references to specific sections or elements of the paper. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing is difficult to follow in many places and suggests it can be simplified. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the writing is unclear, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a general issue with the writing being difficult to follow in many places, suggesting that it can be simplified. However, it lacks specificity and does not provide any actionable guidance or examples on how to achieve this simplification. Without detailed feedback or suggestions, the authors are left without a clear understanding of what changes are needed to improve the clarity of their writing. This makes the comment 2, as it highlights a potential issue but does not offer sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests several improvements, including providing intuition for the proof of Theorem 1, exploring how the invertible function $f^*$ depends on the fixed $P^*$, and determining which distributions $P^*$ make it easier to determine $f^*$. Additionally, it raises a practical question about how to choose the $P^*$ to fix. While the comment implies that these are areas for improvement, it does not explicitly instruct the authors to address them. The actions are inferred and somewhat vague, as the authors need to deduce the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific questions and suggestions regarding the proof of Theorem 1, such as the intuition behind it and the dependence of the invertible function $f^*$ on the fixed $P^*$. Additionally, it raises practical questions about determining which distributions $P^*$ make it easier to determine $f^*$ and how to choose $P^*$ in practice. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several questions and suggestions regarding the proof of Theorem 1 and the invertible function $f^*$, which are based on logical reasoning and a desire for clarity. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims, making it 3. The authors would need to infer the potential issues and address them based on their understanding of the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors should provide intuition for the proof of Theorem 1. It also raises questions about the dependence of the invertible function $f^*$ on the fixed $P^*$ and how certain distributions $P^*$ might make it easier to determine $f^*$. Additionally, it asks for practical guidance on how to choose the $P^*$ to fix. These suggestions are clear and offer concrete areas for improvement, allowing the authors to enhance the clarity and depth of their work. However, the comment could be more helpful if it provided additional context or examples to support the suggestions. Overall, the feedback is 4, as it directs the authors to specific areas that need further elaboration and clarification."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the inconsistency in the use of variables in Eqs. (7) and (10), specifically why one uses \"X\" and the other uses \"H^(1)\". However, it does not provide any explicit or implicit guidance on how the authors should address this issue or suggest a resolution. The comment lacks actionable details, leaving the authors without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqs. (7) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the inconsistency in the use of variables between these two equations, specifically asking why one uses \"X\" and the other uses \"H^(1).\" This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the inconsistency in the use of variables between Eqs. (7) and (10), specifically why one uses \"X\" and the other uses \"H^(1)\". This is a factual observation that does not express an opinion or make a subjective claim. It is a request for clarification, fitting the \"No\" label.", "helpfulness_rationale": "The review comment raises a specific question about the inconsistency in the use of variables between Eqs. (7) and (10), noting that one uses \"X\" and the other uses \"H^(1)\". This observation highlights a potential issue in the paper that the authors should address. However, the comment does not provide any suggestions or guidance on how to resolve this inconsistency or why it might be important. While it points out a specific area for improvement, it lacks depth and actionable advice, making it 3. The authors are informed of a potential issue but are not given a clear path to address it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a lack of clarity in Section 4.2 regarding the use of the question to learn an attention on the image feature. It points out that the description does not match the equation provided, specifically noting the absence of the term \"r^q\" and the unclear meaning of \"\u03c3.\" The reviewer suggests clarifying these points and raises a concern about the potential numerical instability of multiplying two sigmoid activations. This feedback provides explicit actions for the authors to take, such as clarifying the description and addressing the potential numerical instability issue. The guidance is clear and actionable, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the description and equation in this section, particularly the absence of the term \"r^q\" and the unclear meaning of \"\u03c3.\" The comment provides clear guidance on what needs to be clarified, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the description in Sec. 4.2 does not match the equation, specifically noting the absence of the term \"r^q\" and the unclear meaning of \"\u03c3.\" The reviewer suggests that the equation might be illconditioned and numerically unstable due to the multiplication of two sigmoid activations. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the exact nature of the problem and how it affects the equation. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the description in Section 4.2, where the use of the question to learn an attention on the image feature is not clearly explained. It points out that the description does not match the equation provided, specifically noting the absence of the term \"r^q\" and the unclear meaning of \"\u03c3.\" The reviewer also raises a concern about the potential numerical instability of multiplying two sigmoid activations. This feedback is clear and actionable, as it provides specific guidance on what needs to be clarified and addressed in the paper. By highlighting these issues, the comment helps the authors improve the clarity and accuracy of their work, making it 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the process of updating archetype positions after initialization, specifically asking for clarification on how the archetype positions are updated after being initialized with the FurthestSum procedure. While the comment does not explicitly instruct the authors to make changes, it implies that the authors should provide additional information or clarification on this process. The action is implicit, as it requires the authors to infer that they need to address the lack of clarity in their paper. However, the comment is 3 because it provides a clear direction for the authors to follow, which is to clarify the process of updating archetype positions. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of how archetype positions are updated after initialization. This provides clear guidance on what needs to be clarified, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the process of updating archetype positions after initialization. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual question seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the process of updating archetype positions after initialization, which is an important aspect of the algorithm. By asking for clarification, the reviewer highlights a potential area of confusion in the paper that could be clarified to improve the reader\"s understanding. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a specific point that needs clarification, it lacks actionable feedback or depth, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies several areas that are missing from the empirical study and suggests that they should be included in the supplement or main text. It specifies the types of information that are missing, such as recording parameters for MRI, preprocessing steps, the condition under which restingstate recordings were made, and a brief explanation of the harmonization technique. Additionally, it suggests mentioning the number of regions in the parcellation in the main text. These explicit and concrete suggestions provide the authors with clear guidance on what needs to be added to their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific aspects that are missing from the empirical study, such as recording parameters for MRI, preprocessing steps, the condition under which restingstate recordings were made, and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. This provides clear guidance on what needs to be addressed, making it easy for the authors to identify the parts of the paper that require revision. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that important information about the empirical study is missing, specifically regarding the recording parameters for MRI, preprocessing steps, and the condition under which restingstate recordings were made. It also requests a brief explanation of the harmonization technique and the number of regions in the parcellation. While the comment identifies specific areas where information is lacking, it does not provide detailed reasoning or examples to support why these details are crucial or how they impact the study. The lack of supporting evidence or detailed justification makes the claim 3, as the authors would need to infer the importance of these details themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several important pieces of information that are missing from the empirical study, such as recording parameters for MRI, preprocessing steps, and the condition under which restingstate recordings were made. It also suggests providing a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. These specific suggestions are actionable and provide clear guidance for the authors to enhance the comprehensiveness and clarity of their study. By addressing these gaps, the authors can improve the transparency and reproducibility of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential risk in methods that exploit relationships between action units, noting that these relationships can vary significantly across different datasets. It suggests that crossdataset experiments could be a good way to test the generalization of such work, as the paper currently lacks. While the comment implies that the authors should conduct crossdataset experiments to address this issue, it does not provide specific guidance on how to implement these experiments or which datasets to use. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by highlighting the potential risk of methods exploiting relationships between action units and the need for crossdataset experiments to test generalization. The comment provides a clear example of how the relationships can differ across datasets, such as the cooccurrence of AU1 and AU12 in Figure 1. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that methods exploiting relationships between action units may not generalize well across datasets due to differences in cooccurrence patterns. It provides a specific example by mentioning AU6, which can occur in both pain and happiness expressions, and notes that this cooccurrence differs between datasets like SEMAINE and UNBC pain. The comment also references Figure 1, which illustrates the different cooccurrences of AU1 and AU12. This detailed explanation and reference to specific data points provide a solid basis for the claim, making it 4. However, the comment could be strengthened by including more examples or references to support the generalization issue. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant risk in methods that exploit relationships between action units, noting that these relationships can vary across different datasets. It provides a specific example by mentioning AU6, which can occur in both pain and happiness expressions, and highlights the difference in cooccurrence patterns between datasets like SEMAINE and UNBC pain. The comment suggests that crossdataset experiments could be a good way to test the generalization of such work, which is a valuable and actionable piece of feedback. However, the comment could be more helpful if it offered specific guidance on how to conduct these experiments or which datasets to use. Overall, the comment is 4 as it points out a critical area for improvement and provides a direction for further research, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a contradiction between the statement that overparametrization leads to overfitting and worse performance, and the observation that it is beneficial for supervised learning of deep neural networks in practice. The reviewer also mentions theoretical works that support the benefits of overparametrization. However, the comment does not provide explicit guidance or suggestions on how the authors should address this contradiction or incorporate the theoretical works into their paper. The action is implicit and vague, as the authors are left to infer that they should clarify or reconcile the apparent contradiction, but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 4748, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a contradiction between the statement about overparametrization leading to overfitting and the observation that it is beneficial for supervised learning of deep neural networks in practice. The comment further supports this observation by referencing theoretical works that show the benefits of overparametrization. This provides clear guidance on what needs to be addressed in the paper, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that overparametrization is beneficial for supervised learning of deep neural networks in practice, contradicting the statement that it leads to overfitting and worse performance. The reviewer supports this claim by referencing theoretical works that show the benefits of overparametrization, such as 1. This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more specific examples or detailed references to the theoretical works, which would further enhance the verifiability of the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential contradiction in the paper regarding the impact of overparametrization on deep neural networks. It points out that the statement \"overparametrization invariably overfits the data and results in worse performance\" seems to contradict the observation that overparametrization is beneficial for supervised learning in practice. The reviewer supports this observation by referencing theoretical works that show the benefits of overparametrization. This feedback is helpful as it highlights a critical inconsistency in the paper and provides a reference to theoretical works that could help the authors clarify and address this issue. However, the comment could be more helpful if it offered specific suggestions on how to reconcile the contradiction or integrate the theoretical works into the paper. Overall, the comment is 4, as it provides valuable insights and references that can guide the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take, including adding more sentences to explain the experimental setting for continual learning and providing explanations for the learning curves in Fig 3. It also asks specific questions about the correspondence between the learning curves and MPHATE, the impact of worse performance on structural collapse, and the accuracy number for the last task or average. These questions and requests for clarification are concrete and provide clear guidance on what the authors need to address in their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as explaining the correspondence between the learning curves and MPHATE, and asking questions about the impact of worse performance on structural collapse and the accuracy number. The comment specifies what needs to be clarified or addressed in the figure, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of requests for clarification and additional information, such as explaining the experimental setting for continual learning and providing details about the learning curves in Fig 3. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by requesting additional explanations and clarifications in the paper. It suggests adding more sentences to explain the experimental setting for continual learning, which is a clear and concrete action for the authors to take. Additionally, it asks for detailed explanations regarding the learning curves in Fig 3, including the correspondence between the learning curves and MPHATE, the impact of worse performance on structural collapse, and the accuracy number for the last task or average. These requests are specific and provide a clear path for the authors to improve their draft by addressing these gaps in clarity and detail. Therefore, the comment is 5, as it offers detailed and actionable feedback that can significantly enhance the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar scale pretrained model as the proposed method. It highlights a potential issue with the experimental setup, suggesting that the proposed method without SSL performs inferior to most compared methods. However, the comment does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the pretraining stage and ensure fairness in the comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental comparison, questioning the fairness of the comparison due to the pretraining stage and the potential lack of similar initialization for the compared methods. The comment provides a clear critique of the experimental setup and suggests that the proposed method without SSL performs inferior to most compared methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental comparison is unfair due to the proposed method being pretrained before the finetuning stage, while it is unclear if the compared methods were initialized with the same or similar scale pretrained model. The comment provides a logical reasoning by pointing out the potential bias in the comparison and references Table 1 to support the claim. However, it lacks specific examples or references to other studies that might have used similar pretraining methods, which would strengthen the argument. Overall, the claim is 4, as it provides a clear rationale but could be further supported with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental comparison, specifically questioning the fairness of the comparison due to the proposed method being pretrained before the finetuning stage. It raises a valid concern about whether the compared methods were initialized with the same or similar scale pretrained model, which could impact the results. The comment also points out that the proposed method without SSL performs inferior to most compared methods, as shown in Table 1. This feedback is clear and actionable, as it prompts the authors to clarify the pretraining stage and ensure fairness in the comparison. However, it could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how to standardize the pretraining process. Overall, the comment is 4, as it directs the authors to a critical area that needs attention and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that while the use of \"attribute\" metadata for zeroshot learning on the CUB dataset is good for fair comparison, better metadata embeddings options are available. It references a specific paper, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" and suggests exploring these options for better performance. The comment explicitly instructs the authors to update the paper with the performance of their method using better metadata embeddings. This feedback is clear and provides a specific action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the metadata used for zeroshot learning on the CUB dataset and suggests exploring better metadata embeddings options, referencing a specific paper for further guidance. This provides clear guidance on what needs to be addressed and how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that while the use of \"attribute\" metadata for zeroshot learning on the CUB dataset is good for fair comparison, better metadata embeddings options are available. It references a specific paper, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" which provides a basis for the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how these better metadata embeddings options could improve performance. The reference to the external work is a good starting point, but the claim could be more fully verified with additional supporting evidence or analysis. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment provides specific feedback on the results of zeroshot learning on the CUB dataset, noting that the use of \"attribute\" metadata is good for fair comparison but suggests that better metadata embeddings options are available. It references a relevant paper, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" which could offer insights into improving performance. The comment is actionable as it suggests exploring these better metadata embeddings options and provides a specific reference for further investigation. This feedback is clear and constructive, offering the authors a concrete path to enhance their work, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors include a plot with sparsity on the xaxis and performance on the yaxis to directly compare the flexibility of SGC with LoRA. This is an explicit action with concrete details on how to implement it, as it specifies the type of plot and the variables to be included. The authors know exactly what needs to be done to address the comment, making it 5.", "grounding_specificity_rationale": "The comment addresses the limited applicability of SGC and suggests a plot to compare its flexibility with LoRA. It provides a specific suggestion for visualization, which is to include a plot with sparsity on the xaxis and performance on the yaxis. This makes the comment fully grounded as it explicitly mentions the need for a specific type of plot, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, the inclusion of this plot to demonstrate the practical benefits of SGC\"s finegrained control. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that SGC offers a more flexible, finegrained tradeoff but notes that PEFT methods typically target computeconstrained scenarios, where such granular control may require extra tuning, reducing practicality. The reviewer suggests including a plot to compare the flexibility of SGC with LoRA, which could more intuitively demonstrate whether SGC\"s finegrained control offers practical performance benefits at different sparsity levels. This claim is 3 as it provides a logical reasoning for the potential limitation of SGC in practical scenarios and suggests a method to visually demonstrate the difference. However, the comment lacks specific examples or references to support the claim fully, making it 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s claim about the flexibility of SGC compared to PEFT methods. It suggests that the finegrained control offered by SGC may not be practical in computeconstrained scenarios, where extra tuning could be required. The comment provides a specific and actionable suggestion to include a plot with sparsity on the xaxis and performance on the yaxis to visually compare the flexibility of SGC with LoRA. This feedback is clear and constructive, offering a concrete way for the authors to demonstrate the practical benefits of SGC\"s finegrained control. By addressing this suggestion, the authors can enhance the clarity and persuasiveness of their argument, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reasonableness of the German and Law school dataset having shorter training times in Gerrymandering compared to Independent. It also suggests that the code should be published, as the main advantage of the method is its computation time. While the comment implies that the authors should address the discrepancy in training times and consider publishing the code, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and address the training time issue and consider publishing the code. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiment 2\" and \"ERM and plugin,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the reasonableness of the German and Law school dataset having shorter training times in Gerrymandering compared to Independent. Additionally, it suggests that the code should be published, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the reasonableness of the German and Law school dataset having shorter training times in Gerrymandering compared to Independent. It also suggests that the code should be published, as the main advantage is its computation time. However, the comment lacks specific evidence or references to support the claim that the training times are unreasonable or to substantiate the suggestion for publishing the code. Without detailed reasoning or examples, the claim remains 3, as the authors would need to infer the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the reasonableness of the German and Law school dataset having shorter training times in Gerrymandering compared to Independent. It also suggests that the code should be published, as the main advantage of the method is its computation time. This feedback is 3 as it identifies a potential issue with the experimental results and provides a suggestion for improvement by recommending the publication of the code. However, the comment could be more helpful if it offered specific guidance on how to address the discrepancy in training times or provided more detailed suggestions for improving the code\"s publication. Overall, the comment provides some direction for the authors to consider, but it lacks depth and actionable steps, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the human baseline, noting that it only follows a little more than 1 hour of speech recordings, making it weaker compared to the model baseline. The comment also references Section 4.1, which mentions additional factors contributing to the human baseline\"s weakness. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific changes to improve the human baseline. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or address the discrepancy in the human baseline\"s performance. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the human baseline and the discrepancy in the duration of speech recordings it follows, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the human baseline is weaker due to this limitation, and it references Section 4.1 for additional factors contributing to this weakness. Additionally, the comment critiques the abstract for being misleading regarding the comparison with the human baseline. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the human baseline is weaker than the model baseline due to the human only following a little more than 1 hour of speech recordings, rather than the full 15 hours. The comment also critiques the abstract for being misleading regarding the comparison with the human baseline. While the claim highlights a potential issue with the human baseline, it lacks specific examples or detailed reasoning to fully substantiate the claim. The reference to Section 4.1 provides some context but does not fully support the claim. Therefore, the comment is 3, as it provides some justification but requires more detailed evidence or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies a significant issue with the human baseline, noting that it only follows a little more than 1 hour of speech recordings, making it weaker compared to the model baseline. It also points out that the abstract is misleading in its comparison with the human baseline. This feedback is valuable as it highlights a critical flaw in the human baseline and suggests that the authors should clarify or correct the comparison in the abstract. However, the comment could be more helpful if it provided specific suggestions on how to address the discrepancy or improve the human baseline. Overall, the comment is 3 as it directs the authors\" attention to a key issue but lacks detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of multiple questions and requests for clarification regarding the synthetic data, Figure 1, and the model used. It explicitly asks for examples of synthetic data, clarification on the terms \"support data\" and \"predicted training count data\" in Figure 1, and requests that the model used be explicitly written down, possibly in the appendix. These requests are clear and direct, providing the authors with specific actions to take to improve their draft. The feedback is concrete and actionable, as it guides the authors on what information to include and how to present it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"synthetic data,\" \"Figure 1,\" and specific terms like \"support data\" and \"predicted training count data,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it requests examples of synthetic data, clarification on the terms in Figure 1, and asks for the model used to be explicitly written down, possibly in the appendix. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of questions and requests for clarification regarding the synthetic data, Figure 1, and the model used. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek additional information, which is not a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas that need clarification and improvement. It requests examples of synthetic data, asks for clarification on the terms \"support data\" and \"predicted training count data\" in Figure 1, and suggests that the model used should be explicitly written down, possibly in the appendix. These requests provide clear and actionable feedback that can guide the authors in enhancing the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it offered additional suggestions or context on how these clarifications might impact the overall understanding or interpretation of the results. Nonetheless, the feedback is valuable and directs the authors toward specific improvements, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly recommends that the authors provide a more detailed explanation of the EEG token quantization process, specifically regarding the role of the spatial arrangement of EEG sensors. This suggestion is clear and provides a concrete action for the authors to take, ensuring they understand exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of ambiguity in interpretation and suggests that the authors provide a more detailed explanation of the EEG token quantization process, particularly regarding the role of the spatial arrangement of EEG sensors. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 3 presents EEG topography plots that lead to ambiguity in interpretation, recommending a more detailed explanation of the EEG token quantization process. The comment is 3 as it identifies a potential issue with the interpretation of the figure but lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a clear suggestion for improvement, the authors might find it challenging to address the ambiguity without additional guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that the EEG topography plots for both the input and output during the EEG token quantization process lead to ambiguity in interpretation. It provides a clear and actionable suggestion for the authors to elucidate this procedure in greater detail, specifically asking whether the spatial arrangement of EEG sensors played a role in the process. This feedback is valuable as it directs the authors to clarify a critical aspect of their methodology, potentially enhancing the understanding and reproducibility of their work. However, the comment could be more helpful if it offered additional guidance on how to present this information or suggested specific details to include. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors are not addressing the problem in a direct way by leveraging the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the issue or improve their approach. Without specific suggestions or directions, the authors are left without a clear understanding of what changes are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the authors\" use of the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment provides some insight into the perceived indirectness of the approach but lacks specificity in terms of what needs to be addressed or how the authors might improve their method. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the authors are not addressing the problem in a direct way by leveraging the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the authors are leveraging the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. The reviewer suggests that this approach may not be addressing the problem in a direct way, implying that the method could be improved or clarified. However, the comment lacks specificity and does not provide actionable suggestions or examples of how the authors might address this issue. Without detailed guidance or examples, the authors may find it challenging to understand how to improve their approach. Therefore, the comment is 3, as it identifies a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper lacks relevant literature on using moment matching instead of quantile regression in distributional reinforcement learning (DRL). It references a specific paper, \"Distributional Reinforcement Learning via Moment Matching\" by NguyenTang et al. (AAAI\u201921), and implies that this should be discussed in the context of various approaches to DRL. The comment explicitly suggests that the authors should include this discussion, even though the paper still uses quantile regression. This feedback is explicit and provides a clear action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific paragraph from lines 2230, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of lacking relevant literature on using moment matching instead of quantile regression in distributional reinforcement learning (DRL), and it references a specific paper by NguyenTang et al. (AAAI\u201921) for further context. The comment provides a clear suggestion for improvement by recommending the inclusion of this discussion, even though the paper still uses quantile regression. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks relevant literature on using moment matching instead of quantile regression in distributional reinforcement learning (DRL). It references a specific paper, \"Distributional Reinforcement Learning via Moment Matching\" by NguyenTang et al. (AAAI\u201921), which supports the claim. The comment provides a clear rationale for the suggestion, explaining that moment matching is a relevant approach that should be discussed in the context of DRL methods. This level of detail and reference makes the claim 5, as it provides a robust basis for the authors to consider the suggestion. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks relevant literature on using moment matching in distributional reinforcement learning (DRL), instead of quantile regression, as most DRL methods do. It references a specific paper, \"Distributional Reinforcement Learning via Moment Matching\" by NguyenTang et al. (AAAI\u201921), which provides a relevant example of this approach. The comment suggests that this should be discussed in the context of various approaches to DRL, even though the present paper still uses quantile regression. This feedback is clear and actionable, as it directs the authors to include a discussion on moment matching, which could enhance the comprehensiveness and depth of their work. However, it could be more helpful if it provided specific guidance on how to integrate this discussion into the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that in the introduction, the second paragraph discusses modelling curves, but it is unclear what is being modelled. However, it does not provide explicit guidance or suggestions on how to clarify this point or what specific information should be added to make it clear. The action is implicit and vague, as the authors can infer that they need to provide more context or clarification but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction\" and the \"second paragraph,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that it is not immediately clear what is being modelled, presumably tumour growth. This provides clear guidance on what needs to be clarified in the introduction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the second paragraph of the introduction discusses modelling curves but does not specify what is being modelled. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the introduction, where the second paragraph discusses modelling curves but does not clearly specify what is being modelled. This feedback is 3 as it points out a potential area for clarification, allowing the authors to improve the clarity and specificity of their introduction. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending additional details or examples to make the modelling context clearer. Overall, the comment provides some guidance but lacks depth, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that while the paper analyzes under which cases Algorithm 1 converges to permutations as local minima, it would be beneficial to also analyze the quality of these local minima, such as their approximation ratio under certain assumptions. This comment implies that the authors should expand their analysis to include the quality of the local minima, but it does not provide specific guidance on how to conduct this analysis or what assumptions should be considered. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the analysis of the quality of local minima, such as the approximation ratio under certain assumptions. This provides clear guidance on what the authors should focus on to improve their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that while the paper analyzes under which cases Algorithm 1 converges to permutations as local minima, it would be beneficial to also analyze the quality of these local minima, such as their approximation ratio under certain assumptions. The comment provides a logical reasoning for the suggestion, implying that the current analysis is incomplete and that further investigation into the quality of local minima could enhance the paper. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the importance of this analysis and how it could be conducted, which adds to the complexity of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that while it analyzes under which cases Algorithm 1 converges to permutations as local minima, it would be beneficial to also analyze the quality of these local minima, such as their approximation ratio under certain assumptions. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their analysis, which could enhance the comprehensiveness and depth of their work. However, the comment could be more helpful if it offered examples or guidance on how to approach this analysis. Overall, the comment is 4, as it effectively guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms. It also references a specific sentence regarding the robustness of Cans and the information redundancy in the weight pool. However, the comment does not provide explicit instructions or suggestions on how the authors should address this question or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to clarify or elaborate on the information redundancy aspect. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Fill, Propagate, Decode algorithms\" and references a specific sentence regarding the information redundancy and the robustness of Cans. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it questions how information redundancy is built into the algorithms and references a specific sentence for further clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms, specifically referencing a sentence about the robustness of Cans. However, the comment does not provide any supporting evidence, reasoning, or examples to justify the need for clarification on this point. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms, which is a relevant and specific area for improvement. It also references a specific sentence regarding the robustness of Cans and the information redundancy in the weight pool, providing a clear context for the inquiry. However, the comment lacks depth and does not offer any suggestions or guidance on how the authors might address this question or improve their explanation. While it identifies a potential area for clarification, it does not provide actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include experimental results that exclude the mixup technique from the proposed method to demonstrate its pure contribution. This is an explicit action that provides clear guidance on what the authors need to do to improve their draft. The comment specifies the exact action and provides a concrete suggestion on how to implement it, making it 5. The authors know exactly what results to include and why, allowing them to make a direct improvement to their paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that experimental results should be included to demonstrate the pure contribution of the proposed method by excluding the mixup technique. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should include experimental results excluding the mixup technique to demonstrate the pure contribution of the proposed method. This claim is based on a logical reasoning that by excluding the mixup technique, the authors can isolate the contribution of their method. However, the comment does not provide specific examples or references to support why this exclusion is necessary or how it would impact the results. While the reasoning is sound, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental setup of the paper. It suggests that the authors should include experimental results that exclude the mixup technique to demonstrate the pure contribution of the proposed method. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\"s experimental rigor and clarity. By following this advice, the authors can better isolate the impact of their method and provide a more comprehensive understanding of its effectiveness. However, the comment could be more helpful if it offered additional guidance on how to implement this suggestion or why it is important. Overall, the comment is 4, as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential source of speed disparities observed between RSPs and FDs, suggesting that an error in the initial calibration steps might be the cause. However, it does not provide explicit guidance or suggestions on how the authors should investigate or address this issue. The comment implies that the authors should look into the calibration steps, but it lacks concrete steps or actions for the authors to take. As a result, the comment is 3, as it identifies a potential area for investigation but does not provide detailed guidance on how to proceed.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section III of \u201cRecognition and Velocity Computation of Large Moving Objects in Images\u201d\u2014RVC paper,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether an error in the initial calibration steps (steps 1 & 2) might explain the speed disparities observed between the RSPs and FDs. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the potential source of speed disparities observed between RSPs and FDs, suggesting that an error in the initial calibration steps might be the cause. However, the comment does not provide any evidence, examples, or references to support this claim. It lacks specific details or reasoning to substantiate the suggestion, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the potential source of speed disparities observed between RSPs and FDs, suggesting that an error in the initial calibration steps might be the cause. While it identifies a potential issue, it lacks specific guidance or suggestions on how the authors might investigate or address this concern. The comment does not provide actionable steps or detailed feedback, leaving the authors with a general direction but no clear path for improvement. Therefore, the comment is 3, as it points out a potential area for investigation but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks the authors to clarify the labels for each dataset in Section 4.1, specifically questioning whether they come from the dataset itself or from another source. This request is clear and direct, providing the authors with a specific action to take to address the reviewer\"s concern. The comment also provides context by mentioning the ease of labeling for generated datasets but highlights the need for clarification regarding the labels for specific datasets like caspealr1 and mugshot. This level of detail makes the action concrete and easy for the authors to implement, aligning with a score of 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by asking for clarification on the labels for each dataset, particularly for caspealr1 and mugshot. The comment provides a clear request for additional information, making it 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point is a request for clarification regarding the labels for each dataset in Section 4.1, specifically asking where these labels come from. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual question seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of confusion regarding the labels for each dataset in Section 4.1. It asks for clarification on where these labels come from, which is a legitimate question that could help the authors improve the clarity and transparency of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as recommending specific methods for labeling or discussing potential sources of confusion. Overall, while the comment provides some direction, it lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and observations about the paper, including the sensitivity of performance and sample efficiency to the \u03bb parameter, the process of calculating \u03bb, and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. However, the comment does not provide explicit or implicit actions for the authors to take. It lacks guidance on how to address these issues or improve the clarity of the paper. The authors are left without a clear understanding of what changes or additions are needed to address the reviewer\"s concerns. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific pages and lines (Page 9, lines 310313, and Page 8, lines 281285), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the sensitivity of performance and sample efficiency to the \u03bb parameter, the process of calculating \u03bb, and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The comment provides references to external works, which adds to its specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several claims and questions about the paper, including the sensitivity of performance and sample efficiency to the \u03bb parameter, the process of calculating \u03bb, and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The reviewer provides references to external works, such as 1 Yuri Burda et al, Exploration by Random Network Distillation, ICLR 2019, 2 Deepak Pathak et al, Curiositydriven Exploration by Selfsupervised Prediction, ICML 2017, and 3 Roberta Raileanu et al, RIDE: Rewarding ImpactDriven Exploration for ProcedurallyGenerated Environments, ICLR 2020, which could help support the claims. However, the comment lacks detailed reasoning or examples to fully substantiate the claims, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several concerns and questions about the paper, including the sensitivity of performance and sample efficiency to the \u03bb parameter, the process of calculating \u03bb, and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The comment provides specific references to external works, which could help the authors better understand the context and address the issues raised. However, the comment lacks detailed guidance or suggestions on how the authors might improve their explanation or address the concerns. While it identifies areas for improvement, it does not provide actionable steps or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the effectiveness of lower bound double qlearning, specifically mentioning a slight performance decrease in MsPacman and convergence into the same solutions in other environments. It also notes a potential issue with overestimating the true maximum value. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their work. The authors are left to infer that they need to investigate and address these issues, but without concrete steps or recommendations, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"MsPacman of Figure2\" and specific environments like \"WizardOfWor, Zaxxon RoadRunner, and BattleZone,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the effectiveness of lower bound double qlearning, including a slight performance decrease in MsPacman and convergence into the same solutions in other environments. Additionally, it points out a potential issue with overestimating the true maximum value. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of lower bound double qlearning is doubtful, citing specific examples from the paper, such as a slight performance decrease in MsPacman and convergence into the same solutions in other environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone. It also mentions a potential issue with overestimating the true maximum value. While the comment provides some evidence and examples, it lacks detailed reasoning or references to support the claim fully. The authors might need to delve deeper into the analysis to fully understand the basis of the claim. Therefore, the comment is 3, as it provides a foundation for the claim but requires further elaboration.", "helpfulness_rationale": "The review comment raises concerns about the effectiveness of lower bound double qlearning, specifically pointing out a slight performance decrease in MsPacman and convergence into the same solutions in other environments. It also mentions a potential issue with overestimating the true maximum value. While the comment identifies specific areas of concern, it lacks detailed analysis or suggestions on how the authors might address these issues or improve their work. The feedback is 3 as it highlights potential weaknesses, but it does not provide actionable guidance or depth to help the authors effectively address these concerns. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small. It suggests that the performance should approach vanilla methods from below, but instead, it becomes worse. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what changes might be needed to clarify the performance trend. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig.34,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of why the performance of DNN+MMA becomes worse than vanilla DNN when lambda becomes small, and it provides an expectation for how the performance should behave. This level of detail helps the authors understand what needs to be addressed in their analysis. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance trend of DNN+MMA compared to vanilla DNN when lambda becomes small. It suggests that the performance should approach vanilla methods from below but instead becomes worse. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this trend is unexpected or how it relates to the literature. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a specific question about the performance trend of DNN+MMA compared to vanilla DNN when lambda becomes small. It points out a discrepancy in the expected behavior, suggesting that the performance should approach vanilla methods from below but instead becomes worse. This feedback is clear and identifies a potential issue that the authors should address to clarify their results. However, the comment could be more helpful if it provided suggestions on how to investigate or explain this trend, such as recommending additional analysis or experiments. Overall, the comment is 3 as it directs the authors\" attention to a specific area needing clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the paper does not compare its results with earlier research work from 2020, despite the authors providing a reason for not doing so in the author response. The comment suggests that the authors have compared their results to earlier systems with worse performances, which is noted as a point of interest. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their comparisons. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider their comparisons or provide a more comprehensive evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of not comparing results with earlier research work from 2020 and references the authors\" response regarding stateoftheart systems. It also provides a specific example of earlier systems with worse performances (Taghipour and Ng, 2016) that the authors have compared their results to. This allows the authors to accurately identify the part of the paper being addressed and understand what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not compare its results with earlier research work from 2020, despite the authors providing a reason for not doing so. The comment highlights a potential inconsistency in the comparison, noting that the authors have compared their results to earlier systems with worse performances. However, the comment does not provide specific examples or detailed reasoning to support the claim, making it 3. The authors would need to delve deeper into the paper and the author response to fully understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a specific issue with the paper\"s comparison to earlier research work, noting that the authors have not compared their results with some of the earlier research from 2020. The comment acknowledges the authors\" explanation for not doing so, which is based on the claim that those systems are not stateoftheart. However, it highlights a potential inconsistency by mentioning that the authors have compared their results to earlier systems with worse performances, such as Taghipour and Ng (2016). This feedback is 3 as it identifies a potential gap in the comparison and encourages the authors to reconsider their evaluation methodology. However, it could be more helpful if it provided specific suggestions on how to address this issue or offered examples of relevant earlier work to include in the comparison. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of comparisons with other representative panoptic segmentation models, such as PanopticFPN and Mask2Former. While it identifies a gap in the comparison, it does not provide explicit guidance on which models should be included or how to incorporate them into the evaluation. The action is implicit and somewhat vague, as the authors can infer that they need to add these models to their comparison but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment points out the absence of comparisons with other representative panoptic segmentation models, specifically mentioning PanopticFPN and Mask2Former. However, it does not specify which part of the paper this comparison should be included in, such as the results section or the discussion. The authors can infer that it relates to the evaluation or comparison section, but the comment lacks full grounding. It is specific in identifying the models that should be included in the comparison, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that some representative panoptic segmentation models are not compared, specifically mentioning PanopticFPN and Mask2Former. However, the comment does not provide any reasoning or evidence to support why these models should be included in the comparison. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out the absence of comparisons with other representative panoptic segmentation models, such as PanopticFPN and Mask2Former. This feedback is clear and actionable, as it directs the authors to expand their evaluation by including these models. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these models into the comparison or why they are relevant. Despite this, the feedback is 4 as it guides the authors toward a meaningful enhancement of their work. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point provides explicit actions for the authors to take, specifically suggesting that they should proofread the paper to fix language problems. It also provides examples of specific language issues, such as \"we typically considers,\" \"two permutation,\" and \"until converge,\" which need to be corrected. This feedback is clear and concrete, giving the authors a direct and actionable path to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"the above of (7),\" \"Theorem 1,\" and \"the above of (14),\" allowing the authors to accurately identify the sections that need attention. It is also specific because it provides examples of language issues that need to be corrected, such as \"we typically considers,\" \"two permutation,\" and \"until converge.\" This level of detail guides the authors on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of minor comments on language usage, providing specific examples of grammatical errors or inconsistencies (\"we typically considers,\" \"two permutation,\" \"until converge\"). These are factual statements that describe issues in the paper without making subjective claims or suggestions for improvement. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies minor issues with language usage in the paper, such as grammatical errors or inconsistencies in terminology. It provides specific examples of these issues, like \"we typically considers,\" \"two permutation,\" and \"until converge,\" which need to be corrected. While the comment highlights areas for improvement, it does not offer suggestions on how to address these issues or provide broader feedback on the content or structure of the paper. The feedback is 3 as it directs the authors to proofread and correct the language problems, but it lacks depth and actionable guidance for more significant improvements. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the limited scope of the evaluative framework, specifically mentioning its focus on only three QuestionAnswering tasks and two language models. It suggests that this restricts the method\"s broader applicability and questions its potential to generalize to other tasks or more advanced models. However, the comment does not provide explicit guidance or suggestions on how the authors might address these limitations or expand the scope of their framework. The action is implicit and vague, as the authors are left to infer that they should consider broader applicability and potential generalization, but without concrete steps or examples, it remains unclear how to implement these suggestions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the evaluative framework, specifically mentioning its limited scope due to the focus on only three QuestionAnswering tasks and two language models. However, it does not explicitly mention which part of the paper discusses this framework, making it weakly grounded. The comment is specific in detailing the limitations and suggesting potential areas for broader applicability, such as considering other reasoning or generation tasks or more advanced models. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluative framework is limited in scope due to its focus on only three QuestionAnswering tasks and two language models. It suggests that this restricts the method\"s broader applicability and questions its potential to generalize to other tasks or more advanced models. However, the comment lacks specific examples or references to support the claim about the limitations of the framework or the potential for broader applicability. Without detailed evidence or reasoning, the claim remains 3, as it provides a general critique but lacks concrete justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluative framework, noting that it is restricted to only three QuestionAnswering tasks and two language models. It raises concerns about the method\"s broader applicability and suggests that its potential to generalize to other reasoning or generation tasks or more advanced models is uncertain. This feedback is 3 as it points out a potential weakness in the framework, prompting the authors to consider expanding their evaluation to include a broader range of tasks and models. However, the comment could be more helpful if it provided specific suggestions or examples of additional tasks or models that could be included to enhance the framework\"s applicability. Overall, the feedback is clear but incomplete, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the experiments are insufficient and suggests that more empirical experiments or toy experiments are needed to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions the need to cite the result in Kaplan et al. 2020. This feedback provides a clear and concrete action for the authors to take, as it specifies the types of experiments that should be conducted and the need to include additional references. The authors know exactly what steps to take to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment addresses the sufficiency of the experiments, suggesting the need for more empirical or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions the need to cite the result in Kaplan et al. 2020. However, the comment does not specify which experiments are insufficient or where these experiments are described in the paper, making it weakly grounded. The authors can infer that it relates to the experimental sections, but the lack of explicit references makes it challenging to pinpoint the exact parts needing revision. The comment is specific in suggesting additional experiments and referencing external work, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are insufficient and suggests conducting more empirical or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. The comment also mentions the need to cite the result in Kaplan et al. 2020. While the suggestion to conduct additional experiments is logical and provides a clear direction for improvement, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. The reference to Kaplan et al. 2020 is mentioned but not elaborated upon, which further limits the verifiability of the claim. Therefore, the comment is 3, as it provides a general direction but lacks detailed evidence or examples to fully support the claim.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the insufficiency of the experiments. It provides a clear and actionable suggestion by recommending the need for more empirical experiments or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. Additionally, it mentions the importance of citing the result in Kaplan et al. 2020, which could provide additional context and support for the analysis. This feedback is 5 as it directs the authors to a specific area for improvement, offering a clear path forward to enhance the validity and robustness of their work. However, it could be further improved by providing more detailed guidance on the types of experiments or analyses that would be most beneficial. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests a specific action for the authors to take: presenting the performance as a function of the distance of initialization to the groundtruth. It provides a clear and concrete method for implementing this suggestion, including specific steps such as varying the distance c and reporting the performance accordingly. The comment also offers an expectation of the outcome, which further guides the authors on what to expect. This level of detail and explicit guidance makes the comment 5.", "grounding_specificity_rationale": "The comment suggests an analysis of sensitivity to initialization by proposing a specific method to present performance as a function of the distance of initialization to the groundtruth. It provides a clear and actionable suggestion, but it does not specify which part of the paper this analysis should be included in. While the authors can infer that it relates to the experimental or results sections, the comment lacks full grounding as it does not explicitly mention these sections. The suggestion is specific, as it outlines a method for analyzing sensitivity to initialization, but the lack of explicit grounding limits the comment to being 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests an analysis of sensitivity to initialization by proposing a specific method to present performance as a function of the distance of initialization to the groundtruth. The suggestion is supported by logical reasoning, as it is based on the expectation that the mean error and variance would increase as the quality of initialization decreases. However, the comment lacks specific examples or references to existing literature that might support this claim, making it 3. The authors would need to consider the rationale and potentially conduct additional research to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper by analyzing the sensitivity to initialization. It proposes a method to present performance as a function of the distance of initialization to the groundtruth, which could help in understanding how the quality of initialization affects the results. This feedback is clear and offers a concrete way for the authors to enhance their analysis, making it 5 for improving the draft. However, the comment could be more helpful if it included additional guidance on how to interpret the results or potential implications of the findings. Overall, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This provides a clear and direct action for the authors to take, which is to remove the absolute value operation. The comment is specific and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the definition of the Frobenius norm, namely the unnecessary use of the absolute value operation due to the real nature of tensor entries. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absolute value operation in the definition of the Frobenius norm is unnecessary because tensor entries are real numbers. This claim is based on a logical reasoning that since tensor entries are real, taking the absolute value does not add any value to the calculation. The comment provides a clear and straightforward explanation, making it 5. The authors can easily understand and address this point by removing the unnecessary operation. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a minor issue with the definition of the Frobenius norm in the paper, specifically pointing out that the absolute value operation is unnecessary because tensor entries are real numbers. This feedback is clear and actionable, as it provides a specific suggestion for improvement that can be easily implemented by the authors. However, the comment could be more helpful if it explained why this change is important or how it might impact the overall analysis or results. Despite this, the comment is still valuable as it directs the authors to a precise area for refinement, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests using DinoV2 Frechet Distances in addition to the widely used FID metric for comparisons, referencing a specific source \"C\". This provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The reference to a specific source adds further guidance, making the action 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FIDs\" and \"the simplistic Inception network C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests using DinoV2 Frechet Distances in addition to the widely used FID metric, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests using DinoV2 Frechet Distances instead of FIDs for evaluation, citing \"clear flaws\" associated with FIDs and referencing a specific source \"C\" for the Inception network. However, the comment does not provide detailed reasoning or examples of these flaws, making it 3. The authors would need to consult the referenced source to fully understand the justification for the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of FIDs for evaluation, noting that there have been \"clear flaws\" associated with them. It suggests using DinoV2 Frechet Distances in addition to FID metrics, providing a clear and actionable recommendation for improvement. This feedback is valuable as it directs the authors to consider alternative evaluation metrics that might better suit their needs. However, the comment could be more helpful if it elaborated on the specific flaws associated with FIDs or provided more context about why DinoV2 Frechet Distances are preferred. Overall, the comment is 4 as it offers a constructive suggestion for enhancing the evaluation methodology."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests an action: \"I would suggest using a second yaxis or another visualization which is more physically accurate.\" This provides a clear and concrete direction for the authors to improve their draft by addressing the issue with Figure 6C. The suggestion is specific and actionable, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely that it implies negative rates when it should not, and suggests using a second yaxis or another visualization to address this issue. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 6C implies negative rates, which is not the case. The reviewer suggests using a second yaxis or another visualization to address this issue. However, the comment does not provide any evidence or reasoning to support the claim that the figure implies negative rates. Without specific examples or references, the claim remains 1, as the authors may not fully understand the basis of the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates when it should not. The reviewer provides a clear and actionable suggestion to address this issue by recommending the use of a second yaxis or another visualization that is more physically accurate. This feedback is specific and offers a concrete way for the authors to improve their draft, making it 4. However, the comment could be more helpful if it included additional context or examples to further clarify the issue and the suggested solution. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point questions a statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LM) compared to GAN models to avoid overfitting. The reviewer provides a counterexample from Zaremba et al. (2014) and suggests that the baseline models may not be properly regularized. The comment raises a specific issue with the statement and implies that the authors should investigate the regularization methods used in their models. However, it does not explicitly instruct the authors to check the regularization methods or provide detailed guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the regularization methods used in their models. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"supplemental section D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions a particular statement regarding the necessity of smaller architectures for language models compared to GAN models to avoid overfitting. The reviewer provides a counterexample from Zaremba et al. (2014) and suggests that the baseline models may not be properly regularized, specifically questioning whether dropout is applied to the hidden states. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions a statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LM) compared to GAN models to avoid overfitting. The reviewer provides a counterexample from Zaremba et al. (2014), which trains 1500dimensional LSTMs on PTB, suggesting that the baseline models may not be properly regularized. The reviewer also questions whether dropout is applied to the hidden states, as mentioned in D.4. This provides a logical reasoning and a specific reference to support the claim, making the comment 4. However, the comment could be strengthened by providing more detailed analysis or examples of how the baseline models could be improved. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment questions a specific statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LM) compared to GAN models to avoid overfitting. The reviewer provides a counterexample from Zaremba et al. (2014), which trains 1500dimensional LSTMs on PTB, suggesting that the baseline models may not be properly regularized. This feedback is 3 as it points out a potential issue with the statement and encourages the authors to investigate the regularization methods used in their models. However, the comment could be more helpful if it provided specific suggestions on how to address the issue or offered additional guidance on improving the regularization techniques. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point makes a comparison between the multilingual chainofthought and the villa chainofthought, stating that the former is incremental compared to the latter. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this comparison, whether it should be clarified, or how the authors might improve their contribution. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment compares the contribution of multilingual chainofthought to the villa chainofthought, suggesting that the former is incremental compared to the latter. However, it does not specify which part of the paper this comparison is based on, nor does it provide details on what aspects of the contribution are considered incremental. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of multilingual chainofthought is incremental compared to the villa chainofthought. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment makes a claim about the incremental contribution of multilingual chainofthought compared to the villa chainofthought. However, it lacks specificity and does not provide any actionable feedback or suggestions for the authors to improve their work. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects of their contribution need to be addressed or how to enhance it. As a result, the comment is 1, as it does not offer any meaningful insights or directions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the comparability of Geffect values across different unlearning objectives and approaches, as the paper studies each objective in isolation. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve the comparability of their results. The comment implies that the authors should consider a more comprehensive approach to comparing Geffect values, but it lacks concrete details on how to achieve this. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the concern regarding the comparability of Geffect values across various unlearning objectives and approaches. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the comparability of Geffect values across different unlearning objectives and approaches, as the paper studies each objective in isolation. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of supporting evidence or detailed justification makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s methodology, specifically noting that the study of Geffects for each unlearning objective in isolation may raise concerns about the comparability of Geffect values across different approaches. This is a valid observation that could impact the interpretation of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the comparability of their results. While it highlights a potential weakness, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the consistency of the advantage of the UNIFORM procedure over other methods, particularly in the 1shot setting. It questions whether the authors have a theory explaining why the method is less effective in this setting. While the comment raises a specific issue and suggests that the authors should address it, it does not provide explicit guidance on how to develop a theory or improve the method. The action is implicit and somewhat vague, as the authors need to infer that they should explore theoretical explanations for the observed inconsistency. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the tables\" and \"the 1shot setting,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the inconsistency in the advantage of the UNIFORM procedure over other methods, particularly in the 1shot setting, and asks for a theoretical explanation for this observation. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the advantage of the UNIFORM procedure over other methods is not consistent, particularly in the 1shot setting. It supports this claim by referencing the tables, which show that UNIFORM does not always offer a clear advantage. However, the comment lacks specific examples or detailed analysis to fully substantiate the claim. While it provides some evidence, the lack of detailed reasoning or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the advantage of the UNIFORM procedure over other methods is not consistent, particularly in the 1shot setting. It points out that the tables show UNIFORM does not always offer a clear advantage, prompting the authors to consider why this might be the case. The comment also acknowledges that the clarity and design of the experiments and results are well done. However, it could be more helpful if it provided suggestions on how the authors might address the inconsistency or explore theoretical explanations for the observed effect. Despite this, the comment offers a clear direction for the authors to investigate and improve their work, making it 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should consider the reason behind the information value being a \"stronger predictor\" for dialogue, specifically referencing the complementarity discussed on page 7 or the discussion on page 8. It implies that adding an explanation or reference to an existing linguistic theory could strengthen the paper. While the comment provides a clear direction for the authors to explore, it does not explicitly instruct them to add the explanation or reference. The action is mostly implicit, as the authors need to infer that they should include this information. However, the suggestion is concrete, as it specifies the areas to focus on and the potential impact on the paper. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 7\" and \"page 8,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of the information value being a \"stronger predictor\" for dialogue and suggests that the authors should consider existing linguistic theories that could explain this phenomenon. By recommending the inclusion of such theories, the comment provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the information value being a \"stronger predictor\" for dialogue could be explained by existing linguistic theories. However, it does not provide specific references or examples of such theories, making the claim 3. The authors would need to conduct additional research to identify relevant theories and incorporate them into their paper. While the comment provides a direction for improvement, it lacks detailed justification or evidence, making it 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors consider the reason behind the information value being a \"stronger predictor\" for dialogue. It references specific pages (7 and 8) where the complementarity is discussed, providing a clear direction for the authors to explore. The comment also implies that incorporating an explanation or reference to existing linguistic theories could strengthen the paper. While the feedback is actionable and provides a specific area for enhancement, it could be more helpful if it offered examples of relevant linguistic theories or suggested how to integrate them into the discussion. Overall, the comment is 4 as it guides the authors toward a meaningful improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the definition of \"T_a(t)\" between Section 3.1, where it is used, and Section 4, where it is defined. This comment explicitly identifies the issue and suggests that the authors should ensure consistency in the definition and usage of variables across different sections of the paper. However, it does not provide specific guidance on how to address this inconsistency, such as suggesting a reorganization of the sections or a clarification in the definitions. While the action is clear, the lack of detailed instructions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of \"T_a(t)\" being used without being defined until Section 4. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual observation about the usage and definition of \"T_a(t)\" in the paper. It does not express an opinion, judgment, or suggestion that requires verification. It is purely descriptive and does not contain any claims or subjective statements. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that \"T_a(t)\" is used in Section 3.1 but is only defined in Section 4. This feedback is clear and actionable, as it highlights a potential inconsistency in the paper that could cause confusion for readers. By pointing out this discrepancy, the comment provides the authors with a clear direction for improvement, encouraging them to ensure that definitions are consistent throughout the paper. However, the comment could be more helpful if it suggested ways to address this issue, such as reorganizing the sections or adding a definition earlier. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two distinct parts. The first part requests clarification on the empirical analysis in Figure 3, specifically asking for additional information on how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. The second part requests an explanation of why these adjustments are effective in enhancing the model\"s performance. The third part points out the large spacing between Equations (9) and (10) and the preceding text. While the comment identifies areas that need clarification and formatting improvement, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer the specific steps to take for each point. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also mentions \"Equations (9) and (10),\" providing further grounding. The comment is specific in its request for clarification on the empirical analysis, specifically asking for details on how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. It also requests an explanation of why these adjustments are effective. Additionally, it points out the formatting issue with the equations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple requests for clarification and additional information regarding the empirical analysis in Figure 3. It asks for details on how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy, and why these adjustments are effective. Additionally, it points out a formatting issue with Equations (9) and (10). While the comment identifies areas that need clarification, it does not provide specific evidence or references to support the claims or suggestions. The inclusion of a reference to a related work by Liu et al. does not directly address the empirical analysis or the specific issues raised. Therefore, the comment is 3, as it provides a general direction for improvement but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies several areas that require clarification and improvement in the paper. It points out that the empirical analysis in Figure 3 is confusing and requests additional clarification on how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. It also asks for an explanation of why these adjustments are effective in enhancing the model\"s performance. Additionally, the comment highlights a formatting issue with Equations (9) and (10) having large spacing from the preceding text. The inclusion of a reference to a related work by Liu et al. provides some context but does not directly address the issues raised. While the comment identifies specific areas for improvement, it could be more helpful by providing detailed guidance on how to address these issues. Therefore, the comment is 3, as it provides some direction but lacks comprehensive feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should compare their work with the recent related work CoCoOp in the experiments. It provides a clear and direct action for the authors to take, which is to include CoCoOp in the experimental comparisons. The comment also explains the rationale behind this suggestion, noting that CoCoOp is an extended version of CoOp and should be considered for comparison. This level of detail provides the authors with a concrete and explicit action to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"CoCoOp,\" allowing the authors to accurately identify the part of the paper being addressed, which is the experimental section. It also specifies the issue by pointing out the omission of CoCoOp in the experiments, despite it being a relevant work that should be compared. The comment provides a clear direction for the authors to include CoCoOp in the comparisons, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the recent related work CoCoOp should be compared in the experiments, despite being published after the NeurIPS deadline. The reviewer provides a logical reasoning by explaining that CoCoOp is an extended version of CoOp, implying that it is relevant and should be included in the comparisons. However, the comment lacks specific examples or references to support the claim that CoCoOp is a significant work that should be included. This makes the claim 3, as it provides a rationale but lacks detailed evidence or examples to fully substantiate the request for comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific omission in the experimental comparisons, noting that the recent related work CoCoOp is not included despite being a relevant work. It provides a clear and actionable suggestion for the authors to include CoCoOp in the experiments, explaining that it is an extended version of CoOp and should be considered for comparison. This feedback is valuable as it highlights a gap in the current experimental setup and offers a concrete step for the authors to enhance the comprehensiveness of their work. However, the comment could be more helpful if it provided additional context or examples of how CoCoOp relates to the current work, which would further support the authors in making the necessary adjustments. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that Figure 1 could be improved by better illustrating the processing pipeline, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring. It also mentions the need to show where model training is used to optimize the selection modules. While the comment implies that the authors should enhance the figure, it does not provide specific guidance on how to achieve this improvement. The action is implicit and somewhat vague, as the authors are left to infer the exact changes needed to enhance the figure. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the figure, suggesting that it should better illustrate the processing pipeline, including prompt generation, manual check, demonstration selection with ground truth scores, and automatic scoring, as well as showing where model training is used to optimize the selection modules. This level of detail provides the authors with a clear understanding of what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 1 could be improved by better illustrating the processing pipeline. However, it does not provide any specific reasoning or examples to support why this improvement is necessary or how it would enhance the understanding of the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests an improvement to Figure 1 by proposing a better illustration of the processing pipeline. It provides specific details on what aspects should be included, such as prompt generation, manual check, demonstration selection with ground truth scores, and automatic scoring, as well as the integration of model training to optimize selection modules. This feedback is clear and actionable, offering the authors a concrete way to enhance the visual representation of their work. However, the comment could be more helpful if it explained why these improvements are necessary or how they would impact the reader\"s understanding. Overall, the comment is 4 as it provides specific guidance for improving the figure, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to avoid using abbreviations like \"MoCo\" in section headers, as they may be unfamiliar to readers. This feedback provides a clear and direct action for the authors to take, ensuring that section headers are more accessible and understandable. The comment is specific and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section number \"(136)\" and the specific issue with the use of the abbreviation \"MoCo\" in the section header. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with using abbreviations in section headers, providing a clear direction for improvement. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that abbreviations like \"MoCo\" should not appear in section headers because readers might not know what they mean. This is a logical claim supported by the reasoning that section headers should be clear and accessible to readers. However, the comment does not provide specific examples or references to substantiate the claim further, which could strengthen the argument. Therefore, the claim is 4, as it provides a clear rationale but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of abbreviations in section headers, suggesting that they should be avoided as they may be unfamiliar to readers. This feedback is clear and actionable, providing the authors with a direct suggestion to improve the clarity and accessibility of their section headers. By addressing this issue, the authors can enhance the readability of their paper, making it more understandable for a broader audience. However, the comment could be more helpful if it provided additional guidance on how to replace or explain the abbreviations. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how the authors might clarify their technical contribution or improve the analysis. The comment lacks explicit or implicit actions, leaving the authors without a clear understanding of what steps to take to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not specify which part of the paper is unclear or which analyses are considered standard. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas that need improvement. The comment is 1 as it does not refer to any specific section or part of the paper, and it is not specific in detailing what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the technical contribution is unclear and that most of the analysis is standard. This feedback is important as it highlights a critical area that needs clarification and improvement. However, the comment lacks specificity and does not provide actionable suggestions on how the authors might enhance the clarity of their technical contribution or differentiate their analysis from standard approaches. Without detailed guidance, the authors may find it challenging to address the issue effectively. Therefore, the comment is 3, as it points out a key area for improvement but does not offer comprehensive guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach and that more substantial evidence or arguments are needed to establish this as a significant contribution. However, it does not provide explicit guidance on what specific evidence or arguments are lacking or how the authors might address this issue. The action is implicit and vague, leaving the authors to infer that they need to provide more substantial evidence or arguments but without clear direction on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper\"s primary contribution, specifically mentioning the incremental advancement in efficiency over the TACTiS approach. However, it does not specify which part of the paper discusses this contribution, making it weakly grounded. The comment is specific in its request for more substantial evidence or arguments to establish the significance of this contribution. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach, suggesting that more substantial evidence or arguments are needed to establish this as a significant contribution. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence renders the claim 3, as the authors would need to infer the specific issues or areas where more evidence is needed. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s contribution, suggesting that the primary advancement is merely an incremental improvement over the TACTiS approach. It highlights the need for more substantial evidence or arguments to establish this contribution as significant. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or provide the necessary evidence. While it points out a critical area for improvement, it does not offer actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the S2D structure, specifically why the number of parameters does not change despite an increase in depth. The reviewer acknowledges that efficiency could be improved but notes that more details are needed regarding parameters. While the comment identifies an area for clarification, it does not provide explicit guidance on how the authors should address this issue or what specific details are expected. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information about the parameters. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"S2D structure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of why the number of parameters does not change, even when the kernel height/width stay the same, and suggests that more details are expected regarding parameters. The comment provides a clear direction for the authors to address the lack of clarity in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the S2D structure, specifically why the number of parameters does not change despite an increase in depth. The reviewer provides a logical explanation that if the kernel height/width stay the same, the depth increase would result in more parameters. However, the comment does not provide specific examples or references to support this claim, leaving it 3. The authors would need to consider the reasoning and potentially conduct further analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the S2D structure, questioning why the number of parameters does not change despite an increase in depth. It provides a logical explanation that if the kernel height/width remain the same, the depth increase would lead to more parameters. The comment also acknowledges the potential for efficiency improvement, noting that the FLOP is quadratic on the activation side length. However, it lacks detailed guidance or suggestions on how the authors might address this issue or provide the expected details about parameters. While it highlights an area for improvement, the comment could be more helpful with additional actionable advice or examples. Therefore, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should reiterate why the GPC (benchmark) is performing better than BPC (their method), specifically highlighting the role of bandit feedback and the lack of information about the form of the cost function. This provides a clear and direct action for the authors to take, ensuring they understand exactly what needs to be addressed in their draft. The comment is explicit and concrete, offering specific guidance on how to improve the presentation of the simulation study. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"presentation of the simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of explanation for why the GPC (benchmark) is performing better than BPC (the authors\" method). The comment suggests that the authors should reiterate that this is due to the use of bandit feedback and not using information about the form of the cost function. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the presentation of the simulation study is not beneficial to the authors and suggests that the authors should reiterate why the GPC (benchmark) is performing better than BPC (their method). The comment provides a specific reason for this claim, stating that it is due to the use of bandit feedback and not using information about the form of the cost function. This reasoning is logical and provides a clear explanation for the observed performance difference, making the claim 4. However, the comment could be strengthened by providing more detailed examples or references to support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the simulation study, noting that the authors do not adequately explain why the GPC (benchmark) is performing better than BPC (their method). It suggests that the authors should reiterate the importance of bandit feedback and the lack of information about the form of the cost function in this context. This feedback is clear and actionable, providing the authors with a direct suggestion on how to improve the clarity and comprehensiveness of their results. By addressing this point, the authors can enhance the understanding and interpretation of their simulation study, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should quantify and clarify the claim about ReLU not working well in very deep or convolutional networks. The reviewer provides a specific example from the AlexNet paper, which used ReLUs and was considered deep at the time. This feedback implies that the authors should provide more detailed evidence or reasoning to support their claim, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed evidence. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim about the performance of ReLU in deep or convolutional networks. It provides a reference to the AlexNet paper, which used ReLUs and was considered deep at the time, making a point that challenges the claim. However, the comment does not specify which part of the paper this claim is made in, leaving the authors to infer the relevant section. While the comment is specific in its critique, it lacks full grounding because it does not explicitly mention the section where the claim is discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim that \"ReLU does not work very well in very deep or in convolutional networks\" by referencing the AlexNet paper, which used ReLUs and was considered deep at the time. This provides a logical counterexample to the claim, making the comment 3. However, the comment could be strengthened by providing more detailed analysis or references to support the claim further. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the claim that \"ReLU does not work very well in very deep or in convolutional networks\" by pointing out that ReLUs were used in the AlexNet paper, which was considered deep and used convolutional layers. This feedback is 3 as it challenges the authors to provide a more nuanced or evidencebased argument for their claim. However, it does not offer specific suggestions or guidance on how to address the issue or improve the draft. While it prompts the authors to reconsider their claim, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the high perplexity values reported in Figure 1, which seems to contradict the better BLEU scores. The reviewer questions how the perplexity was calculated, implying that the authors should clarify or justify their calculation method. While the comment identifies an issue and suggests a need for clarification, it does not provide explicit instructions on how to address the concern or improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation of their perplexity calculation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the high perplexity values and questions the calculation method, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the high perplexity values reported in Figure 1, which seems to contradict better BLEU scores. The reviewer questions the calculation method of perplexity, implying that there might be an issue with the methodology or interpretation. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the perplexity is unusually high or how it contradicts the BLEU scores. This lack of detailed justification makes the claim 3, as the authors would need to investigate further to understand the basis of the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the high perplexity values reported in Figure 1, which seems to contradict better BLEU scores. It questions the calculation method of perplexity, indicating that the authors should clarify or justify their calculation. This feedback is 3 as it identifies a potential issue with the interpretation of the results and prompts the authors to provide a detailed explanation. However, the comment could be more helpful if it offered suggestions on how to address the discrepancy or provided examples of how to improve the calculation or interpretation of perplexity. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors provide more explanations regarding the consistency between training and inference, which can be easily satisfied due to the smoothness of neural models. While the comment implies that the authors should expand on this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given specific guidance on what additional explanations are needed or how to present them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (9597 and 308310) where the paper discusses the consistency between training and inference. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests that the authors provide more explanations on this topic, which is a clear and actionable request. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper addresses the consistency between training and inference, suggesting that this consistency can be easily satisfied due to the smoothness of neural models. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the authors provide more explanations regarding the consistency between training and inference. It points out that the paper mentions this aspect multiple times (Lines 9597 and 308310) but does not elaborate on it. This feedback is clear and actionable, as it directs the authors to expand on a particular topic that could enhance the clarity and depth of their work. However, the comment could be more helpful if it provided specific suggestions on what additional explanations or insights could be included. Overall, the comment is 4, as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors include some failure cases and related discussion in their paper. While it implies that the authors should add this information, the comment does not provide specific guidance on what constitutes a \"failure case\" or how to structure the discussion. The action is implicit and somewhat vague, as the authors can infer that they need to include additional content but may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including \"some failure cases and related discussion,\" but it does not specify which part of the paper this suggestion pertains to. The authors may infer that it relates to the methodology or results sections, but without explicit guidance, it is difficult to pinpoint the exact area needing attention. The comment is specific in suggesting the inclusion of failure cases and discussion, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that including \"some failure cases and related discussion\" would be beneficial. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that including failure cases and related discussion would be beneficial for the paper. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what constitutes a \"failure case\" or how to structure the discussion. The feedback is 3 as it points out a potential gap in the paper, but it does not offer detailed or actionable advice on how to address it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the introduction of epsilon in equation (11) might be clearer if it were introduced when discussing equation (11). This is an explicit suggestion for improvement, as it provides a specific action for the authors to take. The comment is concrete, as it clearly indicates what needs to be done to enhance clarity. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1\" and references specific equations (10 and 11), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests introducing epsilon when discussing equation (11), providing clear guidance on how to improve the clarity of the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the introduction of epsilon in equation (11) might be clearer if it were introduced when discussing equation (11). This is a logical suggestion based on the structure of the equations, but it does not provide specific reasoning or examples to support why this change would improve clarity. The comment lacks detailed justification or references, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the paper by recommending that epsilon be introduced when discussing equation (11). This feedback is clear and actionable, as it directs the authors to a particular section where they can enhance the presentation of their work. However, the comment could be more helpful if it explained why introducing epsilon at this point would be beneficial or how it would impact the reader\"s understanding. Despite this, the comment is 4 as it offers a concrete step for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should \"explicitly add the upper bounds of counting\" and potentially elaborate on empirical runtimes. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, offering a clear path forward for the authors. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L 145,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of inadequate discussion on the computational complexity of counting homomorphisms and suggests adding upper bounds and elaborating on empirical runtimes. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms, specifically mentioning a brief statement on page 145. The reviewer suggests that the paper should include upper bounds of counting and potentially elaborate on empirical runtimes. While the comment identifies a potential gap in the discussion, it lacks specific examples or references to support the claim that the current discussion is inadequate. The suggestion for improvement is logical, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks depth, namely the discussion of computational complexity in counting homomorphisms. It points out that the current statements are brief and suggests that the authors should explicitly add upper bounds of counting and potentially elaborate on empirical runtimes. This feedback is clear and actionable, providing the authors with a concrete direction to enhance their draft by addressing a critical aspect of their methodology. However, the comment could be more helpful if it offered examples or specific suggestions on how to present the upper bounds or empirical runtimes. Overall, the comment is 4 as it directs the authors to a significant improvement area, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take, including correcting a typo (\"f\" to \"g\") in line 108 and removing an extra period in line 115. Additionally, it poses a question about the convergence of the baseline MCL with deep learning, which implies that the authors should address this concern in their draft. The actions are clear and concrete, providing the authors with specific steps to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (\"line 108\" and \"line 115\") where corrections need to be made, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as a typo and an extra period, which need to be corrected. Additionally, it raises a question about the convergence of the baseline MCL with deep learning, providing a clear direction for the authors to address this concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and questions, without any subjective claims or opinions that require verification. It points out specific errors in the text, such as a typo and an extra period, and raises a question about the convergence of the baseline MCL with deep learning. Since it does not contain any claims or suggestions that need justification, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by pointing out two errors in the text: a typo in \"f\" to \"g\" in line 108 and an extra period in line 115. Additionally, it raises a question about the convergence of the baseline MCL with deep learning, which is a critical aspect of the methodology. This question prompts the authors to address a potential issue that could impact the ensemble performance. By identifying these specific areas for improvement and raising a relevant question, the comment is 5 as it guides the authors in refining their draft and addressing potential methodological concerns. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point raises two specific questions about the proof of Theorem A.3. It questions the representation of the input \"x\" as having two indices, given that it is described as a vector, not a matrix. Additionally, it challenges the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d, suggesting it should be d instead. These questions are explicit and provide clear guidance on what aspects of the proof need clarification or correction. The authors are given direct actions to take, such as revisiting the proof to address these issues. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem A.3 proof,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the proof, such as the representation of the input \"x\" and the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d. The comment provides clear details on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises specific questions about the proof of Theorem A.3, questioning the representation of the input \"x\" as having two indices and challenging the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d. These are factual observations that require clarification or correction, rather than subjective claims or opinions. The comment does not contain any subjective claims or suggestions, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises specific questions about the proof of Theorem A.3, questioning the representation of the input \"x\" as having two indices and challenging the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d. These questions are clear and actionable, providing the authors with direct guidance on areas that need clarification or correction in their proof. By addressing these points, the authors can improve the rigor and accuracy of their proof, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the effectiveness of the model, specifically regarding the use of beam search and the accuracy of the results. It questions the reliability of the model when relationships and entities are replaced and suggests that the authors should provide more information on the percentage of correct entities/relationships being plugged in. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors need to infer that they should address these concerns by providing additional data or analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions sections 4.3 and 4.4, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the concern about the use of words like \"somewhat\" and \"good generative ability\" in the description, and it questions the reliability of the model when relationships and entities are replaced. The comment further requests specific information on the percentage of correct entities/relationships being plugged in. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the effectiveness of the model, specifically regarding the use of beam search and the accuracy of the results. It questions the reliability of the model when relationships and entities are replaced and suggests that the authors should provide more information on the percentage of correct entities/relationships being plugged in. However, the comment lacks specific examples or references to support these claims, making it 3. The authors would need to infer the basis of the concern and address it themselves, which could be challenging without additional guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the effectiveness of the model, particularly in sections 4.3 and 4.4. It questions the reliability of the model when relationships and entities are replaced, highlighting the need for assurance that the pluggedin entities/relationships are correct. The comment also requests specific information on the percentage of correct entities/relationships being plugged in, which is a clear and actionable suggestion for improvement. However, the comment could be more helpful if it provided additional context or examples to further clarify the issue and guide the authors in addressing it. Overall, the feedback is 4 as it directs the authors to a critical area that requires further analysis and explanation."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the performance of FedPCL is heavily reliant on the selection of pretrained models, which limits its applications. It notes that the model accuracy is sensitive to these pretrained models, as shown in Table 4. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest ways to address this limitation, such as experimenting with different pretrained models or developing strategies to reduce reliance on them. Without actionable guidance, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of the performance of FedPCL being heavily reliant on the selection of pretrained models and notes the sensitivity of model accuracy to these models. The comment further acknowledges that the authors have adequately addressed this limitation by developing a lightweight federated learning framework and integrating pretrained models for federated aggregation. This provides clear guidance on what the authors have done to address the issue. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance of FedPCL heavily relies on the selection of different pretrained models, limiting its applications. It supports this claim by referencing Table 4, which shows the model accuracy is sensitive to pretrained models. The comment also acknowledges that the authors have addressed this limitation by developing a lightweight federated learning framework and integrating pretrained models for federated aggregation. This provides a logical reasoning and specific examples to support the claim, making it 4. However, the comment could be strengthened by providing more detailed analysis or references to similar works in the field. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment acknowledges that the performance of FedPCL is heavily reliant on the selection of pretrained models, which limits its applications. It notes that the model accuracy is sensitive to these pretrained models, as shown in Table 4. The comment also recognizes that the authors have adequately addressed this limitation by developing a lightweight federated learning framework and integrating pretrained models for federated aggregation. This feedback is 3 as it identifies a key limitation of the work and acknowledges the authors\" efforts to address it. However, it could be more helpful if it provided suggestions or guidance on how to further improve the framework or reduce its reliance on pretrained models. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit suggestions for improving the organization and clarity of the paper. It recommends separating the description of the main contributions, specifically the two types of attention for deep VAEs, into a separate section, and then describing the generative and inference models. Additionally, it suggests referencing tricks like normalization or feature scaling in a separate section. These suggestions are clear and provide concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections (2.3 and 2.4) where the description of the layerwise attention mechanism is scattered. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests organizing the main contributions into a separate section and then describing the generative and inference models. Additionally, it recommends referencing tricks like normalization or feature scaling in a separate section. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of suggestions for improving the organization and clarity of the paper, specifically regarding the description of the main contributions and the referencing of certain techniques. It does not contain any subjective claims, opinions, or judgments that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the organization and clarity of the paper. It suggests separating the description of the main contributions, specifically the two types of attention for deep VAEs, into a separate section, and then describing the generative and inference models. This recommendation would help improve the paper\"s structure and make it easier for readers to follow. Additionally, the comment suggests referencing tricks like normalization or feature scaling in a separate section, which could enhance the paper\"s comprehensiveness. However, the comment is incomplete, as it only provides suggestions without fully elaborating on the potential benefits or how these changes would impact the paper. Despite this, the feedback is 4 as it offers clear directions for improvement. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests a specific change to the terminology used in section 4, recommending that \"X\" should be a multiset instead of a set. This is an explicit action with clear guidance on how to implement the change, as it specifies the need to include multiplicities of labels in the graph for the histogram to accurately represent it. The authors know exactly what needs to be done to address this feedback, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the terminology used, suggesting that \"X\" should be a multiset instead of a set to accurately represent a graph with repeated vertex or edge labels. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the use of a set in section 4 is inappropriate because it does not account for the multiplicities of labels in a graph. The reviewer provides a logical explanation for why a multiset would be more appropriate, as it can include the multiplicities of the labels. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the draft. It identifies a potential issue with the terminology used in section 4, suggesting that \"X\" should be a multiset instead of a set to accurately represent a graph with repeated vertex or edge labels. This feedback is clear and provides a concrete way for the authors to enhance the accuracy and clarity of their work. By addressing this suggestion, the authors can improve the precision of their representation and ensure that their histogram accurately reflects the graph\"s characteristics. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point starts by acknowledging the paper\"s organization and writing quality, but then it provides specific feedback on areas that could be improved. It suggests drawing a table to compare different CoT prompting methods across different dimensions, which is a concrete action. Additionally, it raises questions about the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and the selection criteria in section 4.2, prompting the authors to clarify these points. These questions are explicit and provide clear guidance on what the authors need to address. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the writing quality and the need for a table to compare different CoT prompting methods. It also raises specific questions about the assumption in section 4.2, such as the selection criteria and the reasoning behind it. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a positive statement about the paper\"s organization and writing quality, followed by specific feedback and questions. The positive statement is factual and does not require verification. The feedback and questions are also factual and do not contain subjective claims or opinions that need verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment starts by acknowledging the paper\"s organization and writing quality, which is a positive observation. However, it then provides specific feedback on areas for improvement, such as suggesting the inclusion of a table to compare different CoT prompting methods across various dimensions. This is a clear and actionable suggestion that could enhance the clarity and comprehensiveness of the paper. Additionally, the comment raises questions about the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and the selection criteria in section 4.2, prompting the authors to clarify these points. These questions are specific and provide a clear direction for the authors to address. Overall, the comment is 4 as it offers constructive feedback and guidance for improving the draft, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant omission in the title, abstract, introduction, and discussion regarding the results being for unsupervised random forests. The reviewer emphasizes that this is a serious issue that needs to be addressed to prevent casual readers from drawing incorrect conclusions. The comment explicitly states that this must be fixed for publication, indicating a clear and direct action for the authors to take. Additionally, the reviewer suggests that it would be straightforward to make these changes. The feedback is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title, abstract, introduction, and discussion, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of not explaining that the results are for unsupervised random forests, which is a critical omission that could lead to incorrect conclusions. The comment provides a clear direction for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the title, abstract, introduction, and discussion do not adequately explain that the results are for unsupervised random forests, which could lead to incorrect conclusions. The reviewer emphasizes the importance of this clarification, suggesting it is a \"fairly serious omission.\" However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the exact issues and how to address them based on the general feedback provided. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically that the title, abstract, introduction, and discussion do not clearly indicate that the results are for unsupervised random forests. This omission could lead to incorrect conclusions by casual readers. The reviewer emphasizes the importance of addressing this issue for publication, providing a clear and actionable suggestion for improvement. However, the comment could be more helpful by offering specific guidance on how to incorporate this clarification into the paper. Despite this, the feedback is 4 as it highlights a significant weakness and directs the authors to a necessary correction. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly highlights the lack of significance testing to support claims about the differences between certain methods. It provides a specific example from line 486, where the authors make a claim about the conversational ability of ChatGPT and GPT4 boosting translation quality and discourse awareness. The reviewer suggests that without proper testing, including checking the distribution and accounting for multiple comparisons, it is difficult to determine the significance of these claims. This feedback is explicit and provides a clear action for the authors to take, which is to conduct significance testing to support their claims. The comment is 5 as it gives a direct and concrete instruction on how to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 486,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of lacking significance testing to support claims about the differences between certain methods. The reviewer provides a concrete example from the paper, highlighting the need for proper testing, including checking the distribution and accounting for multiple comparisons. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors make significant claims about the differences between certain methods without providing sufficient evidence or testing to support these claims. The reviewer specifically points out an example from line 486, where the authors discuss the conversational ability of ChatGPT and GPT4, and highlights the lack of significance testing to determine whether the observed differences are statistically significant. The comment provides a logical reasoning by suggesting that without proper testing, including checking the distribution and accounting for multiple comparisons, it is difficult to determine the significance of the claims. This reasoning is clear and provides a basis for the claim, making it 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of significance testing to support claims about the differences between certain methods. It provides a concrete example from line 486, where the authors make a claim about the conversational ability of ChatGPT and GPT4 boosting translation quality and discourse awareness. The reviewer points out that the differences between the methods are minimal and suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to determine significance. This feedback is 5 as it clearly identifies a critical gap in the paper and provides specific guidance on how to address it, empowering the authors to improve the rigor and validity of their claims. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that Figure 5 is difficult to comprehend and requests more details about the two baselines presented. It also points out that the authors only studied CATER for Englishcentric datasets, suggesting that they could extend CATER to other languages in the future. While the comment implies that the authors should provide more details about the baselines and consider extending CATER to other languages, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, namely that it is hard to comprehend, and requests more details about the two baselines presented. Additionally, the comment points out the limitation of the study being confined to Englishcentric datasets and suggests extending CATER to other languages. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 5 is hard to comprehend and suggests that the authors provide more details about the two baselines presented. It also points out a limitation in the study, noting that it only considers Englishcentric datasets, and suggests extending CATER to other languages. While the comment identifies a potential issue with the figure and a limitation in the study, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to extend CATER to other languages is based on common knowledge about text generation APIs, but the comment could be strengthened with more detailed justification or references. Therefore, the claim is 3, as it provides a basis for the suggestion but requires more detailed evidence to fully support it.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, stating that it is hard to comprehend. It provides a clear and actionable suggestion by requesting more details about the two baselines presented in the figure. Additionally, the comment points out a limitation in the study, noting that it only considers Englishcentric datasets, and suggests that the authors could extend their work to other languages in the future. This feedback is valuable as it highlights a potential area for improvement and offers a constructive suggestion for enhancing the comprehensibility and scope of the study. However, the comment could be more helpful if it provided specific guidance on how to enhance the figure or suggested additional languages to consider. Overall, the comment is 4, as it provides clear and actionable feedback that can guide the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the literature review needs improvement, specifically highlighting the lack of clarity regarding the main contribution of the proposed method and its distinction from existing work, particularly in relation to GFlowNet for sequence generation. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. This feedback is clear and provides a direct action for the authors to take, which is to enhance the literature review by making it more explicit and comparative. The suggestion is concrete, as it specifies what needs to be done to improve the literature review. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the literature review section, indicating that it needs improvement to clarify the main contribution of the proposed method and its distinction from existing work, particularly regarding the utilization of GFlowNet for sequence generation. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it details what needs to be improved, such as providing a more explicit and comparative analysis of related work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review is unclear regarding the main contribution of the proposed method and its distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. While the claim highlights a potential issue with the literature review, it lacks specific examples or detailed reasoning to support the assertion. The authors may find it challenging to address the comment without additional guidance or examples. Therefore, the claim is considered 2, as it provides some basis for the critique but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the literature review. It points out that the current literature review lacks clarity regarding the main contribution of the proposed method and its distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The comment provides a clear and actionable suggestion to enhance the literature review by making it more explicit and comparative. This feedback is valuable as it guides the authors on how to improve the clarity and comprehensiveness of their literature review, which is essential for readers to understand the novelty and significance of their work. However, the comment could be more helpful if it offered specific examples or references to illustrate the improvements needed. Overall, the comment is 4, as it provides a clear direction for improvement but could be more detailed in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests eliminating section 3.2, implying that the content is not necessary for the readers. However, it does not provide any reasoning or explanation for why this section is redundant or how its elimination would impact the paper. The action is explicit but lacks concrete details on how to implement the suggestion, making it 3. The authors know they need to remove the section, but they are not provided with specific guidance on how to do so or what potential consequences this might have for the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the suggestion to eliminate this section, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests eliminating section 3.2, stating that readers are presumed to know about the GumbelSoftmax/Concrete distribution. However, the comment lacks any supporting evidence, reasoning, or references to justify why this section is unnecessary or redundant. Without further explanation or context, the authors may find it challenging to understand the basis of the suggestion, making the claim 1.", "helpfulness_rationale": "The review comment suggests eliminating section 3.2, implying that the content is redundant and that readers are already familiar with the GumbelSoftmax/Concrete distribution. While this feedback identifies a potential area for reduction, it lacks depth and does not provide any reasoning or justification for why this section is unnecessary. The comment does not offer alternative suggestions or guidance on how to improve the draft, leaving the authors with limited actionable feedback. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment provides two explicit actions for the authors to take. First, it suggests that the link between IP and the terms/equations should be explained more explicitly and prominently, which gives the authors a clear direction on how to enhance the clarity of their draft. Second, it instructs the authors to include labels for subfigures in Figs 3 and 4, rather than just stating them in the captions. This feedback is concrete and provides specific guidance on how to implement the suggested changes. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figs 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the link between IP and the terms/equations should be explained more explicitly and prominently, and by instructing the authors to include labels for subfigures in these figures. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the link between IP and the terms/equations could be explained more explicitly and prominently. It also requests that labels be included for subfigures in Figs 3 and 4, rather than just stating them in the captions. However, the comment does not provide any reasoning or evidence to support why this explanation is necessary or how it would improve the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment provides two specific suggestions for improving the clarity and presentation of the paper. First, it recommends explaining the link between IP and the terms/equations more explicitly and prominently, which could enhance the reader\"s understanding of the material. Second, it instructs the authors to include labels for subfigures in Figs 3 and 4, rather than just stating them in the captions, which would improve the accessibility and clarity of the figures. These suggestions are clear and actionable, offering the authors concrete steps to enhance the quality and readability of their draft. However, the comment could be more helpful if it provided additional context or examples to support the first suggestion. Overall, the feedback is 4, as it provides valuable guidance for improving the paper\"s clarity and presentation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests conducting ablation experiments on the modifications mentioned in Section 3.4 to further validate the model\"s performance. This is an explicit action that provides a clear direction for the authors to take, as it specifies what needs to be done to improve the draft. The comment is also concrete, as it provides a specific suggestion for experimentation that the authors can follow. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests conducting ablation experiments on the modifications mentioned in this section to further validate the model\"s performance. This provides clear guidance on what needs to be addressed to improve the draft. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests conducting ablation experiments to validate the model performance further, given that several modifications were mentioned in Section 3.4. This claim is 3 as it provides a logical reasoning for why ablation experiments would be beneficial. However, it lacks specific examples or references to support the necessity of these experiments, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests conducting ablation experiments on the modifications mentioned in Section 3.4 to further validate the model\"s performance. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the robustness of their results by testing the impact of individual modifications. By doing so, the authors can gain a deeper understanding of which modifications are crucial for the model\"s performance. However, the comment could be more helpful if it included examples of specific modifications or suggested how to design the ablation experiments. Overall, the comment is 4 as it offers a constructive suggestion for improving the draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It questions whether Proposition B.1 is merely an illustration of the classic partitioning principle of Kmeans and notes the absence of a \"proof.\" While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should fill in Appendix A and clarify the purpose and proof of Proposition B.1. However, the lack of concrete guidance on how to improve these sections makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Proposition B.1 in Appendix B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with these sections, namely the blank Appendix A and the unclear purpose of Proposition B.1, which is questioned in relation to the classic partitioning principle of Kmeans. The comment further points out the absence of a \"proof,\" providing detailed guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A is left blank and questions the purpose of Proposition B.1 in Appendix B, suggesting it might be an illustration of the classic partitioning principle of Kmeans. The reviewer also notes the absence of a \"proof.\" While the comment raises valid points about the clarity and completeness of the appendices, it lacks specific examples or references to support the claim that the \"proof\" is missing or that the purpose of Proposition B.1 is unclear. This makes the claim 3, as it provides a general critique but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It questions whether Proposition B.1 is merely an illustration of the classic partitioning principle of Kmeans, suggesting that this is a wellknown concept in machine learning. The comment also points out the absence of a \"proof,\" which is a critical component of the paper. By highlighting these issues, the comment provides clear and actionable feedback that can help the authors improve their draft by addressing these gaps. However, the comment could be more helpful if it offered suggestions on how to clarify the purpose of Proposition B.1 or provide a proof. Overall, the comment is 4 as it directs the authors to important areas needing clarification and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the approximations introduced in the paper, specifically mentioning lines 107110 where the assumption of attacks being in the feasible set is made. The reviewer suggests that this vulnerability needs to be expanded upon to reassure readers that it is not a real concern. While the comment identifies a specific area that needs attention, it does not provide explicit guidance on how to address this issue or what specific steps the authors should take to expand on the vulnerability. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detail but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (107110) where the assumption of attacks being in the feasible set is made. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights a potential vulnerability related to the approximations and suggests that this issue needs to be expanded upon to reassure readers. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approximations introduced in the paper leave \"loose ends\" and suggests that the vulnerability related to the assumption of attacks being in the feasible set needs to be expanded upon. However, the comment does not provide specific examples or detailed reasoning to support why this vulnerability is a concern or how it affects the results. The lack of explicit evidence or references makes it difficult for the authors to understand and address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the approximations introduced in the paper, specifically highlighting a vulnerability related to the assumption of attacks being in the feasible set. It acknowledges that approximations are necessary for deriving clean results but emphasizes the need to address this vulnerability to reassure readers. This feedback is 3 as it points out a specific area that needs further clarification or expansion. However, it lacks detailed guidance on how the authors might address this issue or what specific steps they should take to reassure the readers. While it provides some direction, it could be more helpful with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses an opinion that the contribution of the paper is limited and the proposed model is incremental in its approach. However, it does not provide any specific guidance or suggestions for the authors to address these concerns. There is no explicit or implicit action for the authors to take, such as revising the contribution section or explaining the novelty of the model. Without any actionable advice, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the contribution and incremental nature of the proposed model but does not specify which part of the paper this assessment is based on. It lacks grounding as it does not identify a specific section, figure, or aspect of the paper being addressed. Additionally, it is not specific about what aspects of the contribution or model are considered limited or incremental. Without clear references or detailed feedback, the authors cannot effectively address the concerns raised. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion about the limited contribution and incremental nature of the proposed model. However, it lacks specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses an opinion that the contribution of the paper appears limited and that the proposed model is incremental in its approach. However, it does not provide any specific details or examples to support this claim, nor does it offer suggestions for improvement. Without actionable feedback or guidance, the authors are left without a clear understanding of how to address the perceived limitations or enhance their work. As a result, the comment is 1, as it does not provide any value in terms of improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a discrepancy in the experimental part, specifically noting that the different methods in the two sets of benchmarks proposed in the article are quite different in different OPE methods. The reviewer requests that the authors provide comments on the differences between the two sets of evaluation methods. While the comment identifies an area for clarification, it does not explicitly instruct the authors to address this issue or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide additional comments but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4 and Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the differences between the two sets of benchmarks proposed in the article and requests comments on these differences. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper verifies different metrics for different OPE methods but notes a discrepancy in the evaluation methods used in Figure 4 and Figure 5. The reviewer requests comments on the differences between the two sets of evaluation methods. However, the comment lacks specific examples or detailed reasoning to support the claim of discrepancies, making it 3. The authors would need to infer the exact nature of the differences and how they impact the evaluation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the experimental part of the paper, noting that the different methods in the two sets of benchmarks proposed in the article are quite different in different OPE methods. It requests that the authors provide comments on the differences between the two sets of evaluation methods. This feedback is clear and actionable, as it directs the authors to clarify a potential inconsistency or discrepancy in their experimental setup. By addressing this point, the authors can enhance the clarity and comprehensiveness of their experimental results. However, the comment could be more helpful if it provided specific suggestions on how to address the differences or offered examples of how to present the results in a more consistent manner. Overall, the comment is 4, as it provides a clear direction for improvement but could be more detailed in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to discuss the iteration cost (computational budget) of the proposed method and suggests that they should also include the iteration cost of related methods, including baseline methods. This feedback is clear and provides a specific action for the authors to take, making it 5. The authors know exactly what needs to be added to their draft to address the reviewer\"s concern, and the comment provides concrete guidance on how to implement this action. Therefore, the comment is rated as 5.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss the iteration cost (computational budget) of the proposed method and also include the iteration cost of related methods, including baseline methods. However, it does not specify which part of the paper this discussion should be included in, such as a specific section or table. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for additional discussion on iteration costs, but without clear grounding, it is challenging for the authors to know where to make these changes. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should discuss the iteration cost (computational budget) of the proposed method and include the iteration cost of related methods, including baseline methods. This is a reasonable suggestion, as discussing computational costs can provide valuable insights into the efficiency of the proposed method. However, the comment does not provide specific examples or references to support why this discussion is necessary or how it would enhance the paper. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the importance of this discussion based on general knowledge of computational costs in research papers. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should discuss the iteration cost (computational budget) of the proposed method and include the iteration cost of related methods, including baseline methods. This feedback is clear and actionable, as it identifies a specific area for improvement that could enhance the comprehensiveness and clarity of the paper. By addressing this suggestion, the authors can provide a more detailed analysis of the computational efficiency of their method, which is valuable for readers interested in the practical applications and scalability of the approach. However, the comment could be more helpful if it provided additional context or examples of how this discussion could be integrated into the paper. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take in the experimental section. It suggests reporting the average over multiple runs to better compare the results, as the current results are very close together. Additionally, it recommends discussing the decision boundaries in the toy dataset in Section 3.1 and clarifies the information presented in Figure 9, specifically the middle and right parts. These suggestions are clear and concrete, providing the authors with specific steps to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Experimental section\" and references specific sections (\"Sec. 3.1\" and \"Sec. 3.3\") and a figure (\"Fig. 9\"), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed in each part, such as reporting averages over multiple runs, discussing decision boundaries in the toy dataset, and clarifying the information in Figure 9. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and requests for clarification or additional information. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback for improving the experimental section of the paper. It suggests reporting the average over multiple runs to better compare the results, which is a clear and concrete suggestion. Additionally, it recommends discussing the decision boundaries in the toy dataset, which could enhance the understanding of the results. The comment also requests clarification on the information presented in Figure 9, specifically the middle and right parts. These suggestions are detailed and provide the authors with clear guidance on how to enhance the clarity and comprehensiveness of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the inconsistency in the authors\" use of the center correlation metric. It points out that the authors initially state that this metric is not insightful for discriminating model defenses, but then use it in Figure 4 A&B. The reviewer is seeking clarification on why the metric was found useful in this context but not elsewhere. While the comment does not explicitly instruct the authors to revise their draft, it implies that the authors should provide a clearer explanation or justification for their use of the metric. The action is implicit and somewhat vague, as the authors need to infer that they should address the inconsistency and provide a rationale. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 8082 and figure 4 A&B, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the inconsistency in the authors\" use of the center correlation metric, asking for clarification on why it was found useful in figure 4 but not elsewhere. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the inconsistency in the authors\" use of the center correlation metric, noting that it is initially stated as not insightful for discriminating model defenses but is then used in Figure 4 A&B. The reviewer seeks clarification on why this metric was found useful in this context but not elsewhere. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim of inconsistency. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the authors\" use of the center correlation metric. It points out that the authors initially state that this metric is not insightful for discriminating model defenses, but then use it in Figure 4 A&B. The reviewer questions the reasoning behind this inconsistency, seeking clarification on why the metric was found useful in this context but not elsewhere. This feedback is clear and actionable, as it prompts the authors to provide a logical explanation for their use of the metric, which could help clarify the methodology and results. However, the comment could be more helpful if it offered suggestions on how to address this inconsistency or provided examples of how to improve the explanation. Overall, the comment is 4, as it directs the authors to a specific area needing clarification and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights two main issues with the experimental evaluation section. First, it notes that the \"picking\" step is not ablated, which is a claim made in the paper but not supported by experimental evidence. Second, it criticizes the comparison on CIFAR, suggesting that the paper only compares to one approach (DEN) and does not use the same setup as in the DEN paper, which could make the comparison unfair or incorrect. The comment provides specific suggestions for improvement, such as abating the \"picking\" step and ensuring that the comparison to DEN is fair by using the same setup. These suggestions are explicit and concrete, giving the authors clear guidance on how to address the issues. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experimental Evaluation 2.1. Ablations\" and \"Experiments on CIFAR,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the ablation study, specifically the lack of ablation for the \"picking\" step, and the comparison on CIFAR, which is not convincing due to the limited comparison to only one approach (DEN). The comment further specifies that the comparison would be more convincing if the authors used the same setup as in the DEN paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s experimental evaluation is flawed in two areas: the lack of ablation for the \"picking\" step and the limited comparison on CIFAR. The reviewer provides specific details about the issues, such as the need for ablation studies and the importance of comparing to multiple approaches in the continual learning literature. However, the comment lacks references or examples to support the claim that the comparison on CIFAR is not convincing or that the use of DEN is incorrect. While the feedback is clear, it could be strengthened with additional evidence or references to fully substantiate the claims. Therefore, the comment is 4, as it provides a solid foundation for the claims but requires further elaboration for complete verification.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the experimental evaluation section of the paper. It points out two main issues: the lack of ablation for the \"picking\" step, which is claimed as a distinct aspect of the approach, and the limited comparison on CIFAR, where the paper only compares to one approach (DEN) without using the same setup as in the DEN paper. The comment suggests that using the same setup would make the comparison more convincing and fair. This feedback is clear and provides the authors with concrete steps to improve the robustness and validity of their experimental evaluation. By addressing these issues, the authors can enhance the credibility and impact of their results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should use \"above/below diagonal\" instead of \"above/below 45 degree\" for easier interpretation. The comment provides a specific suggestion for improvement, which is explicit and concrete. The authors know exactly what change to make to enhance the clarity of their plot. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests a change in terminology from \"above/below 45 degree\" to \"above/below diagonal\" for easier interpretation. However, it does not specify which part of the paper this suggestion pertains to, such as a figure or table where this terminology is used. Without explicit references to specific sections or elements, the authors may find it challenging to identify where this change should be made. The comment is specific in suggesting a change in terminology but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that using \"above/below diagonal\" is easier to interpret than \"above/below 45 degree,\" providing a logical reasoning for the claim. The reviewer explains that \"above/below 45 degree\" might be misinterpreted as a local property, whereas \"above/below diagonal\" is more intuitive. This reasoning is clear and provides a basis for the suggestion, making the claim 4. However, the comment could be strengthened with specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the plot by recommending the use of \"above/below diagonal\" instead of \"above/below 45 degree.\" This feedback is actionable and offers a clear direction for enhancing the interpretability of the plot, which is a valuable contribution to the authors. However, the comment could be more helpful if it explained why the suggested change is beneficial or provided additional context about how it might impact the reader\"s understanding. Overall, the comment is 4 as it provides a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the lack of clarity regarding the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It specifically questions whether the model is a prototype approximation to nonlinear RNN models that exhibit emergent behavior. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their work. The feedback lacks actionable details, leaving the authors uncertain about what steps to take to clarify the scientific contribution of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of unclear scientific insight and the need for a clearer explanation of how the model provides further understanding of nonlinear RNN models. The comment provides a detailed critique of the work, making it clear what needs to be addressed. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It questions whether the model is a prototype approximation to nonlinear RNN models that exhibit emergent behavior, suggesting that the work may not offer a new explanation for how these models attain solutions through optimization. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. As a result, the claim is considered 2, as it lacks sufficient evidence or detailed justification to be 5.", "helpfulness_rationale": "The review comment raises a critical point about the lack of clarity regarding the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It specifically questions whether the model is a prototype approximation to nonlinear RNN models that exhibit emergent behavior, suggesting that the work may not offer a new explanation for how these models attain solutions through optimization. This feedback is 3 as it identifies a potential weakness in the paper and prompts the authors to clarify their contribution. However, it could be more helpful if it provided specific suggestions or examples on how to address this issue, such as proposing alternative explanations or experiments to demonstrate the model\"s unique value. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit and concrete actions for the authors to take. It suggests that the text in legends and axis labels should be larger, and it specifically mentions that \"Proposition (1)\" should be corrected to \"Proposition 1\" to avoid confusion with Equation 1. Additionally, it recommends increasing the font size of captions and legends in Figures 2 and 3 to match the text size. These instructions are clear and direct, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"at the beginning of page 6\" and \"Fig. 2 and 3,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issues, including the need for larger text in legends and axis labels, and the correction of \"Proposition (1)\" to \"Proposition 1\" to avoid confusion with Equation 1. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements and suggestions for improvement, such as recommending larger font sizes for text in legends and axis labels, and correcting the notation \"Proposition (1)\" to avoid confusion with Equation 1. These are descriptive and do not contain subjective opinions, judgments, or claims that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the formatting and clarity of the paper. It suggests that the text in legends and axis labels should be larger, which would improve readability. Additionally, it points out a potential source of confusion between \"Proposition (1)\" and Equation 1, recommending a correction to avoid this issue. The comment also advises increasing the font size of captions and legends in Figures 2 and 3 to match the text size. These suggestions are clear and concrete, offering the authors direct guidance on how to enhance the presentation and clarity of their work. However, the comment could be more helpful if it provided additional context or examples of how these changes would impact the overall readability or understanding of the paper. Overall, the feedback is 4 as it provides actionable steps for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests a specific comparison for the counterfactual experiments, recommending a comparison against Journey TRAK 1 at a particular step of the sampling trajectory. It also references a specific figure, 1, Figure 2, which shows a larger effect of removing highscoring images according to Journey TRAK compared to CLIP cosine similarity. This feedback provides a clear and explicit action for the authors to take, as it specifies the exact comparison they should make and references a specific figure for guidance. The authors know exactly what needs to be done to address this feedback, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"counterfactual experiments\" and references a specific figure, 1, Figure 2, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular comparison against Journey TRAK and references a specific figure to support the suggestion. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a comparison between the counterfactual experiments and Journey TRAK, specifically referencing Figure 2 from 1. This provides a clear basis for the claim, as it references a specific figure and study that supports the suggestion. However, the comment could be strengthened by providing more detailed reasoning or examples of how this comparison would enhance the paper. Overall, the claim is 4, as it is supported by a reference to external work, but it could benefit from additional explanation or examples to fully substantiate the suggestion. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the counterfactual experiments by recommending a comparison against Journey TRAK at a particular step of the sampling trajectory. It references a specific figure from 1 that shows a larger effect of removing highscoring images according to Journey TRAK compared to CLIP cosine similarity. This feedback is clear and constructive, offering a concrete way for the authors to enhance their analysis and potentially improve the validity of their results. By suggesting a direct comparison with a specific method and referencing a relevant figure, the comment empowers the authors to make a meaningful addition to their work. Therefore, it is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific observation from the experimental results, noting that replacing normal convolutions with adaptive convolutions may not always be beneficial. It points out a particular instance where ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer), suggesting that the placement of adaptive convolutions is important. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific analysis or comments should be added to the paper. The action is implicit and somewhat vague, as the authors can infer that they need to analyze the placement of adaptive convolutions but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table3\" and \"ACNNv3\" and \"ACNNv2,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it details the observation that replacing normal convolutions with adaptive convolutions may not always be beneficial, particularly noting the performance difference between ACNNv3 and ACNNv2. The comment further specifies that there is no analysis or comments on the placement of adaptive convolutions, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that replacing normal convolutions with adaptive convolutions is not always beneficial, citing a specific example from Table3 where ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer). This claim is 3 as it provides a specific example to support the assertion. However, the comment lacks detailed analysis or references to further substantiate the claim, making it difficult for the authors to fully understand the implications or to address the issue effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific observation from the experimental results, noting that replacing normal convolutions with adaptive convolutions may not always be beneficial. It highlights a particular instance where ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer), suggesting that the placement of adaptive convolutions is important. However, the comment lacks depth and does not offer actionable suggestions on how the authors might analyze or address this aspect of the technique. While it identifies a potential area for improvement, the feedback is incomplete and does not provide detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a tradeoff in the proposed method, noting that while it reduces computation time by limiting the search space to ancestral graphs, it also results in less information compared to the output of a method with a richer search space (DAGs). The comment raises a question about how much information of a DAG is encoded in its corresponding ancestral graph, implying that the authors should consider this aspect in their analysis. However, the comment does not provide explicit guidance on how to address this issue or what specific steps the authors should take to improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should explore this tradeoff further and potentially discuss it in their paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and its comparison to 10, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by highlighting the tradeoff between computation time and the richness of the search space, noting that the output of ACI has less information compared to the output of 10. The comment raises a question about the information encoded in ancestral graphs compared to DAGs, which provides a clear direction for the authors to consider in their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the tradeoff between computation time and the richness of the search space in the proposed method. It suggests that the method reduces computation time by limiting the search space to ancestral graphs, but this comes at the cost of less information compared to the output of a method with a richer search space (DAGs). The comment questions how much information of a DAG is encoded in its corresponding ancestral graph, implying that this is a critical aspect to consider. However, the comment does not provide specific evidence, examples, or references to support the claim or the reasoning behind it. This makes the claim 3, as the authors would need to explore the issue further to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights a tradeoff in the proposed method, noting that while it significantly reduces computation time compared to a previous method, this is achieved by limiting the search space to ancestral graphs. This results in less information compared to the output of the previous method, which has a richer search space (DAGs). The comment raises a question about how much information of a DAG is encoded in its corresponding ancestral graph, which is a critical aspect to consider in the analysis. This feedback is 3 as it points out a potential limitation of the proposed method and encourages the authors to explore this tradeoff further. However, it could be more helpful if it provided specific suggestions on how to address this issue or what aspects to focus on in the analysis. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors include a brief discussion on the empirical motivation for using timevarying Q^t and S^t, as opposed to a fixed one, in the discussion section. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1^t and the average lengths of the predictive intervals. This feedback is explicit and provides concrete guidance on what the authors should include in their discussion, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the inclusion of a brief discussion on the empirical motivation for using timevarying Q^t and S^t, as opposed to a fixed one. The comment provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1^t and the average lengths of the predictive intervals. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the discussion section could benefit from an empirical motivation for using timevarying Q^t and S^t, as opposed to a fixed one. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1^t and the average lengths of the predictive intervals. This suggestion is based on logical reasoning and provides a clear direction for the authors to consider. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that the discussion section could be improved by including a brief discussion on the empirical motivation for using timevarying Q^t and S^t, as opposed to a fixed one. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1^t and the average lengths of the predictive intervals. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their discussion and providing insights into the empirical implications of their model. By addressing this suggestion, the authors can enhance the depth and relevance of their discussion, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises doubts about the definitions in Table 1, specifically questioning the differences between anchorbased regression and the regression in RepPoints. The reviewer provides a detailed explanation of the methods, including RetinaNet and ATSS, and suggests that the regression methods do not significantly influence the results. The comment concludes by asking the authors to clarify this issue, implying that without clarification, the motivations in the paper may not be solid. While the comment identifies a specific area of concern and suggests a need for clarification, it does not provide explicit instructions on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definitions and their differences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the confusion regarding the definitions of anchorbased regression and the regression in RepPoints, and it provides a comparison with RetinaNet and ATSS. The comment specifies the need for clarification on the differences between these methods, which is clear and actionable feedback for the authors. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the definitions in Table 1, specifically regarding the differences between anchorbased regression and the regression in RepPoints. The reviewer provides a detailed explanation of the methods, including RetinaNet and ATSS, and suggests that the regression methods do not significantly influence the results. This reasoning is based on common knowledge in the field and provides a logical argument for the claim. However, the comment could be strengthened by including specific references or examples to support the claim more thoroughly. Therefore, the comment is 4, as it provides a solid foundation for the claim but could benefit from additional evidence or references.", "helpfulness_rationale": "The review comment raises a specific concern about the definitions in Table 1, questioning the differences between anchorbased regression and the regression in RepPoints. The reviewer provides a detailed explanation of the methods, including RetinaNet and ATSS, and suggests that the regression methods may not significantly influence the results. This feedback is clear and actionable, as it prompts the authors to clarify the definitions and their implications. By addressing this issue, the authors can strengthen the motivations and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to present the information or provided additional context. Overall, the comment is 4, as it identifies a critical area for improvement and guides the authors toward enhancing their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the caption for Figure 7 is incorrect and should be corrected to \"Edge Dynamics\" from \"Node Dynamics.\" This provides a clear and direct action for the authors to take, ensuring that the caption accurately reflects the content of the figure. The feedback is specific and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the caption, indicating that it should be corrected to \"Edge Dynamics\" from \"Node Dynamics.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual statement regarding the incorrect caption for Figure 7. It does not express an opinion, judgment, or suggestion that requires verification. It is purely descriptive and does not contain any claims or subjective elements. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and direct, identifying a specific error in the caption of Figure 7. It provides a precise correction, instructing the authors to change \"Node Dynamics\" to \"Edge Dynamics.\" This feedback is actionable and straightforward, allowing the authors to make a simple correction that improves the accuracy and clarity of their work. However, the comment could be more helpful if it explained why the correction is necessary or how it impacts the understanding of the figure. Nonetheless, the feedback is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This provides a clear and direct action for the authors to take, ensuring they understand exactly what needs to be addressed in their draft. The comment is specific and concrete, offering a straightforward path for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section\" of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it points out the lack of standard deviation after multiple experiments and suggests that the author clarify which effects are due to random fluctuations and which are improvements brought by the SoRA method. This provides clear guidance on what needs to be addressed in the experimental section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the standard deviation after multiple experiments is not provided, which may lead to confusion about the improvements brought by the SoRA method. The reviewer suggests that the author clarify which effects are within the range of standard deviation fluctuations and which are improvements due to the SoRA method. This claim is 3 as it highlights a potential issue with the presentation of experimental results but lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to consider this feedback to clarify their results, making the comment 4.", "helpfulness_rationale": "The review comment identifies a specific issue in the experimental section of the paper, namely the lack of standard deviation after multiple experiments. It points out that the improvement brought by SoRA compared to the baseline is limited and may be due to random fluctuations. The comment provides a clear and actionable suggestion for the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This feedback is valuable as it directs the authors to a critical area of their paper that requires clarification, potentially enhancing the clarity and robustness of their results. Therefore, the comment is 4, as it offers specific guidance for improvement but could be further enhanced by providing examples or more detailed suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the organization and layout of the paper, including the font size of annotations in figures, the lack of explicit drawing of figures, and the incorrect placement of Table 2. It also mentions formatting issues on page 6. While the comment identifies specific problems, it does not provide explicit instructions or suggestions on how to address these issues. The authors can infer that they need to improve the organization and layout of the paper, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it points out areas for improvement but does not provide detailed steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific issues with the organization and layout of the paper, including the font size of annotations in Figure 1 and Figure 2, the lack of explicit drawing of these figures, the incorrect placement of Table 2, and formatting issues on page 6. This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific as it details what is wrong with each of these elements, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not well organized, citing specific issues such as the font size of annotations in figures, the lack of explicit drawing of figures, and the incorrect placement of Table 2. These are factual observations that can be verified by examining the paper. However, the comment lacks detailed reasoning or examples to fully substantiate the claim of poor organization. While the specific issues mentioned are verifiable, the overall claim could be strengthened with more comprehensive evidence or explanation. Therefore, the comment is 4, as it provides some support but could be more robust with additional details.", "helpfulness_rationale": "The review comment identifies several specific issues with the organization and layout of the paper, including the font size of annotations in figures, the lack of explicit drawing of figures, and the incorrect placement of Table 2. It also mentions formatting issues on page 6. By pointing out these specific problems, the comment provides the authors with clear and actionable feedback on how to improve the presentation and clarity of their paper. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of better practices. Overall, the feedback is 4 as it directs the authors to areas that need improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several issues that need to be addressed. First, it questions the meaning of \"upper faces\" of the convex hull, suggesting that the dual subdivision and projection \u03c0 need better explanation. Second, it points out that the variable \"p\" is not explicitly defined, which is problematic since it has been used extensively throughout the paper. The comment suggests moving the definition of \"p\" to make the paper more understandable. While the comment identifies specific areas that need clarification and improvement, it does not provide detailed guidance on how to address these issues. The actions are explicit but somewhat vague, as the authors know what needs to be clarified but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises several specific issues that need clarification or improvement. It questions the meaning of \"upper faces\" of the convex hull, suggesting that the dual subdivision and projection \u03c0 need better explanation. Additionally, it points out that the variable \"p\" is not explicitly defined, which is problematic since it has been used extensively throughout the paper. The comment suggests moving the definition of \"p\" to improve clarity. However, the comment does not specify which sections of the paper these issues are located in, making it weakly grounded. Despite this, the comment is specific in detailing what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims and questions about the paper. The first claim questions the meaning of \"upper faces\" of the convex hull, suggesting that the dual subdivision and projection \u03c0 need better explanation. This is 3 as it points out a potential lack of clarity in the paper, but it does not provide specific examples or references to support the claim. The second claim points out that the variable \"p\" is not explicitly defined, which is problematic since it has been used extensively throughout the paper. This is a logical observation that highlights a potential issue with the paper\"s clarity. However, the comment lacks specific examples or references to fully substantiate the claim. Overall, the comment is 3, as it provides a logical basis for the claims but lacks detailed evidence or references to fully support them.", "helpfulness_rationale": "The review comment identifies several areas that need clarification or improvement in the paper. It questions the meaning of \"upper faces\" of the convex hull, suggesting that the dual subdivision and projection \u03c0 need better explanation. Additionally, it points out that the variable \"p\" is not explicitly defined, which is problematic since it has been used extensively throughout the paper. The comment provides actionable feedback by suggesting that the definition of \"p\" should be moved to improve clarity. However, the comment could be more helpful if it offered specific suggestions on how to explain the concept of \"upper faces\" or provided examples of how the variable \"p\" is used. Overall, the comment is 3 as it highlights important areas for improvement but lacks depth and specificity in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should evaluate the performance gain of their proposed method by comparing it to baseline detection or parsing techniques separately. This implies an action for the authors to take, which is to conduct additional evaluations to better support their claims. However, the comment does not provide specific guidance on how to conduct these evaluations or which baseline techniques to use. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed method, specifically mentioning its two major components: the generative shape model and the word parsing model. It highlights the need for clearer evaluation of which component contributes to the performance gain. The suggestion to evaluate the approach separately from baseline detection or parsing techniques provides specific guidance on how to address the issue. However, the comment does not explicitly mention which part of the paper discusses these components, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in its suggestion for improvement, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that it is unclear which component of the proposed method contributes to the performance gain. The reviewer suggests evaluating the approach separately from baseline detection or parsing techniques to better support the claim. However, the comment does not provide specific examples or references to support the claim that the current evaluation is insufficient. The suggestion for additional evaluation is logical, but without detailed justification or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation of the proposed method, noting that it is unclear which component contributes to the performance gain. It suggests that evaluating the approach separately from baseline detection or parsing techniques would provide better support for the claim. This feedback is clear and actionable, as it directs the authors to conduct additional evaluations to clarify the contribution of each component. However, the comment could be more helpful if it provided specific examples of baseline techniques or detailed guidance on how to conduct these evaluations. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of a series of questions regarding the experimental setup and the design choices in Figure 1. It asks for the main rationales behind having a separate timbre encoder module and why SADTW takes outputs from the content encoder instead of the timbre encoder. While the questions are clear and imply that the authors should provide explanations for these design choices, they do not explicitly instruct the authors to make any changes or additions to their draft. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for the main rationales behind two specific design choices: (a) having a separate timbre encoder module and (b) why SADTW takes outputs from the content encoder instead of the timbre encoder. This provides clear guidance on what needs to be addressed in the figure, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of questions regarding the experimental setup and design choices in Figure 1. It does not contain any claims, opinions, or suggestions that require verification. The questions are factual and seek clarification, fitting the \"No\" label.", "helpfulness_rationale": "The review comment consists of a series of questions regarding the experimental setup and design choices in Figure 1. It asks for the main rationales behind having a separate timbre encoder module and why SADTW takes outputs from the content encoder instead of the timbre encoder. While these questions are clear and indicate areas where the authors might need to provide more explanation or justification, they do not offer specific suggestions or guidance on how to address these issues. The feedback is 3 as it prompts the authors to clarify their experimental design, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that Table 4 is incomplete and should include results for all four datasets. This provides a clear and direct action for the authors to take, ensuring that the table is comprehensive. The comment is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the results for all four datasets. This provides clear guidance on what needs to be added to the table. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Table 4 is incomplete\" and suggests that it should include results for all four datasets. However, the comment does not provide any reasoning or evidence to support why the table is incomplete or why the results for all four datasets are necessary. Without additional context or justification, the claim remains 1, as the authors may not understand the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 4, noting that it is incomplete and should include results for all four datasets. This feedback is clear and actionable, providing the authors with a direct suggestion for improvement. By addressing this gap, the authors can enhance the comprehensiveness and usefulness of their results. However, the comment could be more helpful if it explained why including all datasets is important or how it would impact the overall analysis. Despite this, the feedback is 4 as it guides the authors toward a specific improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point mentions that the writing/presentation is \"a bit jumbled at times,\" but it does not provide any specific guidance or suggestions on how to improve this aspect. There is no explicit or implicit action for the authors to take, such as revising certain sections or clarifying specific points. Without actionable advice or examples, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that the writing/presentation is \"a bit jumbled at times,\" but it does not specify which parts of the paper are affected or provide any details on what aspects are unclear. This makes it difficult for the authors to identify the exact sections that need improvement. Without specific examples or references to particular sections, tables, or figures, the comment lacks grounding and specificity. Therefore, it aligns with a score of 1.", "verifiability_rationale": "The review point claims that the writing/presentation is \"a bit jumbled at times,\" but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed feedback or references to particular sections of the paper, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment acknowledges a perceived issue with the writing or presentation of the paper, noting that it can be \"a bit jumbled at times.\" However, it does not provide any specific examples, details, or suggestions on how to improve the clarity or organization of the content. Without actionable feedback or guidance, the authors are left without a clear understanding of what changes are needed to address the issue. This lack of specificity and actionable advice makes the comment 2, as it does not effectively assist the authors in improving their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the authors have made an incorrect statement regarding the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It specifies that these heads are active at the S2 token but do not primarily attend to it, as per Section 3 of Wang et al., 2023. This feedback provides clear and explicit guidance on what needs to be corrected in the draft, ensuring that the authors know exactly what action to take to improve the accuracy of their statement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific statement in the paper (\"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token\") and references Section 3 of Wang et al., 2023, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error in the statement, indicating that the heads are active at the S2 token but do not primarily attend to it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement about the Induction, Duplicate Token, and Previous Token heads primarily attending to the S2 token is incorrect, as per Section 3 of Wang et al., 2023. The comment provides a specific reference to external work, which supports the claim by indicating that the heads are active at the S2 token but do not primarily attend to it. This level of detail provides a clear basis for the claim, making it 4. However, the comment could be strengthened by including a direct quote or more detailed explanation from Wang et al., 2023, to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific error in the authors\" statement regarding the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It corrects the authors\" claim by pointing out that these heads are active at the S2 token but do not primarily attend to it, as per Section 3 of Wang et al., 2023. This feedback is clear and actionable, providing the authors with a precise correction to make in their draft. By addressing this error, the authors can improve the accuracy and reliability of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the work as being incremental and lacking novelty, suggesting that the proposed pipeline is merely a collection of tricks to improve defense evaluation. However, it does not provide any explicit or implicit actions for the authors to take to address these concerns. There is no guidance on how to enhance the novelty or impressiveness of the pipeline, nor are there suggestions for specific improvements or changes. As a result, the comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the work as being incremental and lacking novelty, suggesting that the proposed pipeline is merely a collection of tricks to improve defense evaluation. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure, making it difficult for the authors to identify the exact area needing revision. Additionally, the comment lacks specificity regarding what aspects of the pipeline are considered \"tricks\" or how they could be improved. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of the work is incremental and that the proposed pipeline is not novel, but rather a collection of tricks to improve defense evaluation. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references to other works that have achieved similar results, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the work by stating that its contribution is incremental and that the proposed pipeline is not novel, but rather a collection of tricks to improve defense evaluation. However, it does not provide any specific examples or suggestions on how the authors could enhance the novelty or impressiveness of their work. Without actionable feedback or guidance, the comment lacks value in helping the authors improve their draft. Therefore, it is rated as 1."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides two distinct comments. The first part critiques the vagueness of a statement at line 15, suggesting that certain RNNs work well for specific natural language reasoning tasks, and references literature on natural language inference and a leaderboard. This feedback is explicit and provides a concrete suggestion for improvement by referencing specific examples. The second part critiques the use of a reinforcement learning/agent analogy, suggesting that it is out of place and that generalization capabilities are better illustrated later in the paper. While the first part is 5, the second part is 3 as it provides a clear critique but lacks detailed guidance on how to improve the analogy. Overall, the comment is 4 due to the explicit and concrete suggestions in the first part, but the second part adds some vagueness. Therefore, it aligns with a score of 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 15 and 1618, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear feedback on the vagueness of the statement at line 15 and suggests that the reinforcement learning/agent analogy is out of place, recommending that generalization capabilities be better illustrated by examples given later in the paper. The reference to specific lines and the detailed critique make this comment 5, aligning with a score of 5.", "verifiability_rationale": "The review point consists of two parts. The first part critiques the vagueness of a statement at line 15, suggesting that certain RNNs work well for specific natural language reasoning tasks. It references literature on natural language inference and a leaderboard, providing some support for the claim. However, the reference to the leaderboard is not fully elaborated, making the claim 3. The second part critiques the use of a reinforcement learning/agent analogy, suggesting it is out of place and that generalization capabilities are better illustrated later in the paper. This part lacks specific examples or references, making it 2. Overall, the comment is 3, as it provides some support but lacks detailed evidence or examples to fully substantiate the claims. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment provides two distinct points of feedback. The first part critiques the vagueness of a statement at line 15, suggesting that it lacks specificity regarding the performance of certain RNNs in natural language reasoning tasks. It references literature on natural language inference and a leaderboard, offering a concrete example to support the critique. This feedback is clear and actionable, as it directs the authors to provide more specific examples or references to substantiate their claims. The second part critiques the use of a reinforcement learning/agent analogy, suggesting it is out of place and that generalization capabilities are better illustrated by examples provided later in the paper. While this feedback identifies a potential issue, it lacks specific guidance on how to improve the analogy or what alternative approaches might be more effective. Overall, the comment is 4 as it provides clear and actionable feedback on the first point, but the second point could be more comprehensive. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the lack of significant difference between the proposed sensitivelayer selection and randomized selection in terms of StableDiffusion, and the absence of mathematical or theoretical justification for Algorithm.1. While the comment identifies these areas for improvement, it does not provide explicit instructions or suggestions on how the authors should address these issues. The authors are left to infer that they need to discuss the observation and provide a theoretical justification, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it points out areas for improvement but does not offer detailed steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.5\" and \"the third figure,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that the proposed sensitivelayer selection does not make a significant difference in terms of StableDiffusion and that there is a lack of mathematical or theoretical justification for Algorithm.1. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed sensitivelayer selection does not make a significant difference in terms of StableDiffusion, as shown in Fig. 5. It also points out the lack of mathematical or theoretical justification for Algorithm.1. While the comment highlights these issues, it does not provide specific examples, detailed reasoning, or references to support the claims. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some basis for the claims but lacks sufficient detail to fully substantiate them.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper. First, it points out that the proposed sensitivelayer selection does not make a significant difference in terms of StableDiffusion, as shown in Fig. 5. This observation highlights a potential weakness in the experimental results. Second, the comment notes the lack of mathematical or theoretical justification for Algorithm.1, which is a critical aspect of the paper that needs further explanation. By addressing these points, the authors can improve the clarity and robustness of their work. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of how to enhance the justification for Algorithm.1. Overall, the feedback is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to change the representation of triples from sets to a tuplelike structure, specifically mentioning line 122. This provides a clear and direct action for the authors to take, ensuring they know exactly what modification is needed. The comment is explicit and concrete, offering a straightforward path for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the representation of triples as sets instead of a tuplelike structure. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a change in the representation of triples from sets to a tuplelike structure, providing a specific and actionable recommendation. However, it does not offer any reasoning or justification for why this change is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the representation of triples in the paper. By recommending that triples be represented as tuplelike structures instead of sets, the comment offers a clear and concrete way for the authors to enhance the clarity and precision of their work. This feedback is valuable as it directly addresses a potential area of improvement, allowing the authors to make a tangible change that could enhance the readability and effectiveness of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the paper regarding the representation of kernel functions by neural networks (NNs). It points out that while it is claimed that every kernel can be described by a feature space parameterized by a NN, this is not true for infinitedimensional RKHSs, such as the RBF kernel. The reviewer suggests that this limitation should be made more clear. While the comment identifies a specific issue that needs clarification, it does not provide explicit guidance on how to address this limitation or suggest specific changes to the text. The action is implicit and somewhat vague, as the authors know they need to clarify the limitation but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"104,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that every kernel can be described by a feature space parameterized by a neural network, providing a counterexample with RBF kernels and their infinitedimensional RKHS. The comment suggests that this limitation should be made more clear, offering a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"every kernel can be described by a feature space parameterized by a neural network\" is not true, particularly for RBF kernels. The reviewer provides a logical explanation by noting that the RKHS for RBF kernels is infinitedimensional, requiring an NN with infinite width to represent it. This reasoning is clear and provides a specific example to support the claim, making it 4. However, the comment could be strengthened by referencing specific literature or studies that demonstrate this limitation, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the claim that every kernel can be described by a feature space parameterized by a neural network. It provides a clear and logical explanation by referencing the infinitedimensional RKHS of RBF kernels, which cannot be represented by a neural network with finite width. This feedback is valuable as it highlights a critical limitation in the paper and suggests that this limitation should be made more clear. However, the comment could be more helpful if it offered suggestions on how to address this limitation or provide additional context to clarify the issue. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of GPI with noise added in Fig. 4 and suggests that the authors should consider other measures to demonstrate that GPI cannot achieve a good fit with behavioral data. It also implies that the authors should discuss the suitability of this approach for modeling pattern separation tasks, for which behavioral data is available. While the comment provides some direction, it lacks explicit instructions or concrete steps on how to address these points. The authors are left to infer that they need to conduct additional analyses or discussions, but the comment does not specify what these analyses should entail or how to structure the discussion. Therefore, the comment is 3, as it provides a general direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the performance of GPI with noise added and suggests additional measures to demonstrate its limitations. Furthermore, it provides a specific suggestion to discuss the suitability of the approach for modeling pattern separation tasks, which is a clear and actionable point. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of GPI with noise added in Fig. 4 and suggests that the authors should consider other measures to demonstrate that GPI cannot achieve a good fit with behavioral data. It also mentions the suitability of the approach for modeling pattern separation tasks and suggests discussing this further. However, the comment lacks specific examples or references to support the claim that GPI cannot achieve a good fit with behavioral data. The suggestion to discuss the suitability for pattern separation tasks is logical but not fully substantiated. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment raises a question about the performance of GPI with noise added in Fig. 4, suggesting that the authors should consider other measures to demonstrate that GPI cannot achieve a good fit with behavioral data. It also points out the potential suitability of the approach for modeling pattern separation tasks, for which behavioral data is available, and suggests that the authors should discuss this further. While the comment identifies a potential area for improvement and provides a direction for additional analysis, it lacks specific guidance on how to conduct these analyses or what aspects to focus on. The feedback is 3 as it prompts the authors to consider additional measures and discussions, but it could be more actionable with more detailed suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the performance gains are not very high, noting that the difference between the baseline and the best approach is less than 1% for most metrics. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion on how to improve the performance or what specific changes could be made to enhance the results. Without any guidance or direction, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance gains of the paper, specifically noting that the differences between the baseline and the best approach are less than 1% for most metrics. However, it does not specify which part of the paper this observation is based on, such as a particular section or table that presents these metrics. Without explicit references to specific sections or elements, the authors may find it challenging to identify the exact part of the paper being discussed. Additionally, the comment lacks specificity regarding what aspects of the performance gains are being questioned or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the performance gains are not very high, noting that the difference between the baseline and the best approach is less than 1% for most metrics. However, the comment does not provide any supporting evidence, such as specific metrics or data points, to substantiate this claim. Without detailed information or references, the authors may find it challenging to understand the basis of the claim or to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the performance gains are not very high, noting that the difference between the baseline and the best approach is less than 1% for most metrics. However, it does not provide any specific suggestions or guidance on how the authors might improve the performance or address this issue. Without actionable feedback or constructive advice, the comment lacks depth and does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the utility of specific information in the feedback network, such as the incorrect phrase/corrected phrase and the type of mistake. It asks for performance metrics without each of these types of information and with just natural language feedback. While the comment implies that the authors should provide these performance metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the utility of specific information in the feedback network, such as the incorrect phrase/corrected phrase and the type of mistake. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its inquiry about the performance metrics but lacks grounding, as it does not provide a clear reference to the part of the paper being discussed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point consists of questions seeking clarification on the utility of specific information in the feedback network. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the utility of specific information in the feedback network, such as the incorrect phrase/corrected phrase and the type of mistake. It prompts the authors to consider the impact of these elements on the performance of the feedback network. However, the comment lacks specific suggestions or guidance on how to address these questions or improve the draft. While it identifies areas for exploration, it does not provide actionable steps or detailed feedback, making it 3. The authors are given some direction but need to infer the exact steps to take, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance boost due to additional parameters, specifically comparing the performance of LinearTop and NLTop to Unary. It suggests that if a better Unary baseline is used, there might still be a performance boost. While the comment implies that the authors should consider using a better baseline for comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the performance boost due to additional parameters and suggests a comparison with a different and possibly better neural network, as referenced in 14. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the performance boost due to additional parameters, specifically comparing the performance of LinearTop and NLTop to Unary. It suggests that if a better Unary baseline is used, there might still be a performance boost. The comment references an external work (14) to support the claim that a different and possibly better neural network was used, which could impact the comparison. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim, making it 3. The authors would need to delve deeper into the referenced work and their own results to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the performance boost observed in the paper, specifically whether it is due to the addition of more parameters. It points out that LinearTop and NLTop add additional parameters, while Unary performs worse compared to a different and possibly better neural network reported in 14. This prompts the authors to consider whether using a better Unary baseline would still result in a performance boost. The comment is 3 as it identifies a potential issue with the comparison and suggests a direction for further investigation. However, it lacks specific guidance on how to address this issue or what specific improvements could be made. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the learning rates used for the deep models, specifically CIFAR10 and CIFAR100, and questions whether the optimal learning rate for the baseline was within the tested interval. However, it does not provide explicit instructions or suggestions on how the authors should address this issue. The comment implies that the authors should report the final used learning rates, but it lacks concrete guidance on how to ensure that the optimal learning rate was within the tested interval. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the learning rates used for the deep models, specifically CIFAR10 and CIFAR100, and questions whether the optimal learning rate for the baseline was within the tested interval. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its request for information about the learning rates but lacks grounding, as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the learning rates used for the deep models, specifically CIFAR10 and CIFAR100, and questions whether the optimal learning rate for the baseline was within the tested interval. However, the comment does not provide specific examples or references to support the claim that the results could be spoiled if the optimal learning rate was outside the tested interval. This lack of detailed justification makes the claim 3, as the authors would need to infer the potential impact themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the learning rates used for the deep models, specifically CIFAR10 and CIFAR100, and questions whether the optimal learning rate for the baseline was within the tested interval. This is a valid point that could impact the validity of the results, as using an optimal learning rate outside the tested interval could indeed affect the outcomes. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or ensure that the optimal learning rate is within the tested interval. While it identifies a potential weakness, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. The reviewer suggests that additional experiments or a more indepth analysis are needed to better justify the claims made in the paper. While the comment implies that the authors should conduct more experiments or analysis, it does not provide specific guidance on how to achieve this or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer the need for more experiments but may not know exactly how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results, noting that the proposed approaches only outperform the baselines in one setup and that there is no consistent trend in the results. The comment further specifies that additional experiments or a more indepth analysis are necessary to justify the claims. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods, as the proposed approaches only outperform the baselines in one setup out of three. The reviewer also notes the lack of a consistent trend in the results, suggesting that additional experiments or a more indepth analysis are needed. This claim is 3 as it provides a logical reasoning for the need for more comprehensive results. However, it lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. This feedback is crucial as it highlights a potential weakness in the paper\"s claims about the effectiveness of the proposed methods. The comment suggests that additional experiments or a more indepth analysis are necessary to better justify the claims made in the paper. This is a clear and actionable suggestion that could help the authors strengthen their argument and improve the robustness of their findings. However, the comment could be more helpful if it provided specific guidance on what additional experiments or analyses might be necessary. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with Figure 4, noting that the lines for \"No adapt\" and \"Finetune\" are covered by other lines and lacks additional explanation. This feedback is explicit, as it directly identifies the problem and suggests that the authors should provide further explanation for these lines. However, it does not specify how the authors should address this issue, such as by adding labels or annotations to clarify the figure. While the action is clear, the lack of detailed guidance on execution makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, noting that the lines for \"No adapt\" and \"Finetune\" are covered by other lines and lacks additional explanation. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some figures are not selfexplanatory, specifically mentioning Figure 4 as an example. It provides a clear and specific critique by pointing out that the lines for \"No adapt\" and \"Finetune\" are covered by other lines, which could make the figure difficult to understand without additional explanation. This feedback is wellsupported by a specific example, making it 4. However, the comment could be strengthened by suggesting ways to improve the figure\"s clarity, such as adding labels or annotations. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the figures in the paper, noting that some are not selfexplanatory. It provides a concrete example by mentioning Figure 4, where the lines for \"No adapt\" and \"Finetune\" are covered by other lines, making it difficult to understand without additional explanation. This feedback is actionable as it directs the authors to clarify their figures, which is crucial for the reader\"s comprehension. However, the comment could be more helpful if it suggested specific ways to improve the figure\"s clarity, such as adding labels or annotations. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the importance of the sampling performed to obtain different initializations x_0 for convergence to the optimum. It notes that this aspect is not experimentally evaluated thoroughly on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. The comment implies that the authors should conduct more comprehensive experiments to evaluate the impact of sampling on convergence. However, it does not provide specific guidance on how to conduct these experiments or what metrics to use, leaving the authors to infer the necessary actions. The action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab. 1 in supplementary,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the importance of the sampling performed to obtain different initializations x_0 for convergence to the optimum and notes that this aspect is not experimentally evaluated thoroughly on the proposed benchmarks. The comment specifies the need for more comprehensive evaluation, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the sampling performed to obtain different initializations x_0 is important for convergence to the optimum, but it is not experimentally evaluated thoroughly on the proposed benchmarks. The comment provides a specific example from the supplementary material, where it is compared to sampling from a uniform distribution. This provides some evidence to support the claim, but it could be strengthened by including more detailed analysis or references to similar studies. Therefore, the comment is 4, as it offers a basis for the claim but could benefit from additional supporting details.", "helpfulness_rationale": "The review comment highlights an important aspect of the paper that has not been thoroughly evaluated: the sampling performed to obtain different initializations x_0 and its impact on convergence to the optimum. It points out that this aspect is not experimentally evaluated on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. This feedback is valuable as it identifies a potential gap in the evaluation of the paper and suggests that the authors should conduct more comprehensive experiments to assess the impact of sampling on convergence. However, the comment could be more helpful if it provided specific suggestions on how to design these experiments or what metrics to use. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the logic and methodology used in the paper, specifically regarding the comparison between the proposed method and references 9 and 16. It questions the order of comparisons, the focus on computational cost, and whether this aspect is a significant contribution or issue in practical scenarios. While the comment highlights areas of confusion and potential inconsistencies, it does not provide explicit instructions or suggestions for how the authors should address these issues. The authors are left to infer that they need to clarify the logic and methodology, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed steps for the authors to follow.", "grounding_specificity_rationale": "The comment raises questions about the logic and methodology used in the paper, specifically regarding the comparison between the proposed method and references 9 and 16. It questions the order of comparisons and the focus on computational cost, suggesting that this aspect is unclear and lacks further discussion. However, the comment does not specify which part of the paper these questions relate to, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors can infer that it relates to the methodology or results sections, the comment lacks full grounding. It is specific in detailing the issues with the comparisons and the focus on computational cost, but without explicit references to sections, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions about the logic and methodology used in the paper, specifically regarding the comparison between the proposed method and references 9 and 16. It questions the order of comparisons, the focus on computational cost, and whether this aspect is a significant contribution or issue in practical scenarios. However, the comment does not provide any supporting evidence, reasoning, or references to justify these questions. Without additional context or explanation, the authors may find it challenging to understand the basis of the reviewer\"s concerns. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several questions about the logic and methodology used in the paper, specifically regarding the comparison between the proposed method and references 9 and 16. It questions the order of comparisons, the focus on computational cost, and whether this aspect is a significant contribution or issue in practical scenarios. The comment highlights a potential confusion in the paper and suggests that the authors should clarify these points. However, it does not provide specific suggestions or guidance on how to address these issues, leaving the authors with a general understanding of what needs to be improved but without detailed steps to take. Therefore, the comment is 3, as it identifies areas for clarification but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the comparison of the PL condition used in the paper with the conditions proposed in a specific reference, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions,\" arXiv:1709.03014. However, it does not provide any explicit or implicit action for the authors to take. The question is phrased as a request for clarification, but it does not guide the authors on how to address the issue or what specific aspects of the comparison should be explored. As a result, the comment lacks actionable guidance, leaving the authors without a clear path for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises a question about the comparison of the PL condition used in the paper with the conditions proposed in a specific reference, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions,\" arXiv:1709.03014. However, it does not specify which part of the paper this comparison should be made in, nor does it provide guidance on how to address the question. The authors can infer that it relates to the methodology or results sections, but the lack of explicit grounding and specificity makes it difficult for them to pinpoint the exact area needing attention. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the comparison of the PL condition used in the paper with the conditions proposed in a specific reference, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions,\" arXiv:1709.03014. However, it does not provide any supporting evidence, reasoning, or examples to justify why this comparison is relevant or necessary. The comment lacks specific details or references that would help the authors understand the context or significance of the comparison. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the question effectively.", "helpfulness_rationale": "The review comment raises a question about the comparison of the PL condition used in the paper with the conditions proposed in a specific reference, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions,\" arXiv:1709.03014. While it identifies a potential area for comparison, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or what aspects of the comparison are relevant. The comment does not offer actionable feedback or insights that would help the authors improve their draft. Therefore, it is rated as 2, as it provides minimal value to the authors in terms of improving their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a lack of discussion regarding the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It explicitly suggests that the authors should provide this analysis for a fair comparison with the baseline. This feedback is clear and direct, providing a specific action for the authors to take. The comment is explicit and concrete, as it specifies exactly what needs to be addressed and how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of discussion regarding the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing, namely an analysis of the impact of these factors for a fair comparison with the baseline. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. The reviewer suggests that this analysis is necessary for a fair comparison with the baseline. However, the comment does not provide specific examples or detailed reasoning to support the claim that this analysis is crucial or how it would impact the comparison. The lack of detailed justification makes the claim 3, as the authors would need to infer the importance of this analysis themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It suggests that the authors should provide this analysis for a fair comparison with the baseline. This feedback is clear and actionable, as it highlights a critical area for improvement and provides a specific direction for the authors to enhance their draft. By addressing this gap, the authors can strengthen their paper and provide a more comprehensive comparison with existing work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the analysis of the correlation between dataset size and the Frobenius norm and singular values, noting that it is unclear if this trend holds across different model architectures and lacks theoretical evidence. However, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve their analysis. The comment implies that the authors should consider exploring this trend further and providing theoretical evidence, but it does not specify how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment critiques the analysis of the correlation between dataset size and the Frobenius norm and singular values, suggesting that it is underwhelming and lacks theoretical evidence. However, it does not specify which part of the paper this analysis is presented in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment provides some specificity by highlighting the lack of theoretical evidence, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming. It suggests that the trend may not hold across different model architectures and lacks theoretical evidence. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of concrete evidence or detailed justification makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the analysis of the correlation between dataset size and the Frobenius norm and singular values. It points out that the analysis is underwhelming and lacks clarity, particularly in terms of whether this trend holds across different model architectures. The comment also notes the absence of theoretical evidence to support this correlation. While the comment highlights a critical area for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues or enhance their analysis. The feedback is 3 as it directs the authors to a specific area needing attention, but it lacks actionable advice, making it incomplete. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential for information leakage in the AutoAugment policy, which is obtained through supervised training on ImageNet. It also questions the conclusion in L114 regarding the importance of matching the pretraining and target datasets in terms of being object or scenecentric for linear classification. The reviewer suggests that this could be a setback for selfsupervised learning (SSL) algorithms that aim to learn more generic representations. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the implications of their findings and potentially discuss them in the context of SSL algorithms. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.2\" and \"L114,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the potential for information leakage in the AutoAugment policy and the implications of the conclusion regarding the importance of matching pretraining and target datasets for linear classification. The comment raises a specific concern about the generality of representations learned by selfsupervised learning algorithms, providing a clear direction for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the potential for information leakage in the AutoAugment policy, which is obtained through supervised training on ImageNet. It also questions the conclusion in L114 regarding the importance of matching the pretraining and target datasets for linear classification. The comment suggests that this could be a setback for selfsupervised learning (SSL) algorithms that aim to learn more generic representations. However, the comment lacks specific evidence or references to support these claims, making it 3. The authors would need to delve deeper into the literature or their own experiments to fully understand and address these concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the potential for information leakage in the AutoAugment policy, which is obtained through supervised training on ImageNet. It also questions the conclusion in L114 regarding the importance of matching the pretraining and target datasets for linear classification, suggesting that this could be a setback for selfsupervised learning (SSL) algorithms that aim to learn more generic representations. The comment prompts the authors to consider the implications of their findings and whether combining two datasets could lead to better representations. While the comment identifies a potential issue and raises questions, it lacks specific guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback is 3 as it points out a critical area for consideration, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the empirical version of the objective (3) should be placed in the supplementary materials. This is an explicit action that provides a clear direction for the authors to follow. However, the comment does not specify why this change is necessary or how it might impact the main text, which could make it slightly less actionable. Despite this, the authors know exactly what action to take, making the comment 4.", "grounding_specificity_rationale": "The comment suggests moving the empirical version of the objective (3) to the supplementary materials. While it does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the empirical section where the objective is discussed. This provides weak grounding, as the authors can make an educated guess about the part of the paper being addressed. The comment is specific in suggesting a particular action, which is to move the empirical version of the objective to the supplementary materials. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests moving the empirical version of the objective to the supplementary materials. However, it does not provide any reasoning or justification for this suggestion, such as why this information is better suited for the supplementary materials or how it might impact the main text. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests moving the empirical version of the objective to the supplementary materials. While this feedback provides a clear and actionable suggestion for improving the organization and presentation of the paper, it lacks further explanation or justification for why this change might be beneficial. The authors are given a specific direction to enhance their draft, but without additional context or reasoning, the comment could be more helpful if it provided more depth or rationale for the suggestion. Therefore, the comment is rated as 3, as it offers a clear action but could be more comprehensive with additional context."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point critiques a specific line in the paper, pointing out that Corollar 10 only demonstrates that uncertainty sampling moves in descent directions of the expected 01 loss, but this does not necessarily mean it is not minimizing the expected convex surrogate. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this critique or improve their draft. Without actionable suggestions or a clear direction for revision, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 180182, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with Corollar 10, explaining that it only shows that uncertainty sampling moves in descent directions of the expected 01 loss, but this does not necessarily mean it is not minimizing the expected convex surrogate. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the claim made in Corollar 10, suggesting that it only demonstrates that uncertainty sampling moves in descent directions of the expected 01 loss, but this does not necessarily mean it is not minimizing the expected convex surrogate. The comment provides a logical reasoning by pointing out the limitation of the corollar, which is a clear and specific critique. However, it does not provide additional evidence or references to further substantiate the claim. Therefore, the comment is 4, as it provides a solid foundation for the critique but could benefit from more detailed support.", "helpfulness_rationale": "The review comment provides a specific critique of the paper by questioning the interpretation of Corollar 10. It points out that the corollar only shows that uncertainty sampling moves in descent directions of the expected 01 loss, which does not necessarily mean it is not minimizing the expected convex surrogate. This feedback is 3 as it prompts the authors to reconsider their interpretation and potentially clarify or expand on the implications of Corollar 10. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context for a clearer understanding. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the significance of the performance improvement shown in Figure 3, noting that the biggest improvement in the bank dataset was only ~0.02. It suggests that using tables to directly show key improvements could be more intuitive and detailed. While the comment implies that the authors should consider presenting their results in a more detailed and intuitive manner, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to enhance the presentation of their results but are not given specific guidance on how to achieve this. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance improvement of the proposed methods does not seem significant, particularly noting that the biggest improvement in the bank dataset was only ~0.02. Additionally, the comment suggests using tables to show key improvements, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance improvement of the proposed methods is not significant, citing a specific example from Figure 3 where the biggest improvement in the bank dataset is only ~0.02. The comment also suggests using tables to show key improvements, which could enhance the clarity and detail of the results. However, the claim about the lack of significance is based on a single figure and dataset, and the suggestion for using tables is a general recommendation without specific examples or references. While the comment provides some justification, it lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance improvement of the proposed methods, noting that the biggest improvement in the bank dataset is only ~0.02. It suggests that using tables to directly show key improvements could be more intuitive and detailed, providing a clear and actionable suggestion for enhancing the presentation of results. This feedback is valuable as it highlights a potential weakness in the paper and offers a concrete way for the authors to improve the clarity and effectiveness of their presentation. However, the comment could be more helpful if it provided additional context or examples of how to effectively use tables to present the results. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises several concerns about the experimental validation, including the limited consideration of shallow networks and the lack of description of the optimization strategy, such as the grid search strategy for hyperparameter selection. It also mentions a minor issue with the positioning of the work in relation to existing literature, specifically referencing layer redundancy in network pruning. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to expand their experimental validation to include deeper networks and provide more detailed descriptions of their optimization strategies. However, the comment lacks concrete guidance on how to implement these changes, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses several issues with the experimental validation, including the limited consideration of shallow networks and the lack of description of the optimization strategy. It also mentions a minor issue with the positioning of the work in relation to related works, specifically referencing layer redundancy in network pruning. The comment provides a specific example of related work, which helps to ground the feedback. However, it does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as expanding experimental validation and describing the optimization strategy. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experimental validation is not convincing due to the limited consideration of shallow networks and the lack of description of the optimization strategy, including the grid search strategy for hyperparameter selection. It also mentions a minor issue with the positioning of the work in relation to related works, specifically referencing layer redundancy in network pruning. The comment provides a specific reference to a related work, which supports the claim and adds credibility to the feedback. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claims. Overall, the claim is 4, as it is supported by a reference to external work, but it could benefit from more detailed justification. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the experimental validation and related work sections. It points out that the experimental validation is not convincing due to the limited consideration of shallow networks and the lack of description of the optimization strategy, including the grid search strategy for hyperparameter selection. Additionally, it notes that the positioning of the work in relation to related works is limited, specifically mentioning layer redundancy in network pruning as an example. The comment provides a specific reference to a related work, which can help the authors better understand the context and relevance of their work. However, the feedback could be more helpful if it offered suggestions on how to expand the experimental validation or improve the description of the optimization strategy. Overall, the comment is 4 as it highlights important areas for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the technical contribution is limited, stating that there is no significant technical contribution or extension based on a typical model for the crossdomain recommendation setting. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might enhance their technical contribution or what specific aspects need improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the technical contribution of the paper, stating that it is limited and lacks significant extension based on a typical model for the crossdomain recommendation setting. However, it does not specify which part of the paper this critique pertains to, such as a particular section or methodology. Without explicit references to specific sections or elements of the paper, the authors cannot confidently determine where to address the feedback. Additionally, the comment lacks specificity regarding what aspects of the technical contribution are limited or how they could be improved. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution is limited, stating that there is no significant technical contribution or extension based on a typical model for the crossdomain recommendation setting. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, stating that the technical contribution is limited and lacks significant extension based on a typical model for the crossdomain recommendation setting. This feedback is important as it highlights a critical area where the authors could improve their work. However, the comment does not provide specific suggestions or guidance on how the authors might enhance their technical contribution or what aspects of the model could be improved. Without actionable advice or examples, the authors are left with a general understanding of the issue but without a clear path forward for improvement. Therefore, the comment is 3, as it points out a key area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. This is an explicit action that provides a clear direction for the authors to enhance their draft. The suggestion is concrete, as it specifies what needs to be added to the table, giving the authors a direct path to implement the recommendation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. This provides specific guidance on what needs to be addressed, which is the addition of fullysupervised baselines in a particular table. However, it does not specify which part of the table or the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the experimental setup or results section, but the exact location is not explicitly mentioned. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. The claim is based on a logical reasoning that adding such baselines would provide valuable insights into the performance gap between full supervision and SSL. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the importance of this addition based on the context of the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. This is a clear and actionable suggestion that could significantly enhance the paper by providing a more comprehensive comparison of the models. By including these baselines, the authors can gain a deeper understanding of the performance differences between full supervision and SSL, which could lead to valuable insights and improvements in their work. The comment is specific and provides a concrete direction for the authors to improve their draft, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the novelty of the approach\"s components, specifically mentioning that the weak predictor used (MLP, Regression Tree, or Random Forest) has been used before for NAS performance prediction. It also notes that the sampling strategy is similar to epsilongreedy and identical to that in BRPNAS, and that the results of WeakNAS are almost the same as BRPNAS. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these issues or improve the novelty of their approach. Without actionable suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific components of the approach, such as the weak predictor (MLP, Regression Tree, or Random Forest) and the sampling strategy (epsilongreedy, similar to BRPNAS), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what is lacking in terms of novelty and provides references to previous works that have used similar components. This level of detail helps the authors understand what needs to be addressed in their draft. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that the specific components of the approach are not novel, citing the use of MLP, Regression Tree, or Random Forest as weak predictors, which have been used before for NAS performance prediction. It also notes that the sampling strategy is similar to epsilongreedy and identical to that in BRPNAS, and that the results of WeakNAS are almost the same as BRPNAS. The comment provides specific references to previous works 2, 3, 7 and 5, which supports the claim of lack of novelty. However, the comment could be strengthened by providing more detailed comparisons or examples to further substantiate the claim. Overall, the claim is 4 due to the provided references, but it could be more robust with additional evidence or analysis. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment critiques the novelty of the approach by pointing out that the components used, such as the weak predictor (MLP, Regression Tree, or Random Forest), have been used before for NAS performance prediction. It also notes that the sampling strategy is similar to epsilongreedy and identical to that in BRPNAS, and that the results of WeakNAS are almost the same as BRPNAS. This feedback highlights a significant issue with the originality of the approach, which is crucial for the paper\"s contribution. However, the comment could be more helpful if it provided suggestions on how the authors might enhance the novelty of their approach or differentiate it from existing work. Despite this, the comment still offers valuable insight into a critical area that needs attention, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises several questions and suggestions for clarification regarding the OT sample selection process and its relationship with the EP module during training. It explicitly asks about the frequency of the OT sample selection process, whether it runs iteratively, and how the loss optimization and OT solving are conducted. The comment also suggests adding more details and a flow chart to make the process clearer for readers. Additionally, it requests information on the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. These explicit questions and suggestions provide clear guidance on what the authors need to address to improve their draft. The feedback is concrete and actionable, as it specifies exactly what information is needed and how it can be presented. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2.4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the OT sample selection process, such as the frequency of its execution and the relationship with the EP module during training. Additionally, it suggests adding more details and a flow chart to clarify the process and requests information on runtime. This level of specificity provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several questions and suggestions for clarification regarding the OT sample selection process and its relationship with the EP module during training. It questions the frequency of the OT sample selection process and whether it runs iteratively, and it suggests adding more details and a flow chart to clarify the process. Additionally, it requests information on the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. While the comment identifies areas that need clarification, it does not provide specific evidence or references to support these claims. The lack of detailed reasoning or examples makes the claims 3, as the authors would need to infer the necessary steps to address these points. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several important questions and suggestions for clarification regarding the OT sample selection process and its relationship with the EP module during training. It questions the frequency of the OT sample selection process, whether it runs iteratively, and how the loss optimization and OT solving are conducted. The comment also suggests adding more details and a flow chart to make the process clearer for readers. Additionally, it requests information on the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. These questions and suggestions are clear and actionable, providing the authors with specific areas to address and improve their draft. By addressing these points, the authors can enhance the clarity and comprehensibility of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two concerns: the lack of experiments with continuous tasks despite a discussion on how KG handles this setting, and the absence of empirical performance comparisons between entropy methods for conditional optimization and ConBO. The comment explicitly asks for experiments with continuous tasks and for a comparison of the empirical performance of the derived entropy methods with ConBO. These are clear and direct actions for the authors to take, providing concrete guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 7 in the appendix,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the absence of experiments with continuous tasks and the lack of empirical performance comparisons between entropy methods and ConBO. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a claim about the absence of experiments with continuous tasks despite a discussion on how KG handles this setting. It also questions the inclusion of entropy methods for conditional optimization in the experiments and their comparison with ConBO. The comment provides a logical reasoning for the claim by pointing out the discrepancy between the discussion and the experiments. However, it lacks specific examples or references to support the claim fully, making it 3. The authors would need to provide additional context or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper. First, it notes that the authors discuss how KG handles continuous tasks but do not include experiments with these tasks, which is a significant gap. Second, it points out that entropy methods for conditional optimization are derived in the appendix but not included in the experiments, and it questions the comparison with ConBO. This feedback is clear and actionable, as it highlights areas where the authors can enhance the comprehensiveness and relevance of their work. By addressing these points, the authors can strengthen their paper and provide a more complete analysis. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the calculation of precision, recall, and F1score for a 4class classification of breast density and suggests providing AUC results for breast cancer detection. While the comment implies that the authors should clarify their calculation methods and consider reporting AUC results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed information about their calculations and consider reporting AUC results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the calculation of precision, recall, and F1score for a 4class classification of breast density and suggests providing AUC results for breast cancer detection. It does not specify which part of the paper these calculations or suggestions are related to, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its request for clarification and additional information but lacks grounding, as it does not reference specific sections or figures. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the calculation of precision, recall, and F1score for a 4class classification of breast density, and suggests providing AUC results for breast cancer detection. The comment is based on common practices in the field of breast cancer detection and classification, which typically involve reporting AUC with sensitivity and specificity at different operating points. This reasoning is logical and aligns with standard practices in the field, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the suggestion. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises important questions about the calculation of precision, recall, and F1score for a 4class classification of breast density, which is a specific and relevant aspect of the paper. It also suggests providing AUC results for breast cancer detection, which is a common practice in the field. This feedback is clear and actionable, as it directs the authors to clarify their methodology and consider a more informative way to present their results. However, the comment could be more helpful if it provided specific examples or references to support the suggestion for AUC results. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their results section."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the transformer modification and its impact on machine learning insights. It also questions the significance of the improvement brought by the selfcross attention in the ablation study. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the concerns about novelty, the impact of the modification, or the interpretation of the ablation study results. Without actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the novelty of the transformer modification and the limited improvement brought by the selfcross attention in the ablation study. The comment provides a clear critique of the significance of the proposed modification and suggests that the main improvements come from using a na\u00efve transformer rather than the proposed modification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the transformer modification is no longer novel and does not bring significant insights in machine learning. It also questions the significance of the improvement brought by the selfcross attention in the ablation study, suggesting that the main improvements come from using a na\u00efve transformer. The comment provides some reasoning by mentioning the limited improvement (<1%) and the lack of novelty in the transformer modification. However, the claim could be strengthened with more detailed analysis or references to specific studies that have achieved similar results without the proposed modification. Overall, the comment is 3 as it provides a logical basis for the claim but lacks comprehensive evidence or references to fully substantiate it.", "helpfulness_rationale": "The review comment provides a critical evaluation of the paper, questioning the novelty of the transformer modification and its impact on machine learning insights. It points out that the selfcross attention brings limited improvement (<1%) in the ablation study, suggesting that the main improvements may come from using a na\u00efve transformer rather than the proposed modification. This feedback is 3 as it highlights a potential weakness in the paper\"s claims of innovation and suggests that the authors should reconsider the significance of their contributions. However, the comment could be more helpful if it offered specific suggestions on how to address these concerns or provided examples of how to improve the novelty and impact of the work. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This provides a clear and concrete action for the authors to take, as it specifies the additional tasks they should consider for their experiments. The comment is explicit and provides specific examples of tasks to include, making it 5.", "grounding_specificity_rationale": "The comment addresses the limitation of the experiments conducted in the paper, specifically mentioning that the evaluation is only on sentence similarity tasks and open domain QA tasks. It suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the experimental section. The suggestion to include additional tasks is specific, providing clear guidance on what the authors should consider. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiments are limited because they only include sentence similarity tasks and open domain QA tasks, suggesting that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. The comment provides a logical reasoning by pointing out the omission of other relevant tasks in the NLP field, which supports the claim. However, it lacks specific examples or references to these tasks, which would strengthen the argument. Therefore, the claim is 4, as it provides a clear direction for improvement but could be further supported with additional details or references.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments conducted in the paper, noting that they are limited to sentence similarity tasks and open domain QA tasks. It suggests that the authors should expand their experiments to include other types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, providing the authors with a specific direction for improving the scope and comprehensiveness of their experiments. By suggesting additional tasks, the comment empowers the authors to enhance the depth and relevance of their study, making it 5 for improving the draft. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the prompt should be included in the appendix or supplement, implying that it is currently missing. However, it does not provide explicit instructions on how to include it or where exactly it should be placed. The comment is 3 because it identifies a potential issue and suggests a possible solution, but it lacks concrete details on how to implement the action. The authors can infer that they need to add the prompt to the appendix or supplement, but they may not know the exact format or placement. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests that the prompt should be included in the appendix or supplement, implying that it is currently missing. However, it does not specify which part of the paper the prompt is missing from, making it weakly grounded. The comment is specific in its suggestion to include the prompt in the appendix or supplement, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location of the prompt. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the prompt should be included in the appendix or supplement, implying that it is currently missing. However, the comment does not provide any reasoning or evidence to support why the prompt is important or how its inclusion would enhance the paper. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the prompt should be included in the appendix or supplement, implying that it is currently missing. This is a clear and actionable piece of feedback that can help the authors improve their draft by ensuring that all necessary information is accessible to readers. However, the comment could be more helpful if it provided additional context or explanation about why the prompt is important or how its inclusion would enhance the paper. Additionally, the minor comments about the abstract and Figure 2 are vague and do not offer specific guidance for improvement. Overall, the comment is 4 as it identifies a clear area for improvement, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the introduction, where it claims that \"these shape constraints do not require tuning a free parameter.\" However, the reviewer argues that the choice between convex or concave constraints, and increasing or decreasing constraints, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback implies that the authors should clarify or address this point in their introduction, but it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the introduction but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction\" where the claim is made, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the claim that \"these shape constraints do not require tuning a free parameter,\" by pointing out that the choice between convex or concave constraints and increasing or decreasing constraints can be seen as a hyperparameter that needs to be chosen or tuned. This provides clear guidance on what needs to be addressed in the introduction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction is misleading because it states that \"these shape constraints do not require tuning a free parameter,\" while the choice between convex or concave constraints and increasing or decreasing constraints can be seen as a hyperparameter that needs to be chosen or tuned. The reviewer provides a logical reasoning by pointing out the distinction between the absence of a free parameter and the need to choose between different types of constraints. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened with specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the introduction, where it claims that \"these shape constraints do not require tuning a free parameter.\" However, the reviewer points out that the choice between convex or concave constraints and increasing or decreasing constraints can be seen as a hyperparameter that needs to be chosen or tuned. This feedback is 3 as it highlights a potential inconsistency in the introduction and suggests that the authors should clarify this point. However, it does not provide specific guidance on how to address the issue or improve the clarity of the introduction. To be more helpful, the comment could include suggestions for rephrasing or additional details to clarify the point. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the convergence proof as trivial, suggesting that it lacks substantial novelty and rigor. It implies that the authors should address this issue by providing a more substantial and rigorous proof. However, the comment does not explicitly instruct the authors to revise the proof or provide specific guidance on how to enhance its novelty and rigor. The action is implicit and somewhat vague, as the authors can infer that they need to improve the proof but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Triviality of Convergence Proof,\" indicating that it addresses the theoretical proof for convergence. It also references \"Assumption 4.1\" and \"Modification 1 in Appendix C,\" providing clear references to specific parts of the paper. The comment is specific because it details the issue with the convergence proof, explaining that it appears trivial due to the i.i.d. nature of $X$ and the resulting covariance matrix for $Z$. It also suggests that previous theorems can be adapted with straightforward modifications, highlighting the lack of substantial novelty and rigor in the proof. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical proof for convergence appears trivial, suggesting that the paper\"s claim of noni.i.d. data is contradicted by Assumption 4.1, which indicates that $X$ is i.i.d. The reviewer argues that this leads to a clear covariance matrix for $Z$ and that previous theorems can be adapted with straightforward modifications, implying a lack of novelty and rigor in the convergence proof. The comment provides a logical reasoning based on the assumptions and modifications mentioned, making the claim 4. However, it could be strengthened by providing more detailed examples or references to support the assertion. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the convergence proof, suggesting that it appears trivial due to the i.i.d. nature of $X$ and the resulting covariance matrix for $Z$. It points out that Assumption 4.1 indicates $X$ is i.i.d., which contradicts the claim of noni.i.d. data, and that previous theorems can be adapted with straightforward modifications. This feedback is clear and actionable, as it highlights a potential weakness in the paper\"s theoretical foundation and suggests a way to address it by providing a more rigorous proof. However, the comment could be more helpful if it offered specific guidance on how to enhance the proof or suggested alternative approaches. Overall, the comment is 4, as it directs the authors to a critical area that requires improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a conflict between two statements in the paper regarding the performance of the multienv model compared to the singleenv model. It explicitly requests clarification to resolve this apparent contradiction. The action is direct and clear, as the authors are instructed to clarify the conflicting statements. This provides a concrete and explicit action for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the conflicting statements regarding the performance of the multienv model compared to the singleenv model. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue of conflicting statements and requests clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies a potential conflict between two statements in the paper regarding the performance of the multienv model. It points out that the model is described as having an inevitable performance loss and also as outperforming the singleenv model due to knowledge sharing. The comment requests clarification to resolve this apparent contradiction. However, it does not provide any additional reasoning or evidence to support the claim of conflict, leaving the authors to infer the issue themselves. Therefore, the comment is 3, as it highlights a potential issue but lacks detailed justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential conflict between two statements in the paper regarding the performance of the multienv model. It points out that the model is described as having an inevitable performance loss and also as outperforming the singleenv model due to knowledge sharing. This observation highlights a critical inconsistency that needs to be addressed to ensure the clarity and accuracy of the paper. By requesting clarification, the comment provides a clear and actionable suggestion for the authors to resolve this issue, which is essential for improving the draft. However, the comment could be more helpful if it offered specific guidance on how to reconcile the conflicting statements or suggested potential explanations. Overall, the comment is 4 as it directs the authors to a significant area of improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of motivation for the problem being addressed, specifically the need for fast label aggregation algorithms in a streaming setting. It suggests that the paper should better motivate the applications where such algorithms are necessary. However, the comment does not provide explicit guidance on how to achieve this motivation or what specific aspects should be included to address the issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a motivation section but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of motivation for the problem being studied, specifically the need for fast label aggregation algorithms in a streaming setting. It points out that the paper does not spend time motivating the applications where such algorithms are needed and that all the datasets used in the empirical analysis are static. This provides a clear indication of the issue, but it does not specify which part of the paper should be revised to address this concern. The authors can infer that the introduction or motivation section might need revision, but the comment lacks full grounding as it does not explicitly mention these sections. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks motivation for the problem it addresses, specifically the need for fast label aggregation algorithms in a streaming setting. It points out that the datasets used in the empirical analysis are static, which contradicts the objective of the paper. However, the comment does not provide specific examples or references to support the claim that the problem is not wellmotivated or that the use of static datasets is inappropriate. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that it lacks motivation for the problem being addressed, specifically the need for fast label aggregation algorithms in a streaming setting. It points out that the datasets used in the empirical analysis are static, which contradicts the objective of the paper. This feedback is valuable as it highlights a critical area for improvement, encouraging the authors to better motivate the problem and its relevance. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending examples of applications where such algorithms are needed or suggesting ways to incorporate streaming datasets into the analysis. Despite this, the comment is 4 as it directs the authors to a key area that needs attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the scope of the study is underspecified and suggests that the work focuses on injecting a CoTbased approach into smallscale Language Models. It implies that additional relevant CoT baselines for incontext learning of Large Language Models, such as text003 and ChatGPT, are missing in Tables 2 and 3. While the comment identifies the need for clarification and additional information, it does not explicitly instruct the authors to include these baselines or specify how to do so. The action is implicit and somewhat vague, as the authors can infer the need for additional information but may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the scope of the study, suggesting that the work focuses on injecting a CoTbased approach into smallscale Language Models and that additional relevant CoT baselines for incontext learning of Large Language Models are missing. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the scope of the study is underspecified and suggests that the work focuses on injecting a CoTbased approach into smallscale Language Models. It also implies that additional relevant CoT baselines for incontext learning of Large Language Models are missing in Tables 2 and 3. However, the comment does not provide specific examples or references to support these claims, making it 3. The authors would need to infer the missing information and potentially conduct additional research to fully understand the scope and the missing baselines. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the scope of the study, suggesting that it is underspecified and that the work focuses on injecting a CoTbased approach into smallscale Language Models. It also points out the absence of relevant CoT baselines for incontext learning of Large Language Models in Tables 2 and 3. This feedback is clear and actionable, as it directs the authors to clarify the scope of their study and to include additional relevant baselines. However, the comment could be more helpful if it provided specific examples of the missing baselines or suggested how to incorporate them effectively. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their work."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the connection between the difficulty of tensor decomposition in the symmetric versus nonsymmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on how the authors should address this question or what specific steps they should consider to improve their draft. As a result, the authors are left without a clear understanding of what actions to take, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the connection between the difficulty of tensor decomposition in the symmetric versus nonsymmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the connection between the difficulty of tensor decomposition in the symmetric versus nonsymmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim or question. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the connection between the difficulty of tensor decomposition in the symmetric versus nonsymmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. While it identifies a potential gap in the introduction, it does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. The comment lacks actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the model, noting that performance worsens with an increase in the maximum number of identities. It suggests that the capacity should be preset to a small number, such as 10, and questions whether the authors have considered scaling up without compromising performance. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to do so. The suggestion to preset the capacity to a small number is concrete, but the question about scaling up without compromising performance is more vague. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed instructions on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 (a),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of scalability and performance degradation with an increase in the maximum number of identities. The comment suggests that the capacity should be preset to a small number and questions whether the authors have considered scaling up without compromising performance. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance worsens with the growth of the maximum number of identities, as shown in Table 3. It suggests that the capacity should be preset to a small number, such as 10, to address this issue. However, the comment lacks specific examples or detailed reasoning to support the claim that presetting the capacity to a small number would improve scalability. Additionally, it does not provide references or common knowledge to substantiate the assertion that this approach would be effective. Therefore, the claim is 3, as it provides a basis for the suggestion but lacks comprehensive evidence or detailed justification.", "helpfulness_rationale": "The review comment raises a concern about the scalability of the model, specifically noting that performance worsens with an increase in the maximum number of identities. It suggests that the capacity should be preset to a small number, such as 10, and questions whether the authors have considered scaling up without compromising performance. This feedback is 3 as it identifies a potential issue with the model\"s scalability and provides a specific suggestion for improvement. However, it lacks detailed guidance on how to address the scalability issue or how to balance capacity with performance. To be more helpful, the comment could include additional suggestions or examples of how to scale up the model effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the claim that the work is one of the preliminary works discussing the application of LLP to NLP tasks, as it does not see any NLPspecific elements in the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what specific aspects of the work should be revised to better align with the claim. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the authors\" claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in questioning the NLPspecific elements in the approach, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the claim that the work is one of the preliminary works discussing the application of LLP to NLP tasks, as it does not see any NLPspecific elements in the approach. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of supporting evidence or detailed justification renders the claim 2, as it requires more information to be fully substantiated.", "helpfulness_rationale": "The review comment questions the claim that the work is one of the preliminary works discussing the application of LLP to NLP tasks, as it does not identify any NLPspecific elements in the approach. This feedback is 3 as it points out a potential inconsistency in the authors\" claim, prompting them to reconsider and clarify their work\"s focus. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their work. To be more helpful, the comment could include examples of what NLPspecific elements are missing or suggest ways to incorporate them. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of justification for the need to design a new curriculum learning method for text graphs, noting that the research gap and limitations of existing methods are not discussed. While the comment identifies an area for improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to discuss the limitations of existing methods and justify the need for a new approach, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of justification for designing a new curriculum learning method for text graphs and the absence of discussion on the limitations of existing methods. The comment provides a clear direction for the authors to address by discussing the research gap and why existing methods cannot be applied. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the need for a new curriculum learning method for text graphs is not justified and that the research gap is not discussed. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence leaves the claim 3, as the authors would need to infer the gaps in the justification and research gap themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that while several curriculum learning methods are discussed in Section 1, the need for a new curriculum learning method for text graphs is not justified. It points out that the research gap, such as why existing methods cannot be applied, is not discussed. This feedback is clear and actionable, as it prompts the authors to address the lack of justification and discuss the limitations of existing methods. However, the comment could be more helpful if it provided specific suggestions on how to justify the need for a new method or examples of existing methods that could be discussed. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that there are areas where the writing could be improved, specifically mentioning the definition 2.1 and the interpretation of \"relevant\" auxiliary model weights. However, it does not provide explicit guidance on how to improve the writing or clarify the definition. The comment implies that the authors should revisit the definition and provide more clarity, but it lacks concrete steps or suggestions on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that there are areas where the writing could be improved, specifically mentioning \"definition 2.1\" and the interpretation of \"relevant\" auxiliary model weights. This provides full grounding as it explicitly mentions a specific part of the paper, allowing the authors to accurately identify the section being addressed. The comment is also specific because it points out a particular issue with the definition, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the writing could be improved in certain places, specifically mentioning a difficulty in interpreting \"definition 2.1\" regarding \"relevant\" auxiliary model weights. However, the comment does not provide any specific reasoning, examples, or references to support why the definition is difficult to interpret or how it could be improved. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a specific area where the writing could be improved, namely in the definition of \"relevant\" auxiliary model weights in section 2.1. It points out that the current definition is difficult to interpret, providing a clear example of where the writing could be clarified. This feedback is actionable and specific, as it directs the authors to revisit and refine their definition to enhance clarity. However, the comment could be more helpful if it offered suggestions on how to improve the definition or provided additional context. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the quantitive evaluation results in Figure 3, which only reflect middle outputs rather than the final outputs. It suggests that this limits the ability to confirm ModelAngelo\"s superiority over competitors. The comment explicitly asks if it is possible to perform a quantitative comparison on the final outputs. This provides a clear and direct action for the authors to take, which is to conduct a quantitative comparison on the final outputs. The feedback is explicit and concrete, offering a specific step for the authors to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is that the quantitative evaluation results in Figure 3 only reflect middle outputs rather than the final outputs, and suggests that a quantitative comparison on the final outputs would be more convincing. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the quantitative evaluation results in Figure 3 only reflect middle outputs, rather than the final outputs, and that this limits the ability to confirm ModelAngelo\"s superiority over competitors. The comment suggests that a quantitative comparison on the final outputs would be more convincing. While the comment highlights a potential issue with the evaluation methodology, it does not provide specific examples or detailed reasoning to fully substantiate the claim. The suggestion for a quantitative comparison on the final outputs is logical but lacks detailed justification or references to support the need for this change. Therefore, the comment is 3, as it provides a basis for the claim but lacks comprehensive evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation results presented in the paper, noting that the quantitative evaluation in Figure 3 only reflects middle outputs rather than the final outputs. It suggests that this limits the ability to confirm ModelAngelo\"s superiority over competitors. The comment also questions whether it is possible to perform a quantitative comparison on the final outputs, providing a clear and actionable suggestion for improvement. This feedback is valuable as it highlights a critical aspect of the evaluation methodology and offers a concrete step for the authors to enhance the credibility of their results. However, the comment could be more helpful if it provided additional context or examples of how such a comparison could be conducted. Overall, the comment is 4, as it directs the authors to a specific area for improvement while offering a clear path forward."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the paper, including qualitative explanations, minimal descriptions of simulation or experiment procedures, and confusing figures. It suggests adding more details to the paper and/or supplementary information to clarify the work. Additionally, it recommends including error bars and/or pvalues for statistical inferences. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to implement these suggestions. The authors can infer that they need to add more details and statistical analysis, but the comment lacks concrete guidance on what specific details to include or how to present them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific issues with the explanations, simulation or experiment procedures, and figures, allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific details about what is missing, such as more detailed descriptions of procedures, the need for error bars and/or pvalues for statistical inferences, and clarification of figures like \"sample count\" in fig. 2. This level of specificity guides the authors on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the explanations in the paper are qualitative and lack detailed descriptions of simulation or experiment procedures. It also points out that some figures are confusing, such as the \"sample count\" in fig. 2. The reviewer suggests that adding more details to the paper and/or supplementary information would improve the clarity of the work. Additionally, the comment recommends including error bars and/or pvalues for statistical inferences. While the comment highlights specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claims. The suggestion to include error bars and pvalues is a common practice in scientific writing, but the comment could benefit from more explicit justification or references to support the need for these additions. Therefore, the comment is 3, as it provides a general direction for improvement but lacks detailed evidence or examples to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the need for more detailed explanations, clearer descriptions of simulation or experiment procedures, and the inclusion of error bars and/or pvalues for statistical inferences. It also points out specific issues with figures, such as the lack of clarity regarding \"sample count\" in fig. 2. By highlighting these weaknesses, the comment provides the authors with actionable feedback on how to enhance the clarity and rigor of their work. However, the comment could be more helpful if it offered specific suggestions on how to address these issues, such as recommending additional data or analysis to support the claims. Overall, the comment is 4 as it directs the authors to areas that require improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior work such as Dagger and searn. This implies that the authors should include specific settings or comparisons to enhance the paper\"s contribution and relevance to the community. However, the comment does not provide explicit guidance on how to implement this suggestion, such as which specific settings to include or how to present them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior work such as Dagger and searn. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its suggestion to include settings for comparison, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior work such as Dagger and searn. However, the comment does not provide specific examples or references to support why this would be beneficial or how it would enhance the paper. The suggestion lacks detailed reasoning or evidence, making it difficult for the authors to understand the rationale behind the recommendation. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior work such as Dagger and searn. This feedback is 3 as it identifies a potential area for enhancement and provides a specific suggestion for improvement. However, the comment lacks depth and does not offer detailed guidance on how to implement this suggestion or why it would be beneficial. The authors are given a general direction but not a clear path forward, making the feedback 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the generalizability of specific examples presented in the paper, specifically those related to biases in target statistics and prediction shift of gradient values. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the clarity of their examples. The comment implies that the authors should consider providing more context or analysis to establish the generalizability of these examples, but it does not specify how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the lack of clarity regarding the generalizability of specific examples presented in the paper. The comment highlights the need for more context or analysis to establish the generalizability of these examples. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents specific examples of biases in target statistics and prediction shift of gradient values, but it does not provide a clear explanation of why these examples are unclear or how they could be improved. The comment lacks specific details or references that would help the authors understand the issue or suggest how to address it. Without additional context or reasoning, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of examples presented in the paper, specifically those related to biases in target statistics and prediction shift of gradient values. It points out that while the paper provides examples, it does not establish the generalizability of these situations. This feedback is 3 as it highlights a potential weakness in the paper and prompts the authors to consider providing more context or analysis to address this issue. However, the comment could be more helpful if it offered specific suggestions or guidance on how to improve the clarity or generalizability of the examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should clarify whether their work on 3D Gaussians generation in Section 3.1 includes any novel efforts beyond following the previous work, \"Luciddreamer.\" While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to address the concern. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.1 for 3D Gaussians generation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the work in this section includes any novel efforts beyond following the previous work, \"Luciddreamer.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions whether the work on 3D Gaussians generation in Section 3.1 includes any novel efforts beyond following the previous work, \"Luciddreamer.\" However, it does not provide any specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the concern. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the originality of the work presented in Section 3.1, specifically regarding the generation of 3D Gaussians. It questions whether the work merely follows the previous work, \"Luciddreamer,\" without any additional novel efforts. This feedback prompts the authors to clarify their contribution and differentiate their work from existing research. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of potential novel contributions. Overall, the comment is 3 as it highlights an area for improvement but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a perceived drawback of MMD DRO, noting that it lacks a tractable exact equivalent reformulation compared to other methods like phidivergence or Wasserstein uncertainty sets. It critiques the upper bound provided in Theorem 3.1, suggesting it is crude and drops the nonnegative constraint on the distribution, necessitating further approximation. Additionally, it questions the assumption that the loss function belongs to the RKHS. While the comment identifies specific issues, it does not provide explicit guidance on how the authors might address these concerns or suggest potential improvements. The feedback is 3 as it points out areas for improvement but lacks concrete steps for the authors to take. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the upper bound provided in the theorem, such as the crude nature of the bound and the dropping of the nonnegative constraint on the distribution. Additionally, it critiques the assumption that the loss function belongs to the RKHS, providing a clear direction for the authors to address these concerns. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that MMD DRO lacks a tractable exact equivalent reformulation compared to other methods like phidivergence or Wasserstein uncertainty sets. It critiques the upper bound provided in Theorem 3.1, stating that it is crude and drops the nonnegative constraint on the distribution, necessitating further approximation. The comment also questions the assumption that the loss function belongs to the RKHS. While the reviewer provides some reasoning and references to specific issues, the claim could be strengthened by providing more detailed examples or references to support the critique. The lack of explicit evidence or detailed reasoning makes the claim 3, as the authors would need to delve deeper into the literature to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant drawback of MMD DRO, noting that it lacks a tractable exact equivalent reformulation compared to other methods like phidivergence or Wasserstein uncertainty sets. It critiques the upper bound provided in Theorem 3.1, pointing out that it is crude and drops the nonnegative constraint on the distribution, necessitating further approximation. Additionally, the comment questions the assumption that the loss function belongs to the RKHS, as already pointed out by the authors. This feedback is 4 as it highlights specific weaknesses in the paper and provides a clear direction for the authors to address these issues. However, it could be more helpful if it offered suggestions on how to improve the reformulation or approximation. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the Appendix H section should be reorganized because it is difficult to follow. However, it does not provide any specific guidance or details on how the authors should reorganize the section. The action is implicit, as the authors need to infer that they should make changes to the structure of the appendix, but it is vague because it lacks concrete instructions on what changes to make. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment explicitly mentions \"Appendix H,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by stating that the section is difficult to follow, providing clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the Appendix H section should be reorganized because it is difficult to follow. However, it does not provide any specific reasons or examples to support this claim, such as explaining what makes the section difficult to follow or suggesting alternative organizational structures. Without detailed justification or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment identifies a specific issue with the Appendix H section, noting that it is difficult to follow. This feedback is clear and actionable, as it directs the authors to reorganize the section to improve its clarity. However, the comment lacks further guidance or suggestions on how to achieve this reorganization, such as proposing alternative structures or suggesting specific changes to improve readability. While it provides a clear direction for improvement, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern that the paper is not written to be reproducible, despite providing pseudocode in the supplementary material. The reviewer suggests that more details are needed to reproduce the work, such as specifics about the RNN implementation. While the comment identifies the need for additional details, it does not provide explicit guidance on what specific details should be included or how to present them. The action is implicit and somewhat vague, as the authors can infer that they need to provide more technical details but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"pseudocode given in the supplementary material,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is that the paper lacks details necessary for reproduction, such as specifics about the RNN implementation. The comment provides examples of what is missing, like the number of units, and mentions \"many other technical details.\" This level of detail helps the authors understand what needs to be addressed to improve the reproducibility of their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not written to be reproducible, despite providing pseudocode in the supplementary material. The reviewer suggests that more details are needed, such as specifics about the RNN implementation, to facilitate reproduction. This claim is 3 as it provides a logical reasoning about the lack of details necessary for reproduction. However, the comment lacks specific examples or references to support the claim fully, making it 3. The authors would need to infer the exact details that are missing, which could be challenging without further guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that despite providing pseudocode in the supplementary material, the paper lacks the necessary details for reproduction. It highlights the need for more technical details, such as specifics about the RNN implementation, to facilitate reproducibility. This feedback is clear and actionable, as it directs the authors to focus on providing the missing details to enhance the reproducibility of their work. However, the comment could be more helpful if it provided specific examples of what details are missing or suggested ways to present them. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that Figure 1 would be strengthened by the inclusion of error bars and/or more random trials to reduce random fluctuations in the results. While the comment implies that these additions would improve the figure, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors can infer that they need to add error bars and more trials, but they are not provided with specific guidance on how to implement these suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the figure would be stronger with the inclusion of error bars and/or more random trials to reduce random fluctuations in the results. This provides clear guidance on what could be improved in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 1 would be strengthened by the inclusion of error bars and/or more random trials to reduce random fluctuations in the results. This claim is 3 as it provides a logical reasoning for why error bars and more trials would improve the figure. However, the comment lacks specific examples or references to support the claim that these additions would effectively reduce random fluctuations. Providing such examples or references would strengthen the justification, making the comment more verifiable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving Figure 1 by recommending the inclusion of error bars and/or more random trials to reduce random fluctuations in the results. This feedback is clear and actionable, as it offers a concrete way for the authors to enhance the figure and potentially improve the clarity and robustness of their findings. However, the comment could be more helpful if it explained why these additions are important or how they would impact the interpretation of the results. Despite this, the suggestion is valuable and provides a clear direction for improvement, making the comment 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests two explicit actions: providing a brief introduction to energy models in the related work section and clarifying which points in Figure 1 correspond to different learning rates and steps. The first action is clear and concrete, as it specifies what needs to be added to the related work section. The second action is also explicit and provides a specific request for clarification regarding Figure 1. Both actions are concrete and directly stated, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related work section\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for a brief introduction to energy models in the related work section and requests clarification on which points in Figure 1 correspond to different learning rates and steps. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two separate suggestions and observations. The first suggestion to include a brief introduction to energy models in the related work section is a factual statement and does not contain a claim. The second part of the comment, regarding Figure 1, is a request for clarification and does not express an opinion or claim. Therefore, the entire comment is factual and does not require verification, aligning with the label \"No.\"", "helpfulness_rationale": "The review comment provides two distinct suggestions for improvement. First, it recommends including a brief introduction to energy models in the related work section, which could help contextualize the paper\"s contributions. Second, it points out a lack of clarity in Figure 1, specifically regarding which points correspond to different learning rates and steps. This feedback is clear and actionable, as it identifies specific areas where the authors can enhance the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it provided additional context or examples to support the suggestions. Overall, the comment is 4, as it offers constructive feedback that can guide the authors in improving their work."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the first paragraph of the Introduction for being too general and not relevant to the paper\"s focus on detecting drift types and magnitude. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion to revise or remove the paragraph, nor is there guidance on how to improve the introduction to better align with the paper\"s focus. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first paragraph of the Introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the introduction, namely that it focuses too much on a general introduction of DNNs without mentioning drift, which is the core focus of the paper. The comment provides a clear critique of the relevance of the content, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the first paragraph of the Introduction is not relevant to the paper because it focuses on a general introduction of DNNs without mentioning drift, which is the core focus of the paper. The reviewer provides a logical reasoning by pointing out the mismatch between the content of the paragraph and the paper\"s focus. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the relevance of the general introduction to the paper\"s focus, which could be challenging without further guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of the paper, noting that the first paragraph focuses too much on a general introduction of DNNs without mentioning drift, which is the core focus of the paper. This feedback is clear and actionable, as it highlights a potential misalignment between the content of the introduction and the paper\"s main contributions. However, the comment could be more helpful if it suggested alternative ways to structure the introduction or provided guidance on how to better integrate the discussion of DNNs with the paper\"s focus on drift detection. Despite this, the comment provides valuable insight into improving the paper\"s introduction, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the author should make it easier to distinguish between the different curves in Figure 2. It provides specific and concrete suggestions, such as using styles (e.g., dashed lines) or adding color, to enhance the visual clarity of the figure. This feedback is explicit and provides clear guidance on how to improve the figure, making it 5. The authors know exactly what changes to make to enhance the readability of their figure.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for improving the figure, such as using styles (e.g., dashed lines) or adding color to distinguish between the different curves. This level of detail helps the authors understand exactly what needs to be addressed to enhance the figure\"s clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it is difficult to distinguish between the different curves in Figure 2 and recommends using styles (e.g., dashed lines) or adding color to improve clarity. This is a subjective opinion based on the reviewer\"s experience and does not require specific evidence or references to support the claim. The suggestion is logical and provides a clear path for improvement, but it lacks detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a reasonable suggestion but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that it is difficult to distinguish between the different curves. It provides actionable feedback by suggesting the use of styles, such as dashed lines, or adding color to enhance the visual clarity of the figure. This feedback is clear and constructive, offering the authors a direct way to improve the presentation of their data. However, the comment could be more helpful if it included examples of how different styles or colors could be effectively used. Overall, the comment is 4 as it provides a specific suggestion for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should \"tonedown the intro\" and not refer to the task as \"language learning,\" as it is more accurately described as \"feedback driven QA in the form of a dialog.\" This feedback provides a clear and direct action for the authors to take, ensuring they understand exactly what needs to be changed in their draft. The recommendation is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly addresses the introduction of the paper, allowing the authors to accurately identify the part being discussed. It is also specific because it clearly specifies the issue with the claims made in the introduction, pointing out the discrepancy between the task described and the evaluation method used. The comment suggests a change in the introduction to better align with the actual task, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claims made in the introduction are not supported by the tasks and models evaluated. It suggests that the task is more accurately described as \"feedback driven QA in the form of a dialog\" rather than \"language learning.\" However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to review their introduction and evaluation methods to understand the basis of the critique, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between the claims made in the introduction and the actual evaluation methods used in the paper. It points out that the task is described as \"language learning\" but is evaluated through question answering, which is more accurately described as \"feedback driven QA in the form of a dialog.\" This feedback is clear and actionable, as it suggests a specific change to the introduction to better align the description with the actual task. However, the comment could be more helpful if it provided additional context or examples to support the claim and guide the authors in making the necessary adjustments. Overall, the comment is 4, as it directs the authors to a significant improvement in the clarity and accuracy of their introduction."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the performance on REC and RES in Table 4 is behind more recent models, providing specific examples of models (GLaMM and UNINEXT) that have achieved better results. This feedback is clear and actionable, as it directs the authors to compare their results with those of more recent models and to consider how their performance can be improved. The inclusion of specific references (GLaMM and UNINEXT) and their respective results provides concrete guidance on what the authors need to do to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance on REC and RES, comparing it to more recent models like GLaMM and UNINEXT, and providing specific results from these models. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance on REC and RES in Table 4 is behind more recent models, providing specific examples of models (GLaMM and UNINEXT) that have achieved better results. The inclusion of references to these models and their respective results provides a clear basis for the claim, making it 4. However, the comment could be strengthened by including more detailed comparisons or explanations of why the current performance is considered behind. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by comparing the performance of the paper on REC and RES with more recent models, such as GLaMM and UNINEXT. It highlights that the current performance is behind these models, offering a clear direction for the authors to improve their results. By referencing specific models and their achievements, the comment gives the authors concrete examples to consider for enhancing their draft. This level of detail and specificity makes the comment 5, as it empowers the authors to make targeted improvements. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a change in the wording of a statement regarding evidence, proposing a more nuanced expression. However, it does not provide explicit guidance on how to make this change or what specific wording would be more appropriate. The action is implicit and somewhat vague, as the authors are left to infer the exact changes needed without detailed instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting a change in the wording from \"evidence\" to a more appropriate term, such as \"Fig.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the term \"evidence\" might be too strong and proposes an alternative phrase, \"Fig.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why \"evidence\" is too strong or why \"Fig.\" would be a better choice. Without additional context or explanation, the claim remains 1, as the authors are left without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests a change in the wording of a statement, specifically replacing \"evidence\" with a more appropriate term, such as \"Fig.\" This feedback is clear and actionable, as it provides a specific suggestion for improvement. However, it could be more helpful if it explained why the original term \"evidence\" might be misleading or if it offered additional context or examples to support the proposed change. Despite this, the comment is 4 as it directs the authors to a precise area for improvement, making it a 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that a fullpage explanation of the implementation of kernels with OpenAI\"s Triton instead of CUDA is unnecessary due to wellknown engineering improvements. This provides a clear and direct action for the authors to take, which is to omit the detailed explanation. The comment is explicit and concrete, as it specifies exactly what action the authors should take to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the implementation of kernels using OpenAI\"s Triton instead of CUDA, suggesting that a fullpage explanation is unnecessary due to wellknown engineering improvements. However, it does not specify which part of the paper this implementation is discussed in, making it weakly grounded. The comment is specific in its suggestion to omit the detailed explanation, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that a fullpage explanation of the implementation of kernels with OpenAI\"s Triton instead of CUDA is unnecessary due to wellknown engineering improvements. However, the comment does not provide any specific examples, references, or detailed reasoning to support why these improvements are wellknown or why a fullpage explanation is unnecessary. This lack of supporting evidence makes the claim difficult for the authors to verify or address effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment points out that the implementation of kernels using OpenAI\"s Triton instead of CUDA does not require a fullpage explanation, as the engineering improvements are wellknown. This feedback is 3 as it highlights an area where the authors might be overexplaining a point that is already understood in the field. However, the comment could be more helpful if it provided specific guidance on how to condense the explanation or suggested alternative ways to present the information. The authors gain some insight into reducing unnecessary detail, but the feedback could be more actionable and detailed to be fully beneficial. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the analysis of neural networks, suggesting that it contributes less and that the extension from linear models to wide fullyconnected neural networks is trivial given the existing NTK theorem. It also claims that the work bypasses the core problem of overparametrized neural networks. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these concerns or improve their analysis. Without actionable suggestions or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2, 3.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the analysis of neural networks, noting that the extension from linear models to wide fullyconnected neural networks is trivial given the existing NTK theorem and that the work bypasses the core problem of overparametrized neural networks. This provides clear guidance on what needs to be addressed in the analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of neural networks contributes less and that the extension from linear models to wide fullyconnected neural networks is trivial given the existing NTK theorem. It also suggests that the work bypasses the core problem of overparametrized neural networks. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the critique. The absence of concrete evidence or references to the NTK theorem or the core problem of overparametrized neural networks limits the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of neural networks, suggesting that it contributes less and that the extension from linear models to wide fullyconnected neural networks is trivial given the existing NTK theorem. It also points out that the work bypasses the core problem of overparametrized neural networks, which is a critical aspect of neural network analysis. However, the comment lacks actionable suggestions or guidance on how the authors might address these concerns or improve their analysis. Without specific recommendations or examples, the feedback is 3 as it highlights an area for improvement but does not provide a clear path forward for the authors. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the results section, noting that while there is good performance on imageNet classification with smaller models like ResNet50/34/18, there are no results provided for larger models like ResNet101/152. This comment implies that the authors should include results for these larger models to provide a more comprehensive evaluation of their approach. However, it does not explicitly instruct the authors to do so, leaving the action implicit. The suggestion is concrete in that it specifies which models should be included, but the authors need to infer the action themselves. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses the performance results on imageNet classification, specifically mentioning the use of ResNet50/34/18 models. However, it does not specify which part of the paper these results are presented in, such as a specific section or table. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in pointing out the absence of results for larger models like ResNet101/152, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is good performance on imageNet classification with ResNet50/34/18 but lacks results for larger models like ResNet101/152. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a gap in the results section, noting that while there is good performance on imageNet classification with smaller models like ResNet50/34/18, there are no results provided for larger models like ResNet101/152. This feedback is 3 as it identifies an area where the authors could expand their evaluation to provide a more comprehensive assessment of their approach. However, the comment lacks specific suggestions on how to address this gap or what benefits might be expected from including results for larger models. To be more helpful, the comment could provide guidance on why larger models are important or how they might impact the evaluation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two parts. The first part suggests that the authors should consider a multifidelity framework and sequential design for learning quantities of interest, referencing a specific paper by Stroh et al. (2017). This provides a clear and explicit action for the authors to explore and potentially incorporate into their work. The second part points out a potential inconsistency in the text, specifically the use of \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. While the comment identifies a specific issue, it does not provide explicit guidance on how to resolve it. The action is mostly implicit, as the authors need to infer that they should clarify or reconcile these statements. However, the suggestion to explore the multifidelity framework is explicit and concrete, making the overall comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the multifidelity framework and sequential design for learning quantities (e.g. probabilities of threshold exceedance)\" and \"Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach (Stroh et al. 2017),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the text, noting the inconsistency between \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a suggestion to consider a multifidelity framework and sequential design for learning quantities of interest, and a critique of the text regarding the use of \"relatively inexpensive\" and \"expensive to evaluate.\" The first part is a suggestion and does not contain a claim that requires verification. The second part critiques the text for inconsistency but does not provide specific evidence or reasoning to support why this inconsistency is problematic. Without detailed justification or examples, the comment lacks verifiability. Therefore, it aligns with a score of 1.", "helpfulness_rationale": "The review comment provides two distinct points of feedback. First, it suggests that the authors consider a multifidelity framework and sequential design for learning quantities of interest, referencing a specific paper by Stroh et al. (2017). This is a valuable suggestion that could enhance the paper by introducing a relevant and applicable methodology. However, the comment does not elaborate on how this framework could be integrated or what specific aspects of the paper it could improve. The second point critiques the inconsistency in the text regarding the cost of evaluation, noting the use of \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. While this feedback identifies a potential issue, it lacks specific guidance on how to resolve the inconsistency or improve the clarity of the text. Overall, the comment provides some helpful insights but could be more actionable and detailed to fully support the authors in improving their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to compare their final results on the official COOC leaderboard for the blind test set, referencing a specific link and mentioning that other approaches have been proposed and evaluated on this set. This provides clear and concrete guidance on what action the authors should take to improve their draft. The comment also suggests comparing to specific approaches that have won the challenge, which adds a level of detail to the action. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"captioning experiment\" and the need to compare results on the official COOC leaderboard for the blind test set, providing a specific link. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details what needs to be addressed, namely comparing results on the official leaderboard and referencing specific approaches that have been evaluated on this set. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper should compare its results on the official COOC leaderboard for the blind test set, referencing a specific link and mentioning that other approaches have been proposed and evaluated on this set. The comment provides a logical reasoning by pointing out the importance of comparing results on the official leaderboard, especially since other approaches have been evaluated and published. However, it lacks specific examples or references to these other approaches, which would strengthen the claim. Therefore, the comment is 4, as it provides a clear direction but could be further supported with more detailed examples or references.", "helpfulness_rationale": "The review comment provides specific and actionable feedback regarding the comparison of results in the captioning experiment. It highlights the importance of comparing results on the official COOC leaderboard for the blind test set, rather than on unofficial test sets or dev sets. The comment also references specific approaches that have won the challenge and suggests comparing to these, which could help the authors improve the validity and relevance of their results. Additionally, it points out the need to consider more recent approaches that have been proposed and evaluated on the blind test set. This feedback is clear, actionable, and constructive, offering the authors a clear path to enhance the rigor and impact of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the reliability of the experimental results, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. However, it does not provide any explicit or implicit actions for the authors to take to address these concerns. There is no guidance on how to improve the reliability of the results or what specific changes should be made to the experimental setup or analysis. Without actionable advice or suggestions, the authors are left without a clear path forward to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental results, specifically the discrepancy between the MSE and MAE values, which raises concerns about the validity of the results. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are unreliable, specifically pointing out the discrepancy between the MSE and MAE values in Table 1. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the MSE is significantly smaller than the MAE in Table 1, which raises concerns about the validity of the results. This feedback is clear and highlights a potential problem that the authors should address. However, the comment does not provide any suggestions or guidance on how to resolve this issue or improve the reliability of the results. While it points out a critical area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that there is not much novelty in the methodology and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or improve the novelty of their methodology. The comment lacks explicit or implicit actions, leaving the authors without a clear understanding of what changes they should make to enhance the novelty of their work. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment claims that there is not much novelty in the methodology and that the proposed meta algorithm is a direct extension of existing methods. However, it does not specify which part of the paper this claim is based on, such as a particular section or methodology description. Without explicit references or detailed explanations, the authors cannot confidently determine which aspects of the paper are being addressed. Additionally, the comment lacks specificity regarding what aspects of the methodology are considered extensions of existing methods or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there is not much novelty in the methodology, stating that the proposed meta algorithm is a direct extension of existing methods. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the methodology, suggesting that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide any specific examples or details about which existing methods are being referenced or how the proposed algorithm could be improved to offer more novelty. Without actionable feedback or suggestions, the comment lacks depth and does not offer the authors a clear path for improvement. As a result, it is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a need for clarification regarding the terms \"good,\" \"bad,\" and \"wrong\" explanation at line 248. It suggests that the authors should clarify these concepts before using them, which provides a direct and concrete action for the authors to take. The comment is explicit and specific, offering clear guidance on how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L248\" and \"L255,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of needing clarification on the terms \"good,\" \"bad,\" and \"wrong\" explanation. The comment provides a clear direction for improvement by suggesting that the authors should clarify these concepts before using them. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the meaning of \"wrong\" at line 248 and suggests that the paper should clarify the concepts of \"good,\" \"bad,\" and \"wrong\" explanations before using them. This is a request for clarification rather than a claim, as it does not express an opinion or judgment. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by clarifying the meaning of \"wrong\" at line 248. It suggests that the authors should provide a clear explanation of what is meant by \"good,\" \"bad,\" and \"wrong\" explanations before using these terms. This feedback is actionable and provides a clear direction for the authors to enhance the clarity and coherence of their draft. However, the comment could be more helpful if it offered additional suggestions on how to present this clarification or provided examples of how similar concepts have been addressed in other works. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper regarding the types of activities captured in the datasets and their importance in smart homes, particularly from the perspectives of occupant comfort and energy efficiency. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should expand on this topic, but it lacks concrete details on what specific aspects to cover or how to present them. As a result, the authors are left with a vague understanding of what needs to be done, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a gap in the paper regarding the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it difficult for the authors to identify the exact area needing attention. The comment is specific in detailing what is missing, but it lacks grounding as it does not direct the authors to a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, particularly from the perspectives of occupant comfort and energy efficiency. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the types of activities captured in the datasets and their importance in smart homes, particularly from the perspectives of occupant comfort and energy efficiency. This feedback is 3 as it points out an area where the authors could provide more depth and analysis. However, the comment lacks specific suggestions or guidance on how the authors might address this gap, such as recommending additional data or analysis to include. While it highlights an important area for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue in Section 5.3, where a generator equipped with a standard RGCN as a discriminator tends to collapse after several iterations, while the proposed module does not. The reviewer suggests that explaining the reason behind this difference is essential to demonstrate the mechanism by which the proposed method differs from previous ones. This feedback explicitly instructs the authors to include an explanation for this observed difference, providing a clear and concrete action to take. The authors know exactly what needs to be addressed and how to improve their draft by adding this explanation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of the generator collapsing and suggests that the reason behind this difference should be explained to demonstrate the mechanism by which the proposed method differs from previous ones. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed module prevents a generator from collapsing, unlike a generator equipped with a standard RGCN as a discriminator, which tends to collapse after several iterations. The reviewer suggests that explaining the reason behind this difference is essential to demonstrate the mechanism by which the proposed method differs from previous ones. However, the comment does not provide specific evidence, examples, or references to support the claim about the generator collapsing or the proposed module\"s effectiveness. This lack of detailed justification makes the claim 3, as the authors would need to conduct further analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in Section 5.3, where a generator equipped with a standard RGCN as a discriminator tends to collapse after several iterations, while the proposed module does not. It suggests that explaining the reason behind this difference is crucial to demonstrate the mechanism by which the proposed method differs from previous ones. This feedback is clear and actionable, as it directs the authors to include an explanation for the observed difference, which could significantly enhance the paper\"s clarity and impact. However, the comment could be more helpful if it provided additional guidance on how to approach this explanation or suggested specific aspects to focus on. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with further details."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the originality of the article, suggesting that its reasoning and writing logic bear similarities to another study. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or differentiate their work from the previous study. The comment implies that the authors should consider whether their work is an extension or introduces novel contributions, but it lacks concrete steps or actions for the authors to take. As a result, the comment is vague and does not provide actionable feedback, making it barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the originality of the article, suggesting similarities with another study, \"How Do Nonlinear Transformers Learn and Generalize in InContext Learning.\" However, it does not specify which parts of the article are similar or how they relate to the previous study. The authors may infer that the comment pertains to the methodology or results sections, but this is not explicitly stated. The comment lacks specificity regarding what aspects need to be addressed or how the authors should differentiate their work. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the originality of the article, suggesting that its reasoning and writing logic bear similarities to another study. However, it does not provide specific examples or detailed comparisons to support this claim, making it difficult for the authors to understand the basis of the concern. The comment lacks concrete evidence or references to the other study, which would be necessary to fully substantiate the claim. As a result, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully support it.", "helpfulness_rationale": "The review comment raises a concern about the originality of the article, suggesting that its reasoning and writing logic bear similarities to another study. This is a valid point that could prompt the authors to reflect on whether their work introduces novel contributions or is merely an extension of existing research. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or differentiate their work from the previous study. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on what specific aspects need to be clarified or how the authors might improve the theoretical comparisons. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in identifying the issue of unclear theoretical comparisons, but without grounding, the authors may struggle to determine where to address this feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"Theoretical comparisons to adaptive learning of GPRGNN is not clear.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why the comparisons are unclear. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of theoretical comparisons to adaptive learning of GPRGNN. However, it lacks depth and does not provide any suggestions or guidance on how the authors might improve this aspect of their paper. Without actionable feedback or specific recommendations, the authors are left without a clear path to address the issue. Therefore, the comment is 2, as it highlights a problem but does not offer any constructive advice for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the authors should conduct experiments and provide explanations regarding the different queries used in spatiotemporal representation, specifically mentioning spatial, temporal, and summary queries. It also suggests exploring scenarios where only spatial or temporal and summary queries are used. This feedback provides clear and concrete actions for the authors to take, ensuring they understand exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments  Ablation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: experiments and explanations regarding the different queries used in spatiotemporal representation, such as spatial, temporal, and summary queries. The comment further suggests exploring scenarios where only spatial or temporal and summary queries are used, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks experiments and explanations regarding the different queries used in spatiotemporal representation, such as spatial, temporal, and summary queries. It implies that this is a key difference from other works like VideoChatGPT. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the importance of these queries and their potential impact on the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of experiments and explanations regarding the different queries used in spatiotemporal representation. It highlights the importance of exploring these queries, such as spatial, temporal, and summary, as a key difference from other works like VideoChatGPT. The comment provides a clear and actionable suggestion by asking the authors to consider scenarios where only spatial or temporal and summary queries are used. This feedback is valuable as it directs the authors to a critical aspect of their work that needs further exploration and explanation. However, the comment could be more helpful if it offered additional guidance on how to conduct these experiments or what specific insights might be gained from them. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors could mention the potential social impacts of their work, specifically the risks associated with increased automation and the dual use of their method. While the comment implies that the authors should address this aspect, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to discuss potential social impacts but are not given specific instructions on how to incorporate this into their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 379,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors could mention the social impact of increased automation and the risks from the dual use of their method. This provides clear guidance on what the authors could add to their draft to address the reviewer\"s concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" assertion that their work has no negative social impacts. The reviewer expresses skepticism about the potential for significant negative social impact and suggests that the authors should consider the social implications of increased automation and the dual use of their method. However, the comment lacks specific examples or references to support the claim that these aspects are relevant or significant. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment addresses the societal impact of the work, specifically questioning the authors\" assertion that their work has no negative social impacts. It suggests that the authors could discuss the potential risks associated with increased automation and the dual use of their method. While the comment identifies a relevant area for consideration, it lacks specific guidance or examples on how the authors might address these concerns. The feedback is 3 as it prompts the authors to consider broader implications, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. While it identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The comment lacks concrete suggestions or details on what specific information should be included or how the authors should estimate the reliability of the model. As a result, the authors are left with an implicit action that is vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking information on how the function for the optimal sequence length was estimated and the reliability of the model. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and the reliability of the model. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and the reliability of the model. This is a critical issue that needs to be addressed to ensure the validity and credibility of the research. However, the comment does not provide specific suggestions or guidance on how the authors might address this gap, such as recommending additional experiments or analyses to validate the model\"s reliability. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it points out a critical issue but does not fully support the authors in resolving it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the term \"thousands\" is not accurate in the context of L006 and recommends adding \"on the subword level\" to improve clarity. This feedback is explicit, as it directly instructs the authors to make a specific change to their draft. The suggestion is also concrete, as it provides a clear and actionable step for the authors to take. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L006,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the term \"thousands\" is not accurate and recommends adding \"on the subword level\" to improve clarity. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the term \"thousands\" is not accurate in the context of L006 and recommends adding \"on the subword level.\" However, the comment does not provide any reasoning or evidence to support why \"thousands\" is inaccurate or how \"on the subword level\" would improve the clarity. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the term \"thousands\" in L006, suggesting that it may not be accurate in the context provided. It offers a constructive suggestion to add \"on the subword level\" to improve clarity. This feedback is clear and actionable, providing the authors with a direct way to enhance the precision and accuracy of their draft. However, the comment could be more helpful if it explained why \"thousands\" is not accurate or how the addition of \"on the subword level\" would improve the manuscript. Overall, the comment is 4 as it guides the authors toward a specific improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises several issues that need to be addressed. First, it points out that a number of hyperparameters, such as regularization, are not given. This is an explicit action for the authors to provide these missing hyperparameters. Second, it questions the yvalue at x=0 in the latent path figures, suggesting that it might be normalized to this value. This is an implicit action for the authors to clarify their description regarding normalization. Lastly, the reviewer suggests conducting further analysis using the interpolations themselves, which is an explicit action with concrete guidance on how to enhance the paper. Overall, the comment provides clear and actionable feedback, making it 5.", "grounding_specificity_rationale": "The comment raises several specific issues, providing explicit references to \"a number of hyperparameters\" and \"the latent path figures (e.g., Fig 3),\" which allows the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the yvalue at x=0 in the figures and suggests that it might be normalized. Additionally, the comment suggests further analysis using interpolations, which provides clear guidance on what the authors could do to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions and observations about the paper, including the absence of hyperparameters, the yvalue at x=0 in the latent path figures, and the suggestion for further analysis using interpolations. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the feedback and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several areas that need clarification or improvement in the paper. It points out the absence of hyperparameters, such as regularization, which is an important detail for reproducibility. It also questions the yvalue at x=0 in the latent path figures, suggesting that it might be normalized, and requests clarification on this point. Additionally, the reviewer suggests conducting further analysis using the interpolations themselves, which could provide valuable insights into the model. While the comment highlights specific issues and offers some suggestions, it could be more helpful by providing more detailed guidance on how to address these points. Overall, the feedback is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the theoretical effect of rounding core tensors on the full tensor error and asks if there is an error bound in terms of epsilon. While the comment identifies a potential area for clarification, it does not provide explicit instructions or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should explore or discuss the theoretical impact of rounding on the full tensor error. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific aspect of the paper, namely the mention of rounding core tensors to smaller ranks with a given accuracy. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the theoretical effect of this rounding on the full tensor error and asks if there is an error bound in terms of epsilon. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the theoretical effect of rounding core tensors on the full tensor error and asks if there is an error bound in terms of epsilon. The comment does not make a claim or provide an opinion but rather seeks clarification on a specific aspect of the paper. It is a factual question that requires no justification or evidence, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the theoretical effect of rounding core tensors on the full tensor error and asks if there is an error bound in terms of epsilon. This is a relevant and specific point that could help the authors clarify and improve their theoretical analysis. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific steps they could take to explore the theoretical impact. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the presentation of results, specifically noting that Table 1 only shows results for the discriminative setting, while there are two test settings in visual dialog. The reviewer questions the applicability of the discriminative setting to realworld applications and asks for the results on the generative setting. This comment explicitly requests additional information, providing a clear and concrete action for the authors to take. The authors know exactly what is missing and can easily address it by including the results for the generative setting. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the table only shows results for the discriminative setting, while there are two test settings in visual dialog, and questions the applicability of the discriminative setting to realworld applications. The comment further requests the results on the generative setting, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the absence of results for the generative setting in Table 1, given that there are two test settings in visual dialog. The reviewer highlights the known limitation of the discriminative setting in realworld applications, which provides a logical basis for the claim. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim. While the reviewer provides a clear question, the lack of supporting evidence or detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the presentation of results, noting that Table 1 only includes results for the discriminative setting, while there are two test settings in visual dialog. It questions the applicability of the discriminative setting to realworld applications and requests the results for the generative setting. This feedback is clear and actionable, providing the authors with a direct suggestion for improving the comprehensiveness of their results. By addressing this point, the authors can enhance the relevance and usefulness of their work. Therefore, the comment is rated as 4, as it effectively guides the authors toward a specific improvement in their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not specify what additional information or examples should be included to achieve this. The action is implicit and vague, as the authors are left to infer what specific steps or details are needed to address the concern. Without concrete guidance, the authors may struggle to determine how to implement the suggested improvement. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its suggestion to provide more convincing evidence, but without a clear reference to the section or part of the paper where this evidence should be included, the authors may find it challenging to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. This feedback identifies a potential weakness in the paper, specifically the need for more convincing evidence to support the feasibility of the query type. However, the comment lacks specificity and does not provide detailed guidance on what additional evidence or examples should be included. While it points out an area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it provides a general direction for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the form of \"p\" should be described near line 135, as it is currently not explicitly stated. This provides a clear and direct action for the authors to take, ensuring that the form of \"p\" is clarified in the draft. The comment is specific and concrete, offering a precise instruction on how to improve the clarity of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the description of the form of \"p\" near line 135. The reviewer assumes it is a Gaussian distribution but notes that it is not explicitly stated, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the form of \"p\" should be described near line 135, as it is currently not explicitly stated. The reviewer assumes it is a Gaussian distribution but notes that it is not explicitly stated. This is a request for clarification rather than a subjective claim or opinion, as it does not express a judgment or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of the paper. It points out that the form of \"p\" is not explicitly described near line 135, which could lead to confusion. By suggesting that the form of \"p\" should be described, the comment offers a clear direction for the authors to enhance the readability and understanding of their work. This feedback is valuable as it directly addresses a potential ambiguity in the paper, allowing the authors to make a specific improvement. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the interpretation of the results, specifically regarding the sublinearity of regret. It does not provide any explicit or implicit actions for the authors to take, nor does it suggest any changes or improvements to the draft. The comment is purely a query seeking clarification, leaving the authors without any actionable steps to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 3237, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the interpretation of the results regarding the sublinearity of regret, prompting the authors to clarify whether the prediction error over the entire horizon T cannot be sublinear. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the interpretation of the results regarding sublinearity of regret. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the interpretation of the results regarding sublinearity of regret, specifically asking if the prediction error over the entire horizon T cannot be sublinear. While it identifies a potential confusion in the paper, it does not provide any suggestions or guidance on how to address this issue or clarify the interpretation. The comment is 3 as it points out a potential misunderstanding, but it lacks actionable feedback or detailed guidance for the authors to improve their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the details of the forwardprediction model are not well explained, particularly in Figure 2(b), which should be redrawn to better represent the forward prediction model. The comment also mentions that it was difficult to connect the text with the figure and equations. This feedback provides a clear and direct action for the authors to take: redraw Figure 2(b) to improve the clarity of the forwardprediction model representation. The action is explicit and concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2(b),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the lack of clarity in the forwardprediction model, and suggests that the figure should be redrawn to better represent the model. Additionally, it points out the difficulty in connecting the text with the figure and equations. This provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the details of the forwardprediction model are not well explained, specifically mentioning Figure 2(b) as an example. The reviewer suggests that the figure should be redrawn to better represent the model. While the comment identifies a potential issue with the clarity of the model\"s representation, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to redraw the figure is a logical step, but without additional context or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the forwardprediction model, particularly in Figure 2(b), which is not well explained. It suggests that the figure should be redrawn to better represent the model, and it highlights the difficulty in connecting the text with the figure and equations. This feedback is clear and actionable, providing the authors with a direct suggestion to improve the clarity and coherence of their work. By addressing this issue, the authors can enhance the readability and comprehensibility of their draft. Therefore, the comment is rated as 4, as it offers specific guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the paper, including the weakness of the baseline methods and the lack of discussion on limitations. It also suggests that the authors should discuss the similarity and difference between their work and reinforcement learning, as well as the generalizability of the results to RL settings. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to strengthen their baseline methods, discuss limitations, and explore the generalizability of their results, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the baseline methods, noting that they are weak and not stateoftheart, and lacks discussion on limitations. It also suggests discussing the similarity and difference between the work and reinforcement learning in the conclusion, as well as the generalizability of the results to RL settings. While the comment does not explicitly mention a specific section, it implies that the baseline methods are discussed in the results or methodology sections, providing some level of grounding. However, it lacks specificity regarding which baseline methods are weak or how the discussion on limitations should be improved. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the baseline methods are weak and not stateoftheart, and it suggests that the paper lacks a discussion on limitations. It also questions the difference between the work and reinforcement learning, suggesting a discussion on similarity and difference in the conclusion. However, the comment does not provide specific examples or references to support the claim about the baseline methods being weak or outdated. Additionally, it lacks detailed reasoning or evidence to substantiate the suggestion for discussing limitations and the comparison with reinforcement learning. This makes the claim 3, as it provides a general direction for improvement but lacks concrete evidence or detailed justification.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the weakness of the baseline methods and the lack of discussion on limitations. It also suggests that the authors should discuss the similarity and difference between their work and reinforcement learning, as well as the generalizability of the results to RL settings. This feedback is clear and actionable, providing the authors with specific directions to enhance their draft. However, the comment could be more helpful if it offered examples or specific suggestions on how to strengthen the baseline methods or discuss limitations. Overall, the comment is 4 as it guides the authors toward significant improvements, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests two distinct actions. First, it asks if running VGAE with a vamp prior could help match the doubly stochastic construction in the work, which would inform whether the benefits come from a better generative model or better inference. This is an explicit suggestion with a clear direction for the authors to explore. Second, it recommends keeping the generative model fixed and optimizing only the inference part of the model, parameterizing it as either SIGVAE or VGAE to compare representations. This is also an explicit suggestion with concrete guidance on how to conduct the comparison. Both suggestions are clear and actionable, providing the authors with specific steps to take to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific suggestions for improving the figure, such as keeping the generative model fixed and optimizing only the inference part of the model. This level of detail helps the authors understand what needs to be addressed in the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work, which could help determine if the benefits come from a better generative model or better inference. This is a logical suggestion based on the context of the paper, but it lacks specific examples or references to support the claim. The second part of the comment provides a suggestion for improving Figure 3 by keeping the generative model fixed and optimizing only the inference part. While this is a constructive suggestion, it does not provide detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis but lacks comprehensive support.", "helpfulness_rationale": "The review comment provides two distinct suggestions for improving the draft. First, it questions whether running VGAE with a vamp prior could help match the doubly stochastic construction in the work, which would inform whether the benefits come from a better generative model or better inference. This is a thoughtful suggestion that could lead to a deeper understanding of the paper\"s contributions. Second, it recommends keeping the generative model fixed and optimizing only the inference part of the model, parameterizing it as either SIGVAE or VGAE to compare representations. This suggestion is clear and actionable, offering a specific way to enhance the analysis and comparison of the models. By addressing these points, the authors can gain valuable insights and improve the clarity and comprehensiveness of their work. Therefore, the comment is 5, as it provides actionable and constructive feedback that can significantly enhance the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the necessity of learning longrange dependencies for powerful predictors, particularly in the context of semantic segmentation. The reviewer acknowledges that the paper demonstrates this importance but suggests that the discussion could be more nuanced. The comment implies that the authors should consider the role of locality in the graph structure and its impact on prediction, especially in relation to image size. However, it does not provide explicit guidance on how to address this issue or what specific aspects of the discussion should be expanded. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the tradeoff between longrange dependencies and locality in the graph structure. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the need for a discussion about the importance of learning longrange dependencies versus the role of locality in the graph structure, particularly in relation to image size. The comment provides a clear direction for the authors to consider the tradeoff between these aspects, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the necessity of learning longrange dependencies for powerful predictors, particularly in the context of semantic segmentation. The reviewer acknowledges that the paper demonstrates this importance but suggests that the discussion could be more nuanced. The comment implies that the authors should consider the role of locality in the graph structure and its impact on prediction, especially in relation to image size. However, the claim is somewhat vague as it lacks specific examples or references to support the assertion that the truth lies \"somewhere in between.\" The reviewer provides a logical reasoning about the potential impact of locality on prediction, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s discussion on the importance of learning longrange dependencies for powerful predictors. It acknowledges that the paper demonstrates this importance in the context of semantic segmentation but suggests that the discussion could be more nuanced. The reviewer points out a specific concern about the role of locality in the graph structure and its potential impact on prediction, particularly in relation to image size. This feedback is 3 as it prompts the authors to consider a more balanced discussion of the tradeoffs involved. However, it lacks specific suggestions or guidance on how to address this issue, which would make it more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the variable $e_l$ in Eq. (3) and points out that Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also mentions that the performance is getting worse than standard random features, as shown in Figure 1. While the comment identifies potential issues and dependencies, it does not provide explicit instructions or suggestions on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the variable $e_l$ and address the exponential dependence on $M$. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. (3),\" \"Corollaries 1, 2, and 3,\" and \"Theorem 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the exponential dependence on the diameter $M$ of the domain of data and how it affects the required feature size. Additionally, it references Figure 1 to support the claim that the performance is getting worse than standard random features. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several claims, including the need for clarification of the variable $e_l$ in Eq. (3) and the observation that Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also suggests that this dependence affects the constant factor of the required feature size and references Figure 1 to support the claim that the performance is worse than standard random features. While the comment provides some logical reasoning and references specific parts of the paper, it lacks detailed examples or references to external works that could further substantiate the claims. Therefore, the comment is 4, as it provides a solid foundation for the claims but could benefit from additional supporting evidence.", "helpfulness_rationale": "The review comment raises several points that are relevant to the authors. It questions the variable $e_l$ in Eq. (3), which could indicate a need for clarification or explanation. Additionally, it points out that Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data, which could impact the required feature size. The comment also references Figure 1, suggesting that the performance is worse than standard random features, which may indicate a weakness in the proposed approaches. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered guidance on how to improve the theoretical results. Overall, the feedback is 3 as it identifies areas for clarification and improvement but lacks detailed actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the demonstration or results related to the model collapsing less than other methods. It also references a specific line (159) where the reviewer mentions gradients becoming 0 and collapsing, and asks if this is a commonly encountered issue or observed in experiments. While the comment implies that the authors should provide more information or results on this topic, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the issue of model collapse and provide additional information. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 159,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for a demonstration or result related to the model collapsing less than other methods and seeks clarification on whether this is a commonly encountered issue or observed in experiments. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification and additional information regarding the model collapsing issue. It does not contain subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks more details, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the demonstration or results related to the model collapsing less than other methods. It references a specific line in the paper where the issue of gradients becoming 0 and collapsing is mentioned, and asks if this is a commonly encountered problem or observed in experiments. This feedback is 3 as it prompts the authors to provide additional information or results that could enhance the understanding and credibility of their work. However, the comment could be more helpful if it offered suggestions on how to address the issue or provided examples of similar studies that have encountered this problem. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include the results for linear scalarization combined with the SOTA heuristic solver (Concorde) for a better comparison, given that the Pareto front is not highly nonconvex. This is an explicit action with concrete details on how to implement it, as it specifies the exact results that should be included for a more comprehensive comparison. The authors know exactly what needs to be done to enhance their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Competitive Baselines\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the experimental results, noting that the learningbased solvers are better than the heuristicbased solvers but that the SOTA heuristic solver (Concorde) usually performs best for the singleobjective TSP. The comment further specifies that the results for linear scalarization combined with Concorde should be included for a better comparison, given the nonconvexity of the Pareto front. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the learningbased solvers are better than the heuristicbased solvers based on the experimental results. However, it also notes that for the singleobjective TSP, the SOTA heuristic solver (Concorde) usually performs best. The comment suggests including the results for linear scalarization combined with Concorde for a better comparison, given the nonconvexity of the Pareto front. While the claim about the performance of learningbased versus heuristic solvers is supported by the experimental results, the suggestion to include additional results is logical and provides a clear direction for improvement. However, the comment could be strengthened by providing specific examples or references to support the claim about Concorde\"s performance. Therefore, the comment is 4, as it provides a solid basis for the claim but could benefit from additional details.", "helpfulness_rationale": "The review comment provides a specific observation about the experimental results, noting that the learningbased solvers outperform the heuristicbased solvers but that the SOTA heuristic solver (Concorde) typically achieves the best results for the singleobjective TSP. It suggests that including the results for linear scalarization combined with Concorde would enhance the comparison, given the nonconvexity of the Pareto front. This feedback is clear and actionable, offering a concrete suggestion for improving the draft by providing a more comprehensive comparison. However, it could be more helpful if it included additional context or examples to further clarify the importance of this comparison. Overall, the comment is 4 as it provides valuable guidance for enhancing the experimental section of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide glosses in Figure 2. This is an explicit action that is clear and concrete, as it directly instructs the authors on what needs to be done to improve their draft. The comment provides specific guidance on where to make the addition, which makes it 5. The authors know exactly what action to take and how to implement it, ensuring that the feedback is actionable.", "grounding_specificity_rationale": "The comment suggests providing glosses in Figure 2, which allows the authors to identify the specific part of the paper being addressed. However, it does not specify what kind of glosses are needed or why they are necessary, making the comment somewhat vague in terms of what needs to be addressed. Therefore, the comment is fully grounded as it clearly identifies the part of the paper, but it is underspecific in terms of the details needed for improvement. This aligns with a score of 4.", "verifiability_rationale": "The review point suggests providing glosses in Figure 2, but it does not explain why glosses are necessary or how they would improve the figure. Without additional context or justification, the authors may find it challenging to understand the importance of adding glosses or how to implement this suggestion effectively. Therefore, the comment is considered 1 as it lacks supporting evidence or reasoning.", "helpfulness_rationale": "The comment suggests providing glosses in Figure 2, which is a clear and actionable piece of feedback. By adding glosses, the authors can enhance the clarity and accessibility of the figure for readers who may not be familiar with the terminology or concepts presented. This feedback is specific and provides a concrete suggestion for improvement, making it 4 for the authors. However, it could be more helpful if it explained why glosses are necessary or how they would benefit the figure. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about considering finer grouping for quantization instead of pertensor and perchannel approaches. However, it does not provide any explicit guidance or suggestions on how the authors should address this question or what specific actions they should take. The comment lacks concrete details or actionable steps, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the choice of quantization approach, specifically asking why a finer grouping is not considered instead of pertensor and perchannel methods. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure discussing quantization methods. Without explicit references or context, the authors may find it challenging to determine where this comment should be addressed. The comment is specific in its questioning of the quantization approach but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point is a question asking for justification or explanation regarding the choice of quantization approach. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the choice of quantization approach, specifically asking why a finer grouping is not considered instead of pertensor and perchannel methods. While it identifies a potential area for improvement, it lacks depth and does not provide any specific suggestions or guidance on how the authors might address this issue. The comment does not offer actionable advice or insights that would help the authors improve their draft. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the definition of \"active vertices\" in the context of the network\"s sparsity. While it does not explicitly instruct the authors to clarify or define this term, it implies that the authors should provide a clear explanation or definition. The action is implicit and somewhat vague, as the authors need to infer that they should address the lack of clarity regarding \"active vertices.\" However, the comment provides a clear direction for improvement, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the definition of \"active vertices,\" which is a clear and direct request for clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the definition of \"active vertices\" in the context of the network\"s sparsity. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the definition of \"active vertices\" in the context of the network\"s sparsity, which is mentioned in line 135. This feedback is 3 as it points out a potential ambiguity in the text that needs clarification. However, it does not provide specific guidance on how to address the issue or suggest alternative ways to define \"active vertices.\" While it prompts the authors to clarify their terminology, it lacks depth and actionable advice, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern that the paper\"s theory is not applicable to the used model, which is not explicitly mentioned in the limitations section. It also points out the vagueness of \"structural assumptions\" that are only provided in the appendix, making it difficult to identify the theoretical limitation. The reviewer suggests that the authors should provide more elaboration on the potential negative societal impact of graph neural networks, given their widespread use in industry. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the limitations and provide additional discussion on societal impact. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"limitations\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of mention of the theory\"s inapplicability to the used model and the vagueness of \"structural assumptions\" provided in the appendix. Additionally, the comment suggests that the authors should provide more elaboration on the potential negative societal impact of graph neural networks, given their widespread use in industry. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s theory is not applicable to the used model and that this limitation is not honestly mentioned in the limitations section. It also suggests that the authors underestimate the current use of graph neural networks in industry and should provide more elaboration on potential negative societal impacts. The comment provides some logical reasoning by pointing out the lack of mention of the theory\"s inapplicability and the vagueness of \"structural assumptions.\" However, it lacks specific examples or references to support the claim about the widespread use of graph neural networks or the potential negative societal impacts. This makes the claim 3, as it provides a basis for the argument but requires further evidence or details to be fully substantiated.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, specifically addressing the applicability of the theory to the used model and the lack of mention of this limitation in the limitations section. It also points out the vagueness of \"structural assumptions\" provided in the appendix, which makes it difficult to identify the theoretical limitation. Additionally, the reviewer suggests that the authors should provide more elaboration on the potential negative societal impact of graph neural networks, given their widespread use in industry. This feedback is clear and actionable, as it identifies specific areas for improvement and provides a direction for the authors to enhance their draft. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of potential societal impacts. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the importance of specific components within the framework for using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary for distinguishing the paper from related work but does not provide a clear answer or guidance on how to address this issue. The comment implies that the authors should clarify this aspect, but it lacks explicit instructions or concrete steps on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the importance of specific components within the framework for using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary for distinguishing the paper from related work but does not specify which part of the paper this discussion should be included in. The authors can infer that it relates to the discussion section, but the comment lacks full grounding as it does not explicitly mention the section. The comment is specific in identifying the need for a clear discussion on the use of CLIP, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the importance of specific components within the framework for using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary for distinguishing the paper from related work but does not provide any evidence or reasoning to support this claim. The comment lacks specific examples or references to related work, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1, as it does not provide sufficient justification or evidence to support the need for a clearer discussion on the use of CLIP.", "helpfulness_rationale": "The review comment raises a question about the importance of specific components within the framework for using CLIP to guide weakly supervised learning. It suggests that a clearer discussion on this topic is necessary to distinguish the paper from related work. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what aspects of the framework are crucial for using CLIP. While it identifies a potential area for improvement, the lack of detailed feedback or actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the analogy between HOI analysis and Harmonic analysis, suggesting that the link is weak. It points out that there are only two \"basis\" (human and object) in the problem context, which does not support a strong connection to Fourier analysis. However, the comment does not provide explicit guidance or suggestions on how the authors could strengthen the analogy or improve the connection. The feedback lacks actionable details, leaving the authors uncertain about how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the analogy between HOI analysis and Harmonic analysis, suggesting that the link is weak. It provides specific details by mentioning the limited \"basis\" (human and object) in the problem context and the lack of a close connection between the decomposition/integration steps and Fourier analysis. However, it does not specify which part of the paper discusses this analogy, making it weakly grounded. The comment is specific in detailing what is wrong with the analogy, so it aligns with the label 3.", "verifiability_rationale": "The review point claims that the analogy between HOI analysis and Harmonic analysis is weak, specifically pointing out the limited \"basis\" (human and object) in the problem context and the lack of a close connection between the decomposition/integration steps and Fourier analysis. While the comment provides some reasoning, it lacks specific examples or references to support the claim fully. The authors might need to delve deeper into the paper to understand the exact nature of the analogy and its limitations. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by questioning the strength of the analogy between HOI analysis and Harmonic analysis. It points out that the link between the two is weak, specifically noting the limited \"basis\" (human and object) in the problem context and the lack of a close connection between the decomposition/integration steps and Fourier analysis. This feedback is 3 as it highlights an area where the authors might need to strengthen their argument or provide more detailed connections. However, the comment could be more helpful if it offered suggestions on how to improve the analogy or provided examples of how to better connect the concepts. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the generalizability of the model by questioning whether it can handle focusing distances other than those present in the training data. It explicitly asks for an evaluation of the model\"s performance on focusing distances not seen during training. This provides a clear and direct action for the authors to take, which is to investigate and report on the model\"s performance on unseen focusing distances. The comment is explicit and concrete, offering a specific task for the authors to address. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the generalizability of the model by asking whether it can handle focusing distances other than those present in the training data. The comment provides a clear direction for the authors to consider and evaluate, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the generalizability of the model by pointing out that the images in Figure 8 are from focusing distances that are also present in the training data. This is a logical observation that prompts the authors to consider whether their model can handle focusing distances not seen during training. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the potential issue and address it themselves, which aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the model by pointing out that the images in Figure 8 are from focusing distances that are also present in the training data. This observation prompts the authors to consider whether their model can handle focusing distances not seen during training, which is an important aspect of model evaluation. The comment provides a clear and actionable suggestion for the authors to investigate and report on the model\"s performance on unseen focusing distances. However, it could be more helpful if it offered specific guidance on how to conduct this evaluation or what metrics to use. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear direction for further analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider defining \"content\" and \"style\" more broadly in the context of their neural application, referencing a specific example from Gabbay & Hosehn (2018). It also questions the meaning of \"style\" in the context of the model, which is not sequential and does not capture temporal dynamics. While the comment implies that the authors should clarify these terms, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should define these terms more broadly and clarify their meaning in the context of their model. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should define \"content\" and \"style\" more broadly in the context of their neural application, referencing a specific example from Gabbay & Hosehn (2018). It also questions the meaning of \"style\" in the context of the model, which is not sequential and does not capture temporal dynamics. This provides specific guidance on what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper this issue pertains to, leaving the authors to infer that it relates to the sections discussing neural applications or style. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should define \"content\" and \"style\" more broadly in the context of their neural application, referencing a specific example from Gabbay & Hosehn (2018). The comment questions the meaning of \"style\" in the context of the model, which is not sequential and does not capture temporal dynamics. While the reference to Gabbay & Hosehn (2018) provides some context, the comment lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the specific issues with the current definitions of \"content\" and \"style\" in their work. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification or examples to be fully supported.", "helpfulness_rationale": "The review comment suggests that the authors should define \"content\" and \"style\" more broadly in the context of their neural application, referencing a specific example from Gabbay & Hosehn (2018). It questions the meaning of \"style\" in the context of the model, which is not sequential and does not capture temporal dynamics. This feedback is 3 as it identifies a potential area for clarification and provides a reference for the authors to consider. However, the comment could be more helpful if it offered specific suggestions on how to define these terms or provided additional context to aid the authors in addressing the issue. Overall, the comment provides some guidance but lacks depth, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides a detailed critique of the analysis of vit quantification, specifically addressing the claim that a direct quantization method leads to information distortion. It points out that the proposed approach does not improve this phenomenon and provides specific numerical examples to support the claim. Additionally, it notes that the quantization of MHSA introduces a large loss of precision, which is a known issue in transformer quantization. While the comment highlights specific issues with the analysis, it does not provide explicit guidance on how the authors should address these concerns or improve their analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a more detailed explanation of their analysis and potentially address the issues raised. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 45\" and \"Fig1(b) v.s. Fig5(b) for Block.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the analysis of vit quantification, including the claim that the proposed approach does not improve the information distortion phenomenon and that the quantization of MHSA introduces a large loss of precision. The comment provides specific examples and references to external works, such as QBERT, Q8BERT, BinaryBERT, FullyBinaryBert, which further supports the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of vit quantification is not adequately explained and that the proposed approach does not improve the information distortion phenomenon. It provides specific examples from the paper, such as the comparison of values in Fig1(b) and Fig5(b) for Block.3, to support the claim. Additionally, it references external works in the NLP field, like QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert, to demonstrate that the issue of quantization loss of precision is not unique to the ViT model. This provides a solid foundation for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the analysis of vit quantification, specifically addressing the claim that a direct quantization method leads to information distortion. It points out that the proposed approach does not improve this phenomenon and provides specific numerical examples to support the claim. Additionally, it notes that the quantization of MHSA introduces a large loss of precision, which is a known issue in transformer quantization. This feedback is valuable as it highlights specific areas where the analysis could be improved and provides concrete examples to support the critique. However, the comment could be more helpful if it offered suggestions on how the authors might address these issues or improve their analysis. Overall, the comment is 4, as it provides clear and actionable feedback that can guide the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a main weakness in the work, specifically the lack of technical novelty compared to spatial transformer networks (STN) and the absence of comparisons to STN. It highlights that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that have applied STN in a local pixel neighborhood. The comment also notes the use of a variant of STN in PointNet. While the comment clearly identifies the issue, it does not provide explicit guidance on how the authors should address this lack of novelty or how to conduct the necessary comparisons. The action is implicit and somewhat vague, as the authors are left to infer that they need to enhance the novelty of their work and conduct comparisons to STN. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment identifies a main weakness in the paper, specifically the lack of technical novelty compared to spatial transformer networks (STN) and the absence of comparisons to STN. It provides specific examples of existing works that have applied STN in a local pixel neighborhood and mentions PointNet using a variant of STN. However, the comment does not explicitly mention which part of the paper discusses the proposed Xtransformation or the comparisons to STN, making it weakly grounded. The comment is specific in detailing the issue with the lack of novelty and comparisons, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the work lacks technical novelty compared to spatial transformer networks (STN) and that the proposed Xtransformation is similar to STN but applied locally. It supports this claim by referencing existing works that have applied STN in a local pixel neighborhood and mentioning PointNet\"s use of a variant of STN. This provides a logical reasoning and some evidence to substantiate the claim, making it 4. However, the comment could be strengthened by providing more specific references or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of technical novelty compared to spatial transformer networks (STN) and the absence of comparisons to STN. It highlights that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that have applied STN in a local pixel neighborhood. Additionally, it notes the use of a variant of STN in PointNet, further emphasizing the limited novelty of the work. The comment provides a clear and actionable suggestion for improvement by recommending empirical or conceptual comparisons to STN, which would help establish the technical novelty of the work. However, the comment could be more helpful if it offered specific guidance on how to conduct these comparisons or what aspects to focus on. Overall, the feedback is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific equation, Eq. 12, as confusing and suggests that the reward at each trial is unclear. It implies that the authors should clarify where the reward comes from, possibly by referencing Eq. 11. Additionally, the comment recommends explaining the network model in Sec. 4.2 with equations to improve clarity. The inclusion of references to external works provides additional context and potential examples for the authors to consider. While the comment is explicit in its suggestions, it could be more concrete by providing specific guidance on how to clarify the reward source or the network model. Overall, the comment is 4, as it provides clear directions for improvement but could benefit from more detailed instructions.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 12\" and \"Sec. 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with Eq. 12, questioning the source of the reward and suggesting that it might be related to Eq. 11. Additionally, it provides a recommendation to explain the network model in Sec. 4.2 with equations to improve clarity. The inclusion of references to external works further supports the suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Eq. 12 is confusing and questions the source of the reward at each trial. It suggests that the reward might be taken from Eq. 11 and recommends explaining the network model in Sec. 4.2 with equations to improve clarity. The comment provides references to external works, which could support the claim by offering examples of how similar models are explained. However, the comment lacks detailed reasoning or specific examples from the provided references to fully substantiate the claim. Therefore, the claim is 3, as it provides some support but requires more detailed justification or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with Eq. 12, questioning the source of the reward at each trial and suggesting that it might be related to Eq. 11. It also recommends explaining the network model in Sec. 4.2 with equations to improve clarity. The inclusion of references to external works provides additional context and examples for the authors to consider. However, the comment could be more helpful if it provided specific guidance on how to clarify the reward source or the network model. Despite this, the feedback is 4 as it directs the authors to address a critical area of confusion and offers some references for further exploration. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two explicit actions: correcting a typographical error (\"Fig.7\" to \"Fig.12\") in the supplementary material and attaching theorems and corollaries in the main paper to their corresponding proof links. These actions are clear and concrete, providing the authors with direct guidance on how to improve their draft. Additionally, the comment suggests addressing concerns related to motivation, methodology soundness, and experiment persuasion, which are also explicit and actionable. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the typo (\"Fig.7\" should be \"Fig.12\") and provides a clear suggestion to attach theorems and corollaries to their corresponding proof links. Additionally, the comment highlights areas of concern regarding motivation, methodology soundness, and experiment persuasion, providing specific feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and suggestions for improvement, such as correcting a typographical error and attaching theorems and corollaries to their corresponding proof links. It also provides an overall assessment of the paper, noting its novelty, theoretical guarantees, and empirical results. However, the comment does not contain subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by pointing out a typographical error in the supplementary material and suggesting that theorems and corollaries in the main paper should be linked to their corresponding proofs. This feedback is clear and directly guides the authors on how to improve the readability and clarity of their work. Additionally, the comment highlights areas of concern regarding motivation, methodology soundness, and experiment persuasion, which are important aspects of the paper. However, the comment could be more helpful if it provided more detailed suggestions or examples for addressing these concerns. Overall, the feedback is 4 as it offers concrete steps for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about specific parts of the paper, including the definition of \"Above definition,\" the selection of action verbs, and the concept of \"action frames.\" While the comment identifies areas that need clarification, it does not provide explicit instructions or suggestions on how the authors should address these issues. The questions are implicit and lack concrete guidance, leaving the authors to infer what needs to be done. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"Section 3\" and \"Section 3 306ff,\" allowing the authors to accurately identify the parts being addressed. It also raises specific questions about the definitions and concepts presented in these sections, such as the missing determiner in the definition of \"Above definition,\" the selection of action verbs, and the concept of \"action frames.\" This level of detail provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification on specific aspects of the paper, such as the definition of \"Above definition,\" the selection of action verbs, and the concept of \"action frames.\" These questions are factual and do not express opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several specific questions about the paper, including the definition of \"Above definition,\" the selection of action verbs, and the concept of \"action frames.\" These questions indicate areas where the authors may need to provide further clarification or explanation to enhance the comprehensibility of their work. However, the comment does not offer suggestions or guidance on how to address these issues, leaving the authors with a clear understanding of what needs to be clarified but without actionable steps to take. Therefore, the comment is 3, as it identifies areas for improvement but lacks depth and specific guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a minor issue with a typo in the manuscript, specifically suggesting that \"Empiically\" should be corrected to \"Empirically\" on Line 32 of Page 1. This feedback is explicit and provides clear guidance on what action the authors need to take to correct the error. The comment is concrete, as it specifies the exact location of the issue and the correction needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Ln 32 on Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is a typo in the word \"Empiically\" that should be corrected to \"Empirically.\" This provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point consists of a factual statement about a minor issue with a typo in the manuscript, specifically suggesting that \"Empiically\" should be corrected to \"Empirically\" on Line 32 of Page 1. This is a descriptive statement without any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a minor issue with a typo in the manuscript, specifically pointing out that \"Empiically\" should be corrected to \"Empirically\" on Line 32 of Page 1. While this feedback is accurate and actionable, it is limited in scope and does not provide broader insights or suggestions for improving the draft. The comment is clear and direct, but it does not offer any additional guidance or context that could help the authors improve the overall quality or content of their work. Therefore, it is 3, as it provides a specific correction but lacks depth and comprehensiveness."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the fixed number of entities in the model and questions how it can be generalized to different numbers of entities. While it points out a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation. The comment lacks concrete details on what changes or modifications could be made to improve the model\"s generalizability. As a result, the authors are left without a clear understanding of how to proceed with addressing this issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to \"figure 3 of INs,\" which provides full grounding as it explicitly mentions a specific figure and reference, allowing the authors to accurately identify the part of the paper being addressed. However, the comment is not specific in detailing what needs to be addressed regarding the generalization of the model to different numbers of entities. It highlights a potential issue but does not provide guidance on how to resolve it. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point raises a concern about the fixed number of entities in the model and questions how it can be generalized to different numbers of entities. The comment references \"figure 3 of INs,\" which suggests that the issue is related to a specific figure or example. However, the comment does not provide detailed reasoning or examples to support why this limitation is problematic or how it affects the model\"s performance. Without additional context or evidence, the claim remains 3, as the authors would need to infer the significance of the issue based on the reference to figure 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the model, specifically the fixed number of entities, and questions how it can be generalized to different numbers of entities. It references figure 3 of INs, which provides a specific example of the issue. However, the comment lacks depth and does not offer any suggestions or guidance on how the authors might address this limitation or improve the model\"s generalizability. While it highlights an important area for improvement, the feedback is incomplete and does not provide actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that the novelty of the idea is insufficient and that both the new metric and method are relatively straightforward. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty of the idea, improve the metric, or make the method more complex. Without specific suggestions or directions, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the idea and the straightforwardness of both the new metric and method. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact sections that need attention. The comment lacks grounding as it does not reference specific sections, tables, or figures. Additionally, it is not specific in detailing what aspects of the novelty or method are lacking or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the idea is insufficient and that both the new metric and method are relatively straightforward. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, it is challenging for the authors to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a concern about the novelty of the idea, suggesting that both the new metric and method are relatively straightforward. However, it does not provide any specific guidance or suggestions on how the authors might enhance the novelty or complexity of their approach. Without actionable feedback or detailed insights, the authors are left without a clear understanding of what changes could be made to address this critique. As a result, the comment is 1, as it lacks the depth and specificity needed to guide the authors in improving their draft."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the paper \"oversells\" the method, which makes the contribution less clear. However, it does not provide specific guidance on how to address this issue or what changes should be made to improve the clarity of the contribution. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to revise their draft. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper \"oversells\" the method, making the contribution less clear. However, it does not specify which part of the paper this issue pertains to, such as a particular section or claim. Without explicit references or detailed examples, the authors cannot confidently determine where the overselling occurs or what specific aspects need clarification. This makes the comment 1, as it lacks a clear reference to a specific part of the paper. Additionally, the comment is not specific because it does not provide detailed guidance on how to address the issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper \"oversells\" the method, making the contribution less clear. However, the comment does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or references, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1, as it lacks sufficient support to guide the authors in improving their work.", "helpfulness_rationale": "The review comment suggests that the paper \"oversells\" the method, which makes the contribution less clear. However, it does not provide specific examples or details on what aspects of the paper are overemphasized or how the contribution could be clarified. Without actionable feedback or guidance, the authors are left without a clear understanding of how to address the issue. This lack of specificity and actionable advice makes the comment 2, as it identifies a potential problem but does not offer a path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the model description could be improved by presenting the generative process in separate steps and reducing the use of symbols and notation tables. While the comment implies that these changes would enhance understanding, it does not provide explicit instructions on how to implement these suggestions. The authors can infer that they need to break down the generative process into more detailed steps and simplify the notation, but the comment lacks concrete guidance on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the model description could be improved by presenting the generative process in separate steps and reducing the use of symbols and notation tables. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or figure. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing improvement. The comment is specific in suggesting improvements to the model description, but it is 1 as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the model description could be improved by presenting the generative process in separate steps and reducing the use of symbols and notation tables. However, the comment does not provide specific examples or detailed reasoning to support why this would enhance understanding. The suggestion is based on a general principle of clarity and organization, but it lacks concrete evidence or references to substantiate the claim. Therefore, the comment is 3, as it provides a logical suggestion but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment suggests that the model description could be improved by presenting the generative process in separate steps and reducing the use of symbols and notation tables. This feedback is clear and actionable, as it provides specific guidance on how to enhance the clarity and readability of the model description. By breaking down the generative process into separate steps, the authors can make the content more understandable for readers. However, the comment could be more helpful if it included examples or further details on how to simplify the notation. Overall, the comment is 4 as it offers constructive feedback that can lead to improvements in the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point acknowledges that identifying rationales is a complex problem, particularly in NLP tasks like machine translation. It praises the paper for being wellorganized and easy to follow. However, it provides a specific suggestion for improving Figure 2 by recommending the use of another color or a bigger font to better highlight the humanidentified rationales. This feedback is explicit and provides concrete guidance on how to enhance the visual presentation of the figure, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific feedback on the visual presentation of the figure, suggesting the use of another color or a bigger font to highlight the humanidentified rationales. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point acknowledges that identifying rationales is a complex problem, particularly in NLP tasks like machine translation. It praises the organization and clarity of the paper but provides a specific suggestion for improving Figure 2 by recommending a different color or font size to highlight humanidentified rationales. This feedback is factual and descriptive, as it does not express an opinion or make a claim that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment acknowledges the complexity of identifying rationales, particularly in NLP tasks like machine translation, and praises the paper for its organization and clarity. It provides a specific and actionable suggestion for improving Figure 2 by recommending the use of another color or a bigger font to better highlight the humanidentified rationales. This feedback is clear and constructive, offering a concrete way for the authors to enhance the visual presentation of their work. However, the comment could be more helpful if it addressed other aspects of the paper, such as the methodology or results. Overall, the comment is 4 as it provides a valuable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should further verify the effectiveness and universality of the FlippedQA framework by applying it to nonLLMbased models like HiTeA and InternVideo. While the comment implies that the authors should conduct additional experiments or analyses, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct further testing and determine the specific models to use. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should further verify the effectiveness and universality of the FlippedQA framework by applying it to nonLLMbased models like HiTeA and InternVideo. However, it does not specify which part of the paper this suggestion is based on, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in suggesting additional experiments, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the FlippedQA framework should be tested on nonLLMbased models like HiTeA and InternVideo to verify its universality. The claim is based on a logical reasoning that the framework should be applicable beyond LLMbased models, and the suggestion to test it on other models is a reasonable request for further validation. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the importance of testing the framework on these models based on the reviewer\"s suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should further verify the effectiveness and universality of the FlippedQA framework by applying it to nonLLMbased models like HiTeA and InternVideo. This feedback is clear and actionable, as it identifies a potential limitation in the current application of the framework and provides specific models for further testing. By addressing this suggestion, the authors can enhance the robustness and generalizability of their work, making the comment 5. However, the comment could be more helpful if it included additional guidance on how to conduct these experiments or what specific aspects to focus on. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the proposed method, stating that it primarily builds upon existing methods and lacks significant theoretical novelty. The reviewer expresses willingness to improve their score if the authors address these concerns. However, the comment does not provide specific guidance or suggestions on how the authors might address these concerns or enhance the theoretical novelty of their method. The action is implicit and vague, as the authors are left to infer what changes might be necessary without clear direction. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the combination of existing methods, such as ClopperPearson intervals and Gaussian elimination, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concern about the lack of significant theoretical novelty, providing references to the existing methods. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method primarily builds upon existing methods, specifically mentioning ClopperPearson intervals and Gaussian elimination. The reviewer provides references to these existing methods, which supports the claim. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the lack of theoretical novelty. While the references provide some basis for the claim, the comment could be strengthened by more explicit comparisons or explanations of how the proposed method differs from or builds upon these existing methods. Therefore, the claim is 4, as it provides some support but could be further substantiated.", "helpfulness_rationale": "The review comment raises a concern about the originality of the proposed method, noting that it primarily builds upon existing methods such as ClopperPearson intervals and Gaussian elimination. The reviewer suggests that the paper lacks significant theoretical novelty and expresses willingness to improve the score if the authors address these concerns. While the comment identifies a potential weakness in the paper, it does not provide specific guidance or suggestions on how the authors might enhance the theoretical novelty or originality of their work. This limits the helpfulness of the feedback, as it does not offer actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not provide any explicit or implicit actions for the authors to take. The question lacks guidance on what the authors should do with this information or how it might impact their draft. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether the text input can be concatenated by the four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs clarification. Additionally, the comment lacks specificity regarding what aspects of the text input or object elements are being questioned. Without clear grounding or specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the concatenation of text inputs by the four text elements of an object. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review point raises a question about whether the text input can be concatenated by the four text elements of an object. While it identifies a potential area of confusion or lack of clarity in the paper, it does not provide any specific guidance or suggestions on how the authors might address this issue or clarify the text. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a specific sentence in the abstract (lines 1217) as being cumbersome and suggests that it can be made clearer. While the comment implies that the authors should revise this sentence, it does not provide explicit guidance on how to improve it. The action is implicit and somewhat vague, as the authors are left to infer that they need to rephrase the sentence for clarity. However, the comment does point out a specific area that needs attention, which is a step in the right direction. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, namely the sentence in lines 1217 of the abstract. It also specifies the issue, which is that the sentence is cumbersome and can be made clearer. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sentence in lines 1217 of the abstract is cumbersome and suggests it can be made clearer. However, the comment does not provide any specific reasoning or examples to support why the sentence is cumbersome or how it could be improved. Without detailed justification or suggestions, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, noting that a particular sentence is cumbersome and could be clarified. While it points out a potential area for improvement, it lacks detailed guidance or suggestions on how to rephrase the sentence for better clarity. The comment provides some direction by indicating that the sentence is problematic, but it does not offer specific advice or examples to help the authors improve it. As a result, the feedback is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern that the proposed approach does not outperform or is even worse than Decouple Kang et al. for overall performance. It also points out that the tradeoff between head and tail categories is not fully investigated for the baselines, suggesting that changing hyperparameters in Decouple Kang et al. could improve tail accuracy while slightly decreasing head accuracy. The reviewer encourages the authors to continue this line of work for future submission. While the comment identifies areas for improvement, it does not provide explicit instructions on how the authors should address these issues or what specific changes they should make. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the tradeoff for baselines and potentially explore hyperparameter tuning. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3)\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the proposed approach does not outperform or is even worse than Decouple Kang et al. for overall performance and that the tradeoff between head and tail categories has not been fully investigated for the baselines. The comment provides a specific suggestion to explore the tradeoff by changing hyperparameters in Decouple Kang et al.. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed approach does not outperform or is even worse than Decouple Kang et al. for overall performance, as shown in Figure 3. It also suggests that the tradeoff between head and tail categories has not been fully investigated for the baselines, implying that changing hyperparameters in Decouple Kang et al. could improve tail accuracy while slightly decreasing head accuracy. The comment provides a logical reasoning by comparing the performance of the proposed approach with Decouple Kang et al., which is a wellknown method in the field. However, it lacks specific examples or detailed comparisons to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence to be fully convincing.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically that the proposed approach does not outperform or is even worse than Decouple Kang et al. for overall performance. It also points out that the tradeoff between head and tail categories has not been fully investigated for the baselines, suggesting that changing hyperparameters in Decouple Kang et al. could improve tail accuracy while slightly decreasing head accuracy. This feedback is valuable as it highlights a critical weakness in the paper and provides a specific direction for improvement. However, the comment could be more helpful by offering suggestions on how to address these issues or by providing examples of how to explore the tradeoff for baselines. Overall, the comment is 4 as it directs the authors to a key area needing further investigation and improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the evaluation, noting that it is mostly based on 4 OCR QA datasets and that the authors themselves acknowledge the potential unreliability of this evaluation in Fig 4(5). The comment suggests that more scenarios, such as the LLaVA benchmark, should be included, especially in ablation studies. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to incorporate additional scenarios or datasets. The action is implicit and somewhat vague, as the authors need to infer that they should expand their evaluation to include more diverse scenarios. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 4(5),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limitation of the evaluation, which is mostly based on 4 OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited, relying on only 4 OCR QA datasets, and suggests that this may be unreliable. The comment references Figure 4(5), where the authors acknowledge the potential unreliability of the evaluation. However, it does not provide specific examples or detailed reasoning to support the claim that more scenarios like the LLaVA benchmark are necessary. While the comment highlights a potential issue, it lacks sufficient evidence or detailed justification to fully substantiate the claim. Therefore, the comment is considered 2, as it provides some basis for the claim but requires more detailed support.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation, noting that it is primarily based on 4 OCR QA datasets and that the authors themselves acknowledge the potential unreliability of this evaluation. It suggests that more scenarios, such as the LLaVA benchmark, should be included, especially in ablation studies. This feedback is clear and actionable, as it provides a specific area for improvement and a suggestion for enhancing the robustness of the evaluation. However, the comment could be more helpful if it offered additional guidance on how to incorporate these additional scenarios or datasets. Overall, the comment is 4 as it directs the authors to a significant area for improvement, but it could be more comprehensive with further details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides two explicit suggestions for improvement. First, it recommends clarifying the function pi by specifying its domain as R^m to \u0394^(K+1). Second, it questions the dimensions in the equation (2) and suggests assuming the 1st column of X_t is always 0 to resolve the issue. These suggestions are clear and provide concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L75\" and \"In (2),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the notation and dimensions, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a suggestion to clarify the function pi and a question about the dimensions in equation (2). The first part is a suggestion for improvement, which is not a claim requiring verification. The second part questions the dimensions, which is a factual observation. Since the comment does not contain subjective claims or opinions that need verification, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides two specific suggestions for improvement. First, it recommends clarifying the function pi by specifying its domain, which could help readers understand the notation better. Second, it questions the dimensions in equation (2) and suggests assuming the 1st column of X_t is always 0 to resolve the issue. These suggestions are clear and actionable, offering the authors concrete ways to enhance the clarity and accuracy of their work. However, the comment could be more helpful if it provided additional context or examples to support the suggestions. Overall, the feedback is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation of weak supervision could be improved, specifically questioning the realism of the evaluated tweets. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be the most realistic scenario. Additionally, it notes that the generation of authors is not realistic due to the use of averaged artificial tweets. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or suggest specific changes to enhance the realism of the evaluation. The action is implicit and somewhat vague, as the authors can infer that they need to improve the realism of the evaluation but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation of weak supervision and the specific aspects of the prompt and generation of authors that are not realistic. It provides clear details on what is lacking in the evaluation, such as the realism of the evaluated tweets and the generation of authors. This allows the authors to accurately identify the parts of the paper that need revision. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of weak supervision could be improved, specifically questioning the realism of the evaluated tweets. It provides specific examples, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the use of \"author embeddings are initialized by averaging the corresponding artificial tweets.\" These examples offer a clear rationale for why the evaluation might not be realistic, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or references to support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the evaluation of weak supervision, questioning the realism of the evaluated tweets. It provides concrete examples, such as the requirement for all structured elements to be present in the generated tweets and the use of averaged artificial tweets for author embeddings. This feedback is actionable as it highlights a potential weakness in the evaluation methodology and suggests that the authors should consider more realistic scenarios. However, the comment could be more helpful if it offered suggestions on how to enhance the realism of the evaluation or provided examples of more realistic approaches. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include keypoint detection results in the experiments section. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on where the results should be included, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly instructs the authors to include keypoint detection results in the experiments section, allowing them to accurately identify the part of the paper that needs revision. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of keypoint detection results in the experiments section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement requesting the inclusion of keypoint detection results in the experiments section. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a clear and specific suggestion for improving the paper by instructing the authors to include keypoint detection results in the experiments section. This feedback is actionable and directly addresses a gap in the current draft, offering a straightforward way for the authors to enhance the comprehensiveness of their results. However, the comment could be more helpful if it explained why these results are important or how they would impact the overall understanding of the paper. Despite this, the feedback is 4 as it provides a clear direction for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a specific comparison that the authors should make to further evaluate the performance of their proposed model. It explicitly requests a comparison with existing models that use answers as inputs, such as the Revisiting Visual Question Answering Baselines by Jabri et al. (ECCV16). This provides clear and concrete guidance on what action the authors should take to enhance their draft. The suggestion is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment suggests a specific comparison with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). However, it does not explicitly mention which part of the paper this comparison should be made in, leaving the authors to infer that it should be integrated into the discussion or results sections. The suggestion is specific in terms of the comparison, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a comparison between the proposed model and existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This claim is 3 as it provides a specific reference to an existing work that could serve as a basis for comparison. However, the comment lacks detailed reasoning or examples of how the proposed model might differ from or improve upon these existing models. While the suggestion is clear, the lack of additional context or evidence makes it difficult for the authors to fully understand and address the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a specific comparison that the authors should make to further evaluate the performance of their proposed model. It recommends comparing the model with existing models that use answers as inputs, such as the Revisiting Visual Question Answering Baselines by Jabri et al. (ECCV16). This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their draft by exploring the impact of ternary potential on performance. However, the comment could be more helpful if it included additional context or suggestions on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is 4 as it offers a valuable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the number of discourse relations in Table A2, suggesting that it might be an artifact of colloquial language or a misclassification of nondiscourse elements. However, it does not provide explicit guidance or suggestions for the authors to address this issue. The comment implies that the authors should investigate the cause of this observation, but it lacks concrete steps or actions to take. As a result, the authors are left with a vague understanding of what needs to be done, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the number of discourse relations in the treebank, suggesting that it might be an artifact of colloquial language or a misclassification of nondiscourse elements. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the number of discourse relations in Table A2, suggesting that it might be an artifact of colloquial language or a misclassification of nondiscourse elements. However, the comment does not provide any evidence, examples, or references to support this claim, making it difficult for the authors to understand the basis of the observation. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a specific question about the number of discourse relations in Table A2, suggesting that it might be an artifact of colloquial language or a misclassification of nondiscourse elements. This feedback is 3 as it prompts the authors to consider the potential reasons behind this observation and to clarify their categorization. However, the comment lacks depth and does not provide specific guidance on how to address the issue or what steps to take to improve the categorization. While it identifies a potential area for improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the use of soft labels in conjunction with CRM and crossentropy, suggesting that a higher beta value might be more effective. It also questions the authors\" choice of hyperparameters, implying that they might be subpar. However, the comment does not provide explicit guidance on how to address these issues or suggest specific hyperparameters to use. The action is implicit and vague, leaving the authors to infer that they need to reassess their hyperparameter choices and potentially adjust them. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is weakly grounded as it does not explicitly mention a specific section or part of the paper, making it difficult for the authors to pinpoint the exact area being addressed. However, it is specific in its critique, questioning the use of soft labels in conjunction with CRM and crossentropy, and suggesting that a higher beta value might be more effective. It also raises concerns about the choice of hyperparameters for the leftmost plots. While the authors may be able to infer the general area of the paper being discussed, the lack of explicit grounding makes it challenging to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the use of soft labels in conjunction with CRM and crossentropy, suggesting that a higher beta value might be more effective. It also questions the choice of hyperparameters, implying that they might be subpar. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence renders the claim 3, as the authors would need to infer the potential issues and address them without clear guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the use of soft labels in conjunction with CRM and crossentropy, suggesting that a higher beta value might be more effective. It also questions the choice of hyperparameters for the leftmost plots, implying that they might be subpar. While the comment identifies potential issues, it lacks specific guidance or suggestions on how the authors might address these concerns. It does not provide actionable advice or detailed feedback on how to improve the draft, leaving the authors with a general sense of what might need attention but without a clear path forward. Therefore, the comment is 3, as it highlights areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the traditional experiment for unseen characters is a nice idea but is presented as an afterthought. It implies that the authors should include more evaluations in this direction, specifically on classifying unseen words. Additionally, it suggests adding translations to Figure 6 for readers who do not speak Chinese. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these suggestions, such as which specific evaluations to include or how to present the translations. The action is explicit but somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting the addition of translations for readers who do not speak Chinese, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the traditional experiment for unseen characters is a nice idea but is presented as an afterthought. It implies that the authors should include more evaluations in this direction, specifically on classifying unseen words. The comment also suggests adding translations to Figure 6 for readers who do not speak Chinese. However, the comment lacks specific examples or references to support the claim that the experiment is presented as an afterthought or that more evaluations are needed. The suggestion to add translations is a logical one, but it does not address the main claim. Therefore, the comment is 3, as it provides some justification but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a constructive suggestion by noting that the traditional experiment for unseen characters is a nice idea but is presented as an afterthought. It implies that the authors should include more evaluations in this direction, specifically on classifying unseen words. Additionally, the comment suggests adding translations to Figure 6 for readers who do not speak Chinese, which could enhance accessibility. While the feedback is clear and actionable, it could be more helpful if it provided specific examples or detailed guidance on how to implement these suggestions. Overall, the comment is 4 as it offers valuable insights for improving the draft, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point consists of multiple separate issues, each of which is explicit and concrete. The first point explicitly states that the text in Table 1 is too small and hard to read, providing a clear action for the authors to take. The second point identifies a missing gradient symbol in Algorithm 1, line 4, which is also explicit and actionable. The third point references specific papers for further reading, providing a clear action for the authors to consider. Each of these points is explicit and concrete, offering the authors clear guidance on how to address the issues. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" \"Algorithm 1,\" and specific references, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the text size in Table 1, the missing gradient symbol in Algorithm 1, and provides references for further reading. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of multiple factual statements and references, which are verifiable through the provided references. The claim about the text size in Table 1 being too small and hard to read is supported by the explicit mention of the issue. The reference to missing symbols in Algorithm 1 and the citations of specific papers for further reading provide additional evidence. However, the comment does not include any subjective claims or opinions that require justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback on several aspects of the paper. It highlights the issue of small text in Table 1, which is hard to read, and suggests that this should be addressed. Additionally, it points out a missing gradient symbol in Algorithm 1, line 4, which is a clear and concrete suggestion for improvement. The comment also references specific papers for further reading, offering additional context and resources for the authors. This feedback is detailed and provides the authors with clear guidance on how to enhance the readability and accuracy of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of detailed discussion on computational aspects, particularly in high dimensions, and questions the practical usefulness of the proposed methods. It also points out that the algorithm requires solving several LPs in high dimensions, which involves parameters that are not easily calculable. The comment suggests that the experiments are performed on very smallscale datasets, implying that this might be a limitation. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve the computational aspects of their work. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed discussions on computational aspects and potentially explore ways to make their methods more practical for high dimensions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of detailed discussion on computational aspects, particularly in high dimensions, and questions the practical usefulness of the proposed methods. It mentions that the algorithm requires solving several LPs in high dimensions, each involving a parameter that is not easily calculable. The comment also notes that the experiments are performed on very smallscale datasets. While the comment does not explicitly mention specific sections or parts of the paper, the authors can infer that it relates to the methodology and results sections, where computational aspects and experimental details are typically discussed. The comment is specific in detailing the issues with computational aspects and the limitations of the experiments, but it lacks full grounding as it does not explicitly reference these sections. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors do not discuss computational aspects in detail and questions the practical usefulness of their proposed methods in high dimensions. It highlights the requirement to solve several LPs in high dimensions, each involving a parameter that is not easily calculable, and notes that the experiments are performed on very smallscale datasets. While the comment provides some reasoning and observations, it lacks specific examples or references to support the claim about the computational aspects or the limitations of the experiments. The lack of detailed evidence or examples makes the claim 3, as the authors would need to delve deeper into the paper to fully understand and address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the discussion of computational aspects, particularly in high dimensions. It points out that the proposed methods may not be practically useful due to the complexity of solving LPs in high dimensions, which involves parameters that are not easily calculable. The comment also notes that the experiments are conducted on very smallscale datasets, which may not accurately reflect the performance in higher dimensions. This feedback is valuable as it highlights a critical area for improvement, suggesting that the authors need to provide more detailed discussions on computational aspects and potentially explore ways to make their methods more practical for high dimensions. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these issues. Overall, the comment is 4, as it provides clear guidance on areas that need further exploration and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies specific errors in the equations, providing clear and concrete instructions on how to correct them. It specifies the exact lines where the corrections are needed and what changes should be made, such as replacing \"+\" signs with \"\" signs and adjusting the signs in the definition of B. Additionally, it provides a minor comment about the equation in Line 504. This level of detail and explicit guidance ensures that the authors know exactly what actions to take to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (Lines 502, 503, and 504), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the errors in the equations, such as the need to replace \"+\" signs with \"\" signs and adjust the signs in the definition of B. Additionally, it provides a minor comment about the equation in Line 504. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and corrections regarding specific mathematical expressions in the paper. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback regarding mathematical errors in the paper. It identifies incorrect signs in equations and offers precise corrections, such as replacing \"+\" signs with \"\" signs and adjusting the signs in the definition of B. Additionally, it includes a minor comment about the equation in Line 504. This level of detail and clarity empowers the authors to make accurate corrections, ensuring the integrity and accuracy of their work. The comment is comprehensive and provides clear guidance, making it 5 for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the ResNet in section 7.1 shares parameters between residual blocks. It also suggests a potentially interesting baseline for comparison, which would involve a deeper ResNet with parameter sharing, equivalent to an ODE net with a fixed timestep Euler integrator. While the comment implies that the authors should investigate this further, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 7.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by asking about parameter sharing in the ResNet experiments and suggests a potentially interesting baseline for comparison. The comment provides a clear direction for the authors to consider, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about whether the ResNet in section 7.1 shares parameters between residual blocks. It also suggests a potentially interesting baseline for comparison, which would involve a deeper ResNet with parameter sharing, equivalent to an ODE net with a fixed timestep Euler integrator. However, the comment does not provide any evidence, reasoning, or references to support the claim that this comparison would be interesting or equivalent. The suggestion lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the ResNet experiments in section 7.1, asking whether the ResNet shares parameters between residual blocks. It also suggests a potentially interesting baseline for comparison, which would involve a deeper ResNet with parameter sharing, equivalent to an ODE net with a fixed timestep Euler integrator. This feedback is 3 as it identifies a potential area for exploration and suggests a specific direction for improvement. However, it lacks depth and does not provide detailed guidance on how to implement this suggestion or why it would be beneficial. Therefore, the comment is rated as 3, as it offers some insight but could be more comprehensive."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the design choice of trimming questions after the first 10, suggesting that it might be an odd choice, especially since the question model is a bag of words and does not incur significant computational cost for longer sequences. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or whether they should reconsider their design choice. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the design choice of trimming questions after the first 10 and provides a rationale for this critique, noting that the question model is a bag of words and does not incur significant computational cost for longer sequences. This provides clear guidance on what aspect of the paper needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the design choice of trimming questions after the first 10, suggesting that it might be an odd choice, especially since the question model is a bag of words and does not incur significant computational cost for longer sequences. This claim is 3 as it provides a logical reasoning for questioning the design choice, but it lacks specific examples or references to support the assertion that trimming questions is unnecessary. The comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the design choice of trimming questions after the first 10, suggesting that this might be an odd choice, especially since the question model is a bag of words and does not incur significant computational cost for longer sequences. This feedback identifies a potential issue with the experimental design and provides a rationale for why the trimming might not be necessary. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or whether they should reconsider their design choice. While it highlights a potential area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the clarity of Figure 1, specifically regarding how the proposed method produces the type of explanation shown. It suggests that additional adhoc postanalysis might be needed to extract shared motifs, implying that the authors should clarify or address this issue. While the comment identifies a potential problem, it does not provide explicit instructions on how to resolve it or what specific steps the authors should take. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the explanation process but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, questioning how the proposed method produces the type of explanation shown and suggesting that additional adhoc postanalysis might be necessary. The comment provides a clear direction for the authors to clarify the explanation process, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of Figure 1, specifically regarding how the proposed method produces the type of explanation shown. The reviewer suggests that additional adhoc postanalysis might be necessary to extract shared motifs, implying that the proposed method may not fully address this need. However, the comment does not provide specific examples or detailed reasoning to support the claim that the explanation is unclear or that additional analysis is required. This lack of detailed justification makes the claim 3, as the authors would need to infer the exact nature of the issue and how to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 1, questioning the clarity of how the proposed method produces the type of explanation shown. It suggests that additional adhoc postanalysis might be necessary to extract shared motifs, which could explain a set of instances. This feedback is clear and actionable, as it points out a potential weakness in the explanation process and provides a direction for the authors to improve their draft by clarifying the method\"s capabilities. However, the comment could be more helpful if it offered specific suggestions on how to enhance the explanation or provided examples of how the proposed method could be improved. Overall, the comment is 4, as it directs the authors to a specific area needing clarification and improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that nonconvexity may not be an issue for the SGD to converge if the function Z has good properties. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the potential nonconvexity issue or what properties of function Z should be considered. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 182184, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of nonconvexity and suggests that it may not be a problem for the SGD to converge if the function Z has good properties. This provides clear guidance on what needs to be addressed in the specified part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that nonconvexity may not be an issue for the SGD to converge if the function Z has good properties. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples of what \"good properties\" might entail or how they would affect convergence. Without detailed justification or references, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a specific line in the paper (ln. 182184) and suggests that nonconvexity may not be an issue for the SGD to converge if the function Z has good properties. This feedback is 3 as it identifies a potential area of concern and provides a direction for the authors to consider. However, it lacks depth and does not offer specific guidance on how to address the issue or what properties of function Z should be evaluated. While it prompts the authors to think about the implications of nonconvexity, it does not provide actionable steps for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several issues: the lack of comparison with other models beyond GPT2, confusing sections of the paper, a missing citation/reference in Line 99 of section 3.1, and an unreferenced notation in Line 165 of section 3.4. While the comment identifies these problems, it does not provide explicit instructions or suggestions on how to address them. The authors are left to infer that they need to add comparisons with other models, clarify confusing sections, correct the citation/reference issue, and reference the notation. However, the lack of specific guidance on how to improve these areas makes the comment 3, as the authors know what needs to be done but not exactly how to execute it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and sections of the paper, allowing the authors to accurately identify the parts being addressed. It specifies the issues of missing comparisons with other models, confusing sections, a missing citation/reference in Line 99 of section 3.1, and an unreferenced notation in Line 165 of section 3.4. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of multiple claims and observations. The first claim about the lack of comparison with other models is not supported by any evidence or reasoning, making it 1. The second claim regarding confusing sections is subjective and lacks specific examples or references to substantiate the claim. The third point about a missing citation/reference in Line 99 of section 3.1 and the unreferenced notation in Line 165 of section 3.4 are factual observations that do not require verification. However, the claim about the authors acknowledging limitations is a positive statement and does not require verification. Overall, the comment lacks sufficient evidence or reasoning to support the claims, making it 1.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the lack of comparison with other models beyond GPT2, confusing sections, and missing citations or references. It also acknowledges the authors\" effort to acknowledge the limitations of their work. While the comment highlights important areas for improvement, it does not provide specific suggestions or guidance on how to address these issues. The feedback is 3 as it points out weaknesses, but it lacks depth and actionable advice, leaving the authors with a general understanding of what needs to be improved but without detailed steps to take. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to change two lines in red to green in the Supplemental Material. It provides specific line numbers and references to the changes needed, such as \"SuppMat, L502: \u03f5 \u03b8 > z \u03b8\" and \"SuppMat, L507: (4) > Table 4.\" This level of detail ensures that the authors know exactly what changes to make, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the Supplemental Material (SuppMat, L502, L507, and L509) where changes are needed. It specifies the exact changes required, such as changing \"\u03f5 \u03b8\" to \"z \u03b8\" and \"(4)\" to \"Table 4,\" and \"(1)\" to \"Algorithm 1.\" This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements regarding specific lines in the Supplemental Material that need to be corrected. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback. It identifies two lines in the Supplemental Material that need to be corrected, specifying the exact changes required. This level of detail empowers the authors to make precise adjustments, ensuring that the draft is accurate and consistent. The comment is clear and direct, offering a straightforward path for improvement, which aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a gap in the paper, specifically the lack of a proper comparison between the proposed approach and online learning formulations in the evaluation results. It also mentions the absence of a comparison against reinforcement learning (RL) and raises questions about the retraining cost and challenges of including it in the evaluation. The comment provides a clear and concrete action for the authors to take: conduct a comparison with online learning approaches and address the questions raised. This feedback is explicit and provides specific guidance on what needs to be done to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract and other parts of the paper where the issue of \"online learning formulation overlooking key practical considerations\" is discussed. It also specifies the need for a proper comparison against online learning approaches and reinforcement learning (RL) in the evaluation results. The comment provides clear guidance on what needs to be addressed, such as comparing retraining cost and incremental updates, and why online learning is discarded. This level of detail allows the authors to accurately identify the parts of the paper that require revision and understand the specific issues that need to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a proper comparison between the proposed approach and online learning formulations, as well as against reinforcement learning (RL). It raises questions about the retraining cost and challenges of including it in the evaluation. While the comment identifies a potential gap in the paper, it does not provide specific examples or references to support the claim. The reasoning is somewhat logical, but the lack of detailed evidence or examples makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is 3, as it provides a basis for the claim but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of a proper comparison between the proposed approach and online learning formulations, as well as against reinforcement learning (RL). It raises important questions about the retraining cost and challenges of including it in the evaluation, which are crucial for understanding the limitations and potential applications of the proposed method. By highlighting these areas, the comment provides clear and actionable feedback that can guide the authors in enhancing the comprehensiveness and rigor of their evaluation. However, while the comment is 4, it could be more beneficial if it offered specific suggestions on how to conduct these comparisons or address the challenges mentioned. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that important references are missing and encourages the authors to conduct a comprehensive comparison with the works \"GFF\" and \"EfficientFCN.\" It also provides specific references to these works, which are \"Gated Fully Fusion for Semantic Segmentation, AAAI\"20\" and \"EfficientFCN: Holisticallyguided Decoding for Semantic Segmentation, ECCV\"20.\" This feedback is clear and provides concrete guidance on what the authors need to do to improve their draft. The suggestion to include a comprehensive comparison with these works is explicit and actionable, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the missing references, \"GFF\" and \"EfficientFCN,\" and provides their respective references. This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific because it suggests a comprehensive comparison with these works, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that important references are missing and suggests a comprehensive comparison with the works \"GFF\" and \"EfficientFCN.\" The reviewer provides specific references to these works, which supports the claim. However, the comment could be strengthened by explaining why these references are important or how they relate to the current work. Despite this, the inclusion of references and the suggestion for comparison provide a solid basis for the claim, making it 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of important references, specifically mentioning \"GFF\" and \"EfficientFCN,\" which are relevant to the topic of fast semantic segmentation in the encodedecoder architecture. The reviewer encourages the authors to conduct a comprehensive comparison with these works, providing specific references to facilitate this process. This feedback is actionable and provides clear guidance on how the authors can enhance their draft by incorporating these references and comparisons. However, the comment could be more helpful if it explained why these references are crucial or how they relate to the current work. Overall, the comment is 4 as it directs the authors to important areas for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point questions the validity of the claim regarding the effectiveness of the proposed prompts based on the slight improvement observed in Table 6 and Table 7. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what specific changes should be made to support the claim. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6 and Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the claim of effectiveness, questioning whether the slight improvement supports the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the claim about the effectiveness of the proposed prompts based on the slight improvement observed in Table 6 and Table 7. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate why the slight improvement is insufficient to support the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the validity of the claim regarding the effectiveness of the proposed prompts, citing the slight improvement observed in Table 6 and Table 7. While it identifies a potential issue with the claim, it does not provide specific suggestions or guidance on how the authors might address this concern or improve their argument. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the analysis of the Cycle FC align features is insufficient and proposes that experiments or analysis with different sampling intervals and sample sizes could be considered. While the comment implies that the authors should conduct additional experiments or analyses, it does not provide explicit instructions on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments or analyses but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the \"Cycle FC align features\" and suggests that the analysis is insufficient. It implies that there could be various designs for this feature, such as experiments with different sampling intervals and sample sizes. However, the comment does not specify which part of the paper discusses the Cycle FC align features, making it weakly grounded. The suggestion to consider different designs is specific, as it provides a clear direction for potential improvements. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the analysis of the Cycle FC align features is insufficient and proposes that experiments or analysis with different sampling intervals and sample sizes could be considered. However, the comment lacks specific examples or references to support the claim that the analysis is insufficient or to justify the need for additional experiments. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient support.", "helpfulness_rationale": "The review comment identifies a potential weakness in the analysis of the Cycle FC align features, suggesting that the current analysis is insufficient. It proposes that the authors consider different designs, such as experiments with various sampling intervals and sample sizes, to enhance the analysis. This feedback is 3 as it points out an area for improvement and provides a specific suggestion for expanding the analysis. However, the comment could be more helpful if it offered additional guidance on how to implement these suggestions or provided examples of similar analyses in the literature. Overall, the comment provides some direction for the authors to consider, but it could be more comprehensive and actionable."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of standard deviations in the results, which makes it difficult to determine if the best method is indeed the best or if other RF configurations have similar performances. This feedback implies that the authors should include standard deviations to provide a clearer picture of the results. However, it does not explicitly instruct the authors to add standard deviations or explain how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to include standard deviations but may not know the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights the absence of standard deviations in the results, which makes it difficult to determine if the best method is indeed the best or if other RF configurations have similar performances. However, it does not specify which part of the paper this issue pertains to, such as a particular table or figure where the results are presented. Without explicit references to specific sections or results, the authors may find it challenging to identify the exact area needing attention. The comment is specific in its critique of the lack of standard deviations but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the absence of standard deviations makes it difficult to determine if the best method is truly the best or if other RF configurations have similar performances. This claim is 3 as it logically reasons that standard deviations are necessary for a comprehensive understanding of the results. However, the comment lacks specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is rated as 3, as it provides a logical basis but requires more detailed evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment points out a significant omission in the presentation of results, specifically the lack of standard deviations. This is a critical issue because it makes it difficult for the reader to understand the variability and reliability of the results. By highlighting this gap, the comment provides a clear and actionable suggestion for improvement. However, it could be more helpful if it offered specific guidance on how to incorporate standard deviations into the results or suggested alternative ways to present the data. Despite this, the comment effectively directs the authors to a crucial area that needs attention, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the choice of p < 0.4 in Algorithm 1, implying that the authors should provide an explanation or justification for this selection. However, the comment does not explicitly instruct the authors to include this information or provide guidance on how to address the question. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the choice of p, but they are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation of how the value of p < 0.4 was chosen, providing clear guidance on what needs to be clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the choice of p < 0.4 in Algorithm 1. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, the correct label is \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the choice of p < 0.4 in Algorithm 1, which is a clear and actionable point for the authors to address. By asking for an explanation of this choice, the reviewer prompts the authors to provide additional context or justification for their methodological decisions. This feedback is valuable as it directs the authors to clarify an important aspect of their work, potentially enhancing the transparency and comprehensibility of their methodology. However, the comment could be more helpful if it provided additional context or suggestions on how to address the question. Overall, the comment is 4, as it identifies a specific area for improvement and guides the authors toward enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide explanations or analysis for Figures 1, 2, and 3 in Section 5. It also specifies the need to clarify the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. This feedback is clear and direct, providing the authors with specific actions to take to improve their draft. The explicit nature of the instructions and the concrete details on what needs to be addressed make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5\" and \"Figures 1, 2, and 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of explanations or analysis for these figures, particularly the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. This provides clear guidance on what the authors need to revise. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors failed to provide explanations or analysis for Figures 1, 2, and 3 in Section 5. It specifically points out the need for clarification regarding the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of explanations or analysis for Figures 1, 2, and 3 in Section 5. It highlights the need for clarification regarding the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. This feedback is clear and actionable, providing the authors with a direct path to improve their draft by addressing these gaps. However, the comment could be more helpful if it offered suggestions on how to present the explanations or analysis, such as providing examples or discussing potential interpretations. Overall, the comment is 4 as it effectively points out a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a trend observed in the paper, noting that the advantage of RLCD over RLAIF diminishes as the model size increases from 7B to 30B. It raises a question about whether RLCD (or RLCDRescore) can scale to even larger language models that are better at differentiating responses near the decision boundary. While the comment identifies a potential area of concern and raises a question, it does not provide explicit guidance or suggestions on how the authors might address this issue or conduct further research. The action is implicit and somewhat vague, as the authors are left to infer that they should explore the scalability of RLCD to larger models. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the observation that the advantage of RLCD over RLAIF diminishes as the model size increases from 7B to 30B, and it raises a question about the scalability of RLCD to larger language models. This provides clear guidance on what needs to be addressed or explored further in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the advantage of RLCD over RLAIF diminishes as the model size increases from 7B to 30B, as observed in Table 2. It also raises a question about the scalability of RLCD to larger language models. The comment provides some logical reasoning by pointing out the trend observed in the data, but it lacks specific examples or references to support the claim fully. Additionally, the question about scalability is more of an inquiry than a claim, as it does not make a definitive statement. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a trend observed in the paper, noting that the advantage of RLCD over RLAIF diminishes as the model size increases from 7B to 30B. It raises a question about whether RLCD (or RLCDRescore) can scale to even larger language models that are better at differentiating responses near the decision boundary. This feedback is 3 as it points out a potential limitation in the paper and encourages the authors to consider the scalability of their approach. However, it lacks specific suggestions or guidance on how the authors might address this issue or conduct further research. While it provides some insight, it could be more helpful with additional details or actionable advice. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input. It questions how this method can be learned and applied to largescale datasets like ImageNet, suggesting that the practical contribution of the paper could be significantly reduced without a solution to this issue. While the comment highlights a potential problem, it does not provide explicit guidance or suggestions on how the authors might address the scalability issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to find a solution to the scalability problem but are not given specific steps or methods to consider. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the scalability of the proposed NC measure, specifically mentioning its applicability to largescale datasets like ImageNet. However, it does not explicitly mention which part of the paper discusses the NC measure or its scalability issues, making it weakly grounded. The comment is specific in detailing the concern about scalability and the potential impact on the paper\"s practical contribution. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the scalability of the proposed NC measure, questioning how it can be applied to largescale datasets like ImageNet. The comment suggests that the practical contribution of the paper could be significantly reduced without addressing this issue. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim about the scalability issue or its potential impact. This lack of detailed justification makes the claim 3, as the authors would need to infer the exact nature of the scalability problem and potential solutions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input. It questions how this method can be applied to largescale datasets like ImageNet, suggesting that the practical contribution of the paper could be significantly reduced without addressing this issue. This feedback is valuable as it highlights a potential limitation of the proposed method and prompts the authors to consider scalability in their approach. However, the comment could be more helpful if it provided suggestions or examples of how the authors might address the scalability issue. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the complexity of the proposed CoNO model, specifically questioning whether the performance boost is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are necessary, especially since UNets have shown strong performance on regular gridded domains. While the comment implies that the authors should include comparisons to UNets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct these comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"CoNO model\" and the \"UNet part after the fractional transform,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the source of the performance boost and suggesting that comparisons to UNets are necessary. The comment further supports its claim with references to relevant works by Raonic et al. and Gupta et al., providing additional context and justification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the complexity of the proposed CoNO model, questioning whether the performance boost is due to the fractional transform or the UNet operation in the fractional Fourier domain. The reviewer suggests that comparisons to UNets are necessary, especially since UNets have shown strong performance on regular gridded domains, as evidenced by references to Raonic et al. and Gupta et al. This claim is 4 as it provides a logical reasoning and references to external works, which supports the need for comparisons to UNets. However, the comment could be strengthened by providing more detailed examples or specific comparisons to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a critical point about the complexity of the proposed CoNO model, specifically questioning whether the performance boost is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are necessary, especially since UNets have shown strong performance on regular gridded domains, as evidenced by references to Raonic et al. and Gupta et al. This feedback is clear and actionable, as it directs the authors to include comparisons to UNets to clarify the source of the performance boost. However, the comment could be more helpful if it provided specific guidance on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4 as it identifies a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It provides a detailed explanation of the computation complexity issue, specifically mentioning the calculation of all flipped previous layer outputs into the current layer in Algorithm 1. The comment explicitly suggests that a comparison of computation complexity should be included in the experiment part. This feedback is clear and provides a direct action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1\" and \"the experiment part,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of computation complexity and suggests that a comparison of computation complexity should be included in the experiment part. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed PSA method requires more computation than baselines and provides a specific explanation of the computation complexity issue in Algorithm 1. This detailed explanation supports the claim, making it 4. However, the comment could be strengthened by including specific examples or references to support the comparison of computation complexity with baselines. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It provides a detailed explanation of the computation complexity issue, specifically mentioning the calculation of all flipped previous layer outputs into the current layer in Algorithm 1. The comment also suggests that a comparison of computation complexity should be included in the experiment part. This feedback is clear and actionable, offering the authors a specific area to address and a concrete suggestion for improvement. By highlighting the computational complexity and suggesting a comparison, the comment empowers the authors to enhance the comprehensiveness and validity of their experimental results. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take, such as increasing the font size in figures 1 and 2, making the words in the grey box larger, and ensuring that \"V_mem, Th_i, U_i^t\" are not too small. It also suggests adding a \"table\" to compare the number of epochs and parameters with other stateoftheart Transformer designs. These suggestions are concrete and provide clear guidance on how to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 1\" and \"figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific feedback on font sizes and the clarity of certain elements, such as the grey box and labels like \"V_mem, Th_i, U_i^t.\" Additionally, it suggests improvements for the \"CTRL\" explanation and proposes a comparison with other stateoftheart Transformer designs using a table. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple claims and suggestions. The first part is a subjective opinion about the quality of the figures, which is not verifiable as it lacks specific evidence or reasoning. The second part suggests improvements, such as increasing font sizes and adding a table for comparison, which are factual and do not require verification. The third part critiques the lack of details in the comparison with other stateoftheart Transformer designs, which is a subjective claim that could be supported by examples or references. Overall, the comment is 4, as it provides some logical reasoning but lacks specific examples or references to fully substantiate the claims. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the visual presentation of the figures, suggesting improvements such as increasing font sizes and making certain labels larger. It also identifies a lack of detail in the comparison with other stateoftheart Transformer designs, recommending the inclusion of a table to emphasize the data and justify the improved accuracy. This feedback is clear and constructive, offering the authors concrete steps to enhance the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it provided additional suggestions or examples for the table or comparison. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to rewrite a specific sentence that is unclear. It provides a clear action for the authors to take, which is to rephrase the sentence to improve clarity. The feedback is direct and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific sentence that is unclear, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need to rewrite the sentence, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding a specific sentence in the paper. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific sentence that is unclear and requests the authors to rewrite it. This feedback is clear and actionable, as it directly points out a part of the paper that needs improvement and provides a specific task for the authors to complete. By addressing this issue, the authors can enhance the clarity and readability of their draft, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of the main contribution and questions the motivation behind the PBSD component, given that the paper is primarily motivated by supervised contrastive learning (DSCL). It suggests that the performance gain is mostly attributed to PBSD, but it does not provide explicit guidance on how the authors should address this issue or clarify the contribution. The comment implies that the authors should provide additional motivation or explanation for the PBSD component, but it does not specify what kind of motivation or explanation is needed. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the PBSD component in the context of a paper primarily motivated by supervised contrastive learning (DSCL). It references the ablation study to highlight the performance gain attributed to PBSD. However, the comment does not specify which part of the paper discusses the main contribution or the ablation study, making it weakly grounded. The comment is specific in its request for additional motivation for PBSD beyond improving discriminative representation on tail classes. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the PBSD component in the context of a paper primarily motivated by supervised contrastive learning (DSCL). It references the ablation study to highlight the performance gain attributed to PBSD, but it does not provide specific examples or detailed reasoning to support the claim that the motivation for PBSD is unclear. The comment lacks sufficient evidence or justification to fully substantiate the claim, making it 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the PBSD component in the context of a paper primarily motivated by supervised contrastive learning (DSCL). It points out that the performance gain is mostly attributed to PBSD, but the paper does not provide clear motivations for this component beyond improving discriminative representation on tail classes. This feedback is 3 as it identifies a potential area of confusion in the paper and prompts the authors to clarify the role and motivation of PBSD. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of alternative motivations. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the tester for the spread parameter and whether it immediately yields an (\u03f5, \u03b4)identity tester. It provides an example of how the tester might not handle (\u03c0, \u03d5) pairs where \u03d5 = \u03d50 but dK(\u03c00, \u03c0) is large. While the comment highlights a potential issue, it does not explicitly instruct the authors to address this concern or provide specific guidance on how to resolve it. The action is implicit and somewhat vague, as the authors can infer that they need to clarify or address the issue but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2,\" which allows the authors to accurately identify the part of the paper being addressed, likely referring to a specific section or part of the manuscript. It is also specific because it raises a question about the tester for the spread parameter and whether it immediately yields an (\u03f5, \u03b4)identity tester. The comment provides a specific example of how the tester might not handle certain pairs, which further clarifies the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the tester for the spread parameter and whether it immediately yields an (\u03f5, \u03b4)identity tester. It provides an example of how the tester might not handle (\u03c0, \u03d5) pairs where \u03d5 = \u03d50 but dK(\u03c00, \u03c0) is large. This example is a logical deduction based on the information provided, but it lacks specific references or detailed reasoning to fully substantiate the claim. The comment is 3 as it provides a clear example of the issue but could be strengthened with additional context or references to support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the tester for the spread parameter, specifically whether it immediately yields an (\u03f5, \u03b4)identity tester. It provides an example of how the tester might not handle (\u03c0, \u03d5) pairs where \u03d5 = \u03d50 but dK(\u03c00, \u03c0) is large. This feedback is 3 as it identifies a potential issue with the tester and prompts the authors to clarify or address this concern. However, the comment could be more helpful if it offered suggestions or guidance on how to resolve the issue or improve the tester. Overall, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the authors\" claim of using active learning in step 2 and whether the \"active learning pipeline\" method is the same as traditional active learning. It suggests that if the methods are not the same, the description could be misleading. However, the comment does not provide explicit guidance on how to address this issue or clarify the distinction between the two methods. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the description and potentially provide more information about the active learning pipeline. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the authors\" claim of using active learning in step 2 and whether the \"active learning pipeline\" method is the same as traditional active learning. It suggests that if the methods are not the same, the description could be misleading. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or figure, making it weakly grounded. The comment is specific in its questioning of the method\"s description, but without clear grounding, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" claim of using active learning in step 2 and whether the \"active learning pipeline\" method is the same as traditional active learning. The comment raises a concern about potential confusion in the description, suggesting that if the methods are not the same, the description could be misleading. However, the comment does not provide specific examples or references to support the claim, nor does it offer detailed reasoning or evidence to substantiate the concern. This makes the claim 3, as it highlights a potential issue but lacks sufficient detail to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the authors\" claim of using active learning in step 2, specifically questioning whether the \"active learning pipeline\" method is the same as traditional active learning. This prompts the authors to clarify their description and ensure that it accurately reflects their methodology. By pointing out this potential confusion, the comment encourages the authors to provide more detailed information about their active learning approach, which could enhance the clarity and transparency of their work. However, the comment could be more helpful if it provided specific suggestions on how to address the issue or offered examples of how to clarify the description. Overall, the comment is 3 as it identifies a potential area for improvement but lacks depth in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed method requires annotated labels for learning semantic tokens, which limits its application to supervised training. It implies that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment does not explicitly instruct the authors to implement a selfsupervised approach or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer the need for a different approach but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitation of the proposed method, which requires annotated labels for learning semantic tokens, thereby limiting its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment does not specify which part of the paper discusses the proposed method or the limitations of the current approach. Without explicit references to sections or specific elements of the paper, the authors may find it challenging to pinpoint the exact areas needing revision. The comment is specific in its suggestion for improvement but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the proposed method requires annotated labels for learning semantic tokens, limiting its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment does not provide specific examples, references, or detailed reasoning to support why a selfsupervised approach would be more appealing or how it could be implemented. The lack of supporting evidence or detailed justification makes the claim 3, as the authors would need to infer the potential benefits of a selfsupervised approach based on general knowledge. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation of the proposed method, which requires annotated labels for learning semantic tokens, thereby limiting its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. This feedback is 3 as it points out a potential limitation and offers a direction for improvement. However, it lacks specific guidance or suggestions on how to implement a selfsupervised approach or what benefits it might offer. While it provides some insight into the method\"s limitations, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides two explicit suggestions for improvement. First, it recommends adding a specific phrase to the abstract to enhance clarity, suggesting a change in wording to include a reference to the change in linear regions in output space. Second, it suggests including learning curves for all experiments, at least in an appendix. These suggestions are clear and concrete, giving the authors specific actions to take to improve their draft. The feedback is explicit and provides detailed guidance on how to implement the suggested changes, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, suggesting a change in the wording of \"attain greater expressivity\" to include a reference to the change in linear regions in output space after a citation. Additionally, it suggests including learning curves for all experiments, at least in an appendix. This provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests a change in the abstract to include a specific phrase related to the change in linear regions in output space after a citation. It also recommends including learning curves for all experiments, at least in an appendix. While the suggestion for the abstract is clear, the comment lacks specific reasoning or evidence to support why the current phrasing is insufficient or why the inclusion of learning curves is necessary. The claim is 3 as it provides a logical suggestion but lacks detailed justification or references to substantiate the need for these changes. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides two specific suggestions for improvement. First, it recommends a more detailed and specific way to express the concept of \"attain greater expressivity\" in the abstract, suggesting the inclusion of a reference to the change in linear regions in output space after a citation. This feedback is actionable and helps the authors enhance the clarity and precision of their abstract. Second, it suggests including learning curves for all experiments, at least in an appendix, which would provide valuable additional information for readers. This feedback is clear and actionable, offering the authors a concrete way to improve the comprehensiveness and clarity of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the paper\"s motivation and the practical application of the proposed method. It suggests that the paper should demonstrate the methodology\"s use in actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset. While the comment implies that the authors should provide more context and examples to clarify the paper\"s motivation and application, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer the need for additional examples but may not know exactly how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of clarity regarding the paper\"s motivation and the application of the proposed method. It also provides specific examples of how the methodology could be demonstrated, such as adapting a model trained on a synthetic dataset to a real dataset. This allows the authors to accurately identify the parts of the paper that need revision and understand what specific issues need to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s motivation is unclear and lacks a clear application of the proposed method. It questions the need for domain adaptation and suggests that demonstrating the methodology on actual tasks involving domain adaptation would be beneficial. The comment provides a logical reasoning by suggesting specific examples of how the methodology could be applied, such as adapting a model trained on a synthetic dataset to a real dataset. However, it lacks specific references or detailed examples to fully substantiate the claim. Therefore, the comment is 4, as it provides a clear direction for improvement but could benefit from more detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s motivation and application, questioning the relevance and usefulness of the proposed method. It highlights the need for clearer examples of how the methodology could be applied in realworld scenarios, such as domain adaptation. The suggestion to demonstrate the methodology\"s use on actual tasks involving domain adaptation, like adapting a model trained on a synthetic dataset to a real dataset, provides a concrete direction for improvement. This feedback is actionable and constructive, as it guides the authors to enhance the paper\"s applicability and relevance. However, the comment could be more helpful if it included specific examples or references to further support the suggestion. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the comparison against other models in the experiments is unclear due to the omission of value ranks for all models. It provides a clear action for the authors to take: they must compare the tensor completion results for all models with the same number of model parameters. The comment also suggests a method for computing the number of model parameters by adding the number of entries of all core tensors for each model. This feedback is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the comparison against other models in the experiments, specifically noting the omission of value ranks for all models. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed: comparing tensor completion results for all models with the same number of model parameters. The suggestion to compute the number of model parameters by adding the number of entries of all core tensors for each model provides concrete guidance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison against other models in the experiments is unclear due to the omission of value ranks for all models. It suggests that to show the superiority of TW over TT and TR, the authors should compare the tensor completion results for all models with the same number of model parameters. The comment provides a logical reasoning by explaining that the number of model parameters can be computed by adding the number of entries of all core tensors for each model. This reasoning is clear and provides a specific suggestion for improvement, making the claim 4. However, the comment could be strengthened by including specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental comparison, noting that the value of the used ranks for all models is omitted, making it impossible to conduct a fair comparison. It provides a clear and actionable suggestion for improvement by recommending that the authors compare the tensor completion results for all models with the same number of model parameters. This feedback is valuable as it highlights a critical aspect of the paper that needs attention and offers a specific way to address it. However, the comment could be more helpful if it included additional guidance on how to compute the number of model parameters or suggested specific models for comparison. Overall, the comment is 4, as it provides clear and actionable feedback that can significantly improve the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should include ATA in the comparison in Table 2, as it is better than FP according to the results in Table 1. This is an explicit action with clear guidance on what needs to be done to improve the draft. The comment provides a specific suggestion for enhancing the comparison, making it concrete and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"leave one out setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of comparison to \"ATA\" in Table 2, and suggests including it for a more convincing comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the proposed method should be compared to \"ATA\" in addition to \"+LFP\" in Table 2, as \"ATA\" is better than \"FP\" according to the results in Table 1. This claim is 3 as it provides a logical reasoning based on the results presented in the paper. However, it lacks specific examples or detailed comparisons to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparison in Table 2, noting that the proposed method is only compared to \"+LFP\" under the leave one out setting. It suggests that including ATA in the comparison would be more convincing, given that ATA is better than FP according to the results in Table 1. This feedback is clear and actionable, providing the authors with a specific suggestion to enhance the validity and comprehensiveness of their results. By addressing this point, the authors can strengthen their paper and improve its overall impact. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues, including a potential discrepancy in the normalization module between two versions, the need for standardization of pictograms in figures, and specific issues with Figure 4. It also mentions minor textual problems. While the comment identifies areas that need attention, it does not provide explicit instructions or detailed guidance on how to address these issues. The authors can infer that they need to clarify the normalization module, standardize pictograms, and resolve the confusion in Figure 4, but the comment lacks concrete steps or examples to follow. Therefore, the comment is 3, as it provides a general direction but lacks detailed guidance.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the normalization module, figures, and a particular page and equation. This allows the authors to accurately identify the sections being addressed. The comment is also specific because it details the issues with the normalization module, the need for standardization of pictograms in figures, and the confusion in Figure 4. Additionally, it mentions minor textual problems on page 4 after a specific equation. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several claims, including a potential discrepancy in the normalization module between two versions, the need for standardization of pictograms in figures, and specific issues with Figure 4. However, the comment lacks detailed justification or evidence to support these claims. It does not provide specific examples or references to substantiate the discrepancies or the need for standardization. The mention of minor textual problems is also not elaborated upon. Without additional context or evidence, the claims remain vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several issues that need attention, including a potential discrepancy in the normalization module between two versions, the need for standardization of pictograms in figures, and specific issues with Figure 4, such as overlapping symbols in the 0/50 latency range and 2.5/4.0 MAE. Additionally, it mentions minor textual problems, specifically on page 4 after a particular equation. While the comment highlights these areas for improvement, it does not provide detailed guidance or suggestions on how to address these issues. The feedback is 3 as it points out specific weaknesses, but it lacks depth and actionable advice, leaving the authors with a general understanding of what needs to be improved. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the theoretical part of the paper, specifically questioning how the proposed algorithm removes subdivision splines and whether it incurs extra computation costs. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should provide more detailed information about the algorithm and its computational costs. However, the comment lacks concrete details on how to implement this improvement, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"theoretical part\" of the paper, allowing the authors to accurately identify the section being addressed. It also specifies the issue by questioning the detailed explanation of how the proposed algorithm removes subdivision splines and whether it incurs extra computation costs. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the claim made by the authors regarding the removal of subdivision splines and the potential extra computation cost for space partition building. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the theoretical part of the paper, questioning the claim that the proposed algorithm removes subdivision splines and whether it incurs extra computation costs. This feedback is 3 as it points out a potential gap in the explanation of the algorithm, prompting the authors to clarify this aspect. However, the comment could be more helpful if it provided suggestions on how to address the issue or offered examples of how to explain the algorithm more clearly. Overall, the feedback is clear but incomplete, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and observations about the paper, including the potential benefits of outputside layers, the clarity of Figure 4, the presentation of Pixelshuffle details, and the use of pixelshuffle in the superresolution field. It also questions the dimensionality after upsampling in Figure 2 and notes the absence of limitations and societal impact discussions. While the comment identifies areas that need clarification or further explanation, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, leaving the authors to infer what needs to be addressed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and observations about specific parts of the paper, such as the outputside layers, Figure 4, the presentation of Pixelshuffle details, and the use of pixelshuffle in the superresolution field. It also questions the dimensionality after upsampling in Figure 2 and notes the absence of limitations and societal impact discussions. While the comment does not explicitly mention sections or figures, the authors can infer that it pertains to the methodology and results sections, providing some level of grounding. However, the comment is specific in detailing what needs to be addressed, such as the clarity of Figure 4 and the presentation of Pixelshuffle details. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and observations about the paper, including the potential benefits of outputside layers, the clarity of Figure 4, the presentation of Pixelshuffle details, and the use of pixelshuffle in the superresolution field. It also questions the dimensionality after upsampling in Figure 2 and notes the absence of limitations and societal impact discussions. However, the comment lacks specific evidence, examples, or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or supporting information renders the claims 1, as the authors are left without a clear path to address the concerns. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises several important points that could help the authors improve their draft. It questions the potential benefits of the outputside layers, which could lead to a more detailed explanation of the methodology. Additionally, it points out that Figure 4 is not clearly illustrated, suggesting that the authors should clarify this figure. The comment also questions the presentation of Pixelshuffle details and its relevance to the superresolution field, which could prompt the authors to provide more context or references. Furthermore, it notes the absence of discussions on limitations and potential negative societal impacts, which is a critical aspect of any research paper. While the comment identifies several areas for improvement, it could be more helpful if it provided specific suggestions or examples for addressing these issues. Overall, the feedback is 4 as it guides the authors toward enhancing the clarity and completeness of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the experimental methodology, specifically questioning the use of the 300WLP dataset in training the model. It points out that most baselines do not use this dataset, which could provide an unfair advantage to the proposed method. The comment implies that the authors should clarify whether 300WLP is used in all experiments and, if so, why it might be considered an unfair advantage. While the comment identifies an issue, it does not explicitly instruct the authors to clarify or address this point. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information about the experimental methodology. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the experimental methodology, specifically questioning the use of the 300WLP dataset in training the model. It points out that the paper initially states that 300WLP is used for training but later claims the same procedure is used as for the baselines. The comment asks if 300WLP is used in all experiments and whether this would provide an unfair advantage to the proposed method. This provides clear guidance on what needs to be clarified or addressed in the paper. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the experimental methodology, specifically questioning the use of the 300WLP dataset in training the model. It points out that the paper initially states that 300WLP is used for training but later claims the same procedure is used as for the baselines, which most do not use. The comment suggests that if 300WLP is used in all experiments, it could provide an unfair advantage to the proposed method. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that using 300WLP would be unfair. This makes the claim 3, as it provides a logical reasoning but requires further evidence or examples to fully substantiate the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental methodology, specifically questioning the use of the 300WLP dataset in training the model. It points out that the paper initially states that 300WLP is used for training but later claims the same procedure is used as for the baselines, which most do not use. The comment raises a concern that if 300WLP is used in all experiments, it could provide an unfair advantage to the proposed method. This feedback is clear and actionable, as it prompts the authors to clarify whether 300WLP is used in all experiments and to address the potential unfair advantage. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how to ensure fairness in the experimental setup. Overall, the comment is 4 as it directs the authors to a critical area that needs clarification and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the formulation introduced by the authors, suggesting that the observations might be aggregated by methods other than averaging, such as summation or populationweighted average. It also provides specific examples, like disease incident data being available in counts or rates per number of residents. While the comment identifies a potential limitation and provides examples, it does not explicitly instruct the authors to address this issue or suggest how to modify their formulation. The action is implicit and somewhat vague, as the authors need to infer that they should consider alternative aggregation methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (1)\" and \"the formulation introduced by the authors,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the formulation, pointing out that the observations might be aggregated by methods other than averaging, such as summation or populationweighted average, and provides specific examples like disease incident data. This level of detail helps the authors understand what needs to be addressed in their formulation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the formulation introduced by the authors assumes observations are obtained by averaging over the corresponding support, but suggests that other aggregation methods, such as summation or populationweighted average, might be more appropriate. The comment provides specific examples, like disease incident data being available in counts or rates per number of residents, to support the claim. This level of detail and reference to specific data types provides a clear rationale for the claim, making it 4. However, the comment could be strengthened by referencing the specific sections of the paper where these assumptions are made, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the formulation introduced by the authors, specifically regarding the assumption that observations are obtained by averaging over the corresponding support. It suggests that other aggregation methods, such as summation or populationweighted average, might be more appropriate, particularly in the context of disease incident data. The comment provides specific examples, like disease incident data being available in counts or rates per number of residents, which helps the authors understand the potential limitations of their formulation. However, the comment could be more helpful if it offered suggestions on how to address these limitations or provided examples of how other aggregation methods might be applied. Overall, the feedback is 3 as it highlights a specific area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a lack of mathematical definition in the architectural details of the model, specifically mentioning multihead attention. It also questions the split arrow in Figure 2, asking for clarification on whether the same vectors are used for keys and values. The comment explicitly suggests that a formal definition would be beneficial for readers. While the action is clear, the comment could be more actionable by providing specific guidance on how to present the mathematical definitions or clarify the figure. However, the authors know exactly what needs to be addressed, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"general architecture of the model\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of mathematical definition in architectural details, such as multihead attention, and questions the split arrow in Figure 2. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of mathematical definition in the architectural details of the model, specifically mentioning multihead attention. It questions the split arrow in Figure 2, asking for clarification on whether the same vectors are used for keys and values. The comment suggests that a formal definition would be beneficial for readers. While the comment identifies a potential issue, it does not provide specific examples or references to support the claim. The reasoning is logical, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of mathematical definition in the architectural details of the model, particularly regarding multihead attention. It provides a clear and actionable suggestion by asking for a formal definition of this component, which would enhance the readers\" understanding. Additionally, the comment raises a question about the split arrow in Figure 2, seeking clarification on the inputs for the attention layer. This feedback is detailed and constructive, offering the authors a clear path to improve the clarity and comprehensiveness of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the assumption that each individual\"s data is iid drawn from the same distribution, which is necessary for the proposed algorithm to work. The reviewer questions the justification of this assumption, suggesting that it may not hold in practice due to differences in users\" preferred emojis. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to justify or address the assumption, but without specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.1\" and \"Theorem 6\" and \"Theorem 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the assumption of iid data and how it affects the application of the theorems. The comment provides a detailed critique of the assumption and its implications, offering a clear direction for the authors to address the concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the assumption that each individual\"s data is iid drawn from the same distribution, which is necessary for the proposed algorithm to work. The reviewer questions the justification of this assumption, suggesting that it may not hold in practice due to differences in users\" preferred emojis. The comment provides a logical reasoning by pointing out the potential issue with the assumption and its impact on the application of the theorems. However, it lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to consider the justification of this assumption and its implications for the algorithm\"s applicability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the assumption that each individual\"s data is iid drawn from the same distribution, which is necessary for the proposed algorithm to work. The reviewer questions the justification of this assumption, suggesting that it may not hold in practice due to differences in users\" preferred emojis. This feedback is 3 as it highlights a critical assumption that may impact the applicability of the algorithm. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue or alternative approaches to justify the assumption. The feedback is clear but incomplete, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors consider making the policy nonfixed to allow for more complicated tasks, which would enable a comparison with a reinforcement learning algorithm baseline. This is an explicit action, as it clearly instructs the authors on what to do to improve their draft. The suggestion is also concrete, as it provides a specific direction for the authors to take, such as introducing more complex tasks and comparing with a reinforcement learning baseline. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors consider making the policy nonfixed to allow for more complicated tasks, which would enable a comparison with a reinforcement learning algorithm baseline. However, it does not specify which part of the paper this suggestion should be applied to, nor does it provide detailed guidance on how to implement this change. The authors can infer that it relates to the sections discussing policy and reinforcement learning, but the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the current setting is a subset of reinforcement learning with a fixed policy and proposes a way to make the policy nonfixed to allow for more complicated tasks. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or how it would enhance the paper. The suggestion lacks specific examples or detailed explanations, making it difficult for the authors to understand the rationale behind the recommendation. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a potential enhancement to the paper by proposing that the authors consider making the policy nonfixed to allow for more complicated tasks. This could enable a comparison with a reinforcement learning algorithm baseline, which could provide a more comprehensive evaluation of the work. However, the comment lacks specific guidance on how to implement this suggestion or what aspects of the policy should be made nonfixed. While it identifies a potential area for improvement, the feedback is somewhat vague and does not provide detailed actionable steps. Therefore, the comment is 3, as it offers a direction for improvement but requires further elaboration to be fully beneficial."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the comprehensiveness of the analyses of the method and experimental outcomes, noting that the experiments primarily focus on presenting results. It questions the extent to which the performance improvement claimed by the authors can be attributed to their method, given that it underperforms the baseline in some instances. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their analysis. The action is implicit and vague, as the authors are left to infer that they need to provide more comprehensive analyses and clarify the contribution of their method. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the comprehensiveness of the analyses of the method and experimental outcomes, specifically mentioning that the experiments focus on presenting results rather than providing a comprehensive analysis. It also questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. However, the comment does not specify which sections of the paper are lacking in analysis or provide specific examples of where the method underperforms the baseline. While the authors can infer that the comment relates to the experimental results and analysis sections, the lack of explicit references or detailed guidance makes it weakly grounded. The comment is specific in its critique of the analysis and the claim, but the authors may struggle to pinpoint the exact parts needing improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the analyses of the method and experimental outcomes are not comprehensive enough, particularly given that the authors\" method underperforms the baseline in some instances. It questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. However, the comment lacks specific examples or detailed reasoning to support the claim that the analyses are insufficient or that the performance improvement is questionable. Without additional evidence or references, the claim remains 3, as it provides a general critique but lacks concrete justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the comprehensiveness of the analyses in the paper, specifically noting that the experiments focus more on presenting results rather than providing a thorough analysis of the method and experimental outcomes. It also questions the extent to which the performance improvement claimed by the authors can be attributed to their method, given that it underperforms the baseline in some instances. This feedback is valuable as it highlights a critical area for improvement, encouraging the authors to provide more detailed analyses and clarify the contributions of their method. However, the comment could be more helpful if it offered specific suggestions on how to enhance the analysis or provide additional evidence to support the claims. Overall, the comment is 4, as it directs the authors to a key area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the literature review ignores several papers that are seemingly relevant, specifically mentioning VRMARINA and DASHAMVR. It suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not explicitly instruct the authors to include these papers in the literature review or provide specific guidance on how to incorporate them. The action is implicit and somewhat vague, as the authors can infer that they need to add these papers but are not given clear instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the next section\" and \"literature review,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies specific papers (VRMARINA and DASHAMVR) that are missing from the literature review and suggests that they satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. This provides clear guidance on what needs to be addressed in the literature review. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review ignores several relevant papers, specifically mentioning VRMARINA and DASHAMVR. It suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not provide detailed reasoning or evidence to support why these papers are relevant or how they satisfy Assumption 2. The reference to \"See Question\" implies that the reviewer is seeking clarification, but it does not provide sufficient justification for the claim. Therefore, the comment is considered 2, as it lacks specific examples or detailed reasoning to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the literature review, noting that it ignores several papers that are seemingly relevant, including VRMARINA and DASHAMVR. It suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. This feedback is clear and actionable, as it directs the authors to include these papers in the literature review, which could enhance the comprehensiveness and accuracy of their work. However, the comment could be more helpful if it provided specific guidance on how to incorporate these papers or why they are relevant. Overall, the comment is 4 as it highlights a significant gap in the literature review and offers a clear direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the presentation of the paper is difficult to follow for the reviewer, but it does not provide any specific guidance or suggestions on how the authors might improve the clarity or structure of their paper. Without explicit or implicit actions, the authors are left without a clear understanding of what changes they should make to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment states that the presentation of the paper is hard to follow for the reviewer, but it does not specify which part of the paper is causing this issue. The authors cannot confidently determine which sections or aspects of the paper are problematic, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide details on what aspects of the presentation are unclear or how they could be improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the presentation of the paper is hard to follow for the reviewer. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment indicates that the presentation of the paper is difficult to follow for the reviewer, which is a valid concern. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might improve the clarity or structure of their paper. Without detailed guidance or examples, the authors are left without a clear understanding of what changes they should make to address the issue. Therefore, the comment is 2, as it identifies a problem but does not offer any actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors provide a more detailed presentation of the compared models, specifically highlighting the differences between KVAE and the other models, DMM and DVBF. It also requests comments on the computation requirements of the three methods compared in Table 1. While the comment implies that the authors should provide more detailed information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional details about the computation requirements. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, namely, a more detailed presentation of the compared models, specifically highlighting the differences between KVAE and the other models, DMM and DVBF. Additionally, it requests comments on the computation requirements of the three methods compared in Table 1. This level of detail provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors provide more detailed information about the compared models, specifically highlighting the differences between KVAE and the other models, DMM and DVBF. The reviewer acknowledges a lack of familiarity with the compared models but provides some insight into their differences, such as the simplicity of KVAE due to linear state space transitions and the need for computation of timedependent LGSSM parameters. However, the comment lacks specific examples or references to support the claim that more detailed presentation is needed. This makes the claim 3, as it provides some context but requires further elaboration for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges a lack of familiarity with the compared models, DMM and DVBF, but highlights the need for a more detailed presentation of these models in comparison to KVAE. It provides specific insights into the differences between KVAE and the other models, such as the simplicity of KVAE due to linear state space transitions and the need for computation of timedependent LGSSM parameters. The comment also requests that the authors comment on the computation requirements of the three methods compared in Table 1. This feedback is clear and actionable, as it directs the authors to provide more detailed information about the compared models and their computational aspects. However, it could be more helpful if it included suggestions on how to present this information or what specific details to focus on. Overall, the comment is 4 as it provides valuable guidance for improving the clarity and comprehensiveness of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct additional experiments on different famous LLMs like LLaMA and Falcon, in addition to the ones already mentioned (T5, PaLM, and GPT series). While the comment implies that these additional experiments are necessary, it does not provide specific guidance on how to conduct them or which specific aspects of these models should be explored. The action is implicit and somewhat vague, as the authors can infer the need for more experiments but may not know exactly how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on different famous LLMs like LLaMA and Falcon, in addition to the ones already mentioned (T5, PaLM, and GPT series). However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in suggesting the need for more experiments, but it is 1, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should conduct additional experiments on different famous LLMs like LLaMA and Falcon, in addition to the ones already mentioned (T5, PaLM, and GPT series). The claim is based on the assumption that these additional experiments would provide a more comprehensive benchmark. However, the comment lacks specific reasoning or evidence to support why these particular models are necessary or how they would enhance the study. The suggestion is 3 as it provides a logical basis for expanding the scope of experiments, but it could be strengthened with more detailed justification or references to similar studies. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should conduct additional experiments on different famous LLMs like LLaMA and Falcon, in addition to the ones already mentioned (T5, PaLM, and GPT series). This feedback is clear and actionable, as it provides a specific direction for expanding the scope of the experiments to include more benchmark baselines. By doing so, the authors can gain a more comprehensive understanding of the influence of parameter size on benchmark scores. However, the comment could be more helpful if it included specific suggestions on which aspects of these models should be explored or how the experiments should be designed. Overall, the comment is 4 as it offers a clear and actionable suggestion for improving the study, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that besides the number of queries, the real search cost (e.g., in terms of GPU days) should be compared in Table 3. This is an explicit action that provides a clear direction for the authors to enhance their analysis by including additional metrics. The suggestion is concrete, as it specifies what needs to be added to the table, making it easy for the authors to implement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests comparing the real search cost, such as in terms of GPU days, in addition to the number of queries. This provides clear guidance on what needs to be addressed in the table. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that besides the number of queries, the real search cost (e.g., in terms of GPU days) should be compared in Table 3. This is a suggestion for improvement, but it does not contain a claim that requires verification. It is a request for additional information or analysis, which is factual and does not necessitate a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the analysis presented in Table 3. It recommends comparing the real search cost, such as in terms of GPU days, in addition to the number of queries. This feedback is actionable and offers a clear direction for enhancing the depth and comprehensiveness of the analysis. However, the comment could be more helpful if it explained why this comparison is important or how it would impact the understanding of the results. Despite this, the suggestion is valuable and provides a concrete step for the authors to take, making the comment 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the first quotation mark in the phrase \"for \"inbetween\" uncertainty\" should be a forward mark instead of a backward mark. This provides clear and direct guidance on how to correct the error, making the comment 5. The authors know exactly what needs to be done to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"for \"inbetween\" uncertainty,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error, which is the incorrect use of quotation marks, and provides the correct notation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement about the correct usage of quotation marks in the phrase \"for \"inbetween\" uncertainty.\" It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific typographical error in the paper, namely the incorrect use of quotation marks in the phrase \"for \"inbetween\" uncertainty.\" By pointing out this error, the comment provides clear and actionable feedback that allows the authors to make a precise correction, improving the accuracy and professionalism of their draft. This level of detail is valuable for authors seeking to refine their work, making the comment 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point raises several questions and suggestions for clarification regarding specific details in the paper. It asks for an explanation of what Omega is, suggests being more explicit about the OMD algorithm, and questions the link function and the specific theorem from reference 32 being referred to. These questions and suggestions provide clear and explicit actions for the authors to take, such as providing definitions, clarifying terminology, and specifying references. The feedback is concrete and directly guides the authors on how to improve their draft by addressing these specific points. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L178,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises several questions and suggestions for clarification, such as explaining what Omega is, being more explicit about the OMD algorithm, and specifying the link function and the theorem from reference 32. These details provide clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions and suggestions for clarification, such as asking for an explanation of what Omega is, being more explicit about the OMD algorithm, and specifying the link function and the theorem from reference 32. These questions are factual and do not contain subjective claims or opinions that require verification. They are requests for clarification or additional information, making the comment factual and descriptive. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by questioning the lack of clarity in the paper. It points out the need for explicit definitions, such as explaining what Omega is and being more specific about the OMD algorithm. Additionally, it raises questions about the link function and the theorem from reference 32 being referred to, which could help the authors clarify their work. This feedback is clear and direct, offering the authors concrete steps to improve the clarity and comprehensiveness of their draft. Therefore, the comment is rated as 5, as it effectively guides the authors in enhancing the clarity and precision of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges the usefulness of the sequence example at different steps of the paper but expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically the use of the Hamming distance over entire parts of the sequence. The reviewer suggests that this approach is not commonly seen and requests references to support this claim. While the comment implies that the authors should provide references to substantiate their claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors know they need to provide references but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Example 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the mention of a \"common\" practice in the context of CRF, specifically the use of the Hamming distance over entire parts of the sequence, and requests references to support this claim. The authors are provided with clear guidance on what needs to be addressed, making this comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically the use of the Hamming distance over entire parts of the sequence. The reviewer questions the validity of this claim, stating that they are only aware of works reporting the Hamming loss defined nodewise. The comment requests references to support the claim, which is a reasonable request for clarification. However, the comment does not provide any specific examples or references to substantiate the claim, making it 3. The authors would need to provide additional information or references to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the usefulness of the sequence example at different steps of the paper but expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically the use of the Hamming distance over entire parts of the sequence. The reviewer questions the validity of this claim, noting that they are only aware of works reporting the Hamming loss defined nodewise. The comment provides a specific area for improvement by requesting references to support the claim, which is a clear and actionable suggestion. However, the comment could be more helpful if it offered additional guidance on how to address the issue or suggested alternative approaches. Overall, the feedback is 4 as it identifies a potential weakness and provides a concrete step for the authors to take, but it could be more comprehensive with further elaboration."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests changing the name of the \"Evaluation\" element to \"Metrics\" to avoid confusion with the broader meaning of \"evaluation.\" It also implies that the corresponding sections could be removed and the metrics mentioned alongside the datasets or in table captions, as most metrics are standard practice. This feedback provides explicit actions for the authors to take, such as renaming the element and potentially restructuring the content. The suggestions are clear and concrete, making the comment 5.", "grounding_specificity_rationale": "The comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and implies that the corresponding sections could be removed or integrated into other parts of the paper. However, it does not specify which sections or parts of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a change in terminology and a potential restructuring of the content, but without explicit references to specific sections or elements, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests renaming the \"Evaluation\" element to \"Metrics\" to avoid confusion with the broader meaning of \"evaluation.\" It also implies that the corresponding sections could be removed and the metrics mentioned alongside the datasets or in table captions, as most metrics are standard practice. The comment provides a logical reasoning for the suggestion, which is based on the common understanding of the terms \"evaluation\" and \"metrics\" in the context of research papers. However, it lacks specific examples or references to support the claim that most metrics are wellknown and used as standard practice. Therefore, the comment is 4, as it provides a clear rationale but could benefit from additional evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the clarity and structure of the paper. It recommends renaming the \"Evaluation\" element to \"Metrics\" to avoid confusion with the broader meaning of \"evaluation.\" Additionally, it suggests removing the corresponding sections and integrating the metrics into the datasets or table captions, as most metrics are standard practice. This feedback is specific and offers concrete steps for the authors to enhance the organization and readability of their work. By addressing these suggestions, the authors can improve the clarity and effectiveness of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to use more objective terms instead of \"remarkable\" when describing the accuracy improvement. It also provides a specific suggestion to characterize the improvement, noting that while it is present, it might be difficult to label as \"remarkable\" due to the squished axes. This feedback is clear and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line number, \"218,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on using more objective terms instead of \"remarkable\" to describe the accuracy improvement. Additionally, it offers a suggestion to characterize the improvement, noting the squished axes. This level of detail helps the authors understand what needs to be addressed and how to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the term \"remarkable\" is subjective and should be replaced with more objective terms. The reviewer provides a logical reasoning by noting that the improvement is \"definitely there\" but might not be considered remarkable due to the squished axes. This reasoning is clear and provides a basis for the suggestion, making the claim 4. However, the comment could be strengthened with specific examples or references to support the claim about the use of \"remarkable\" being subjective. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting the use of more objective terms instead of \"remarkable\" to describe the accuracy improvement. It also offers a constructive critique by pointing out that the axes are squished, which might make it difficult to characterize the improvement as remarkable. This feedback is clear and helps the authors refine their language and presentation, making it 4. However, it could be more helpful if it included suggestions on how to better present the data or axes to enhance clarity. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights an issue with the synthesized results for UCF101, noting inconsistent motion, changing color, or objects disappearing over time. It suggests that it would be interesting to see videos with a longer duration by running the LSTM over many time steps. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how to address the issue or what specific changes should be made to the experiments. The suggestion is implicit and somewhat vague, as it lacks concrete steps for the authors to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"UCF101,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the synthesized results, such as inconsistent motion, changing color, or objects disappearing over time. The comment suggests exploring videos with longer durations by running the LSTM over many time steps. This provides clear guidance on what needs to be addressed and how to improve the results. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the results of the paper, specifically mentioning inconsistent motion, changing color, or objects disappearing over time in the synthesized results for UCF101. It suggests that the results could be improved by running the LSTM over many time steps to handle longer video sequences. However, the comment lacks specific examples or detailed reasoning to support the claim, making it 3. The authors would need to infer the exact issues and how they could be addressed, which adds to the complexity of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the synthesized results for UCF101, noting inconsistencies in motion, color changes, or objects disappearing over time. It suggests that exploring videos with longer durations by running the LSTM over many time steps could be beneficial. This feedback is clear and actionable, as it points out a particular area for improvement and provides a concrete suggestion for enhancing the results. However, the comment could be more helpful if it offered additional guidance on how to implement this suggestion or what specific metrics or evaluations could be used to assess the improvement. Overall, the comment is 4 as it provides valuable insights for the authors to consider in refining their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the numerical evaluation, specifically that it is not fully convincing due to the use of synthetic data and an unfair comparison with a method designed for a more complex problem. However, it does not provide explicit guidance or suggestions on how the authors might address these issues. The comment implies that the authors should consider using real data or adjusting their comparison, but it does not specify which data or comparison would be more appropriate. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the numerical evaluation and the comparison with a specific reference, 5, which is designed for a more complex problem. However, it does not specify which part of the paper discusses the numerical evaluation or the comparison, making it weakly grounded. The comment is specific in pointing out the issue with the comparison and the use of synthetic data, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the numerical evaluation is not fully convincing due to the use of synthetic data and an unfair comparison with a method designed for a more complex problem. The reviewer provides a logical reasoning by pointing out the difference in the complexity of the problems addressed by the two methods, which supports the claim. However, the comment could be strengthened by providing specific examples or references to further substantiate the claim. Overall, the claim is 4, as it provides a clear rationale but lacks detailed evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the numerical evaluation, noting that it is not fully convincing due to the use of synthetic data. It also points out that the comparison with another method, 5, is not fair because it is designed for a more complex problem. This feedback is valuable as it highlights a critical weakness in the evaluation process and suggests that the authors should consider using real data or adjusting their comparison to make it more meaningful. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of alternative approaches. Despite this, the comment is 4 as it directs the authors to a key area for improvement, making it a 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors studied the effect of using numbers of bits in logits against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness against a more powerful adversary, implying that this experiment could strengthen the paper. However, the comment does not explicitly instruct the authors to conduct this experiment or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors can infer that they might need to conduct this experiment but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the study of numbers of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness against a more powerful adversary. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the experimental section, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in its suggestion to explore this aspect, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the authors studied the effect of using numbers of bits in logits against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness against a more powerful adversary, implying that this experiment could strengthen the paper. However, the comment does not provide any evidence, reasoning, or references to support this claim. The lack of supporting information makes it difficult for the authors to understand the basis of the suggestion or to verify the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about whether the authors have explored the effect of using numbers of bits in logits against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness against a more powerful adversary, implying that this experiment could strengthen the paper. While the comment identifies a potential area for exploration, it does not provide specific guidance or suggestions on how to conduct this experiment or what specific aspects to focus on. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, making it less comprehensive than it could be. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point notes that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on what specific aspects of the refinement should be focused on or how the authors might improve the performance. As a result, the comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the observed performance enhancements are modest, implying that there is room for further refinement. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what aspects of the performance could be refined. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what kind of refinement is needed or how it could be achieved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the observed performance enhancements are \"somewhat modest,\" suggesting that there is room for further refinement. However, the comment lacks specific examples, data, or references to support this claim. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment notes that the observed performance enhancements are modest, suggesting that there is room for further refinement in the future. While this observation highlights an area for potential improvement, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might enhance the performance or what specific aspects could be refined. Without detailed feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take. It instructs them to provide references for specific passages in Section 3.2 and to clarify the meaning of \"MLP\" in Figure 2. These actions are clear and direct, leaving no ambiguity about what needs to be done. The authors know exactly how to apply these suggestions to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2, lines 230234 and 234235,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by requesting references for two passages and asking for clarification on \"MLP\" in Figure 2. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual requests for clarification and references, which do not contain subjective opinions, judgments, or suggestions that require verification. It is purely descriptive and does not make any claims that need to be substantiated. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas in the paper that require improvement. It points out the need for references in Section 3.2, which is a clear and actionable suggestion for enhancing the credibility and transparency of the work. Additionally, it raises a question about the meaning of \"MLP\" in Figure 2, prompting the authors to clarify this point. However, the comment could be more helpful if it provided additional context or suggestions on how to address these issues. Overall, the feedback is clear and actionable, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between Equation 9 and Figure 1, suggesting that the output patches may not be cropped parts of the input image but rather masked versions of the input image with most pixels being black. The reviewer questions the correctness of this interpretation and suggests that Figure 1 might be misleading. Additionally, the reviewer proposes an alternative approach, suggesting that zooming on the region of interest using bilinear sampling could provide better results. While the comment identifies a potential issue and offers a suggestion, it does not provide explicit instructions on how to address the discrepancy or implement the suggested alternative. The action is 3 as it provides a clear direction for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"eq. 9\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the discrepancy between the equation and the figure, and questions the interpretation of the output patches. Additionally, it suggests an alternative approach using bilinear sampling. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a discrepancy between Equation 9 and Figure 1, questioning the interpretation of the output patches. It suggests that the output patches might not be cropped parts of the input image but rather masked versions of the input image with most pixels being black. The reviewer questions the correctness of this interpretation and suggests that Figure 1 might be misleading. Additionally, the reviewer proposes an alternative approach using bilinear sampling. While the comment raises a valid point about the discrepancy, it lacks specific references or detailed reasoning to fully substantiate the claim. The suggestion for an alternative approach is also not fully elaborated. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to be fully supported.", "helpfulness_rationale": "The review comment identifies a discrepancy between Equation 9 and Figure 1, questioning the interpretation of the output patches. It suggests that the output patches might not be cropped parts of the input image but rather masked versions of the input image with most pixels being black, which could make Figure 1 misleading. The reviewer also proposes an alternative approach using bilinear sampling, which could potentially provide better results. This feedback is clear and actionable, as it highlights a specific issue that needs clarification and offers a constructive suggestion for improvement. However, it could be more helpful if it provided additional context or examples to support the proposed alternative approach. Overall, the comment is 4, as it directs the authors to a critical area that requires attention and offers a potential solution, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests deleting the word \"Discussion\" from a specific sentence on page 5. This is an explicit action with clear instructions on what the authors should do to improve their draft. The comment is concrete, as it specifies the exact change needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Pg.5\" and the specific sentence, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the statement about training time reduction has not been revisited in the Discussion section, and suggests deleting the word \"Discussion\" from the sentence. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the statement about training time reduction not being as drastic as parameter reduction is not supported by the Discussion section. The reviewer implies that the statement should be deleted because it is not revisited in the Discussion. However, the comment does not provide any specific reasoning or evidence to support why the statement is incorrect or why it should be deleted. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the text on page 5, where it mentions that the training time reduction is less drastic than the parameter reduction. The reviewer points out that this statement is not revisited in the Discussion section, suggesting that the word \"Discussion\" should be deleted. While the comment highlights a potential inconsistency or redundancy in the text, it does not provide any deeper analysis or suggestions for improvement. The feedback is 3 as it directs the authors to a specific area for revision, but it lacks depth and actionable guidance to fully address the issue. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the font size in Figure 6 is too small, providing a clear and direct action for the authors to take. This feedback is specific and actionable, as it instructs the authors to adjust the font size in Figure 6 to make it more readable. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the font size being too small. This provides clear guidance on what needs to be addressed to improve the figure\"s readability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement about the font size in Figure 6 being too small. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment is brief and points out a specific issue with the font size in Figure 6, indicating that it is too small. While it identifies a potential problem with the figure\"s readability, it lacks depth and does not provide any suggestions or guidance on how to address the issue. The authors are left with a clear problem to fix but without any actionable advice on how to improve the figure. Therefore, the comment is 3, as it highlights a specific issue but does not fully support the authors in resolving it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. This is an explicit action with concrete guidance on how to improve the paper by suggesting a specific area of focus. The comment provides a clear direction for the authors to enhance their work by addressing the issue of interprocess communication and providing examples of relevant problems. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction and the second paragraph, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the lack of clarity in the paper\"s goal and the examples provided, particularly regarding the relevance of the paper\"s results to samplingbased Bayesian methods. The comment further suggests focusing on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the examples provided in the paper do not convincingly demonstrate the need for interprocess communication, particularly mentioning the second paragraph where samplingbased Bayesian methods are discussed. The reviewer suggests that the paper\"s results are irrelevant to these methods, which are already embarrassingly parallel. The comment further suggests focusing on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. While the comment provides some reasoning, it lacks specific examples or detailed justification to fully support the claim. The suggestion to focus on different types of problems is a logical step, but the comment could be strengthened with more detailed reasoning or references. Therefore, the claim is 3, as it provides a basis for the suggestion but requires more elaboration to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the examples provided in the introduction do not convincingly demonstrate the need for interprocess communication. It suggests that the authors focus on problems where the loss function does not decompose as the sum of sample losses, such as Hogwild, to better illustrate the relevance of their work. This feedback is clear and actionable, providing the authors with a concrete direction to enhance the clarity and relevance of their paper. However, the comment could be more helpful if it included specific examples or further elaboration on how to apply the suggested focus. Overall, the comment is 4 as it offers a valuable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should compare their model, CPEF, with another pretrained model, such as ExpertBert, to demonstrate the advantages of its pretraining module design. This recommendation is clear and provides a specific action for the authors to take, ensuring that the comparison is fair and highlights the innovative aspects of CPEF. The comment is 5 as it gives precise guidance on how to improve the draft by suggesting a specific alternative model for comparison. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"line 529lin534,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison between CPEF and PMEF, noting that PMEF lacks a pretraining module and suggesting a comparison with ExpertBert to showcase the advantage of CPEF\"s pretraining module design. This provides clear guidance on what needs to be addressed to ensure fairness in the comparison. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison between CPEF and PMEF in Figure 3 is unfair because PMEF lacks a pretraining module. The reviewer suggests comparing CPEF with another pretrained model, such as ExpertBert, to demonstrate the advantage of CPEF\"s pretraining module design. This claim is 3 as it provides a logical reasoning for the unfair comparison and suggests an alternative comparison that could address the issue. However, the comment lacks specific examples or references to support the claim fully, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparison in Figure 3, noting that the comparison between CPEF and PMEF is unfair because PMEF lacks a pretraining module. It provides a clear and actionable suggestion to address this issue by recommending a comparison with another pretrained model, such as ExpertBert, to showcase the advantage of CPEF\"s pretraining module design. This feedback is valuable as it highlights a critical aspect of the paper that needs improvement and offers a concrete way for the authors to enhance their draft. However, the comment could be more helpful if it provided additional context or examples of how this comparison could be conducted. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a specific issue with the hyperlinks for footnotes 3 and 4, indicating that they do not work. However, it does not provide any guidance or suggestions on how to resolve this issue or what steps the authors should take to fix the problem. The comment lacks explicit or implicit actions, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"footnote 3 and 4,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue with the hyperlinks not working. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement about the functionality of hyperlinks for footnotes 3 and 4. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment identifies a specific issue with the hyperlinks for footnotes 3 and 4, indicating that they do not work. While this is a factual observation, it does not provide any guidance or suggestions on how to resolve the issue or improve the draft. The lack of actionable feedback or suggestions makes the comment 2, as it does not offer any direction for the authors to address the problem. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific examples, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. While the comment implies that these changes are necessary, it does not explicitly instruct the authors to make these revisions. The action is implicit and somewhat vague, as the authors need to infer the specific changes required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific examples, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The mention of \"section 2\" and \"Label Embeddings\" allows the authors to identify the parts of the paper being addressed, making the comment fully grounded. The comment is also specific as it details what needs to be addressed, namely the need for a better formalization of the architecture and clarification of the Label Embeddings. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific examples, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The comment also points out a potential misunderstanding in the figure regarding Label Embeddings. While the comment identifies areas for improvement, it does not provide detailed reasoning or evidence to support the claim that the current discussion is unclear. The suggestion for improvement is logical, but the lack of specific examples or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific examples, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The comment also points out a potential misunderstanding in the figure regarding Label Embeddings, which could be misleading. By offering these detailed suggestions, the comment helps the authors identify areas for improvement and provides actionable feedback to enhance the clarity and accuracy of their work. However, the comment could be more helpful if it included additional guidance on how to formalize the architecture or clarify the Label Embeddings. Overall, the feedback is 4 as it directs the authors to specific parts of the paper that need revision, but it could be more comprehensive with further details. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the confusion between uncertainty calibration and temperature calibration, specifically regarding the regularization term H. It points out that the training regularization term requires temperature calibration, yet temperature calibration is applied after training. The reviewer asks the authors to clarify this point. Additionally, the comment suggests that reducing entropy makes predictions more confident, which contradicts the paper\"s motivation to calibrate networks that are already overconfident. The feedback is explicit in asking for clarification and provides a specific issue to address, making it 4. The authors know exactly what needs to be clarified and can take concrete steps to address the confusion and the contradiction in the paper\"s motivation. Therefore, this comment is rated as 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (155160) and sections (lines 133136) of the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue of confusion regarding the relationship between uncertainty calibration and temperature calibration, particularly with the regularization term H. The comment provides clear guidance on what needs to be clarified, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the confusion between uncertainty calibration and temperature calibration, specifically regarding the regularization term H. It points out that the training regularization term requires temperature calibration, yet temperature calibration is applied after training. The comment also suggests that reducing entropy makes predictions more confident, which contradicts the paper\"s motivation to calibrate networks that are already overconfident. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to delve deeper into the paper to understand the exact nature of the confusion and the implications of the regularization term. Therefore, the comment is 3, as it provides a basis for further investigation but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the relationship between uncertainty calibration and temperature calibration, specifically with the regularization term H. It points out that the training regularization term requires temperature calibration, yet temperature calibration is applied after training, which could be confusing. Additionally, the comment highlights a contradiction between the effect of reducing entropy, which makes predictions more confident, and the paper\"s motivation to calibrate networks that are already overconfident. The reviewer provides specific lines of the paper where these issues are discussed, allowing the authors to clarify these points. This feedback is 4 as it identifies specific areas of confusion and provides clear guidance on how to address them, enabling the authors to improve the clarity and coherence of their draft. However, it could be more helpful if it offered suggestions on how to resolve the contradictions or clarify the relationships between the concepts. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide an intuitive explanation of the linear program in Theorem 3, specifically asking for clarification on the objective and constraints in equation (3). This feedback is clear and direct, giving the authors a concrete action to take to improve their draft. The comment provides specific guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: providing an intuitive explanation of the linear program, specifically focusing on the objective and constraints in equation (3). This level of detail guides the authors on what aspects of the theorem require further clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the linear program in Theorem 3 should be explained intuitively, specifically asking for clarification on the objective and constraints in equation (3). This is a request for clarification rather than a claim, as it does not express an opinion or judgment. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the authors can improve their draft by suggesting that the linear program in Theorem 3 needs an intuitive explanation. It specifically asks for clarification on the objective and constraints in equation (3), providing clear guidance on what the authors should focus on to enhance the reader\"s understanding. This feedback is actionable and constructive, as it directs the authors to a particular aspect of their work that requires further elaboration. However, the comment could be more helpful if it offered suggestions on how to present this explanation or provided examples of intuitive explanations. Overall, the comment is 4, as it effectively points out a critical area for improvement and offers a clear direction for enhancement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the FLOT cost matrix in Algorithm 1 is not defined. This provides a clear and direct action for the authors to take, which is to define the FLOT cost matrix in the algorithm. The comment is explicit and concrete, as it specifies exactly what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by stating that the FLOT cost matrix is not defined. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement indicating that the FLOT cost matrix in Algorithm 1 is not defined. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and direct, pointing out a specific issue with the paper: the FLOT cost matrix in Algorithm 1 is not defined. This feedback is actionable and provides a clear direction for the authors to improve their draft by defining the missing matrix. However, the comment could be more helpful if it offered suggestions on how to define the matrix or why it is important for the algorithm. Despite this, the comment is 4 as it effectively identifies a critical gap in the paper and guides the authors toward a necessary improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the convergence of the bound in Theorem 2, Eq. (30), specifically asking if it converges to 0 as T goes to infinity. It provides a comparison with a similar bound in Grunewalder et al, 2010, Eq. (27), which is known to converge to 0. The reviewer suggests that the authors should prove whether the second term in Eq. (30) also converges to 0. This feedback is explicit in its request for proof and provides a clear direction for the authors to address the issue. The action is concrete, as it specifies what needs to be proven, making it 5. Therefore, the comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 2, Eq. (30)\" and \"Eq. (27)\" from Grunewalder et al, 2010, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of convergence and asks the authors to prove whether the second term in Eq. (30) converges to 0. The comment provides a clear direction for the authors to address the question, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the convergence of the bound in Theorem 2, Eq. (30), specifically asking if it converges to 0 as T goes to infinity. It provides a comparison with a similar bound in Grunewalder et al, 2010, Eq. (27), which is known to converge to 0. The reviewer notes that the first term in Eq. (30) converges to 0 but questions the convergence of the second term. This claim is 3 as it provides a logical basis for the question and references a similar work for context. However, it lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the convergence of the bound in Theorem 2, Eq. (30), as T goes to infinity. It provides a comparison with a similar bound in Grunewalder et al, 2010, Eq. (27), which is known to converge to 0. The reviewer notes that the first term in Eq. (30) converges to 0 but questions the convergence of the second term. This feedback is clear and actionable, as it prompts the authors to address a potential gap in their proof or analysis. By asking the authors to prove the convergence of the second term, the comment provides a specific direction for improvement, making it 4. However, it could be more helpful if it offered suggestions on how to approach the proof or provided additional context. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and concerns about the clarity and implementation of Algorithm 2. It questions whether it is possible to update one node based on results from multiple connected nodes, points out that \"avg\" is computed but not used, and asks for clarification on what \"j\" and \"i\"\" refer to. While the comment identifies areas that need clarification, it does not provide explicit instructions or concrete steps for the authors to follow. The authors are left to infer that they need to clarify these aspects, but the comment lacks specificity and detail on how to address these issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several specific concerns about Algorithm 2, including the computation of \"avg\" and the use of \"j\" and \"i\"\". It also questions the possibility of updating one node based on results from multiple connected nodes. However, the comment does not explicitly mention which part of the paper discusses Algorithm 2, making it weakly grounded. The authors can infer that it relates to the algorithmic sections, but this inference is not as direct as it could be. The comment is specific in detailing what needs to be clarified or addressed, such as the use of \"avg\" and the meaning of \"j\" and \"i\"\". Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and concerns about Algorithm 2, specifically regarding the computation of \"avg\" and the use of \"j\" and \"i\"\". However, it does not provide any supporting evidence, reasoning, or references to justify these claims. The lack of detailed explanation or examples makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several specific concerns about Algorithm 2, including the computation of \"avg\" and the use of \"j\" and \"i\"\". It also questions the possibility of updating one node based on results from multiple connected nodes. While the comment identifies areas that need clarification, it lacks depth and does not provide detailed guidance on how to address these issues. The authors are left with a general understanding of what needs improvement but without specific steps to take. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the accuracy drop in Figure 5, specifically asking if it is due to overfitting. While it prompts the authors to consider the potential cause of the accuracy drop, it does not provide explicit guidance on how to address this issue or what steps to take to investigate further. The action is implicit and somewhat vague, as the authors are left to infer that they should explore the possibility of overfitting and potentially conduct additional analysis or experiments to clarify the reason for the accuracy drop. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a clear question about the accuracy drop after a certain order and suggests a possible reason, overfitting. This provides the authors with a clear direction on what needs to be addressed or clarified in their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the accuracy drop in Figure 5, specifically asking if it is due to overfitting. It does not contain a claim or opinion that requires verification. It is a request for information or clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the accuracy drop observed in Figure 5, asking if it is due to overfitting. While it prompts the authors to consider a potential explanation for the observed phenomenon, it lacks depth and does not provide any suggestions or guidance on how to investigate or address the issue. The comment is 3 as it identifies a potential area of concern, but it does not offer actionable advice or insights that could lead to significant improvements in the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify how they handle comparisons between episodes of different lengths in the equation between lines 282 and 283. It also provides specific details about the method used, which is padding the shorter sequence by replicating its last state, and notes the potential issue with the lack of a normalization factor of 1/T. The comment suggests that these decisions should be explained to readers without requiring them to check the code. This feedback is clear and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the equation between lines 282 and 283,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of handling comparisons between episodes of different lengths and suggests that the authors should explain how they handle this in the equation. Additionally, it provides specific details about the method used, such as padding the shorter sequence by replicating its last state, and notes the potential issue with the lack of a normalization factor of 1/T. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the handling of comparisons between episodes of different lengths in the equation between lines 282 and 283. It provides specific details about the method used, such as padding the shorter sequence by replicating its last state, and notes the potential issue with the lack of a normalization factor of 1/T. This information is supported by the reviewer\"s observation of the code, which adds a level of verification. However, the comment could be strengthened by providing more detailed reasoning or references to similar practices in the field. Overall, the claim is 4, as it provides a clear explanation of the issue but lacks comprehensive evidence or references to fully substantiate the critique. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper regarding the handling of comparisons between episodes of different lengths in the equation between lines 282 and 283. It provides detailed feedback by explaining the method used, which involves padding the shorter sequence by replicating its last state, and notes the potential issue with the lack of a normalization factor of 1/T. This feedback is actionable as it suggests that the authors should clarify this aspect in the paper to ensure readers understand the methodology without needing to check the code. The comment is clear and provides specific guidance, making it 5 for the authors to improve their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the absence of Vision Transformer in the experiment, noting its importance as a stateoftheart model in image classification. It also questions whether the pruning strategy would differ in selfattention layers for larger datasets like ImageNet. While the comment highlights a potential gap in the study, it does not provide explicit guidance on how the authors should address this issue or conduct further experiments. The action is implicit and somewhat vague, as the authors need to infer that they should consider including Vision Transformer and exploring its impact on larger datasets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experiment section, specifically mentioning the absence of Vision Transformer, an important stateoftheart model in image classification. It questions whether the pruning strategy would differ in selfattention layers for larger datasets like ImageNet. This provides clear guidance on what needs to be addressed in the experiment section, making the comment fully grounded. The comment is also specific as it identifies a particular model and a specific aspect of the experiment that needs further exploration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the absence of Vision Transformer in the experiment, noting its importance as a stateoftheart model in image classification. It questions whether the pruning strategy would differ in selfattention layers for larger datasets like ImageNet. The comment provides a logical reasoning by pointing out the omission of a relevant model and its potential impact on the study. However, it lacks specific references or detailed examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or references to be fully convincing.", "helpfulness_rationale": "The review comment identifies a significant gap in the experiment by noting the absence of Vision Transformer, an important stateoftheart model in image classification. It questions whether the pruning strategy would differ in selfattention layers for larger datasets like ImageNet. This feedback is valuable as it highlights a potential limitation in the study and prompts the authors to consider including this model in their experiments. However, the comment could be more helpful if it provided specific suggestions on how to incorporate Vision Transformer or what aspects of the pruning strategy might be affected. Despite this, the comment is 4 as it directs the authors\" attention to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies several issues with the figures in the paper, specifically mentioning that the text is too small, the inputs and outputs for each task are not clearly explained, and the captions are not selfcontained. It also notes that it is difficult to link the captions to specific parts of the main text. This feedback provides clear and concrete actions for the authors to take, such as increasing the font size of the text in the figures, clarifying the inputs and outputs for each task, and ensuring that the captions are selfcontained and linked to relevant parts of the main text. The explicit nature of the actions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.1 to Fig.3,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also specifies the issues with the figures, such as the small text size, unclear inputs and outputs, and nonselfcontained captions. Additionally, it highlights the difficulty in linking the captions to specific parts of the main text. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figures 1 to 3 are difficult to parse due to small text size, unclear inputs and outputs, and nonselfcontained captions. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues effectively. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies specific issues with the figures in the paper, noting that the text is too small, the inputs and outputs for each task are not clearly explained, and the captions are not selfcontained. It also points out the difficulty in linking the captions to certain parts of the main text. This feedback is clear and actionable, as it provides concrete suggestions for improvement, such as increasing the font size of the text in the figures and clarifying the inputs and outputs for each task. By addressing these issues, the authors can enhance the readability and comprehensibility of their figures, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the continuous diffusion model (GDSS) should be compared as a baseline in Table 3, given its performance in Table 2. It also mentions recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could be used as a baseline. This feedback provides a clear and explicit action for the authors to take, which is to include GDSS as a baseline in Table 3 and consider the recent work as a potential baseline. The suggestion is concrete and directly actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of comparing the continuous diffusion model (GDSS) as a baseline in Table 3, given its performance in Table 2. Additionally, it provides a suggestion to consider recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the continuous diffusion model (GDSS) outperforms the discrete diffusion model (DiGress) in Table 2 and suggests that GDSS should be compared as a baseline in Table 3. The comment also references recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could be used as a baseline. This provides some justification for the claim, as it references specific models and recent work. However, the comment could be strengthened by providing more detailed comparisons or references to support the claim. Therefore, the comment is 4, as it provides a solid foundation for the claim but could benefit from additional evidence or examples.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by pointing out that the continuous diffusion model (GDSS) outperforms the discrete diffusion model (DiGress) in Table 2. It suggests that GDSS should be compared as a baseline in Table 3, which is a conditional generation task. Additionally, the comment references recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS, offering a potential baseline for comparison. This feedback is clear and provides the authors with a concrete suggestion for improving their draft by expanding the comparison to include GDSS as a baseline. The inclusion of a specific reference to recent work adds depth to the suggestion, making the comment 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests replacing \"t\" with the size of \"T\" in the histogram intersection kernel for clarity. This is an explicit action that provides a clear direction for the authors to improve their draft. The comment also explains the reasoning behind the suggestion, which is that allowing \"t\" to be arbitrary does not add value. This level of detail makes the action concrete and easy for the authors to implement. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"histogram intersection kernel,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests replacing \"t\" with the size of \"T\" for clarity, providing a clear and actionable recommendation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests replacing \"t\" with the size of \"T\" in the histogram intersection kernel for clarity. The reviewer provides a logical reasoning for this suggestion, stating that allowing \"t\" to be arbitrary does not add value. However, the comment lacks specific examples or references to support why this change would improve clarity or how it aligns with best practices in the field. While the reasoning is clear, the absence of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the histogram intersection kernel by recommending the replacement of \"t\" with the size of \"T.\" This feedback is actionable and clear, offering a direct way for the authors to enhance the readability and precision of their work. However, the comment could be more helpful if it explained why this change is necessary or how it would impact the understanding of the kernel. Despite this, the suggestion is valuable and provides a concrete step for the authors to take, making the comment 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides several explicit actions for the authors to take, including correcting grammatical errors, ensuring consistency in terminology, and correcting formatting issues in tables and references. Each of these actions is concrete and directly stated, leaving no ambiguity for the authors on what needs to be done. The comment is 5 as it provides clear and specific instructions for improvement, allowing the authors to make precise changes to their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and sections of the paper, allowing the authors to accurately identify the parts that need attention. It is also specific because it details the issues, such as grammatical errors, inconsistencies in terminology, and formatting errors in tables and references. The comment provides clear guidance on what needs to be corrected, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements and corrections, such as grammatical errors, inconsistencies in terminology, and formatting issues. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a list of specific corrections and improvements that need to be made to the manuscript. It addresses grammatical errors, inconsistencies in terminology, and formatting issues in tables and references. Each point is clear and actionable, allowing the authors to make precise changes to their draft. However, the comment could be more helpful if it offered additional context or explanations for why these corrections are important or how they might impact the overall quality of the paper. Despite this, the feedback is 4 as it provides concrete steps for improvement, making it a valuable resource for the authors. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides several explicit suggestions for improving the clarity and readability of the paper. It suggests spelling out \"F.L.T.R\" in figure 4, addressing the issue of small text in figure 1, and recommending notation and figure crossreferencing. These suggestions are concrete and provide clear actions for the authors to take, ensuring they know exactly what changes to make. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"figure 4,\" \"figure 1,\" and the use of \"M and N\" without definition. This allows the authors to accurately identify the sections being addressed. The comment is also specific because it details the issues with notation, suggests spelling out \"F.L.T.R\" in figure 4, and recommends improving the visibility of figure 1 text and crossreferencing notation and figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple suggestions for improving the clarity and readability of the paper, including clarifying notation, spelling out \"F.L.T.R\" in figure 4, and addressing the issue of small text in figure 1. These suggestions are factual and descriptive, providing guidance on how to enhance the paper without making subjective claims or opinions. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides several actionable suggestions for improving the clarity and readability of the paper. It points out specific issues, such as the confusion caused by the use of \"M and N\" without definition, and suggests spelling out \"F.L.T.R\" in figure 4. Additionally, it highlights the problem of small text in figure 1 and recommends crossreferencing notation and figures. These suggestions are clear and concrete, offering the authors specific ways to enhance the presentation and organization of their work. However, the comment could be more helpful if it provided additional context or examples to further clarify the issues. Overall, the feedback is 4 as it provides valuable guidance for improving the draft, but it could be more comprehensive with further elaboration. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that using $p$ to denote both the phase mixing probability and the dummy variable in the inner loop in Phase 2 might be confusing. This comment implies that the authors should clarify or differentiate the use of $p$ to avoid confusion. However, it does not provide explicit guidance on how to achieve this clarification, such as suggesting alternative notation or rephrasing the text. The action is implicit and somewhat vague, as the authors need to infer that they should make changes to improve clarity but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the potential confusion caused by using $p$ to denote both the phase mixing probability and the dummy variable in the inner loop in Phase 2. This provides clear guidance on what needs to be addressed to improve the clarity of the algorithm description. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that using $p$ to denote both the phase mixing probability and the dummy variable in the inner loop in Phase 2 might be confusing. However, the comment does not provide any reasoning or evidence to support why this notation is confusing or how it affects the understanding of the algorithm. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the notation used in Algorithm 1, specifically the use of $p$ to denote both the phase mixing probability and the dummy variable in the inner loop of Phase 2. This feedback is clear and actionable, as it directs the authors to clarify or differentiate the use of $p$ to improve the clarity and readability of their algorithm description. However, the comment could be more helpful if it provided specific suggestions on how to resolve the confusion, such as recommending alternative notation or rephrasing the text. Overall, the comment is 4 as it highlights a specific area for improvement and guides the authors toward enhancing the clarity of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit suggestions for improving the paper. It recommends adding a more detailed, mathematical formulation of the approach in the appendix, which would help readers understand the methodology better. Additionally, it suggests enhancing the figure by adding more text labels to clarify its content. The comment also suggests reworking the figure to better align with the main contribution of the paper, which is improvements on the WiC task. These suggestions are concrete and provide clear actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"highlevel description\" and the \"figure,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific suggestions for improvement, such as adding a more detailed mathematical formulation in the appendix and enhancing the figure by adding text labels. Additionally, it suggests reworking the figure to better align with the main contribution of the paper. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the highlevel description of the approach is helpful for understanding it intuitively, but it lacks a detailed mathematical formulation, which would be beneficial. It also critiques the figure, stating it is too abstract and does not align well with the main contribution of the paper, suggesting that reworking the figure to depict the WiC task could improve it. While the comment provides some reasoning, it lacks specific examples or references to support the claim that the figure is confusing or that a detailed mathematical formulation is necessary. Therefore, the comment is 3, as it provides a general direction for improvement but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment provides constructive feedback on two aspects of the paper: the highlevel description and the figure. It suggests that while the highlevel description is helpful for understanding the approach intuitively, a more detailed mathematical formulation would be beneficial, possibly in the appendix. Additionally, the comment critiques the figure, noting that it is too abstract and does not align well with the main contribution of the paper, which is improvements on the WiC task. The reviewer offers specific suggestions for improving the figure, such as adding more text labels and reworking it to better depict the WiC task. These suggestions are actionable and provide clear guidance for the authors to enhance the clarity and relevance of their work. However, the comment could be more helpful if it included examples or further elaboration on how to implement these suggestions. Overall, the feedback is 4 as it identifies areas for improvement and offers concrete steps for enhancement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and requests for clarification regarding the experiments, specifically asking for the comparison results of YOSO with linformer on iterationwise convergence and seeking an explanation for the difference in performance. While the comment does not explicitly instruct the authors to provide these comparisons or explanations, it implies that these are necessary for a complete understanding of the results. The authors can infer that they need to include these comparisons and analyses in their draft. However, the comment lacks concrete guidance on how to conduct these analyses or present the results, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what is missing from the pretraining experiment part, namely the comparison of steps vs. ppl of linformer with YOSO, and asks for the comparison result of YOSO with linformer on iterationwise convergence. Additionally, it raises a question about the comparison to an explanation that can analyze the difference in performance between YOSO and linformer. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several questions and observations about the experiments, specifically regarding the comparison between YOSO and linformer. It questions the absence of steps vs. ppl of linformer with YOSO in Figure 4 and asks for the comparison result of YOSO with linformer on iterationwise convergence. Additionally, it notes that linformer demonstrates better accuracy in downstream tasks like SST2 and requests an explanation for the difference in performance. While the comment highlights areas that need clarification or further analysis, it does not provide specific evidence, examples, or references to support these claims. The lack of detailed justification or examples makes the claims 3, as the authors would need to infer the necessary steps to address these points. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the experiments, noting that the pretraining experiment part does not provide steps vs. ppl of linformer with YOSO in Figure 4. It also raises questions about the comparison of YOSO with linformer on iterationwise convergence and the difference in performance on downstream tasks like SST2. Additionally, it suggests that an explanation is needed to analyze the difference in performance. This feedback is clear and actionable, as it directs the authors to provide specific comparisons and analyses that would enhance the clarity and comprehensiveness of their results. However, the comment could be more helpful if it offered suggestions on how to present these comparisons or analyses. Overall, the comment is 4, as it provides valuable guidance for improving the draft, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the abstract and the text, specifically regarding the requirement for the proposal distribution to upper bound the target everywhere. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion for correction, clarification, or improvement. As a result, the authors are left without any actionable steps to take in response to this comment. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the abstract requires the proposal distribution to upper bound the target everywhere, which is contradicted by the text. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. This is a clear and actionable feedback that highlights a potential error or inconsistency in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify the discrepancy. While it points out a critical area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a specific issue with Figure 1, where the reference to \"PointNet\" is confusing due to the absence of this name in the paper and the existence of another paper with the same name. The reviewer provides a clear action for the authors to take by suggesting that they should clarify the reference to avoid confusion. This feedback is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the reference to \"PointNet\" and provides a clear suggestion to clarify the reference to avoid confusion. The comment further specifies the issue by mentioning another paper with the same name, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,\" by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that referring to 15 as \"PointNet\" is confusing because the name does not appear in the paper and there is another paper with the same name. The reviewer provides a specific reference to the other paper, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,\" by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas, which supports the claim. This detailed reference helps to clarify the confusion and provides a clear basis for the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the reference to \"PointNet\" in Figure 1, pointing out that the name does not appear in the paper and is confused with another paper. The reviewer provides a clear suggestion to clarify the reference by mentioning the correct paper, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,\" by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. This feedback is actionable and provides a precise way for the authors to improve the clarity and accuracy of their references, making it 5 for the authors to enhance their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the policy gradient in Eq. 6 and whether it solves the optimal problem, suggesting that clarification might be needed. It also provides minor corrections, such as removing \"on learning  on\" from Line 78 and correcting the equation in Line 132. While the comment implies that the authors should clarify the policy gradient and make these minor corrections, the actions are not explicitly stated. The feedback is 4 because it provides concrete suggestions for improvement, but the authors need to infer the need for clarification and the specific corrections. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific equations (Eq. 6 and Eq. 5) and lines (78 and 132), allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific suggestions for clarification and minor corrections, such as removing unnecessary text and correcting an equation. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the policy gradient in Eq. 6 and its relation to solving the optimal problem in Eq. 5. It suggests that clarification might be needed, but it does not provide any specific reasoning, examples, or references to support the claim. The comment is more of a request for clarification rather than a claim that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the policy gradient in Eq. 6, questioning whether it solves the optimal problem and whether the optimal solution to Eq. 5 is obtained after convergence. This is a valid concern that could help the authors clarify their methodology. Additionally, the comment provides minor corrections, such as removing unnecessary text and correcting an equation. While the feedback is 3 in identifying areas for clarification and improvement, it could be more comprehensive by providing detailed guidance on how to address the questions raised. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether it is possible to assume a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm. It also asks for clarification on the difference between the two. While the comment implies that the authors should consider this alternative, it does not provide explicit guidance on how to address the question or what specific actions to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore this possibility and provide a response. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this assumption is discussed. Without explicit references, the authors may find it challenging to determine the exact context of the question. The comment is specific in its inquiry about the difference between the two distributions, but it lacks grounding due to the absence of a clear reference to the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point is a question seeking clarification on the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. It seeks clarification on whether it is possible to assume a general Gaussian distribution and what the difference is between the two. While the comment identifies a potential area for exploration, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this question or its implications for their work. The feedback is 3 as it prompts the authors to consider an alternative assumption, but it does not offer actionable steps or detailed insights to improve the draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a potential issue with the paper, specifically the decision to freeze the partitioning in the first iteration. It suggests that this choice makes strong assumptions about the coverage of the initial data and recommends discussing the limitations of this approach. The comment provides a clear and direct action for the authors to take, which is to address the limitations of this method. This feedback is concrete and actionable, as it specifies exactly what needs to be discussed in the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the potential risk of freezing the partitioning in the first iteration and suggests that the authors should discuss the limitations of this approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that freezing the partitioning in the first iteration is a \"risky choice\" that makes strong assumptions about the coverage of the initial data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the decision to freeze the partitioning in the first iteration. It suggests that this choice may make strong assumptions about the coverage of the initial data and recommends that the authors discuss the limitations of this approach. This feedback is clear and actionable, as it points out a specific area that may need further consideration or justification. However, the comment could be more helpful if it provided additional context or suggestions on how to address these limitations. Overall, the comment is 4, as it directs the authors to a critical area that requires attention, but it could be more comprehensive with further guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the decision to use early stopping based solely on link prediction accuracy should be explained. It implies that the authors should provide a rationale for this choice, possibly by considering alternative metrics like type accuracy. While the comment does not explicitly instruct the authors to include this explanation, it provides a clear direction on what aspect of the paper needs clarification. The action is implicit but concrete, as the authors know they need to address the reasoning behind their choice. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"590,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the decision to use early stopping only based on link prediction accuracy and suggests considering an average with type accuracy. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the decision to use early stopping based solely on link prediction accuracy, suggesting that it should be explained and potentially considering an average with type accuracy. However, the comment does not provide any reasoning or evidence to support why this decision might be problematic or why an average with type accuracy would be beneficial. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, questioning the decision to use early stopping based solely on link prediction accuracy. It suggests that the authors should explain this choice, potentially by considering an average with type accuracy. This feedback is clear and actionable, as it directs the authors to provide a rationale for their methodological choice, which could enhance the clarity and robustness of their approach. However, the comment could be more helpful if it provided additional context or examples of how this explanation could be integrated into the paper. Overall, the comment is 4, as it offers a specific suggestion for improvement but could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the feasibility of setting a classimbalanced task in the context of fewshot learning, where there are only a few examples for each class. It explicitly asks the authors to provide \"concrete details\" to explain how they would approach this issue. This feedback is clear and direct, providing a specific action for the authors to take\u2014namely, to provide detailed explanations on how they would set up a classimbalanced task in the fewshot learning setting. The request for concrete details ensures that the authors know exactly what is expected of them, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"sampling classimbalanced tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the feasibility of setting a classimbalanced task in the context of fewshot learning, where there are only a few examples for each class, and asks the authors to provide concrete details to explain how they would approach this issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the feasibility of setting a classimbalanced task in the context of fewshot learning, where there are only a few examples for each class. It asks the authors to explain with concrete details, which is a request for clarification rather than a claim. Since it does not make a subjective claim or judgment, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the feasibility of setting a classimbalanced task in the context of fewshot learning, where there are only a few examples for each class. It prompts the authors to provide concrete details on how they would approach this issue, which is a valuable suggestion for improving the clarity and validity of the paper. However, the comment could be more helpful if it offered specific guidance or examples on how to address this challenge. Despite this, the feedback is 4 as it directs the authors to a critical area that needs further explanation, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of explanation regarding the ground truth of sensitivity, specifically noting that the authors only mention \"pruning\" without providing details on how it was done. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should provide more details on the pruning process. However, the comment lacks concrete instructions on what specific details should be included or how to present them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 238239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking detail on how the ground truth of sensitivity is achieved, particularly regarding the pruning process. The comment provides a clear direction for the authors to improve their draft by explaining the details of the pruning process. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not provide sufficient detail on how the ground truth of sensitivity is achieved, specifically mentioning the lack of explanation regarding the pruning process. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the specific issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors lack detailed explanation, namely the process of achieving the ground truth of sensitivity through pruning. It points out that the current explanation is insufficient, as it only mentions \"pruning\" without providing details on how it was done. This feedback is 3 as it directs the authors to a particular section of the paper where they need to provide more detailed information. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific areas where the text could be written more clearly, providing explicit examples of what needs clarification. It asks the authors to explain what a proper rotation matrix is in line 97 and to clarify the meaning of a specific statement regarding the matrix being nonpositive semidefinite in lines 105106. These requests are direct and concrete, giving the authors clear guidance on what needs to be addressed in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (97 and 105106) where the text could be clarified. This allows the authors to accurately identify the parts of the paper that need revision. The comment is also specific because it clearly specifies what needs to be addressed: the explanation of a proper rotation matrix and the meaning of a statement regarding the matrix being nonpositive semidefinite. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements requesting clarification on specific points in the text. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas where the text could be improved by suggesting that certain parts need to be written more clearly. It provides explicit examples of what needs clarification, such as the explanation of a proper rotation matrix in line 97 and the meaning of a statement regarding the matrix being nonpositive semidefinite in lines 105106. This feedback is clear and actionable, guiding the authors on how to enhance the clarity and comprehensibility of their draft. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided additional context. Overall, the comment is 4 as it directs the authors to specific areas needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a potential improvement by recommending a change in terminology from \"g activation function\" to \"a binary operator,\" similar to the approach taken by Cohen and Shashua (2016). However, it does not provide explicit guidance on how to implement this change or why it would be beneficial. The suggestion is implicit and somewhat vague, as the authors are left to infer the exact steps needed to make this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a change in terminology from \"g activation function\" to \"a binary operator,\" providing a clear direction for improvement. Additionally, it references a specific work by Cohen and Shashua (2016) to support the suggestion, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests a change in terminology from \"g activation function\" to \"a binary operator,\" referencing a similar approach by Cohen and Shashua (2016). The comment provides a specific reference to support the suggestion, which is a clear and logical reasoning for the proposed change. This level of detail makes the claim 5, as it offers a concrete basis for the authors to consider the suggested change. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the terminology used in the paper, recommending a change from \"g activation function\" to \"a binary operator.\" It references a similar approach by Cohen and Shashua (2016), which adds context and supports the suggestion. This feedback is clear and actionable, offering the authors a concrete way to enhance the clarity and precision of their work. However, the comment could be more helpful if it explained why this change is beneficial or how it aligns with the broader context of the paper. Overall, the comment is 4 as it provides a direct and constructive suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors consider shrinking the captions of Fig. 1 and Fig. 2 to leave more space for the methods or related work sections. This provides a clear and direct action for the authors to take, along with a concrete suggestion on how to implement it. The comment is explicit and provides specific guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1 and Fig. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the captions, suggesting that they have large overlaps with the content and recommending shrinking them to leave more space for the methods or related work sections. This provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point suggests that the captions of Fig. 1 and Fig. 2 have large overlaps with the content, implying that this could be improved by shrinking the captions. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issue or how to address it. The lack of detailed justification or examples makes the claim 2, as it requires more information to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the captions of Fig. 1 and Fig. 2, noting that they have large overlaps with the content. It provides a clear and actionable suggestion to consider shrinking the captions to leave more space for the methods or related work sections. This feedback is valuable as it directly addresses a visual aspect of the paper that could improve its readability and organization. However, the comment could be more helpful if it included examples or further guidance on how to effectively reduce the overlap without compromising the clarity of the figures. Overall, the comment is 4 as it offers a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the exclusion of Vidgen et al., 2021, from Table 2, suggesting that it might be similar to the dataset presented in the work. The reviewer questions why this dataset is not used as a potential benchmark for evaluation, particularly for investigating the role of context in detecting hate. While the comment implies that the authors should consider including Vidgen et al., 2021, as a benchmark, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider adding this dataset as a benchmark. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of excluding Vidgen et al., 2021, from the table, and questions why this dataset is not used as a potential benchmark for evaluation. The comment provides a clear rationale for why this dataset might be relevant, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the exclusion of Vidgen et al., 2021, from Table 2, suggesting that it might be similar to the dataset presented in the work. The reviewer questions why this dataset is not used as a potential benchmark for evaluation, particularly for investigating the role of context in detecting hate. The comment provides a logical reasoning by pointing out the potential similarity and the absence of this dataset, which could be relevant for the evaluation. However, it lacks specific references or detailed comparisons to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires additional evidence or examples to be fully supported.", "helpfulness_rationale": "The review comment identifies a specific issue with the inclusion of datasets in Table 2, noting the exclusion of Vidgen et al., 2021, which might be similar to the dataset presented in the work. It questions why this dataset is not used as a potential benchmark for evaluation, particularly for investigating the role of context in detecting hate. This feedback is clear and actionable, as it prompts the authors to consider including this dataset for a more comprehensive evaluation. However, the comment could be more helpful if it provided additional context or suggestions on how to incorporate Vidgen et al., 2021, into the evaluation framework. Overall, the comment is 4 as it directs the authors to a potential area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point consists of two separate statements. The first part discusses the challenges of using fully realistic datasets, noting that they can make it difficult to control multiple aspects of variation with precision. However, this statement does not provide any actionable advice or suggestions for the authors to address this issue. The second part agrees with the authors\" judgment regarding the lack of immediate societal impact, which is a factual statement and does not offer any guidance for improvement. Since neither part provides actionable feedback or suggestions, the comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it addresses, leaving the authors uncertain about where to focus their attention. It also lacks specificity, as it does not detail what aspects of the datasets are problematic or how the authors might address the issue of controlling multiple aspects of variation. Without clear guidance or references to specific sections, the authors are left without a clear understanding of what needs to be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two separate statements. The first statement claims that fully realistic datasets can make it difficult to control multiple aspects of variation with precision. However, this claim is not supported by any evidence, reasoning, or references, making it 1. The second statement agrees with the authors\" judgment regarding the lack of immediate societal impact, which is a factual statement and does not require verification. Since the first part of the comment lacks support, the overall comment is rated as 1.", "helpfulness_rationale": "The review comment consists of two separate statements. The first part discusses the challenges of using fully realistic datasets, noting that they can make it difficult to control multiple aspects of variation with precision. However, this statement lacks actionable feedback or suggestions for the authors to address this issue. The second part agrees with the authors\" judgment regarding the lack of immediate societal impact, which is a factual statement and does not provide any guidance for improvement. Since neither part offers actionable advice or constructive feedback, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific paragraph (L156166) where the reviewer struggles to understand the content, despite having a general idea of what the authors are trying to convey. The reviewer also criticizes the figure, stating that the explanation of dashed lines is too vague. While the comment identifies areas of confusion, it does not provide explicit guidance on how to clarify the paragraph or improve the figure. The action is implicit and somewhat vague, as the authors are left to infer what specific changes are needed to address the issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paragraph \"L156166,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with understanding the paragraph and the figure, providing clear feedback on what is unclear or vague. The reviewer suggests that the paragraph is hard to understand and that the explanation of dashed lines in the figure is too vague. This level of detail helps the authors understand what needs to be clarified or improved in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paragraph from L156166 is difficult to understand and that the explanation of dashed lines in the figure is vague. However, the comment does not provide specific examples or detailed reasoning to support these claims. It lacks concrete evidence or references to substantiate the assertion that the paragraph is unclear or that the figure is poorly explained. Without additional context or examples, the authors may find it challenging to address the issues effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues with a paragraph (L156166) and a figure, indicating that the text is difficult to understand and that the explanation of dashed lines in the figure is vague. This feedback is 3 as it points out areas where the authors need to clarify their content to improve the readability and comprehensibility of their draft. However, the comment could be more helpful if it provided suggestions on how to rephrase the paragraph or improve the figure\"s explanation. While it highlights the need for improvement, it lacks actionable guidance, making it 3 but incomplete."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the behavior of the model under higher noise levels, as the current noise value of 3 is not considered high based on the observations in the plot compared to the true trajectories. This feedback is explicit, as it clearly states what action the authors should take to improve their draft. It is also concrete, as it provides a specific suggestion for further study. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the simulation study\" and \"the plot compared to the true trajectories,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the discrepancy between the stated standard deviation of the noise and the observed behavior in the plot, suggesting that the authors should study the model under higher noise levels. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the standard deviation of the noise is not high based on observations in the plot compared to the true trajectories. However, it does not provide specific examples or detailed reasoning to support this claim, making it 3. The suggestion to study the model under higher noise levels is logical but lacks detailed justification or references to substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the simulation study, specifically the standard deviation of the noise being considered low based on the observations in the plot compared to the true trajectories. It suggests that the authors should study the behavior of the model under higher noise levels, which could provide more insight into its robustness. This feedback is clear and actionable, as it directs the authors to a specific area for further investigation, which could enhance the comprehensiveness and robustness of their results. However, the comment could be more helpful if it provided additional guidance on how to conduct this study or what specific aspects to focus on. Overall, the comment is 4, as it offers a valuable suggestion for improvement but could be more detailed."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises an interesting question about how DVP performs on videos of different lengths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what the authors should do with this observation or how it could be explored further in the paper. Without any actionable steps or suggestions, the authors are left without a clear direction on how to address this point. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises an interesting question about the performance of DVP on videos of different lengths but does not specify which part of the paper this question pertains to. It lacks grounding as it does not identify a specific section, figure, or table where this issue is discussed. Additionally, it is not specific about what aspects of performance are being questioned or how the authors might address this issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question and does not contain any claims, opinions, or suggestions that require verification. It is purely descriptive and does not necessitate a response or further clarification from the authors. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises an interesting question about the performance of DVP on videos of different lengths. However, it does not provide any context, analysis, or suggestions for how this observation could be explored or addressed in the paper. Without additional guidance or direction, the authors are left without a clear understanding of how to incorporate this question into their work. The comment lacks depth and actionable feedback, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to evaluate the approximation error by calculating the actual KLdivergence and checking whether it approaches zero. This provides a clear and concrete action for the authors to take, ensuring they understand exactly what needs to be done to address the issue. The comment is 5 as it specifies the steps to be taken, leaving no ambiguity for the authors. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed training objective, namely the omission of the KLdivergence term in equation (3), and requests an evaluation of the approximation error by calculating the actual KLdivergence. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the omission of the KLdivergence term in the proposed training objective and suggests evaluating the approximation error by calculating the actual KLdivergence. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this omission is significant or how it affects the results. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed training objective in Section 3.3, noting the omission of the KLdivergence term in equation (3). It provides a clear and actionable suggestion for the authors to evaluate the approximation error by calculating the actual KLdivergence and checking whether it indeed approaches zero. This feedback is valuable as it directs the authors to a critical aspect of their methodology that requires further analysis. However, the comment could be more helpful if it offered additional context or examples of how this evaluation might impact the overall results or conclusions. Nonetheless, the suggestion is clear and actionable, making the comment 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point expresses an opinion that Section 2 lacks a clear connection with the methodology section and that the theoretical analysis is simplistic and closely related to reference 1. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the connection between Section 2 and the methodology or how to enhance the theoretical analysis. Without actionable suggestions or specific feedback, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the limited connection with the methodology section and the simplicity of the theoretical analysis, which is closely related to reference 1. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Section 2 lacks a clear connection with the methodology section and that the theoretical analysis is simplistic and closely related to reference 1. However, the comment does not provide specific examples or detailed reasoning to support these claims. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the limited connection between Section 2 and the methodology section, and the simplicity of the theoretical analysis, which is closely related to reference 1. While the comment highlights these weaknesses, it does not provide specific suggestions or guidance on how the authors might address these issues. Without actionable feedback or detailed advice, the authors are left with a general understanding of what needs improvement but without a clear path forward. Therefore, the comment is 3, as it points out areas for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be interesting to further discuss the situations in which the losses are helpful, specifically mentioning specular areas. However, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the discussion should be included. The action is implicit and somewhat vague, as the authors are left to infer that they should add a discussion on the utility of losses in specific contexts, such as specular areas. While the comment points out an area for improvement, it lacks concrete details on how to address it, making it 3.", "grounding_specificity_rationale": "The comment suggests that it would be interesting to further discuss or specify situations where the losses are helpful, particularly in relation to specular areas. However, it does not explicitly mention which part of the paper this discussion should be added to, making it weakly grounded. The comment is specific in suggesting a particular area of interest, namely the utility of losses in specular areas, but it lacks grounding as it does not direct the authors to a specific section or part of the paper where this discussion should be included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to further discuss or specify situations where the losses are helpful, particularly in relation to specular areas. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that it would be interesting to further discuss or specify situations where the losses are helpful, particularly in relation to specular areas. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how the authors might address this suggestion. The comment does not offer actionable steps or examples of how to enhance the discussion, leaving the authors with a general idea but without a clear path for improvement. Therefore, the comment is 3, as it points out a potential area for enhancement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses doubt about the paper\"s strength in its current state, questioning whether it is suitable for ICLR. However, it does not provide any specific feedback or suggestions on how the authors might strengthen their contribution or improve the paper. Without actionable guidance or concrete steps for improvement, the authors are left without a clear understanding of what changes are needed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment expresses doubt about the paper\"s strength in its current state, questioning whether it is suitable for ICLR. However, it does not specify which aspects of the paper are lacking or what specific contributions are insufficient. Without detailed guidance or references to specific sections or elements of the paper, the authors cannot confidently determine which parts need improvement. The comment lacks both grounding and specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a subjective opinion about the paper\"s strength, specifically questioning whether it is suitable for ICLR. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the reviewer\"s doubt. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses doubt about the paper\"s strength in its current state, questioning whether it is suitable for ICLR. However, it does not provide any specific feedback or suggestions on how the authors might strengthen their contribution or improve the paper. Without actionable guidance or detailed critique, the authors are left without a clear understanding of what changes are needed to enhance their work. This lack of specificity and actionable advice makes the comment unhelpful, as it does not offer any meaningful direction for improvement. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly questions the determination of \"n_t\" in Algorithm 2 and seeks clarification on the meaning of \"appropriate number\" in line 225. It also mentions that the answer cannot be found in reference 30. This feedback provides a clear and direct action for the authors to take: clarify the determination of \"n_t\" and provide a clear explanation of the term \"appropriate number.\" The comment is explicit and concrete, as it specifies exactly what needs to be addressed and how to address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2\" and \"line 225,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the determination of \"n_t\" and seeks clarification on the meaning of \"appropriate number,\" providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the determination of \"n_t\" in Algorithm 2 and seeks clarification on the meaning of \"appropriate number\" in line 225. It also mentions that the answer cannot be found in reference 30. This comment is 3 as it raises a specific question about the clarity of the algorithm and references a specific line and reference, indicating where the issue might be. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Algorithm 2, questioning how to determine \"n_t\" and seeking clarification on the meaning of \"appropriate number\" in line 225. It also mentions that the answer cannot be found in reference 30, which suggests that the authors should provide more detailed explanations or examples to clarify these points. This feedback is clear and actionable, as it directs the authors to address a particular ambiguity in their algorithm, which is crucial for the paper\"s clarity and reproducibility. However, the comment could be more helpful if it provided additional suggestions on how to clarify these points or offered examples of how similar issues have been addressed in other works. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity of their algorithmic descriptions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the lack of sufficient support for the claim that \"in practice the mixing time is even better,\" stating that the evidence provided to practitioners is limited. However, it does not offer any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the support for the claim or what additional evidence might be needed. As a result, the authors are left without a clear understanding of how to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses specific claims made in the paper regarding the mixing time, indicating that the evidence provided is insufficient. However, it does not specify which part of the paper these claims are made in, such as a particular section or experiment. This makes it difficult for the authors to pinpoint the exact location that needs revision. The comment is specific in its critique of the evidence but lacks grounding, as it does not clearly identify the section or context where these claims are discussed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the evidence supporting the claim \"in practice the mixing time is even better\" is insufficient. However, it does not provide specific examples or detailed reasoning to substantiate this claim. The comment lacks references or examples of experiments that could support the claim, making it difficult for the authors to understand and address the critique. As a result, the claim is considered 1 due to the lack of supporting evidence or detailed justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the claims about the mixing time being better in practice are not sufficiently supported by the experiments. This is a clear and actionable feedback that highlights a weakness in the paper\"s evidence. However, the comment could be more helpful if it provided suggestions on how the authors might improve the support for these claims or what additional experiments or analyses could be conducted to strengthen the evidence. Despite this, the comment still offers valuable insight into an area that needs improvement, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit suggestions for clarification and additional details. It asks the authors to denote the vector representations of \"x\" and \"t\" in the equation, which is a clear and direct action. Additionally, it requests information about whether the vectors are L2normalized and how the \"nearest neighbor\" examples are computed, specifically whether cosine or dotproduct is used. These questions are also explicit and provide concrete guidance on what information the authors should include. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear and actionable suggestions for clarification, such as denoting the vector representations of \"x\" and \"t,\" and requests additional details about the normalization process and the method used for computing \"nearest neighbor\" examples. The comment specifies what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of questions and suggestions for clarification regarding specific details in the paper, such as the vector representations of \"x\" and \"t,\" normalization, and the method used for computing \"nearest neighbor\" examples. These are factual requests for information and do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas in the paper that require clarification and additional details. By suggesting that the vector representations of \"x\" and \"t\" be denoted, the reviewer provides a clear and actionable suggestion for improving the clarity of the paper. Additionally, the comment raises important questions about the normalization process and the method used for computing \"nearest neighbor\" examples, which are crucial for understanding the methodology. However, the comment could be more helpful if it provided further context or examples to support these suggestions. Overall, the feedback is valuable and guides the authors toward enhancing the transparency and comprehensiveness of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that experiments in deep reinforcement learning (RL) should be run multiple times to address the issue of reproducibility and the significance of improvements. It references a community effort towards reproducibility and suggests that this should be considered in the paper. The comment explicitly states the action of running multiple experiments and reporting statistics, providing a clear and concrete direction for the authors to follow. However, it does not specify which experiments should be run multiple times or how to report the statistics, which could be considered a minor limitation. Overall, the comment is 5 as it provides a direct and concrete action for the authors to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments\" and \"deep RL,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of reproducibility and the need for running multiple experiments and reporting statistics. The reference to a community effort towards reproducibility and the suggestion to consider this in the paper further enhance the specificity of the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that experiments in deep reinforcement learning should be run multiple times to address issues of reproducibility and the significance of improvements. It references a community effort towards reproducibility and cites a specific paper, \"Deep reinforcement learning that matters\" by Henderson et al. (2018), as evidence. This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or specific statistics on how running multiple experiments would improve reproducibility. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment addresses a critical issue in deep reinforcement learning (RL) experiments, specifically the lack of reproducibility and the significance of improvements. It suggests that running multiple experiments and reporting statistics is crucial for addressing these concerns. The comment also references a community effort towards reproducibility, providing a specific example from the literature. This feedback is 5 as it identifies a key area for improvement and offers a concrete suggestion for enhancing the paper\"s rigor and credibility. By referencing a relevant paper, the comment provides a clear direction for the authors to follow, making it actionable and valuable for improving the draft. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to check Figure 2, Line 433, and Line 468 for consistency in the punctuation of equations. It clearly specifies the actions needed to address the issue, which is to ensure that all equations end with either a period or a comma consistently. This feedback is direct and provides concrete guidance on what the authors need to do to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, namely \"Figure 2, Line 433, and Line 468,\" allowing the authors to accurately identify the sections that need attention. It is also specific because it clearly specifies the issue of inconsistent punctuation in equations, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual observation about the punctuation of equations in the paper, specifically mentioning Figure 2, Line 433, and Line 468. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the punctuation of equations in the paper, suggesting that some end with a period while others end with a comma. It provides clear and actionable feedback by instructing the authors to ensure consistency in the punctuation of equations. This feedback is direct and helps the authors to make a precise correction, which is valuable for improving the clarity and professionalism of their draft. However, the comment could be more helpful if it explained why consistency in punctuation is important or provided examples of how it affects the readability of the paper. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point raises a question about the origin of the figures in Figure 1, asking whether they are generated from real experiments or artificially. It also suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon observed in the figures. This feedback is explicit in its request for clarification and provides a clear action for the authors to take, which is to conduct realworld experiments if the figures are artificially generated. The suggestion is concrete, as it specifies what the authors need to do to address the concern. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: determining whether the figures are generated from real experiments or artificially, and if artificially, suggesting the need for realworld experiments to support the phenomenon observed. This provides clear guidance on what the authors need to clarify or address in their work. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the origin of the figures in Figure 1, asking whether they are generated from real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon observed. However, the comment does not provide any evidence, reasoning, or references to support the claim that the figures are artificially generated or that realworld experiments are necessary. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a critical question about the origin of the figures in Figure 1, specifically whether they are generated from real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon observed. This feedback is highly relevant and actionable, as it prompts the authors to clarify the basis of their results and potentially conduct additional experiments to strengthen their claims. By addressing this concern, the authors can enhance the credibility and validity of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the author was unclear about the numbers of parameters used in each approach, specifically in Section B.3. This provides a direct action for the authors to take, which is to clarify and provide the specific numbers of parameters used in each approach. The comment is explicit and concrete, as it clearly instructs the authors on what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section B.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the numbers of parameters used in each approach. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement requesting clarification on the numbers of parameters used in each approach, as mentioned in Section B.3. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the numbers of parameters used in each approach, as mentioned in Section B.3. This feedback is clear and actionable, as it directs the authors to clarify and provide the specific numbers of parameters used in each approach. By addressing this point, the authors can improve the clarity and transparency of their paper, making it more understandable for readers. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the evaluation results reported in Table 1, specifically noting that they are based on only three trials for each case. The reviewer suggests that this is statistically insignificant and questions the relevance of reporting deviations. The comment also critiques statements claiming performance superiority over baselines due to the lack of statistical significance. While the comment identifies a potential issue with the evaluation methodology and the interpretation of results, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors are left to infer that they should either increase the number of trials or rephrase their claims to reflect the limitations of the current evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the evaluation results, noting that they are based on only three trials for each case, which is statistically insignificant. The comment further explains why this affects the interpretation of deviations and the validity of certain performance claims. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation results reported in Table 1 are based on only three trials for each case, which is statistically insignificant. The reviewer argues that this lack of statistical significance makes it nonsensical to report deviations and supports the claim that statements about performance superiority over baselines are not valid. The comment provides a logical reasoning for the claim, explaining why the limited number of trials affects the reliability of the results. However, it could be strengthened by providing specific examples or references to support the assertion about the impact of limited trials on statistical significance. Overall, the claim is 4, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation results reported in Table 1, specifically noting that they are based on only three trials for each case. This is a critical observation because it highlights a potential flaw in the statistical significance of the results, which could impact the validity of claims about performance superiority over baselines. The comment provides a clear and actionable suggestion by pointing out that the lack of statistical significance makes it nonsensical to report deviations or make claims about performance being better than the next best baseline. This feedback is valuable as it prompts the authors to reconsider their evaluation methodology and potentially revise their claims to reflect the limitations of their data. However, the comment could be more helpful if it offered specific guidance on how to address this issue, such as suggesting additional trials or statistical analyses. Overall, the comment is 4, as it effectively identifies a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a more cautious usage of the word \"equivalent\" in the paper, particularly when the equivalence is not verified. This is an explicit suggestion for the authors to reconsider their use of the term, providing a clear action to take. The comment is specific in its guidance, offering a concrete step for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific line numbers (8, 56, 70, 93) where the issue with the word \"equivalent\" is observed. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests a more cautious usage of the word \"equivalent,\" particularly when the equivalence is not verified. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a more cautious use of the word \"equivalent\" when the equivalence is not verified. This is a reasonable suggestion, as it highlights a potential issue with the language used in the paper. However, the comment does not provide specific examples or detailed reasoning to support why this caution is necessary. While the suggestion is logical, it lacks concrete evidence or references to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the suggestion but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the usage of the word \"equivalent\" in the paper, suggesting a more cautious approach when the equivalence is not verified. This feedback is clear and actionable, as it directs the authors to reconsider their language choice and potentially provide evidence or verification for the equivalences claimed. However, the comment could be more helpful if it provided examples or further context on why this caution is necessary, which would enhance its utility for the authors. Overall, the comment is 4, as it offers a specific suggestion for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the architecture used for the experiments is not clearly explained in the paper, and instead, the authors refer to Jiang et al. (2019) for details. This makes the paper not selfcontained. The comment implies that the authors should provide a clear explanation of the architecture used in their experiments, rather than relying on external references. However, it does not specify how to do this or what details should be included in the explanation. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details but are not given explicit guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"architecture used for the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper relies on an external reference (Jiang et al., 2019) for details, making it not selfcontained. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper\"s architecture is not clearly explained, relying on an external reference (Jiang et al., 2019) for details. This claim is 3 as it highlights a potential issue with the paper\"s selfcontainment. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it difficult for the authors to understand the exact nature of the problem. Therefore, the comment is rated as 3, as it provides some justification but requires more detailed evidence or examples to be 5.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the architecture used for the experiments is not clearly explained within the paper. Instead, the authors refer to an external source, Jiang et al. (2019), for details. This makes the paper not selfcontained, which is a critical concern for readers who may not have access to the external reference. The comment highlights a specific area for improvement, suggesting that the authors should provide a clear explanation of the architecture used in their experiments. This feedback is clear and actionable, as it directs the authors to enhance the paper\"s selfcontainment by including necessary details. However, the comment could be more helpful if it provided suggestions on how to present the architecture or what specific details should be included. Overall, the comment is 4, as it effectively points out a critical issue and offers a clear path for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the typesetting of \"BertScore\" and \"BLEURT\" is inconsistent throughout the paper, suggesting that it would be better to maintain consistency. This provides a clear and direct action for the authors to take, which is to ensure that these terms are consistently typeset throughout the draft. The comment is explicit and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"BertScore and BLEURT,\" allowing the authors to accurately identify the specific parts of the paper where the inconsistency occurs. It is also specific because it clearly specifies the issue of inconsistent typesetting and suggests maintaining consistency. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the inconsistent typesetting of \"BertScore\" and \"BLEURT\" throughout the paper. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the typesetting of \"BertScore\" and \"BLEURT\" throughout the paper, noting that they are inconsistently presented as \"Bertscore\" or \"Bleurt.\" This feedback is clear and actionable, as it provides a straightforward suggestion to maintain consistency in the typesetting of these terms. By addressing this issue, the authors can improve the clarity and professionalism of their draft. However, the comment could be more helpful if it suggested specific guidelines or best practices for maintaining consistency in typesetting. Overall, the comment is 4, as it directs the authors to a specific area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a lack of clarity in some explanations, specifically mentioning the last paragraph of Section 3 (lines 207210) regarding the single image case. However, it does not provide explicit guidance on how to improve the clarity or what specific aspects need to be clarified. The comment raises questions and comments, which implies that the authors should address these points, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment identifies a lack of clarity in some explanations, specifically mentioning the last paragraph of Section 3 (lines 207210) regarding the single image case. This provides full grounding as it explicitly mentions the section and lines where the issue is located, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out the vagueness of the explanation in that section, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some explanations are \"a little vague,\" specifically mentioning the last paragraph of Section 3 (lines 207210) regarding the single image case. However, it does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The comment lacks concrete evidence or references to substantiate the claim of vagueness, rendering it barely verifiable. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment identifies a specific area where the explanations are vague, pointing out the last paragraph of Section 3 (lines 207210) regarding the single image case. This feedback is 3 as it directs the authors to a particular section that needs clarification. However, the comment lacks depth and does not provide specific suggestions or guidance on how to improve the clarity of the explanation. While it highlights an area for improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the proposed approach to pretraining lacks novelty because it largely follows the strategies used in ELECTRA. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the novelty of their approach. Without any actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the proposed approach to pretraining, suggesting it largely follows strategies used in ELECTRA. However, it does not specify which part of the paper discusses the pretraining approach, making it weakly grounded. The comment is specific in its critique of the lack of novelty, but without explicit references to sections or specific elements of the paper, the authors may struggle to identify where to address this feedback. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the proposed approach to pretraining lacks novelty because it largely follows the strategies used in ELECTRA. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or references to specific strategies or features of ELECTRA that the proposed approach is allegedly copying, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the proposed approach to pretraining lacks novelty as it largely follows the strategies used in ELECTRA. While this feedback identifies a potential issue with the originality of the work, it does not provide any specific suggestions or guidance on how the authors might enhance the novelty of their approach or differentiate it from existing methods. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a perceived lack of motivation for the Newton algorithm in Section 4, suggesting that a bisecting line search would also converge linearly. It implies that the authors should conduct experiments to demonstrate the impact of quadratic convergence on the algorithm\"s runtime, which would help motivate the need for the analysis/algorithm. While the comment identifies a potential area for improvement, it does not explicitly instruct the authors to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer that they should perform experiments to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the motivation for the Newton algorithm, explaining that a bisecting line search would also converge linearly and questioning the impact of quadratic convergence on the algorithm\"s runtime. The comment suggests conducting experiments to motivate the need for the analysis/algorithm, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation for the Newton algorithm in Section 4 is lacking, suggesting that a bisecting line search would also converge linearly. The reviewer questions the significance of quadratic convergence in terms of runtime impact. While the comment provides a logical reasoning about the convergence rates, it lacks specific examples or references to support the claim about the impact on runtime. This makes the claim 3, as it requires further evidence or detailed analysis to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a perceived lack of motivation for the Newton algorithm in Section 4, suggesting that a bisecting line search would also converge linearly. It questions the significance of quadratic convergence in terms of runtime impact and recommends conducting experiments to demonstrate the need for the analysis/algorithm. This feedback is clear and actionable, as it provides a specific area for improvement and suggests a concrete way to address it. By highlighting the need for experiments to motivate the analysis, the comment offers valuable guidance for enhancing the draft. Therefore, it is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the proposed upweighing and KNN methods, suggesting that they do not significantly differentiate between idiomatic and random data, as indicated by Figure 3. The comment implies that the results do not demonstrate the methods\" effectiveness in handling idiomatic translations. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their methods. The feedback lacks actionable details, leaving the authors uncertain about how to proceed with revisions. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proposed methods, noting that the impact on idiomatic vs. random data is similar, and suggests that the results do not demonstrate the methods\" effectiveness in handling idiomatic translations. The comment provides a clear critique of the results, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed upweighing and KNN methods do not significantly differentiate between idiomatic and random data, as indicated by Figure 3. The comment provides a logical reasoning by stating that the results suggest \"better NMT systems are also better at idiomatic translations,\" implying that the methods do not offer a unique advantage for idiomatic translations. However, the comment lacks specific examples or detailed analysis to fully substantiate the claim, making it 3. The authors would need to delve deeper into the results and analysis to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific critique of the proposed upweighing and KNN methods, suggesting that they do not effectively differentiate between idiomatic and random data. It references Figure 3 to support this claim, indicating that the results do not demonstrate the methods\" effectiveness in handling idiomatic translations. This feedback is clear and actionable, as it highlights a potential weakness in the paper and encourages the authors to reconsider their approach or provide additional analysis to support their claims. However, the comment could be more helpful if it offered suggestions on how to address this issue or improve the methods. Overall, the comment is 4, as it provides valuable insights for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the authors should have multiple kernels and biases, as indicated by the notation \"C biases.\" It also suggests that the resulting volume should be WxHx1 and the bias should be a scalar. However, the comment does not provide specific guidance on how to implement these changes or where exactly in the paper these adjustments should be made. While the action is clear, the lack of detailed instructions on execution makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation, indicating that the authors should have multiple kernels and biases, and that the notation \"C biases\" is confusing. The comment provides a clear direction for the authors to clarify their notation and ensure consistency in their description of the model architecture. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation \"C biases\" is confusing because it suggests the authors should have multiple kernels and biases, but only found a hyperparameter for feedforward models in section 3.4. The comment provides a logical reasoning by pointing out the inconsistency in the notation and the lack of information about multiple biases. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the exact issue and potential solutions based on the provided information. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation used in the paper, particularly with the notation \"C biases\" in the context of multiple kernels and biases. It points out that the authors have only described a hyperparameter for feedforward models in section 3.4, which is confusing. This feedback is clear and actionable, as it directs the authors to clarify their notation and ensure consistency in their description of the model architecture. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific changes to the notation or additional explanations. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with Equation 8, specifically the subtraction of \"s\" from the dynamic information, which could lead to the loss of dynamic information and hinder the LSTM module\"s ability to capture complete dynamic changes. However, the comment does not provide explicit guidance on how to address this issue or suggest specific modifications to Equation 8. The action is implicit, as the authors need to infer that they should reconsider the subtraction of \"s\" from the dynamic information. The feedback lacks concrete details on how to implement the suggested change, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the potential issue with subtracting \"s\" from the dynamic information, which could lead to the loss of dynamic information and hinder the LSTM module\"s ability to capture complete dynamic changes. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the potential loss of dynamic information when subtracting \"s\" from the dynamic information in Equation 8. However, it does not provide specific examples, references, or detailed reasoning to support this claim. The comment lacks concrete evidence or detailed explanation, making it difficult for the authors to fully understand and address the issue. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a potential issue with Equation 8, specifically the subtraction of \"s\" from the dynamic information, which could lead to the loss of dynamic information and hinder the LSTM module\"s ability to capture complete dynamic changes. This feedback is 3 as it points out a specific area of concern that the authors should address. However, it lacks depth and does not provide detailed guidance on how to resolve the issue or suggest alternative approaches. While it highlights a potential problem, it does not offer actionable steps for improvement, limiting its usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this relationship. However, it does not provide explicit instructions or suggestions for the authors to address these questions. The authors are left to infer that they should investigate or discuss these aspects in their paper, but the comment lacks concrete guidance on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this relationship. However, it does not specify which part of the paper these questions relate to, such as specific sections or figures that discuss MC samples or network structure. Without explicit references, the authors cannot confidently determine which parts of the paper need attention. The comment is specific in its inquiry but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point consists of questions seeking clarification on the impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this relationship. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this relationship. While it identifies areas that need further exploration or clarification, it lacks specific suggestions or guidance on how the authors might address these questions. The comment provides a direction for potential improvement but does not offer actionable steps or detailed advice, making it 3. The authors are left to infer that they should investigate these aspects further, but the feedback could be more comprehensive with additional guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of direct comparisons between the proposed approach and the prior approach PRANC in both language and vision tasks. It notes that while there are comparisons of training loss and the rank of possible solutions, there is no direct comparison of test accuracy. This feedback implies that the authors should include a direct comparison of test accuracy to demonstrate whether their approach is an improvement over the baseline. However, it does not provide specific guidance on how to conduct this comparison or what metrics to use. The action is implicit and somewhat vague, as the authors can infer the need for a direct comparison but may not know exactly how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4\" and \"Section 3.5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of direct comparisons with the prior approach PRANC in terms of test accuracy, despite comparisons of training loss and the rank of possible solutions. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that there is a lack of direct comparisons between the proposed approach and the prior approach PRANC in terms of test accuracy, despite comparisons of training loss and the rank of possible solutions. This claim is 3 as it highlights a gap in the evaluation process, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The comment suggests that a direct comparison of test accuracy is necessary to determine if the proposed approach is an improvement over the baseline. While the authors are directed to consider this gap, the comment could be strengthened by providing more detailed guidance or examples of how to conduct such a comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation of the proposed approach, specifically the lack of direct comparisons with the prior approach PRANC in both language and vision tasks. It highlights that while there are comparisons of training loss and the rank of possible solutions, there is no direct comparison of test accuracy, which is crucial to determine if the proposed approach is an improvement over the baseline. This feedback is clear and actionable, as it directs the authors to include a direct comparison of test accuracy to strengthen their evaluation. However, the comment could be more helpful if it provided specific suggestions on how to conduct this comparison or what metrics to use. Overall, the comment is 4, as it effectively points out a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the generalizability of the method to other domains and questions the selection process of 21 event types from Freebase, as well as the coverage of the 33 event types in the ACE data. While the comment identifies specific areas of concern, it does not provide explicit instructions or suggestions on how the authors should address these issues. The authors can infer that they need to provide more information about the selection process and the coverage of event types, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it points out areas for improvement but does not provide detailed steps for execution.", "grounding_specificity_rationale": "The comment raises concerns about the generalizability of the method to other domains and questions the selection process of 21 event types from Freebase, as well as the coverage of the 33 event types in the ACE data. It specifically mentions \"Section 2 line 262,\" which provides full grounding as it allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details what needs to be addressed, namely the selection process and coverage of event types. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the generalizability of the method to other domains and questions the selection process of 21 event types from Freebase, as well as the coverage of the 33 event types in the ACE data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these concerns. Without additional context or justification, the authors may find it challenging to address these issues effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the method to other domains, specifically questioning the selection process of 21 event types from Freebase and the coverage of the 33 event types in the ACE data. This is a relevant issue that the authors should address to enhance the robustness and applicability of their work. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might improve the generalizability or address these concerns. As it stands, the comment identifies a weakness but lacks actionable advice, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct experiments on generation tasks that are more likely to require a wellperforming language model, such as language modeling, machine translation, or text summarization. This is an explicit action with concrete details on how to implement it, as it specifies the types of experiments that could strengthen the paper\"s claims about the importance of language modeling capability. The authors know exactly what experiments to conduct to address the feedback, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experiments conducted, namely that they do not adequately reflect the language modeling capability. The comment suggests including tasks like language modeling, machine translation, or text summarization to strengthen the paper\"s claims. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s experiments on word similarity and SquAD in section 5.3 do not adequately reflect the language modeling capability of pretrained models. The reviewer suggests that the authors should include tasks like language modeling, machine translation, or text summarization to strengthen this part of the paper. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that these tasks are more relevant to language modeling. This makes the claim 3, as it requires further evidence or detailed reasoning to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper, noting that the experiments conducted in section 5.3 do not adequately reflect the language modeling capability of pretrained models. It suggests that the authors should consider including tasks like language modeling, machine translation, or text summarization to strengthen this part of the paper. This feedback is clear and actionable, providing the authors with a concrete direction for improving their draft. However, it could be more helpful if it offered additional guidance on how to implement these suggestions or why these tasks are particularly relevant. Overall, the comment is 4 as it effectively points out a gap in the paper and offers a constructive suggestion for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the improvement of the proposed method over existing RL methods is not impressive. However, it does not provide any specific guidance or suggestions on how the authors could improve their method or address this issue. There is no explicit or implicit action for the authors to take, leaving them without a clear understanding of what changes are needed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment claims that the improvement of the proposed method over existing RL methods is not impressive. However, it does not specify which part of the paper this claim is based on, nor does it provide details on what aspects of the improvement are lacking. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the improvement are not impressive. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvement of the proposed method over existing RL methods is not impressive. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or comparisons to existing methods, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment claims that the improvement of the proposed method over existing RL methods is not impressive. However, it lacks specificity and does not provide any detailed feedback or suggestions on how the authors could enhance their method or address this issue. Without actionable guidance or examples, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 1."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a claim in the paper as misleading and suggests that prior work (e.g., ClimateBench or ClimateSet) already addresses the gap being claimed. However, it does not provide explicit guidance on how the authors should address this issue or clarify the misleading claim. The action is implicit, as the authors need to infer that they should clarify the novelty of their work by comparing it to existing literature. The comment lacks concrete details on how to execute this action, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific claim in the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by pointing out that the claim is misleading without acknowledging prior work, such as ClimateBench or ClimateSet, which already addresses the gap being claimed. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the statement \"To address this gap, we propose PACE, which treats climate emulation as a diagnostictype prediction\" is misleading because prior work (e.g., ClimateBench or ClimateSet) already addresses this gap. However, the comment does not provide specific examples or detailed comparisons to support this claim, making it 3. The authors would need to investigate the prior work mentioned to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific claim in the paper as misleading, suggesting that prior work (e.g., ClimateBench or ClimateSet) already addresses the gap being claimed. This feedback is valuable as it points out a potential error in the paper\"s claims, prompting the authors to clarify their contribution and differentiate it from existing work. However, the comment could be more helpful if it provided specific examples or references to the prior work, which would give the authors a clearer understanding of what needs to be addressed. Overall, the comment is 3 as it highlights an important issue but lacks detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests moving some visual results from the supplementary material to the main paper, specifically noting the lack of visual results on crowd density estimation, which is the main experiment. It also suggests condensing the figures illustrating the proposed network architecture from three to two and using the freed space for visual results. This feedback is explicit and provides concrete actions for the authors to take, such as moving visual results and condensing figures. The suggestion is clear and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to move visual results from the supplementary material to the main paper, specifically highlighting the lack of visual results on crowd density estimation, which is the main experiment. It also suggests condensing the figures illustrating the proposed network architecture from three to two and using the freed space for visual results. This provides clear guidance on what needs to be addressed and where, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests moving visual results from the supplementary material to the main paper, specifically noting the lack of visual results on crowd density estimation, which is the main experiment. The reviewer provides a logical reasoning by pointing out the imbalance in the presentation of visual results, suggesting that the authors should condense the figures illustrating the proposed network architecture to make space for additional visual results. This reasoning is clear and provides a specific suggestion for improvement, making the claim 4. However, the comment could be strengthened with specific examples or references to similar practices in the field, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that some visual results currently in the supplementary material should be moved to the main paper. It highlights the lack of visual results on crowd density estimation, which is the main experiment, and suggests condensing the figures illustrating the proposed network architecture to make space for these visual results. This feedback is clear and constructive, offering a direct way for the authors to enhance the presentation and clarity of their work. By addressing this suggestion, the authors can improve the visibility and impact of their findings, making the comment 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should include analysis or results on other datasets, specifically mentioning ImageNet derivatives. It provides a clear action for the authors to take, which is to verify the effectiveness of the framework on these datasets and present the results in the main paper. The comment is specific and provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for analysis or results on other datasets, such as ImageNet derivatives, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the analysis or results on these datasets, and suggests presenting them in the main paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks analysis or results on datasets other than CIFAR derivatives, specifically mentioning ImageNet derivatives. The reviewer suggests that verifying the effectiveness of the framework on ImageNet1k or ImageNet100 is important. This claim is 3 as it provides a logical reasoning for the importance of including results on other datasets. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand the context and scope of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting that it only presents improvements on CIFAR derivatives and lacks analysis or results on other datasets, such as ImageNet derivatives. It provides a clear and actionable suggestion to include results on these datasets, specifically mentioning ImageNet1k or ImageNet100, which would enhance the paper\"s comprehensiveness and robustness. The comment is specific and offers a concrete direction for improvement, making it 5 for the authors. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a discrepancy between how BigFive and MBTI are referred to in the Abstract, Introduction, and Experiments sections. It suggests that these should be consistently referred to as datasets throughout the paper, unless the authors provide an extended explanation for their current usage. This feedback is clear and provides a direct action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the Abstract, Introduction, and Experiments sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of inconsistent labeling of BigFive and MBTI, suggesting that they should be referred to as datasets throughout the paper unless an extended explanation is provided. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that BigFive and MBTI are referred to as models in the Abstract and Introduction but are used as datasets in the Experiments section. The reviewer suggests that it would be better to consistently refer to them as datasets throughout the paper, unless the authors provide an extended explanation for their current usage. This claim is 3 as it points out an inconsistency in the paper\"s terminology, but it lacks specific examples or references to support the claim. The authors would need to verify the accuracy of the claim and consider the suggested change, making the comment 3.", "helpfulness_rationale": "The review comment identifies a specific inconsistency in the paper, noting that BigFive and MBTI are referred to as models in the Abstract and Introduction but are used as datasets in the Experiments section. It provides a clear and actionable suggestion to consistently refer to them as datasets throughout the paper, unless the authors provide an extended explanation for their current usage. This feedback is valuable as it highlights a potential source of confusion and offers a straightforward way for the authors to improve the clarity and consistency of their paper. However, the comment could be more helpful if it included additional guidance on how to address the potential confusion or why the distinction matters. Overall, the comment is 4, as it provides clear guidance for improvement but could be more comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to include rejection rates in their experiments or to consider misclassifications as rejections in the results. This provides a clear and direct action for the authors to take, ensuring they understand exactly what needs to be done to address the comment. The feedback is concrete and actionable, as it specifies both options for how to incorporate rejection rates into the results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of missing rejection rates and suggests including them or viewing misclassifications as rejections in the results. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the rejection rate is not shown in any experiments and suggests including it or viewing misclassifications as rejections. This claim is 3 as it provides a logical reasoning for why the rejection rate should be included, but it lacks specific examples or references to support the necessity of including this information. The suggestion to view misclassifications as rejections is a reasonable one, but without further elaboration or evidence, the claim remains 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by pointing out that the rejection rate is not shown in any experiments. It provides a logical suggestion to either include the rejection rates or consider misclassifications as rejections in the results. This feedback is clear and actionable, offering the authors a concrete way to enhance their analysis and presentation of results. By addressing this issue, the authors can provide a more comprehensive understanding of their experiments, which is valuable for the readers. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for the final thresholds used for the results and suggests that sharing the full set of hyperparameters would enhance reproducibility. This provides clear and direct actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly asks about the \"final thresholds\" used for the results, allowing the authors to accurately identify the part of the paper being addressed. It also suggests sharing the full set of hyperparameters, which is a specific request that can guide the authors on how to improve the reproducibility of their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for clarification regarding the final thresholds used for the results and a suggestion to share the full set of hyperparameters for reproducibility. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement by asking for the final thresholds used for the results and suggesting that sharing the full set of hyperparameters would enhance reproducibility. This feedback is clear and actionable, providing the authors with a direct way to improve the transparency and reproducibility of their work. However, the comment could be more helpful if it offered additional guidance on how to present these thresholds or hyperparameters, such as suggesting specific formats or locations within the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that Figure 1 could be optimized to use less whitespace. However, it does not provide any specific guidance or suggestions on how to achieve this optimization. The action is implicit, as the authors need to infer that they should reduce the whitespace in Figure 1, but it is vague because it lacks concrete details on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the optimization of Figure 1 to use less whitespace. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 1 could be optimized to use less whitespace. However, it does not provide any reasoning, examples, or references to support why this optimization is necessary or beneficial. The comment lacks specific details or evidence to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that Figure 1 could be optimized by using less whitespace. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance on how to achieve this optimization. The authors are left with a vague suggestion without actionable steps to enhance their figure. Therefore, the comment is 2, as it offers minimal guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the replacement of the first column of Qo by vo to form P\"o, which results in the first state becoming unreachable but from a terminating state. The reviewer assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of a sequence) is violated. However, the comment does not provide explicit guidance on how the authors should address this issue or which assumption is more relevant. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and address the violation of these assumptions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 140,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the replacement of the first column of Qo by vo to form P\"o, explaining how this affects the reachability of the first state. The comment further assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of a sequence) is violated, providing a clear direction for the authors to investigate and address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the replacement of the first column of Qo by vo to form P\"o, which results in the first state becoming unreachable but from a terminating state. The reviewer assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of a sequence) is violated. However, the comment lacks specific reasoning or evidence to support this claim, such as examples or references to similar issues in the literature. The assumption is based on logical reasoning, but without further elaboration or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the replacement of the first column of Qo by vo to form P\"o, which results in the first state becoming unreachable but from a terminating state. It assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of a sequence) is violated, providing a clear direction for the authors to investigate and address the issue. However, the comment lacks detailed guidance on how to resolve the problem or which assumption is more relevant, leaving the authors with some insight but incomplete feedback. Therefore, the comment is 3, as it highlights a potential issue but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that if the authors did not observe improvements in FLOPs or inference time, they should consider whether there are any improvements in accuracy or specific properties. It provides a specific example related to the recurrent model, suggesting that the sequential relationship might be easier to model. This feedback is explicit and provides a concrete direction for the authors to explore, making it 5.", "grounding_specificity_rationale": "The comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider whether there are any improvements in accuracy or specific properties. It provides a specific example related to the recurrent model, suggesting that the sequential relationship might be easier to model. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The suggestion is specific in terms of what the authors should consider, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that if the authors did not observe improvements in FLOPs or inference time, they should consider whether there are any improvements in accuracy or specific properties. It provides a specific example related to the recurrent model, suggesting that the sequential relationship might be easier to model. However, the comment lacks detailed reasoning or evidence to support why the authors should focus on these aspects or how they relate to the improvements in the model. The suggestion is based on logical reasoning but lacks specific examples or references to substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that if the authors did not observe improvements in FLOPs or inference time, they should consider whether there are any improvements in accuracy or specific properties. It provides a specific example related to the recurrent model, suggesting that the sequential relationship might be easier to model. This feedback is clear and actionable, offering a direction for the authors to explore and potentially identify additional benefits of their approach. However, the comment could be more helpful if it provided more detailed guidance on how to analyze these aspects or offered specific metrics to consider. Overall, the comment is 4 as it directs the authors to a relevant area for further investigation, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the assumption that d_e are good replacements for entity embeddings has been tested. While it implies that the authors should verify this assumption, it does not explicitly instruct them to conduct a test or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to test the assumption but are not given specific steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about an assumption made in the paper regarding the use of d_e as replacements for entity embeddings. However, it does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in its inquiry about whether this assumption has been tested, providing a clear direction for the authors to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether the assumption that d_e are good replacements for entity embeddings has been tested. This is a claim that requires verification, as it suggests a potential gap in the paper\"s methodology or results. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or justification, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical question about an important assumption made in the paper, specifically whether the use of d_e as replacements for entity embeddings has been tested. This is a relevant and timely concern that could significantly impact the validity and reliability of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or what specific tests or evaluations could be conducted to verify the assumption. While it identifies a potential weakness, the feedback is incomplete and does not offer actionable steps for improvement. Therefore, the comment is 3, as it prompts the authors to consider a critical aspect of their work but does not fully support them in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the choice of IoT datasets (FlatCam Face and Headpose detection) is unusual and may make the benchmarking results difficult to evaluate. It suggests that better options for IoT benchmarking could include wearable health or mobile activity recognition data, or datasets from the UCI repository. This feedback provides a clear and concrete action for the authors to consider alternative datasets that might improve the comprehensibility and relevance of their benchmarking results. The comment is explicit and provides specific guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the choice of IoT datasets, specifically mentioning \"FlatCam Face\" and \"Headpose detection,\" and suggests alternative datasets that could be used for benchmarking. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the choice of IoT datasets is unusual and may make the benchmarking results difficult to evaluate. The reviewer provides specific examples of the datasets used, \"FlatCam Face\" and \"Headpose detection,\" and explains why they are considered uncommon choices. The reviewer also suggests alternative datasets that could be used for benchmarking, such as wearable health or mobile activity recognition data, or datasets from the UCI repository. This provides a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to support the assertion that these datasets are not commonly used. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the choice of IoT datasets used in the paper, namely \"FlatCam Face\" and \"Headpose detection.\" It questions the relevance and popularity of these datasets, suggesting that they may not be the best choices for benchmarking. The reviewer provides a rationale for this concern, noting that the datasets are relatively recent or outdated, which could make the benchmarking results less understandable. Additionally, the comment offers suggestions for alternative datasets that could be used, such as wearable health or mobile activity recognition data, or datasets from the UCI repository. This feedback is clear and actionable, as it directs the authors to consider more appropriate datasets for their benchmarking, which could significantly improve the comprehensibility and relevance of their results. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper formatting is off and does not follow the NeurIPS formatting style. It specifically mentions issues with the abstract font size and bottom page margins. The reviewer suggests that by fixing these formatting issues, the authors could gain space and include the NLP experiments in the main body of the paper. This feedback provides clear and concrete actions for the authors to take, such as ensuring the paper adheres to the NeurIPS formatting guidelines and adjusting the font size and margins accordingly. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the paper formatting, specifically the abstract font size and the bottom page margins, which are clear indicators of the parts of the paper being addressed. It also provides specific guidance on how to address these issues, such as ensuring the paper follows the NeurIPS formatting style and gaining space to include NLP experiments in the main body. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper formatting is off and does not follow the NeurIPS formatting style, specifically mentioning issues with the abstract font size and bottom page margins. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact nature of the formatting issues. The suggestion to fix the formatting to include NLP experiments in the main body is logical but lacks detailed justification or evidence. Therefore, the claim is 3, as it provides a general direction but lacks specific details or references to substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper formatting, noting that it does not follow the NeurIPS formatting style. It highlights two specific problems: the abstract font size is too large and the bottom page margins are altered. The reviewer suggests that by correcting these formatting issues, the authors could gain space and include the NLP experiments in the main body of the paper. This feedback is clear and actionable, providing the authors with a concrete step to improve the presentation and organization of their work. However, the comment could be more helpful if it offered additional guidance on how to ensure the paper adheres to the NeurIPS style or provided examples of how to effectively integrate the NLP experiments into the main body. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the annotations in Figure 4 should be further enlarged for better visibility. This is a direct and concrete action that the authors can take to improve their draft. The comment clearly instructs the authors on what needs to be done, providing a specific and actionable step. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the enlargement of annotations in Figure 4 for better visibility. This provides clear guidance on how to improve the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the annotations in Figure 4 should be enlarged for better visibility. However, it does not provide any reasoning or evidence to support why this is necessary or how it would improve the figure. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the draft. By recommending that the annotations in Figure 4 be enlarged for better visibility, the reviewer offers a clear and concrete way for the authors to enhance the clarity and usability of their figure. This feedback is direct and provides a tangible step for the authors to take, making it 4. However, it could be more helpful if it included additional context or explanation for why this change is necessary or how it would impact the overall understanding of the figure. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the text, pointing out that multiple entities can exist in both sentences and documents, which is relevant even for relation classification tasks beyond documentlevel RE or joint entity and relation extraction. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what changes should be made to the draft. As a result, the authors are left without any actionable steps to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 2627,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, pointing out that multiple entities can exist in both sentences and documents, which is relevant even for relation classification tasks beyond documentlevel RE or joint entity and relation extraction. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement describing a characteristic of entities in sentences and documents, particularly in relation to relation classification tasks. It does not express an opinion, suggestion, or claim that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the text, pointing out that multiple entities can exist in both sentences and documents, which is relevant even for relation classification tasks beyond documentlevel RE or joint entity and relation extraction. This feedback is clear and highlights a potential misunderstanding or oversimplification in the paper. However, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it offers some insight into the topic, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to change the label on the color bar in Fig. 4 to \"worse\". This is a direct and concrete action that the authors can take to improve their draft. The comment clearly specifies what needs to be done, providing a precise instruction for modification. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the color bar, suggesting that one of the labels should say \"worse.\" This provides clear guidance on what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement requesting a change in the label on the color bar in Fig. 4. It does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it identifies a particular issue with the color bar in Fig. 4, suggesting that one of the labels should be changed to \"worse.\" This feedback is clear and provides a direct way for the authors to improve their draft by making a specific change. However, the comment could be more helpful if it explained why this change is necessary or how it would enhance the clarity of the figure. Despite this, the comment is 4 as it offers a concrete suggestion for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a specific error in the text, indicating that the phrase \"\u2026training/validation/test\" should be corrected to \"\u2026training/validation/test sets.\" This provides clear and direct guidance on what needs to be changed in the draft. The action is explicit and concrete, leaving no ambiguity for the authors on how to implement the suggested correction. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 757 in Supp. Page 29,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error, which is the incorrect use of \"\u2026training/validation/test\" instead of \"\u2026training/validation/test sets.\" This provides clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement pointing out a specific error in the text, \"\u2026training/validation/test\" should be corrected to \"\u2026training/validation/test sets.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific error in the text, providing clear and actionable feedback. By pointing out the incorrect phrase \"\u2026training/validation/test\" and suggesting the correction to \"\u2026training/validation/test sets,\" the reviewer offers a precise and straightforward way for the authors to improve their draft. This level of detail and specificity empowers the authors to make a direct and meaningful change, enhancing the clarity and accuracy of their work. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the definition of the quantile is confusing and proposes two potential solutions: adding an extra pair of brackets around the term or defining the bracketed term separately if space allows. While the comment provides explicit suggestions for improvement, it does not specify which part of the paper the definition is located in, making it somewhat vague in terms of execution. The authors know what needs to be done but may need to search the paper to identify the exact location of the definition. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"definition of the quantile,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific suggestions for improvement, such as adding an extra pair of brackets or defining the bracketed term separately, which clearly specifies what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the definition of the quantile is confusing and proposes two potential solutions: adding extra brackets or defining the bracketed term separately. However, the comment does not provide any reasoning or evidence to support why the current definition is confusing or how the suggested changes would improve clarity. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of the quantile, suggesting that it is confusing. It provides two potential solutions to clarify the definition: adding an extra pair of brackets or defining the bracketed term separately if space allows. This feedback is clear and actionable, offering the authors concrete steps to improve the clarity of their work. However, the comment could be more helpful if it explained why the current definition is confusing or provided additional context. Overall, the comment is 4 as it directs the authors to a specific area needing improvement and offers practical suggestions for enhancement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests replacing the term \"stateoftheart\" with \"very high performing model\" in line 152, citing the model by Dozat and Manning (2016) as no longer stateoftheart. This feedback is explicit, as it clearly instructs the authors to make a specific change to their draft. The suggestion is also concrete, as it provides a clear alternative phrase to use. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 152,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests replacing the term \"stateoftheart\" with \"very high performing model,\" providing a clear action for improvement. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the model by Dozat and Manning (2016) is no longer stateoftheart, recommending a replacement with \"very high performing model.\" However, the comment does not provide any supporting evidence or reasoning to justify why the model is no longer considered stateoftheart. Without additional context or references, the claim remains 1, as the authors would need more information to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the terminology used in the paper, suggesting that the term \"stateoftheart\" may not accurately reflect the current status of the model by Dozat and Manning (2016). It provides a clear and actionable suggestion to replace this term with \"very high performing model,\" which could help maintain the accuracy and relevance of the paper. However, the comment could be more helpful if it included additional context or explanation about why the model is no longer considered stateoftheart, or if it suggested alternative models that could be used for comparison. Overall, the feedback is 4 as it directs the authors to a specific improvement, but it could be more comprehensive with additional context or suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether there are other properties of features that could be used besides norm, and suggests that it is necessary and helpful for the approach design. However, it does not provide explicit guidance or suggestions on how the authors should explore or utilize these properties. The action is implicit, as the authors need to infer that they should consider other properties, but it lacks concrete details on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about whether there are other properties of features that could be used besides norm, suggesting it is necessary and helpful for the approach design. However, it does not specify which part of the paper this question pertains to, nor does it provide details on what specific properties or aspects of the approach design are being questioned. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine where this comment should be addressed. Additionally, the comment lacks specificity regarding what other properties might be considered or how they could be integrated into the approach. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about whether there are other properties of features that could be used besides norm, suggesting it is necessary and helpful for the approach design. However, the comment lacks any supporting evidence, reasoning, or references to substantiate the claim that other properties are necessary or beneficial. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about whether there are other properties of features that could be used besides norm, suggesting that it is necessary and helpful for the approach design. While the comment identifies a potential area for exploration, it lacks specificity and does not provide any guidance or suggestions on how the authors might investigate or utilize these other properties. Without actionable advice or examples, the authors are left with a vague direction for improvement, making the comment 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point identifies several weaknesses in the method, including its reliance on previous methods and the lack of network changes or losses. It also questions the use of two SIRENs for functions f and d, suggesting that d could be a simpler network. While the comment highlights areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The feedback is 3 as it points out specific issues but lacks detailed guidance on how to address them. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses specific weaknesses in the method, such as its reliance on previous methods and the lack of network changes or losses. It also questions the use of two SIRENs for functions f and d, suggesting that d could be a simpler network. This provides clear guidance on what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims about the method, including its reliance on previous methods and the lack of network changes or losses. It also questions the use of two SIRENs for functions f and d, suggesting that d could be a simpler network. While the comment identifies potential weaknesses, it lacks specific examples or references to support these claims. The reasoning is somewhat logical but incomplete, making it difficult for the authors to fully understand and address the issues. Therefore, the comment is considered 2, as it provides some justification but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies several weaknesses in the method, including its reliance on previous methods and the lack of network changes or losses. It also questions the use of two SIRENs for functions f and d, suggesting that d could be a simpler network. This feedback is clear and actionable, as it points out specific areas where the method could be improved and provides a rationale for why these changes might be beneficial. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of simpler networks that could be used for d. Overall, the comment is 4 as it directs the authors to areas that need further development and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a redundancy in RQ1, suggesting that it does not add any new information for the audience. It implies that the authors should consider analyzing the impact of explicit hate information on implicit hate speech detection performance and its effect on RQ2 and RQ3 tsne plots. While the comment suggests an alternative analysis, it does not provide explicit instructions on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RQ1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with RQ1, stating that it adds no extra information for the audience and suggests an alternative analysis regarding the impact of explicit hate information on implicit hate speech detection performance and its effect on RQ2 and RQ3 tsne plots. The reference to a specific paper (\"https://aclanthology.org/2023.findingseacl.9/\") provides additional context and supports the suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that RQ1 is redundant and does not add new information for the audience. It suggests an alternative analysis regarding the impact of explicit hate information on implicit hate speech detection performance and its effect on RQ2 and RQ3 tsne plots. The comment provides a reference to a specific paper, which could support the suggestion for an alternative analysis. However, the claim about RQ1 being redundant lacks detailed reasoning or evidence, making it 3. The suggestion for an alternative analysis is more verifiable due to the reference, but the overall claim is not fully supported. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a redundancy in RQ1, suggesting that it does not provide any additional information for the audience. It implies that the performance variation across multiple HS datasets in a crossdata setting is expected and therefore not novel. The comment also offers a constructive suggestion for an alternative analysis, focusing on the impact of explicit hate information on implicit hate speech detection performance and its effect on RQ2 and RQ3 tsne plots. This feedback is actionable and provides a clear direction for the authors to enhance their analysis. However, it could be more helpful if it included specific guidance on how to implement this alternative analysis. Overall, the comment is 4 as it identifies a potential area for improvement and suggests a meaningful direction for further analysis."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the differences between the current work and other papers that focus on semantic face editing, specifically those that demonstrate continuous control over different attributes. While it does not explicitly instruct the authors to make any changes, it implies that the authors should provide a detailed explanation of how their work differs from these other papers. This inference is clear, and the authors know exactly what action to take to address the comment. The feedback is concrete, as it specifies the need to elaborate on the differences, making it 4.", "grounding_specificity_rationale": "The comment raises a question about the differences between the current work and other papers focusing on semantic face editing, specifically those that demonstrate continuous control over different attributes. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where these differences should be discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. The comment is specific in its request for elaboration on the differences, but it is 1 as it does not clearly identify the section or context where this information should be included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the differences between the current work and other papers that focus on semantic face editing, specifically those that demonstrate continuous control over different attributes. However, it does not make a claim or provide any subjective opinion, judgment, or suggestion that requires verification. It is a factual question seeking clarification, which aligns with the \"No\" label.", "helpfulness_rationale": "The review comment raises a relevant question about the differences between the current work and other papers that focus on semantic face editing, specifically those that demonstrate continuous control over different attributes. By asking the authors to elaborate on these differences, the comment encourages the authors to provide a clearer understanding of their work\"s originality and contributions. This feedback is 3 as it prompts the authors to address a potential gap in their paper, but it could be more helpful if it included specific suggestions on how to frame the differences or what aspects to focus on. Overall, the comment provides a direction for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a minor issue with Figure 3, noting that \"OAA\" is not referenced in the body text and suggesting that there might be missing content in the appendix or an outdated caption. While the comment identifies the problem, it does not provide explicit instructions on how to address it. The authors are left to infer that they need to either update the caption, include the missing content, or clarify the reference to \"OAA\" in the body text. The action is implicit and somewhat vague, as the authors are not given specific guidance on how to resolve the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that \"OAA\" is not referenced in the body text and suggesting that there might be missing content in the appendix or an outdated caption. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about Figure 3, noting that \"OAA\" is not referenced in the body text. It suggests that there might be missing content in the appendix or an outdated caption. However, the comment does not provide specific examples or detailed reasoning to support the claim that the content is missing or the caption is outdated. This lack of detailed justification makes the claim 3, as the authors would need to investigate further to understand the issue fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a minor issue with Figure 3, noting that \"OAA\" is not referenced in the body text. It suggests that there might be missing content in the appendix or that the caption is outdated. This feedback is 3 as it points out a potential inconsistency or missing reference in the paper, prompting the authors to review and correct this issue. However, the comment could be more helpful if it provided specific guidance on how to address the issue, such as suggesting where the reference should be included or how to update the caption. Overall, the comment provides some direction for improvement but lacks depth, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify in the introduction that their proposed solution is a \"fix\" of an existing work, rather than a new approach. It also specifies that the authors should mention the existing work 12 and its relation to their framework. This feedback provides clear and concrete guidance on what the authors need to do to improve their draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction and lines 2930, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: the distinction between the proposed solution being a \"fix\" of an existing work rather than a new approach. Additionally, it highlights the need to mention the existing work 12 and its relation to the framework. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors must clarify in the introduction that their proposed solution is a \"fix\" of an existing work, rather than a new approach. The reviewer supports this claim by referencing specific lines in the paper (2930) and mentioning the existing work 12. This provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the existing work relates to the proposed solution. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction, where the authors claim their solution is a new approach when, in fact, it is a \"fix\" of an existing work. The reviewer points out that the authors should clarify this distinction and mention the existing work 12 to avoid confusion. This feedback is clear and actionable, providing the authors with a direct way to improve the clarity and accuracy of their introduction. By addressing this point, the authors can enhance the transparency and credibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the effective receptive field is improved after applying the GS module, suggesting that this could be computed from reference 2. While it implies that the authors should investigate this aspect, the comment does not provide explicit instructions or concrete steps on how to conduct this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should explore the impact of the GS module on the receptive field. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"GS module,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the effective receptive field and suggests that it could be computed from reference 2. This provides clear guidance on what aspect of the GS module needs further exploration or clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about whether the effective receptive field is improved after applying the GS module, suggesting that this could be computed from reference 2. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or the suggestion to compute the effective receptive field. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an interesting question about the impact of the GS module on the effective receptive field, suggesting that it could be computed from reference 2. This feedback is 3 as it prompts the authors to consider an important aspect of their methodology, specifically how the GS module affects the receptive field. However, the comment lacks depth and does not provide specific guidance on how to compute or analyze the effective receptive field, nor does it suggest potential improvements or alternatives. While it identifies a potential area for exploration, it does not offer actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the rationale behind combining G4RL with HRAC (HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. While it does not explicitly instruct the authors to address these questions, it implies that the authors should provide a rationale or explanation for this combination. The action is implicit, as the authors need to infer that they should clarify the reasoning behind the combination. However, the comment is 3 because it provides a clear direction for the authors to follow, even if it does not specify exactly how to address the questions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the rationale behind combining G4RL with HRAC (HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. However, it does not specify which part of the paper discusses this combination, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in its questioning of the rationale and requirements, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the rationale behind combining G4RL with HRAC (HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the rationale behind combining G4RL with HRAC (HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. This feedback is 3 as it prompts the authors to clarify the reasoning behind their approach, which could lead to a better understanding of the methodology and its components. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address these questions, leaving the authors with a general direction but not a detailed path forward. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the results in Table 2, specifically the comparison between linear/exponentialdecay sampling and uniform sampling. The reviewer expresses confusion about why the former underperforms the latter, given the argument that the predictor is accurate on the good subregion. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this confusion or improve their analysis. Without actionable suggestions or questions that prompt further investigation, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the confusion regarding the results, specifically the underperformance of linear/exponentialdecay sampling compared to uniform sampling. The comment provides a clear rationale for the confusion, suggesting that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming architectures should lead to better performance than uniform sampling. This level of detail helps the authors understand what needs to be addressed in their analysis. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the results in Table 2, specifically the underperformance of linear/exponentialdecay sampling compared to uniform sampling. The reviewer provides a logical reasoning by suggesting that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming predicted architectures should lead to better performance than uniform sampling. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to delve deeper into the analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the results presented in Table 2, specifically the underperformance of linear/exponentialdecay sampling compared to uniform sampling. It provides a logical reasoning for why this underperformance might be expected, suggesting that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming architectures should lead to better performance than uniform sampling. However, the comment does not offer any specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it highlights a potential area of confusion, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides two explicit actions for the authors to take. First, it suggests adding a brief explanation of \"multiaspect\" at specific line numbers (14 and 47), which is a clear and concrete instruction. Second, it requests a correction in Figure 1, specifying that the subscripts \"s\" and \"t\" should be \"1\" and \"2,\" respectively. These actions are explicit and provide detailed guidance on what needs to be done, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (14 and 47) and a figure (Figure 1), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the need for a brief explanation of \"multiaspect\" and the correction of subscripts in Figure 1. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two separate requests for clarification and correction. The first request for a brief explanation of \"multiaspect\" is a factual statement asking for additional information, which does not contain a claim. The second request for correcting subscripts in Figure 1 is also factual and does not express an opinion or judgment. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides two specific and actionable suggestions for improving the clarity and accuracy of the paper. First, it recommends adding a brief explanation of the term \"multiaspect\" at specific line numbers, which would enhance the reader\"s understanding of the content. Second, it points out a potential error in Figure 1, suggesting that the subscripts \"s\" and \"t\" should be \"1\" and \"2,\" respectively. These suggestions are clear and concrete, offering the authors direct guidance on how to enhance the readability and accuracy of their draft. However, the comment could be more helpful if it provided additional context or explanation for the importance of these corrections. Overall, the feedback is 4 as it provides actionable steps for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing citation for the public skipgram data set in a specific line of the paper (L425). This provides clear and direct guidance to the authors on what action to take: they need to include the missing citation. The comment is explicit and concrete, as it specifies the exact location and the action required, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L425,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of missing citations for the public skipgram data set. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement indicating a missing citation for the public skipgram data set in a specific line of the paper. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and direct, pointing out a specific issue with missing citations for the public skipgram data set in a particular line of the paper. By identifying this omission, the comment provides actionable feedback that the authors can use to improve the accuracy and completeness of their references. However, the comment could be more helpful if it suggested where the citation should be included or provided additional context about the importance of the citation. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the discussion on the arbitrary hyperparameter \u03b3 is missing, including how to set it in practice for a given graph and analyzing its sensitivity. This provides a clear action for the authors to include this discussion in their paper. The comment is specific about what needs to be addressed, offering concrete guidance on how to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"discussion on arbitrary hyperparameter \u03b3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the discussion on how to set the hyperparameter in practice for a given graph and the analysis of its sensitivity. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion on the arbitrary hyperparameter \u03b3 is missing, which would make it difficult for researchers to follow. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning on why this discussion is crucial. The lack of supporting evidence or detailed justification makes the claim 3, as the authors would need to infer the importance of this discussion themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the discussion regarding the arbitrary hyperparameter \u03b3, specifically noting the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. This feedback is clear and actionable, as it highlights a critical area that needs attention to enhance the comprehensibility and usability of the paper. By addressing this gap, the authors can provide valuable insights for researchers interested in applying the methodology. However, the comment could be more helpful if it offered suggestions on how to approach this discussion or provided examples of similar analyses in related work. Overall, the comment is 4, as it directs the authors to a specific area that requires improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to redefine Figure 3, as the expected quantities are scalars but are shown as vectors. This feedback is clear and direct, providing a specific action for the authors to take. The comment also specifies the issue, which is the inconsistent representation of scalar quantities as vectors in the figure. This level of detail ensures that the authors know exactly what needs to be done to address the issue. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which is that the expected quantities are scalars but are shown as vectors. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the quantities in Figure 3 should be represented as scalars instead of vectors, as they are expected to be scalar values. However, the comment does not provide any reasoning or evidence to support why this change is necessary or how it would improve the clarity or accuracy of the figure. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of the paper. It points out an inconsistency in the representation of quantities in Figure 3, noting that scalar values are shown as vectors. By suggesting a redefinition of the figure to accurately represent the quantities, the comment offers a clear path for the authors to enhance the presentation and accuracy of their work. This feedback is direct and helpful, as it guides the authors toward a specific improvement that can enhance the overall quality of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the resolution of the 3D voxel and its potential impact on computational and memory costs. It suggests that studying the importance of the global feature by comparing different resolutions of voxel features could be more convincing. The comment also provides a specific example of reducing the resolution to 1x1x1, which is equivalent to using a single global feature. While the comment implies that the authors should explore this aspect further, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the study of global features, questioning the resolution of the 3D voxel and its potential impact on computational and memory costs. The comment suggests comparing different resolutions of voxel features to better understand the importance of the global feature, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the resolution of the 3D voxel and its potential impact on computational and memory costs. It suggests that studying the importance of the global feature by comparing different resolutions of voxel features could be more convincing. The comment provides a specific example of reducing the resolution to 1x1x1, which is equivalent to using a single global feature. This reasoning is logical and provides a clear suggestion for improvement, making the claim 4. However, the comment could be strengthened by including references to similar studies or practices that support the suggestion. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a specific concern about the study of global features, particularly in relation to the use of voxellike features. It questions the resolution of the 3D voxel and its potential impact on computational and memory costs, suggesting that comparing different resolutions of voxel features could provide more insight into the importance of the global feature. The comment also provides a concrete example by noting that reducing the resolution to 1x1x1 is equivalent to using a single global feature. This feedback is clear and actionable, as it directs the authors to explore this aspect further and potentially improve the robustness of their analysis. However, it could be more helpful if it included specific suggestions on how to conduct these comparisons or what metrics to use. Overall, the comment is 4, as it provides valuable guidance for enhancing the paper\"s analysis and presentation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it is difficult to identify trends in Table 3, particularly with the behavior of PM+CL compared to PM or CL alone. The reviewer recommends exploring development set trends with respect to these hyperparameters. While the comment implies that the authors should analyze the trends further, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the development set trends but are not given specific guidance on how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the difficulty in seeing trends in the table, particularly with the behavior of PM+CL compared to PM or CL alone. The comment further suggests that it would be interesting to see development set trends with respect to these hyperparameters. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that it is difficult to see trends in Table 3, particularly with the behavior of PM+CL compared to PM or CL alone. The reviewer recommends exploring development set trends with respect to these hyperparameters. However, the comment does not provide any specific reasoning, examples, or references to support why this is the case or how it would be beneficial to explore development set trends. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting that it is difficult to see trends, particularly with the behavior of PM+CL compared to PM or CL alone. The reviewer suggests that it would be interesting to see development set trends with respect to these hyperparameters. This feedback is 3 as it points out a potential area for improvement in the presentation of the data, but it lacks depth and does not provide specific guidance on how to address the issue. The authors are given a general direction to explore development set trends, but without detailed suggestions or examples, the comment could be more helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a difficulty in understanding Figure 5 due to the numerous lines overlapping, suggesting that the authors could improve clarity by reporting additional metrics such as flops or model size. While the comment implies that the authors should include these metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer the need for additional metrics but may not be entirely sure of the specific metrics to report. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, noting the difficulty in understanding due to overlapping lines, and suggests that reporting additional metrics like flops or model size would improve the clarity. This provides clear guidance on what needs to be addressed to enhance the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is difficult to understand Figure 5 due to the numerous lines overlapping, and suggests that reporting additional metrics like flops or model size would improve the clarity. However, the comment does not provide specific examples or detailed reasoning to support why these metrics are necessary or how they would enhance understanding. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the importance of these metrics themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that the numerous lines overlapping make it difficult to understand. It suggests that reporting additional metrics such as flops or model size would improve the clarity and concreteness of the figure. This feedback is clear and actionable, providing the authors with a direct suggestion for enhancing the presentation of their results. However, the comment could be more helpful if it offered specific guidance on how to present these metrics or suggested alternative visualizations. Overall, the comment is 4 as it directs the authors to a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper is too dense and difficult to follow, requiring multiple reads to grasp the concepts and contribution. It provides a clear action for the authors to simplify the description and explain the architecture and computations better. Additionally, it suggests specific sections and lines that could be reduced to gain more space. This feedback is direct and provides concrete guidance on how to improve the clarity and readability of the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7, Section 8\" and \"lines 3964,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of the paper being too dense and difficult to follow, and it provides actionable suggestions for simplifying the description and explaining the architecture and computations better. The comment also suggests reducing specific sections to gain more space. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is \"too dense and is not very easy to follow,\" requiring multiple reads to grasp the concepts and contribution. The reviewer suggests simplifying the description and explaining the architecture and computations better, specifically mentioning Figure 7, Section 8, and lines 3964 as areas for reduction. While the comment provides a clear suggestion for improvement, it lacks specific examples or detailed reasoning to support the claim that the paper is overly dense. This makes the claim 3, as the authors would need to infer the exact issues and how to address them based on the general feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s density and readability, noting that multiple reads are required to grasp the concepts and contribution. It provides a clear and actionable suggestion to simplify the description and explain the architecture and computations better. The comment also specifies particular sections, such as Figure 7, Section 8, and lines 3964, that could be reduced to gain more space. This feedback is valuable as it directs the authors to focus on improving the clarity and accessibility of their work, which is crucial for the paper\"s overall impact. However, the comment could be more helpful if it offered specific examples or strategies for simplification. Overall, the comment is 4, as it provides clear guidance for improvement but could be more detailed."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that it would be interesting to evaluate the EIGNN model in terms of oversmoothing under standard settings on realworld datasets, particularly in comparison with variants that focus on dealing with oversmoothing, such as GCNII. While the comment implies that the authors should conduct this evaluation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the evaluation or what aspects to focus on. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests evaluating the EIGNN model in terms of oversmoothing under standard settings on realworld datasets, particularly in comparison with variants that focus on dealing with oversmoothing, such as GCNII. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a particular area for evaluation and comparison, which aligns with the second category. Therefore, this comment is 3, corresponding to a score of 3.", "verifiability_rationale": "The review point suggests that it would be interesting to evaluate the EIGNN model in terms of oversmoothing under standard settings on realworld datasets, particularly in comparison with variants that focus on dealing with oversmoothing, such as GCNII. The comment provides a logical suggestion for further evaluation, but it lacks specific examples or references to support the claim that this comparison would be beneficial. While the suggestion is reasonable, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment suggests an interesting direction for further evaluation of the EIGNN model, specifically in the context of oversmoothing under standard settings on realworld datasets. It also proposes a comparison with variants that focus on dealing with oversmoothing, such as GCNII. This feedback is clear and actionable, as it provides a specific area for the authors to explore and potentially improve their work. However, the comment could be more helpful if it included specific suggestions on how to conduct this evaluation or what aspects to focus on. Overall, the comment is 4, as it offers a valuable direction for further research but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing part in the paper, specifically the lack of a separate section or subsection to introduce the inference strategy for using multiple prompts in the test stage. This provides a clear and direct action for the authors to take, which is to add a separate part or subsection to address this gap. The comment is explicit and concrete, as it specifies exactly what needs to be added to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the approach method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking a separate part or subsection to introduce the inference strategy, particularly how to use multiple prompts in the test stage. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is a lack of a separate part or subsection to introduce the inference strategy, specifically how to use multiple prompts in the test stage. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the specific issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper, namely the lack of a separate part or subsection to introduce the inference strategy, particularly how to use multiple prompts in the test stage. This feedback is clear and actionable, as it provides a direct suggestion for improvement by indicating where the authors should add more detail. However, the comment could be more helpful if it offered additional guidance on what aspects of the inference strategy should be included or how to effectively present this information. Despite this, the comment is 4 as it directs the authors to a critical area that needs expansion, allowing them to enhance the clarity and comprehensiveness of their draft. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that Figure 4 is confusing and that the columns are not explained in the text or caption. This provides a clear and direct action for the authors to take: they should clarify the meaning of the columns in the figure by adding an explanation in the text or caption. The feedback is explicit and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the confusion regarding the meaning of the columns in the figure. The comment suggests that the columns are not explained in the text or caption, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 4 is confusing due to unclear column meanings, which is not explained in the text or caption. This is a subjective opinion based on the reviewer\"s interpretation of the figure. While the comment highlights a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that the columns are confusing and not explained in the text or caption. This feedback is clear and actionable, as it directs the authors to clarify the meaning of the columns, which is essential for the reader\"s understanding. However, the comment could be more helpful if it provided suggestions on how to improve the figure or offered examples of how to clarify the column meanings. Despite this, the comment is 4 as it effectively points out a critical area for improvement, guiding the authors to enhance the clarity of their figure."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides several suggestions for improvement, including a request to discuss experiment results more thoroughly and to clarify the realworld applications of the new problem setting. It also raises a question about the computational complexity of the proposed algorithm when applied to ranking problems. While the comment identifies areas that need attention, it does not provide explicit instructions or concrete steps for the authors to follow. The suggestions are implicit and somewhat vague, leaving the authors to infer the necessary actions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiment results\" and \"the realworld applications,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific points for improvement, such as discussing the results of the Streetview experiment and clarifying the applicability to sorting/ranking problems. Additionally, it raises a question about the computational complexity of the proposed algorithm when applied to ranking problems. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises several claims, including the need for more discussion of experiment results and the lack of clarity in realworld applications. The comment suggests that the Streetview experiment results may indicate that MaxGapTop2UCB is better than other methods, but it does not provide specific data or analysis to support this claim. Additionally, it questions the applicability of the proposed algorithm to sorting/ranking problems, citing the complexity of Algorithm 4. However, the comment lacks detailed reasoning or references to substantiate these claims, making them 3. The authors would need to provide more evidence or explanation to fully understand and address these points. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two main areas for improvement: the discussion of experiment results and the clarity of realworld applications. It suggests that the experiment results could be more thoroughly discussed, particularly in relation to the Streetview experiment, where it questions whether MaxGapTop2UCB is better than other methods. Additionally, it points out the lack of clarity in the realworld applications, specifically mentioning the applicability to sorting/ranking problems and the potential complexity of the proposed algorithm. The comment also raises a minor detail about the computational complexity of the algorithm when applied to ranking problems. While the feedback is clear and identifies specific areas for improvement, it could be more helpful if it provided detailed suggestions or examples on how to enhance the discussion of experiment results or clarify the realworld applications. Overall, the comment is 4 as it guides the authors toward improving their draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. The reviewer suggests that more explanations are needed. While the comment implies that the authors should provide additional explanations for the observed results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. However, it does not specify which part of the paper these results are presented in, making it difficult for the authors to pinpoint the exact section being addressed. The comment suggests that more explanations are needed, but it does not provide specific guidance on what aspects of the results or methods should be clarified. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods like fCLSWGAN and fVAEGAND2. However, the comment lacks specific reasoning or evidence to support why these results are unexpected or how they compare to the mentioned methods. Without detailed analysis or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. It suggests that more explanations are needed to understand this observation. While the comment identifies a potential issue with the results, it lacks specific guidance or suggestions on how the authors might address this concern or provide additional explanations. The feedback is 3 as it points out a potential area for improvement, but it does not offer detailed actionable advice, making it incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests a specific action for the authors to take: comparing the model trained on the original dataset with the one trained on a mixture of the original and adversarial datasets. This is an explicit suggestion that provides a clear direction for improvement. The comment also explains why this comparison is important, emphasizing the need to make the experiment more convincing as it serves as the motivation for the work. The feedback is concrete and actionable, as it gives the authors a specific task to enhance the validity of their experiment. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: comparing the model trained on the original dataset with the one trained on a mixture of the original and adversarial datasets. This provides clear guidance on how to improve the experiment to make it more convincing. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the hypothesis is not well verified by the designed experiment. It provides a specific critique by comparing the training methods of conventional models and the base model, suggesting that the experiment should compare the model trained on the original dataset with the one trained on a mixture of the original and adversarial datasets. This critique is supported by logical reasoning and references to specific sections of the paper, making it 4. However, the comment could be strengthened by providing more detailed examples or references to support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental design, noting that the hypothesis is not well verified by the current experiment. It points out a discrepancy in the training methods between conventional models and the base model, suggesting that a comparison between models trained on the original dataset and those trained on a mixture of the original and adversarial datasets would be more convincing. This feedback is clear and actionable, providing the authors with a concrete suggestion to enhance the validity and impact of their work. By addressing this critique, the authors can strengthen their experimental design and improve the overall quality of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to clarify whether the results for model (3) (Chung et al. 2016) for CsEn were computed by the authors themselves or taken from the papers. It provides a clear action for the authors to take, which is to mention the source of these results. This feedback is concrete and direct, giving the authors a specific step to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results for model (3) (Chung et al. 2016) for CsEn, noting that these results were not taken from the papers and suggesting that the authors should mention if they computed these results themselves. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results for model (3) (Chung et al. 2016) for CsEn were not taken from the papers, as they are not reported. The reviewer suggests that if the authors computed these results themselves, they should mention it. This claim is based on a logical observation and a request for clarification, making it 3. The reviewer provides a clear rationale for the claim, but it lacks specific references or detailed examples to fully substantiate the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in Table 1, noting that the results for model (3) (Chung et al. 2016) for CsEn were not taken from the papers, as they are not reported. The comment suggests that if the authors computed these results themselves, they should mention it. This feedback is clear and actionable, providing the authors with a specific area to clarify in their draft. By addressing this point, the authors can improve the transparency and accuracy of their results, making the comment 4. However, it could be more helpful if it included suggestions on how to present this information or why it is important. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that while the authors have mentioned limitations in the paper, they should provide a more detailed plan on how to address these drawbacks in their future work. This feedback is explicit, as it clearly states what the authors need to do to improve their draft. However, it is somewhat vague because it does not specify what aspects of the plan should be detailed or how the authors should present this information. The authors know they need to provide a more detailed plan but may not be entirely sure of the exact steps or level of detail required. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that while the authors have mentioned limitations in the paper, they should provide a more detailed plan on how to address these drawbacks in their future work. However, it does not specify which limitations are being referred to or where in the paper these limitations are discussed. This makes it difficult for the authors to pinpoint the exact parts of the paper that need attention. The comment is specific in its request for a detailed plan but lacks grounding, as it does not identify the specific sections or aspects of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that while the authors have mentioned limitations in the paper, they should provide a more detailed plan on how to address these drawbacks in their future work. This claim is 3 as it acknowledges the authors\" mention of limitations but highlights the need for a more detailed plan. However, the comment lacks specific examples or references to support the claim that the current plan is insufficient. Providing more detailed guidance or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the authors have mentioned limitations in the paper but suggests that they should provide a more detailed plan on how to address these drawbacks in their future work. This feedback is 3 as it identifies a potential area for improvement by encouraging the authors to be more specific about their plans for addressing the limitations. However, the comment could be more helpful if it provided specific guidance on what aspects of the plan should be detailed or how the authors might structure their future work discussion. Overall, the comment offers a direction for improvement but lacks depth, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises several specific issues with the paper, including the confusion in using \"p m\" in the numerator and \"p c\" in the denominator in Eq. 3, and the use of only the mean \"\u03bc f\" in Alg. 2 for the fusion prototype. The reviewer suggests considering the addition of variance for further improvement and recommends replacing \"\u03bc f\" with \"\u03bc g\" to maintain consistency with Eq. These suggestions are explicit and provide concrete guidance on how the authors can improve their draft. The comment is 5 as it clearly outlines specific actions for the authors to take, ensuring they know exactly what changes to make to enhance their work.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 3\" and \"Alg. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the confusion in the use of \"p m\" and \"p c\" in Eq. 3 and suggests considering the addition of variance in Alg. 2. Additionally, it provides a recommendation to replace \"\u03bc f\" with \"\u03bc g\" to maintain consistency. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises several specific issues with the paper, including the confusion in using \"p m\" in the numerator and \"p c\" in the denominator in Eq. 3, and the use of only the mean \"\u03bc f\" in Alg. 2. The reviewer suggests considering the addition of variance for further improvement and recommends replacing \"\u03bc f\" with \"\u03bc g\" to maintain consistency with Eq. These points are based on logical reasoning and provide a clear explanation of the issues, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the suggestions. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, including the confusion in using \"p m\" in the numerator and \"p c\" in the denominator in Eq. 3, and the use of only the mean \"\u03bc f\" in Alg. 2. It suggests considering the addition of variance for further improvement and recommends replacing \"\u03bc f\" with \"\u03bc g\" to maintain consistency with Eq. These observations and suggestions are clear and actionable, providing the authors with concrete steps to enhance their draft. The comment is 4 as it effectively guides the authors in addressing these specific issues, but it could be more comprehensive by explaining why the current approach might be problematic or how the suggested changes would improve the work. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the computational cost of the proposed approach, noting that the paper mentions it does not lead to \"significant delays in computation\" but lacks a comprehensive discussion on the computational complexity. The reviewer suggests that the paper should include a more detailed discussion on this aspect. While the comment implies that the authors should expand their discussion on computational complexity, it does not provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more detail but are not given concrete steps on how to achieve this. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of computational cost, specifically questioning the lack of a comprehensive discussion on the computational complexity of the proposed approach. It mentions that the paper mentions the additional cost not leading to \"significant delays in computation\" but does not provide a clear explanation. The reviewer suggests that the paper should include a more detailed discussion on this aspect and wonders if the proposed approach becomes prohibitive in some settings. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the discussion of computational costs or the methodology section. The comment is specific in its request for a more comprehensive discussion on computational complexity, making it weakly grounded but specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the lack of a comprehensive discussion on the computational cost of the proposed approach, noting that the paper mentions it does not lead to \"significant delays in computation\" but does not provide a clear explanation. The reviewer suggests that the paper should include a more detailed discussion on computational complexity and wonders if the proposed approach becomes prohibitive in some settings. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that the computational cost is a significant concern. The reasoning is 3, as it provides a logical basis for the suggestion but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s discussion of computational cost, noting that while the paper mentions the additional cost does not lead to significant delays, it lacks a comprehensive discussion on the computational complexity of the proposal. The reviewer suggests that the paper should include a more detailed discussion on this aspect and questions whether the proposed approach becomes prohibitive in certain settings. This feedback is 3 as it points out a gap in the paper\"s discussion and encourages the authors to provide more detailed analysis. However, it could be more helpful if it offered specific suggestions on how to address the issue or provided examples of what a comprehensive discussion might entail. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a missing indepth analysis of experimental results, specifically questioning why improvements are limited on the offense detection dataset and significant on the coarse stereotype set. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the analysis should be included. The action is implicit and somewhat vague, as the authors can infer that they need to conduct a more detailed analysis but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the experimental results, questioning the limited improvements on the offense detection dataset and significant improvements on the coarse stereotype set. However, it does not specify which part of the paper discusses these results, making it weakly grounded. The comment is specific in detailing what is missing, namely an indepth analysis of the experimental results. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of indepth analysis on experimental results, specifically questioning the limited improvements on the offense detection dataset and significant improvements on the coarse stereotype set. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of indepth analysis of experimental results. It provides a clear example of what is missing by questioning the limited improvements on the offense detection dataset and significant improvements on the coarse stereotype set. This feedback is actionable as it directs the authors to conduct a more detailed analysis of their experimental results, which could enhance the comprehensiveness and clarity of their findings. However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should add more baselines for graph contrastive learning and test them on common datasets. It provides specific examples of missing baselines, such as MVGRL and gptgnn, which gives the authors a clear direction on what needs to be added. The comment is explicit and concrete, providing a direct action for the authors to take. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"graph classification task,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of sufficient baselines, such as MVGRL and gptgnn, and suggests adding more baselines for graph contrastive learning and testing them on common datasets. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the baseline for the graph classification task is insufficient, specifically mentioning the absence of MVGRL and gptgnn. The reviewer suggests adding more baselines for graph contrastive learning and testing them on common datasets. While the comment identifies a potential gap in the baseline comparison, it lacks specific reasoning or evidence to support why these particular baselines are necessary or how they would enhance the study. The suggestion is 3 as it provides a direction for improvement but lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper, namely the insufficient baseline comparison in the graph classification task. It points out the absence of certain baselines, such as MVGRL and gptgnn, and suggests adding more baselines for graph contrastive learning and testing them on common datasets. This feedback is clear and actionable, providing the authors with a concrete direction for improving their draft by enhancing the baseline comparison. However, the comment could be more helpful if it included specific suggestions on which additional baselines to consider or how to implement the suggested tests. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to make the legends in Tables 1, 2, and 3 longer and to clarify whether the numbers represent percentage errors or percentage correct. This feedback provides a clear and concrete action for the authors to take, ensuring they understand exactly what needs to be done to improve their draft. The explicit nature of the comment and the specific details provided make it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the legends should be longer and clarify whether the numbers represent percentage errors or percentage correct. This provides clear guidance on how to improve the clarity of the tables. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the legends in Tables 1, 2, and 3 should be longer and clarify whether the numbers represent percentage errors or percentage correct. This is a factual statement requesting clarification, as it does not express an opinion or judgment that requires verification. It is purely descriptive and does not contain any subjective claims or suggestions that need justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the legends in Tables 1, 2, and 3 should be longer and clarify whether the numbers represent percentage errors or percentage correct. This feedback is clear and directly addresses a potential source of confusion in the paper, offering a concrete step for the authors to improve the clarity and readability of their results. By following this suggestion, the authors can enhance the comprehensibility of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a perceived weakness in the analysis, specifically regarding the theoretical work on sampling and particlebased optimization methods. It points out the lack of evidence for the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization in time and space. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific steps they should take to strengthen their analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more theoretical justification but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"theoretical work on sampling and particlebased optimization methods,\" allowing the authors to identify the part of the paper being addressed. It also specifies the issues with the analysis, such as the lack of evidence for the existence and smoothness of the solution of SDE (2a)(2d) and guarantees of discretization. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the provided analysis is \"somewhat weak\" in light of theoretical work on sampling and particlebased optimization methods. It specifically points out the lack of evidence for the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of discretization. However, the comment does not provide detailed reasoning or references to support this claim, making it 3. The authors would need to infer the specific issues and potential solutions based on the general critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a weakness in the analysis by pointing out the lack of evidence for the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of discretization. This feedback is clear and actionable, as it highlights specific areas where the authors need to strengthen their theoretical foundation. However, the comment could be more helpful if it provided suggestions on how to address these gaps or offered examples of how similar analyses have been conducted in the literature. Despite this, the comment still offers valuable guidance for improving the draft, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take, specifically asking for a description of how G is built using the human skeleton in Section 3.3 and requesting additional details such as the size and elements of G. It also suggests adding the dimensions of G, X, and W to enhance understanding. These instructions are clear and concrete, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the description of how G is built using the human skeleton, the size and elements of G, and the addition of dimensions for G, X, and W to better understand the DGCN. This provides clear guidance on what the authors need to revise in their draft. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point consists of factual requests for clarification and additional details about the construction of G using the human skeleton and the dimensions of G, X, and W. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by asking for a detailed description of how G is built using the human skeleton in Section 3.3. It also suggests adding the size and elements of G to enhance understanding. Additionally, it recommends including the dimensions of G, X, and W to better comprehend the DGCN. This feedback is clear and constructive, offering the authors concrete steps to improve their draft by providing more detailed information. However, the comment could be more helpful if it explained why this information is crucial or how it would impact the reader\"s understanding. Overall, the comment is 4 as it guides the authors toward enhancing the clarity and comprehensiveness of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the term \"hyperspectral\" is confusing and provides a clear explanation of what hyperspectral imaging is. This feedback is direct and actionable, as it instructs the authors to avoid using the term \"hyperspectral\" and instead use the correct term \"hyperspectral imaging.\" The comment provides a concrete action for the authors to take, ensuring that the terminology in their draft is accurate and clear. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"hyperspectral,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term, explaining that it is confusing and providing a definition of hyperspectral imaging. This feedback is clear and actionable, guiding the authors on how to improve their terminology. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"hyperspectral\" is confusing and provides a definition of hyperspectral imaging. This claim is supported by the explanation of what hyperspectral imaging entails, which is a clear and logical reasoning. The comment does not require external references or additional evidence, as the explanation is sufficient to understand the issue. Therefore, the claim is considered 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the terminology used in the paper, pointing out that \"hyperspectral\" is confusing and providing a clear explanation of what hyperspectral imaging is. This feedback is actionable and provides a precise suggestion for improvement, helping the authors to correct their terminology and ensure clarity in their draft. By addressing this issue, the authors can enhance the accuracy and readability of their paper. Therefore, the comment is rated as 5, as it offers clear and actionable guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that while the concept of energy is introduced in Section 3.1, it would be beneficial to refresh the idea in Section 5.2, where it is used multiple times. The reviewer also suggests providing hints on how to interpret energy, such as its relation to splitting morphemes. Additionally, the comment points out that the concept of peak in Figure 5 is not described. These suggestions are explicit and provide concrete guidance on how to improve the draft by clarifying the use of energy and peak in the paper. The authors know exactly what actions to take to enhance their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 5.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the concept of energy should be refreshed in Section 5.2 and providing hints on how to interpret it. Additionally, it points out the lack of description for the concept of peak in Figure 5. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the concept of energy should be refreshed in Section 5.2, where it is used multiple times, and provides a hint on how to interpret it. It also points out that the concept of peak in Figure 5 is not described. While the comment identifies areas for improvement, it lacks specific reasoning or examples to fully substantiate the claim. The suggestion to refresh the concept of energy and provide hints on interpretation is logical, but the comment could be strengthened with more detailed justification or references. Therefore, the claim is 3, as it provides a basis for improvement but requires further elaboration.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper. First, it suggests that the concept of energy, introduced in Section 3.1, should be refreshed in Section 5.2, where it is used multiple times. This is a clear and actionable suggestion that could enhance the clarity and coherence of the paper. Second, the comment points out that the concept of peak in Figure 5 is not described, which is an important omission that could impact the reader\"s understanding. The reviewer provides a hint on how to interpret energy, suggesting that a high energy value could indicate a split in the morpheme. This feedback is detailed and constructive, offering the authors specific guidance on how to improve their draft. Therefore, the comment is 5, as it provides clear and actionable suggestions for enhancing the paper\"s clarity and coherence."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that while some ablation studies are provided in Sections 3 and 4, the authors should further elaborate on how each component contributes to the final performance improvements. The comment explicitly states that the authors should provide more detailed information, such as how the performance of combining the Linformer and window attention in Big Bird contributes to the overall improvement. This feedback is clear and provides a concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions sections \"1), 2), and 3)\" and sections \"3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing: a detailed explanation of how each component contributes to the final performance improvements. The comment provides a concrete example of what the authors should include, such as the performance of combining the Linformer and window attention in Big Bird. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that while some ablation studies are provided, the authors should further elaborate on how each component contributes to the final performance improvements. The comment provides a specific example of what could be included, such as the performance of combining the Linformer and window attention in Big Bird. This level of detail supports the claim, making it 4. However, the comment could be strengthened by providing more examples or references to similar studies, which would fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need for a more detailed explanation of how each component contributes to the final performance improvements. It suggests that while some ablation studies are provided, the authors should elaborate on the specific contributions of each component, such as the performance of combining the Linformer and window attention in Big Bird. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their draft. However, it could be more helpful if it included specific examples or suggestions on how to present this information effectively. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the role of visual information in the paper, specifically questioning the effectiveness of the ablation study in verifying the contribution of the knowledgegraph memory and visualdriven reasoning. It highlights that the performance of \"w/o perception module\" and \"w perception\" is similar, and the implementation details of \"w/o perception\" are unknown. Additionally, it suggests that the sample size of 1000 users makes significant improvements unlikely. While the comment identifies areas of concern, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The authors are left to infer that they need to clarify the role of visual information, provide more detailed implementation information, and consider the sample size in their analysis. Therefore, the comment is 3, as it points out areas for improvement but lacks specific guidance on how to implement these changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 10,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the effectiveness of the ablation study, particularly regarding the role of visual information, and highlights the similarity in performance between \"w/o perception module\" and \"w perception.\" Additionally, it points out the lack of implementation details for \"w/o perception\" and the questionable nature of the experiment results given the sample size. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the role of visual information is unknown and questions the effectiveness of the ablation study. It provides specific details, such as the similarity in performance between \"w/o perception module\" and \"w perception\" in Table 10, and notes the lack of implementation details for \"w/o perception.\" Additionally, it points out that the sample size of 1000 users makes significant improvements unlikely. These specific examples and reasoning provide a clear basis for the claim, making it 4. However, the comment could be strengthened by including references or further explanation of why the sample size is insufficient for significant improvements. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically questioning the role of visual information and the effectiveness of the ablation study. It points out that the performance of \"w/o perception module\" and \"w perception\" is similar, and the implementation details of \"w/o perception\" are unknown. Additionally, it raises concerns about the sample size of 1000 users, suggesting that significant improvements may not be feasible. This feedback is clear and actionable, as it highlights specific areas where the authors need to provide more detailed information and analysis to strengthen their claims. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to improve the ablation study. Overall, the comment is 4, as it directs the authors to important areas for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that the end of Section 4.2 claims Transfer Lasso shows the best accuracy in feature screening but fails to cite or compare with previous works on Lasso screening, such as Ren et al. \"Safe feature screening for generalized LASSO.\" This feedback is explicit in its request for the authors to include these references and comparisons, providing a clear action for the authors to take. The comment is also concrete, as it specifies the exact references that should be included, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the end of Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of citation or comparison with previous works on Lasso screening, such as Ren et al. \"Safe feature screening for generalized LASSO.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper fails to cite or compare previous works on Lasso screening, specifically mentioning Ren et al. \"Safe feature screening for generalized LASSO.\" This claim is verifiable as it provides a specific reference to an external work that should be considered for comparison. The mention of a specific publication and the context of Lasso screening provides a clear basis for the claim, making it 4. However, the comment could be strengthened by explaining why these references are relevant or how they relate to the claim, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the end of Section 4.2 claims Transfer Lasso shows the best accuracy in feature screening but fails to cite or compare with previous works on Lasso screening. The comment provides a specific reference to a relevant work by Ren et al. that should be considered for comparison. This feedback is clear and actionable, as it directs the authors to include these references and comparisons, which would enhance the validity and comprehensiveness of their claims. By addressing this gap, the authors can improve the rigor and depth of their analysis, making the comment 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a specific claim made by the authors on line 238 regarding the Central Limit Theorem (CLT) and points out that it contains multiple incorrect assertions. However, it does not provide any guidance or suggestions on how the authors should address these inaccuracies or improve their understanding of the CLT. The comment lacks explicit or implicit actions, leaving the authors without a clear path for improvement. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim made about the Central Limit Theorem (CLT), pointing out that it makes multiple incorrect assertions. The comment provides detailed reasoning about what is incorrect, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement about the Central Limit Theorem (CLT) is incorrect. It provides a clear explanation of why the statement is incorrect, stating that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This reasoning is logical and based on common knowledge in statistics, making the claim 5. The reviewer provides a detailed explanation of the issue, which supports the claim and helps the authors understand the problem. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the Central Limit Theorem (CLT) and points out that it contains multiple incorrect assertions. It provides a clear explanation of why the claim is incorrect, stating that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is 5 as it directly addresses a critical error in the paper, allowing the authors to correct their understanding and presentation of the CLT. However, the comment could be more helpful if it offered suggestions on how to correct the statement or provided additional context for the authors to better understand the issue. Nonetheless, the comment is 5 and provides significant value to the authors, making it a 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to analyze the time complexity of the proposed policies mentioned in Section 4. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be done, making it 5. The authors know exactly what action to take and how to implement it, as the comment specifies the section of the paper that requires analysis. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the need to analyze the time complexity of the proposed policies, providing clear guidance on what needs to be addressed in this section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for analysis, which is not a claim but rather a suggestion for improvement. It does not express an opinion, judgment, or deduction that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, as it explicitly instructs the authors to analyze the time complexity of the proposed policies mentioned in Section 4. This feedback is valuable because it identifies a specific area that needs further examination, providing the authors with a clear direction for improvement. By addressing this point, the authors can enhance the rigor and comprehensiveness of their analysis, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the paper for overclaiming the strength of the proposed BC loss in theoretical analysis. It identifies specific aspects, such as geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability, which are claimed to be distinct but are actually the same concept from different viewpoints. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify the claims. The action is implicit and vague, as the authors are left to infer that they need to revise their claims but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"theoretical analysis\" and \"theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the paper\"s claims, pointing out that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are actually the same concept from different viewpoints. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper overclaims the strength of the proposed BC loss in theoretical analysis. It supports this claim by explaining that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are actually the same concept from different viewpoints. This logical reasoning provides a clear explanation of why the claim is valid, making the comment 4. However, the comment could be strengthened by providing specific examples or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that it overclaims the strength of the proposed BC loss in theoretical analysis. It points out that several aspects, such as geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability, are actually the same concept viewed from different perspectives. This feedback is clear and actionable, as it prompts the authors to revisit and clarify their claims to ensure accuracy and avoid overstatement. However, the comment could be more helpful if it provided suggestions on how to rephrase or reorganize the theoretical analysis to better reflect the actual contributions. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the relevance of the proposed method to the authors\" motivations, specifically questioning its effectiveness in evaluating a single dialogue system. The reviewer suggests that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena are more suited for comparing dialogue systems rather than evaluating a single system. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstract section\" and the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proposed method\"s relevance to the authors\" motivations and questions its effectiveness in evaluating a single dialogue system. The comment provides a clear critique of the proposed framework and its limitations, offering a specific area for improvement. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the relevance of the proposed method to the authors\" motivations, specifically questioning its effectiveness in evaluating a single dialogue system. The reviewer provides a logical reasoning by pointing out that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena are used for comparing dialogue systems, not for evaluating a single system. This reasoning is clear and provides a basis for the claim. However, the comment could be strengthened by providing specific examples or references to support the claim further. Overall, the claim is 4, as it provides a logical argument but lacks detailed evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment raises a concern about the relevance of the proposed method to the authors\" motivations, specifically questioning its effectiveness in evaluating a single dialogue system. It points out that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena are more suited for comparing dialogue systems rather than evaluating a single system. This feedback is 3 as it identifies a potential limitation of the proposed method and suggests that the authors should consider this aspect in their evaluation. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue or improve the evaluation framework. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the improvements of the proposed model over the RL without feedback model, noting that the differences are not significant, particularly for BLEU1. The reviewer suggests that the authors should verify if these improvements are statistically significant. While the comment implies that the authors should conduct a statistical analysis to address this concern, it does not provide explicit instructions on how to perform the analysis or what specific tests to use. The action is implicit and somewhat vague, as the authors need to infer the need for a statistical analysis and figure out the details themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"row3 vs. row4 in table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of the improvements not being significant, particularly for BLEU1, and suggests that the authors verify if these improvements are statistically significant. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the improvements of the proposed model over the RL without feedback model are not significant, particularly for BLEU1. The reviewer provides specific references to rows 3 and 4 in Table 6, which allows the authors to verify the claim by examining the data. However, the comment lacks detailed reasoning or examples to fully substantiate the claim of statistical insignificance. While the reference to specific rows in the table provides some basis for the claim, the lack of additional evidence or analysis makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the improvements of the proposed model over the RL without feedback model are not significant, particularly for BLEU1. It suggests that the authors verify if these improvements are statistically significant, which is a clear and actionable piece of feedback. By pointing out this potential issue, the comment helps the authors to focus on a critical aspect of their work that may impact its validity and conclusions. However, the comment could be more helpful if it provided additional guidance on how to conduct the statistical analysis or what specific tests to use. Overall, the comment is 4 as it directs the authors to a key area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests improving the choice of baseline methods, specifically recommending the inclusion of RefNeRF and MipNerF as baselines for evaluating appearance decomposition and larger outdoor scenes, respectively. This feedback is explicit and provides concrete suggestions on which methods to consider, giving the authors a clear direction on how to enhance their draft. The action is direct and actionable, as the authors know exactly which baselines to include for comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests improving the choice of baseline methods, specifically recommending RefNeRF and MipNerF for evaluating appearance decomposition and larger outdoor scenes, respectively. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where baseline comparisons are discussed. The comment is specific in suggesting particular baseline methods to include, providing clear guidance on how to enhance the evaluation. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the choice of baseline methods could be improved by comparing to other existing methods, specifically mentioning RefNeRF and MipNerF as examples. This claim is 3 as it provides specific examples of methods that could be used as baselines, offering a clear direction for improvement. However, the comment lacks detailed reasoning or references to support why these methods are particularly relevant or how they would enhance the evaluation. Therefore, the claim is 3, as it provides a starting point for the authors but requires further elaboration to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting improvements to the choice of baseline methods for evaluating appearance decomposition and larger outdoor scenes. It recommends including RefNeRF and MipNerF as baselines, which are relevant to the specific aspects of the paper being discussed. This feedback is clear and constructive, offering the authors a concrete way to enhance their draft by comparing their results to established methods. However, the comment could be more helpful if it provided additional context or justification for why these specific baselines are relevant or how they would improve the evaluation. Overall, the comment is 4 as it provides valuable guidance for improving the draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential source of confusion in the manuscript, where the symbol \"P\" is used to represent both a probability and a cumulative distribution function. However, it does not provide explicit guidance on how to resolve this issue or suggest specific actions for the authors to take. The comment implies that the authors should clarify the usage of \"P\" to avoid confusion, but it lacks concrete details on how to achieve this clarification. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific equations (Eqs. (3) and (4)) and a line number (L44) in the appendix, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the confusion caused by the use of \"P\" to represent both a probability and a cumulative distribution function. This provides clear guidance on what needs to be clarified or corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the symbol \"P\" is used to represent both a probability and a cumulative distribution function, leading to confusion. This claim is 3 as it identifies a potential issue with notation consistency. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the problem. Providing more detailed examples or explanations would enhance the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with notation consistency in the manuscript, where the symbol \"P\" is used to represent both a probability and a cumulative distribution function. This is a clear and actionable feedback that can help the authors clarify their notation and avoid confusion for readers. By pointing out specific equations and a line number in the appendix, the comment provides precise guidance on where the issue arises, allowing the authors to make targeted improvements. However, the comment could be more helpful if it suggested alternative notations or provided examples of how to clarify the usage of \"P\" in different contexts. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the suitability of feature spaces for 1NN (1nearest neighbor) classification. It suggests that if a feature space is not close to a spherical Gaussian, it may perform poorly. The comment provides a specific suggestion to avoid this issue by individually standardizing feature dimensions. This feedback is explicit and concrete, as it clearly identifies the potential problem and offers a direct solution. The authors know exactly what needs to be done to address the issue, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the feature spaces being wellsuited for 1NN and provides a suggestion to avoid this problem by individually standardizing feature dimensions. This level of detail guides the authors on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the suitability of feature spaces for 1NN classification, suggesting that if a feature space is not close to a spherical Gaussian, it may perform poorly. The comment provides a logical reasoning by explaining the potential issue and offering a suggestion to avoid it by individually standardizing feature dimensions. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened with specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the suitability of feature spaces for 1NN (1nearest neighbor) classification. It raises a concern that if a feature space is not close to a spherical Gaussian, it may perform poorly. The comment provides a constructive suggestion to address this issue by individually standardizing feature dimensions, which could improve the performance of the 1NN classification. This feedback is clear and actionable, offering the authors a specific direction for improving their work. However, it could be more helpful if it included additional context or examples to further illustrate the potential impact of this suggestion. Overall, the comment is 4 as it provides valuable guidance for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies specific issues in the paper, namely the misrepresentation of standard MDP formulations in section 3.1 and the lack of clarity regarding whether each action is a single feature or the power set. The reviewer suggests making the description more clear, which is an explicit action. However, the comment does not provide detailed guidance on how to achieve this clarity, such as suggesting specific changes to the wording or examples to illustrate the point. While the action is explicit, the lack of concrete details makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.1, line 143\" and \"line 154,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the misrepresentation of standard MDP formulations and the lack of clarity regarding whether each action is a single feature or the power set. The reviewer suggests making the description more clear, providing specific guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"Then the state changes and environment gives a reward\" is not true of standard MDP formulations. It provides a logical reasoning by explaining that rewards are not necessarily given after each action, which supports the claim. Additionally, the comment suggests that the description could be made clearer regarding whether each action is a single feature or the power set. This provides a basis for the claim, making it 4. However, the comment could be strengthened with specific examples or references to standard MDP formulations for further substantiation. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific issues in the paper, namely the misrepresentation of standard MDP formulations in section 3.1 and the lack of clarity regarding whether each action is a single feature or the power set. It provides explicit guidance by suggesting that the description should be made more clear, which is a valuable and actionable piece of feedback. However, the comment could be more helpful if it offered additional suggestions or examples on how to clarify these points. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the notation used in the text and the notation used in Figure 1, specifically noting that \"L_task\" is used in the text but \"L_class\" is used in Figure 1. This comment explicitly identifies the inconsistency and suggests that the authors should ensure consistency in their notation across the paper. However, it does not provide specific guidance on how to resolve this issue, such as suggesting which notation to use or how to update the figure. The action is explicit but somewhat vague, as the authors know what needs to be corrected but may not be entirely sure of the best approach to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in notation, noting that \"L_task\" is used in the text but \"L_class\" is used in Figure 1. This provides clear guidance on what needs to be addressed, ensuring that the authors know exactly what part of the paper requires revision. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about a discrepancy in notation between the text and Figure 1. It does not express an opinion, suggestion, or claim that requires verification. It is purely descriptive, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment identifies a specific inconsistency in notation between the text and Figure 1, noting that \"L_task\" is used in the text but \"L_class\" is used in Figure 1. This feedback is clear and actionable, as it directly points out a potential source of confusion for readers. By addressing this inconsistency, the authors can improve the clarity and consistency of their paper. However, the comment could be more helpful if it suggested which notation should be used consistently throughout the paper. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the work would be more convincing if it were evaluated in machine translation, which is considered a \"close domain\" generation task with lower uncertainties per word compared to \"open domain\" generation tasks like answer generation and summarization. While the comment implies that the authors should consider evaluating their method in machine translation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should include machine translation in their evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluation of the proposed method, specifically mentioning that it only uses answer generation and summarization tasks, which are considered \"open domain\" generation tasks. The reviewer suggests that the work would be more convincing if it were also evaluated in machine translation, a \"close domain\" generation task with lower uncertainties per word. However, the comment does not specify which part of the paper discusses the evaluation tasks or where the authors should include the additional evaluation in machine translation. While the authors can infer that the comment relates to the evaluation section, the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting an additional evaluation task, but without explicit references to the paper, it is not fully grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the work would be more convincing if it included evaluation in machine translation, which is considered a \"close domain\" generation task with lower uncertainties per word. The reviewer provides a logical reasoning by contrasting the tasks used (answer generation and summarization) with machine translation, suggesting that the latter would provide a more convincing evaluation. However, the comment lacks specific examples or references to support the claim about the differences in uncertainties between these tasks. This makes the claim 3, as it provides a logical basis but requires further elaboration or evidence to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the proposed method, noting that it only uses answer generation and summarization tasks, which are considered \"open domain\" generation tasks. The reviewer suggests that the work would be more convincing if it were also evaluated in machine translation, a \"close domain\" generation task with lower uncertainties per word. This feedback is 3 as it points out a potential gap in the evaluation and suggests a specific area for improvement. However, it lacks detailed guidance on how to incorporate machine translation into the evaluation or what specific aspects of machine translation should be considered. To be more helpful, the comment could provide additional context or examples of how machine translation could enhance the evaluation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific sentence (9395) that is confusing and suggests that the meaning is not immediately clear. However, it does not provide any explicit guidance or suggestions on how to clarify the sentence or improve its readability. The comment implies that the authors should revisit the sentence and consider rephrasing it for better understanding, but it lacks concrete details on how to achieve this. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sentence numbers \"9395,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the confusion caused by the sentence and the need for clarification. The reviewer provides a personal experience of rereading the sentence to understand it, which adds specificity to the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a specific sentence is confusing and not immediately clear. However, it does not provide any supporting evidence, reasoning, or examples to justify why the sentence is confusing. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific sentence (9395) that is confusing and not immediately clear. The reviewer acknowledges that they understood it after rereading it, but notes that it may not be obvious to others. This feedback is 3 as it points out a potential issue with the clarity of the text, but it lacks specific suggestions or guidance on how to improve the sentence or make it more understandable. While it highlights an area for improvement, the comment could be more helpful if it provided actionable advice or examples for rephrasing the sentence. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take, specifically requesting citations for certain statements in the paper. This feedback is clear and direct, leaving no ambiguity about what needs to be done. The authors know exactly which lines to address and what type of information is needed to support the claims. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (7879, 129130, 156158, and 217218), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014citations for certain claims. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements requesting citations for specific claims made in the paper. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying instances where citations are needed to support claims made in the paper. It highlights the importance of referencing previous work and evidence to substantiate assertions, particularly in lines 7879, 129130, 156158, and 217218. This feedback is clear and direct, guiding the authors on how to enhance the credibility and rigor of their work by incorporating necessary citations. However, the comment could be more helpful if it offered suggestions on which specific studies or references might be relevant for the cited claims. Overall, the comment is 4 as it directs the authors to improve the paper\"s documentation and credibility."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between Figure 1 and Figure 2, noting that Figure 2 shows one encoderdecoder per auxiliary task, whereas Figure 1 depicts a single shared encoderdecoder for multiple tasks. This comment explicitly points out the inconsistency between the two figures, indicating that the authors should reconcile this discrepancy. However, it does not provide specific guidance on how to address the issue or suggest a way to resolve the inconsistency. The action is explicit but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the inconsistency between the two figures regarding the representation of encoderdecoders for auxiliary tasks. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figure 1 is inconsistent with Figure 2 regarding the representation of encoderdecoders for auxiliary tasks. However, it does not provide any further explanation or evidence to support this claim, such as specific details about the inconsistency or how it affects the understanding of the paper. Without additional context or reasoning, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific inconsistency between Figure 1 and Figure 2, noting that Figure 1 shows a single shared encoderdecoder for multiple tasks, whereas Figure 2 depicts one encoderdecoder per auxiliary task. This feedback is clear and actionable, as it highlights a discrepancy that needs to be addressed to ensure consistency in the presentation of the methodology. However, the comment could be more helpful if it provided suggestions on how to reconcile this inconsistency or offered guidance on which figure is correct. Despite this, the comment is 4 as it directs the authors to a critical area for improvement, making it a 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to clarify how the inequality after line 433 follows from Lemma 7. It suggests that while the inequality seems to be a combination of previous inequalities, the authors should facilitate the reader\"s understanding by explicitly stating how Lemma 7 contributes to this result. This feedback provides a clear and direct action for the authors to take, which is to add a clarification on the relationship between the inequality and Lemma 7. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ineq. after l433\" and \"Lemma 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by asking how the inequality follows from Lemma 7 and suggests that the authors should facilitate the reader\"s understanding by stating how Lemma 7 comes into play. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the logical flow of an inequality after line 433 and its relation to Lemma 7. It suggests that the authors should clarify how Lemma 7 contributes to this inequality. However, the comment does not provide specific reasoning or examples to support why the connection between the inequality and Lemma 7 is unclear. Without detailed justification or references, the claim remains 3, as the authors would need to infer the issue and address it themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the logical flow of the paper, questioning how an inequality after line 433 follows from Lemma 7. It suggests that while the inequality seems to be a combination of previous inequalities, the authors should clarify the role of Lemma 7 in this context. This feedback is clear and actionable, as it directs the authors to provide a clearer explanation of the relationship between the inequality and the lemma. By addressing this point, the authors can improve the readability and coherence of their paper. Therefore, the comment is 4, as it provides a specific area for improvement with actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests two actions: first, to include the bottomup method 9 in the tables, and second, to evaluate the performance of the method on the standard MS coco dataset to assess any potential drop in performance in easy (nonoccluded) settings. Both suggestions are explicit and provide clear guidance on what the authors should do to improve their draft. The first suggestion is concrete, as it specifies the inclusion of a particular method in the tables, and the second is also concrete, as it outlines a specific evaluation to be conducted. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"the bottomup method 9,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely including the bottomup method in the tables and evaluating the performance on the standard MS coco dataset. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the bottomup method 9 has reported results on the crowdpose dataset that outperform all methods in Table 4, even when using a ResNet50. It recommends including this method in the tables and evaluating the performance on the standard MS coco dataset to assess any potential drop in performance in easy (nonoccluded) settings. The claim is 3 as it provides a specific reference to the bottomup method 9 and suggests a comparison with the paper\"s results. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting the inclusion of the bottomup method 9 in the tables, as it has reported results outperforming all methods in Table 4, even with a ResNet50. This recommendation is clear and could help the authors improve the comprehensiveness of their results. Additionally, the comment suggests evaluating the performance of the method on the standard MS coco dataset to assess any potential drop in performance in easy (nonoccluded) settings. This suggestion is also constructive, as it encourages the authors to consider additional scenarios that could impact their results. However, the comment could be more helpful if it provided more detailed guidance on how to conduct these evaluations or what specific aspects to focus on. Overall, the feedback is 4, as it offers clear and actionable suggestions for improving the draft, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point questions the claim of using \"annotation guidelines\" in the paper, suggesting that the current approach may not fully capture the complexity of true annotation guidelines. The reviewer provides an example from the TACRED slot filling guidelines, highlighting the depth of annotation guidelines in the IE domain. While the comment raises a concern about the paper\"s claim, it does not provide explicit guidance on how the authors should address this issue or improve their approach. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider their claim and potentially expand their annotation guidelines. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"claim of making use of \u201cannotation guideline\u201d\" and provides a specific example from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details what is missing in the paper\"s claim, namely the depth of true guideline understanding, and provides a reference to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s use of \"annotation guidelines\" may be an overstatement, as it only considers label name, label description, and fewshot examples, whereas annotation guidelines in the IE domain are more complex and curated by linguists. The reviewer supports this claim by referencing a specific example from the TACRED slot filling guidelines, which provides a detailed example of how annotation guidelines are structured. This reference helps to substantiate the claim, making it 4. However, the comment could be strengthened by providing more examples or a clearer explanation of how the paper\"s approach differs from the referenced guidelines. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a concern about the claim of using \"annotation guidelines\" in the paper, suggesting that the current approach may not fully capture the complexity of true annotation guidelines. The reviewer provides a specific example from the TACRED slot filling guidelines, which highlights the depth and complexity of annotation guidelines in the IE domain. This feedback is valuable as it prompts the authors to reconsider their claim and potentially expand their annotation guidelines to better align with the standards in the field. However, the comment could be more helpful if it offered suggestions on how to enhance the annotation guidelines or provided additional examples to support the claim. Overall, the comment is 4 as it identifies a potential weakness and provides a specific example for the authors to consider, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the experiment comparison is weak because it only compares the method to the BERTbaseline, and suggests that the authors should also compare it to token pruning and token combination baselines. This provides a clear and direct action for the authors to take, which is to expand their comparison to include additional baselines. The feedback is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the experiment comparison, specifically mentioning that the authors only compare their method to the BERTbaseline and suggesting that they should also compare it to token pruning and token combination baselines. This provides clear guidance on what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper this issue is discussed in, so the authors might need to infer that it relates to the experimental section. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiment comparison is weak because it only compares the method to the BERTbaseline, suggesting that the authors should also compare it to token pruning and token combination baselines. This claim is 3 as it provides a logical reasoning for the need for additional comparisons. However, the comment lacks specific examples or references to support why these additional comparisons are necessary or how they would enhance the experiment. Providing more detailed reasoning or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experiment comparison, noting that the authors only compare their method to the BERTbaseline and suggesting that they should also include comparisons with token pruning and token combination baselines. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the robustness and comprehensiveness of their experimental evaluation. By addressing this point, the authors can enhance the validity and comparability of their results, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the experimental section should include comparisons with methods that are aware of point coordinates, such as TFN or SchNet. This is an explicit action that provides specific examples of methods to consider for comparison. The comment is clear and concrete, giving the authors a direct and actionable step to improve their draft by including these comparisons. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a comparison with methods that are aware of point coordinates, such as TFN or SchNet, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experimental section should include comparisons with methods that are aware of point coordinates, such as TFN or SchNet. This claim is 3 as it provides a logical reasoning for the comparison, suggesting that including such methods would enhance the evaluation. However, the comment lacks specific examples or references to support the claim, making it less robust. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the experimental section, noting that it only compares to methods that are unaware of point coordinates, except for input features. It suggests that a comparison to coordinateaware methods, such as TFN or SchNet, would be appropriate. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their experimental evaluation. By suggesting a comparison to coordinateaware methods, the comment offers a concrete way for the authors to improve the comprehensiveness and validity of their results. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should demonstrate the possible weaknesses of the proposed model. However, it does not provide any explicit guidance or concrete suggestions on how to do so. The action is implicit, as the authors need to infer that they should address the lack of discussion on potential weaknesses. Additionally, the comment lacks specificity, as it does not specify which aspects of the model might be vulnerable or how to present these weaknesses. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the possible weaknesses of the proposed model. However, it does not specify which part of the paper this issue pertains to, nor does it provide details on what specific weaknesses should be addressed. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding the nature of the weaknesses that should be discussed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to potential weaknesses, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a significant gap in the paper by noting that the authors have not demonstrated the possible weaknesses of the proposed model. This is a critical observation that highlights an important area for improvement, as understanding and addressing potential weaknesses is crucial for the robustness and credibility of the model. However, the comment lacks specificity and does not provide guidance on how the authors might identify or discuss these weaknesses. While it identifies a key area for improvement, the feedback could be more actionable and helpful if it included suggestions or examples of potential weaknesses to consider. Therefore, the comment is 3, as it directs the authors to a critical area but does not fully support them in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the introduction of related work is insufficient and suggests that more work on GLN should be included to highlight the advantages or differences of the proposed method, such as distinguishing it from BGLN. While the comment implies that the authors should expand the related work section, it does not provide specific guidance on what aspects of GLN should be emphasized or how to differentiate the proposed method from BGLN. The action is implicit and somewhat vague, as the authors can infer that they need to add more content but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the introduction of related work, specifically mentioning that it is insufficient and suggests including more work on GLN to highlight the advantages or differences of the proposed method. It also mentions the need to differentiate the proposed method from BGLN. However, the comment does not specify which part of the introduction is insufficient or where the additional information should be included, making it weakly grounded. The authors can infer that it relates to the introduction section, but the lack of explicit references makes it challenging to pinpoint the exact areas needing improvement. The comment is specific in suggesting what needs to be addressed, such as highlighting the advantages or differences of the proposed method. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of related work is insufficient and suggests that more work on GLN should be included to highlight the advantages or differences of the proposed method. However, the comment does not provide specific examples or references to support this claim, nor does it explain why the current introduction is insufficient. This lack of detailed justification or evidence makes the claim difficult for the authors to address effectively, as they are left without clear guidance on what aspects of GLN should be emphasized or how to differentiate the proposed method from BGLN. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the insufficient introduction of related work, particularly regarding GLN. It suggests that more work on GLN should be included to highlight the advantages or differences of the proposed method, such as distinguishing it from BGLN. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the related work section. However, the comment could be more helpful if it offered specific examples or guidance on how to differentiate the proposed method from BGLN. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the inconsistency in the dropout rates used for Moon\"s approach and Variational dropout. It explicitly asks why only one dropout rate is used for Moon\"s approach, while Variational dropout has both an inputoutput and a recurrent dropout parameter. This question prompts the authors to clarify or justify their choice of dropout rates, providing a clear and specific action for them to take. The comment is explicit and concrete, as it directly addresses a specific aspect of the paper and provides a clear direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment raises a question about the inconsistency in dropout rates used for Moon\"s approach and Variational dropout. It explicitly mentions \"hypers > hyperparameters,\" which suggests that the comment is addressing a specific part of the paper where hyperparameters are discussed. However, it does not specify which section or part of the paper this discussion is in, making it weakly grounded. The comment is specific in its question about the dropout rates, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the inconsistency in dropout rates used for Moon\"s approach and Variational dropout, specifically noting that Variational dropout has both an inputoutput and a recurrent dropout parameter. However, the comment does not provide any reasoning or evidence to support why this inconsistency is problematic or how it affects the paper\"s validity. Without additional context or explanation, the authors may find it challenging to understand the significance of this observation or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the inconsistency in dropout rates used for Moon\"s approach and Variational dropout. It points out that Variational dropout has both an inputoutput and a recurrent dropout parameter, while Moon\"s approach only uses one dropout rate. This observation prompts the authors to clarify or justify their choice of dropout rates, which could be an important aspect of their methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential area for clarification, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that no information from 2hop neighbors is included and questions the effectiveness of the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what information should be included from 2hop neighbors or how to clarify the effectiveness of the method. Without actionable suggestions or specific instructions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that \"no information from 2hop neighbors is included,\" which suggests that it is addressing a specific aspect of the methodology or results. However, it does not specify which part of the paper this information is missing from, making it weakly grounded. The comment also questions the effectiveness of the method but does not provide specific details or examples to support this claim. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the method is simple and questions its effectiveness, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The lack of detailed explanation or examples makes it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a significant omission in the paper, noting that no information from 2hop neighbors is included. It also questions the effectiveness of the method, suggesting that it is unclear why it is effective. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address these issues. Without detailed feedback or examples, the authors are left without a clear path for improvement. Therefore, the comment is 2, as it identifies a potential weakness but does not offer sufficient guidance for the authors to address it effectively."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests clarification on the training of the model in Figure 7, specifically asking about the stimulus used and whether the duration of the cycle changes. It also references a specific study (Smirnakis et al. Nature 1997) to provide context for the adaptation time scale. This feedback is clear and direct, providing the authors with specific actions to take to address the reviewer\"s concerns. The inclusion of a reference to a relevant study adds concrete guidance on how to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: the training of the model in Figure 7, including the stimulus used and the potential impact of changing the cycle duration on the adaptation time scale. The reference to Smirnakis et al. (1997) provides additional context and specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the training of the model in Figure 7, specifically asking about the stimulus used and whether the duration of the cycle changes. It also references a study by Smirnakis et al. (1997) to provide context for the adaptation time scale. While the comment raises a valid point, it does not provide any evidence or detailed reasoning to support the claim that the model cannot handle longer time scales. The reference to the study is mentioned but not fully integrated into the argument. Therefore, the comment is 3, as it provides a basis for the claim but lacks comprehensive support.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area of concern regarding the training of the model in Figure 7. It asks for clarification on the stimulus used and whether the duration of the cycle changes, which could impact the adaptation time scale. The reference to Smirnakis et al. (1997) provides context and suggests a potential issue with the model\"s handling of longer time scales. This feedback is clear and actionable, guiding the authors to provide more detailed information about their methodology and its implications. However, it could be more helpful if it offered suggestions on how to address the issue or provided additional context. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the fairness of comparisons in Table 2, specifically regarding the use of different amounts of data across various scenarios. The reviewer suggests that comparisons should be made between scenarios using the same amount of data. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest specific actions to take. The authors can infer that they need to ensure consistent data usage across comparisons, but the comment lacks concrete details on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the fairness of comparisons in the table, specifically regarding the use of different amounts of data across various scenarios. The comment provides examples of scenarios where less data is used, such as H>N and H>B compared to H>N+B, and H>N>H and H>N>H compared to H>N+B>H. This level of detail helps the authors understand what needs to be addressed in the table. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the fairness of comparisons in Table 2, specifically regarding the use of different amounts of data across various scenarios. The reviewer provides specific examples, such as H>N and H>B using less data than H>N+B, and H>N>H and H>N>H using less data than H>N+B>H. This detailed analysis supports the claim by highlighting potential inconsistencies in the data usage, making the comment 4. However, the comment could be strengthened by suggesting how the authors might address these issues or provide a more detailed explanation of the implications of these differences. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparisons in Table 2, specifically regarding the use of different amounts of data across various scenarios. It points out that some comparisons involve using less data than others, which could impact the validity of the results. This feedback is clear and actionable, as it prompts the authors to ensure that comparisons are made under consistent conditions. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending a standardization of data usage across all scenarios. Overall, the comment is 4 as it identifies a critical area for improvement and guides the authors toward a more robust analysis."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several issues, including the counterintuitive placement of a section, confusion about the application of Algorithm 1, and the lack of reference to Laplacian eigenmaps. While the comment identifies areas that need attention, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and vague, leaving the authors to infer what needs to be done without clear guidance on how to address these issues. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is weakly grounded as it does not explicitly mention which part of the paper it addresses, such as a specific section or figure. However, it does specify several issues: the counterintuitive placement of a section, confusion about the application of Algorithm 1, and the lack of reference to Laplacian eigenmaps. The comment provides clear guidance on what needs to be addressed, making it specific. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises several claims, including the counterintuitive placement of a section and the lack of reference to Laplacian eigenmaps. However, the comment does not provide detailed reasoning or evidence to support these claims, such as explaining why the placement is counterintuitive or how the lack of reference affects the paper. The claim about the application of Algorithm 1 is also not fully substantiated. Without specific examples or references, the claims remain vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the counterintuitive placement of a section, confusion about the application of Algorithm 1, and the lack of reference to Laplacian eigenmaps. It also points out the absence of a reference to Laplacian eigenmaps in the introduction and in the figure. While the comment highlights these weaknesses, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it directs the authors to areas needing improvement, but it lacks actionable advice or detailed guidance, making it incomplete. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the inclusion of Section 2.1, suggesting that the description of Batch Normalization and Conditional Batch Normalization (CBN) is general and not specific to the proposed methodology. It implies that the time spent on describing the ResNet architecture could be better utilized to provide more motivation and intuition for the CBN approach. While the comment identifies a potential issue with the structure of the paper, it does not provide explicit guidance on how to address this issue or suggest specific changes to improve the draft. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider the content of Section 2.1 and potentially reorganize the material to better align with the proposed methodology. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the inclusion of this section, questioning its relevance and suggesting that the time spent on describing the ResNet architecture could be better used to provide more motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the inclusion of Section 2.1, suggesting that the description of Batch Normalization and Conditional Batch Normalization (CBN) is general and not specific to the proposed methodology. The reviewer implies that the time spent on describing the ResNet architecture could be better utilized to provide more motivation and intuition for the CBN approach. However, the comment lacks specific examples or references to support the claim that the section is unnecessary or that the time could be better spent. This makes the claim 3, as it provides a logical reasoning but lacks detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the inclusion of Section 2.1, suggesting that the description of Batch Normalization and Conditional Batch Normalization (CBN) is general and not specific to the proposed methodology. It implies that the time spent on describing the ResNet architecture could be better utilized to provide more motivation and intuition for the CBN approach. This feedback is 3 as it identifies a potential redundancy in the content and suggests a way to improve the draft by focusing on the specific contributions of the proposed methodology. However, the comment could be more helpful if it provided specific suggestions on how to reorganize the content or what additional information could be included to enhance the motivation and intuition for the CBN approach. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the clarity of the paper regarding the sparsity of the resulting matrix when multiplying by a dense projection matrix. The reviewer questions the expectation of sparsity in this context, suggesting that the multiplication would likely result in a dense matrix. However, the comment does not provide explicit guidance on how the authors should address this issue or clarify the expectation of sparsity. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the sparsity expectation but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L122,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the expectation of sparsity when multiplying by a dense projection matrix, providing clear guidance on what needs to be clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the expectation of sparsity in the resulting matrix when multiplying by a dense projection matrix. The reviewer provides a logical reasoning by pointing out that multiplying by a dense matrix would likely result in a dense matrix, rather than a sparse one. This reasoning is clear and provides a basis for the claim, making the comment 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, questioning the expectation of sparsity in the resulting matrix when multiplying by a dense projection matrix. It points out a potential contradiction in the paper\"s claims, suggesting that the multiplication would likely result in a dense matrix rather than a sparse one. This feedback is clear and actionable, as it prompts the authors to clarify their expectations regarding sparsity. However, the comment could be more helpful if it provided additional guidance on how to address this issue or suggested ways to clarify the sparsity expectation. Overall, the comment is 4, as it directs the authors to a critical area that needs clarification, but it could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to plot a figure showing the decline in accuracy of a predictor over time in different settings to support their claim about the motivation. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be done, making it 5. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the issue of the evidence for the motivation being indirect and suggests that the authors should plot a figure showing the decline in accuracy of a predictor over time in different settings. This provides specific guidance on what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper this issue pertains to, leaving the authors to infer that it relates to the introduction or motivation section. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the evidence for the motivation is not direct and suggests that the authors should plot a figure showing the decline in accuracy of a predictor over time in different settings. This claim is 3 as it provides a logical reasoning for why the evidence is lacking and offers a specific suggestion for improvement. However, the comment could be strengthened by providing examples or references to similar studies that have effectively demonstrated this decline in accuracy. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the evidence provided for the motivation, noting that it is not direct. It suggests that the authors should plot a figure showing the decline in accuracy of a predictor over time in different settings to support their claim. This feedback is clear and actionable, providing the authors with a concrete step to take to strengthen their argument. By addressing this suggestion, the authors can enhance the credibility and persuasiveness of their work. Therefore, the comment is rated as 4, as it offers a specific and actionable piece of feedback that can significantly improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and requests for clarification regarding the definition and calculation of excessive risk, particularly in relation to the expectation and the representation of fairness. It explicitly asks the authors to explain more about the definition of excessive risk, how it is calculated in practice, and whether the values are comparable among different groups. The comment also questions the use of excessive risk as a representation of fairness. While the questions are clear and direct, the comment does not provide specific guidance on how the authors should address these issues or what specific changes they should make to their draft. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 103,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the definition of excessive risk, how it is calculated, and whether the values are comparable among different groups. The comment further questions the use of excessive risk as a representation of fairness, providing a clear direction for the authors to address these concerns. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions and concerns about the definition and calculation of excessive risk, particularly in relation to its representation in Figures 3 and 7. The reviewer questions the positivity of excessive risk values and their comparability across different groups. While the comment highlights potential issues with the representation of excessive risk, it does not provide specific evidence, examples, or references to support these claims. The lack of detailed reasoning or supporting data makes the claims 3, as the authors would need to delve deeper into the paper to fully understand and address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several important questions and concerns about the definition and calculation of excessive risk, particularly in relation to its representation in Figures 3 and 7. It questions the positivity of excessive risk values and their comparability across different groups, which are critical aspects of the paper\"s methodology and results. By asking for clarification on these points, the comment encourages the authors to provide more detailed explanations and justifications for their methods, which could significantly enhance the clarity and robustness of their work. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these issues. Overall, the comment is 4 as it identifies key areas for improvement and prompts the authors to provide more detailed explanations, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part raises a concern about the implication of \"for every arm a\" suggesting a single optimistic parameter, but notes that it actually depends on a. This part is 3 as it points out a potential misunderstanding but does not provide explicit guidance on how to address it. The second part suggests an alternative choice for T_0, which is a concrete suggestion for improvement. However, the comment does not fully explain why this alternative is better or how it should be implemented. Overall, the comment provides some guidance but lacks full actionability due to the lack of detailed instructions on how to address the first point and the second point\"s limited explanation. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (\"L200\" and \"L303\") where the issues are discussed, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the implication of \"for every arm a\" and suggests an alternative choice for T_0, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part raises a concern about the implication of \"for every arm a,\" suggesting that it implies a single optimistic parameter, but notes that it actually depends on a. This part is 3 as it points out a potential misunderstanding, but it lacks specific examples or references to fully substantiate the claim. The second part suggests an alternative choice for T_0, which is supported by a logical explanation and a specific mathematical expression. However, the first part of the comment is not 5 due to the lack of detailed justification, making the overall comment 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment provides specific feedback on the paper, addressing two distinct issues. The first part points out a potential misunderstanding in the implication of \"for every arm a,\" suggesting that it might imply a single optimistic parameter, but notes that it actually depends on a. This feedback is 3 as it highlights a potential confusion in the text, but it lacks actionable guidance on how to clarify this point. The second part of the comment offers a constructive suggestion by proposing an alternative choice for T_0, which could improve the condition. This suggestion is more helpful as it provides a concrete way to enhance the draft. However, the comment could be more helpful if it explained why this alternative is beneficial or how it aligns with the paper\"s goals. Overall, the comment is 4 due to the specific suggestions, but it could be more comprehensive with additional guidance or explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to define \"L\" and \"E\" in the immediate vicinity of line 296, addressing the inconsistency in their formatting. This feedback is clear and direct, providing a specific action for the authors to take to improve their draft. The comment also points out the inconsistency in formatting, which is a concrete issue that the authors can easily address. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 296,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the inconsistency in the formatting of \"L\" and \"E,\" noting that they are sometimes italicized and sometimes not. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual observation about the formatting inconsistency of \"L\" and \"E\" in the paper, specifically noting that they are sometimes italicized and sometimes not. This is a descriptive statement without any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific formatting issue in the paper, noting that \"L\" and \"E\" are sometimes italicized and sometimes not. This feedback is clear and actionable, as it directs the authors to ensure consistency in the formatting of these variables throughout the paper. By addressing this issue, the authors can improve the clarity and professionalism of their draft. However, the comment could be more helpful if it provided additional context or suggestions on why consistency in formatting is important or how it might impact the reader\"s understanding. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experimental section is weak and requires more experiments. However, it does not provide any specific guidance on what kind of experiments are needed or how they should be conducted. The action is implicit, as the authors can infer that they need to add more experiments, but it is vague because it lacks concrete details on what those experiments should entail. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the experimental section is weak and requires more experiments. However, it does not specify which part of the experimental section is weak or what specific experiments are needed. This makes it difficult for the authors to pinpoint the exact areas that require improvement. The comment lacks both grounding and specificity, as it does not provide clear guidance on what needs to be addressed or how to address it. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experimental section is weak and requires more experiments. However, it does not provide any specific reasoning, examples, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a weakness in the experimental section, noting that it is \"a little weak\" and suggests that more experiments are required. However, it lacks specificity and does not provide any guidance on what kind of experiments are needed or how they should be conducted. Without detailed suggestions or examples, the authors are left with a general idea of what might be lacking but without a clear path for improvement. This makes the comment 3, as it points out an area for enhancement but does not offer actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of a series of explicit corrections to grammatical errors and inconsistencies in the manuscript. Each correction is clearly stated, providing the authors with direct and concrete actions to take. The comment explicitly identifies the lines where these corrections are needed, ensuring that the authors know exactly where to apply the changes. This level of detail and specificity makes the feedback 5, as the authors can directly implement the suggested corrections to improve the clarity and accuracy of their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper where corrections are needed, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the grammatical errors and inconsistencies that need to be corrected, providing precise guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of grammatical corrections and suggestions for improvement. Each correction is factual and does not express an opinion or claim that requires verification. The comment is descriptive and provides clear guidance on how to improve the manuscript\"s grammar and clarity. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a series of explicit corrections to grammatical errors and inconsistencies in the manuscript. It identifies specific lines where these corrections are needed, such as \"Despite of being compact\" should be \"Despite being compact,\" and \"We refer multiway arrays\" should be \"We refer to multiway arrays.\" Additionally, it points out a grammatical error in the phrase \"Effect of the modelling mixed temporalmodality features,\" suggesting that it is not grammatically correct. These corrections are clear and actionable, allowing the authors to directly improve the clarity and accuracy of their draft. However, the comment could be more helpful if it provided additional context or suggestions for improving the overall structure or content of the paper. Nonetheless, the feedback is 4 as it effectively guides the authors in refining their manuscript."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises an interesting question about the performance of the proposed method in pure combinational logic versus sequential design. It suggests that the method might be easier to model without staterelated registers and proposes a comparison between sequential and combinational designs. However, the comment does not provide explicit instructions or concrete steps for the authors to follow. While it implies that the authors should consider this comparison, the action is not directly stated, and the authors may not know exactly how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the performance of the proposed method in pure combinational logic versus sequential design, suggesting that it might be easier to model without staterelated registers. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to identify the exact area needing attention. The comment is specific in its suggestion for a comparison between sequential and combinational designs, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic versus sequential design, suggesting that it might be easier to model without staterelated registers. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or detailed comparisons to substantiate the suggestion for a comparison between sequential and combinational designs. Without additional context or justification, the claim remains 1, as it does not provide sufficient information for the authors to understand or address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises an interesting question about the performance of the proposed method in pure combinational logic versus sequential design. It suggests that the method might be easier to model without staterelated registers and proposes a comparison between sequential and combinational designs. This feedback is 3 as it identifies a potential area for exploration and improvement in the paper. However, it lacks specific guidance or suggestions on how to conduct this comparison or what aspects to focus on. While it provides a direction for further analysis, it does not offer detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point expresses curiosity about the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While it does not explicitly instruct the authors to include this information, it implies that the authors should consider adding it to their analysis. The action is implicit, as the authors need to infer that they should include this metric, and it is somewhat vague because it does not provide specific guidance on how to calculate or present the metric. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment section\" and the specific baseline \"LDA+LSTM,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the interest in the performance of this baseline in terms of the topic switch percent metric. This provides clear guidance on what the authors need to address or explore further. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses curiosity about the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. However, it does not make a claim or provide any subjective opinion, judgment, or suggestion that requires verification. It is a factual statement seeking clarification, which aligns with the \"No\" label.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific aspect of the experiment section that could be explored further. It highlights the LDA+LSTM baseline and expresses curiosity about its performance in terms of the topic switch percent metric. This feedback prompts the authors to consider including this metric in their analysis, which could provide valuable insights into the effectiveness of their approach. However, the comment lacks depth and does not offer specific suggestions or guidance on how to incorporate this metric or what it might reveal about the baseline. Therefore, while it provides some direction, it could be more helpful with additional details or examples."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include bold numbers for the baselines of previous work in Table 4. It also specifies that for WMT17WIKT, the best result in terms of BLEU is actually in the baselines, providing clear guidance on what needs to be corrected. This feedback is direct and concrete, leaving no ambiguity for the authors on how to implement the suggested changes. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear instructions on what needs to be included, namely bold numbers for the baselines of previous work, and specifies that the best result in terms of BLEU for WMT17WIKT is actually in the baselines. This level of detail guides the authors on what changes to make, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification and does not contain a subjective claim or opinion. It is a factual statement asking for a specific change in the presentation of results in Table 4. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by requesting that the authors include bold numbers for the baselines of previous work in Table 4. It also points out a discrepancy in the results for WMT17WIKT, noting that the best result in terms of BLEU is actually in the baselines. This feedback is clear and directs the authors to make a precise correction, which can enhance the clarity and accuracy of their presentation. However, the comment could be more helpful if it offered additional context or explanation for why this correction is important or how it might impact the interpretation of the results. Overall, the comment is 4 as it provides concrete guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks for examples of \"unreliable neighbors\" referenced in lines 170 to 171. This request is clear and direct, providing the authors with a specific action to take to address the comment. The feedback is concrete, as it specifies exactly what the authors need to provide to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 170 to 171, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for examples of \"unreliable neighbors,\" which clearly specifies what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking for examples of \"unreliable neighbors\" mentioned in lines 170 to 171. It does not contain a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it requests examples of \"unreliable neighbors\" mentioned in lines 170 to 171. This feedback is clear and directs the authors to provide additional information that could enhance the clarity and comprehensiveness of their draft. By addressing this request, the authors can improve the transparency and depth of their work. Therefore, the comment is rated as 5, as it provides a concrete suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of sufficient backing for the claim about the synergies between DQD and PPO, specifically noting the absence of mention of the TD3GA algorithm. It suggests that the study of combining DQD with TD3 is crucial for understanding these synergies and that a comparison to TD3GA should be central to the paper. While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to address the issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to include a comparison with TD3GA but are not given detailed guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"claim about the synergies between DQD and PPO,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of mention of the TD3GA algorithm and the importance of comparing DQD with TD3GA to understand the synergies. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the claim about the synergies between DQD and PPO is insufficiently backed up. It specifically points out the absence of mention of the TD3GA algorithm, which is crucial for understanding these synergies. The comment also suggests that a comparison to TD3GA should be central to the paper. While the comment identifies a potential gap in the paper, it does not provide specific examples or detailed reasoning to fully substantiate the claim. The lack of detailed evidence or references makes the claim 3, as the authors would need to delve deeper into the paper to understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the claim about the synergies between DQD and PPO is insufficiently backed up. It points out the absence of mention of the TD3GA algorithm, which is crucial for understanding these synergies. The comment also suggests that a comparison to TD3GA should be central to the paper, as it is relevant to the claim that using onpolicy RL better fits the DQD framework. This feedback is clear and actionable, providing the authors with a specific area to address and a direction for improvement. However, it could be more helpful if it offered suggestions on how to incorporate the comparison or provide additional evidence to support the claim. Overall, the comment is 4, as it effectively guides the authors toward enhancing the rigor and clarity of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the unexpected performance of the treesliced Wasserstein distance compared to the original optimal transport distance in Sections 6.1 and 6.2. It explicitly asks the authors to explain why this occurs, providing a clear and direct action for the authors to take. The comment is specific and concrete, as it identifies the sections where the issue is observed and requests an explanation, giving the authors a clear path forward. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sections 6.1 and 6.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the unexpected performance of the treesliced Wasserstein distance compared to the original optimal transport distance and requests an explanation for this observation. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the unexpected performance of the treesliced Wasserstein distance compared to the original optimal transport distance in Sections 6.1 and 6.2. It does not make a claim or provide an opinion but rather seeks clarification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a surprising observation in Sections 6.1 and 6.2, where the treesliced Wasserstein distance outperforms the original optimal transport distance. It raises a question about the reason behind this unexpected outcome, prompting the authors to provide an explanation. This feedback is clear and actionable, as it directs the authors to clarify a specific aspect of their results, which could be crucial for understanding the implications of their findings. However, the comment could be more helpful if it offered suggestions on how to approach the explanation or potential reasons for the observed performance. Overall, the comment is 4, as it guides the authors toward a critical aspect of their work that requires further clarification."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should include additional data from a label noise experiment performed on ImageNet with 1000 classes, specifically focusing on nontail classes. This is an explicit suggestion for the authors to include more data to strengthen their case and further test their conjecture. The comment provides a clear and concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper should include numbers from a label noise experiment performed on ImageNet with 1000 classes, specifically focusing on nontail classes. This provides a clear direction for the authors to consider additional data to strengthen their case. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. While the authors can infer that it relates to the experimental results, the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting what additional data to include, so it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that including numbers from a label noise experiment on ImageNet with 1000 classes would strengthen the case and further test the conjecture. The comment provides a logical reasoning for why this additional data would be valuable, as it would help to stress test the conjecture even if the phenomenon weakens in this setting. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the importance of this additional data based on the reasoning provided. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper would be strengthened by including numbers from a label noise experiment performed on ImageNet with 1000 classes, specifically focusing on nontail classes. This is a clear and actionable suggestion that could help the authors further test their conjecture and provide additional evidence for their claims. The comment is specific in its request for specific data and acknowledges that even if the phenomenon weakens in this setting, the numbers are still worth reporting. This feedback is valuable as it directs the authors to a potential area for improvement that could enhance the robustness of their findings. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the evaluation in the paper, including a lack of comprehensiveness, transparency regarding the experiment setup, and limited generalizability due to reliance on a single dataset. The reviewer specifically mentions the absence of information about the number of different sets of incontent examples used and the lack of exploration of varying the number of InContext Examples. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The feedback is 4 as it clearly outlines the issues but lacks detailed guidance on how to address them. Therefore, this comment is rated as 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the evaluation, such as the lack of comprehensiveness, transparency regarding the experiment setup, and the reliance on a single dataset. The comment provides specific examples, such as the absence of information about the number of different sets of incontent examples used and the lack of exploration of varying the number of InContext Examples. This level of detail helps the authors understand what needs to be addressed in the evaluation section. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation in the paper is not sufficiently comprehensive and lacks transparency regarding the experiment setup. It provides specific examples, such as the absence of information about the number of different sets of incontent examples used and the lack of exploration of varying the number of InContext Examples. Additionally, it points out the reliance on a single dataset, which may limit the generalizability of the results. These specific examples and detailed critiques support the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to similar studies that have addressed these issues. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies several weaknesses in the evaluation section of the paper, including a lack of comprehensiveness and transparency regarding the experiment setup. It specifically points out the absence of information about the number of different sets of incontent examples used and the lack of exploration of varying the number of InContext Examples. Additionally, the comment notes that the evaluation relies solely on one dataset, which may limit the generalizability of the results. This feedback is clear and actionable, as it provides specific areas for improvement that the authors can address to enhance the robustness and comprehensiveness of their evaluation. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to increase the comprehensiveness of the evaluation. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include comparative experiments with other nonlinear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2, to showcase the unique advantages or potential shortcomings of the proposed method. This feedback is explicit, as it clearly states what action the authors should take to improve their draft. It is also concrete, as it provides specific examples of nonlinear blocks that could be included in the comparative experiments. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by suggesting the inclusion of comparative experiments with other nonlinear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2. This provides clear guidance on what needs to be addressed to enhance the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks comparative experiments with other nonlinear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2. This claim is 3 as it provides a logical reasoning for the suggestion, noting that such experiments could showcase the unique advantages or potential shortcomings of the proposed method. However, the comment lacks specific examples or references to existing works that have conducted similar experiments, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback is clear and actionable, as it suggests a concrete way for the authors to enhance their draft by including these comparative experiments. By doing so, the authors can better demonstrate the unique advantages or potential shortcomings of their proposed method in a broader context. However, the comment could be more helpful if it provided additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides a specific and explicit suggestion for improving the readability of Tables 4 and 5. It recommends splitting each table into two separate tables, one for each measure (SFII and SPDI), to enhance clarity. This feedback is clear and actionable, as it gives the authors a direct instruction on how to improve the presentation of their data. The suggestion is concrete, providing a clear path for the authors to follow, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improving the readability of these tables by splitting them into two tables each, one for SFII and one for SPDI columns. This detailed guidance helps the authors understand exactly what needs to be done to enhance the clarity of their presentation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Tables 4 and 5 would be more readable if they were split into two tables each, with one table per measure. This is a logical suggestion based on common practices in data presentation, aiming to improve the clarity and organization of the data. However, the comment does not provide specific examples or references to support why this arrangement would be beneficial or how it would enhance readability. While the suggestion is reasonable, it lacks detailed justification or evidence, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the readability of Tables 4 and 5. By recommending that each table be split into two, with one table for each measure (SFII and SPDI), the comment offers a clear and concrete way for the authors to enhance the clarity and organization of their data presentation. This feedback is valuable as it directly addresses a potential issue with the current format and provides a straightforward path for improvement. However, the comment could be more helpful if it explained why this change would be beneficial or if it suggested additional ways to improve the tables. Overall, the comment is 4, as it provides actionable guidance but could be more comprehensive with additional context or rationale."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should specify what \"valid\" and \"orig\" differ in, as shown in Fig. 5. This is an explicit action that provides clear guidance on what needs to be clarified in the figure. The comment is concrete because it directly instructs the authors on how to improve their draft by providing more detailed information about the differences between \"valid\" and \"orig.\" Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need to explain the differences between \"valid\" and \"orig\" in Fig. 5. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the differences between \"valid\" and \"orig\" in Fig. 5. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where the authors could improve their draft by clarifying the differences between \"valid\" and \"orig\" in Fig. 5. This feedback is actionable, as it directs the authors to provide more detailed information in the figure, which could enhance the reader\"s understanding of the results. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the feedback is clear and provides a specific direction for improvement, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. While the comment implies that the authors should consider adapting methods from computer vision to language tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore comparisons with computer vision methods. However, the comment provides a concrete suggestion by mentioning specific methods that could be adapted, which makes the action 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where comparisons are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, while the comment provides a specific suggestion for improvement, it does not specify what aspects of the computer vision methods should be compared or how they might be adapted to language tasks. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that including a comparison to methods from the computer vision setting would be more useful than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and typically require a supervised setup, but suggests that some could be adapted to language tasks relatively easily. However, the comment lacks specific examples or references to support the claim that such adaptations are feasible or beneficial. This makes the claim 3, as it provides a logical reasoning but lacks detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that including a comparison to methods from the computer vision setting would be more beneficial than comparing to lossbased sampling. It acknowledges that some methods might not be directly applicable but suggests that they could be adapted to language tasks with relative ease. This feedback provides a clear and actionable suggestion for improving the draft by expanding the scope of comparisons, which could enhance the paper\"s relevance and impact. However, the comment could be more helpful if it specified which computer vision methods might be relevant or provided examples of how they could be adapted. Overall, the comment is 4 as it offers a constructive direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the discussion around equation (10) is terse and not clearly explained. However, it does not provide any explicit or implicit guidance on how the authors should improve the clarity of the discussion. There is no suggestion on what specific aspects need to be expanded or clarified, nor are there any concrete steps offered for enhancing the explanation. As a result, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion around this equation, noting that it is \"very terse\" and \"not very clearly explained.\" This provides clear guidance on what needs to be improved. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion around equation (10) is \"very terse\" and \"not very clearly explained.\" However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion around equation (10), noting that it is \"very terse\" and \"not very clearly explained.\" This feedback is clear and actionable, as it directs the authors to expand and clarify their discussion around this equation. However, the comment could be more helpful if it provided specific suggestions on how to enhance the clarity or offered examples of what additional information could be included. Despite this, the comment still provides valuable guidance for improving the draft, making it 4."}
