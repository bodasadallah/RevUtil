{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the choice of operators used in the paper, specifically asking why the \"and\" operator or elementwise max were not considered. While the comment does not explicitly instruct the authors to make changes, it implies that the authors should provide a justification for their choice of operators. The action is implicit, as the authors need to infer that they should address this question in their response. However, the comment is 3 because it provides a clear direction for the authors to consider alternative operators and explain their reasoning. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 261 and 272, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the choice of operators and suggests considering the \"and\" operator or elementwise max, providing a clear direction for improvement. The comment explains why these alternatives might be relevant and encourages the authors to justify their choice. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of operators used in the paper, specifically asking why the \"and\" operator or elementwise max were not considered. The reviewer provides a logical reasoning by suggesting that these operators correspond to the ideas of union and intersection from the \"or\" operator and elementwise min, respectively. However, the comment lacks specific examples or references to support the claim that these operators were overlooked or would have been better choices. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the choice of operators used in the paper, questioning why the \"and\" operator or elementwise max were not considered. It provides a logical connection between the operators used and suggests that the \"and\" operator or elementwise max might correspond to the ideas of union and intersection from the \"or\" operator and elementwise min, respectively. This feedback is clear and actionable, as it prompts the authors to justify their choice of operators and consider alternative options. By addressing this point, the authors can enhance the clarity and comprehensiveness of their paper. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential inconsistency in the paper regarding the source of the data used. It suggests that the authors should clarify the description by mentioning Li et al. (2019a) earlier, which would make the text more precise and clear. This feedback provides a specific action for the authors to take, namely revising the description to include the earlier mention of Li et al. (2019a). The suggestion is explicit and concrete, offering a clear path for the authors to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (226238 and 242244) where the issue is identified, allowing the authors to accurately pinpoint the parts of the paper being addressed. It is also specific because it details the inconsistency regarding the source of the data and suggests a revision to clarify the description by mentioning Li et al. (2019a) earlier. This provides clear guidance on what needs to be addressed to improve the clarity and precision of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies a potential inconsistency in the paper regarding the source of the data used. It suggests that the authors should clarify the description by mentioning Li et al. (2019a) earlier. The comment provides a logical reasoning for the revision, pointing out the discrepancy between the lines mentioned and the need for clarity. However, it does not provide specific examples or references to support the claim, which could make it more robust. Therefore, the comment is 4, as it provides a clear direction for improvement but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the paper regarding the source of the data used. It points out that the text seems to suggest that the authors selected sentences from raw data, but later mentions that the data already has syntactic information. The reviewer suggests revising the description to clarify this by mentioning Li et al. (2019a) earlier. This feedback is clear and actionable, providing the authors with a specific direction to improve the clarity and precision of their paper. By addressing this inconsistency, the authors can enhance the readability and accuracy of their work. Therefore, the comment is 4, as it offers constructive guidance for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two parts. The first part critiques the adopted baseline models as weak and suggests that the authors should compare their work with Campos et al. (2020), which also uses feedback in QA tasks. This is an explicit suggestion for improvement, as it clearly identifies a missing comparison that the authors should make. The second part points out a grammatical error in the text and suggests a correction. While the first part is explicit and actionable, the second part is also explicit and provides a concrete action for the authors to take. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 277,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a grammatical error and suggests a correction, providing clear guidance on what needs to be addressed. Additionally, the comment critiques the adopted baseline models, suggesting comparisons with Campos et al. (2020) and other domain adaptation methods, which further specifies the areas needing improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the adopted baseline models are weak and suggests comparisons with Campos et al. (2020) and other domain adaptation methods. However, the comment does not provide specific reasons or evidence to support why the baseline models are weak or why these comparisons are necessary. The mention of Campos et al. (2020) and the suggestion to compare with other domain adaptation methods are vague and lack detailed justification or examples. Therefore, the claim is considered 2, as it provides some direction but lacks sufficient evidence or reasoning to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies two main issues with the paper. First, it critiques the adopted baseline models as weak, suggesting that the authors should compare their work with Campos et al. (2020), which also uses feedback in QA tasks. This feedback is 3 as it points out a potential gap in the comparison, but it lacks specific suggestions on how to conduct this comparison or what aspects to focus on. Second, the comment points out a grammatical error in the text and suggests a correction, which is a minor but actionable feedback. However, the comment could be more helpful if it provided more detailed guidance on how to address the weaknesses in the baseline models or offered specific examples of comparisons to make. Overall, the comment provides some useful insights but could be more comprehensive, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides two explicit actions for the authors to take. First, it suggests adding information about the input being word embeddings, similar to Lample et al., in section 2.3. This is a clear and concrete action that the authors can take to enhance their draft. Second, it questions whether the KNs in Figure 3 are in the source language or in English, as the mentions have been translated to English. This is also a direct and actionable suggestion that the authors can address by clarifying the figure. Additionally, the comment acknowledges that the authors have already stated they will correct the figure, which is a positive note. Overall, the comment is 5 as it provides explicit and concrete actions for the authors to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2.3\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as adding information about the input being word embeddings and clarifying whether the KNs in Figure 3 are in the source language or in English. The comment provides clear guidance on what needs to be improved, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should add information about the input being word embeddings, similar to Lample et al., in section 2.3. It also questions whether the KNs in Figure 3 are in the source language or in English, as the mentions have been translated to English. The comment provides a logical suggestion for improvement and raises a question that requires clarification. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the importance of this suggestion and the potential impact on the clarity of their work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback, addressing two distinct areas for improvement. First, it suggests adding information about the input being word embeddings, similar to Lample et al., in section 2.3, which could enhance the clarity of the paper. Second, it questions whether the KNs in Figure 3 are in the source language or in English, as the mentions have been translated to English. This feedback is clear and actionable, guiding the authors on how to improve the accuracy and comprehensiveness of their work. Additionally, the comment acknowledges that the authors have already stated they will correct the figure, which is a positive note. Overall, the comment is 5 as it offers detailed and constructive suggestions for enhancing the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies two areas that need improvement in the presentation of the model. It asks for clarification on the pooling method used for embedding features (line 397) and requests a clearer definition of the variables in Equation (7), specifically whether E_i represents the type or identity of AC i. Additionally, it suggests that the lefthand side of the equation should be a conditional probability. These explicit requests provide clear and concrete actions for the authors to take, ensuring they know exactly what needs to be addressed and how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (lines 397 and 472) and equations (Equation 7), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, such as clarifying the pooling method used for embedding features and defining the variables in Equation 7. The comment also provides a suggestion for improving the presentation of the equation by indicating that the lefthand side should be a conditional probability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises specific questions and concerns about the presentation of the model, particularly regarding the pooling method used for embedding features and the clarity of Equation (7). It questions whether E_i represents the type or identity of AC i and suggests that the lefthand side of the equation should be a conditional probability. These are logical and reasonable points that require clarification from the authors. However, the comment does not provide additional evidence or references to support these claims, making it 3. The authors would need to address these points themselves to fully understand and resolve the issues. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas that need improvement in the presentation of the model. It asks for clarification on the pooling method used for embedding features, which is a clear and actionable request. Additionally, it questions the clarity of Equation (7) and suggests that the lefthand side should be a conditional probability, providing a specific and constructive suggestion for improvement. By addressing these points, the authors can enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional context or examples to further guide the authors in making these improvements. Overall, the feedback is 4 as it directs the authors to specific areas that require attention, but it could be more comprehensive with further elaboration. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions what the experiments reveal about the underlying research question and the specific hypothesis tested, as well as how the different components fit together. While the comment identifies a gap in the paper\"s presentation, it does not provide explicit guidance on how the authors might address this issue. The authors are left to infer that they need to clarify the connections between their results and the research question, but without specific suggestions on how to do so, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"many empirical results and analyses\" in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the overall picture of the experiments and how they relate to the research question and hypothesis. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions what the experiments reveal about the underlying research question and the specific hypothesis tested, as well as how the different components fit together. However, the comment does not provide specific examples or detailed reasoning to support the claim that the experiments are unclear or disconnected. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that despite the presence of many empirical results and analyses, it is difficult to understand the overall picture of what the experiments reveal about the research question and hypothesis. This feedback is valuable as it highlights a critical gap in the paper\"s presentation and suggests that the authors need to better integrate their findings to provide a clearer understanding of their work. However, the comment could be more helpful if it offered specific suggestions on how to achieve this integration, such as recommending the use of visual aids or more detailed summaries. Overall, the comment is 3 as it points out a key area for improvement but lacks detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experimental comparisons are insufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7), similar to methods like MoCo and SimCLR. This provides a clear and explicit action for the authors to take, which is to conduct additional experiments with these wider backbones. The suggestion is concrete, as it specifies the exact experiments that should be performed to enhance the comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the experimental comparisons are insufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7), similar to methods like MoCo and SimCLR. This provides a specific suggestion for improvement, but it does not explicitly mention which part of the paper this suggestion pertains to, such as the experimental section or results. While the authors can infer that it relates to the experimental comparisons, the comment lacks full grounding. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the experimental comparisons are insufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7), similar to methods like MoCo and SimCLR. This claim is 3 as it provides a logical suggestion for enhancing the experimental comparisons, but it lacks specific examples or references to support the assertion that MoCo and SimCLR have tested with these wider backbones. The suggestion is based on a reasonable inference, but the authors might need additional context or evidence to fully understand the rationale behind the recommendation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental comparisons, noting that the proposed method, InvP, should be tested with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7), similar to other methods like MoCo and SimCLR. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the experimental setup to better compare the proposed method with existing approaches. By following this advice, the authors can improve the comprehensiveness and robustness of their experimental results, which is valuable for the readers and the scientific community. However, the comment could be more helpful if it included additional context or examples of how these wider backbones might impact the results. Overall, the comment is 4, as it offers a constructive suggestion for improvement but could be more detailed."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the probabilistic connection in the paper is not welldrawn and should be formalized or clarified. The reviewer provides a clear action for the authors to take, which is to either \"cement this connection more formally\" or \"adjust the language to clarify.\" This feedback is explicit and provides concrete guidance on how to improve the draft. The authors know exactly what needs to be done to address the issue, making the comment 5.", "grounding_specificity_rationale": "The comment addresses the probabilistic connection in the paper, suggesting that it is not formally established and should be clarified. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting that the connection should be formalized or the language clarified, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the probabilistic connection in the paper is not welldrawn and suggests that it should be formalized or clarified. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the specific areas needing improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the probabilistic connection in the paper, suggesting that it is not formally established and is presented more as a motivational aspect. The reviewer provides a clear and actionable suggestion for the authors to either formalize the connection or adjust the language to clarify it. This feedback is valuable as it directs the authors to a specific area needing improvement and offers a concrete way to enhance the clarity and rigor of their work. However, the comment could be more helpful if it provided additional guidance on how to formalize the connection or examples of how to improve the language. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with further details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states two actions: the first is to correct the callout to table 5 to refer to table 3, and the second is to ensure that the callout to figure 6 in page 7, section 5, is properly directed. These actions are clear and concrete, providing the authors with specific steps to take to improve their draft. The feedback is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 5\" and \"table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the callout and provides a clear direction for correction. Additionally, it mentions \"page 7, section 5, last par.\" to further ground the comment, making it clear where the issue with the figure callout is located. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements regarding the incorrect callouts in the paper, specifically mentioning that the callout to table 5 should refer to table 3 and that the callout to figure 6 is not properly directed. These statements are descriptive and do not contain subjective opinions, claims, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the incorrect callout to table 5, which should refer to table 3, and the improper direction of the callout to figure 6 in page 7, section 5. These are clear and actionable points that the authors can address to improve the accuracy and clarity of their draft. By providing specific corrections, the comment offers valuable guidance that can help the authors enhance the quality and coherence of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern with the experiments, specifically noting that the paper only includes selfcomparisons and lacks explanation for this choice. It suggests that comparisons with SketchRNN could be performed in a generative setting. While the comment identifies a potential issue and provides a specific suggestion for improvement, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should include comparisons with SketchRNN and provide a rationale for their experimental choices. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experiments section of the paper, specifically mentioning that the paper only includes selfcomparisons and lacks explanation for this choice. It also suggests that comparisons with SketchRNN could be performed in a generative setting. This provides clear guidance on what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper discusses the experiments, so the authors might need to infer that it refers to the results or methodology sections. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s experiments are a concern due to the lack of comparisons with other models, specifically mentioning SketchRNN. However, the comment does not provide specific examples or detailed reasoning to support why these comparisons are necessary or how they would enhance the paper. The suggestion to include comparisons with SketchRNN is vague and lacks context, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient detail or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant concern with the paper, specifically the lack of comparisons with other models, such as SketchRNN, in the experiments. It highlights that the paper only includes selfcomparisons, which can limit the paper\"s impact and motivation. The comment provides a clear and actionable suggestion to include comparisons with SketchRNN, which could enhance the paper\"s validity and relevance. However, the comment could be more helpful if it offered additional guidance on how to conduct these comparisons or why they are important. Overall, the feedback is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with further details."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly recommends additional analysis and comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It also challenges the authors\" viewpoint that both CNNs and ViTs benefit similarly from increased model capacity, providing specific examples and data to support the disagreement. The comment suggests that the authors should address the discrepancy in performance between DeiT models and CNNs as capacity increases. While the action is explicit, the comment could be more actionable by providing specific guidance on how to conduct the additional analysis or what aspects to focus on. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the performance trending of increasing the number of parameters for ViT (DeiT) and challenges the authors\" viewpoint on the benefit of increased model capacity. The comment specifies the discrepancies in performance between DeiT models and CNNs, providing examples and data to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" viewpoint on the benefit of increased model capacity for both CNNs and ViTs is incorrect. It provides specific examples and data from Figure 3 to support this claim, such as the performance of DeiTB models not outperforming DeiTT in APTOS2019 and not outperforming DeiTS on APTOS2019, ISIC2019, and CheXpert. This detailed analysis and evidence make the claim 5, as it provides a clear and logical reasoning for the disagreement. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by recommending additional analysis and comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It challenges the authors\" viewpoint that both CNNs and ViTs benefit similarly from increased model capacity, offering detailed examples and data to support the disagreement. This feedback is valuable as it prompts the authors to revisit their analysis and provide a more nuanced understanding of the performance trends. However, the comment could be more helpful if it suggested specific ways to conduct the additional analysis or how to present the findings. Overall, the comment is 4, as it directs the authors to a critical area for improvement in their draft."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that the paper is generally easy to follow but identifies specific places that may cause confusion. However, it does not provide explicit guidance on which places these are or how the authors might address the potential confusion. The comment implies that the authors should review their draft to identify and clarify these areas, but it lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment mentions that there are places in the paper that may cause confusion, but it does not specify which parts of the paper these are. It also does not provide any details on what might be causing the confusion, making it difficult for the authors to identify and address the issues. The reference to \"point 3\" is not sufficient for the authors to determine which part of the paper is being addressed, as it does not provide context or details about the content of point 3. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not difficult to follow but identifies several places that may cause confusion. However, it does not specify which places these are or provide any supporting evidence or examples to substantiate the claim. Without detailed information or references, the authors may find it challenging to understand and address the potential issues. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the paper is generally easy to follow but identifies specific areas that may cause confusion. However, it does not provide detailed guidance or suggestions on how to address these potential issues, leaving the authors without actionable feedback. The comment lacks specificity and does not offer any constructive advice for improvement, making it 2. The authors are left with a vague understanding of where the confusion might lie, without clear steps to take to resolve it. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the results are based on \"standard\" techniques but are not immediately obvious and require technical competency. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of making the results more accessible or how to enhance the clarity of the techniques used. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the results section, noting that while the techniques used are considered \"standard,\" they are not immediately obvious and require a high level of technical expertise. However, it does not specify which results or techniques are being referred to, making it weakly grounded. The comment is specific in its critique of the technical competency required to understand the results, but without explicit references to specific sections or elements of the paper, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the results are based on \"standard\" techniques but are not immediately obvious, requiring a high degree of technical competency. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains 3, as it provides a general observation but lacks concrete support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights a potential issue with the accessibility of the results, noting that while the techniques used are considered \"standard,\" they may not be immediately obvious to all readers. This observation suggests that the authors should consider making their results more accessible or providing additional context to help readers understand the techniques used. However, the comment does not offer specific suggestions or guidance on how to achieve this, such as recommending additional explanations, examples, or references. While it identifies a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests clarifying the differences between the implemented bilinear layer and other approaches that use bilinear pooling. It asks specific questions about the dimensionality of embeddings, the swapping of the bilinear layer with other approaches, and whether the compression of representations using Equation (3) is still done. While the comment provides clear guidance on what needs to be clarified, it does not explicitly instruct the authors to make these clarifications. The action is implicit but concrete, as the authors can infer that they need to address these points. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L290,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: the differences between the implemented bilinear layer and other approaches that use bilinear pooling, particularly regarding the dimensionality of embeddings and the swapping of the bilinear layer with other approaches. Additionally, it questions whether the compression of representations using Equation (3) is still done in this case. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the differences between the implemented bilinear layer and other approaches that use bilinear pooling. It asks specific questions about the dimensionality of embeddings, the swapping of the bilinear layer with other approaches, and whether the compression of representations using Equation (3) is still done. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these questions. Without additional context or justification, the authors may find it challenging to address these points effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for clarification regarding the implemented bilinear layer and its differences from other approaches that use bilinear pooling. It raises questions about the dimensionality of embeddings, the swapping of the bilinear layer with other approaches, and whether the compression of representations using Equation (3) is still done. This feedback is clear and actionable, as it directs the authors to provide additional details that could enhance the understanding and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of how similar approaches have been discussed in the literature. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the similarity in preactivation values of two networks and suggests that the output cosine similarity will be high. It then asks why the results of the latter loss term of Eqn 13 are not directly illustrated. While the comment implies that the authors should provide more detailed results or analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include more detailed results or analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 3 e,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the results of the latter loss term of Eqn 13 are not directly illustrated, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the relevance of illustrating the results of the latter loss term of Eqn 13, suggesting that the preactivation values of two networks being the same would lead to a high output cosine similarity. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the interpretation of results in Fig. 3, specifically questioning why the preactivation values of two networks being the same would lead to a high output cosine similarity. It suggests that the results of the latter loss term of Eqn 13 should be directly illustrated. This feedback is 3 as it points out a specific area for clarification and improvement, encouraging the authors to provide more detailed results or analysis. However, the comment could be more helpful if it offered suggestions on how to present these results or why they are important. Overall, the feedback provides some guidance but lacks depth, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a specific issue with the \"required implicit call to the Witness oracle,\" indicating that it is confusing. However, it does not provide any guidance or suggestions on how to clarify or address this confusion. The comment lacks explicit instructions or concrete details on what changes should be made to improve the clarity of the implicit call. As a result, the authors are left without a clear understanding of how to address the issue, making the comment 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the \"required implicit call to the Witness oracle,\" suggesting that it is confusing. However, it does not specify which part of the paper this issue is located in, such as a particular section or figure. Without explicit references or detailed guidance, the authors cannot confidently determine where to address this concern. The comment is specific in its critique but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point claims that the \"required implicit call to the Witness oracle\" is confusing. However, it does not provide any supporting evidence, reasoning, or examples to explain why this is confusing or how it could be clarified. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper, noting that the \"required implicit call to the Witness oracle\" is confusing. However, it does not provide any further explanation or suggestions on how to clarify this confusion or improve the clarity of the paper. Without actionable guidance or detailed feedback, the authors are left without a clear understanding of how to address the issue, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify the distinction between when the proposed method is trained using only weak supervision and when it is semisupervised trained. It provides a specific suggestion for renaming a column in Table 1 to better reflect the semisupervised version of the method. Additionally, it offers a more comprehensive approach by suggesting the use of two columns to specify the data used for training each model. This feedback is clear and provides concrete steps for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and the \"proposed framework row,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the distinction between weak supervision and semisupervised training, and suggests renaming a column in Table 1. Additionally, it provides a detailed suggestion for improving the clarity of the table by using two columns to specify the data used for training each model. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify the distinction between weak supervision and semisupervised training in their proposed method. It provides a specific example from Table 1, suggesting a renaming of the column to better reflect the semisupervised version of the method. The comment also offers a more comprehensive approach by proposing the use of two columns to specify the data used for training each model. This feedback is wellsupported by logical reasoning and specific suggestions, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by identifying a specific area where the authors need to clarify the distinction between weak supervision and semisupervised training in their proposed method. It suggests renaming a column in Table 1 to better reflect the semisupervised version of the method and proposes a more comprehensive approach by using two columns to specify the data used for training each model. This feedback is detailed and offers concrete suggestions for improvement, making it 5 for the authors to enhance the clarity and comprehensibility of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the paper for making small contributions over previous methods, such as NCNet and Sparse NCNet, and suggests that the work is mostly engineering. It also notes that it is challenging to differentiate the current work from its predecessors due to similar performance. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue of small contributions or differentiate the work from previous methods. Without actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the paper for making small contributions over previous methods, specifically mentioning NCNet and Sparse NCNet. However, it does not specify which part of the paper these comparisons are based on, making it difficult for the authors to identify the exact sections that need attention. The comment also lacks specificity regarding what aspects of the contributions are considered small or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper makes small contributions over previous methods, specifically NCNet and Sparse NCNet, and suggests that the work is mostly engineering. It also notes that it is challenging to differentiate the current work from its predecessors due to similar performance. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the critique. The absence of concrete evidence or references to previous work limits the verifiability of the claim, rendering it barely verifiable. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment critiques the paper for making small contributions over previous methods, specifically NCNet and Sparse NCNet, and suggests that the work is mostly engineering. It also notes that it is challenging to differentiate the current work from its predecessors due to similar performance. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve their work. Without actionable feedback or detailed advice, the authors are left without a clear path for improvement. Therefore, the comment is 2, as it identifies a weakness but does not provide sufficient guidance for the authors to address it effectively."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the vulnerability discovery methodology, specifically questioning the approach of considering a single vulnerability at a time. It also questions the ecological validity of the study and suggests that previous work has considered multiple CVEs or CWEs simultaneously. The reviewer asks if the authors are arguing that identifying one vulnerability at a time is an intended use case and notes that the results are difficult to interpret. While the comment identifies areas of concern and raises questions, it does not provide explicit instructions or concrete suggestions for the authors to address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should clarify their methodology and provide more context for their approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the vulnerability discovery methodology, specifically questioning the approach of considering a single vulnerability at a time. It also questions the ecological validity of the study and compares it to previous work that considered multiple CVEs or CWEs. However, the comment does not explicitly mention which part of the paper discusses this methodology, making it weakly grounded. The authors can infer that it relates to the methodology section, but this is not explicitly stated. The comment is specific in detailing the concerns about the methodology and the comparison with previous work, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the vulnerability discovery methodology, specifically questioning the approach of considering a single vulnerability at a time. It compares this approach to previous work that considered multiple CVEs or CWEs and questions the ecological validity of the study. The reviewer also asks if the authors are arguing that identifying one vulnerability at a time is an intended use case. While the comment provides some context and comparisons, it lacks specific references or detailed examples to fully substantiate the claim. The reasoning is somewhat logical but could be strengthened with more detailed evidence or references. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment raises concerns about the vulnerability discovery methodology, specifically questioning the approach of considering a single vulnerability at a time. It highlights the potential issue of ecological validity and compares it to previous work that considered multiple CVEs or CWEs. The reviewer also questions whether the authors are arguing that identifying one vulnerability at a time is an intended use case. This feedback is 3 as it identifies a potential weakness in the methodology and prompts the authors to clarify their approach. However, it lacks specific suggestions or guidance on how to address these concerns, which would make it more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or improve the originality of their work. There is no explicit or implicit action for the authors to take, such as suggesting new approaches or ideas to enhance originality. Without any actionable advice, the comment leaves the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not specify which part of the paper discusses variable splitting or the algorithm, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the originality are lacking or how the authors could improve it. Without clear guidance or references to specific parts of the paper, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or comparisons to existing work, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not provide any specific examples, references, or suggestions on how the authors could enhance the originality of their work or address this critique. Without actionable feedback or guidance, the authors are left without a clear understanding of how to improve their draft. The comment lacks depth and does not offer any constructive suggestions, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the claim that INRs operate on a perdatainstance basis, suggesting that this characteristic is not an advantage. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or improve the draft. The comment lacks actionable details, leaving the authors without a clear understanding of what changes are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that INRs operate on a perdatainstance basis and suggesting that this characteristic is not an advantage. The comment provides a clear critique of the paper\"s claim, making it specific. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that INRs operate on a perdatainstance basis, suggesting that this characteristic is not an advantage. The reviewer provides a logical reasoning by stating that a model that can only handle a single time series data is almost useless. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider the implications of this limitation and potentially provide additional context or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the claim that INRs operate on a perdatainstance basis, suggesting that this characteristic is not an advantage. The reviewer argues that a model that can only handle a single time series data is almost useless, which provides a clear critique of the paper\"s claim. However, the comment lacks depth and does not offer any suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential weakness, it does not provide actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a limitation in the experiments, noting that most experiments are limited to RoBERTabase and raises concerns about the generalizability of the results to other models with learnable APEs. It suggests investigating the results\" generalizability to differences in model size, objective function, and architecture, and specifically recommends including more analysis and discussion for GPT2. The comment provides explicit actions for the authors to take, such as conducting additional experiments and including more analysis, and offers specific examples like including results for Figure 2 for GPT2. This level of detail and guidance makes the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1.1\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the experiments, namely the limited scope to RoBERTabase and the need to investigate generalizability to other models. The comment further suggests including more analysis and discussion for GPT2, providing a concrete example of what additional information could be included. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited to RoBERTabase and questions the generalizability of the results to other models with learnable APEs. It suggests investigating the results for differences in model size, objective function, and architecture, and specifically recommends including more analysis for GPT2. While the comment raises a valid concern about the scope of the experiments, it lacks specific examples or references to support the claim that the results cannot be generalized. The suggestion to include more analysis for GPT2 is a logical step, but without detailed reasoning or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper\"s experiments, noting that most experiments are limited to RoBERTabase and questioning the generalizability of the results to other models with learnable APEs. It suggests that the authors should investigate whether the results can be generalized to differences in model size, objective function, and architecture, such as GPT2. The comment provides specific and actionable feedback by recommending additional analysis and discussion for GPT2, including results for Figure 2. This feedback is clear and constructive, offering the authors a clear path to improve the comprehensiveness and robustness of their experimental results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of description in the abstract regarding the evaluation of the proposed idea and its outcome. While it acknowledges that the abstract does a good job explaining the idea, it points out a specific gap in the evaluation and outcome description. However, the comment does not provide explicit guidance on how to address this issue or suggest specific changes to improve the abstract. The action is implicit, as the authors can infer that they need to add more details about the evaluation and outcome, but it lacks concrete steps or examples. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of description regarding the evaluation and outcome of the proposed idea, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract does a good job explaining the proposed idea but lacks description of how the idea was evaluated and what the outcome was. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a clear observation about the abstract, noting that it effectively explains the proposed idea but lacks details on how the idea was evaluated and what the outcome was. This feedback is 3 as it identifies a specific area for improvement, suggesting that the authors should include more information about the evaluation and outcome in the abstract. However, the comment could be more helpful if it offered specific suggestions on how to present this information or what aspects of the evaluation should be highlighted. Overall, the feedback is actionable but could be more comprehensive, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights confusion in the description of the MFDA setting in the first paragraph of the Method Section. It points out inconsistencies in the notation and questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper. While the comment identifies specific areas of confusion and references the original paper for context, it does not provide explicit instructions on how to clarify or address these issues. The authors are left to infer that they need to clarify the notation and the use of unlabeled data in source domains. The action is implicit and somewhat vague, as it lacks detailed guidance on how to resolve the confusion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first paragraph of the Method Section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the description of the MFDA setting, including the confusion caused by the notation for the target domain and the use of labeled and unlabeled data. The comment provides specific examples and references to the original MFDA paper, which helps the authors understand what needs to be clarified or addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the MFDA setting is confusing, specifically mentioning the notation for the target domain and the use of labeled and unlabeled data. The reviewer references the original MFDA paper (Yue et al., 2021a) to support their claim, noting that the target data is unlabeled in the original paper. This provides a logical basis for the claim, as it highlights a potential inconsistency in the description of the problem setting. However, the comment could be strengthened by providing more detailed examples or explanations of how the description is confusing. Overall, the claim is 4, as it is supported by a reference to the original paper but could benefit from additional clarification. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of the MFDA setting in the first paragraph of the Method Section. It points out confusion regarding the notation for the target domain and the use of labeled and unlabeled data, particularly in comparison to the original MFDA paper. The comment raises questions about the consistency of the problem setting description and suggests that the authors clarify these aspects. By highlighting these inconsistencies and referencing the original paper, the comment provides clear and actionable feedback that can help the authors improve the clarity and accuracy of their description. However, it could be more helpful if it offered specific suggestions on how to address these issues. Overall, the comment is 4, as it directs the authors to a critical area needing clarification and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the paper, namely the difficulty in distinguishing between derogatory and exclusionary extreme speech. It provides a concrete example from the sample data file, questioning the classification of a particular instance. The reviewer also raises a question about the role of local regulation in annotations and its impact on zeroshot crosscountry classification. While the comment identifies a problem and provides specific examples, it does not explicitly instruct the authors to address these issues or suggest how to improve the clarity of the distinction between the two types of extreme speech. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definitions and address the regulatory aspects. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Paper Summary\" and the need for a clear distinction between the three classes of extreme speech. It also references specific instances and lines in the paper, allowing the authors to accurately identify the parts being addressed. The comment is specific because it provides a detailed example from the sample data file, questioning the classification of an instance and raising concerns about the role of local regulation in annotations. This level of detail helps the authors understand what needs to be clarified or addressed in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of distinguishing between derogatory and exclusionary extreme speech, citing a specific example from the sample data file. It questions the classification of an instance and highlights the potential impact of local regulation on annotations. While the comment provides a specific example and raises a valid point about the need for clearer distinctions, it lacks detailed reasoning or references to support the claim fully. The authors are left to infer the importance of addressing this issue, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clear distinction between derogatory and exclusionary extreme speech. It provides a concrete example from the sample data file, questioning the classification of a particular instance and highlighting the potential impact of local regulation on annotations. This feedback is actionable as it prompts the authors to clarify the definitions and address the regulatory aspects that may influence the annotations. However, the comment could be more helpful if it offered suggestions on how to improve the clarity of the distinction or provided additional guidance on addressing the regulatory concerns. Overall, the comment is 4 as it directs the authors to a critical area that needs attention, but it could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the performance of the proposed method compared to the baseline model when trained and evaluated at the same timestep. It suggests that the effectiveness of the proposed method is questionable if the goal is merely to achieve good performance. However, the comment also implies that the proposed method might be beneficial in scenarios where the training and evaluation timesteps differ. While the comment identifies a potential issue and offers a possible scenario where the proposed method might be beneficial, it does not provide explicit guidance on how the authors should address this concern or conduct further analysis. The action is implicit and somewhat vague, as the authors need to infer that they should explore scenarios with different timesteps to demonstrate the method\"s effectiveness. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the performance of the proposed methods compared to the baseline model when trained and evaluated at the same timestep, questioning the effectiveness of the proposed methods under this condition. The comment further suggests that the proposed method might be beneficial in scenarios where the training and evaluation timesteps differ. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the effectiveness of the proposed method, noting that it shows similar performance to the baseline model when trained and evaluated at the same timestep. The reviewer suggests that this might make the proposed method questionable for achieving good performance. However, the comment also implies that the method might be beneficial in scenarios where the training and evaluation timesteps differ. While the comment provides some logical reasoning, it lacks specific examples or references to support the claim that the proposed method might be beneficial in different scenarios. This makes the claim 3, as it requires further evidence or detailed reasoning to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the effectiveness of the proposed method, noting that it shows similar performance to the baseline model when trained and evaluated at the same timestep. This observation questions the value of the proposed method if its primary goal is to achieve good performance. However, the comment also suggests that the method might be beneficial in scenarios where the training and evaluation timesteps differ, providing a potential direction for further exploration. While the comment identifies a critical issue and offers a possible avenue for improvement, it lacks specific guidance on how to address the concern or conduct further analysis. The feedback is 3 as it points out a potential weakness and offers a direction for improvement, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the disentanglement process, noting that while the \"Broader Impacts and Limitations\" section mentions it as a limitation, the paper does not clearly explain how disentanglement is guaranteed or realized without certain bias types. The comment implies that the authors should provide more detailed information on this aspect. However, it does not explicitly instruct the authors to add specific details or examples, leaving the action somewhat vague. The authors can infer that they need to elaborate on the disentanglement process, but the comment lacks concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Broader Impacts and Limitations\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the disentanglement process, noting that while it is mentioned as a limitation, the paper does not provide clear details on how disentanglement is realized and guaranteed without certain bias types. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of clarity regarding how disentanglement is guaranteed in the paper. It references the \"Broader Impacts and Limitations\" section, where disentanglement is mentioned as a limitation, but notes that the paper does not provide sufficient details on how disentanglement is achieved without certain bias types. This claim is 3 as it highlights a specific area of concern and references a relevant section of the paper. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the disentanglement process in the paper. It points out that while the \"Broader Impacts and Limitations\" section mentions disentanglement as a limitation, the paper does not provide clear details on how disentanglement is realized and guaranteed without certain bias types. This feedback is clear and actionable, as it prompts the authors to provide more detailed information on this critical aspect of their work. By addressing this point, the authors can enhance the clarity and robustness of their paper. Therefore, the comment is 4, as it provides a specific area for improvement that can significantly enhance the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of certain stateoftheart references in the experiment on face recognition, specifically mentioning a work by Baidu that uses the triplet loss and reports results on a dataset similar to Webface. The reviewer also compares the results of the VRF with those in Table 3 of the paper, noting that the VRF achieves a better result. While the comment identifies a gap in the references and provides a specific example, it does not explicitly instruct the authors to include these references or to address the comparison with the mentioned work. The action is implicit and somewhat vague, as the authors need to infer that they should include these references and consider the comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment of face recognition\" and references a specific work by Baidu, \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding,\" along with a link to the results. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out the missing stateoftheart references and provides a comparison with the results in Table 3, indicating what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some stateoftheart references are missing in the experiment on face recognition, specifically mentioning a work by Baidu that uses the triplet loss and reports results on a dataset similar to Webface. The reviewer provides a specific reference to the Baidu work and compares the results of the VRF with those in Table 3 of the paper, noting that the VRF achieves a better result. This provides a clear and specific comparison, making the claim 4. However, the comment could be strengthened by providing more detailed analysis or examples of how the missing references impact the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific gap in the references used in the experiment on face recognition, pointing out the omission of a stateoftheart work by Baidu. It provides a detailed reference to the work, including a link to the results, and highlights a comparison with the results in Table 3 of the paper. This feedback is actionable as it directs the authors to include these references and consider the implications of the comparison. By addressing this gap, the authors can enhance the credibility and relevance of their work. However, the comment could be more helpful if it suggested how to incorporate these references or provided additional context for the comparison. Overall, the comment is 4, as it provides clear guidance for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the ICLHAR, noting that it has improved consistency and verifiability but has negatively impacted accuracy scores. The reviewer suggests that this should be discussed or acknowledged in the main text in more detail. While the comment implies that the authors should address this issue, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to discuss or acknowledge the impact of ICLHAR on accuracy scores. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ICLHAR,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that while ICLHAR improves consistency and verifiability, it negatively impacts accuracy scores, specifically mentioning a drop from 70.4 to 55.6 on TRIP. This provides clear guidance on what needs to be addressed in the main text, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the ICLHAR has negatively impacted accuracy scores, specifically mentioning a drop from 70.4 to 55.6 on TRIP. While the comment provides specific numbers and references a particular dataset (TRIP), it lacks detailed reasoning or evidence to fully substantiate the claim. The authors might need additional context or explanation to understand the implications of this change. Therefore, the comment is 3, as it provides some support but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the ICLHAR, noting that while it improves consistency and verifiability, it significantly impairs accuracy scores. The reviewer suggests that this should be discussed or acknowledged in the main text in more detail. This feedback is clear and actionable, as it highlights a critical aspect of the paper that needs further exploration or explanation. By pointing out the tradeoff between consistency, verifiability, and accuracy, the comment provides the authors with a specific area to address and potentially improve their draft. However, it could be more helpful if it offered suggestions on how to discuss or acknowledge this issue in the main text. Overall, the comment is 4, as it directs the authors to a significant area of improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point notes a drop in correlation after a short period of training, followed by an increase with more training iterations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to improve the model\"s performance or stability over time. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to a specific observation about the correlation after a short period of training and its increase with more training iterations. However, it does not specify which part of the paper this observation is based on, such as a particular figure, table, or section. Without explicit references, the authors may find it challenging to identify the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or how this observation impacts the overall analysis. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point describes an observation about the correlation after a short period of training and its increase with more training iterations. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the observation or how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific observation regarding the correlation after a short period of training and its increase with more training iterations. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or interpret its implications. Without actionable feedback or insights into potential causes or solutions, the comment offers limited value to the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the derivation from Eqn. 3 to Eqn. 4 is missing the temperature \u03c4 and suggests that it should be shown in a rigorous way or mentioned in the paper. This provides a clear and direct action for the authors to take, which is to include the temperature \u03c4 in the derivation or mention it in the paper. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqn. 3 to Eqn. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of missing the temperature \u03c4 in the derivation and suggests that it should be shown in a rigorous way or mentioned in the paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the derivation from Eqn. 3 to Eqn. 4 is missing the temperature \u03c4 and suggests that it should be shown in a rigorous way or mentioned in the paper. This claim is 3 as it points out a potential gap in the derivation, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The reviewer provides a clear suggestion for improvement, but without additional context or references, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the derivation of the paper, noting that the temperature \u03c4 is missing in the transition from Eqn. 3 to Eqn. 4. It provides a clear and actionable suggestion by recommending that the temperature should be shown in a rigorous way or mentioned in the paper. This feedback is valuable as it directs the authors to a precise area where the paper may lack clarity or completeness, allowing them to make targeted improvements. However, the comment could be more helpful if it offered additional context or examples of how the temperature should be integrated into the derivation. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with further guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the current setting is only partially strategic or game theoretic because the opponent does not behave strategically. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve their setting to make it more strategic or game theoretic. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l28,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the setting, noting that it is only partially strategic or game theoretic due to the opponent\"s behavior. The comment provides a clear critique of the current setting and suggests that it lacks strategic depth. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the current setting is only a \"very first step\" towards real strategic settings, as the opponent does not behave strategically. This claim is based on the authors\" claim of \"strategic predictions\" and the observation that the opponent does not take into account the other strategic player. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides some context, it is not 5 due to the absence of explicit evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the current setting, noting that it is only partially strategic or game theoretic because the opponent does not behave strategically. This feedback is 3 as it points out a potential area for improvement, suggesting that the authors should consider making their setting more strategic or game theoretic. However, the comment lacks specific suggestions or guidance on how to achieve this, such as recommending additional features or modifications to enhance the strategic aspect. While it provides some insight, the feedback could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take. It instructs them to run experiments for untrained networks and add the results to the figures and Table 1. Additionally, it requests clarification on the use of random data in Figures 3c and 3, specifically asking whether the network was trained on random data or if the dotted lines represent networks trained on unaltered data evaluated with random data. The comment also suggests clarifying whether the nonrandom data was normalized and, if so, whether the additional \"unitball\" noise is small or large compared to the data. Finally, it recommends showing examples of the random data in the appendix. These instructions are clear and concrete, providing the authors with specific steps to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figures 3c\" and \"Fig 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific requests for clarification and additional experiments, such as running experiments for untrained networks and adding results to the figures and Table 1. Additionally, it asks for clarification on the use of random data in Figures 3c and 3, and suggests showing examples of the random data in the appendix. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of requests for clarification and additional information, such as running experiments for untrained networks, clarifying the use of random data in Figures 3c and 3, and providing examples of random data in the appendix. These requests are factual and do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback, addressing several areas for improvement in the paper. It requests additional experiments to include results for untrained networks, which would enhance the understanding of the figures and Table 1. The comment also seeks clarification on the use of random data in Figures 3c and 3, asking whether the network was trained on random data or if the dotted lines represent networks trained on unaltered data evaluated with random data. Furthermore, it suggests clarifying whether the nonrandom data was normalized and recommends showing examples of the random data in the appendix. These suggestions are clear and detailed, offering the authors concrete steps to improve the clarity and comprehensiveness of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the task setup, specifically questioning which notes from the EHR are used as input and how far away the outcomes are from the last note date. While the comment identifies areas that need clarification, it does not provide explicit instructions or suggestions on how to address these issues. The authors can infer that they need to provide more detailed information about the task setup, but the comment lacks concrete guidance on what specific details to include or how to present them. Therefore, the comment is 3, as it points out a problem but does not fully direct the authors on how to resolve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"task setup,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the task setup, such as the use of notes in the EHR and the distance of outcomes from the last note date. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the clarity of the task setup, specifically regarding the use of EHR notes and the timing of outcomes. However, it does not make a claim or provide an opinion that requires verification. It is a factual inquiry seeking clarification, which aligns with the label \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the task setup, particularly in relation to the use of EHR notes and the timing of outcomes. It provides a clear and actionable suggestion by asking for clarification on these points, which would help the authors improve the comprehensibility of their work. However, the comment could be more helpful if it offered additional guidance or examples on how to present this information effectively. Overall, the comment is 4 as it directs the authors to a critical area needing clarification, but it could be more comprehensive with further suggestions or examples."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should mention the use of untrained neural networks (like deep image prior) for solving inverse problems across a wide class of images, as shown in recent papers. It also recommends comparing the current method with these types of methods. While the comment implies that the authors should include this information and comparison, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add a discussion on the context and comparison with existing methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"OOD experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a suggestion to mention the use of untrained neural networks (like deep image prior) for solving inverse problems and to place the current method in context by comparing it with those methods. This level of detail guides the authors on what needs to be addressed and how to improve their work. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper\"s claim of strong OOD generalization by the trained network is interesting but notes that recent papers have shown that untrained neural networks can solve inverse problems across a wide class of images. The reviewer recommends mentioning this in the paper and comparing the current method with those approaches. While the comment provides a logical reasoning for the suggestion, it lacks specific references to the papers that demonstrate the effectiveness of untrained neural networks. This makes the claim 3, as the authors would need to conduct further research to fully understand the context and implications of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the interest in the OOD experiments, noting the strong OOD generalization of the trained network. However, it suggests that the authors should place their method in context by mentioning recent papers that have shown the effectiveness of untrained neural networks (like deep image prior) in solving inverse problems across a wide class of images. The comment provides a constructive suggestion for the authors to expand their discussion and comparison with existing methods, which could enhance the paper\"s contribution and relevance. While the feedback is clear and actionable, it could be more helpful if it included specific references to the papers mentioned or more detailed guidance on how to integrate this information into the paper. Overall, the comment is 4, as it offers valuable insights for improving the draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the experiments, noting that they are restricted to toy data and suggests that it would be beneficial to demonstrate the method\"s performance on realworld problems. However, the comment does not provide explicit guidance on how to address this issue or which specific realworld problems should be considered. The action is implicit and somewhat vague, as the authors are left to infer that they should expand their experiments to include realworld data sets. While the suggestion is clear, the lack of concrete details on how to implement it makes the comment 3.", "grounding_specificity_rationale": "The comment highlights a limitation in the experiments, noting that they are restricted to toy data and suggests that it would be beneficial to demonstrate the method\"s performance on realworld problems. However, it does not specify which part of the paper discusses the experiments or which realworld problems should be considered. The authors can infer that the comment relates to the experimental section, but it lacks full grounding as it does not explicitly mention the section. The comment is specific in suggesting the need to include realworld data, but it is not fully grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are limited to toy data and suggests that it would be interesting to show the performance of the method on realworld problems. However, the comment lacks specific examples or references to realworld problems where barycenters could be applied, making it difficult for the authors to understand the scope of the suggestion. The claim is 3 as it provides a general direction for improvement but lacks detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are restricted to toy data and suggests that it would be beneficial to demonstrate the method\"s performance on realworld problems. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experimental scope. However, the comment could be more helpful if it included suggestions on which realworld problems or datasets would be most relevant or how to adapt the method for these settings. Despite this, the comment offers a valuable insight that can guide the authors in enhancing the applicability and robustness of their work. Therefore, it is rated as 4, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides two explicit actions for the authors to take. First, it instructs them to make the captions more descriptive, which is a clear and concrete action. Second, it suggests explaining the scramble network better, which is also a direct and actionable request. The comment provides specific guidance on how to improve the clarity of the figures and the explanation of the scramble network, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the captions\" and \"the figures,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be improved, namely making the captions more descriptive and explaining the scramble network better. This provides clear guidance on what the authors should focus on to enhance their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the captions should be more descriptive, as it is \"annoying to have to search through the text for your interpretation of the figures.\" This claim is 3, as it highlights a potential issue with the clarity of the figures, but it lacks specific examples or detailed reasoning to fully substantiate the need for more descriptive captions. The comment also mentions explaining the scramble network better, which is a separate issue that could be addressed with more detailed guidance or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides two specific suggestions for improving the clarity and comprehensibility of the paper. First, it advises making the captions more descriptive, which would help readers understand the figures without having to search through the text for interpretations. Second, it suggests explaining the scramble network better, which could enhance the reader\"s understanding of the methodology. These suggestions are clear and actionable, offering the authors concrete ways to enhance the readability and comprehensiveness of their draft. However, the comment could be more helpful if it provided examples or specific guidance on how to improve the captions or explain the scramble network. Overall, the feedback is 4, as it directs the authors toward meaningful improvements, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies two issues: undefined abbreviations and superscript notation in an equation that is not defined until later in the paper. The reviewer provides specific examples, such as \"NE\" on line 73 and the superscript notation in equation 6, which are not defined until much later. This feedback is clear and actionable, as it directs the authors to define these abbreviations and notation at the point of their first appearance. The inclusion of references to relevant literature adds context and supports the need for clarity in the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"L73\" and \"Eq 6,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issues, namely undefined abbreviations and superscript notation, which need to be addressed. Additionally, the comment provides references to relevant literature, which further supports the need for clarity in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some abbreviations are not defined and that superscript notation in an equation is not defined until later in the paper, which hinders understanding. The reviewer provides specific examples, such as \"NE\" on line 73 and the superscript notation in equation 6, and references relevant literature to support the need for clarity. This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or explanations of how these issues impact the paper\"s clarity. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies two specific issues that hinder the understanding of the paper: undefined abbreviations and superscript notation in an equation that is not defined until later. By providing examples, such as \"NE\" on line 73 and the superscript notation in equation 6, the reviewer offers clear and actionable feedback. Additionally, the comment includes references to relevant literature, which can help the authors understand the context and importance of defining these elements. This feedback is detailed and provides concrete steps for the authors to improve the clarity and readability of their draft, making it 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to strengthen the evaluation or which alternative baselines might be more suitable. Without specific suggestions or directions, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the evaluation as weak and mentions that the baselines used are not designed for fair classification. However, it does not specify which part of the paper discusses the evaluation or the baselines, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the evaluation are weak or how the baselines could be improved for fair classification. This lack of grounding and specificity makes it challenging for the authors to address the feedback effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, the comment lacks specific examples or references to support these claims. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation methodology, specifically noting that the baselines used are not designed for fair classification. This is a critical observation that highlights a potential flaw in the paper\"s evaluation process. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue or suggest alternative baselines that could be more appropriate. Without detailed suggestions or examples, the authors may find it challenging to understand how to improve their evaluation methodology. Therefore, the comment is 3, as it points out a weakness but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point consists of two separate issues. The first part addresses a claim made in the Related Work section regarding the Walkman algorithm, pointing out that it is not accurate to state that all works are based on simple SGD for decentralized optimization. This feedback is explicit and provides a clear action for the authors to correct the statement. The second part identifies a grammatical issue in Section 3, where the pronoun \"it\" lacks a clear reference. This is also an explicit action for the authors to clarify the reference. Both parts of the comment are clear and direct, providing the authors with specific actions to take. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 2, second paragraph in Related Work\" and \"Section 3, first paragraph,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the claims made in these sections, such as the inaccuracy of stating that all works are based on simple SGD for decentralized optimization and the lack of a clear reference for the pronoun \"it.\" This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two separate claims. The first claim challenges the statement that all works are based on simple SGD for decentralized optimization, pointing out that the Walkman algorithm (Mao et al., 2020) uses ADMM with two versions. This claim is supported by specific references to the algorithm and its variations, making it 4. The second claim points out a grammatical issue with the use of the pronoun \"it\" without a clear reference. While this is a factual observation, it does not constitute a claim requiring verification. Therefore, the first part of the comment is 4, and the second part is factual, aligning with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by addressing two distinct issues in the paper. First, it corrects a claim made in the Related Work section regarding the Walkman algorithm, pointing out that it uses ADMM with two versions, which contradicts the statement that all works are based on simple SGD. This feedback is valuable as it helps the authors ensure the accuracy of their claims. Second, it identifies a grammatical issue in Section 3, where the pronoun \"it\" lacks a clear reference, which could lead to confusion. By highlighting these issues, the comment empowers the authors to make precise corrections and improvements to their draft. Therefore, the comment is 5, as it offers detailed and actionable feedback that can significantly enhance the clarity and accuracy of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to provide a more comprehensive overview of existing methods and their limitations in the Related Work section, specifically mentioning several types of methods that should be discussed. It also suggests positioning SSMs appropriately within this context. The comment provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Related Work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed guidance on what is lacking in the section, specifically suggesting the inclusion of a more comprehensive overview of existing methods and their limitations, including specific types of methods such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This level of detail provides clear direction for the authors on how to improve the section. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Related Work section lacks details and suggests that it should provide a more comprehensive overview of existing methods and their limitations. The comment specifically mentions several types of methods, such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods, which are supported by references 17. This provides a clear and detailed justification for the claim, making it 5. The inclusion of specific references and examples enhances the credibility of the feedback, allowing the authors to understand and address the issue effectively. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying a weakness in the Related Work section, namely the lack of detailed information on existing methods and their limitations. It suggests that the authors should include a more comprehensive overview of methods such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods for handling very long documents. This feedback is clear and constructive, offering the authors a clear path to improve the depth and comprehensiveness of their Related Work section. By addressing this feedback, the authors can enhance the rigor and relevance of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the proposed solution as an incremental step based on the relaxation proposed by Guzman et al. However, it does not provide any explicit or implicit suggestions for improvement. There is no guidance on what specific aspects of the solution need to be addressed or how the authors might enhance their work. Without actionable feedback, the authors are left without a clear understanding of what changes to make to their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the proposed solution as an incremental step based on the relaxation proposed by Guzman et al. However, it does not specify which part of the paper this incremental step is discussed in, nor does it provide any specific feedback or suggestions for improvement. The authors cannot confidently determine which part of the paper is being addressed, and the comment lacks specificity regarding what needs to be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges the proposed solution as an incremental step based on the relaxation proposed by Guzman et al. However, it does not provide any further explanation, evidence, or reasoning to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the comment or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the proposed solution as an incremental step based on the relaxation proposed by Guzman et al. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance or critique, the authors are left without a clear understanding of how to enhance their work. The comment is vague and does not offer any constructive advice, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests several improvements to the results presentation, including labeling the yaxis in Figures 2 and 3 as \"runtime\" instead of \"performance,\" and suggesting a scatter plot with x/y axes as \"runtime/performance\" to enhance understanding. It also recommends highlighting the best results in tables. While the comment provides explicit actions, it lacks detailed guidance on how to implement these suggestions, such as specific formatting instructions for the scatter plot or how to highlight the best results. Therefore, the comment is 3, as it provides a clear direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the yaxis labeling and suggests improvements, such as using a scatter plot with x/y axes as \"runtime/performance\" to enhance understanding. Additionally, it recommends highlighting the best results in tables. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the results presentation can be improved by labeling the yaxis in Figures 2 and 3 as \"runtime\" instead of \"performance,\" and by using a scatter plot with x/y axes as \"runtime/performance\" to enhance understanding. It also recommends highlighting the best results in tables. While the comment provides a logical suggestion for improving the clarity of the results, it lacks specific examples or references to support the claim that the current presentation is ambiguous. The suggestion for a scatter plot is a reasonable improvement, but without further explanation or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on improving the presentation of results in the paper. It identifies issues with the labeling of the yaxis in Figures 2 and 3, suggesting that it should be labeled as \"runtime\" instead of \"performance,\" and recommends using a scatter plot with x/y axes as \"runtime/performance\" to enhance understanding. Additionally, it suggests highlighting the best results in tables. This feedback is clear and provides concrete suggestions for enhancing the clarity and interpretability of the results, making it 5 for the authors to improve their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the choice of using \"advantage\" instead of \"q value\" in the analysis, suggesting that there might be other technical considerations for this choice. However, it does not provide any explicit guidance or suggestions for the authors to address this issue. The comment lacks actionable details, such as what specific technical considerations should be explored or how the authors might investigate this further. As a result, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the choice of using \"advantage\" instead of \"q value\" in the analysis, suggesting that there might be other technical considerations for this choice. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment lacks specificity as it does not provide details on what these technical considerations might be or how they could impact the analysis. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the choice of using \"advantage\" instead of \"q value\" in the analysis, suggesting that there might be other technical considerations for this choice. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice might be problematic or what specific technical considerations are at play. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of using \"advantage\" instead of \"q value\" in the analysis, suggesting that there might be other technical considerations for this choice. While it identifies a potential area of interest, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or explore the technical considerations further. Without actionable feedback or detailed insights, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. However, it does not provide explicit guidance on how to correct these errors or suggest specific actions for the authors to take. The comment implies that the authors should review their manuscript for such errors and correct them, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment identifies specific writing errors on pages 5 and 1, providing full grounding as the authors can accurately pinpoint these sections. It specifies the issues, such as \"informative informative\" and the lack of a title for \"performance,\" which are clear and actionable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are writing errors in the paper, specifically mentioning \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. However, the comment does not provide any further explanation or justification for these claims, such as examples of how these errors affect the paper\"s clarity or impact. Without additional context or evidence, the authors may find it challenging to understand and address the issues. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This feedback is clear and actionable, as it directs the authors to review their manuscript for such errors and correct them. However, the comment could be more helpful if it provided suggestions on how to improve the writing or offered examples of better phrasing. Despite this, the comment is 4 as it highlights a specific area for improvement, allowing the authors to make targeted revisions. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the hGRU architecture as \"adhoc\" and lacking motivation, but it does not provide any explicit or implicit suggestions for improvement. There is no guidance on how the authors might address these concerns or what specific changes could be made to better motivate the architecture. Without actionable advice or direction, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the hGRU architecture, describing it as \"adhoc\" and lacking motivation. However, it does not specify which part of the paper discusses the hGRU architecture, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the architecture are considered adhoc or how it could be better motivated. Without explicit references or detailed guidance, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the hGRU architecture is \"adhoc\" and lacks motivation. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to what makes the architecture adhoc or how it could be improved, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the hGRU architecture, describing it as \"adhoc\" and lacking motivation. While it identifies a potential weakness in the paper, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve the motivation behind the architecture. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a specific question about the use of \"s_n\" instead of \"s_t\" in Algorithm 1, Line 8. It also expresses curiosity about the asymptotic performance of the proposed method and requests average return results with more environment steps. The comment provides a reference to a GitHub repository, which could be useful for further exploration. While the comment identifies a potential issue and suggests a specific action (using \"s_n\" instead of \"s_t\"), it does not fully specify how to implement the change or provide detailed guidance on the asymptotic performance analysis. The action is 4 because it provides a clear direction but lacks detailed instructions on execution. Therefore, this comment is rated as 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1 Line 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of \"s_n\" instead of \"s_t\" and expresses curiosity about the asymptotic performance of the proposed method. Additionally, it requests average return results with more environment steps and provides a reference to a GitHub repository. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the use of \"s_n\" instead of \"s_t\" in Algorithm 1, Line 8, and expresses curiosity about the asymptotic performance of the proposed method. It also requests average return results with more environment steps and provides a reference to a GitHub repository. However, the comment lacks detailed reasoning or evidence to support the claim that \"s_n\" should be used instead of \"s_t\" or to justify the request for additional performance results. The reference to the GitHub repository is not directly relevant to the claim being made. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail and evidence to fully substantiate it.", "helpfulness_rationale": "The review comment raises a specific question about the use of \"s_n\" instead of \"s_t\" in Algorithm 1, Line 8, which could be a critical error in the implementation. It also expresses curiosity about the asymptotic performance of the proposed method and requests average return results with more environment steps. The inclusion of a reference to a GitHub repository provides additional context and potential resources for further exploration. However, the comment could be more helpful if it provided a clearer explanation of why the use of \"s_n\" is preferred or how the asymptotic performance analysis could be improved. Despite this, the comment offers actionable feedback and points out areas for improvement, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point provides several explicit actions for the authors to take. First, it suggests toning down a statement regarding the neural network memorizing critical points, indicating that this is not accurate according to the TopoNet reference. Second, it advises compressing the method section to focus on essential definitions, implying that the current version is too wordy. Lastly, it instructs the authors to doublecheck for grammatical errors, specifically mentioning plurals and articles. These actions are clear and concrete, providing the authors with specific steps to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"to force the neural network to memorize them\" and the reference to TopoNet 24, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests toning down the statement regarding memorization, provides a reason for this suggestion based on the understanding of TopoNet, and offers additional feedback on the method section being wordy and suggesting grammatical corrections. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple claims and suggestions. The first claim about the neural network memorizing critical points is supported by a reference to TopoNet 24, which provides a basis for the reviewer\"s understanding. The suggestion to tone down the statement is logical and based on this reference. The second claim about the method section being wordy is a subjective opinion, but it is supported by the suggestion to focus on essential definitions. The third claim about grammatical errors is factual and requires no justification. Overall, the comment is 4 as it provides a logical basis for the claims and suggestions, but it could be strengthened with more detailed examples or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides several actionable points for improvement. It suggests toning down a statement regarding the neural network memorizing critical points, as the reviewer believes this is not accurate according to the TopoNet reference. This feedback is specific and helps the authors refine their language. Additionally, the comment advises compressing the method section to focus on essential definitions, which is a clear and actionable suggestion for improving the clarity and concision of the paper. Finally, it points out grammatical errors, such as plurals and articles, and suggests doublechecking these. This feedback is detailed and provides concrete steps for the authors to enhance the quality and readability of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the comparison with Megatron, suggesting that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar sizes. It questions the claim of parameter efficiency for COCOLM and suggests that the conclusion could be applicable to other related works. Additionally, the comment poses two questions: one about the experimental setup regarding the switch from uncased to cased BPE vocabulary and another about the potential impact of this change on performance variance. While the comment raises valid points and questions, it does not provide explicit instructions or concrete actions for the authors to take. The questions are implicit and require the authors to infer the need for clarification or further explanation. Therefore, the comment is 3, as it provides guidance but lacks detailed instructions on how to address the issues.", "grounding_specificity_rationale": "The comment addresses the comparison with Megatron and questions the claim of parameter efficiency for COCOLM. It suggests that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar sizes. This provides specific feedback on the comparison and the claim of parameter efficiency. However, the comment does not explicitly mention which part of the paper discusses the comparison with Megatron, making it weakly grounded. The authors can infer that it relates to the experimental results or discussion sections, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison with Megatron is \"a little overrated\" and suggests that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar sizes. This claim is 3 as it provides a logical reasoning based on the similarity in model sizes and performance. However, the comment lacks specific examples or detailed comparisons to fully substantiate the claim, making it 3. The authors would need to consider this feedback and potentially provide more detailed comparisons to strengthen their argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the comparison with Megatron, suggesting that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar sizes. This critique questions the claim of parameter efficiency for COCOLM and suggests that the conclusion could be applicable to other related works. Additionally, the comment poses two questions: one about the experimental setup regarding the switch from uncased to cased BPE vocabulary and another about the potential impact of this change on performance variance. While the comment identifies a potential issue with the comparison and raises questions for further clarification, it lacks detailed guidance or suggestions on how the authors might address these concerns. The feedback is 3 as it points out areas for improvement but could be more comprehensive with specific recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the analysis from line 128 to 149, suggesting that it is not convincing enough. It provides a specific observation about the histogram in Fig 3, noting that the GSP50 model has a smaller class selectivity score, indicating it shares more features, while ResNet50 learns more classspecific features. The reviewer questions the reasoning behind the observation that this indicates GSP50 learns better representations. However, the comment does not provide explicit guidance or suggestions on how the authors should address this critique or improve their analysis. The action is implicit and vague, as the authors are left to infer what changes might be needed without clear direction. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific lines (128149) and references a figure (Fig 3), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the analysis, questioning the reasoning behind the observation that GSP50 learns better representations. The comment provides a clear critique of the analysis and suggests that the authors should explain why this observation supports the claim. Additionally, it references external works to support the critique, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point critiques the analysis from line 128 to 149, questioning the conclusion that GSP50 learns better representations based on the observation that it shares more features. The reviewer provides a logical reasoning by referencing the histogram in Fig 3 and the class selectivity score, which supports the claim. However, the comment could be strengthened by providing more detailed explanations or examples of how the additional context might allow the network to reduce its dependency. The inclusion of references to external works, such as SqueezeandExcitation Networks and Understanding the Effective Receptive Field in Deep Convolutional Neural Networks, adds some level of verifiability. Therefore, the comment is 4, as it provides a solid foundation for the claim but could benefit from more detailed justification.", "helpfulness_rationale": "The review comment critiques the analysis from line 128 to 149, questioning its convincingness. It provides a specific observation from the histogram in Fig 3, noting that the GSP50 model has a smaller class selectivity score, which suggests it shares more features, while ResNet50 learns more classspecific features. The reviewer challenges the authors\" hypothesis that additional context may allow the network to reduce its dependency, asking for a clearer explanation of why this observation supports the claim that GSP50 learns better representations. The comment references relevant literature, such as SqueezeandExcitation Networks and Understanding the Effective Receptive Field in Deep Convolutional Neural Networks, which could help the authors better understand the context and improve their analysis. However, the comment could be more helpful if it provided specific suggestions on how to address the critique or improve the analysis. Overall, the comment is 4 as it identifies a critical area for improvement and offers some guidance, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that some observations and subsequent design decisions might be hardware and software dependent. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this potential dependency or what specific aspects of the design might be affected. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some observations and subsequent design decisions might be hardware and software dependent. However, it does not specify which part of the paper this observation pertains to, nor does it provide details on what aspects are hardware or software dependent. This makes it difficult for the authors to identify the exact sections that need attention or clarification. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or references, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the paper, noting that some observations and design decisions might be hardware and software dependent. However, it does not provide any specific examples, context, or suggestions on how to address this dependency. Without detailed guidance or actionable feedback, the authors are left without a clear understanding of how to improve their draft. The comment highlights a potential area for consideration but lacks depth and specificity, making it 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the weak recovery problem studied is of theoretical interest and questions the practical utility of the AMP algorithm for nonGaussian problems. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the perceived limitation or improve the practical impact of the work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the weak recovery problem studied in the paper and questions the practical utility of the AMP algorithm for nonGaussian problems. However, it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in its critique of the theoretical interest and practical impact of the work, but it lacks detailed guidance on how to address these concerns. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the weak recovery problem studied is primarily of theoretical interest and questions the practical utility of the AMP algorithm for nonGaussian problems. However, the comment lacks specific evidence or references to support this claim. It does not provide detailed reasoning or examples to substantiate the assertion about the limited practical impact. Without additional context or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the practical impact of the AMP algorithm for nonGaussian problems, suggesting that the weak recovery problem studied is primarily of theoretical interest. While it identifies a potential limitation, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the practical utility of their work. Without actionable advice or detailed feedback, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a concern but does not provide sufficient direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This provides a clear and direct action for the authors to take, along with specific criteria for the experiments. The comment is 5 because it specifies exactly what needs to be done and how to implement the suggested action, leaving no ambiguity for the authors. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment suggests performing ablation experiments to compare the proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. However, it does not specify which part of the paper this suggestion should be implemented in, nor does it provide details on how to conduct these experiments or what specific aspects need to be addressed. The authors can infer that it relates to the experimental section, but the lack of explicit grounding and specificity makes it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests performing ablation experiments to compare the proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This claim is 3 as it provides a logical suggestion for improving the paper by comparing the proposed method with existing ones. However, the comment lacks specific examples or references to existing works that have conducted similar comparisons, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of ablation experiments to compare the proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This feedback is specific and offers a concrete way for the authors to enhance the comprehensiveness and rigor of their study. By suggesting a direct comparison with existing methods, the comment helps the authors to better evaluate the performance and efficiency of their proposed approach. However, the comment could be more helpful if it provided additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides several explicit actions for the authors to take. It suggests exploring other bit operations, which is a direct request for additional analysis. It also asks for more explanations regarding Fig. 5a, providing a clear action for the authors to enhance the clarity of their work. Additionally, it requests an explanation of how the input is handled when it is in the \"aer format\" and how DVS input is dealt with, which are specific areas needing clarification. Finally, it suggests analyzing energy consumption as a reference, providing a concrete suggestion for improvement. Each of these actions is explicit and concrete, giving the authors clear guidance on how to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"11,\" \"Fig. 5 a,\" and \"aer format,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear requests for additional explanations and analysis, such as exploring other bit operations, clarifying the appearance of Fig. 5a, and explaining how the input is handled in the \"aer format.\" Additionally, it suggests analyzing energy consumption as a reference, which provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple claims and suggestions. The first claim about \"11\" being wonderful is not supported by any evidence or reasoning, making it 1. The second claim about Fig. 5a being strange is also not substantiated. The suggestion to provide more explanations is a request for clarification rather than a claim. The final suggestion to analyze energy consumption as a reference is a request for additional analysis, not a claim. Therefore, the comment is primarily composed of requests for clarification and suggestions, fitting the label \"No\".", "helpfulness_rationale": "The review comment provides several specific and actionable suggestions for improving the paper. It starts by expressing admiration for a particular aspect (\"11 is wonderful\") and suggests exploring other bit operations, which could enhance the paper\"s scope and depth. The comment also raises a concern about Fig. 5a, requesting more explanations, which could help clarify the paper\"s content. Additionally, it asks for clarification on how the input is handled when it is in the \"aer format\" and how DVS input is dealt with, providing clear areas for improvement. Finally, it suggests analyzing energy consumption as a reference, which could strengthen the paper\"s solidity. Each of these points offers constructive feedback that could significantly enhance the paper, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to define the dashed lines in figures 2AB and 4B. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be clarified, leaving no ambiguity about the action required. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 2AB and 4B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the definition of the dashed lines in these figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking the authors to define the dashed lines in specific figures. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is clear and specific, requesting that the authors define the dashed lines in figures 2AB and 4B. This feedback is actionable and provides a direct way for the authors to improve their draft by clarifying an aspect that may be unclear to readers. However, the comment could be more helpful if it provided additional context or explained why defining these dashed lines is important. Nonetheless, it is 4 as it guides the authors toward a specific improvement. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a lack of clarity in Section 4.2 regarding the use of the question to learn an attention on the image feature. It points out that the description does not match the equation provided, specifically noting the absence of the term \"r^q\" and the unclear meaning of \"\u03c3.\" The reviewer suggests clarifying these points and raises a concern about the potential numerical instability of multiplying two sigmoid activations. This feedback provides explicit actions for the authors to take, such as clarifying the description and addressing the potential numerical instability issue. The guidance is clear and actionable, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the description and equation in this section, including the absence of the term \"r^q\" and the unclear meaning of \"\u03c3.\" The comment provides clear guidance on what needs to be clarified, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the description in Sec. 4.2 does not match the equation, specifically noting the absence of the term \"r^q\" and the unclear meaning of \"\u03c3.\" The reviewer suggests that the equation might be illconditioned and numerically unstable due to the multiplication of two sigmoid activations. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about the equation\"s instability. The reasoning is 3 as it provides a logical basis for the concern, but it could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the description in Section 4.2, where the use of the question to learn an attention on the image feature is not clearly explained. It points out that the description does not match the equation provided, specifically noting the absence of the term \"r^q\" and the unclear meaning of \"\u03c3.\" The reviewer also raises a concern about the potential numerical instability of multiplying two sigmoid activations. This feedback is clear and actionable, as it provides specific guidance on what needs to be clarified and addressed in the paper. By highlighting these issues, the comment helps the authors improve the clarity and accuracy of their work, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide a plot showing how different weights of the model change after unlearning, specifically focusing on which layers are affected the most. This feedback is clear and direct, providing a concrete action for the authors to take. The suggestion is specific and actionable, as it outlines exactly what needs to be done to enhance the clarity and understanding of the results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the method\" and \"each layer,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, providing a plot to show how different weights of the model change after unlearning and which layers are affected the most. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a plot to illustrate how different weights of the model change after unlearning, specifically focusing on which layers are affected the most. This suggestion is based on a logical reasoning that providing such a plot would enhance the understanding of the method\"s impact on different layers. However, the comment does not provide specific examples or references to support the claim that this information is crucial or missing. Therefore, the claim is 3, as it lacks detailed justification or evidence to fully substantiate the need for the suggested plot.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for enhancing the clarity and understanding of the paper. It recommends plotting the relative weight change after unlearning to see which layers are affected the most, which would help the authors better illustrate the impact of their method on different parts of the model. This feedback is clear and constructive, offering a concrete way for the authors to improve their draft. However, it could be more helpful if it included additional context or explanation about why this plot would be beneficial or how it would address specific concerns. Overall, the comment is 4 as it provides a valuable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the authors have reduced whitespace throughout the paper, which is a violation of the 9page paper limit. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve the formatting to meet the page limit. The comment lacks concrete details on what specific changes should be made to rectify the problem, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of reduced whitespace throughout the paper, including crammed equations and captions too close to figures. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the problem of violating the 9page paper limit due to the formatting issues. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have reduced whitespace throughout the paper, which is a violation of the 9page paper limit. However, the comment does not provide any evidence or reasoning to support this claim, such as specific examples of where the whitespace has been reduced or how it affects the page count. Without such details, the claim remains 1, as the authors may not be able to understand or address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting of the paper, noting that the authors have reduced whitespace, resulting in crammed equations and captions that are too close to the figures. This is a clear and actionable feedback that highlights a potential violation of the 9page paper limit. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending ways to improve the layout or suggesting alternative formatting options. Despite this, the comment effectively points out a critical area for improvement, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential risk in methods that exploit relationships between action units, noting that these relationships can vary significantly across different datasets. It suggests that crossdataset experiments could be a good way to test the generalization of such work, as the paper currently lacks. While the comment implies that the authors should conduct crossdataset experiments to address this issue, it does not provide specific guidance on how to implement these experiments or which datasets to use. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by highlighting the potential risk of methods exploiting relationships between action units and the need for crossdataset experiments to test generalization. The comment provides a clear example of how the relationships can differ across datasets, such as the cooccurrence of AU1 and AU12 in Figure 1. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that methods exploiting relationships between action units may not generalize well across datasets due to differences in cooccurrence patterns. It provides a specific example by mentioning AU6, which can occur in both pain and happiness expressions, and notes that this cooccurrence differs between datasets like SEMAINE and UNBC pain. The comment also references Figure 1, which illustrates the different cooccurrences of AU1 and AU12. This detailed explanation and reference to specific data points provide a solid basis for the claim, making it 4. However, the comment could be strengthened by including more examples or references to support the generalization issue. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant risk associated with methods that exploit relationships between action units, specifically highlighting the potential for these relationships to vary across different datasets. It provides a specific example by noting that AU6 can occur in both pain and happiness expressions, and that this cooccurrence differs between datasets like SEMAINE and UNBC pain. The comment suggests that crossdataset experiments could be a good way to test the generalization of such work, which is a valuable and actionable piece of feedback. However, the comment could be more helpful if it offered guidance on how to conduct these crossdataset experiments or which datasets to use. Overall, the comment is 4 as it points out a critical area for improvement and provides a direction for further research, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses difficulty in following the motivation of the paper and suggests that it appears to be an incremental engineering paper. However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity of their motivation or address the perceived incremental nature of the work. Without explicit or implicit actions, the authors are left without a clear understanding of what changes they should make to their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment expresses difficulty in following the motivation of the paper and suggests that it appears to be an incremental engineering paper. However, it does not specify which part of the paper is causing this difficulty or provide any details on what aspects of the motivation are unclear. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that it is \"very difficult to follow the motivation of this paper\" and suggests that it appears to be an incremental engineering paper. However, the comment lacks any supporting evidence, reasoning, or examples to justify why the motivation is difficult to follow or why the paper is considered incremental. Without such details, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment indicates that the motivation of the paper is difficult to follow and suggests that it appears to be an incremental engineering paper. However, it does not provide any specific guidance or suggestions on how the authors might clarify the motivation or address the perceived incremental nature of the work. Without actionable feedback or detailed insights, the authors are left without a clear understanding of what changes they should make to improve their draft. Therefore, the comment is 1, as it lacks actionable feedback and does not contribute to the authors\" understanding of how to enhance their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take, including adding more sentences to explain the experimental setting for continual learning and providing additional explanations for Fig. 3. It also asks specific questions about the learning curves and their relationship to MPHATE, which gives the authors clear guidance on what information to include. The comment is 5 as it provides concrete and direct instructions on how to improve the draft, leaving no ambiguity for the authors.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as explaining the correspondence between the learning curves and MPHATE, and asking questions about the learning curves and their relationship to structural collapse. The comment provides clear guidance on what additional information should be included, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of requests for clarification and additional information, such as explaining the experimental setting for continual learning and providing details about Fig. 3. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting additional explanations for the experimental setting in continual learning and for Fig. 3. It asks for clarification on the correspondence between the learning curves and MPHATE, which could help the authors improve the clarity and comprehensibility of their results. The comment also raises questions about the learning curves and structural collapse, prompting the authors to consider these aspects in their analysis. While the feedback is clear and actionable, it could be more helpful if it offered suggestions on how to address these issues or provided examples of what additional information could be included. Overall, the comment is 4 as it guides the authors toward improving the clarity and depth of their presentation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors include a plot with sparsity on the xaxis and performance on the yaxis to directly compare the flexibility of SGC with LoRA. This is an explicit action with concrete details on how to implement it, as it specifies the type of plot and the variables to be included. The authors know exactly what needs to be done to address the comment, making it 5.", "grounding_specificity_rationale": "The comment addresses the limited applicability of SGC and suggests a plot to compare its flexibility with LoRA. It provides a specific suggestion for visualization, which is to include a plot with sparsity on the xaxis and performance on the yaxis. This makes the comment fully grounded as it explicitly mentions the need for a specific type of plot, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, the inclusion of this plot to demonstrate the practical benefits of SGC\"s finegrained control. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that SGC offers a more flexible, finegrained tradeoff but notes that PEFT methods typically target computeconstrained scenarios where such granular control may require extra tuning, reducing practicality. The reviewer suggests including a plot to compare the flexibility of SGC with LoRA, which could more intuitively demonstrate whether SGC\"s finegrained control offers practical performance benefits at different sparsity levels. This claim is 3 as it provides a logical reasoning for the potential limitation of SGC in practical scenarios and suggests a method to visually demonstrate the difference. However, the comment lacks specific examples or references to support the claim fully, making it 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s claim about the flexibility of SGC, suggesting that it may not be practical in computeconstrained scenarios. It provides a specific and actionable suggestion to include a plot comparing the flexibility of SGC with LoRA, which could help demonstrate the practical benefits of SGC\"s finegrained control. This feedback is clear and constructive, offering a concrete way for the authors to enhance their draft by providing a visual comparison that could address the concern about practicality. Therefore, the comment is rated as 5, as it effectively guides the authors in improving their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of multiple questions and requests for clarification regarding the synthetic data, Figure 1, and the model used. It explicitly asks for examples of synthetic data, clarification on the terms \"support data\" and \"predicted training count data\" in Figure 1, and requests that the model used be explicitly written down, possibly in the appendix. These requests are clear and direct, providing the authors with specific actions to take to improve their draft. The feedback is concrete and actionable, as it guides the authors on what information to include and how to present it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"synthetic data,\" \"Figure 1,\" and specific terms like \"support data\" and \"predicted training count data,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it requests examples of synthetic data, clarification on the terms in Figure 1, and asks for the model used to be explicitly written down, possibly in the appendix. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of questions and requests for clarification regarding the synthetic data, Figure 1, and the model used. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek additional information, which is not a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas that need clarification and improvement. It requests examples of synthetic data, asks for clarification on the terms \"support data\" and \"predicted training count data\" in Figure 1, and suggests that the model used should be explicitly written down, possibly in the appendix. These requests provide clear and actionable feedback that can guide the authors in enhancing the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it offered additional suggestions or context on how these clarifications might impact the overall understanding or interpretation of the results. Nonetheless, the feedback is valuable and directs the authors toward specific improvements, making it 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the originality of the paper, specifically questioning how it contributes novel insights to the understanding of the winnertakeall property, given its simplified settings and the fact that most findings have been reported in previous works. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the novelty of their work. The feedback lacks actionable details, leaving the authors uncertain about what specific changes or additions would be necessary to enhance the originality of their paper. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of the paper\"s contribution to the understanding of the winnertakeall property, questioning the novelty of the findings given the simplified settings and the fact that most findings have been reported in previous works. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks novelty in its understanding of the winnertakeall property, particularly given its simplified settings and the fact that most findings have been reported in previous works. The reviewer supports this claim by referencing previous works that have used the winnertakeall property, such as NNbased clustering algorithms, and by mentioning that the findings in Section 5 have been reported before. This provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more specific references or examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises concerns about the originality of the paper, specifically questioning how it contributes novel insights to the understanding of the winnertakeall property, given its simplified settings and the fact that most findings have been reported in previous works. This feedback is 3 as it identifies a potential weakness in the paper\"s contribution, prompting the authors to consider how their work differs from existing literature. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or enhance the novelty of their work. To be more helpful, the comment could include recommendations for additional experiments, comparisons, or analyses that could strengthen the paper\"s originality. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly recommends that the authors provide a more detailed explanation of the EEG token quantization process, specifically regarding the role of the spatial arrangement of EEG sensors. This suggestion is clear and provides a concrete action for the authors to take, ensuring they understand exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of ambiguity in interpretation and suggests that the authors provide a more detailed explanation of the EEG token quantization process, particularly regarding the role of the spatial arrangement of EEG sensors. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 3 presents EEG topography plots that lead to ambiguity in interpretation, recommending a more detailed explanation of the EEG token quantization process. The comment is 3 as it identifies a potential issue with the interpretation of the figure but lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a clear suggestion for improvement, the authors might find it challenging to fully address the issue without additional context or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that the EEG topography plots for both the input and output during the EEG token quantization process lead to ambiguity in interpretation. It provides a clear and actionable suggestion for the authors to elucidate this procedure in greater detail, specifically asking whether the spatial arrangement of EEG sensors played a role in the process. This feedback is valuable as it directs the authors to clarify a critical aspect of their methodology, potentially enhancing the understanding and reproducibility of their work. However, the comment could be more helpful if it offered additional guidance on how to present this information or suggested specific details to include. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper lacks relevant literature on using moment matching instead of quantile regression in distributional reinforcement learning (DRL). It references a specific paper, \"Distributional Reinforcement Learning via Moment Matching\" by NguyenTang et al. (AAAI\u201921), and implies that this should be discussed in the context of various approaches to DRL. The comment explicitly suggests that the authors should include this discussion, even though the paper currently uses quantile regression. This feedback is explicit and provides a clear action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific paragraph from lines 2230, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of lacking relevant literature on using moment matching instead of quantile regression in distributional reinforcement learning (DRL), and it references a specific paper by NguyenTang et al. (AAAI\u201921) for further context. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks relevant literature on using moment matching instead of quantile regression in distributional reinforcement learning (DRL). It references a specific paper, \"Distributional Reinforcement Learning via Moment Matching\" by NguyenTang et al. (AAAI\u201921), which supports the claim. This provides a clear and specific reference that substantiates the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how moment matching could be applied or compared to quantile regression in the context of the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks relevant literature, namely the discussion of moment matching in distributional reinforcement learning (DRL) compared to quantile regression. It references a specific paper, \"Distributional Reinforcement Learning via Moment Matching\" by NguyenTang et al. (AAAI\u201921), which provides a relevant example of an alternative approach. The comment suggests that this should be discussed in the context of various approaches to DRL, even though the current paper uses quantile regression. This feedback is clear and actionable, as it directs the authors to include a discussion on moment matching, which could enhance the comprehensiveness and depth of their work. However, it could be more helpful if it provided specific guidance on how to integrate this discussion into the paper. Overall, the comment is 4, as it offers a valuable suggestion for improvement but could be more detailed in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that while the paper analyzes under which cases Algorithm 1 converges to permutations as local minima, it would be beneficial to also analyze the quality of these local minima, such as their approximation ratio under certain assumptions. This comment implies that the authors should expand their analysis to include the quality of the local minima, but it does not provide specific guidance on how to conduct this analysis or what assumptions should be considered. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take and the details of the analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the analysis of the quality of local minima, including the approximation ratio under certain assumptions. This provides clear guidance on what the authors should focus on to improve their work. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should analyze the quality of local minima, specifically the approximation ratio under certain assumptions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that while it analyzes under which cases Algorithm 1 converges to permutations as local minima, it would be beneficial to also analyze the quality of these local minima, such as their approximation ratio under certain assumptions. This feedback is clear and actionable, providing the authors with a specific direction to enhance their analysis and potentially improve the comprehensiveness of their results. However, the comment could be more helpful if it offered suggestions on how to approach this analysis or what specific assumptions should be considered. Overall, the comment is 4 as it guides the authors toward a meaningful expansion of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the lack of information on how to apply morphologic segmentation across different domains and whether it should be conducted differently for each domain. It questions whether morphologic segmentation is invariant across domains, which is crucial for task domain adaptation. While the comment highlights an important area for clarification, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to provide more detailed information on this aspect, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it identifies a gap in the paper but does not fully guide the authors on how to fill it.", "grounding_specificity_rationale": "The comment raises a concern about the lack of information on how to apply morphologic segmentation across different domains and whether it should be conducted differently for each domain. It questions the assumption of morphologic segmentation being invariant across domains, which is relevant to task domain adaptation. However, the comment does not specify which part of the paper this issue is addressed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in detailing what needs to be addressed, namely the need for more information on crossdomain morphologic segmentation and its potential variations. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of information on how to apply morphologic segmentation across different domains and whether it should be conducted differently for each domain. The reviewer questions the assumption of morphologic segmentation being invariant across domains, which is relevant to task domain adaptation. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the paper lacks insight into this aspect. The lack of supporting evidence or detailed justification makes the claim 3, as the authors would need to infer the importance of this issue and how it relates to their work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the application of morphologic segmentation across different domains. It questions whether morphologic segmentation should be conducted differently for various domains and highlights the importance of this consideration in the context of task domain adaptation. The comment points out that the paper assumes morphologic segmentation to be invariant across domains, which is a critical oversight. By raising this issue, the comment provides the authors with a clear direction for improvement, encouraging them to address the lack of insight into crossdomain morphologic segmentation. However, the comment could be more helpful if it offered specific suggestions or examples on how to address this gap. Overall, the feedback is 4 as it directs the authors to a critical area needing further exploration and clarification."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the analysis of experimental results, noting that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback implies that the authors should conduct a more thorough analysis of the experimental results to understand the reasons behind the observed performance. However, it does not explicitly instruct the authors to perform this analysis or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to conduct a deeper analysis but are not given specific steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the analysis of experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of analysis regarding the poor performance of the scope prompting method on GPT3.5turbo, suggesting that the authors should provide an analysis of the underlying reasons for this outcome. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of experimental results is insufficient, specifically noting that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This claim is 3 as it highlights a gap in the analysis, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the importance of this analysis and how it could be improved. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper, namely the insufficient analysis of experimental results. It points out that the authors mention the poor performance of the scope prompting method on GPT3.5turbo but do not provide any analysis of the underlying reasons for this outcome. This feedback is clear and actionable, as it directs the authors to conduct a more thorough analysis of the experimental results to understand the reasons behind the observed performance. However, the comment could be more helpful if it suggested specific methods or approaches for conducting this analysis. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the labels for each dataset in Section 4.1, specifically asking where these labels are coming from. The reviewer suggests that for generated datasets, the labels might be straightforward, but questions the process for datasets like caspealr1 and mugshot. While the comment does not explicitly instruct the authors to provide this information, it implies that the authors should clarify the origin of these labels. The action is implicit but concrete, as the authors know exactly what information is needed to address the question. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by asking for clarification on the labels for each dataset, particularly for caspealr1 and mugshot. The comment provides a clear direction for the authors to address, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the labels for each dataset in Section 4.1. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual question seeking information, making it a normal statement. Therefore, the correct label is \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the labels for each dataset in Section 4.1, asking where these labels are coming from. It highlights a potential area of confusion regarding the origin of labels for datasets like caspealr1 and mugshot, which are not generated. This feedback is clear and actionable, as it prompts the authors to clarify the labeling process for these datasets. By addressing this question, the authors can provide more transparency and clarity in their methodology, which is beneficial for the readers. However, the comment could be more helpful if it offered suggestions on how to present this information or why it is important. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and observations about the paper, including the sensitivity of performance and sample efficiency to the \u03bb parameter, the process of calculating \u03bb, and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. However, the comment does not provide explicit or implicit actions for the authors to take. It lacks guidance on how to address these issues or improve the clarity of the paper. The authors are left without a clear understanding of what changes or additions are needed to address the reviewer\"s concerns. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific pages and lines (Page 9, lines 310313, and Page 8, lines 281285), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the sensitivity of performance and sample efficiency to the \u03bb parameter, the process of calculating \u03bb, and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The inclusion of references to external works adds further specificity, providing context for the claims made. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several claims and questions about the paper, including the sensitivity of performance and sample efficiency to the \u03bb parameter, the process of calculating \u03bb, and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The reviewer provides references to external works, such as 1 Yuri Burda et al, Exploration by Random Network Distillation, ICLR 2019, 2 Deepak Pathak et al, Curiositydriven Exploration by Selfsupervised Prediction, ICML 2017, and 3 Roberta Raileanu et al, RIDE: Rewarding ImpactDriven Exploration for ProcedurallyGenerated Environments, ICLR 2020, which could help support the claims. However, the comment lacks detailed reasoning or examples to fully substantiate the claims, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several concerns and questions about the paper, including the sensitivity of performance and sample efficiency to the \u03bb parameter, the process of calculating \u03bb, and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The comment provides specific references to external works, which could help the authors better understand the context and potential improvements. However, the feedback lacks depth and does not offer actionable suggestions or guidance on how to address these issues. While it identifies areas for improvement, it does not provide detailed advice on how to enhance the clarity or effectiveness of the paper. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the novelty of the work is limited, specifically stating that interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the perceived lack of novelty or suggestions for enhancing the originality of the work. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the work, specifically mentioning the interpretation of deep neural networks using a linear model. However, it does not specify which part of the paper discusses this novelty or where the authors could improve it. The authors can make an educated guess that it relates to the methodology or results sections, but the comment lacks full grounding. It is specific in identifying the issue with the novelty, but without clear references to specific sections, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the work is limited, specifically stating that interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the work, specifically pointing out that interpreting the prediction of deep neural networks using a linear model is not a new approach. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might enhance the novelty of their work or address this critique. Without actionable feedback or specific recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a potential issue but does not offer any actionable insights for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive. However, it does not provide explicit guidance on how to achieve this or what specific changes should be made to the experiments. The authors are left to infer that they need to expand their experiments and consider larger models or more diverse baselines, but the comment lacks concrete details on how to implement these changes. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the experiments should be more comprehensive and general, specifically mentioning the limitations of model size and restrictive baselines in both the language modeling and image classification tasks. However, it does not specify which parts of the paper these experiments are described in, making it difficult for the authors to pinpoint the exact sections that need improvement. The comment is specific in its critique of the experiments but lacks grounding, as it does not provide a clear reference to the sections where these experiments are discussed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiments should be more comprehensive and general, specifically mentioning the limited model size and restrictive baselines in both the language modeling and image classification tasks. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains 3, as it provides a general direction for improvement but lacks concrete support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, specifically noting that the model size is limited and the baselines are restrictive. This feedback is 3 as it points out an area for improvement, suggesting that the experiments should be more comprehensive and general. However, the comment lacks specific guidance or suggestions on how to achieve this expansion or what additional baselines or models could be considered. While it provides some insight into potential areas for enhancement, it does not offer detailed actionable advice, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper lacks an ablation study to explain why the authors chose a specific prompt, such as using fewshot examples for CoT. This implies that the authors should conduct an ablation study to provide a clearer understanding of their choice. However, the comment does not specify how to conduct the ablation study or what specific aspects should be included. While the action is implicit, it is somewhat concrete in suggesting the need for an ablation study. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an ablation study to explain the choice of prompt, specifically mentioning the use of fewshot examples for CoT. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for an ablation study to explain the choice of prompt, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks an ablation study to explain the choice of prompt, specifically mentioning the use of fewshot examples for CoT. This claim is 3 as it provides a logical reasoning for the need of an ablation study to understand the choice of prompt. However, the comment lacks specific examples or references to support why fewshot examples might improve performance, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of an ablation study to explain the choice of prompt. It suggests that an ablation study could help clarify why the authors chose a particular approach, such as using fewshot examples for CoT. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\"s methodology and clarity. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment questions the strength of the demonstration of capability by stating that \"better than random\" is not a strong indicator. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to strengthen the demonstration of capability or what specific improvements could be made. As a result, the authors are left without a clear understanding of what changes are needed to address the concern. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific part of the paper, \"Evidently, replacing any of the procedure steps of XAIFOOLER with a random mechanism dropped its performance,\" allowing the authors to accurately identify the section being addressed. It is also specific because it questions the strength of the demonstration of capability by suggesting that \"better than random\" is not a strong indicator. This provides clear guidance on what aspect of the paper needs further elaboration or justification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the strength of the demonstration of capability by suggesting that \"better than random\" is not a strong indicator. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the strength of the demonstration of capability by suggesting that \"better than random\" is not a strong indicator. While it identifies a potential issue with the paper, it lacks depth and does not provide specific guidance or suggestions on how the authors might strengthen their demonstration of capability. Without actionable feedback or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a limitation in the results presented in Section 4, noting that they only apply to shallow fullyconnected ReLU networks. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or expand their results to other types of networks. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the limitation of the results, which is that they only apply to shallow fullyconnected ReLU networks. This provides clear guidance on what needs to be addressed or expanded upon in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results in Section 4 are limited to shallow fullyconnected ReLU networks. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a specific limitation in the results presented in Section 4, noting that they only apply to shallow fullyconnected ReLU networks. While this feedback identifies a particular area where the results may be limited, it does not provide any suggestions or guidance on how the authors might address this limitation or expand their results to other types of networks. The comment lacks actionable advice or constructive feedback, leaving the authors without a clear path for improvement. Therefore, it is rated as 2, as it identifies a weakness but does not offer any actionable insights."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the experiments are insufficient and recommends conducting more empirical experiments or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions the need to cite the result in Kaplan et al. 2020. This feedback provides clear and concrete actions for the authors to take, such as conducting additional experiments and referencing specific work. The explicit nature of the suggestions and the detailed guidance on what needs to be done make this comment 5.", "grounding_specificity_rationale": "The comment addresses the sufficiency of the experiments, suggesting the need for more empirical or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions the need to cite the result in Kaplan et al. 2020. However, the comment does not specify which experiments are insufficient or where these experiments should be conducted, making it weakly grounded. The authors can infer that it relates to the experimental sections, but the lack of specific references or detailed guidance makes it difficult to pinpoint the exact parts of the paper being addressed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiments are insufficient and suggests conducting more empirical or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. The comment also mentions the need to cite the result in Kaplan et al. 2020. While the suggestion for additional experiments is logical and provides a clear direction for improvement, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. The reference to Kaplan et al. 2020 provides some context but does not fully justify the need for more experiments. Therefore, the comment is 3, as it provides a logical basis but requires more detailed evidence or examples to fully support the claim.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the insufficiency of the experiments. It provides a clear and actionable suggestion by recommending the conduct of more empirical experiments or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. Additionally, it mentions the need to cite the result in Kaplan et al. 2020, which could serve as a reference for the authors. This feedback is 5 as it directs the authors to a specific area for improvement and offers a concrete step to enhance the validity and robustness of their work. However, it could be more helpful if it provided additional guidance on the types of experiments or analyses that would be most beneficial. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This provides a clear and direct action for the authors to take, which is to remove the absolute value operation. The comment is specific and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the absolute value operation in the definition of the Frobenius norm, providing a clear direction for the authors to address this point. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absolute value operation in the definition of the Frobenius norm is unnecessary because tensor entries are real numbers. This claim is supported by the fact that real numbers do not require absolute value operations to be defined, as they are already nonnegative. The comment provides a logical and straightforward reasoning that justifies the claim, making it 5. Therefore, the comment is labeled as 5.", "helpfulness_rationale": "The review comment identifies a minor issue with the definition of the Frobenius norm, specifically pointing out that the absolute value operation is unnecessary because tensor entries are real numbers. This feedback is clear and actionable, as it provides a specific suggestion for improvement that can be easily implemented by the authors. However, the comment could be more helpful if it explained why this change is important or how it might impact the overall analysis or results. Despite this, the comment is 4 as it directs the authors to a precise area for improvement, making it a valuable addition to the review process."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests conducting an experiment where the image is occluded, which would simulate irregularities in neural/behavioral data and allow for the inspection of the model\"s longrange inference capacity. The reviewer emphasizes that these experiments should be included in the final version, unless the authors can provide a convincing reason otherwise. The comment provides a clear and specific action for the authors to take, making it 5. The authors know exactly what experiments to conduct and why, giving them a clear direction for improvement.", "grounding_specificity_rationale": "The comment suggests conducting an experiment where the image is occluded, which is a specific suggestion for improving the paper. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental design or results section, but this inference is not as direct as it could be. The comment is specific in detailing what needs to be addressed, but it lacks full grounding. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests conducting an experiment where the image is occluded to simulate irregularities in neural/behavioral data and to assess the model\"s longrange inference capacity. The reviewer provides a logical reasoning for why this experiment would be beneficial, explaining that it would allow for the inspection of the model\"s ability to handle irregularities. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to infer the importance of this experiment based on the reviewer\"s explanation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper by proposing an experiment where the image is occluded. This experiment is designed to simulate the irregularities present in neural/behavioral data, such as keypoint detection failures, and would allow for the evaluation of the model\"s longrange inference capacity. The comment is clear and detailed, offering a concrete way for the authors to enhance their work. However, it could be more helpful if it included a rationale for why this experiment is crucial or how it would impact the overall understanding of the model. Despite this, the comment is 4 as it provides a direct and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests an action: using a second yaxis or another visualization that is more physically accurate for figure 6C. This provides a clear and direct instruction for the authors to follow. The comment also specifies the issue with the current figure, which is that it implies negative rates when this is not the case. This level of detail gives the authors a concrete understanding of what needs to be changed and how to implement the suggested improvement. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely that it implies negative rates when this is not the case, and suggests using a second yaxis or another visualization that is more physically accurate. This provides clear guidance on what needs to be addressed to improve the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that figure 6C implies negative rates, which is not the case. The reviewer suggests using a second yaxis or another visualization that is more physically accurate. However, the comment does not provide any supporting evidence or references to justify why the current visualization is misleading or inaccurate. Without additional context or examples, the claim remains somewhat vague and lacks sufficient justification, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with figure 6C, noting that it implies negative rates, which is not accurate. The reviewer provides a clear and actionable suggestion to address this issue by recommending the use of a second yaxis or another visualization that is more physically accurate. This feedback is specific and offers a concrete way for the authors to improve the clarity and accuracy of their figure, making it 4. However, the comment could be more helpful if it included additional context or examples of how to implement the suggested changes effectively. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the motivation of the work should be further justified, specifically in the context of fewshot learning. It highlights the need to explain how the proposed method effectively uses \"fewshot\" instances and guarantees generalizability to new tasks with limited training steps. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or specific steps to take. The action is implicit and somewhat vague, as the authors can infer that they need to provide more justification and details but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation of the work, specifically in the context of fewshot learning for graph link prediction. It highlights the need for further justification of how the proposed method effectively uses \"fewshot\" instances and guarantees generalizability to new tasks. However, the comment does not specify which part of the paper discusses the motivation or where the authors should provide this additional justification. While the authors can infer that it relates to the introduction or methodology sections, the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in detailing what needs to be addressed, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the motivation of the work should be further justified, particularly in the context of fewshot learning. It provides a logical reasoning by explaining that the paper defines a fewshot situation for graph link prediction but does not address how to effectively use \"fewshot\" instances or guarantee generalizability to new tasks. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim, which would make it 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical area for improvement in the paper, specifically the need for further justification of the motivation behind the work. It highlights the importance of explaining how the proposed method effectively uses \"fewshot\" instances and guarantees generalizability to new tasks with limited training steps. This feedback is clear and actionable, as it directs the authors to provide a more comprehensive explanation of their approach and its benefits. However, the comment could be more helpful if it offered specific suggestions or examples on how to enhance the justification or provide additional details. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the specificity of the proposed methodology, questioning whether it is tailored to bimanual manipulation or if robotic manipulation alone would be sufficient. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete details on what changes or clarifications are needed to resolve the ambiguity. As a result, the authors are left without a clear understanding of how to improve their draft in response to this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the specificity of the proposed methodology, questioning whether it is tailored to bimanual manipulation or if robotic manipulation alone would be sufficient. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in its critique, as it clearly identifies the issue of methodology specificity, but without grounding, the authors may struggle to determine where to address this feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the specificity of the proposed methodology, suggesting that it may not be tailored to bimanual manipulation and that robotic manipulation alone could be more appropriate. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment raises a concern about the specificity of the proposed methodology, questioning whether it is tailored to bimanual manipulation or if robotic manipulation alone would be sufficient. This feedback is 3 as it identifies a potential issue with the methodology\"s applicability, prompting the authors to consider whether their approach is indeed specific to bimanual manipulation. However, the comment lacks depth and does not provide specific suggestions or examples on how to address this concern or improve the methodology. To be more helpful, the comment could include additional guidance or references to similar works that might help the authors refine their approach. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the consistency of the advantage of the UNIFORM procedure over other methods, particularly in the 1shot setting. It questions whether the authors have a theory explaining why the method is less effective in this setting. While the comment identifies an area for further explanation or theory development, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a theoretical explanation for the observed inconsistency. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the tables\" and \"the 1shot setting,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the inconsistency in the advantage of the UNIFORM procedure over other methods, particularly in the 1shot setting, and asks for a theoretical explanation for this observation. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the advantage of UNIFORM over other procedures is not consistent, particularly in the 1shot setting. It supports this claim by referencing the tables, which show that UNIFORM does not always offer a clear advantage. The comment also raises a question about the theoretical basis for the method\"s ineffectiveness in the 1shot setting. While the comment provides some evidence and logical reasoning, it lacks specific examples or detailed references to substantiate the claim fully. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the advantage of the UNIFORM procedure over other methods is not consistent, particularly in the 1shot setting. It points out that the tables show UNIFORM does not always offer a clear advantage, prompting the authors to consider why this might be the case. The comment also acknowledges that the clarity and design of the experiments and results are well done. However, it lacks further guidance or suggestions on how the authors might address the inconsistency or improve their analysis. While it highlights an important area for consideration, the comment could be more helpful with additional actionable advice or specific recommendations for improvement. Therefore, it is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two distinct parts. The first part requests clarification on the empirical analysis in Figure 3, specifically asking for additional information on how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. The second part requests an explanation of why these adjustments are effective in enhancing the model\"s performance. The third part points out the large spacing between Equations (9) and (10) and the preceding text. While the comment identifies areas that need clarification and formatting improvement, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer the specific steps to take for each point. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also mentions \"Equations (9) and (10),\" providing further grounding. The comment is specific in its request for clarification on the empirical analysis, specifically asking for details on how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. It also requests an explanation of why these adjustments are effective. Additionally, it points out the formatting issue with the equations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple requests for clarification and additional information regarding the empirical analysis in Figure 3. It asks for details on how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy, and why these adjustments are effective. Additionally, it points out a formatting issue with Equations (9) and (10). While the comment identifies areas that need clarification, it does not provide specific evidence or references to support the claims or suggestions. The inclusion of a reference to a related work by Liu et al. does not directly address the issues raised in the comment. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks detailed justification or evidence to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies several areas that require clarification and improvement in the paper. It points out that the empirical analysis in Figure 3 is confusing and requests additional clarification on how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. It also asks for an explanation of why these adjustments are effective in enhancing the model\"s performance. Additionally, the comment highlights a formatting issue with Equations (9) and (10) having large spacing from the preceding text. The inclusion of a reference to a related work by Liu et al. provides some context but does not directly address the issues raised in the comment. While the comment identifies specific areas for improvement, it could be more helpful by providing detailed guidance on how to address these issues. Therefore, the comment is 3, as it provides some direction but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that Figure 1 could be improved by better illustrating the processing pipeline, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring. It also mentions the use of model training to optimize selection modules. While the comment implies that the authors should enhance the figure, it does not provide specific guidance on how to achieve this improvement. The action is implicit and somewhat vague, as the authors are left to infer the exact changes needed to enhance the figure. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the figure, suggesting that it should better illustrate the processing pipeline, including prompt generation, manual check, demonstration selection with ground truth scores, and automatic scoring, as well as the use of model training to optimize selection modules. This level of detail provides the authors with a clear understanding of what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 1 could be improved by better illustrating the processing pipeline. However, it does not provide any specific reasoning or examples to support why this improvement is necessary or how it would enhance the clarity of the figure. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment provides a specific suggestion for improving Figure 1 by recommending a better illustration of the processing pipeline. It identifies areas that could be enhanced, such as showing prompt generation, manual check, demonstration selection with ground truth scores, and automatic scoring, as well as the use of model training to optimize selection modules. This feedback is clear and actionable, offering the authors a concrete way to improve the visual representation of their work. However, the comment could be more helpful if it included additional guidance on how to effectively integrate these elements into the figure. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to avoid using abbreviations like \"MoCo\" in section headers, as they may be unfamiliar to readers. This feedback provides a clear and direct action for the authors to take, ensuring that section headers are more accessible and understandable. The comment is specific and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section number \"(136)\" and the specific issue with the use of the abbreviation \"MoCo\" in the section header. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with using abbreviations in section headers, providing a clear direction for improvement. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that abbreviations like \"MoCo\" should not appear in section headers because readers might not know what they mean. This is a logical claim supported by the reasoning that section headers should be clear and accessible to readers. However, the comment does not provide specific examples or references to substantiate the claim further, which could strengthen the argument. Therefore, the claim is 4, as it provides a clear rationale but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of abbreviations like \"MoCo\" in section headers, suggesting that they may be unfamiliar to readers. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending that such abbreviations be avoided in section headers. By addressing this issue, the authors can enhance the clarity and accessibility of their paper for readers. However, the comment could be more helpful if it provided additional context or examples of how to handle such abbreviations effectively. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how the authors might clarify their technical contribution or improve the analysis. The comment lacks explicit or implicit actions, leaving the authors without a clear understanding of what steps to take to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not specify which part of the paper is unclear or which analyses are considered standard. This makes it difficult for the authors to identify the exact areas that need clarification or improvement. The comment lacks grounding as it does not reference specific sections, figures, or tables, and it is also not specific about what aspects of the analysis are considered standard. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the technical contribution is unclear and that most of the analysis is standard. This feedback is important as it highlights a critical area that needs clarification and improvement. However, the comment lacks specificity and does not provide actionable suggestions on how the authors might enhance their technical contribution or make their analysis more original. Without detailed guidance, the authors may find it challenging to address the issue effectively. Therefore, the comment is 3, as it points out a key area for improvement but does not offer comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This could lead to an increase in the number of factors and computation with more tasks. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to implement a sparsity constraint. The action is implicit and somewhat vague, as the authors can infer that they need to consider adding a sparsity constraint but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the proposed method, namely the lack of a sparsity constraint in the number of factors used by subsequent tasks. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the model\"s design and its potential impact on computation, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method lacks a sparsity constraint in the number of factors used by subsequent tasks, which could lead to an increase in the number of factors and computation with more tasks. The comment provides a logical reasoning for this claim by explaining the potential impact of the lack of sparsity constraint. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to consider the implications of this lack of sparsity constraint and potentially include additional analysis or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, specifically noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This observation is relevant and could impact the model\"s efficiency and scalability. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or implement a sparsity constraint. While it highlights a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a weakness but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the application of regularization between the LN model and the GLM presented by pillow et al. It suggests that to make the comparison fair, the authors should try to reproduce the main features of the previous model. However, the comment does not provide explicit instructions on how to achieve this, such as which specific features to focus on or how to implement them. The action is implicit and somewhat vague, as the authors can infer that they need to align their approach with the previous model, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the application of regularization to both LN models and GLMs, allowing the authors to accurately identify the part of the paper being addressed. It also provides specific details about the GLM presented by pillow et al., suggesting that the authors should try to reproduce the main features of this model to make the comparison fair. This level of specificity helps the authors understand what needs to be addressed in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should try to reproduce the main features of the previous model presented by pillow et al. to make the comparison fair. The reviewer provides a specific example of how the previous model used L1 regularization for the filters and a low rank approximation to the spatial filter, suggesting that the current approach should align with these features. This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by including references to the specific work by pillow et al. or more detailed comparisons. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison between the LN model and the GLM presented by pillow et al. It points out that the authors apply regularization in the form of a cropped stimulus to both models, whereas the previous model used L1 regularization for the filters and a low rank approximation to the spatial filter. The reviewer suggests that to make the comparison fair, the authors should try to reproduce the main features of the previous model. This feedback is clear and actionable, as it highlights a specific area where the authors can improve their methodology to ensure a more accurate comparison. However, the comment could be more helpful if it provided additional guidance on how to implement these changes or what specific features of the previous model should be replicated. Overall, the comment is 4, as it directs the authors to a critical area for improvement but could be more comprehensive with further details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the introduction of epsilon in equation (11) might be clearer if it were introduced when discussing equation (11). This is an explicit suggestion for improvement, as it provides a specific action for the authors to take. The comment is also concrete, as it clearly instructs the authors on how to enhance the clarity of their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1\" and \"equation (10)\" and \"(11),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests introducing epsilon when discussing equation (11), providing clear guidance on how to improve the clarity of the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the introduction of epsilon in equation (11) might be clearer if it were introduced when discussing equation (11). This is a logical suggestion based on the structure of the equations, but it does not provide specific reasoning or examples to support why this change would improve clarity. The comment lacks detailed justification or references, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the paper by recommending that the introduction of epsilon in equation (11) be discussed when that equation is introduced. This feedback is clear and actionable, as it directs the authors to a particular section where they can enhance the presentation of their work. However, the comment could be more helpful if it explained why this change would improve the paper or provided additional context. Overall, the comment is 4 as it offers a concrete step for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point raises two specific issues regarding the proof of Theorem A.3. First, it questions how the input x has two indices, given that it is described as a vector. Second, it suggests a correction to the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d, proposing that it should be d instead. These explicit questions and suggestions provide clear and concrete actions for the authors to take, ensuring they understand exactly what needs to be addressed and how to make the necessary corrections. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem A.3 proof,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the proof, such as the input x having two indices and a potential error in the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises specific questions about the proof of Theorem A.3, questioning the indexing of the input \"x\" and suggesting a correction to the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d. These are factual observations and questions that do not contain subjective claims or opinions. They are purely descriptive and do not require verification or justification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies specific issues in the proof of Theorem A.3, questioning the indexing of the input \"x\" and suggesting a correction to the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d. This feedback is clear and actionable, providing the authors with precise guidance on how to improve the clarity and accuracy of their proof. By addressing these points, the authors can enhance the rigor and validity of their work. Therefore, the comment is rated as 5, as it offers detailed and constructive feedback that can significantly improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the effectiveness of the model, specifically regarding the use of beam search and the accuracy of the results. It questions the reliability of the model when relationships and entities are replaced and suggests that the authors should provide more information on the percentage of correct entities/relationships being plugged in. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors need to infer that they should address these concerns by providing additional data or analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions sections 4.3 and 4.4, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the concern about the use of words like \"somewhat\" and \"good generative ability\" in the description, and it questions the reliability of the model when relationships and entities are replaced. The comment further requests specific information on the percentage of correct entities/relationships being plugged in. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the effectiveness of the model, specifically regarding the use of beam search and the accuracy of the results. It questions the reliability of the model when relationships and entities are replaced and suggests that the authors should provide more information on the percentage of correct entities/relationships being plugged in. However, the comment lacks specific examples or references to support these claims, making it 3. The authors would need to infer the basis of the concern and address it themselves, which could be challenging without additional guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the effectiveness of the model, particularly in sections 4.3 and 4.4. It questions the reliability of the model when relationships and entities are replaced, highlighting the need for assurance that the pluggedin entities/relationships are correct. The comment also requests specific information on the percentage of correct entities/relationships being plugged in, which is a clear and actionable suggestion for improvement. However, the comment could be more helpful if it provided additional context or examples to further clarify the issue and guide the authors in addressing it. Overall, the feedback is 4 as it directs the authors to a critical area that requires further analysis and explanation."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should include supervised baselines in their experiments. It provides a clear rationale for why this is important, noting that the scale of the datasets (~100k images) suggests that full annotation is likely available, making supervised baselines a relevant comparison. The comment also highlights the informative value of including such baselines to demonstrate the performance of selfsupervised methods compared to fully supervised pretrained networks. This feedback is explicit and provides concrete guidance on what the authors should do to improve their draft, making it 5.", "grounding_specificity_rationale": "The comment suggests the inclusion of supervised baselines in the experiments, providing a rationale for why this is important. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the experimental setup, but the comment lacks full grounding. It is specific in suggesting the inclusion of supervised baselines, but without explicit references to sections or specific elements, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the absence of supervised baselines is a significant omission, particularly given the scale of the datasets used. The reviewer provides a logical reasoning by suggesting that full annotation is likely available for datasets of this scale, making supervised baselines a relevant comparison. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines in the experiments. It provides a clear rationale for why these baselines are important, especially given the scale of the datasets used, which likely have full annotation available. The comment suggests that including supervised baselines would be informative for comparing the performance of selfsupervised methods to fully supervised pretrained networks. This feedback is actionable and provides a clear direction for the authors to improve their draft by adding relevant baselines. However, it could be more helpful if it offered specific suggestions on how to implement these baselines or which datasets to use. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests a specific change to the terminology used in section 4, recommending that \"X\" should be a multiset instead of a set. This is an explicit action with clear guidance on how to implement the change, as it specifies the need to include multiplicities of labels in the graph to accurately represent it. The authors know exactly what needs to be done to address the comment, making this feedback 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the terminology used, suggesting that \"X\" should be a multiset instead of a set to accurately represent a graph with repeated vertex or edge labels. The comment provides a clear rationale for the change, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the use of a set in section 4 is inappropriate because it does not account for the multiplicities of labels in a graph. The reviewer provides a logical explanation for why a multiset would be more appropriate, as it can include repeated elements. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the draft. It identifies a potential issue with the terminology used in section 4, suggesting that \"X\" should be a multiset instead of a set to accurately represent a graph with repeated vertex or edge labels. This feedback is clear and provides a concrete way for the authors to enhance the clarity and accuracy of their work. By addressing this suggestion, the authors can improve the precision and effectiveness of their representation, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point starts by acknowledging the paper\"s organization and writing quality, but then it provides specific feedback on areas that could be improved. It suggests drawing a table to compare different CoT prompting methods across different dimensions, which is a concrete action. Additionally, it raises questions about the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and the selection criteria in section 4.2, prompting the authors to clarify these points. These questions are explicit and provide clear guidance on what the authors need to address. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the writing quality and the need for a table to compare different CoT prompting methods. It also raises specific questions about the assumption in section 4.2, such as the selection criteria and the reasoning behind it. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a positive statement about the paper\"s organization and writing quality, followed by specific feedback and questions. The positive statement is factual and does not require verification. The feedback and questions are also factual and do not contain subjective claims or opinions that need verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment starts by acknowledging the paper\"s organization and writing quality, which is a positive observation. However, it then provides specific feedback on areas for improvement, such as suggesting the inclusion of a table to compare different CoT prompting methods across various dimensions. This is a clear and actionable suggestion that could enhance the clarity and comprehensiveness of the paper. Additionally, the comment raises questions about the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and the selection criteria in section 4.2, prompting the authors to clarify these points. These questions are specific and provide a clear direction for the authors to address. Overall, the comment is 4 as it offers constructive feedback and guidance for improving the draft, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly highlights the lack of significance testing to support claims about the differences between certain methods. It provides a specific example from line 486, where the authors make a claim about the conversational ability of ChatGPT and GPT4 boosting translation quality and discourse awareness. The reviewer suggests that without proper testing, including checking the distribution and accounting for multiple comparisons, it is difficult to determine the significance of these claims. This feedback is explicit and provides a clear action for the authors to take, which is to conduct significance testing to support their claims. The comment is 5 as it gives a direct and concrete instruction on how to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 486,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of lacking significance testing to support claims about the differences between certain methods. The reviewer provides a concrete example from the paper, highlighting the need for proper testing, including checking the distribution and accounting for multiple comparisons. This level of detail helps the authors understand what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors make significant claims about the differences between certain methods without providing sufficient evidence or testing to support these claims. The reviewer specifically points out an example from line 486, where the authors discuss the conversational ability of ChatGPT and GPT4, and highlights the lack of significance testing to determine whether the observed differences are statistically significant. The comment provides a logical reasoning by suggesting that without proper testing, including checking the distribution and accounting for multiple comparisons, it is difficult to determine the significance of the claims. This reasoning is clear and provides a basis for the claim, making it 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of significance testing to support claims about the differences between certain methods. It provides a concrete example from line 486, where the authors make a claim about the conversational ability of ChatGPT and GPT4 boosting translation quality and discourse awareness. The reviewer points out that the differences between the methods are minimal and suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to determine significance. This feedback is 5 as it clearly identifies a critical gap in the paper and provides specific guidance on how to address it, empowering the authors to improve the rigor and validity of their claims. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the results should be averaged over multiple runs to determine statistical significance. This is a clear and direct action for the authors to take, providing them with a specific step to improve their draft. The comment is concrete in its guidance, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that results should be averaged over multiple runs to determine statistical significance. However, it does not specify which results or sections of the paper this suggestion pertains to, making it difficult for the authors to identify the exact parts that need revision. The comment is specific in its suggestion but lacks grounding, as it does not provide a clear reference to the specific results or sections being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that results should be averaged over multiple runs to determine statistical significance. This is a common practice in experimental design to ensure the reliability of results. However, the comment does not provide specific examples or references to support why this is necessary in the context of the paper. While the suggestion is logical, the lack of detailed justification or examples makes it 3. The authors would need to infer the importance of this suggestion based on general knowledge of statistical analysis. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the results should be averaged over multiple runs to determine statistical significance. This is a clear and actionable piece of feedback that can help the authors improve the robustness and reliability of their findings. By averaging results over multiple runs, the authors can better understand the variability and significance of their results, which is crucial for the validity of their conclusions. However, the comment could be more helpful if it provided additional context or examples of how this should be implemented or why it is important for the specific study. Despite this, the feedback is 4 as it offers a concrete step for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses an opinion that the contribution of the paper is limited and the proposed model is incremental in its approach. However, it does not provide any specific guidance or suggestions for the authors to address these concerns. There is no explicit or implicit action for the authors to take, such as revising the contribution section or explaining the novelty of the model. Without any actionable advice, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the contribution and incremental nature of the proposed model but does not specify which part of the paper this assessment is based on. It lacks grounding as it does not identify a specific section, figure, or aspect of the paper being addressed. Additionally, it is not specific about what aspects of the contribution or model are considered limited or incremental. Without clear references or detailed feedback, the authors cannot effectively address the concerns raised. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion about the limited contribution and incremental nature of the proposed model. However, it lacks specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses an opinion that the contribution of the paper appears limited and that the proposed model is incremental in its approach. However, it does not provide any specific details or examples to support this claim, nor does it offer suggestions for improvement. Without actionable feedback or guidance, the authors are left without a clear understanding of how to address the perceived limitations or enhance their work. As a result, the comment is 1, as it does not provide any value in terms of improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a discrepancy in the experimental part, specifically noting that the different methods in the two sets of benchmarks proposed in the article are quite different in different OPE methods. The reviewer requests that the authors provide comments on the differences between the two sets of evaluation methods. While the comment identifies an area for clarification, it does not explicitly instruct the authors to address this issue or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide an explanation but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4 and Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the differences between the two sets of benchmarks proposed in the article and requests comments on these differences. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper verifies different metrics for different OPE methods but notes a discrepancy in the evaluation methods used in Figure 4 and Figure 5. The comment requests clarification on the differences between the two sets of evaluation methods. However, it does not provide specific examples or detailed reasoning to support the claim, making it 3. The authors would need to infer the exact nature of the discrepancy and how it affects the evaluation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the experimental part of the paper, noting that the different methods in the two sets of benchmarks proposed in the article are quite different in different OPE methods. It requests that the authors provide comments on the differences between the two sets of evaluation methods. This feedback is clear and actionable, as it directs the authors to clarify a potential inconsistency or discrepancy in their experimental setup. By addressing this point, the authors can enhance the clarity and comprehensiveness of their experimental results. However, the comment could be more helpful if it provided specific suggestions on how to present or discuss these differences. Overall, the comment is 4, as it guides the authors toward improving the clarity and rigor of their experimental section."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the adhoc nature of the regularization term and suggests that it lacks theoretical support. It implies that the authors should consider alternative statistics, such as the median, which is less sensitive to outliers, to replace the mean and standard deviation in the regularization. While the comment provides a specific suggestion, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative statistics. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the regularization term, providing a specific critique about its adhoc nature and lack of theoretical support. It suggests considering alternative statistics, such as the median, which is less sensitive to outliers, to replace the mean and standard deviation in the regularization. This feedback is specific in suggesting a potential improvement and provides a clear direction for the authors to consider. However, it does not explicitly mention which part of the paper discusses the regularization term, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the regularization term is adhoc and lacks theoretical support, despite the author providing an intuitive explanation. The reviewer suggests using alternative statistics, such as the median, which is less sensitive to outliers, to replace the mean and standard deviation in the regularization. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim that the median is a better choice. The comment could be strengthened by providing more detailed reasoning or examples, making it 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s regularization term, noting that it seems adhoc and lacks theoretical support. It suggests considering alternative statistics, such as the median, which is less sensitive to outliers, as a replacement for the mean and standard deviation in the regularization. This feedback is clear and actionable, providing the authors with a specific direction for improving the theoretical foundation of their work. However, the comment could be more helpful if it included examples or further explanation of how the median could be used effectively. Overall, the comment is 4 as it offers a constructive suggestion for enhancing the theoretical robustness of the regularization term."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take in the experimental section. It suggests reporting the average over multiple runs to better compare the results, as the current results are very close together. Additionally, it recommends discussing the decision boundaries in the toy dataset, as this would be an interesting aspect to explore. Finally, it asks for clarification on the information presented in Fig. 9, specifically the middle and right parts. These suggestions are clear and concrete, providing the authors with specific steps to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Experimental section\" and references specific sections (Sec. 3.1 and Sec. 3.3) and a figure (Fig. 9), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear and actionable feedback, such as suggesting the reporting of average results over multiple runs, discussing the decision boundaries in the toy dataset, and seeking clarification on the information presented in Fig. 9. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple suggestions and requests for clarification regarding the experimental section and specific sections of the paper. It does not contain subjective opinions, judgments, or claims that require verification. It is purely descriptive and factual, making it a normal statement. Therefore, the correct label is \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback for improving the draft. It suggests reporting the average results over multiple runs to better compare the methods, which is a clear and concrete suggestion. Additionally, it recommends discussing the decision boundaries in the toy dataset, which could enhance the understanding of the results. The comment also requests clarification on the information presented in Fig. 9, which is a direct and helpful request for additional detail. These suggestions are detailed and provide the authors with clear guidance on how to enhance their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two main issues with the experimental evaluation section. First, it notes that the \"picking\" step is not ablated, which is a claim made in the paper but not supported by experimental evidence. Second, it criticizes the comparison on CIFAR, suggesting that the paper only compares to one approach (DEN) and does not use the same setup as in the DEN paper, which could make the comparison unfair or incorrect. The comment provides specific suggestions for improvement, such as abating the \"picking\" step and ensuring that the comparison to DEN is fair by using the same setup. These suggestions are explicit and concrete, providing the authors with clear actions to take to enhance the validity and fairness of their experimental evaluation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experimental Evaluation 2.1. Ablations\" and \"Experiments on CIFAR,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the ablation study, specifically the lack of ablation for the \"picking\" step, and the comparison on CIFAR, which is not convincing due to the limited comparison to only one approach (DEN). The comment further specifies that the comparison would be more convincing if the authors used the same setup as in the DEN paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s experimental evaluation is flawed in two areas: the lack of ablation for the \"picking\" step and the limited comparison on CIFAR. The reviewer provides specific details about the issues, such as the need for ablation studies and the lack of comparison to multiple approaches in the continual learning literature. However, the comment does not provide references or examples to fully substantiate the claims, leaving some gaps in the justification. Therefore, the claim is 4, as it provides a clear direction for improvement but lacks detailed evidence or references to fully support the critique. This aligns with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the experimental evaluation section of the paper. It points out two main issues: the lack of ablation for the \"picking\" step, which is claimed as a distinct aspect of the approach, and the limited comparison on CIFAR, where the paper only compares to one approach (DEN) without using the same setup as in the DEN paper. The comment suggests that using the same setup would make the comparison more convincing and fair. This feedback is clear and actionable, guiding the authors on how to strengthen their experimental evaluation by addressing these specific weaknesses. However, the comment could be more helpful if it provided additional suggestions or examples of how to conduct the ablation study or improve the comparison. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit and concrete actions for the authors to take. It suggests that the text in legends and axis labels should be larger, and it specifically mentions that \"Proposition (1)\" should be corrected to \"Proposition 1\" to avoid confusion with Equation 1. Additionally, it recommends increasing the font size of captions and legends in Figures 2 and 3 to match the text size. These instructions are clear and direct, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"at the beginning of page 6\" and \"Fig. 2 and 3,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issues, including the need for larger text in legends and axis labels, and the correction of \"Proposition (1)\" to \"Proposition 1\" to avoid confusion with Equation 1. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements and suggestions for improvement, such as recommending larger font sizes for text in legends and axis labels, and correcting the notation \"Proposition (1)\" to avoid confusion with Equation 1. These are descriptive and do not contain subjective opinions, judgments, or claims that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the formatting and clarity of the paper. It suggests that the text in legends and axis labels should be larger, which would improve readability. Additionally, it points out a potential source of confusion between \"Proposition (1)\" and Equation 1, recommending a correction to avoid this issue. The comment also advises increasing the font size of captions and legends in Figures 2 and 3 to match the text size. These suggestions are clear and concrete, offering the authors direct guidance on how to enhance the presentation and clarity of their work. However, the comment could be more helpful if it provided additional context or examples of how these changes would impact the overall readability or understanding of the paper. Overall, the feedback is 4 as it provides actionable steps for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests a specific comparison for the counterfactual experiments, recommending a comparison against Journey TRAK 1 at a particular step of the sampling trajectory. It also references a specific figure, 1, Figure 2, which shows a larger effect of removing highscoring images according to Journey TRAK compared to CLIP cosine similarity. This feedback provides a clear and explicit action for the authors to take, as it specifies the exact comparison they should make and references a specific figure for guidance. The authors know exactly what needs to be done to address this suggestion, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"counterfactual experiments\" and references a specific figure, 1, Figure 2, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular comparison against Journey TRAK and references a specific figure to support the suggestion. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a comparison between the counterfactual experiments and Journey TRAK, specifically referencing Figure 2 from 1. This provides a clear basis for the claim, as it references a specific figure and study that supports the suggestion. However, the comment could be strengthened by providing more detailed reasoning or examples of how this comparison would enhance the paper. Overall, the claim is 4, as it is supported by a reference to external work, but it could benefit from additional explanation or examples to fully substantiate the suggestion. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the counterfactual experiments by recommending a comparison against Journey TRAK at a particular step of the sampling trajectory. It references a specific figure from 1 that shows a larger effect of removing highscoring images according to Journey TRAK compared to CLIP cosine similarity. This feedback is clear and constructive, offering a concrete way for the authors to enhance their analysis and potentially improve the validity of their results. By suggesting a direct comparison with a specific method and referencing a relevant figure, the comment empowers the authors to make a meaningful addition to their work. Therefore, it is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the theoretical discussions could be improved, specifically mentioning that the current theorems follow directly from the algorithm design and a wellknown property of mutual information. It implies that the authors should consider adding sample complexitytype results, such as determining the sufficient amount of training data points that would not return NSF, given confidence levels. While the comment identifies an area for improvement, it does not provide explicit guidance on how to implement these suggestions or what specific results should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical discussions in the paper, suggesting improvements by mentioning the direct relationship between the theorems and the algorithm design, as well as the property of mutual information to \u0394_DP. It implies that the authors should consider adding sample complexitytype results, such as determining the sufficient amount of training data points that would not return NSF, given confidence levels. However, the comment does not specify which part of the theoretical discussions needs improvement or where these additional results should be included. While the authors can infer that it relates to the theoretical sections, the comment lacks full grounding as it does not explicitly mention specific sections or elements. It is specific in suggesting the type of results to be added, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the theoretical discussions could be improved by providing sample complexitytype results, such as determining the sufficient amount of training data points that would not return NSF, given confidence levels. The reviewer provides a logical reasoning by mentioning the direct relationship between the theorems and the algorithm design, as well as the property of mutual information to \u0394_DP. However, the comment lacks specific examples or references to support the claim that such results are necessary or would significantly enhance the paper. While the reasoning is clear, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the theoretical discussions of the paper. It suggests that the current theorems are directly related to the algorithm design and a wellknown property of mutual information, and implies that the authors could enhance the theoretical discussions by including sample complexitytype results. The comment provides a specific example of what could be added, such as determining the sufficient amount of training data points that would not return NSF, given confidence levels. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their theoretical discussions. However, it could be more helpful if it provided additional guidance on how to approach these improvements. Overall, the comment is 4, as it effectively guides the authors toward a specific area for enhancement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises doubts about the definitions in Table 1, specifically questioning the differences between anchorbased regression and the regression in RepPoints. The reviewer provides a detailed explanation of the methods, including RetinaNet and ATSS, and suggests that the regression methods do not significantly influence the results. The comment concludes by asking the authors to clarify this issue, implying that without clarification, the motivations in the paper may not be solid. While the comment identifies a specific area of concern and suggests a need for clarification, it does not provide explicit instructions on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definitions and their differences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the confusion regarding the definitions of anchorbased regression and the regression in RepPoints, and it provides a comparison with RetinaNet and ATSS. The comment specifies the need for clarification on the differences between these methods, which is a clear and actionable request. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the definitions in Table 1, specifically regarding the differences between anchorbased regression and the regression in RepPoints. The reviewer provides a detailed explanation of the methods, including RetinaNet and ATSS, and suggests that the regression methods do not significantly influence the results. This reasoning is based on common knowledge in the field and provides a logical explanation for the claim. However, the comment could be strengthened by including specific references or examples to support the claim. Overall, the claim is 4, as it provides a clear rationale but lacks detailed references or examples to fully substantiate the argument. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a specific concern about the definitions in Table 1, questioning the differences between anchorbased regression and the regression in RepPoints. The reviewer provides a detailed explanation of the methods, including RetinaNet and ATSS, and suggests that the regression methods may not significantly influence the results. This feedback is clear and actionable, as it prompts the authors to clarify the definitions and their differences, which could enhance the clarity and solidity of the paper\"s motivations. However, the comment could be more helpful if it offered suggestions on how to present this information or provided additional context. Overall, the comment is 4, as it identifies a critical area for improvement and provides a clear direction for the authors to address it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests clarifying whether the Fourier modes are real or complex numbers when discussing them as numbers. This is an explicit action that provides a clear direction for the authors to improve their draft. The comment is specific and concrete, as it directly instructs the authors to address a particular aspect of their explanation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests clarifying whether the Fourier modes are real or complex numbers when discussing them as numbers. However, it does not specify which part of the paper this clarification is needed in, such as a particular section or figure. The authors can infer that it relates to the discussion of Fourier modes, but without explicit references, it remains weakly grounded. The comment is specific in its request for clarification, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests clarifying whether the Fourier modes are real or complex numbers when discussing them as numbers. This is a logical suggestion to improve clarity in the paper, but it does not contain a claim that requires verification. It is a request for clarification rather than an opinion or judgment that needs justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests clarifying whether the Fourier modes are real or complex numbers when discussing them as numbers. This is a specific and actionable piece of feedback that can help the authors improve the clarity and precision of their explanation. By addressing this point, the authors can enhance the understanding of their work for readers. However, the comment could be more helpful if it provided additional context or examples of how this clarification might impact the overall understanding of the paper. Overall, the comment is 4 as it directs the authors to a clear area for improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to supplement the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be added, making it 5. The authors know exactly what to do to address the feedback, which is to include the comparison results in their paper.", "grounding_specificity_rationale": "The comment suggests supplementing the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure. However, it does not specify which part of the paper this comparison is currently lacking in, making it weakly grounded. The comment is specific in identifying the need for additional results, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure should be supplemented. However, the comment does not provide any reasoning, evidence, or examples to support why this comparison is necessary or how it would improve the paper. Without additional context or justification, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure should be supplemented. This feedback is clear and actionable, as it directs the authors to enhance their analysis by including additional results. However, the comment could be more helpful if it provided specific guidance on what aspects of the comparison should be included or how the results should be presented. Despite this, the comment offers a valuable direction for improving the draft, making it 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the caption for Figure 7 is incorrect and should be corrected to \"Edge Dynamics\" from \"Node Dynamics.\" This provides a clear and direct action for the authors to take, ensuring that the caption accurately reflects the content of the figure. The feedback is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the caption, indicating that it should be corrected to \"Edge Dynamics\" from \"Node Dynamics.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual statement about the incorrect caption for Figure 7 and suggests a correction. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and direct, identifying a specific error in the caption of Figure 7. It provides a precise suggestion for correction, indicating that the caption should be changed from \"Node Dynamics\" to \"Edge Dynamics.\" This feedback is actionable and straightforward, allowing the authors to make a simple correction that improves the accuracy and clarity of their work. However, the comment could be more helpful if it provided additional context or explained why this correction is important. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should discuss case studies and error studies to demonstrate the effectiveness of each proposed component. It provides an example of how this could be done by mentioning a specific case study related to graph pretraining for AMR parsing and generation. While the comment implies that the authors should include case studies, it does not explicitly instruct them to do so. The suggestion is concrete, as it provides a specific example of what could be included, but it is implicit in terms of the action itself. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests discussing case studies and error studies to demonstrate the effectiveness of each proposed component, specifically mentioning the Elementlevel Graph Pretraining. It provides an example of a case study related to graph pretraining for AMR parsing and generation. This feedback is specific as it identifies a particular aspect of the paper that could be improved and provides a concrete example of how to address it. However, it is not fully grounded because it does not explicitly mention the section where this discussion should be included, leaving the authors to infer the relevant part of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that discussing case studies and error studies would enhance the paper\"s effectiveness. It provides a specific example of a case study related to graph pretraining for AMR parsing and generation, which supports the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how these case studies would demonstrate the effectiveness of the proposed components. Overall, the claim is 4, as it offers a clear suggestion with some supporting evidence, but it lacks comprehensive justification. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that the paper could be strengthened by including case studies and error studies to demonstrate the effectiveness of each proposed component. It provides a specific example of how this could be done, referencing a case study related to graph pretraining for AMR parsing and generation. This feedback is actionable and offers a clear direction for the authors to enhance the credibility and persuasiveness of their work. However, the comment could be more helpful if it provided additional guidance on how to conduct these case studies or what specific aspects to focus on. Overall, the comment is 4 as it provides a valuable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This provides a clear and direct action for the authors to take, ensuring they understand exactly what needs to be addressed in their draft. The comment is specific and concrete, offering a straightforward path for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section\" of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it points out the lack of standard deviation after multiple experiments and suggests that the author clarify which effects are due to random fluctuations and which are improvements brought by the SoRA method. This provides clear guidance on what needs to be addressed in the experimental section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the standard deviation after multiple experiments is not provided, which may lead to confusion about the improvements brought by the SoRA method. The reviewer suggests that the author clarify which effects are within the range of standard deviation fluctuations and which are improvements due to the SoRA method. This claim is 3 as it highlights a potential issue with the presentation of experimental results but lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to consider this feedback to clarify their results, making the comment 4.", "helpfulness_rationale": "The review comment identifies a specific issue in the experimental section of the paper, namely the lack of standard deviation after multiple experiments. It points out that the improvement brought by SoRA compared to the baseline is limited and may be due to random fluctuations. The comment provides a clear and actionable suggestion for the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This feedback is valuable as it directs the authors to a critical area of their paper that requires clarification, potentially enhancing the clarity and robustness of their results. Therefore, the comment is 4, as it offers specific guidance for improvement but could be further enhanced by providing additional context or examples."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should evaluate the performance gain of their proposed method by comparing it to baseline detection or parsing techniques separately. This implies an action for the authors to take, which is to conduct additional evaluations to better support their claims. However, the comment does not provide specific guidance on how to conduct these evaluations or which baseline techniques to use. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed method, specifically mentioning its two major components: the generative shape model and the word parsing model. It highlights the need for clarity on which component contributes to the performance gain. The suggestion to evaluate the approach separately from baseline detection or parsing techniques provides specific guidance on how to address this issue. However, the comment does not explicitly mention which part of the paper discusses these components, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in its suggestion for improvement, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that it is unclear which component of the proposed method contributes to the performance gain. The reviewer suggests evaluating the approach separately from baseline detection or parsing techniques to better support the claim. However, the comment does not provide specific examples or references to support the claim that the current evaluation is insufficient. The suggestion for additional evaluation is logical, but without detailed reasoning or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s methodology, noting that it is unclear which component of the proposed method contributes to the performance gain. It suggests that evaluating the approach separately from baseline detection or parsing techniques would provide better support for the claim. This feedback is clear and actionable, as it directs the authors to conduct additional evaluations to clarify the contribution of their method. However, the comment could be more helpful if it provided specific examples of baseline techniques or detailed guidance on how to conduct these evaluations. Overall, the comment is 4 as it offers a clear path for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue. The comment lacks actionable details, such as recommending additional experiments, theoretical analysis, or clarification in the text. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. Without explicit references or context, the authors may find it challenging to identify the exact area needing clarification. The comment is specific in its concern but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point raises a concern about the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not provide any supporting evidence, reasoning, or references to justify why this assumption is critical or how it affects the method\"s behavior. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the method\"s behavior under different assumptions. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of a series of questions regarding the experimental setup and the design choices in Figure 1. It asks for the main rationales behind having a separate timbre encoder module and why SADTW takes outputs from the content encoder instead of the timbre encoder. While the questions imply that the authors should provide explanations or justifications for these design choices, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address these questions but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for the main rationales behind two specific design choices: (a) having a separate timbre encoder module and (b) why SADTW takes outputs from the content encoder instead of the timbre encoder. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions regarding the experimental setup and design choices in Figure 1. It does not contain any claims, opinions, or suggestions that require verification. The questions are factual and seek clarification, fitting the \"No\" label.", "helpfulness_rationale": "The review comment consists of a series of questions regarding the experimental setup and design choices in Figure 1. It asks for the main rationales behind having a separate timbre encoder module and why SADTW takes outputs from the content encoder instead of the timbre encoder. While these questions are relevant and could help the authors clarify their experimental design, they do not provide any suggestions or guidance on how to address these questions or improve the draft. The feedback is 3 as it identifies areas that need clarification, but it lacks actionable advice or depth, making it incomplete for comprehensive improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that Table 4 is incomplete and should include results for all four datasets. This provides a clear and direct action for the authors to take, ensuring that the table is comprehensive. The comment is specific and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by stating that the table is incomplete and should include results for all four datasets. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Table 4 is incomplete and should include results for all four datasets. However, it does not provide any reasoning or evidence to support why the inclusion of results for all four datasets is necessary or how it would enhance the paper. Without additional context or justification, the claim remains 1, as the authors may not understand the importance of including all datasets or how it would impact the paper\"s validity. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 4, noting that it is incomplete and should include results for all four datasets. This feedback is clear and actionable, providing the authors with a direct suggestion for improvement. By addressing this issue, the authors can enhance the comprehensiveness and accuracy of their results, which is a valuable contribution to the paper. However, the comment could be more helpful if it explained why including all datasets is important or how it would impact the paper\"s conclusions. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to the KL divergence due to its invariance to scale and shift. It suggests that the constraint strength of a loss function is defined via its gradient distribution and provides an example to support this claim. The reviewer explicitly states that it is necessary to provide a gradient comparison between KL and PCC, which is a clear and concrete action for the authors to take. This feedback is 5 as it specifies exactly what needs to be done to address the concern, providing a clear path for the authors to follow.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"matching metric\" and the \"Pearson correlation coefficient (PCC),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the assumption that PCC is a more relaxed constraint compared to KL divergence, providing a clear explanation and suggesting a specific action to address this concern by comparing the gradients of KL and PCC. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to KL divergence is not convincing. It provides a logical explanation by comparing the gradient distributions of KL divergence and MSE loss, suggesting that the constraint strength of a loss function is defined via its gradient distribution. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by including specific examples or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment addresses a specific assumption made in the paper regarding the Pearson correlation coefficient (PCC) and its comparison to KL divergence. It provides a logical explanation by discussing the gradient distribution of loss functions, such as KL divergence and MSE loss, to challenge the assumption that PCC is a more relaxed constraint. The comment suggests that the authors should provide a gradient comparison between KL and PCC to substantiate their claim. This feedback is clear and actionable, offering a specific direction for the authors to improve their draft by providing a detailed analysis of the gradient distributions. However, it could be more helpful if it included examples or references to further support the reasoning. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses skepticism about the use of a transformer free of locality bias, suggesting that the neighborhood agents should have more impact on each other due to the limited speed of information propagation. The reviewer requests that the authors provide more explanation on why the lack of locality in the transformer does not pose a concern. While the comment implies that the authors should address this concern, it does not explicitly instruct them to do so or provide specific guidance on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the use of a transformer free of locality bias, suggesting that the neighborhood agents should have more impact on each other due to the limited speed of information propagation. However, it does not specify which part of the paper this concern is related to, such as a particular section or figure discussing the transformer architecture. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment specifies the issue with the transformer\"s nolocality, it does not provide specific guidance on how the authors might address this concern. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point expresses skepticism about the use of a transformer free of locality bias, suggesting that the neighborhood agents should have more impact on each other due to the limited speed of information propagation. The reviewer requests that the authors provide more explanation on why the lack of locality in the transformer does not pose a concern. While the comment raises a valid point, it lacks specific examples or references to support the claim that the neighborhood agents should have more impact. This makes the claim 3, as it provides a logical reasoning but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the use of a transformer free of locality bias, suggesting that the neighborhood agents should have more impact on each other due to the limited speed of information propagation. The reviewer requests that the authors provide more explanation on why the lack of locality in the transformer does not pose a concern. This feedback is 3 as it identifies a potential issue with the approach and prompts the authors to address it. However, the comment could be more helpful if it provided specific suggestions or examples on how the authors might address this concern or if it offered a more detailed explanation of the potential impact of locality bias. Overall, the comment provides some direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern that the presented method, while using ODA as a method for solving the MOIP problem, does not clearly demonstrate how it improves performance and computation speed over just using ODA. However, it does not provide explicit guidance or suggestions on how the authors could address this issue. The comment implies that the authors should provide a clearer explanation of the improvements, but it lacks concrete details on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the use of ODA as a method for solving the MOIP problem and questions how the presented method improves performance and computation speed over just using ODA. However, it does not specify which part of the paper discusses ODA or the presented method, making it weakly grounded. The comment is specific in its critique, as it clearly identifies the issue of lacking clarity on improvements over ODA. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the presented method, ODA, has not clearly demonstrated how it improves performance and computation speed over just using ODA. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered 2, as it lacks sufficient justification to be 5.", "helpfulness_rationale": "The review comment raises a concern about the lack of clarity in the paper regarding how the presented method improves performance and computation speed over using ODA alone. It points out that the paper does not provide a clear explanation of the improvements, which is a valid critique. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or provide evidence of the improvements. While it identifies a weakness, it lacks actionable feedback, making it 3. The authors are left with a general understanding of what needs to be improved but without detailed guidance on how to do so. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with Figure 4, noting that the lines for \"No adapt\" and \"Finetune\" are covered by other lines and lacks additional explanation. This feedback is explicit, as it directly identifies the problem and suggests that the authors should provide further explanation for these lines. However, it does not specify how the authors should address this issue, such as by adding labels or annotations to clarify the figure. While the action is clear, the lack of detailed guidance on execution makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, noting that the lines for \"No adapt\" and \"Finetune\" are covered by other lines and lacks additional explanation. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some figures are not selfexplanatory, specifically mentioning Figure 4 as an example. It provides a clear and specific critique by pointing out that the lines for \"No adapt\" and \"Finetune\" are covered by other lines, which could make the figure difficult to understand without additional explanation. This feedback is wellsupported by a specific example, making it 4. However, the comment could be strengthened by suggesting ways to improve the figure\"s clarity, such as adding labels or annotations. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the figures in the paper, noting that some are not selfexplanatory. It provides a concrete example by mentioning Figure 4, where the lines for \"No adapt\" and \"Finetune\" are covered by other lines, making it difficult to understand without additional explanation. This feedback is actionable as it directs the authors to clarify their figures, which is crucial for the reader\"s comprehension. However, the comment could be more helpful if it suggested specific ways to improve the figure\"s clarity, such as adding labels or annotations. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for enhancement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a lack of discussion regarding the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It explicitly suggests that the authors should provide this analysis for a fair comparison with the baseline. This feedback is clear and direct, providing a specific action for the authors to take. The comment is explicit and concrete, as it specifies exactly what needs to be addressed and how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of discussion regarding the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing, namely an analysis of the impact of these factors for a fair comparison with the baseline. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. The reviewer suggests that this analysis is necessary for a fair comparison with the baseline. However, the comment does not provide specific examples or detailed reasoning to support the claim that this analysis is crucial or how it would impact the comparison. The lack of detailed justification makes the claim 3, as the authors would need to infer the importance of this analysis themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It suggests that the authors should provide this analysis for a fair comparison with the baseline. This feedback is clear and actionable, as it highlights a critical area for improvement and offers a specific direction for the authors to enhance their draft. By addressing this gap, the authors can provide a more comprehensive understanding of their approach and its implications, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the analysis of the correlation between dataset size and the Frobenius norm and singular values, noting that it is unclear if this trend holds across different model architectures and lacks theoretical evidence. However, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve their analysis. The comment implies that the authors should consider exploring this trend further and providing theoretical evidence, but it does not specify how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment critiques the analysis of the correlation between dataset size and the Frobenius norm and singular values, suggesting that it is underwhelming and lacks theoretical evidence. However, it does not specify which part of the paper this analysis is presented in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment provides some specificity by mentioning the lack of theoretical evidence, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming. It suggests that the trend may not hold across different model architectures and lacks theoretical evidence. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of concrete evidence or detailed justification makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the analysis of the correlation between dataset size and the Frobenius norm and singular values. It points out that the analysis is underwhelming and lacks clarity regarding whether this trend holds across different model architectures. Additionally, the comment notes the absence of theoretical evidence to support this correlation. While the comment highlights important issues that need attention, it does not provide specific suggestions or guidance on how the authors might address these concerns or improve their analysis. The feedback is 3 as it directs the authors to areas needing further exploration and justification, but it could be more helpful with additional actionable advice. Therefore, the comment is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the approximation error is defined as the gap between objective values, which is ambiguous without seeing the values in the table. It recommends providing a mathematical characterization to clarify this definition. While the comment implies that the authors should include a mathematical characterization, it does not explicitly instruct them to do so. The action is concrete in terms of what needs to be done, but it is implicit, as the authors need to infer the specific action from the feedback. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses the definition of approximation error, suggesting that it is ambiguous without seeing the values in the table. It recommends providing a mathematical characterization. However, the comment does not specify which part of the paper discusses the approximation error, making it weakly grounded. The authors can infer that it relates to a section or table where the error is discussed, but they cannot pinpoint the exact location. The comment is specific in suggesting a way to improve the clarity of the definition, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the definition of approximation error is ambiguous and suggests providing a mathematical characterization. However, the comment does not offer any specific examples, references, or detailed reasoning to support why the current definition is ambiguous or how a mathematical characterization would improve clarity. This lack of detailed justification makes the claim 3, as the authors would need to infer the basis of the critique and develop their own understanding of the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the definition of approximation error, noting that it is ambiguous without seeing the values in the table. It suggests that providing a mathematical characterization would improve clarity. This feedback is 3 as it points out a specific area for improvement and offers a constructive suggestion for enhancing the paper\"s clarity. However, the comment could be more helpful if it provided additional guidance on how to develop the mathematical characterization or examples of similar approaches in the literature. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the proposed model: first, it notes that the model produces only one node changing cluster per time step on average due to the reassignment probability being 1/n, leading to slow dynamics. Second, it points out that the evolution model is simplistic because it only changes edges with the (on average) 1 node changing cluster. However, the comment does not provide any explicit or implicit actions for the authors to take to address these issues. It lacks guidance on how to improve the model or suggest alternative approaches. As a result, the authors are left without a clear understanding of what changes are needed to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses specific aspects of the proposed model, such as the reassignment probability and the evolution model. However, it does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the model, such as the slow dynamics and the simplicity of the evolution model. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed model produces only 1 node changing cluster per time step on average due to the reassignment probability being 1/n, leading to slow dynamics. It also notes that the evolution model is simplistic because it only changes edges with the (on average) 1 node changing cluster. While the comment provides a logical explanation for the slow dynamics, it lacks specific examples or references to support the claim about the simplicity of the evolution model. This makes the claim 3, as it requires further evidence or detailed reasoning to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies two specific issues with the proposed model. First, it points out that the model\"s reassignment probability of 1/n results in only one node changing cluster per time step on average, leading to slow dynamics. Second, it notes that the evolution model is simplistic because it only changes edges with the (on average) 1 node changing cluster. While the comment highlights these weaknesses, it does not provide actionable suggestions or guidance on how the authors might address these issues or improve their model. The feedback is 3 as it directs the authors\" attention to areas needing improvement, but it lacks depth and specific advice, making it less comprehensive than it could be. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the technical contribution is limited, stating that there is no significant technical contribution or extension based on a typical model for the crossdomain recommendation setting. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might enhance their technical contribution or what specific aspects need improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the technical contribution of the paper, stating that it is limited and lacks significant extension based on a typical model for the crossdomain recommendation setting. However, it does not specify which part of the paper this critique is based on, such as a particular section or methodology. Without explicit references to specific sections or elements of the paper, the authors cannot confidently determine where to address the issue. Additionally, the comment lacks specificity regarding what aspects of the technical contribution are limited or how they could be improved. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution is limited, stating that there is no significant technical contribution or extension based on a typical model for the crossdomain recommendation setting. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, stating that the technical contribution is limited and lacks significant extension based on a typical model for the crossdomain recommendation setting. This feedback is important as it highlights a critical area where the authors need to enhance their work. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or what specific aspects of the technical contribution could be improved. Without actionable advice or examples, the authors are left with a general understanding of the issue but without a clear path forward for improvement. Therefore, the comment is 3, as it points out a significant weakness but lacks depth and specificity in its feedback."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the authors lack a comprehensive discussion of previous work on the topic. However, it does not provide specific guidance on what aspects of previous work should be included or how the discussion should be structured. The action is implicit, as the authors need to infer that they should add a comprehensive discussion of previous work, but it is vague because it does not specify what this discussion should entail. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors lack a comprehensive discussion of previous work on the topic. However, it does not specify which part of the paper this issue pertains to, such as the introduction, literature review, or discussion sections. Without explicit references to these sections, the authors may find it challenging to identify the exact area needing improvement. Additionally, the comment lacks specificity regarding what aspects of previous work are missing or how the discussion could be enhanced. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors do not provide a comprehensive discussion of previous work on the topic. However, it lacks specific examples or references to support this claim, making it difficult for the authors to understand the scope of the missing discussion or how it could be improved. Without detailed justification or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out a significant omission in the paper, noting that the authors have not provided a comprehensive discussion of previous work on the topic. This is a critical aspect of academic writing, as it helps establish the context and relevance of the current research. However, the comment lacks specificity and does not provide guidance on what specific aspects of previous work should be included or how the discussion could be structured. Without detailed suggestions or examples, the authors may find it challenging to address this feedback effectively. Therefore, the comment is 3, as it identifies an important area for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and suggestions for clarification regarding the OT sample selection process and its relationship with the EP module during training. It explicitly asks about the frequency of the OT sample selection process, whether it runs iteratively or only once, and whether the optimization of the loss and solving of OT are conducted by turns iteratively. The comment also suggests adding more details and a flow chart to make the process clearer for readers. Additionally, it requests information on the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. These explicit questions and suggestions provide clear guidance on what the authors need to address to improve their draft. The feedback is concrete and actionable, as it specifies exactly what information is needed and how it can be presented. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2.4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the OT sample selection process, such as the frequency of its execution and the relationship with the EP module, and suggests adding more details and a flow chart to clarify the process. Additionally, it requests information on the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several questions and requests for clarification regarding the OT sample selection process and its relationship with the EP module during training. It questions the frequency of the OT sample selection process and whether it runs iteratively or only once, and it asks about the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. These questions are factual and seek clarification, rather than making subjective claims or suggestions. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions and suggestions for clarification regarding the OT sample selection process and its relationship with the EP module during training. It questions the frequency of the OT sample selection process, whether it runs iteratively or only once, and whether the optimization of the loss and solving of OT are conducted by turns iteratively. The comment also suggests adding more details and a flow chart to make the process clearer for readers. Additionally, it requests information on the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. These questions and suggestions are clear and actionable, providing the authors with specific areas to address and improve their draft. However, the comment could be more helpful if it offered additional guidance on how to present the flow chart or suggested specific details to include. Overall, the feedback is 4 as it effectively guides the authors toward enhancing the clarity and comprehensiveness of their work."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying on automatic evaluation metrics, which can be misleading. However, it does not provide explicit guidance on how to conduct this human evaluation or what specific aspects should be evaluated. The action is implicit and lacks concrete details, leaving the authors uncertain about how to implement the suggested change. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that a human evaluation for caption generation would be more convincing than relying on automatic evaluation metrics, which can be misleading. However, it does not specify which part of the paper this suggestion pertains to, such as the section discussing caption generation or evaluation metrics. Without explicit references to specific sections or elements of the paper, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding what aspects of the human evaluation should be considered or how it would improve the paper. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying on automatic evaluation metrics, which can be misleading. This claim is 3 as it provides a logical reasoning for why human evaluation might be more convincing. However, the comment lacks specific examples or references to support the claim that automatic metrics are misleading, which would strengthen the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. This feedback is 3 as it highlights a potential weakness in the evaluation methodology and suggests an alternative approach. However, the comment lacks specificity and does not provide detailed guidance on how to conduct the human evaluation or what aspects should be considered. While it points out a potential area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of motivation for the problem being addressed, specifically the need for fast label aggregation algorithms in a streaming setting. It suggests that the paper should better motivate the applications where such algorithms are necessary. However, the comment does not provide explicit guidance on how to achieve this motivation or what specific aspects should be included to address the issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a motivation section but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of motivation for the problem being studied, specifically the need for fast label aggregation algorithms in a streaming setting. It points out that the paper does not spend time motivating the applications where such algorithms are needed and that all the datasets used in the empirical analysis are static. This provides a clear indication of the issue, but it does not specify which part of the paper should be revised to address this concern. The authors can infer that the introduction or motivation section might need revision, but the comment lacks full grounding as it does not explicitly mention these sections. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks motivation for the problem it addresses, specifically the need for fast label aggregation algorithms in a streaming setting. It points out that the datasets used in the empirical analysis are static, which contradicts the objective of the paper. However, the comment does not provide specific examples or references to support why the lack of motivation is a significant issue or how it affects the paper\"s contribution. The reasoning is somewhat logical but lacks detailed evidence or examples, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that it lacks motivation for the problem being addressed, specifically the need for fast label aggregation algorithms in a streaming setting. It points out that the datasets used in the empirical analysis are static, which contradicts the objective of the paper. This feedback is clear and actionable, as it highlights a critical area for improvement that could enhance the paper\"s relevance and impact. However, the comment could be more helpful if it provided specific suggestions on how to motivate the problem or what aspects of the paper should be revised to address this issue. Overall, the comment is 4, as it directs the authors to a key area that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two separate comments. The first part, \"The GAT is trained with the whole model?\" is a question that implies the need for clarification or confirmation regarding the training process of the GAT. However, it does not provide explicit guidance on how to address this issue. The second part, \"Needs to be reviewed by a English native speaker and some sentences need to be rewriting for improving the clarity,\" suggests that the text should be reviewed by a native English speaker and that some sentences need rewriting for clarity. While this provides a general direction, it lacks specific guidance on which sentences need rewriting or how to improve clarity. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed instructions on how to implement these changes.", "grounding_specificity_rationale": "The comment is weakly grounded as it does not specify which part of the paper discusses the GAT or where the need for a native English speaker\"s review is mentioned. However, it is specific in suggesting that the GAT is trained with the whole model and that some sentences need rewriting for clarity. This provides clear guidance on what needs to be addressed, even if the authors cannot pinpoint the exact sections. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two separate claims. The first claim, \"The GAT is trained with the whole model?\" is a question that seeks clarification and does not contain an opinion or judgment that requires verification. The second claim, \"Needs to be reviewed by a English native speaker and some sentences need to be rewriting for improving the clarity,\" is a suggestion for improvement but lacks specific examples or reasoning to support why a native speaker\"s review is necessary or which sentences need rewriting. This makes the comment barely verifiable, as it does not provide sufficient evidence or justification for the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies two separate issues. First, it questions whether the GAT is trained with the whole model, which could be a critical aspect of the methodology that needs clarification. Second, it suggests that the text should be reviewed by a native English speaker to improve clarity, indicating that some sentences may be unclear or poorly written. While the comment highlights important areas for improvement, it lacks specific guidance on how to address the first issue or which sentences need rewriting. The feedback is 3 as it points out potential weaknesses but does not provide detailed actionable advice for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests analyzing the domain gap and discussing the differences between datasets. It implies that the authors should consider the proximity of datasets to each other and how this affects the adaptation process. Additionally, it suggests that if the method can finetune a pretrained model on synthetic data, it would enhance the value of the approach. While the comment provides a clear direction for analysis and discussion, it does not specify how to conduct this analysis or what specific aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to analyze the domain gap but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests analyzing the domain gap and discussing the differences between datasets, which implies that the authors should consider the proximity of datasets to each other and how this affects the adaptation process. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. However, the comment does not specify which part of the paper should include this analysis or discussion, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint where to make these changes. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests analyzing the domain gap and discusses the potential value of the approach if it can finetune a pretrained model on synthetic data. However, the comment lacks specific examples or references to support the claim about the domain gap or the benefits of finetuning on synthetic data. Without detailed evidence or reasoning, the authors may find it challenging to understand and address the suggestion effectively. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient support for the claim.", "helpfulness_rationale": "The review comment suggests analyzing the domain gap and discussing the differences between datasets, which is a relevant and important aspect of the paper. It also highlights the potential value of the approach if it can finetune a pretrained model on synthetic data. This feedback is clear and actionable, as it directs the authors to consider the domain gap and its implications for their work. However, the comment could be more helpful if it provided specific examples or references to guide the authors in their analysis. Overall, the comment is 4, as it offers valuable insights and suggestions for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the scalability of the model, noting that performance worsens with an increase in the maximum number of identities. It suggests that the capacity should be preset to a small number, such as 10, and questions whether the authors have considered scaling up without compromising performance. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to do so. The suggestion to preset the capacity to a small number is concrete, but the question about scaling up without compromising performance is more vague. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed instructions on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 (a),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of scalability and performance degradation with an increase in the maximum number of identities. The comment suggests that the capacity should be preset to a small number and questions whether the authors have considered scaling up without compromising performance. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance worsens with the growth of the maximum number of identities, as shown in Table 3. It suggests that the capacity should be preset to a small number, such as 10, and questions whether the authors have considered scaling up without compromising performance. The claim is 3 as it provides a specific observation from the data (Table 3) and suggests a potential solution. However, it lacks detailed reasoning or references to support the claim fully, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a concern about the scalability of the model, specifically noting that performance worsens with an increase in the maximum number of identities. It suggests that the capacity should be preset to a small number, such as 10, and questions whether the authors have considered scaling up without compromising performance. This feedback is clear and actionable, as it identifies a potential issue with the model\"s scalability and provides a specific suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to address the scalability issue or provided examples of how other models handle similar challenges. Overall, the comment is 4, as it directs the authors to a critical area that needs attention and provides a concrete suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the quantitive evaluation results in Figure 3, which only reflect middle outputs rather than the final outputs. It suggests that this limits the ability to confirm ModelAngelo\"s superiority over competitors. The comment explicitly asks if it is possible to perform a quantitative comparison on the final outputs. This provides a clear and direct action for the authors to take, which is to conduct a quantitative comparison on the final outputs. The feedback is explicit and concrete, offering a specific step for the authors to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is that the quantitative evaluation results in Figure 3 only reflect middle outputs rather than the final outputs, and suggests that a quantitative comparison on the final outputs is needed to confirm ModelAngelo\"s superiority. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the quantitative evaluation results in Figure 3 only reflect middle outputs, rather than the final outputs, and that this limits the ability to confirm ModelAngelo\"s superiority over competitors. The comment suggests that a quantitative comparison on the final outputs would be more convincing. While the claim is logical and based on a reasonable critique of the evaluation methodology, it lacks specific examples or references to support the assertion that the current evaluations are not convincing. This makes the claim 3, as it provides a basis for the critique but requires further elaboration or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation results presented in the paper, noting that the quantitative evaluation results in Figure 3 only reflect middle outputs rather than the final outputs. It suggests that this limits the ability to confirm ModelAngelo\"s superiority over competitors. The comment also questions whether it is possible to perform a quantitative comparison on the final outputs, providing a clear and actionable suggestion for improvement. This feedback is valuable as it highlights a critical aspect of the evaluation methodology and offers a concrete step for the authors to enhance the credibility of their results. However, the comment could be more helpful if it provided additional context or examples of how such a comparison could be conducted. Overall, the comment is 4, as it effectively guides the authors toward improving the robustness of their evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights several areas where the paper lacks detail, making it difficult to reproduce the results. It specifically mentions the need for more information about the sparsification process, the extraction of landmark features, and the generation of landmarks on the edge. The comment also questions the number of landmarks used, the type of image features, and the fixed radius with different scales. Additionally, it asks about achieving shape invariance. While the comment identifies several areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to provide more detailed explanations and examples, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of detail about the techniques, specifically the sparsification process, extraction of landmark features, and generation of landmarks on the edge. It also raises questions about the number of landmarks used, the type of image features, and the fixed radius with different scales, as well as achieving shape invariance. This provides clear guidance on what aspects of the paper need more detail and explanation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks detail about the techniques, making it difficult to reproduce the results. It highlights specific areas such as the sparsification process, extraction of landmark features, and generation of landmarks on the edge. The comment raises several questions about the methodology, including the number of landmarks used, the type of image features, and the fixed radius with different scales. While the comment identifies several areas of concern, it does not provide specific examples or references to support the claim. The lack of detailed evidence or examples makes it 3, as the authors would need to infer the necessary steps to address these concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of detail about the techniques used, which makes it difficult to reproduce the results. It raises several specific questions about the sparsification process, the extraction of landmark features, and the generation of landmarks on the edge. Additionally, it questions the number of landmarks used, the type of image features, and the fixed radius with different scales, as well as the achievement of shape invariance. This feedback is clear and actionable, providing the authors with a comprehensive list of areas that need further explanation and detail. By addressing these points, the authors can significantly improve the clarity and reproducibility of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that Figure 1 would be strengthened by the inclusion of error bars and/or more random trials to reduce random fluctuations in the results. While the comment implies that these additions would improve the figure, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should add error bars and more random trials. However, the suggestion is concrete in terms of what needs to be done, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the figure would be stronger with the inclusion of error bars and/or more random trials to reduce random fluctuations in the results. This provides clear guidance on what could be improved in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 1 would be strengthened by the inclusion of error bars and/or more random trials to reduce random fluctuations in the results. This claim is 3 as it provides a logical reasoning for why error bars and more trials would improve the figure. However, the comment lacks specific examples or references to support the claim that these additions would effectively reduce random fluctuations. Providing such examples or references would strengthen the justification, making the comment more verifiable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving Figure 1 by recommending the inclusion of error bars and/or more random trials to reduce random fluctuations in the results. This feedback is clear and actionable, as it offers a concrete way for the authors to enhance the figure and potentially improve the clarity and robustness of their findings. However, the comment could be more helpful if it explained why these additions are important or how they would impact the interpretation of the results. Despite this, the suggestion is valuable and provides a clear direction for improvement, making the comment 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests two explicit actions: providing a brief introduction to energy models in the related work section and clarifying which points in Figure 1 correspond to different learning rates and steps. The first action is clear and concrete, as it specifies what needs to be added to the related work section. The second action is also explicit and concrete, as it instructs the authors to clarify the points in Figure 1. Both actions are direct and provide specific guidance on how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related work section\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for a brief introduction to energy models in the related work section and clarifies the points in Figure 1 that correspond to different learning rates and steps. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two separate suggestions and a reference to external works. The first suggestion to include a brief introduction to energy models in the related work section is a logical request for context, but it lacks specific examples or references to support why this is necessary. The second suggestion to clarify Figure 1 is factual and does not contain a claim. The references to external works 1, 2, and 3 are provided but do not directly support the suggestions. Therefore, the comment is 3, as it provides some justification but lacks detailed evidence or examples to fully substantiate the claims.", "helpfulness_rationale": "The review comment provides two distinct suggestions for improvement. First, it recommends including a brief introduction to energy models in the related work section, which could help contextualize the paper\"s contributions. Second, it points out a lack of clarity in Figure 1, specifically regarding which points correspond to different learning rates and steps. This feedback is clear and actionable, as it identifies specific areas where the authors can enhance the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it provided additional context or examples to support the suggestions. Overall, the comment is 4, as it offers valuable guidance for improving the paper, but it could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the utilitybased approach to determining chunk significance in FIITED, suggesting that it might introduce biases. It provides a specific example of how recent chunks gaining a temporary high utility could lead to premature evictions of other valuable chunks. However, the comment does not explicitly instruct the authors to address this issue or suggest ways to mitigate the bias. While the authors can infer that they need to consider this potential bias, the feedback lacks concrete guidance on how to implement changes. Therefore, the comment is 3, as it identifies a concern but does not provide detailed instructions on how to address it.", "grounding_specificity_rationale": "The comment addresses the utilitybased approach to determining chunk significance in FIITED, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper discusses this approach, making it weakly grounded. The comment is specific in detailing the potential issue of biases introduced by basing eviction decisions solely on utility scores and provides an example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the utilitybased approach to determining chunk significance in FIITED, suggesting that it might introduce biases. The reviewer provides a specific example of how recent chunks gaining a temporary high utility could lead to premature evictions of other valuable chunks. This example offers a logical reasoning for the claim, making it 3. However, the comment could be strengthened by providing more detailed analysis or references to similar issues in other works. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the utilitybased approach to determining chunk significance in FIITED, suggesting that it might introduce biases. It provides a specific example of how recent chunks gaining a temporary high utility could lead to premature evictions of other valuable chunks. This feedback is clear and highlights a critical area for improvement, allowing the authors to consider alternative approaches or mitigations to address the potential bias. However, the comment could be more helpful if it offered suggestions or examples of how to address this issue. Overall, the comment is 4 as it provides a clear direction for improvement but lacks detailed guidance, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity regarding the performance of different parts of the framework and their contributions to the final result. It suggests that the authors should include quantitative experiments and comparisons between different algorithms to provide a clearer understanding of the framework\"s performance. The comment also implies the need for more detailed explanations of the presented results. While the action is implicit, it is concrete in suggesting specific improvements, such as conducting quantitative experiments and comparisons. The authors can infer that they need to enhance the experimental section to address the reviewer\"s concerns. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental aspect\" and the \"result section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the lack of quantitative experiments, comparisons between algorithms, and detailed explanations of the presented results. The comment provides a clear direction for improvement by suggesting the inclusion of these elements to enhance the clarity of the framework\"s performance and contributions. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance of different parts of the framework and their contributions to the final result are unclear from the experimental aspect. It suggests that the lack of quantitative experiments and comparisons between algorithms, as well as a detailed explanation of the presented results, contributes to this uncertainty. The comment provides a logical reasoning by highlighting the absence of specific details that would clarify the framework\"s performance and contributions. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the exact areas that require improvement based on the general feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the clarity of the framework\"s performance and contributions. It points out that while the results section shows promising visual stimuli, it lacks quantitative experiments and comparisons between different algorithms. The comment also highlights the need for more detailed explanations of the presented results. This feedback is clear and actionable, as it provides specific areas for improvement that the authors can address to enhance the comprehensiveness and clarity of their work. By suggesting the inclusion of quantitative experiments and detailed explanations, the comment offers valuable guidance for the authors to strengthen their draft. Therefore, it is rated as 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests improving the clarity of Figure 2 by recommending the use of styles, such as dashed lines, or adding color to distinguish between the different curves. This feedback is explicit and provides a clear action for the authors to take, making it 5. The suggestion is concrete, as it specifies specific visual elements that could enhance the figure\"s readability. Therefore, the comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improving the figure\"s clarity by recommending the use of styles (e.g., dashed lines) or adding color to distinguish between the different curves. This feedback is actionable and provides a concrete way for the authors to enhance their figure. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it is difficult to distinguish between the different curves in Figure 2 and recommends using styles (e.g., dashed lines) or adding color to improve clarity. This is a subjective opinion based on the reviewer\"s experience and does not require specific evidence or references to support the claim. The suggestion is logical and provides a clear path for improvement, but it lacks detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a reasonable suggestion but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that it is difficult to distinguish between the different curves. It provides a clear and actionable suggestion to improve the figure\"s clarity by recommending the use of styles, such as dashed lines, or adding color. This feedback is valuable as it offers a concrete way for the authors to enhance the visual presentation of their data, making it easier for readers to understand the results. However, the comment could be more helpful if it included additional guidance on how to implement these suggestions or provided examples of effective visualizations. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with further details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should \"tonedown the intro\" and not refer to the task as \"language learning,\" as it is more accurately described as \"feedback driven QA in the form of a dialog.\" This feedback provides a clear and direct action for the authors to take, ensuring they understand exactly what needs to be changed in their draft. The recommendation is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly addresses the introduction of the paper, allowing the authors to accurately identify the part being discussed. It is also specific because it clearly specifies the issue with the claims made in the introduction, pointing out the discrepancy between the task described and the evaluation method used. The comment suggests a change in the introduction by recommending a more accurate description of the task, which further enhances its specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claims made in the introduction are not supported by the tasks and models evaluated. It suggests that the task is more accurately described as \"feedback driven QA in the form of a dialog\" rather than \"language learning.\" However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to review their introduction and evaluation methods to understand the basis of the critique, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between the claims made in the introduction and the actual evaluation methods used in the paper. It points out that the task is described as \"language learning\" but is evaluated through question answering, which is more accurately described as \"feedback driven QA in the form of a dialog.\" This feedback is clear and actionable, as it suggests a specific change to the introduction to better align the description with the actual evaluation. However, the comment could be more helpful if it provided additional context or examples to support the claim and guide the authors in making the necessary adjustments. Overall, the comment is 4, as it directs the authors to a significant improvement in the clarity and accuracy of their introduction."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that a fullpage explanation of the implementation of kernels with OpenAI\"s Triton instead of CUDA is unnecessary due to wellknown engineering improvements. This provides a clear and direct action for the authors to take, which is to omit the detailed explanation. The comment is explicit and concrete, as it specifies exactly what action the authors should take to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the implementation of kernels using OpenAI\"s Triton instead of CUDA, suggesting that a fullpage explanation is unnecessary due to wellknown engineering improvements. However, it does not specify which part of the paper this implementation is discussed in, making it weakly grounded. The comment is specific in its suggestion to omit the detailed explanation, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact area needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that a fullpage explanation of the implementation of kernels with OpenAI\"s Triton instead of CUDA is unnecessary due to wellknown engineering improvements. However, the comment does not provide any specific examples, references, or detailed reasoning to support why these improvements are wellknown or why a fullpage explanation is unnecessary. This lack of supporting evidence makes the claim difficult for the authors to verify or address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the implementation of kernels using OpenAI\"s Triton instead of CUDA does not require a fullpage explanation, as the engineering improvements are wellknown. This feedback is 3 as it highlights an area where the authors might be overexplaining a point that is already understood in the field. However, the comment lacks depth and does not provide specific guidance on how to condense the explanation or suggest alternative ways to present the information. While it identifies a potential area for improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the zeroshot nature of the experiment and suggests that the transferability of the policy might be limited due to the difficulty of the source and target tasks. It provides specific examples, such as the difference between \"walkerrun\" and \"walkerwalk,\" and the manipulation scenario with 3prong and 4prong tasks. The reviewer implies that the paper should clarify these points to avoid misleading the reader. While the comment identifies areas that need clarification, it does not explicitly instruct the authors to make these clarifications. The action is implicit and somewhat vague, as the authors need to infer that they should address these points in the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the zeroshot nature of the experiment and suggests that the transferability of the policy might be limited due to the difficulty of the source and target tasks. It provides specific examples, such as the difference between \"walkerrun\" and \"walkerwalk,\" and the manipulation scenario with 3prong and 4prong tasks. However, the comment does not explicitly mention which part of the paper these examples are based on, making it weakly grounded. The comment is specific in detailing what needs to be clarified regarding the transferability and the difficulty of tasks. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the zeroshot nature of the experiment and suggests that the transferability of the policy might be limited due to the difficulty of the source and target tasks. The reviewer provides specific examples, such as the difference between \"walkerrun\" and \"walkerwalk,\" and the manipulation scenario with 3prong and 4prong tasks, to support their claim. However, the comment lacks detailed reasoning or references to substantiate the claim fully. While the examples are relevant, the lack of comprehensive justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the zeroshot nature of the experiment and the transferability of the policy. It provides specific examples, such as the difference between \"walkerrun\" and \"walkerwalk,\" and the manipulation scenario with 3prong and 4prong tasks, to support the claim that the transferability might be limited due to the difficulty of the source and target tasks. The reviewer suggests that the paper should clarify these points to avoid misleading the reader. This feedback is clear and actionable, as it identifies specific areas that need clarification and provides examples to guide the authors in improving their draft. However, it could be more helpful if it offered suggestions on how to present this information in the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of sufficient experimental demonstration of the contribution points, specifically noting the absence of a comparison between the author\"s method (ELF) and the baseline without Mid Vision Feedback (MVF), as well as the lack of comparison with the image classification result of Mid Vision Feedback (MVF). The comment implies that the authors should conduct additional experiments to demonstrate the superiority of their method over the baseline and Mid Vision Feedback. However, it does not provide explicit instructions on how to conduct these experiments or what specific comparisons should be made. While the action is implicit, it is somewhat concrete in suggesting the need for additional experimental comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of experimental demonstration of the contribution points, specifically referencing the absence of a comparison between the author\"s method (ELF) and the baseline without Mid Vision Feedback (MVF), as well as the lack of comparison with the image classification result of Mid Vision Feedback (MVF). This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the experimental section, namely, a comparison with the image classification result of Mid Vision Feedback (MVF). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks sufficient experimental demonstration of its contribution points, specifically noting the absence of a comparison between the author\"s method (ELF) and the baseline without Mid Vision Feedback (MVF), as well as the lack of comparison with the image classification result of Mid Vision Feedback (MVF). The reviewer provides a logical reasoning by explaining that without these comparisons, it is not possible to prove that the schema searched by ELF is better than the schema in Mid Vision Feedback (MVF). This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by including specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental demonstration of the paper\"s contribution points. It points out that the paper lacks a comparison between the author\"s method (ELF) and the baseline without Mid Vision Feedback (MVF), as well as a comparison with the image classification result of Mid Vision Feedback (MVF). This feedback is clear and actionable, as it highlights a critical area for improvement that could strengthen the paper\"s claims and demonstrate the effectiveness of the proposed method. However, the comment could be more helpful if it provided specific suggestions on how to conduct these comparisons or what additional experiments could be included. Overall, the comment is 4 as it directs the authors to a key area for enhancing the experimental section of their paper."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper regarding the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should expand on this topic, but it lacks concrete details on what specific aspects to cover or how to present them. As a result, the authors are left with a vague understanding of what needs to be done, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a gap in the paper regarding the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it difficult for the authors to identify the exact area needing attention. The comment is specific in detailing what is missing, but it lacks grounding as it does not direct the authors to a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This feedback is 3 as it points out an area where the authors could provide more depth and analysis. However, the comment lacks specific suggestions or guidance on how the authors might address this gap, such as recommending additional data or analysis to include. While it highlights an important area for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests using different notation to avoid confusion between the dimensionality of points and the dilation factor, both represented by \"D\". This is an explicit action that provides a clear direction for the authors to improve their draft by changing the notation. The comment is specific and concrete, as it directly instructs the authors on how to address the issue of confusion. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using different notation to avoid confusion between the dimensionality of points and the dilation factor, both represented by \"D\". However, it does not specify which part of the paper this notation is used in, making it weakly grounded. The comment is specific in suggesting a change to avoid confusion, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location for revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the use of \"D\" to represent both dimensionality of points and dilation factor may cause confusion. This is a logical observation, as using the same notation for different concepts can lead to misunderstandings. However, the comment does not provide specific examples or detailed reasoning to fully substantiate the claim. While the suggestion is reasonable, it lacks sufficient evidence or explanation to make it 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper, specifically the use of the notation \"D\" to represent both dimensionality of points and dilation factor. It suggests using different notation to avoid this confusion, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided additional context or examples of how this confusion might impact the reader\"s understanding of the paper. Despite this, the suggestion is straightforward and provides a specific direction for improvement, making the comment 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed FRM is a simple combination of channel attention and spatial attention, suggesting that the innovative aspects should be detailed. However, it does not provide explicit guidance on what specific details should be included or how the authors should present the innovative aspects. The action is implicit and somewhat vague, as the authors can infer that they need to elaborate on the innovative parts but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed FRM, which is a specific part of the paper. However, it does not specify which part of the paper discusses the FRM, making it weakly grounded. The comment suggests that the innovative aspects should be given in detail, which provides some level of specificity regarding what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed FRM is a simple combination of channel attention and spatial attention, suggesting that the innovative aspects should be detailed. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim is not 5. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out that the proposed FRM is a simple combination of channel attention and spatial attention, suggesting that the innovative aspects should be detailed. While this feedback identifies a potential area for improvement by highlighting the need for more detailed explanation of the innovative aspects, it lacks specific guidance or suggestions on how the authors might enhance their explanation. The comment provides some insight into what the authors could focus on, but it does not offer actionable steps or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors could mention the potential social impacts of their work, specifically the risks associated with increased automation and the dual use of their method. While the comment implies that the authors should address this aspect, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to discuss potential social impacts but are not given specific instructions on how to incorporate this into their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 379,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors could mention the social impact of increased automation or the risks from the dual use of their method. This provides clear guidance on what the authors could add to their draft to address the reviewer\"s concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" assertion that their work has no negative social impacts. The reviewer expresses skepticism about the potential for significant negative social impact and suggests that the authors should consider the social implications of increased automation and the dual use of their method. However, the comment lacks specific examples or references to support the claim that these aspects are relevant or significant. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment addresses the societal impact of the work, specifically questioning the authors\" assertion that their work has no negative social impacts. It suggests that the authors could discuss the potential risks associated with increased automation and the dual use of their method. While the comment identifies a relevant area for consideration, it lacks specific guidance or examples on how the authors might address these concerns. The feedback is 3 as it prompts the authors to consider broader implications, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the applicability of the methods to realworld problems due to strong assumptions about the availability of camera parameters and object segmentation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to modify the assumptions, improve the applicability, or provide evidence to support the claims. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the applicability of the methods to realworld problems, specifically mentioning the limitations due to strong assumptions about the availability of camera parameters and object segmentation. However, it does not specify which part of the paper discusses these assumptions or how they impact the applicability. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in identifying the issue with the assumptions but lacks detailed guidance on how to address it. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the applicability of the methods to realworld problems is limited due to strong assumptions about the availability of camera parameters and object segmentation. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the applicability of the methods to realworld problems due to strong assumptions about the availability of camera parameters and object segmentation. This is a relevant observation that could help the authors improve their work by considering how to relax these assumptions or provide evidence for their applicability. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing alternative methods or experiments that could demonstrate the methods\" applicability in more realistic scenarios. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the theoretical effect of rounding core tensors on the full tensor error and asks if there is an error bound in terms of epsilon. While the comment identifies a potential area for clarification, it does not provide explicit instructions or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and provide a theoretical analysis or error bound related to epsilon. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the issue is discussed, specifically the mention of rounding core tensors and the effect on the full tensor error. It also specifies the issue by questioning the theoretical effect of this rounding and asking for an error bound in terms of epsilon. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the theoretical effect of rounding core tensors on the full tensor error and asks if there is an error bound in terms of epsilon. The comment does not make a claim or provide an opinion but rather seeks clarification on a specific aspect of the paper. It is a factual question that requires no justification or evidence, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the theoretical effect of rounding core tensors on the full tensor error and asks if there is an error bound in terms of epsilon. While it identifies a potential area for clarification, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. The comment highlights a gap in the theoretical analysis but lacks actionable feedback, making it 3. The authors are informed of a potential area for improvement but are not given detailed instructions on how to address it. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not specify what additional information or examples should be included to achieve this. The action is implicit and vague, as the authors are left to infer what specific steps to take without clear guidance on how to implement the suggestion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its suggestion to provide more convincing evidence, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not provide any specific examples, reasoning, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, suggesting that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. This is a valid point, as the feasibility of such a query is crucial for the paper\"s credibility. However, the comment lacks specificity and does not offer detailed guidance on how to address this issue or what specific evidence or examples would be most effective. While it highlights an area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the form of \"p\" should be described near line 135, as it is currently not explicitly stated. This provides a clear and direct action for the authors to take, ensuring that the form of \"p\" is clarified in the draft. The comment is specific and concrete, offering a precise instruction on how to improve the clarity of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the description of the form of \"p.\" The comment provides a clear and actionable suggestion for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the form of \"p\" should be described near line 135, as it is currently not explicitly stated. The reviewer assumes it is a Gaussian distribution but notes that it is not explicitly stated. This comment is a request for clarification and does not contain a subjective claim or opinion that requires verification. It is purely factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of the paper. It points out that the form of \"p\" is not explicitly described near line 135, which could lead to confusion. By suggesting that the form of \"p\" should be described, the comment offers a clear direction for the authors to enhance the readability and understanding of their work. However, the comment could be more helpful if it provided additional context or examples of how the form of \"p\" should be described. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the interpretation of the results, specifically regarding the sublinearity of regret. It does not provide any explicit or implicit actions for the authors to take, nor does it suggest any changes or improvements to the draft. The comment is purely a query seeking clarification, leaving the authors without any actionable steps to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 3237, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the interpretation of the results regarding the sublinearity of regret, prompting the authors to clarify their discussion. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the interpretation of the results regarding sublinearity of regret. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the interpretation of the results regarding sublinearity of regret, specifically asking if the prediction error over the entire horizon T cannot be sublinear. While it identifies a potential confusion in the paper, it does not provide any suggestions or guidance on how to address this issue or clarify the discussion. The comment is 3 as it points out a potential misunderstanding, but it lacks actionable feedback or detailed guidance for the authors to improve their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point consists of two parts. The first part suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work, which would help determine if the benefits are due to a better generative model or better inference. This is an explicit suggestion with a clear action for the authors to take. The second part suggests keeping the generative model fixed and optimizing only the inference part of the model, parameterizing it as either SIGVAE or VGAE to compare representations. This is also an explicit suggestion with concrete details on how to implement it. Both parts of the comment are 5 as they provide direct and specific guidance on how to improve the draft. Therefore, the comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific suggestions for improving the figure, such as keeping the generative model fixed and optimizing only the inference part of the model. This level of detail helps the authors understand what needs to be addressed in the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work. This claim is 3 as it provides a logical reasoning for why this approach might be beneficial, but it lacks specific examples or references to support the claim. The suggestion to keep the generative model fixed and optimize only the inference part is also logical but not fully substantiated with detailed reasoning or evidence. Therefore, the comment is rated as 3, as it provides some justification but lacks comprehensive support.", "helpfulness_rationale": "The review comment provides two distinct points of feedback. The first part suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work, which would help determine if the benefits are due to a better generative model or better inference. This is a clear and actionable suggestion that could significantly enhance the understanding of the paper\"s results. The second part suggests keeping the generative model fixed and optimizing only the inference part of the model, parameterizing it as either SIGVAE or VGAE to compare representations. This suggestion is also specific and actionable, offering a concrete way to improve the analysis of the paper. Both points are wellreasoned and provide valuable guidance for the authors to improve their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the necessity of learning longrange dependencies for powerful predictors, particularly in the context of semantic segmentation. The reviewer acknowledges that the paper demonstrates this importance but suggests that the discussion could be more nuanced. The comment implies that the authors should consider the role of locality in the graph structure and its impact on prediction, especially in relation to image size. However, it does not provide explicit guidance on how to address this issue or what specific aspects of the discussion should be expanded. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the balance between longrange dependencies and locality in the graph structure. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the need for a discussion about the balance between learning longrange dependencies and the importance of locality in the graph structure, particularly in relation to image size. The comment provides a clear direction for the authors to consider and address this aspect, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the necessity of learning longrange dependencies for powerful predictors, particularly in the context of semantic segmentation. The reviewer acknowledges that the paper demonstrates this importance but suggests that the discussion could be more nuanced. The comment implies that the authors should consider the role of locality in the graph structure and its impact on prediction, especially in relation to image size. However, the claim lacks specific examples or references to support the assertion that the truth lies somewhere in between, making it 3. The authors would need to provide additional evidence or reasoning to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s discussion on learning longrange dependencies for powerful predictors. It acknowledges that the paper demonstrates the importance of this aspect in semantic segmentation, as seen in the visualizations in Table 3. However, the reviewer expresses uncertainty about whether this is fully required and suggests that the truth might lie somewhere in between. The comment also raises a concern about the impact of locality in the graph structure on prediction, particularly in relation to image size. While the comment highlights an area for further discussion, it lacks specific suggestions or guidance on how the authors might address this issue or what aspects of the discussion should be expanded. As a result, the feedback is 3, as it points out a potential area for improvement but does not provide detailed actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the definition of $e_l$ in Eq. (3) and points out that Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also mentions that the performance is getting worse than standard random features, as shown in Figure 1, which may indicate a weakness in the proposed approaches. While the comment identifies areas that need clarification or further investigation, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the definition of $e_l$ and investigate the implications of the exponential dependence on $M$, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. (3),\" \"Corollaries 1, 2, and 3,\" and \"Theorem 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the exponential dependence on the diameter $M$ of the domain of data and its impact on the required feature size. Additionally, it references Figure 1 to support the claim that the performance is getting worse than standard random features. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several claims, including the need for clarification of $e_l$ in Eq. (3) and the observation that Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also suggests that this dependence affects the constant factor of the required feature size and references Figure 1 to support the claim that the performance is worse than standard random features. While the comment provides some logical reasoning and references a figure, it lacks detailed explanations or specific examples to fully substantiate the claims. Therefore, the comment is 3, as it provides a basis for the claims but requires more detailed evidence or examples to be fully convincing.", "helpfulness_rationale": "The review comment raises several points that are relevant to the authors\" work. It questions the definition of $e_l$ in Eq. (3), which is a clear and specific request for clarification. Additionally, it points out the exponential dependence on the diameter $M$ of the domain of data in Corollaries 1, 2, and 3, and Theorem 4, which could be a significant issue affecting the required feature size. The comment also references Figure 1, which shows that the performance is getting worse than standard random features, suggesting a potential weakness in the proposed approaches. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered alternative approaches to mitigate the exponential dependence. Overall, the feedback is 3 as it identifies areas for clarification and potential weaknesses, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the longrange modeling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that oversmoothing could be another contributing factor, referencing a specific paper for further context. However, the comment does not provide explicit guidance or suggestions for the authors to address these issues in their draft. While it points out areas for consideration, it lacks actionable steps or concrete recommendations for improvement. As a result, the authors are left with a general understanding of the potential issues but without clear direction on how to address them. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the longrange modeling ability of DGNs, specifically mentioning oversquashing and vanishing/exploding gradients as potential issues. It also suggests that oversmoothing could be another factor, referencing a specific paper for further context. However, the comment does not specify which part of the paper discusses DGNs or their modeling abilities, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in identifying potential issues with DGNs, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the poor longrange modeling ability of DGNs could be due to oversquashing and vanishing/exploding gradients, and also mentions oversmoothing as another potential factor. The claim is supported by a reference to a specific paper, \"Deeper Insights into Graph Convolutional Networks for SemiSupervised Learning, In AAAI\"18,\" which provides a basis for the suggestion. However, the comment could be strengthened by providing more detailed reasoning or examples of how oversmoothing affects DGNs. Overall, the claim is 4 due to the reference, but it lacks comprehensive evidence, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the longrange modeling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that oversmoothing could be another contributing factor, referencing a specific paper for further context. This feedback is 3 as it points out a specific area for improvement and provides a reference for the authors to explore. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided more detailed guidance on incorporating the referenced paper into the discussion. Overall, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that while the proposed method is grounded in neuroscience, some of its general ideas are already present in other methods, such as those using generalized Voronoi graphs or semantic maps for exploration. The reviewer suggests that the paper should discuss the proposed method in relation to these existing methods. This feedback is explicit in its request for the authors to discuss their work in the context of existing literature, providing a clear action for the authors to take. However, it does not specify which specific aspects of the existing methods should be discussed or how the authors should integrate this discussion into their paper. While the action is clear, the lack of detailed guidance on execution makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"grounding of the proposed method in neuroscience\" and references specific methods, such as \"generalized Voronoi graph or semantic maps to guide the exploration\" and \"pose graphs in SLAM, where loop closure is applied,\" which are discussed in the \"graphbased slam appendix section.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed: a discussion of the proposed method in relation to these existing methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some general ideas in the proposed method are already present in other methods, such as those using generalized Voronoi graphs or semantic maps for exploration. The reviewer provides specific examples, like \"generalized Voronoi graph or semantic maps to guide the exploration\" and \"pose graphs in SLAM, where loop closure is applied,\" which supports the claim. However, the comment could be strengthened by providing more detailed comparisons or references to these existing methods. Overall, the claim is 4, as it provides a clear direction for the authors to consider but lacks comprehensive evidence or detailed examples. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the originality of the proposed method, noting that some of its general ideas are already present in other methods, such as those using generalized Voronoi graphs or semantic maps for exploration. The reviewer suggests that the paper should discuss the proposed method in relation to these existing methods, which could help clarify its contributions and novelty. This feedback is 3 as it points out a gap in the paper\"s discussion and provides a direction for improvement. However, it lacks specific guidance on how to integrate this discussion or which aspects of the existing methods should be compared. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the importance of specific components within the framework for using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary for distinguishing the paper from related work but does not provide a clear answer or guidance on how to address this issue. The comment implies that the authors should clarify this aspect, but it lacks explicit instructions or concrete steps on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the importance of specific components within the framework for using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary for distinguishing the paper from related work but does not specify which part of the paper this discussion should be included in. The authors can infer that it relates to the discussion section, but the comment lacks full grounding as it does not explicitly mention the section. The comment is specific in identifying the need for a clear discussion on the use of CLIP, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the importance of specific components within the framework for using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary for distinguishing the paper from related work but does not provide any evidence or reasoning to support this claim. The comment lacks specific examples or references to related work, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1, as it does not provide sufficient justification or evidence to support the need for a clearer discussion on the use of CLIP.", "helpfulness_rationale": "The review comment raises a question about the importance of specific components within the framework for using CLIP to guide weakly supervised learning. It suggests that a clearer discussion on this topic is necessary to distinguish the paper from related work. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what aspects of the framework are crucial for using CLIP. While it identifies a potential area for improvement, the lack of detailed feedback or actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider defining \"content\" and \"style\" more broadly in the context of their neural application, referencing a specific example from Gabbay & Hosehn (2018). It also questions the meaning of \"style\" in the context of the model, given that it does not capture temporal dynamics. While the comment implies that the authors should clarify these terms, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should define these terms more broadly and address the specific question about \"style.\" Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should define \"content\" and \"style\" more broadly in the context of their neural application, referencing a specific example from Gabbay & Hosehn (2018). It also questions the meaning of \"style\" in the context of the model, given that it does not capture temporal dynamics. This provides specific guidance on what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper this issue pertains to, leaving the authors to infer that it relates to the sections discussing neural applications or style. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should define \"content\" and \"style\" more broadly in the context of their neural application, referencing a specific example from Gabbay & Hosehn (2018). It questions the meaning of \"style\" in the context of the model, given that it does not capture temporal dynamics. The comment provides a reference to external work, which is a good starting point for further exploration. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to delve deeper into the referenced work and their own model to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should define \"content\" and \"style\" more broadly in the context of their neural application, referencing a specific example from Gabbay & Hosehn (2018). It questions the meaning of \"style\" in the context of the model, given that it does not capture temporal dynamics. This feedback is 3 as it points out a potential area for clarification and suggests a specific reference that could be useful for the authors. However, the comment could be more helpful if it provided additional guidance on how to define these terms or how to address the question about \"style\" in the context of the model. Overall, the comment offers some insight but lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point provides a detailed critique of the analysis of vit quantification, specifically addressing the claim that a direct quantization method leads to information distortion. It provides concrete evidence by referencing specific lines and figures in the paper, such as Line 45 and Figures 1(b) and 5(b), to support the argument. Additionally, it mentions the loss of precision introduced by the quantization of MHSA and references existing works in NLP that have encountered similar issues. This feedback is explicit and provides clear guidance on what aspects of the analysis need to be improved, making it 5. The authors know exactly what parts of the analysis require further explanation and how to address the issues raised by the reviewer.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and figures in the paper, allowing the authors to accurately identify the parts being addressed. It also provides detailed specificity by explaining the issue with the analysis of vit quantification, specifically addressing the claim about direct quantization methods and the loss of precision introduced by the quantization of MHSA. The comment references existing works in NLP, such as QBERT, Q8BERT, BinaryBERT, FullyBinaryBert, to support the claim that the loss of precision is not unique to the ViT model. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the analysis of vit quantification is incomplete and that the proposed approach does not improve the information distortion phenomenon. It provides specific evidence by referencing line 45 and figures 1(b) and 5(b), which supports the claim that the variance difference is larger with the proposed approach. Additionally, the comment references existing works in NLP, such as QBERT, Q8BERT, BinaryBERT, FullyBinaryBert, to support the assertion that the loss of precision due to quantization is not unique to the ViT model. This provides a robust basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed comparisons or examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the analysis of vit quantification, specifically addressing the claim that a direct quantization method leads to information distortion. It offers concrete evidence by referencing specific lines and figures in the paper, such as Line 45 and Figures 1(b) and 5(b), to support the argument. Additionally, it highlights the loss of precision introduced by the quantization of MHSA and references existing works in NLP that have encountered similar issues. This feedback is 5 as it not only identifies specific weaknesses in the analysis but also provides detailed guidance on how to address these issues, allowing the authors to significantly improve their draft. The comment is actionable, specific, and provides a clear path for improvement, making it 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a specific equation, Eq. 12, as confusing and suggests that the reward at each trial is unclear. It implies that the authors should clarify where the reward comes from, possibly by referencing Eq. 11. Additionally, the comment recommends explaining the network model in Sec. 4.2 with equations to improve clarity. The inclusion of references to external works provides additional context and potential examples for the authors to consider. While the action is implicit, it is concrete in suggesting specific steps to improve the clarity of the paper. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 12\" and \"Sec. 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with Eq. 12, questioning the origin of the reward and suggesting that it might be related to Eq. 11. Additionally, it provides a recommendation to explain the network model in Sec. 4.2 with equations to improve clarity. The inclusion of references to external works further supports the suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Eq. 12 is confusing and questions the origin of the reward at each trial. It suggests that the reward might be taken from Eq. 11 and recommends explaining the network model in Sec. 4.2 with equations to improve clarity. The comment provides references to external works, which could support the claim by offering examples or context for the network model. However, the references are not directly linked to the specific issue with Eq. 12, making the claim 3. The authors would need to consult the referenced works to fully understand the context and potential solutions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Eq. 12, questioning the origin of the reward at each trial and suggesting that it might be related to Eq. 11. It provides a clear and actionable suggestion to improve clarity by explaining the network model in Sec. 4.2 with equations. Additionally, the comment includes references to external works that could serve as examples or provide additional context for the network model. This feedback is detailed and constructive, offering the authors specific guidance on how to enhance the clarity and comprehensibility of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a minor issue with a typo in the manuscript, specifically suggesting that \"Empiically\" should be corrected to \"Empirically\" on Line 32 of Page 1. This feedback is explicit and provides clear guidance on what action the authors need to take to correct the error. The comment is concrete, as it specifies the exact location of the issue and the correction needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Ln 32 on Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is a typo in the word \"Empiically\" that should be corrected to \"Empirically.\" This provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point consists of a factual statement about a typo in the manuscript, specifically correcting \"Empiically\" to \"Empirically\" on Line 32 of Page 1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a minor issue with a typo in the manuscript, specifically pointing out that \"Empiically\" should be corrected to \"Empirically\" on Line 32 of Page 1. While this feedback is accurate and actionable, it is limited in scope and does not provide broader insights or suggestions for improving the draft. The comment is clear and direct, but it does not offer any additional guidance or context that could help the authors improve their work beyond correcting the typo. Therefore, it is 3, as it provides a specific correction but lacks depth and breadth in its feedback."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that the novelty of the idea is insufficient and that both the new metric and method are relatively straightforward. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty of the idea, improve the metric, or make the method more complex. Without specific suggestions or directions, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the idea and the straightforwardness of both the new metric and method. However, it does not specify which part of the paper discusses these aspects, making it difficult for the authors to pinpoint the exact sections that need attention. The comment lacks grounding as it does not reference specific sections, tables, or figures, leaving the authors to make an educated guess about where the issues might be. Additionally, it is not specific about what needs to be addressed or how the novelty could be enhanced. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the idea is insufficient and that both the new metric and method are relatively straightforward. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, it is challenging for the authors to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a concern about the novelty of the idea, suggesting that both the new metric and method are relatively straightforward. However, it does not provide any specific guidance or suggestions on how the authors might enhance the novelty of their work or improve the complexity of their approach. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point acknowledges that identifying rationales is a complex problem, particularly in NLP tasks like machine translation. It praises the paper for being wellorganized and easy to follow. However, it provides a specific suggestion for improving Figure 2 by recommending the use of another color or a bigger font to enhance the visibility of the humanidentified rationales. This feedback is explicit and provides concrete guidance on how to improve the figure, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific feedback on the figure, suggesting that the \"bold\" text is hard to see and recommending the use of another color or a bigger font to improve the visibility of the humanidentified rationales. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point acknowledges that identifying rationales is a complex problem, particularly in NLP tasks like machine translation. It praises the organization and clarity of the paper but provides a specific suggestion for improving Figure 2 by recommending a different color or font size for highlighting humanidentified rationales. However, the comment does not provide detailed reasoning or examples to support why these changes would be beneficial or how they would improve the figure. The suggestion is 3 as it offers a logical improvement but lacks comprehensive justification or evidence, making it difficult for the authors to fully understand the rationale behind the suggestion.", "helpfulness_rationale": "The review comment acknowledges the complexity of identifying rationales, particularly in NLP tasks like machine translation, and praises the paper for its organization and clarity. It provides a specific and actionable suggestion for improving Figure 2 by recommending the use of a different color or a bigger font to enhance the visibility of the humanidentified rationales. This feedback is clear and constructive, offering a concrete way for the authors to improve the presentation of their results. However, the comment could be more helpful if it provided additional context or examples of how this improvement would impact the overall understanding of the paper. Overall, the comment is 4 as it provides a specific and actionable suggestion for enhancing the figure, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern that the proposed approach does not outperform or is even worse than Decouple Kang et al. for overall performance. It also points out that the tradeoff between head and tail categories is not fully investigated for the baselines, suggesting that changing hyperparameters in Decouple Kang et al. could improve tail accuracy while slightly decreasing head accuracy. The reviewer encourages the authors to continue this line of work for future submission. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or specific suggestions for further investigation. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the tradeoff for baselines and potentially explore hyperparameter tuning. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3)\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the performance comparison with Decouple Kang et al. and the tradeoff between head and tail categories. The comment provides a clear suggestion for further investigation by encouraging the authors to explore the tradeoff for the baselines. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed approach does not outperform or is even worse than Decouple Kang et al. for overall performance, and it highlights a tradeoff between head and tail categories. The reviewer suggests that similar tradeoffs could be explored for the baselines by adjusting hyperparameters. While the comment provides some reasoning, it lacks specific examples or detailed comparisons to fully substantiate the claim. The reference to Decouple Kang et al. is mentioned, but without further context or data, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically that the proposed approach does not outperform or is even worse than Decouple Kang et al. for overall performance. It also points out that the tradeoff between head and tail categories is not fully investigated for the baselines, suggesting that adjusting hyperparameters in Decouple Kang et al. could improve tail accuracy while slightly decreasing head accuracy. This feedback is valuable as it highlights a significant weakness in the paper and provides a specific direction for further investigation. However, the comment could be more helpful by offering suggestions on how to address these issues or by providing examples of how to explore the tradeoff for the baselines. Overall, the comment is 4 as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides two explicit suggestions for improvement. First, it recommends clarifying the function pi by specifying its domain as R^m to \u0394^(K+1). Second, it questions the dimensions in the equation (2) and suggests assuming the 1st column of X_t is always 0 to resolve the issue. These suggestions are clear and provide concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L75\" and \"In (2),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the need to clarify the function pi and the mismatch in dimensions due to the dropped noop action. The reviewer suggests assuming the 1st column of X_t is always 0 to resolve the dimension issue. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two parts: a suggestion to clarify the function pi and a question about the dimensions in equation (2). The first part is a suggestion for improvement, which is not a claim requiring verification. The second part questions the dimensions, which is a factual observation. Since the comment does not contain subjective claims or opinions, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides two specific suggestions for improvement. First, it recommends clarifying the function pi by specifying its domain as R^m to \u0394^(K+1), which could help in understanding the mathematical context. Second, it questions the dimensions in equation (2) and suggests assuming the 1st column of X_t is always 0 to resolve the issue. These suggestions are clear and actionable, offering the authors concrete steps to enhance the clarity and accuracy of their mathematical expressions. However, the comment could be more helpful if it provided additional context or examples to fully address the issues. Overall, the feedback is 4 as it directs the authors to specific areas needing improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific issue with the expected counterfactual violating a condition stated in Definition 1. However, it does not provide any guidance or suggestions on how the authors should address this issue or what changes they should make to their draft. The comment lacks explicit or implicit actions, leaving the authors without a clear understanding of how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Definition 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the expected counterfactual violating the condition stated in Definition 1. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the expected counterfactual violates a condition stated in Definition 1. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the expected counterfactual violating a condition stated in Definition 1. This feedback is clear and actionable, as it points out a potential problem that needs to be addressed in the paper. However, the comment lacks further guidance or suggestions on how the authors might resolve this issue or what implications it might have for the overall analysis. While it highlights a critical area for improvement, the lack of additional context or direction limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for the authors to focus on but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a specific comparison that the authors should make to further evaluate the performance of their proposed model. It explicitly requests a comparison with existing models that use answers as inputs, such as the Revisiting Visual Question Answering Baselines by Jabri et al. (ECCV16). This provides clear and concrete guidance on what action the authors should take to enhance their draft. The suggestion is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment suggests a specific comparison with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). However, it does not explicitly mention which part of the paper this comparison should be made in, leaving the authors to infer that it should be integrated into the discussion or results section. The suggestion is specific in terms of the comparison, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a comparison between the proposed model and existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This suggestion is based on the observation that ternary potential seems to be the main factor in the performance improvement of the proposed model. However, the comment does not provide detailed reasoning or evidence to support why this comparison is necessary or how it would enhance the paper. The reference to Jabri et al. is a good starting point, but more context or explanation would be needed to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the suggestion but lacks comprehensive justification.", "helpfulness_rationale": "The review comment suggests a specific comparison that the authors should make to further evaluate the performance of their proposed model. It recommends comparing the model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper by exploring the impact of ternary potential in the context of existing models. However, the comment could be more helpful if it explained why this comparison is important or how it would contribute to the paper\"s overall impact. Despite this, the suggestion is valuable and provides a clear direction for the authors to improve their draft. Therefore, the comment is 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests conducting an ablation study on the number of layers versus performance, which is a specific and concrete action for the authors to take. This feedback provides clear guidance on what additional analysis could be beneficial for the paper, allowing the authors to know exactly what to do to enhance their draft. The comment is explicit and actionable, making it 5.", "grounding_specificity_rationale": "The comment suggests conducting an ablation study on the number of layers versus performance, which is a specific suggestion for improvement. However, it does not specify which part of the paper this suggestion should be applied to, making it weakly grounded. The comment is specific in its suggestion, as it clearly outlines what additional analysis could be beneficial. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an ablation study on the number of layers versus performance, which is a claim requiring justification. However, the comment does not provide any reasoning or evidence to support why this study would be interesting or beneficial. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests conducting an ablation study on the number of layers versus performance, which could provide valuable insights into the impact of layer depth on the model\"s performance. This is a specific and actionable suggestion that could help the authors improve their draft by offering a more detailed analysis of their results. However, the comment could be more helpful if it provided additional context or explanation for why this study would be beneficial or how it might address specific questions or concerns raised in the paper. Overall, the feedback is 4 as it offers a clear direction for further analysis, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of detailed discussion on computational aspects, particularly in high dimensions, and questions the practical usefulness of the proposed methods. It also points out that the algorithm requires solving several LPs with parameters that are not easily calculable, which is reflected in the smallscale experiments. While the comment identifies areas for improvement, it does not provide explicit guidance on how the authors should address these issues or suggest specific steps to enhance the computational aspects or experimental scale. The feedback is 3 as it highlights a critical area for improvement but lacks concrete instructions on how to implement these changes. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the lack of detailed discussion on computational aspects, particularly in high dimensions, and questions the practical usefulness of the proposed methods. It mentions that the algorithm requires solving several LPs with parameters that are not easily calculable, which is reflected in the smallscale experiments. However, the comment does not specify which part of the paper discusses the computational aspects or where the appendix is located, making it weakly grounded. The comment is specific in detailing the issue with the computational aspects and the limitations of the experiments, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors do not discuss computational aspects in detail and questions the practical usefulness of their proposed methods in high dimensions. It provides a logical reasoning by pointing out that the algorithm requires solving several LPs with parameters that are not easily calculable, which is reflected in the smallscale experiments. However, the comment lacks specific examples or references to support the claim about the computational aspects or the limitations of the experiments. While the reasoning is clear, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the discussion of computational aspects, particularly in high dimensions. It points out that the proposed methods may not be practically useful due to the complexity of solving LPs with parameters that are not easily calculable. The comment also notes that the experiments are limited to smallscale datasets, which further highlights the need for more detailed computational analysis. While the comment effectively identifies a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or enhance the computational aspects of their work. Providing actionable feedback would have made the comment more helpful. Therefore, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the design choice of trimming questions after the first 10, suggesting that it might be an odd choice, especially since the question model is a bag of words and does not incur significant computational costs for longer sequences. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or whether they should reconsider their design choice. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the design choice of trimming questions after the first 10 and provides a rationale for this critique, noting that the question model is a bag of words and does not incur significant computational costs for longer sequences. This provides clear guidance on what aspect of the paper needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the design choice of trimming questions after the first 10, suggesting that it might be an odd choice, especially since the question model is a bag of words and does not incur significant computational costs for longer sequences. This claim is 3 as it provides a logical reasoning for questioning the design choice, but it lacks specific examples or references to support the assertion that trimming questions is unnecessary. The comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the design choice of trimming questions after the first 10, suggesting that this might be an odd choice, especially since the question model is a bag of words and does not incur significant computational costs for longer sequences. This feedback identifies a potential issue with the experimental design and provides a rationale for why the trimming might not be necessary. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or whether they should reconsider their design choice. While it highlights a potential area for improvement, the feedback could be more actionable and helpful by offering concrete recommendations or alternatives. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to change two lines in red to green in the Supplemental Material. It provides specific line numbers and references to the Supplemental Material, making it clear and concrete. The authors know exactly what needs to be done to address the comment, which is to change the color of these lines. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the Supplemental Material (SuppMat, L502, L507, and L509) and references to figures or tables (Table 4 and Algorithm 1), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, namely the color of the lines from red to green. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements regarding specific lines in the Supplemental Material that should be changed from red to green. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is highly specific and actionable, as it identifies two lines in the Supplemental Material that should be changed from red to green. It provides exact line numbers and references to specific elements, such as equations and tables, allowing the authors to make precise corrections. This level of detail is invaluable for ensuring the accuracy and clarity of the manuscript. By addressing this feedback, the authors can improve the overall quality and professionalism of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a gap in the paper, specifically the lack of a proper comparison between the proposed approach and online learning formulations in the evaluation results. It also mentions the absence of a comparison against reinforcement learning (RL) and raises questions about the retraining cost and challenges of including it in the evaluation. The comment provides a clear and concrete action for the authors to take: conduct a comparison with online learning approaches and address the questions raised. This feedback is explicit and provides specific guidance on what needs to be done to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract and other parts of the paper where the issue of \"online learning formulation overlooking key practical considerations\" is discussed. It also specifies the need for a proper comparison against online learning approaches and reinforcement learning (RL) in the evaluation results. The comment provides clear guidance on what needs to be addressed, such as comparing retraining cost and incremental updates, and why online learning is discarded. This level of detail and specificity allows the authors to accurately identify the parts of the paper that require revision and understand the rationale behind the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a proper comparison between the proposed approach and online learning formulations, as well as against reinforcement learning (RL). It questions the rationale behind discarding online learning and suggests that the retraining cost might be a factor. However, the comment does not provide specific examples or references to support these claims, making it 3. The authors would need to infer the reasoning behind the suggestion and potentially conduct additional research to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of a proper comparison between the proposed approach and online learning formulations in the evaluation results. It also points out the absence of a comparison against reinforcement learning (RL) and raises questions about the retraining cost and challenges of including it in the evaluation. This feedback is 5 as it provides clear and actionable guidance on how to strengthen the paper by addressing these gaps. By suggesting specific comparisons and questions to consider, the comment empowers the authors to make meaningful improvements to their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the main text should be clarified to indicate the presence of additional experiments in the supplement and that these results should be summarized. However, it does not provide explicit instructions on how to achieve this clarification or what specific aspects of the results should be summarized. The action is implicit and somewhat vague, as the authors can infer that they need to add a summary of the supplementary experiments but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the main text should be clarified to indicate the presence of additional experiments in the supplement and that these results should be summarized. However, it does not specify which part of the paper this should be addressed in, such as a particular section or figure. The authors can infer that it relates to the experimental section, but this is not explicitly stated. The comment is specific in suggesting what needs to be clarified and summarized, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the main text should clarify the presence of additional experiments in the supplement and summarize their results. However, it does not provide any specific examples, reasoning, or references to support why this clarification is necessary or how it would improve the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the main text should clarify the presence of additional experiments in the supplement and summarize their results. This feedback is clear and actionable, as it directs the authors to enhance the clarity and comprehensiveness of their paper by including a summary of the supplementary experiments. However, the comment could be more helpful if it provided specific guidance on what aspects of the results should be highlighted or how to effectively integrate the supplementary material into the main text. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that important references are missing and encourages the authors to conduct a comprehensive comparison with the works \"GFF\" and \"EfficientFCN.\" It also provides specific references to these works, which are \"Gated Fully Fusion for Semantic Segmentation, AAAI\"20\" and \"EfficientFCN: Holisticallyguided Decoding for Semantic Segmentation, ECCV\"20.\" This feedback is clear and provides concrete guidance on what the authors need to do to improve their draft. The explicit mention of specific references and the suggestion for a comprehensive comparison make the action 5. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the missing references, \"GFF\" and \"EfficientFCN,\" and provides their respective references. This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific because it suggests a comprehensive comparison with these works, which provides clear guidance on what needs to be addressed. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that important references are missing and suggests a comprehensive comparison with the works \"GFF\" and \"EfficientFCN.\" The reviewer provides specific references to these works, which supports the claim. However, the comment could be strengthened by explaining why these references are important or how they relate to the current work. Despite this, the inclusion of references provides a solid foundation for the claim, making it 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of important references, specifically mentioning \"GFF\" and \"EfficientFCN,\" which are relevant to the topic of fast semantic segmentation in the encodedecoder architecture. The reviewer encourages the authors to conduct a comprehensive comparison with these works, providing specific references to facilitate this process. This feedback is actionable and provides clear guidance on how the authors can enhance their draft by incorporating these references and comparisons. However, the comment could be more helpful if it offered suggestions on how to integrate these references or comparisons into the manuscript. Overall, the comment is 4, as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input. It questions how this method can be learned and applied to largescale datasets like ImageNet, suggesting that the practical contribution of the paper could be significantly reduced without a solution to this issue. While the comment highlights a potential problem, it does not provide explicit guidance or suggestions on how the authors might address the scalability issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to find a solution to the scalability problem but are not given specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the scalability of the proposed NC measure, specifically mentioning its applicability to largescale datasets like ImageNet. However, it does not specify which part of the paper discusses the NC measure or its scalability issues, making it weakly grounded. The comment is specific in identifying the problem of scalability and suggesting that the practical contribution of the paper could be reduced without a solution. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the scalability of the proposed NC measure, questioning how it can be applied to largescale datasets like ImageNet. The comment suggests that the practical contribution of the paper could be significantly reduced without addressing this issue. However, the comment lacks specific examples or references to support the claim about the scalability problem or potential solutions. This makes the claim 3, as it provides a logical concern but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input. It questions how this method can be applied to largescale datasets like ImageNet, suggesting that the practical contribution of the paper could be significantly reduced without addressing this issue. This feedback is valuable as it highlights a potential limitation of the proposed method and prompts the authors to consider scalability in their approach. However, the comment could be more helpful if it provided suggestions or ideas on how to address the scalability issue, such as proposing alternative methods or techniques that could be used to improve scalability. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and concerns about the \"filter manifold network\" (FMN), which is a critical part of the technique. It asks if the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with larger numbers of filter parameters. These questions imply that the authors should provide more discussion, analysis, or experimental results regarding FMN. While the comment does not explicitly instruct the authors to conduct specific experiments or analyses, it provides a clear direction for what needs to be addressed. The authors can infer that they need to provide more detailed information about FMN, its scalability, and potential experiments. Therefore, the comment is 4, as it provides a clear direction for improvement but lacks specific instructions on how to implement the suggested actions.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"filter manifold network\" (FMN), which is a specific part of the technique discussed in the paper. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it raises several questions and concerns about the FMN, such as the lack of discussion or analysis, the use of other architectures, the scaling of adaptive convolutions, and the scalability of FMN with larger numbers of filter parameters. These specific questions provide clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions and concerns about the \"filter manifold network\" (FMN), which is a critical part of the technique. It questions the lack of discussion or analysis on FMN, the use of other architectures for FMN, and the scalability of adaptive convolutions with the number of filter parameters. While the comment highlights areas that need further exploration or clarification, it does not provide specific evidence, examples, or references to support these claims. The lack of detailed justification or examples makes the claims 3, as the authors would need to infer the importance of these questions and address them in their response. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the discussion and analysis of the \"filter manifold network\" (FMN), which is a crucial part of the technique. It raises several questions, including whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with larger numbers of filter parameters. These questions highlight important areas that need further exploration and clarification in the paper. By addressing these questions, the authors can provide a more comprehensive understanding of their technique and its potential applications. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these questions. Overall, the feedback is 4 as it directs the authors to important areas for improvement, but it could be more actionable with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It provides a detailed explanation of the computation complexity issue, specifically mentioning the calculation of all flipped previous layer outputs into the current layer in Algorithm 1. The comment explicitly suggests that a comparison of computation complexity should be included in the experiment part. This feedback is clear and provides a direct action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1\" and \"the experiment part,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of computation complexity and suggests that a comparison of computation complexity should be included in the experiment part. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed PSA method requires more computation than baselines and provides a specific explanation of the computation complexity issue in Algorithm 1. This detailed explanation supports the claim, making it 4. However, the comment could be strengthened by including specific examples or references to support the comparison of computation complexity with baselines. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It provides a detailed explanation of the computation complexity issue, specifically mentioning the calculation of all flipped previous layer outputs into the current layer in Algorithm 1. The comment also suggests that a comparison of computation complexity should be included in the experiment part. This feedback is clear and actionable, offering the authors a specific area to address and a concrete suggestion for improvement. By highlighting the computational complexity and suggesting a comparison, the comment empowers the authors to enhance the comprehensiveness and validity of their experimental results. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take, such as increasing the font size in figures 1 and 2, making the words in the grey box larger, and ensuring that \"V_mem, Th_i, U_i^t\" are not too small. It also suggests adding a \"table\" to compare the number of epochs and parameters with other stateoftheart Transformer designs. These suggestions are concrete and provide clear guidance on how to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 1\" and \"figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific feedback on font sizes and the clarity of certain elements, such as the words in the grey box and the labels \"V_mem, Th_i, U_i^t.\" Additionally, it suggests improvements for the \"CTRL\" explanation and the font size in figure 2. The comment is specific in detailing what needs to be addressed in each part, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of multiple claims and suggestions. The first part is a subjective opinion about the quality of the figures, which is not verifiable as it lacks specific evidence or reasoning. The second part suggests improvements, such as increasing font sizes and adding a table for comparison, which are factual and do not require verification. The third part claims a lack of detail in comparisons with other stateoftheart Transformer designs, which is 3 as it provides a logical suggestion for improvement but lacks specific examples or references. Overall, the comment is a mix of subjective opinions and suggestions, making it difficult to categorize as a whole. However, since it does not contain a single claim that requires verification, it aligns with the label \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the visual presentation of the figures, suggesting improvements such as increasing font sizes and making certain labels larger. It also identifies a lack of detail in comparisons with other stateoftheart Transformer designs, recommending the inclusion of a table to emphasize the data and justify the improved accuracy. This feedback is clear and constructive, offering the authors concrete steps to enhance the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it provided additional suggestions or examples for the table or comparisons. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to rewrite a specific sentence that is unclear. It provides a clear action for the authors to take, which is to rephrase the sentence to improve clarity. The feedback is direct and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific sentence that is unclear, \"While a smaller j to simulate more accumulate errors along with the inference steps,\" and references pages 5 and 3, line. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, which is the rewriting of the sentence to improve clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding a specific sentence in the paper. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific sentence that is unclear and requests the authors to rewrite it for better comprehension. This feedback is clear and actionable, as it directly points out a part of the paper that needs improvement. By suggesting a rewrite, the reviewer provides a concrete step for the authors to enhance the clarity of their work. However, the comment could be more helpful if it offered additional guidance on how to rephrase the sentence or provided context for why the original sentence was unclear. Despite this, the feedback is 4 as it effectively guides the authors toward improving the readability of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the paper\"s motivation and the practical application of the proposed method. It suggests that the paper should demonstrate the methodology\"s use in actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset. While the comment implies that the authors should provide more context and examples to clarify the paper\"s motivation and application, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional examples or context to address the reviewer\"s concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of clarity regarding the paper\"s motivation and the application of the proposed method. It also provides specific examples of how the methodology could be demonstrated, such as adapting a model trained on a synthetic dataset to a real dataset. This allows the authors to accurately identify the parts of the paper that need revision and understand what specific issues need to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s motivation is unclear and that the proposed method lacks a clear application. The reviewer questions the need for domain adaptation and suggests that demonstrating the methodology on actual tasks involving domain adaptation would be beneficial. However, the comment does not provide specific examples or references to support the claim that the paper\"s motivation is unclear or that the proposed method lacks practical application. The reasoning is somewhat vague and lacks detailed justification, making it difficult for the authors to fully understand and address the concerns. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s motivation and application, questioning the need for the proposed method and its potential utility. It suggests that the paper should demonstrate the methodology\"s use in actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset. This feedback is clear and actionable, providing the authors with a specific direction to enhance the paper\"s relevance and impact. However, the comment could be more helpful if it offered additional guidance on how to effectively demonstrate these applications or provided examples of potential tasks. Overall, the comment is 4 as it directs the authors toward a critical area for improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should include ATA in the comparison in Table 2, as it is better than FP according to the results in Table 1. This is an explicit action with clear guidance on what needs to be done to improve the draft. The comment provides a specific suggestion for enhancing the comparison, making it 5. The authors know exactly what action to take to address the feedback, which is to include ATA in the comparison in Table 2.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"leave one out setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: including ATA in the comparison, as it is better than FP according to the results in Table 1. This provides clear guidance on how to enhance the comparison, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the proposed method should be compared to \"ATA\" in addition to \"+LFP\" in Table 2, as ATA is better than FP according to the results in Table 1. This claim is 3 as it provides a logical reasoning based on the results presented in the paper. However, it lacks specific examples or detailed comparisons to fully substantiate the claim, making it 3. The authors would need to consider the results in Table 1 to understand the basis of the suggestion, but the comment could be strengthened with more detailed analysis or references.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparison in Table 2, noting that the proposed method is only compared to \"+LFP\" under the leave one out setting. It suggests that including ATA in the comparison would be more convincing, given that ATA is better than FP according to the results in Table 1. This feedback is clear and actionable, providing the authors with a specific suggestion to enhance the validity and persuasiveness of their results. By addressing this point, the authors can strengthen their argument and improve the overall quality of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the comparison with certain baselines is unfair because they lack prior knowledge of users or language embedding computation. It implies that a better comparison should be considered, but it does not specify what this better comparison would entail or how the authors should implement it. The action is implicit and somewhat vague, as the authors are left to infer what changes are needed without clear guidance on how to make them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the comparison with some baselines is unfair because they lack prior knowledge of users or any language embedding computation. However, it does not specify which baselines are being referred to or where in the paper these comparisons are made. This lack of specificity and grounding makes it difficult for the authors to identify the exact parts of the paper that need attention. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the comparison with some baselines is unfair because they lack prior knowledge of users or any language embedding computation. However, the comment does not provide specific examples of these baselines or explain why their lack of prior knowledge or language embedding computation makes the comparison unfair. This lack of detailed justification or references makes the claim difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison to certain baselines, suggesting that the lack of prior knowledge of users or language embedding computation makes the comparison unfair. This is a valid point that could impact the validity of the results. However, the comment does not provide specific guidance on how to address this issue or suggest alternative baselines that could be used for a more fair comparison. While it highlights a weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and observations about the paper, including the potential benefits of outputside layers, the clarity of Figure 4, the presentation of Pixelshuffle details, and the use of pixelshuffle in the superresolution field. It also questions the dimensionality after upsampling in Figure 2 and notes the absence of limitations and societal impact discussions. While the comment identifies areas that need clarification or further explanation, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, leaving the authors to infer what needs to be addressed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and observations about specific parts of the paper, such as the outputside layers, Figure 4, the presentation of Pixelshuffle details, and the use of pixelshuffle in the superresolution field. It also questions the dimensionality after upsampling in Figure 2. These references provide full grounding as they explicitly mention specific figures and elements of the paper, allowing the authors to accurately identify the parts being addressed. The comment is specific in detailing what needs to be clarified or addressed in each of these parts, such as the benefits of outputside layers, the clarity of Figure 4, and the presentation of Pixelshuffle details. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions and observations about the paper, including the potential benefits of outputside layers, the clarity of Figure 4, and the presentation of Pixelshuffle details. It also questions the use of pixelshuffle in the superresolution field and the dimensionality after upsampling in Figure 2. However, the comment lacks specific evidence, examples, or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or supporting information renders the claims 1, as the authors are left without a clear path to address the concerns. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises several important points that could help the authors improve their draft. It questions the potential benefits of the outputside layers, which could be a significant oversight in the paper. Additionally, it points out that Figure 4 is not clearly illustrated, and the details of Pixelshuffle are not presented clearly. The comment also questions the use of pixelshuffle in the superresolution field and the dimensionality after upsampling in Figure 2. Furthermore, it notes the absence of discussions on limitations and potential negative societal impacts, which is a critical aspect of any research paper. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of how to improve the clarity of Figure 4. Overall, the comment identifies important areas for improvement but could be more actionable with additional guidance. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the presentation of the paper is difficult to follow for the reviewer, but it does not provide any specific guidance or suggestions on how the authors might improve the clarity or structure of their paper. Without explicit or implicit actions, the authors are left without a clear understanding of what changes they should make to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment states that the presentation of the paper is hard to follow for the reviewer, but it does not specify which part of the paper is causing this issue. The authors cannot confidently determine which sections or aspects of the paper are problematic, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide details on what aspects of the presentation are unclear or how they could be improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the presentation of the paper is hard to follow for the reviewer. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment indicates that the presentation of the paper is difficult to follow for the reviewer, which is a valid concern. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might improve the clarity or structure of their paper. Without detailed guidance or examples, the authors are left without a clear understanding of what changes they should make to address the issue. Therefore, the comment is 2, as it identifies a problem but does not offer any actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors provide a more detailed presentation of the compared models, specifically highlighting the differences between KVAE and the other models, DMM and DVBF. It also requests comments on the computation requirements of the three methods compared in Table 1. While the comment implies that the authors should provide more detailed information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given specific guidance on how to present the additional details or what aspects to focus on. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what the reviewer would appreciate, namely a more detailed presentation of the compared models, and highlights the differences between KVAE and the other models. Additionally, it requests comments on the computation requirements of the three methods compared in Table 1. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors provide more detailed information about the compared models, specifically highlighting the differences between KVAE and the other models, DMM and DVBF. The reviewer acknowledges a lack of familiarity with the compared models but provides some insight into their differences, such as the simplicity of KVAE due to linear state space transitions and the need for computation of timedependent LGSSM parameters. However, the comment lacks specific examples or references to support the claim that more detailed presentation is needed. This makes the claim 3, as it provides some context but requires further elaboration or evidence to fully substantiate the request for more detailed information.", "helpfulness_rationale": "The review comment acknowledges a lack of familiarity with the compared models, DMM and DVBF, but highlights the need for a more detailed presentation of these models in comparison to KVAE. It provides specific insights into the differences between KVAE and the other models, such as the simplicity of KVAE due to linear state space transitions and the need for computation of timedependent LGSSM parameters. The comment also requests that the authors comment on the computation requirements of the three methods compared in Table 1. This feedback is clear and actionable, as it directs the authors to provide more detailed information about the compared models and their computational aspects. However, it could be more helpful if it included suggestions on how to present this information or what specific details to focus on. Overall, the comment is 4, as it provides valuable guidance for improving the clarity and comprehensiveness of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should include and compare their work with existing taskoriented recommendation works, such as the ones mentioned by Li et al. and He et al. It also recommends discussing how their work differs from other chatbox research works. While the comment implies that the authors should conduct these comparisons and discussions, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including and comparing the work with existing taskoriented recommendation works, such as those by Li et al. and He et al. It provides specific references to these works, which helps the authors understand what needs to be addressed. However, it does not explicitly mention which part of the paper should include these comparisons, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as including comparisons and discussing differences with other chatbox research works. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that works such as Li et al. and He et al. are important to include and compare with, as they relate to taskoriented recommendation. The comment provides specific references to these works, which supports the claim by offering a clear basis for comparison. However, the comment could be strengthened by explaining why these works are particularly relevant or how they differ from the current work. Despite this, the inclusion of references provides a solid foundation for the claim, making it 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that the authors should include and compare their work with existing taskoriented recommendation works, such as those by Li et al. and He et al. This feedback is clear and actionable, as it provides specific references and a clear direction for the authors to enhance their work by contextualizing it within the broader literature. Additionally, the comment recommends discussing how the current work differs from other chatbox research works, which would help readers understand the novelty and contributions of the paper. This feedback is 5 as it offers concrete suggestions for improving the draft and enhancing its relevance and impact. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the experimental strengths of the proposed approach, suggesting that running a descent procedure for 40 different networks from the training phase may not be necessary. The reviewer proposes an alternative method, suggesting that running vanilla Adam on the final network with 40 random initial points could be sufficient, as at least one of these restarts would likely reach the global minimum. While the comment implies that the authors should consider this alternative approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this alternative method. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental strengths of the proposed approach, specifically questioning the necessity of running a descent procedure for 40 different networks from the training phase. It suggests an alternative method, proposing to run vanilla Adam on the final network with 40 random initial points, which could potentially reach the global minimum. However, the comment does not explicitly mention which part of the paper discusses the experimental setup or the proposed algorithm, making it weakly grounded. The suggestion is specific, as it provides a clear alternative approach to consider, but the lack of explicit grounding limits the comment\"s effectiveness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experimental strengths of the proposed approach are not convincing and suggests an alternative method. The reviewer provides a logical reasoning by comparing the proposed algorithm with vanilla Adam, explaining that running a descent procedure for 40 different networks may not be necessary. However, the comment lacks specific examples or references to support the claim that running vanilla Adam with 40 random initial points would be sufficient to reach the global minimum. This makes the claim 3, as it provides a logical basis but requires further evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the experimental strengths of the proposed approach, specifically questioning the necessity of running a descent procedure for 40 different networks from the training phase. It suggests an alternative method, proposing to run vanilla Adam on the final network with 40 random initial points, which could potentially reach the global minimum. This feedback is 3 as it provides a different perspective on the experimental design and suggests a potential simplification. However, the comment lacks depth and does not offer detailed guidance on how to implement this alternative approach or why it might be more effective. While it identifies a potential area for improvement, it does not fully support the authors in making significant changes to their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the first quotation mark in the phrase \"for \"inbetween\" uncertainty\" should be a forward mark instead of a backward mark. This provides clear and direct guidance on how to correct the error, making the comment 5. The authors know exactly what action to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"for \"inbetween\" uncertainty,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error, which is the incorrect use of quotation marks, and provides the correct notation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement about the correct use of quotation marks in the phrase \"for \"inbetween\" uncertainty.\" It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific typographical error in the paper, namely the incorrect use of quotation marks in the phrase \"for \"inbetween\" uncertainty.\" By pointing out this error, the comment provides clear and actionable feedback that allows the authors to correct their draft and improve its accuracy. This level of detail is valuable for ensuring the paper\"s professionalism and attention to detail. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any explicit or implicit guidance on how the authors should explore this dataset further. There is no indication of what specific aspects of the dataset should be explored, what additional analysis or discussion could be included, or how the exploration should be conducted. As a result, the authors are left without a clear understanding of what actions to take to address this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not specify which part of the paper this relates to, such as a specific section or analysis where the dataset is discussed. Without explicit references or detailed guidance, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding what aspects of the dataset could be explored further. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any specific reasoning, examples, or references to support why this exploration is necessary or how it could enhance the paper. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it lacks specificity and does not provide any guidance on what aspects of the dataset should be explored or how this exploration could enhance the paper. Without actionable feedback or suggestions, the authors are left without a clear understanding of how to address this point. As a result, the comment is 2, as it identifies a potential area for improvement but does not offer any concrete steps for the authors to take."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to use more objective terms instead of \"remarkable\" when describing the accuracy improvement. It also provides a specific suggestion by recommending the use of more descriptive language. Additionally, the comment offers a concrete example by suggesting that the improvement is \"definitely there\" but not necessarily \"remarkable,\" which gives the authors a clear direction on how to rephrase their description. This feedback is explicit and provides concrete guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line number, \"218,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on using more objective terms instead of \"remarkable\" to describe the accuracy improvement. The comment further specifies the issue by suggesting that the improvement is indeed present but not necessarily remarkable, given the squished axes. This level of detail helps the authors understand what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the term \"remarkable\" is subjective and should be replaced with more objective terms. The reviewer provides a logical reasoning by stating that while the improvement is \"definitely there,\" it might not be considered remarkable due to the squished axes. This reasoning is clear and provides a basis for the suggestion. However, the comment could be strengthened by providing specific examples of more objective terms that could be used. Overall, the claim is 4, as it offers a logical argument but lacks detailed examples or references to fully substantiate the suggestion. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the term \"remarkable\" should be replaced with more objective terms when describing the accuracy improvement. It also offers a rationale for this suggestion by noting that the improvement is indeed present but might not be considered remarkable due to the squished axes. This feedback is clear and constructive, guiding the authors on how to improve the language and clarity of their results section. By addressing this feedback, the authors can enhance the objectivity and precision of their claims, making the comment 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point notes that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on what specific aspects of the refinement should be focused on or how the authors might improve the performance. As a result, the comment lacks actionable advice, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the observed performance enhancements are modest, implying that there is room for further refinement. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what aspects of the performance could be refined. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what kind of refinement is needed or how it could be achieved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the observed performance enhancements are \"somewhat modest,\" suggesting that there is room for further refinement. However, the comment lacks specific examples, data, or references to support this claim. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment notes that the observed performance enhancements are modest, suggesting that there is room for further refinement in the future. While this observation highlights an area for potential improvement, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might enhance the performance or what specific aspects could be refined. Without detailed feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of multiple requests for clarification and references. It explicitly instructs the authors to provide references for specific passages in Section 3.2 and to clarify what \"MLP\" refers to in Figure 2. These requests are direct and concrete, providing clear actions for the authors to take. The comment is 5 as it specifies exactly what needs to be addressed and how to address it, leaving no ambiguity for the authors.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2, lines 230234 and 234235,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely providing references for the mentioned passages and clarifying the term \"MLP\" in Figure 2. This level of detail provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual requests for clarification and references, which are not subjective claims or opinions. It asks for specific information to be provided, such as references for certain passages and a description of \"MLP\" in Figure 2. Since it does not contain any claims, suggestions, or judgments, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas in the paper that require improvement. It points out the need for references in Section 3.2, which is a clear and actionable suggestion for enhancing the paper\"s credibility. Additionally, it raises a question about the term \"MLP\" in Figure 2, prompting the authors to clarify this terminology. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate these references or clarify the terminology. Overall, the feedback is clear and actionable, making it 4 for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the experimental results on the last two datasets, suggesting that they are not convincing enough to validate the effectiveness of the proposed method. It implies that the performance is similar to IRM, which may be due to the issues mentioned earlier. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to improve the experimental results. The action is implicit and vague, as the authors are left to infer that they need to improve the experimental results but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the experimental results, specifically mentioning the last two datasets. However, it does not specify which datasets these are, making it weakly grounded. The comment provides some specificity by questioning the validity of the results and suggesting a possible cause, but it lacks detailed guidance on how to address the issue. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method, as the performance is similar to IRM. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of supporting evidence or detailed analysis renders the claim 1, as the authors are left without clear guidance on how to address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the performance on the last two datasets is similar to IRM, which raises concerns about the effectiveness of the proposed method. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. It does not offer specific ways to improve the experimental design, analysis, or interpretation of results. As a result, the comment provides limited value to the authors, making it 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that there is a lack of empirical validation and suggests that experiments should be conducted to validate the bounds. This provides a clear and direct action for the authors to take, which is to include empirical validation through experiments. The comment is explicit and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment points out the lack of empirical validation and suggests conducting experiments to validate the bounds. However, it does not specify which part of the paper lacks empirical validation or which bounds need to be validated. This makes it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its request for empirical validation but lacks grounding as it does not identify the specific parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that there is a lack of empirical validation, suggesting that experiments should be conducted to validate the bounds. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of empirical validation. It suggests that the authors should conduct experiments to validate the bounds, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific guidance on what kind of experiments should be conducted or how the validation should be approached. Despite this, the feedback is 4 as it directs the authors to a critical area that needs attention, allowing them to improve the robustness and credibility of their work. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between Equation 9 and Figure 1, suggesting that the output patches may not be cropped parts of the input image but rather masked versions of the input image with most pixels being black. The reviewer questions the correctness of this interpretation and suggests that Figure 1 might be misleading. Additionally, the comment implies that using bilinear sampling to zoom on the region of interest could provide better results. While the comment identifies a potential issue and suggests an alternative approach, it does not provide explicit instructions on how to address the discrepancy or improve Figure 1. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the interpretation of Equation 9 and Figure 1 and consider the suggested alternative. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"eq. 9\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the discrepancy between the equation and the figure, and questions the interpretation of the output patches. Additionally, it suggests an alternative approach using bilinear sampling. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a discrepancy between Equation 9 and Figure 1, questioning the interpretation of the output patches. It suggests that the output patches might not be cropped parts of the input image but rather masked versions of the input image with most pixels being black. The reviewer implies that Figure 1 might be misleading and suggests an alternative approach using bilinear sampling. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about the discrepancy. The reasoning is logical but could be strengthened with more detailed evidence or examples. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment identifies a discrepancy between Equation 9 and Figure 1, questioning the interpretation of the output patches. It suggests that the output patches might not be cropped parts of the input image but rather masked versions of the input image with most pixels being black. This observation could be misleading, and the reviewer provides a constructive suggestion by proposing the use of bilinear sampling to zoom on the region of interest, which could potentially provide better results. The comment is clear and actionable, offering a specific area for improvement and a potential solution. However, it could be more helpful if it provided additional context or examples to further clarify the issue and the suggested approach. Overall, the comment is 4 as it directs the authors to a critical area that needs clarification and offers a constructive suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests deleting the word \"Discussion\" from a specific sentence on page 5. This is an explicit action with clear instructions on what the authors should do to improve their draft. The comment is concrete, as it specifies the exact change needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Pg.5\" and the specific sentence, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the statement about training time reduction has not been revisited in the Discussion section and suggests deleting the word \"Discussion\" from the sentence. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the statement about training time reduction not being as drastic as parameter reduction is not supported by the Discussion section. The reviewer implies that the statement should be deleted, but does not provide any reasoning or evidence to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the text on page 5, where it mentions that the training time reduction is less drastic than the parameter reduction. The reviewer points out that this statement is not revisited in the Discussion section, suggesting that the word \"Discussion\" should be deleted from the sentence. This feedback is clear and actionable, as it directs the authors to make a specific change to their draft. However, the comment could be more helpful if it provided additional context or explanation for why this change is necessary or how it might impact the overall clarity of the paper. Nonetheless, the comment is 4 as it offers a concrete suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the font size in Figure 6 is too small, providing a clear and direct action for the authors to take. This feedback is specific and actionable, as it instructs the authors to adjust the font size in Figure 6 to make it more readable. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the font size being too small. This provides clear guidance on what needs to be addressed to improve the figure\"s readability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement about the font size in Figure 6 being too small. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment is brief and points out a specific issue with the font size in Figure 6, indicating that it is too small. While it identifies a potential problem with the figure\"s readability, it lacks depth and does not provide any suggestions or guidance on how to address the issue. The authors are left with a clear problem to fix but without any actionable advice on how to improve the figure. Therefore, the comment is 3, as it highlights a specific issue but does not fully support the authors in resolving it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. This is an explicit action with concrete guidance on how to improve the paper by suggesting a specific area of focus. The comment provides a clear direction for the authors to enhance their work by addressing the issue of interprocess communication and providing examples of relevant problems. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction and the second paragraph, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the lack of clarity in the paper\"s goal and the examples provided, particularly regarding the relevance of samplingbased Bayesian methods. The suggestion to focus on problems where the loss function does not decompose as the sum of sample losses and to consider ERMbased distributed algorithms like Hogwild provides clear guidance on how to address the identified issues. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the examples provided in the paper do not convincingly demonstrate the need for interprocess communication, particularly mentioning the second paragraph where samplingbased Bayesian methods are discussed. The reviewer suggests that the paper\"s results are irrelevant for these methods, which are already embarrassingly parallel. The comment further suggests focusing on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms like Hogwild. While the reviewer provides a logical reasoning for their claim, it lacks specific examples or references to support the assertion that the current examples are insufficient. This makes the claim 3, as it requires more detailed evidence to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the examples provided in the introduction do not convincingly demonstrate the need for interprocess communication. It suggests that the authors focus on problems where the loss function does not decompose as the sum of sample losses, such as Hogwild, to better illustrate the relevance of their work. This feedback is clear and actionable, providing the authors with a concrete direction to enhance the clarity and relevance of their paper. However, the comment could be more helpful if it included specific examples or further elaboration on how to apply the suggested focus. Overall, the comment is 4 as it offers a valuable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should compare CPEF with another pretrained model, such as ExpertBert, to demonstrate the advantage of the innovative pretraining module design of CPEF. This recommendation is clear and provides a specific action for the authors to take, ensuring that the comparison is fair and highlights the unique features of CPEF. The comment is 5 as it gives the authors a concrete step to improve their draft by providing a specific alternative model for comparison.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"line 529534,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison between CPEF and PMEF, noting that PMEF lacks a pretraining module and suggesting a comparison with ExpertBert to showcase the advantage of CPEF\"s pretraining module design. This provides clear guidance on what needs to be addressed to ensure fairness in the comparison. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison between CPEF and PMEF in Figure 3 is unfair because PMEF lacks a pretraining module. The reviewer suggests comparing CPEF with another pretrained model, such as ExpertBert, to demonstrate the advantage of CPEF\"s pretraining module design. This claim is 3 as it provides a logical reasoning for the unfair comparison and suggests an alternative comparison. However, the comment lacks specific examples or references to support the claim fully, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparison between CPEF and PMEF in Figure 3, noting that PMEF lacks a pretraining module, which makes the comparison unfair. It provides a clear and actionable suggestion to address this issue by recommending a comparison with another pretrained model, such as ExpertBert, to showcase the advantage of CPEF\"s innovative pretraining module design. This feedback is 5 as it not only points out a weakness in the current comparison but also offers a concrete solution to improve the fairness and clarity of the results. By following this advice, the authors can enhance the validity and impact of their findings, making the comment highly valuable for improving the draft."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, skewing results and leading to issues of unfairness. However, the comment does not provide explicit guidance on how to address these concerns or suggest specific actions for the authors to take. The action is implicit and vague, as the authors are left to infer that they should consider the potential impact of prior knowledge on fairness and take steps to mitigate it, but without clear instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment provides a specific concern about the potential for the pretrained visual model and target dataset to leak additional information, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, skewing results and leading to issues of unfairness. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider the potential impact of prior knowledge on fairness and explore ways to mitigate it, but the comment does not provide detailed guidance or evidence to substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights a potential issue with the pretrained visual model and target dataset leaking additional information, which could skew results and lead to unfairness. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or ensure fairness in their comparisons. While it identifies an important issue, the feedback is incomplete and does not provide actionable steps for improvement. Therefore, the comment is 3, as it points out a potential problem but does not fully support the authors in resolving it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the FLOT cost matrix in Algorithm 1 is not defined. This provides a clear and direct action for the authors to take, which is to define the FLOT cost matrix in the algorithm. The comment is explicit and concrete, as it specifies exactly what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by stating that the FLOT cost matrix is not defined. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement indicating that the FLOT cost matrix in Algorithm 1 is not defined. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and direct, pointing out a specific issue with the paper: the FLOT cost matrix in Algorithm 1 is not defined. This feedback is actionable and provides a clear direction for the authors to improve their draft by defining the missing matrix. However, the comment could be more helpful if it offered suggestions on how to define the matrix or why it is important for the algorithm. Despite this, the comment is 4 as it effectively identifies a critical gap in the paper and guides the authors toward a necessary correction. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the convergence of the bound in Theorem 2, Eq. (30), specifically asking if it converges to 0 as T goes to infinity. It provides a comparison with a similar bound in Grunewalder et al, 2010, Eq. (27), which is known to converge to 0. The reviewer suggests that the authors should prove whether the second term in Eq. (30) also converges to 0. This feedback is explicit and provides a clear action for the authors to take, which is to address the question of convergence. The comment is 5 as it gives a direct and concrete instruction on what the authors need to do to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 2, Eq. (30)\" and \"Eq. (27) in Grunewalder et al, 2010,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of convergence and asks the authors to prove whether the second term in Eq. (30) converges to 0. The comment provides a clear direction for the authors to address the question raised, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the convergence of the bound in Theorem 2, Eq. (30), and compares it with a similar bound in Grunewalder et al, 2010, Eq. (27), which is known to converge to 0. The reviewer notes that the first term in Eq. (30) converges to 0 but questions whether the second term also converges to 0. This is a logical and reasonable inquiry that requires the authors to provide evidence or reasoning to support their claim. However, the comment does not provide specific examples or references to substantiate the claim further, leaving some gaps in the justification. Therefore, the claim is 4, as it provides a clear direction for the authors to address but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment raises a specific question about the convergence of the bound in Theorem 2, Eq. (30), and compares it with a similar bound in Grunewalder et al, 2010, Eq. (27), which is known to converge to 0. The reviewer points out that while the first term in Eq. (30) converges to 0, it is not trivial to derive that the second term also converges to 0. This feedback is 3 as it identifies a potential gap in the proof or analysis and prompts the authors to address it. However, the comment could be more helpful if it provided additional guidance or suggestions on how to approach the proof or what specific aspects of the convergence need to be clarified. Overall, the comment provides a clear direction for improvement but lacks depth, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, it does not provide any guidance or suggestions on how the authors should address this issue or what alternative terminology or explanations could be used. The action is explicit but lacks concrete details on how to implement the change, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"connectivity,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is misleading about the term \"connectivity,\" namely, that it does not refer to the structural connections between the brain and body. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this term is misleading or how it deviates from the intended meaning. Without additional context or explanation, the claim remains 1, as the authors may not fully understand the basis of the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the term \"connectivity\" in the paper, suggesting that it is misleading because it does not refer to the structural connections between the brain and body. This feedback is 3 as it points out a specific area where the terminology might be confusing. However, the comment lacks depth and does not provide suggestions on how to address this issue or what alternative terms or explanations could be used. While it highlights a potential problem, it does not offer actionable guidance for improvement, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights specific steps in the process and suggests that the authors should focus on studying the essentialness of using an orthogonal matrix, particularly in Step 3. It implies that the authors should investigate and present evidence for the benefits of using an orthogonal matrix, rather than just following a form that connects local and beyond local windows. While the comment provides a clear direction for the authors to explore, it does not offer explicit instructions on how to conduct this study or what specific aspects to focus on. The action is 4 because it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Step 2\" and \"Step 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the study of the essentialness of using an orthogonal matrix in Step 3. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of an orthogonal matrix is essential for certain steps in the process, particularly in Step 3. However, it does not provide specific evidence or references to support this claim. The comment suggests that the authors should study the essentialness of using an orthogonal matrix, but it lacks detailed reasoning or examples to substantiate the claim. This makes the comment 3, as it provides a direction for further investigation but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment provides specific feedback on the steps involved in the process, particularly highlighting the importance of using an orthogonal matrix in Step 3. It suggests that the authors should study the essentialness of using an orthogonal matrix, which is not currently presented in the paper. This feedback is clear and actionable, as it directs the authors to a specific area that needs further investigation and validation. By addressing this point, the authors can enhance the rigor and comprehensiveness of their work. Therefore, the comment is rated as 5, as it offers detailed guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify how they handle comparisons between episodes of different lengths in the equation between lines 282 and 283. It also provides specific details about the method used, which is padding the shorter sequence by replicating its last state, and notes the absence of a normalization factor of 1/T, which affects the distance calculation. The comment suggests that these decisions should be explained to readers without requiring them to check the code. This feedback is explicit and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the equation between lines 282 and 283,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of handling comparisons between episodes of different lengths and suggests that the authors should explain how they handle this in the equation. Additionally, it provides specific details about the method used, such as padding the shorter sequence by replicating its last state, and notes the absence of a normalization factor of 1/T. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the handling of comparisons between episodes of different lengths in the equation between lines 282 and 283. It provides specific details about the method used, such as padding the shorter sequence by replicating its last state, and notes the absence of a normalization factor of 1/T, which affects the distance calculation. The comment also suggests that this decision should be explained to readers without requiring them to check the code. This level of detail and specific reasoning makes the claim 4, as it provides a clear explanation of the issue and its implications. However, the comment could be strengthened by referencing specific literature or studies that support the critique, which would make it 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, namely the handling of comparisons between episodes of different lengths in the equation between lines 282 and 283. It provides detailed feedback by explaining the method used, which involves padding the shorter sequence by replicating its last state, and notes the absence of a normalization factor of 1/T, which affects the distance calculation. The comment suggests that these decisions should be explained to readers without requiring them to check the code, offering a clear and actionable suggestion for improvement. By addressing a technical detail and providing guidance on how to enhance the clarity of the paper, this comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the absence of Vision Transformer in the experiment, noting its importance as a stateoftheart model in image classification. It also questions whether the pruning strategy would differ in selfattention layers for larger datasets like ImageNet. While the comment highlights a potential gap in the study, it does not provide explicit guidance on how the authors should address this issue or what specific experiments or analyses should be conducted to explore the impact of Vision Transformer or the pruning strategy in selfattention layers. The action is implicit and somewhat vague, as the authors can infer that they need to consider including Vision Transformer and exploring its impact, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiment,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the omission of Vision Transformer, an important stateoftheart model in image classification, and questions whether the pruning strategy would differ in selfattention layers for larger datasets like ImageNet. This provides clear guidance on what needs to be addressed in the experiment section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the absence of Vision Transformer in the experiment, noting its importance as a stateoftheart model in image classification. It also questions whether the pruning strategy would differ in selfattention layers for larger datasets like ImageNet. While the comment highlights a potential gap in the study, it lacks specific examples or references to support the claim that Vision Transformer is an important model or that its inclusion would significantly impact the results. The reasoning is somewhat logical but lacks detailed evidence or examples, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experiment by pointing out the absence of Vision Transformer, an important stateoftheart model in image classification. It raises a question about whether the pruning strategy would differ in selfattention layers for larger datasets like ImageNet. This feedback is clear and actionable, as it prompts the authors to consider including Vision Transformer in their experiments and to explore its impact on the pruning strategy. By addressing this gap, the authors can enhance the comprehensiveness and validity of their study. However, the comment could be more helpful if it provided specific suggestions on how to incorporate Vision Transformer or what aspects to focus on. Overall, the comment is 4, as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies several issues with the figures in the paper, specifically mentioning that the text is too small, the inputs and outputs for each task are not clearly explained, and the captions are not selfcontained. It also notes that it is difficult to link the captions to specific parts of the main text. This feedback provides clear and concrete actions for the authors to take, such as increasing the font size of the text in the figures, clarifying the inputs and outputs for each task, and ensuring that the captions are selfcontained and linked to relevant parts of the main text. The explicit nature of the actions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.1 to Fig.3,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also specifies the issues with the figures, such as the small text size, unclear inputs and outputs, and nonselfcontained captions. Additionally, it highlights the difficulty in linking the captions to specific parts of the main text. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figures 1 to 3 are difficult to parse due to small text size, unclear inputs and outputs, and nonselfcontained captions. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues effectively. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies specific issues with the figures in the paper, noting that the text is too small, the inputs and outputs for each task are not clearly explained, and the captions are not selfcontained. It also points out the difficulty in linking the captions to certain parts of the main text. This feedback is clear and actionable, as it provides concrete suggestions for improvement, such as increasing the font size of the text in the figures and clarifying the inputs and outputs for each task. By addressing these issues, the authors can enhance the readability and comprehensibility of their figures, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the continuous diffusion model (GDSS) should be compared as a baseline in Table 3, given its performance in Table 2. It also mentions recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could be used as a baseline. This feedback provides a clear and explicit action for the authors to take, which is to include GDSS as a baseline in Table 3 and consider the recent work as a potential baseline. The suggestion is concrete and directly actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the continuous diffusion model (GDSS) should be compared as a baseline in Table 3, given its performance in Table 2. Additionally, it provides a suggestion for using recent work as a baseline, which adds specificity to the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the continuous diffusion model (GDSS) should be compared as a baseline in Table 3, given its performance in Table 2. It also mentions recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS, suggesting this could be used as a baseline. The comment provides a logical reasoning for the suggestion, as GDSS outperforms the discrete diffusion model (DiGress) in Table 2, and recent work offers a potential baseline for comparison. However, the comment could be strengthened by providing more detailed references or examples from the recent work. Overall, the claim is 4, as it provides a clear rationale but lacks specific references to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by pointing out that the continuous diffusion model (GDSS) outperforms the discrete diffusion model (DiGress) in Table 2. It recommends comparing GDSS as a baseline in Table 3, which is a conditional generation task. Additionally, the comment references recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS, suggesting this could be used as a baseline. This feedback is clear and actionable, offering the authors a concrete way to enhance their draft by incorporating GDSS as a baseline and considering the recent work. However, the comment could be more helpful if it provided more detailed guidance on how to implement these suggestions or why they are important. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should add a comparison against stateoftheart loss functions widely used in face/iris verification, specifically mentioning CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This provides a clear and concrete action for the authors to take, as it specifies exactly which loss functions should be included in the comparison. The comment is 5 because it gives the authors a direct and detailed instruction on how to enhance their draft.", "grounding_specificity_rationale": "The comment suggests adding a comparison against stateoftheart loss functions used in face/iris verification, specifically mentioning CenterLoss, ASoftmax, AMSoftmax, and ArcFace. While it does not explicitly mention a specific section of the paper, the authors can infer that this suggestion relates to the experimental or results sections where comparisons are typically discussed. The comment is specific in detailing the loss functions that should be included in the comparison, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include a comparison against stateoftheart loss functions used in face/iris verification, specifically mentioning CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This claim is 3 as it provides a clear suggestion for improvement by naming specific loss functions that should be considered. However, the comment lacks detailed reasoning or examples of why these loss functions are relevant or how they compare to the current methods used in the paper. Providing more context or explanation would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should include a comparison against stateoftheart loss functions widely used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This feedback is clear and actionable, as it provides specific examples of loss functions that the authors should consider including in their comparison. By addressing this suggestion, the authors can enhance the comprehensiveness and validity of their study by demonstrating how their approach compares to established methods. However, the comment could be more helpful if it offered additional context or rationale for why these specific loss functions are relevant or how they relate to the paper\"s focus on biometric verification learning. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides several explicit actions for the authors to take, including correcting grammatical errors, ensuring consistency in terminology, and correcting formatting issues in tables and references. Each of these actions is clear and concrete, leaving no ambiguity about what needs to be done. The comment is 5 as it provides direct and specific instructions for improvement, allowing the authors to make precise changes to their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and sections of the paper, allowing the authors to accurately identify the parts that need attention. It is also specific because it details the issues, such as grammatical errors, inconsistencies in terminology, and formatting errors in tables and references. The comment provides clear guidance on what needs to be corrected, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements and corrections, such as grammatical errors, inconsistencies in terminology, and formatting issues. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a list of specific corrections and improvements that need to be made to the manuscript. It addresses grammatical errors, inconsistencies in terminology, and formatting issues in tables and references. Each point is clear and actionable, allowing the authors to make precise changes to their draft. However, the comment could be more helpful if it offered additional context or explanations for why these corrections are important or how they might impact the overall quality of the paper. Despite this, the feedback is 4 as it provides concrete steps for improvement, making it a valuable resource for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides several explicit suggestions for improving the clarity and readability of the paper. It suggests spelling out \"F.L.T.R\" in figure 4, addressing the issue of small text in figure 1, and recommending notation and figure crossreferencing. These suggestions are concrete and provide clear actions for the authors to take, ensuring they know exactly what changes to make. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"figure 4,\" \"figure 1,\" and the use of \"M and N\" without definition. This allows the authors to accurately identify the sections being addressed. The comment is also specific because it details the issues with notation, suggests spelling out \"F.L.T.R\" in figure 4, and recommends improving the visibility of figure 1 text and crossreferencing notation and figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple suggestions for improving the clarity and readability of the paper, including clarifying notation, spelling out \"F.L.T.R\" in figure 4, and addressing the small text in figure 1. These suggestions are factual and descriptive, providing guidance on how to enhance the paper without making subjective claims or opinions. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides several actionable suggestions for improving the clarity and readability of the paper. It points out specific issues with notation, such as the use of \"M\" and \"N\" without definition, and suggests spelling out \"F.L.T.R\" in figure 4. Additionally, it highlights the problem of small text in figure 1 and recommends crossreferencing notation and figures. These suggestions are clear and concrete, offering the authors specific ways to enhance the presentation and accessibility of their work. However, the comment could be more helpful if it provided additional context or examples to further clarify the issues. Overall, the feedback is 4 as it provides actionable guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises several specific questions and requests for additional information regarding the experiments, particularly concerning the comparison between YOSO and linformer. It asks for the inclusion of steps vs ppl of linformer with YOSO in Figure 4 and seeks clarification on the comparison results of YOSO with linformer on iterationwise convergence. Additionally, it inquires about the comparison of linformer\"s performance in downstream tasks like SST2 and whether there is an explanation for the observed difference in performance. These questions and requests are explicit and provide clear guidance on what the authors need to address in their draft. The feedback is concrete, as it specifies exactly what information is missing and what comparisons need to be made. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments\" and \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what is missing, namely the comparison results of YOSO with linformer on iterationwise convergence and the explanation for the difference in performance. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several questions and requests for clarification regarding the experiments, specifically about the comparison between YOSO and linformer. It questions the absence of steps vs ppl of linformer with YOSO in Figure 4 and seeks information on the comparison results of YOSO with linformer on iterationwise convergence. Additionally, it inquires about the comparison of linformer\"s performance in downstream tasks like SST2 and whether there is an explanation for the observed difference in performance. While the comment identifies areas that need clarification, it does not provide any supporting evidence, reasoning, or references to substantiate the claims. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific areas for improvement in the experiments section, particularly regarding the comparison between YOSO and linformer. It points out the lack of steps vs ppl of linformer with YOSO in Figure 4 and requests clarification on the comparison results of YOSO with linformer on iterationwise convergence. Additionally, it questions the comparison of linformer\"s performance in downstream tasks like SST2 and suggests an explanation for the observed difference in performance. These specific requests for additional information and analysis provide clear guidance for the authors to enhance their experimental section and improve the comprehensiveness of their results. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of similar comparisons in the literature. Overall, the feedback is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a specific issue with Figure 1, where the reference to \"PointNet\" is confusing due to the absence of this name in the paper and the existence of another paper with the same name. The reviewer provides a clear action for the authors to take by suggesting that they should clarify the reference to avoid confusion. This feedback is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the reference to \"PointNet\" and provides a suggestion to clarify the reference to avoid confusion. The comment also includes a reference to an external work, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,\" by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas, which further supports the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that referring to 15 as \"PointNet\" is confusing due to the absence of this name in the paper and the existence of another paper with the same name. The reviewer supports this claim by providing a reference to the original \"PointNet\" paper, which clarifies the confusion. This external reference provides a clear and specific justification for the claim, making it 5. Therefore, the comment is labeled as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the reference to \"PointNet\" in Figure 1, pointing out that the name does not appear in the paper and is confused with another paper. The reviewer provides a clear suggestion to clarify the reference by mentioning the original \"PointNet\" paper by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. This feedback is actionable and provides a precise direction for improvement, making it 5 for the authors to address the confusion and ensure accuracy in their references. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors need to clarify the threat model by defining the assumed threat model more explicitly, specifying the attacker\"s level of access, capabilities, and the defender\"s available resources. It also recommends including this information in a dedicated section to enhance clarity, particularly regarding the assumed whitebox access to the victim model. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"threat model,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be clarified, such as defining the assumed threat model, specifying the attacker\"s level of access, capabilities, and the defender\"s available resources. Additionally, it suggests including this information in a dedicated section to enhance clarity, particularly regarding the assumed whitebox access to the victim model. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the threat model needs further clarification, specifically regarding the attacker\"s level of access, capabilities, and the defender\"s available resources. The comment provides a clear and logical reasoning for why this clarification is necessary, particularly in the context of whitebox access to the victim model. However, it does not provide specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is 4, as it provides a clear direction for improvement but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need for further clarification of the threat model. It provides clear and actionable feedback by suggesting that the authors define the assumed threat model more explicitly, specifying the attacker\"s level of access, capabilities, and the defender\"s available resources. Additionally, it recommends including this information in a dedicated section to enhance clarity, particularly regarding the assumed whitebox access to the victim model. This feedback is detailed and constructive, offering the authors a clear path to enhance the clarity and comprehensiveness of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific areas where the text could be written more clearly, providing explicit examples of what needs clarification. It suggests that the authors should explain what a proper rotation matrix is in line 97 and clarify the meaning of \"solving the problem of the matrix being non positive semidefinite\" in lines 105106. These are direct and concrete actions that the authors can take to improve their draft. The comment provides clear guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (97 and 105106) where the text could be clarified. This allows the authors to accurately identify the parts of the paper that need improvement. The comment is also specific because it clearly specifies what needs to be addressed: the explanation of a proper rotation matrix and the meaning of solving the problem of the matrix being non positive semidefinite. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that certain parts of the text could be written more clearly, specifically mentioning the need for clarification regarding a proper rotation matrix in line 97 and the meaning of solving the problem of the matrix being non positive semidefinite in lines 105106. However, the comment does not provide any specific reasoning, examples, or references to support these claims. Without additional context or explanation, the authors may find it challenging to understand the exact issues or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific areas where the text could be improved by suggesting that certain parts need to be written more clearly. It provides explicit examples of what needs clarification, such as explaining what a proper rotation matrix is in line 97 and clarifying the meaning of solving the problem of the matrix being non positive semidefinite in lines 105106. This feedback is actionable and provides clear guidance for the authors to enhance the clarity and comprehensibility of their draft. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided additional context. Overall, the comment is 4 as it directs the authors to specific areas needing improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a potential improvement by recommending a change in terminology from \"g activation function\" to \"binary operator,\" similar to the approach by Cohen and Shashua (2016). However, it does not provide explicit guidance on how to implement this change or why it is necessary. The suggestion is implicit and somewhat vague, as the authors are left to infer the exact steps needed to make this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a change in terminology from \"g activation function\" to \"binary operator,\" providing a clear direction for improvement. Additionally, it references a specific work by Cohen and Shashua (2016) to support the suggestion, which further enhances the specificity of the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a change in terminology from \"g activation function\" to \"binary operator,\" referencing a similar approach by Cohen and Shashua (2016). The comment provides a specific reference to support the suggestion, which is a clear and logical reasoning for the proposed change. This level of detail makes the claim 4, as it offers a clear basis for the authors to consider the suggested change. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the terminology used in the paper, recommending a change from \"g activation function\" to \"binary operator.\" It references a similar approach by Cohen and Shashua (2016), which adds context and supports the suggestion. This feedback is clear and actionable, offering the authors a concrete way to enhance the clarity and precision of their work. However, the comment could be more helpful if it explained why this change is necessary or how it might impact the understanding of the paper. Overall, the comment is 4 as it provides a valuable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors consider shrinking the captions of Fig. 1 and Fig. 2 to leave more space for the methods or related work sections. This provides a clear and direct action for the authors to take, along with a concrete suggestion on how to implement it. The comment is explicit and provides specific guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1 and Fig. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the captions, suggesting that they have large overlaps with the content and recommending shrinking them to leave more space for the methods or related work sections. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the captions of Fig. 1 and Fig. 2 have large overlaps with the content, implying that this could be improved by shrinking the captions. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issue or how to address it. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the potential improvements based on the suggestion alone.", "helpfulness_rationale": "The review comment identifies a specific issue with the captions of Fig. 1 and Fig. 2, noting that they have large overlaps with the content. It provides a clear and actionable suggestion to consider shrinking the captions to leave more space for the methods or related work sections. This feedback is direct and offers a concrete way for the authors to improve the layout and organization of their paper, making it 4. However, the comment could be more helpful if it included additional guidance on how to balance the content and captions effectively. Overall, the comment is 4 as it directs the authors toward a specific improvement that can enhance the readability and presentation of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the exclusion of Vidgen et al., 2021, from Table 2, suggesting that it might be similar to the dataset presented in the work. The reviewer questions why this dataset is not used as a potential benchmark for evaluation, particularly for investigating the role of context in detecting hate. While the comment implies that the authors should consider including Vidgen et al., 2021, as a benchmark, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider including this dataset. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of excluding Vidgen et al., 2021, from the table, and questions why this dataset is not used as a potential benchmark for evaluation. The comment provides a clear rationale for why this dataset might be relevant, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the exclusion of Vidgen et al., 2021, from Table 2, suggesting that it might be similar to the dataset presented in the work. The reviewer questions why this dataset is not used as a potential benchmark for evaluation, particularly for investigating the role of context in detecting hate. The comment provides a logical reasoning by pointing out the potential similarity and the absence of this dataset, which could be relevant for the evaluation. However, it lacks specific references or detailed comparisons to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the inclusion of datasets in Table 2, noting the exclusion of Vidgen et al., 2021, which might be similar to the dataset presented in the work. It questions why this dataset is not used as a potential benchmark for evaluation, particularly for investigating the role of context in detecting hate. This feedback is clear and actionable, as it prompts the authors to consider including this dataset for a more comprehensive evaluation. However, the comment could be more helpful if it provided additional context or suggestions on how to incorporate Vidgen et al., 2021, into the evaluation. Overall, the comment is 4 as it directs the authors to a potential area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide more detailed information about the experimental environment, specifically mentioning the CUDA version and the PyTorch version. This is a clear and direct action that the authors can take to improve their draft. The comment also provides a rationale for why this information is important, explaining its potential impact on training and inference speeds. Therefore, the comment is 5, as it provides a specific and concrete action for the authors to follow.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to describe the experimental environment in more detail, specifically referencing the CUDA and PyTorch versions. This allows the authors to accurately identify the part of the paper that needs revision. The comment is also specific because it clearly specifies what needs to be addressed, namely the detailed description of the experimental environment and its potential impact on training and inference speeds. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. The claim is based on the logical reasoning that different versions of the experimental environment can affect training and inference speeds. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the importance of this detail and how it might impact their results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need for a more detailed description of the experimental environment, including the CUDA and PyTorch versions. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the transparency and reproducibility of the experimental setup. By addressing this point, the authors can better inform readers about the conditions under which their experiments were conducted, which is crucial for understanding the results and potential applications. However, the comment could be more helpful if it included additional guidance on how to present this information or why it is particularly important for the specific context of the paper. Overall, the comment is 4 as it directs the authors to a significant improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point consists of two separate statements. The first part discusses the challenge of controlling multiple aspects of variation with fully realistic datasets, but it does not provide any actionable advice or suggestions for addressing this issue. The second part agrees with the authors\" judgment regarding societal impact, which is a factual statement and not a suggestion for improvement. Since neither part offers actionable guidance or specific steps for the authors to take, the comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it addresses, leaving the authors uncertain about where to focus their attention. It also lacks specificity, as it does not detail what aspects of the paper are being discussed or what needs to be improved. The comment consists of two separate statements, one about the challenge of controlling multiple aspects of variation with fully realistic datasets and another agreeing with the authors\" judgment on societal impact. Without clear references or detailed feedback, the authors cannot effectively address the issues raised. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two separate statements. The first statement claims that fully realistic datasets make it hard to control multiple aspects of variation with precision. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The second statement agrees with the authors\" judgment regarding societal impact, which is a factual acknowledgment and does not require verification. Since the first part lacks supporting evidence, the comment is considered 1.", "helpfulness_rationale": "The review comment consists of two separate statements. The first part discusses the challenge of controlling multiple aspects of variation with fully realistic datasets, but it does not provide any actionable advice or suggestions for addressing this issue. The second part agrees with the authors\" judgment regarding societal impact, which is a factual statement and not a suggestion for improvement. Since neither part offers actionable feedback or guidance for the authors to enhance their draft, the comment is 1. It lacks depth and does not provide any insights or suggestions for improvement, making it unhelpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the behavior of the model under higher noise levels, as the current noise value of 3 is not considered high based on the observations in the plot. This implies an action for the authors to take, which is to conduct further analysis under different noise conditions. However, the comment does not provide specific guidance on how to implement this suggestion, such as what specific noise levels to test or how to analyze the results. The action is explicit but somewhat vague, as it lacks detailed instructions on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the simulation study\" and \"the plot compared to the true trajectories,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the discrepancy between the stated standard deviation of the noise (3) and the observed behavior in the plot, suggesting that the authors should study the model\"s behavior under higher noise levels. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the standard deviation of the noise is not high based on observations in the plot compared to the true trajectories. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains somewhat vague and lacks full verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the simulation study, specifically questioning the choice of noise level. It points out that the stated standard deviation of the noise (3) may not be high enough based on observations in the plot compared to the true trajectories. The comment suggests that the authors should study the behavior of the model under higher noise levels to better understand its robustness. This feedback is clear and actionable, providing a specific area for improvement that could enhance the validity and comprehensiveness of the study. However, it could be more helpful if it included suggestions on how to implement this analysis or what specific noise levels to test. Overall, the comment is 4, as it directs the authors to a meaningful area for further investigation."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs, suggesting that this might limit the applications of the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to the draft. The comment lacks actionable details, leaving the authors without a clear understanding of how to improve their work based on this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the bounds and their implications for arbitrarily long inputs, suggesting that this might limit the applications of the approach. However, it does not specify which part of the paper discusses these bounds, making it weakly grounded. The comment is specific in detailing the concern about the limitations of the approach but lacks grounding, as the authors cannot confidently determine which section or part of the paper this comment pertains to. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs, suggesting that this might limit the applications of the approach. However, the comment lacks specific examples or detailed reasoning to support the claim that the bounds would seriously limit the applications. Without additional context or evidence, the authors may find it challenging to understand the full extent of the issue or how to address it. Therefore, the claim is considered 2, as it provides some insight but requires more detailed justification or examples to be 5.", "helpfulness_rationale": "The review comment raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs. It suggests that this might limit the applications of the approach, but it does not provide specific guidance or suggestions on how the authors might address this issue or explore alternative applications. The comment highlights a potential limitation but lacks actionable feedback or detailed insights to help the authors improve their draft. Therefore, it is 2, as it identifies a concern but does not offer sufficient guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses an opinion that Section 2 lacks a clear connection with the methodology section and that the theoretical analysis is simplistic and closely related to reference 1. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the connection between Section 2 and the methodology or how to enhance the theoretical analysis. Without actionable suggestions or specific feedback, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the limited connection with the methodology section and the simplicity of the theoretical analysis, which is closely related to reference 1. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Section 2 lacks a clear connection with the methodology section and that the theoretical analysis is simplistic and closely related to reference 1. However, the comment does not provide specific examples or detailed reasoning to support these claims. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the limited connection between Section 2 and the methodology section, and the simplicity of the theoretical analysis, which is closely related to reference 1. While the comment highlights areas that need improvement, it lacks specific suggestions or guidance on how the authors might address these issues. Without actionable advice or detailed feedback, the authors are left with a general understanding of what needs to be improved but without a clear path forward. Therefore, the comment is 3, as it provides some insight but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses doubt about the paper\"s strength in its current state, questioning whether it is suitable for ICLR. However, it does not provide any specific feedback or suggestions on how the authors might strengthen their contribution or improve the paper. Without actionable guidance or concrete steps for improvement, the authors are left without a clear understanding of what changes are needed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment expresses doubt about the paper\"s strength in its current state, questioning whether it is suitable for ICLR. However, it does not specify which aspects of the paper are lacking or what specific contributions are insufficient. Without detailed guidance or references to specific sections or elements of the paper, the authors cannot confidently determine which parts need improvement. The comment is 1 as it does not identify a specific area of the paper, and it is also not specific in detailing what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a subjective opinion about the paper\"s strength, specifically questioning whether it is suitable for ICLR. However, it lacks any supporting evidence, reasoning, or examples to justify this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the reviewer\"s doubt. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a doubt about the paper\"s strength in its current state, questioning whether it is suitable for ICLR. However, it does not provide any specific feedback or suggestions on how the authors might strengthen their contribution or improve the paper. Without actionable guidance or detailed critique, the authors are left without a clear understanding of what changes are needed to enhance their work. This lack of specificity and actionable advice makes the comment unhelpful, as it does not offer any meaningful direction for improvement. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that experiments in deep reinforcement learning (RL) should be run multiple times to address the issue of reproducibility and the significance of improvements. It references a community effort towards reproducibility and suggests that this should be considered in the paper. The comment explicitly states the need for running multiple experiments and reporting statistics, providing a clear and concrete action for the authors to take. This feedback is 5 as it specifies exactly what needs to be done to improve the draft, making it easy for the authors to implement the suggested changes. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments\" and \"deep RL,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of reproducibility and the need for running multiple experiments and reporting statistics. The reference to a community effort towards reproducibility and the suggestion to consider this in the paper further enhance the specificity of the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that experiments in deep reinforcement learning should be run multiple times to address issues of reproducibility and the significance of improvements. It references a community effort towards reproducibility and cites a specific paper by Henderson et al. (2018) as evidence. This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or specific statistics on how running multiple experiments would improve reproducibility. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment addresses a critical issue in deep reinforcement learning (RL) experiments, specifically the lack of reproducibility and the significance of improvements. It suggests that running multiple experiments and reporting statistics is crucial for addressing these concerns. The comment also references a community effort towards reproducibility, providing a specific example from the literature. This feedback is 5 as it identifies a significant weakness in the current draft and offers a clear and actionable suggestion for improvement. By emphasizing the importance of reproducibility and providing a reference to support the claim, the comment empowers the authors to enhance the rigor and credibility of their work. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to check Figure 2, Line 433, and Line 468 for consistency in the punctuation of equations. It clearly specifies the actions needed to address the issue, which is to ensure that all equations end with either a period or a comma consistently. This feedback is direct and provides concrete guidance on what the authors need to do to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, namely \"Figure 2, Line 433, and Line 468,\" allowing the authors to accurately identify the sections that need attention. It is also specific because it clearly specifies the issue of inconsistent punctuation in equations, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual observation about the punctuation of equations in the paper, specifically mentioning Figure 2, Line 433, and Line 468. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the punctuation of equations in the paper, suggesting that some end with a period while others end with a comma. It provides clear and actionable feedback by instructing the authors to ensure consistency in the punctuation of equations. This feedback is direct and helps the authors to make a precise correction, which is valuable for improving the clarity and professionalism of their draft. However, the comment could be more helpful if it explained why consistency in punctuation is important or provided examples of how it affects the readability of the paper. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point raises a question about the origin of the figures in Figure 1, asking whether they are generated from real experiments or artificially. It also suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon observed in the figures. This feedback is explicit in its request for clarification and provides a clear action for the authors to take, which is to conduct realworld experiments if the figures are artificially generated. The suggestion is concrete, as it specifies what the authors need to do to address the concern. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: whether the figures are generated by real experiments or artificially, and if artificially, whether the authors can conduct realworld experiments to support the phenomenon observed. This provides clear guidance on what the authors need to clarify or address in their work. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the origin of the figures in Figure 1, asking whether they are generated by real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon observed. However, the comment does not provide any evidence, reasoning, or references to support the claim that conducting realworld experiments is necessary or beneficial. The lack of supporting information makes the claim difficult for the authors to address effectively, rendering it 1.", "helpfulness_rationale": "The review comment raises a critical question about the origin of the figures in Figure 1, asking whether they are generated from real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon observed. This feedback is highly relevant and actionable, as it prompts the authors to clarify the basis of their results and potentially conduct additional experiments to strengthen their claims. By addressing this concern, the authors can enhance the credibility and validity of their work. Therefore, the comment is rated as 5, as it provides clear and actionable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that including an example and a figure would be beneficial in explaining the definition of uniform shattering. While the comment implies that the authors should add these elements, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to include examples and figures but are not provided with specific guidance on how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where this explanation is needed. Without explicit references or context, the authors may find it challenging to determine where to incorporate these suggestions. The comment is specific in its suggestion but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not provide any reasoning or evidence to support why these would be beneficial or how they would improve the clarity of the definition. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that including an example and a figure would be beneficial in explaining the definition of uniform shattering. This feedback is clear and actionable, as it provides a specific suggestion for improving the clarity and comprehensibility of the paper. By incorporating examples and figures, the authors can enhance the reader\"s understanding of the concept, making the comment 4. However, the comment could be more helpful if it offered guidance on what specific aspects of the definition should be illustrated or how the examples and figures should be presented. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the assumption among classes is not practical and notes that the formulation or definition is somewhat trivial. However, it suggests that the value of the paper lies in its optimization and theoretical property analysis, from which conclusions or insights can be gained. While the comment identifies a potential issue with the assumption, it does not provide explicit guidance on how to address it or improve the draft. The authors are left to infer that they should focus on the optimization and theoretical aspects, but without concrete suggestions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the assumption among classes, noting that it is not practical and that the formulation or definition is somewhat trivial. However, it highlights the value of the paper in its optimization and theoretical property analysis, from which conclusions or insights can be gained. The comment does not specify which part of the paper discusses these assumptions or how they relate to the optimization and theoretical aspects. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the assumption among classes is not practical and notes that the formulation or definition is somewhat trivial. However, it suggests that the value of the paper lies in its optimization and theoretical property analysis, from which conclusions or insights can be gained. The comment provides a logical reasoning by distinguishing between the practicality of the assumption and the potential value of the paper in other areas. While the reasoning is clear, it lacks specific examples or references to support the claim about the optimization and theoretical aspects. Therefore, the comment is 3, as it provides a logical basis but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment acknowledges that the assumption among classes is not practical but notes that the formulation or definition is somewhat trivial. It highlights the value of the paper in its optimization and theoretical property analysis, suggesting that insights or conclusions can be gained from this aspect. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not guide the authors on how to address the issue with the assumption or how to enhance the optimization and theoretical aspects. As a result, the comment is 3, as it identifies a potential area of improvement but does not offer detailed guidance for the authors to act upon. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a lack of clarity in some explanations, specifically mentioning the last paragraph of Section 3 (lines 207210) regarding the single image case. However, it does not provide explicit guidance on how to improve the clarity or what specific aspects need to be clarified. The comment raises questions and comments, but these are not actionable as they do not offer concrete steps for the authors to take. The feedback is vague and lacks detail, making it difficult for the authors to know exactly what changes to make. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment identifies a lack of clarity in some explanations, specifically mentioning the last paragraph of Section 3 (lines 207210) regarding the single image case. This provides full grounding as it explicitly mentions a specific section and lines, allowing the authors to accurately identify the part of the paper being addressed. However, the comment is not specific in detailing what aspects of the explanation are vague or how they could be clarified. Therefore, the comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that some explanations are \"a little vague,\" specifically mentioning the last paragraph of Section 3 (lines 207210) regarding the single image case. However, it does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The comment lacks concrete evidence or references to substantiate the claim of vagueness, rendering it 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the explanations are vague, pointing out the last paragraph of Section 3 (lines 207210) regarding the single image case. This feedback is 3 as it directs the authors to a particular section that needs clarification. However, the comment lacks depth and does not provide specific suggestions or guidance on how to improve the clarity of the explanation. Without actionable advice or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of direct comparisons between the proposed approach and the prior approach PRANC in both language and vision tasks. It notes that while there are comparisons of training loss and the rank of possible solutions, there is no direct comparison of test accuracy. This feedback implies that the authors should include a direct comparison of test accuracy to demonstrate whether their approach is an improvement over the baseline. However, it does not provide specific guidance on how to conduct this comparison or what metrics to use. The action is implicit and somewhat vague, as the authors can infer the need for a direct comparison but may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4\" and \"Section 3.5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of direct comparisons with the prior approach PRANC in terms of test accuracy, despite comparisons of training loss and the rank of possible solutions. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of direct comparisons between the proposed approach and the prior approach PRANC in terms of test accuracy, despite comparisons of training loss and the rank of possible solutions. This claim is 3 as it highlights a gap in the evaluation process, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to consider the implications of this gap and how it affects the validity of the proposed approach. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation of the proposed approach, specifically the lack of direct comparisons with the prior approach PRANC in both language and vision tasks. It highlights that while there are comparisons of training loss and the rank of possible solutions, there is no direct comparison of test accuracy, which is crucial to determine if the proposed approach is an improvement over the baseline. This feedback is clear and actionable, as it directs the authors to include a direct comparison of test accuracy to strengthen their evaluation. However, it could be more helpful if it provided specific suggestions on how to conduct these comparisons or what metrics to use. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct experiments on generation tasks that are more likely to require a wellperforming language model, such as language modeling, machine translation, or text summarization. This is an explicit action with concrete details on how to implement it, as it specifies the types of experiments that could strengthen the paper\"s claims about the importance of language modeling capability. The authors know exactly what experiments to conduct to address the reviewer\"s concern, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experiments conducted, namely that they do not adequately reflect the language modeling capability. The comment further suggests including tasks like language modeling, machine translation, or text summarization to strengthen this part, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s experiments on word similarity and SQuAD in section 5.3 do not adequately reflect the language modeling capability of pretrained models. The reviewer suggests that including tasks like language modeling, machine translation, or text summarization would strengthen this part of the paper. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that these tasks are more relevant to language modeling. This makes the claim 3, as it requires additional evidence or detailed reasoning to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper, noting that the experiments conducted in section 5.3 do not adequately reflect the language modeling capability of pretrained models. It suggests that the authors should consider including tasks like language modeling, machine translation, or text summarization to strengthen this part of the paper. This feedback is clear and actionable, providing the authors with a concrete direction for improving their draft by addressing a critical aspect of their claims. However, the comment could be more helpful if it offered additional guidance on how to design or conduct these experiments. Overall, the comment is 4, as it effectively guides the authors toward enhancing the relevance and validity of their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the improvement of the proposed method over existing RL methods is not impressive. However, it does not provide any specific guidance or suggestions on how the authors could improve their method or address this issue. There is no explicit or implicit action for the authors to take, leaving them without a clear understanding of what changes are needed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment claims that the improvement of the proposed method over existing RL methods is not impressive. However, it does not specify which part of the paper this claim is based on, nor does it provide details on what aspects of the improvement are lacking. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the improvement are not impressive. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvement of the proposed method over existing RL methods is not impressive. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or comparisons to existing methods, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment claims that the improvement of the proposed method over existing RL methods is not impressive. However, it lacks specificity and does not provide any detailed feedback or suggestions on how the authors could enhance their method or address this issue. Without actionable guidance or examples, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the novelty of the work is limited because the design is not new, as attention for motion learning has been widely used in video understanding. However, the comment does not provide any specific guidance or suggestions on how the authors could address this issue or improve the novelty of their work. There is no explicit or implicit action for the authors to take, leaving them without a clear path for improvement. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the work, specifically mentioning that the design is not new due to the widespread use of attention for motion learning in video understanding. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity as it does not provide details on how the novelty could be improved or what specific aspects of the design are not novel. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the work is limited because the design is not new, as attention for motion learning has been widely used in video understanding. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out that the novelty of the work is limited due to the widespread use of attention for motion learning in video understanding. However, it does not provide any specific suggestions or guidance on how the authors could enhance the novelty of their work or address this critique. Without actionable feedback or detailed insights, the comment lacks utility for the authors in improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors provide a plot of the model illustration, pseudocode table, or code repository to clarify the model design and learning details. It also emphasizes the importance of demonstrating integrated details, especially since Neurochaos Learning is not a wellknown method. This feedback is clear and provides concrete actions for the authors to take, ensuring they know exactly what steps to take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2 Unclear model design,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the model architecture and learning details are fragmented or missing, and suggests providing a plot of the model illustration, pseudocode table, or code repository to facilitate reproducibility. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the model design is unclear due to fragmented or missing details. It suggests providing a plot of the model illustration, pseudocode table, or code repository to facilitate reproducibility, especially since Neurochaos Learning is not a wellknown method. The comment provides a logical reasoning for the need for clarity and suggests specific ways to address the issue, making it 4. However, it could be strengthened by providing examples or references to similar practices in the field, which would further support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the model design, noting that the architecture and learning details are fragmented or missing. It provides specific suggestions for improvement, such as including a plot of the model illustration, pseudocode table, or code repository. This feedback is actionable and constructive, as it offers concrete steps for the authors to take to enhance the clarity and reproducibility of their work, particularly given the novelty of the Neurochaos Learning method. By addressing these suggestions, the authors can significantly improve the comprehensibility and usability of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include rejection rates in their experiments or to view them as misclassifications in the results. This provides a clear and direct action for the authors to take, ensuring they understand exactly what needs to be done to address the comment. The feedback is concrete and actionable, as it specifies both options for how to incorporate rejection rates into the results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of missing rejection rates and suggests either including them or viewing them as misclassifications in the results. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the rejection rate is not shown in any experiments and suggests including it or viewing it as misclassifications in the results. This claim is 3 as it highlights a potential omission in the experimental results. However, the comment lacks specific examples or references to support why the rejection rate is important or how it could impact the analysis. Providing more context or examples would strengthen the justification, making the claim more verifiable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the experimental results by pointing out that the rejection rate is not shown. It provides a clear suggestion for improvement by recommending that the authors either include the rejection rates or consider them as misclassifications in the results. This feedback is actionable and offers a concrete way for the authors to enhance their analysis. However, the comment could be more helpful if it explained why the rejection rate is important or how it might impact the interpretation of the results. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional context or rationale."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that Figure 1 could be optimized to use less whitespace. However, it does not provide any specific guidance or suggestions on how to achieve this optimization. The action is implicit, as the authors need to infer that they should reduce the whitespace in Figure 1, but it is vague because it lacks concrete details on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the optimization of Figure 1 to use less whitespace. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 1 could be optimized to use less whitespace. However, it does not provide any reasoning, examples, or references to support why this optimization is necessary or beneficial. The comment lacks specific details or evidence to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that Figure 1 could be optimized by using less whitespace. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance on how to achieve this optimization. The authors are left with a vague suggestion without actionable steps to enhance their figure. Therefore, the comment is 2, as it offers minimal value in terms of actionable feedback for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper formatting is off and does not follow the NeurIPS formatting style. It specifically mentions issues with the abstract font size and bottom page margins. The reviewer suggests that by fixing these formatting issues, the authors could gain space and include the NLP experiments in the main body of the paper. This feedback provides clear and concrete actions for the authors to take, such as ensuring the paper adheres to the NeurIPS formatting guidelines and adjusting the font size and margins accordingly. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the paper formatting, specifically the abstract font size and the bottom page margins, which are clear indicators of the parts of the paper being addressed. It also provides specific guidance on how to address these issues, such as ensuring the paper follows the NeurIPS formatting style and gaining space to include NLP experiments in the main body. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper formatting is off and does not follow the NeurIPS formatting style, specifically mentioning issues with the abstract font size and bottom page margins. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact nature of the formatting issues. Without detailed evidence or examples, the claim is 3, as it lacks the necessary justification to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper formatting, noting that it does not follow the NeurIPS formatting style. It points out specific problems, such as the abstract font size being too large and the bottom page margins being altered. The comment provides actionable feedback by suggesting that fixing these formatting issues could help the authors gain space and include NLP experiments in the main body of the paper. This feedback is clear and constructive, offering a direct path for the authors to improve their draft. However, it could be more helpful if it included examples or specific guidance on how to adjust the formatting. Overall, the comment is 4 as it effectively guides the authors toward improving the presentation of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to change the label on the color bar in Fig. 4 to \"worse\". This is a direct and concrete action that the authors can take to improve their draft. The comment clearly specifies what needs to be done, providing a precise instruction for modification. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the color bar, suggesting that one of the labels should be changed to \"worse.\" This provides clear guidance on what needs to be corrected. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement requesting a change to the label on the color bar in Fig. 4. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it identifies a particular issue with the color bar in Fig. 4 and suggests a correction by recommending that one of the labels should be changed to \"worse.\" This feedback is clear and provides a direct way for the authors to improve their draft by ensuring that the color bar accurately represents the data. However, the comment could be more helpful if it explained why this change is necessary or how it would enhance the clarity of the figure. Overall, the comment is 4 as it offers a specific and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a specific error in the text, indicating that the phrase \"\u2026training/validation/test\" should be corrected to \"\u2026training/validation/test sets.\" This provides clear and direct guidance on what needs to be changed in the draft. The action is explicit and concrete, leaving no ambiguity for the authors on how to implement the suggested correction. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 757 in Supp. Page 29,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error, which is the incorrect use of \"\u2026training/validation/test\" instead of \"\u2026training/validation/test sets.\" This provides clear guidance on what needs to be corrected. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement pointing out a specific error in the text, \"\u2026training/validation/test\" should be corrected to \"\u2026training/validation/test sets.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific error in the text, providing clear and actionable feedback. By pointing out the incorrect phrase \"\u2026training/validation/test\" and suggesting the correction to \"\u2026training/validation/test sets,\" the reviewer offers a precise and straightforward way for the authors to improve their draft. This level of detail and specificity empowers the authors to make a direct and meaningful correction, enhancing the overall quality and accuracy of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the definition of the quantile is confusing and proposes two potential solutions: adding an extra pair of brackets around the term or defining the bracketed term separately if space allows. While the comment provides explicit suggestions, it does not specify which part of the paper the definition is located in, making it somewhat vague in terms of execution. The authors know what actions to take but may need to search the paper to identify the exact location of the definition. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"definition of the quantile,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific suggestions for improving the clarity of the definition, such as adding extra brackets or defining the bracketed term separately. This level of detail helps the authors understand what needs to be addressed and how to make the necessary changes. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the definition of the quantile is confusing and proposes two potential solutions: adding extra brackets or defining the bracketed term separately. However, the comment does not provide any reasoning or evidence to support why the current definition is confusing or how the suggested changes would improve clarity. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of the quantile, suggesting that it is confusing. It provides two potential solutions to improve clarity: adding an extra pair of brackets around the term or defining the bracketed term separately if space allows. This feedback is clear and actionable, offering the authors concrete steps to enhance the readability and understanding of their work. By addressing this issue, the authors can improve the comprehensibility of their paper, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses an expectation for the paper to include a variety of tasks beyond link prediction where PE (Positional Encoding) is important. However, it does not provide any explicit or implicit guidance on how the authors should address this expectation. There is no suggestion on which tasks should be included, how to incorporate them, or what specific aspects of PE are relevant. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper should include a variety of tasks beyond link prediction where Positional Encoding (PE) is important. However, it does not specify which part of the paper this expectation relates to, nor does it provide details on what specific tasks or aspects of PE should be included. This makes it difficult for the authors to identify the exact sections that need attention or improvement. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an expectation for the inclusion of various tasks beyond link prediction where Positional Encoding (PE) is important. However, it does not provide any supporting evidence, reasoning, or references to justify why this expectation is relevant or necessary. The lack of justification or context makes it difficult for the authors to understand the basis of the expectation, rendering the comment 1.", "helpfulness_rationale": "The review comment suggests that the paper should include a variety of tasks beyond link prediction where Positional Encoding (PE) is important. While it identifies a potential area for expansion, it lacks specificity and does not provide guidance on which tasks should be included or how to incorporate them. The comment does not offer actionable advice or detailed suggestions for improvement, leaving the authors with a general idea but no clear direction on how to enhance their work. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a set of fewshot demonstrations could be included to enhance the paper, and it would be beneficial to discuss this. However, it does not provide explicit guidance on how to obtain these demonstrations or how to incorporate them into the paper. The comment also questions the inclusion of zeroshot generation results, suggesting that it might be unnecessary. While the authors are given some direction, the lack of concrete steps or detailed guidance makes the action vague and difficult to execute. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"a set of fewshot demonstrations\" and \"zeroshot generation results,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as the inclusion of a discussion about fewshot demonstrations and the relevance of zeroshot generation results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the inclusion of zeroshot generation results is \"a bit strange\" and questions their relevance. However, the comment does not provide specific reasoning or evidence to support this claim, such as why these results are unnecessary or how they might be misleading. Without detailed justification or examples, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting the inclusion of a set of fewshot demonstrations, which could enhance the paper. It also questions the inclusion of zeroshot generation results, suggesting that they might not be necessary. However, the comment lacks specific guidance on how to implement the suggested fewshot demonstrations or why the zeroshot results are unnecessary. While it provides some direction, the feedback is incomplete and could be more actionable with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a minor issue with Figure 3, noting that \"OAA\" is not referenced in the body text and suggesting that there might be missing content in the appendix or an outdated caption. While the comment identifies the problem, it does not provide explicit instructions on how to address it. The authors are left to infer that they need to either update the caption, include the missing content, or clarify the reference to \"OAA\" in the body text. The action is implicit and somewhat vague, as the authors are not given specific guidance on how to resolve the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that \"OAA\" is not referenced in the body text and suggesting that there might be missing content in the appendix or an outdated caption. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about Figure 3, noting that \"OAA\" is not referenced in the body text. It suggests that there might be missing content in the appendix or an outdated caption. However, the comment does not provide specific examples or detailed reasoning to support the claim that the content is missing or the caption is outdated. This lack of detailed justification makes the claim 3, as the authors would need to investigate further to understand the issue fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a minor issue with Figure 3, noting that \"OAA\" is not referenced in the body text. It suggests that there might be missing content in the appendix or that the caption is outdated. This feedback is 3 as it points out a potential inconsistency or missing reference in the paper, prompting the authors to review and correct this issue. However, the comment could be more helpful if it provided specific guidance on how to address the issue or suggested potential solutions. Overall, the comment is 3 as it directs the authors to a specific area needing attention, but it lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to clarify in the introduction that their proposed solution is a \"fix\" of an existing work, rather than a new approach. It also specifies that the authors should mention the existing work 12 and its relation to their framework. This feedback provides clear and concrete guidance on what the authors need to do to improve their draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction and lines 2930, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: the distinction between the proposed solution being a \"fix\" of an existing work rather than a new approach. Additionally, it points out the need to mention the existing work 12 and its relation to the framework. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors must clarify in the introduction that their proposed solution is a \"fix\" of an existing work, rather than a new approach. The reviewer supports this claim by referencing specific lines in the paper (2930) and mentioning the existing work 12. This provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the existing work relates to the proposed solution. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by pointing out a potential confusion in the introduction. It highlights that the authors need to clarify that their proposed solution is a \"fix\" of an existing work, rather than a new approach, as initially introduced. This feedback is specific and helps the authors avoid misrepresenting their contribution. By suggesting that the authors should mention the existing work 12 and its relation to their framework, the comment offers a concrete step for improvement. However, it could be more helpful if it provided additional context or examples of how the existing work relates to the proposed solution. Overall, the comment is 4 as it directs the authors to a critical area for clarification, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests two specific comparisons that the authors should make: one with NeRFbased methods, such as Zero1to3, and another with pointe. It also questions the relevance of the occlusion experiment, suggesting that it may not be relevant to the method being proposed. While the comment implies that these comparisons and the evaluation of the occlusion experiment are necessary, it does not provide explicit instructions on how to conduct these comparisons or why the occlusion experiment is not relevant. The actions are implicit and somewhat vague, as the authors need to infer the specific steps to take and the reasoning behind the suggestions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests comparisons with NeRFbased methods, specifically mentioning Zero1to3 and pointe. It also questions the relevance of the occlusion experiment, suggesting that it may not be specific to the method being proposed. However, the comment does not specify which part of the paper these suggestions should be made in, such as the methodology or results sections. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting comparisons and questioning the relevance of the occlusion experiment, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper lacks comparison with NeRFbased methods, specifically mentioning Zero1to3 and pointe. It also questions the relevance of the occlusion experiment, suggesting that it may not be specific to the method being proposed. However, the comment does not provide detailed reasoning or evidence to support why these comparisons are necessary or how they would improve the paper. The lack of specific examples or references makes the claim 3, as the authors would need to infer the importance of these comparisons and the relevance of the occlusion experiment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by suggesting comparisons with NeRFbased methods, specifically mentioning Zero1to3 and pointe. It also questions the relevance of the occlusion experiment, suggesting that it may not be specific to the method being proposed. While the comment highlights areas for improvement, it lacks depth and does not provide detailed guidance on how to conduct these comparisons or why the occlusion experiment is not relevant. The feedback is 3 as it points out potential weaknesses, but it could be more actionable with additional suggestions or explanations. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides two explicit actions for the authors to take. First, it suggests adding a brief explanation of \"multiaspect\" at specific line numbers (14 and 47), which is a clear and concrete instruction. Second, it requests a correction in Figure 1, specifying that the subscripts \"s\" and \"t\" should be \"1\" and \"2,\" respectively. These actions are explicit and provide detailed guidance on what needs to be done, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (14 and 47) and a figure (Figure 1), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the need for a brief explanation of \"multiaspect\" and the correction of subscripts in Figure 1. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two separate requests for clarification and correction. The first request for a brief explanation of \"multiaspect\" is a factual statement asking for additional information, which does not contain a claim. The second request for correcting subscripts in Figure 1 is also factual and does not express an opinion or judgment. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides two specific and actionable suggestions for improving the clarity and accuracy of the paper. First, it requests a brief explanation of the term \"multiaspect,\" which would help readers understand the context. Second, it points out a potential error in Figure 1, suggesting that the subscripts \"s\" and \"t\" should be \"1\" and \"2,\" respectively. These suggestions are clear and concrete, offering the authors direct guidance on how to enhance the readability and precision of their work. By addressing these issues, the authors can improve the overall quality and clarity of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests considering alternative methods, such as freezing some layers of the model while training a few layers or using parameterefficient methods like LoRA, for experimental comparison. While the comment implies that the authors should explore these methods, it does not explicitly instruct them to do so. The suggestion is concrete, as it provides specific alternatives to consider, but it is implicit in the sense that the authors need to infer the action from the suggestion. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests exploring alternative methods, such as freezing some layers of the model or using parameterefficient methods like LoRA, for experimental comparison. However, it does not specify which part of the paper this suggestion should be applied to, making it weakly grounded. The comment is specific in suggesting alternative methods for experimental comparison, which provides clear guidance on what the authors could consider. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests considering alternative methods, such as freezing some layers of the model or using parameterefficient methods like LoRA, for experimental comparison. The comment provides a logical reasoning by suggesting that these methods are \"natural to think about\" and could offer a valuable basis for comparison. However, it lacks specific examples or references to support the claim that these methods are particularly relevant or beneficial. While the suggestion is reasonable, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests exploring alternative methods, such as freezing some layers of the model or using parameterefficient methods like LoRA, for experimental comparison. This feedback is clear and actionable, as it provides specific suggestions for improving the experimental design and potentially enhancing the paper\"s contributions. By considering these methods, the authors can gain a deeper understanding of their model\"s performance and make more informed decisions about their approach. However, the comment could be more helpful if it included a rationale for why these methods are relevant or how they might impact the results. Overall, the comment is 4 as it offers constructive guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing citation for the public skipgram data set in line 425. This provides clear and direct guidance to the authors on what action to take: they need to include the missing citation. The comment is explicit and concrete, as it specifies the exact line where the citation is missing and what needs to be added. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L425,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of missing citations for the public skipgram data set. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement indicating a missing citation for the public skipgram data set in line 425. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and direct, pointing out a specific issue with missing citations for the public skipgram data set in line 425. This feedback is actionable and provides the authors with a precise step to take to improve their draft by ensuring all necessary citations are included. However, the comment could be more helpful if it explained why the citation is important or how it impacts the paper\"s credibility. Despite this, the comment is 4 as it effectively guides the authors toward a necessary correction."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the model\"s performance on the triangle dataset, specifically asking why it does not fully succeed in identifying true sources. It prompts the authors to consider whether one of the assumptions is not satisfied or if there are learning difficulties. However, the comment does not provide explicit guidance on how to address these questions or what specific actions the authors should take to improve their draft. The questions are implicit and lack concrete details on how to execute the suggested actions. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the model\"s performance on the triangle dataset, specifically asking why it does not fully succeed in identifying true sources. However, it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in its questioning of the model\"s performance and potential assumptions or learning difficulties, but without clear references to specific sections or elements of the paper, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the model\"s performance on the triangle dataset, specifically asking why it does not fully succeed in identifying true sources. It prompts the authors to consider whether one of the assumptions is not satisfied or if there are learning difficulties. However, the comment lacks specific evidence, examples, or references to support these claims, making it difficult for the authors to understand the basis of the questions. The lack of detailed reasoning or supporting information renders the claim 2, as it provides some direction for further investigation but requires more substantial justification.", "helpfulness_rationale": "The review comment raises a question about the model\"s performance on the triangle dataset, specifically why it does not fully succeed in identifying true sources. It prompts the authors to consider whether one of the assumptions is not satisfied or if there are learning difficulties. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this problem or improve their model. The feedback is 3 as it points out a weakness, but it does not provide actionable steps for improvement, leaving the authors with a general direction but no detailed path forward. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the discussion on the arbitrary hyperparameter \u03b3 is missing, including how to set it in practice for a given graph and analyzing its sensitivity. This provides a clear action for the authors to take: they need to include a discussion on how to set \u03b3 and its sensitivity. The comment is explicit and concrete, as it specifies exactly what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"discussion on arbitrary hyperparameter \u03b3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: a discussion on how to set \u03b3 in practice for a given graph and an analysis of its sensitivity. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the discussion on the arbitrary hyperparameter \u03b3 is missing, which would make it difficult for researchers to follow. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning on why this discussion is crucial. The lack of supporting evidence or detailed justification makes the claim 3, as the authors would need to infer the importance of discussing \u03b3 and its sensitivity based on general knowledge of hyperparameter tuning in graphrelated research. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the discussion of the arbitrary hyperparameter \u03b3, specifically noting the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. This feedback is clear and actionable, as it highlights a critical area that needs attention to enhance the comprehensibility and usability of the paper for researchers. By addressing this gap, the authors can provide valuable insights and practical advice, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper is too dense and difficult to follow, requiring multiple reads to grasp the concepts and contribution. It provides a clear action for the authors to simplify the description and explain the architecture and computations better. Additionally, it suggests specific sections and lines that can be reduced to gain more space. This feedback is direct and provides concrete guidance on how to improve the clarity and readability of the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7, Section 8\" and \"lines 3964,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of the paper being too dense and difficult to follow, and it provides actionable suggestions for simplifying the description and explaining the architecture and computations better. The comment also suggests reducing specific sections to gain more space. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is too dense and difficult to follow, requiring multiple reads to grasp the concepts and contribution. The reviewer suggests simplifying the description and explaining the architecture and computations better, specifically mentioning Figure 7, Section 8, and lines 3964 as areas for reduction. While the comment provides a clear suggestion for improvement, it lacks specific examples or detailed reasoning to support the claim that the paper is overly dense. This makes the claim 3, as the authors would need to infer the exact issues and how to address them based on the general feedback provided.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s density and difficulty in following the concepts and contribution. It provides a clear and actionable suggestion to simplify the description and explain the architecture and computations better. The comment also specifies particular sections, such as Figure 7, Section 8, and lines 3964, that can be reduced to gain more space. This feedback is valuable as it offers concrete guidance on how to improve the clarity and readability of the paper, making it 4 for the authors. However, it could be more helpful if it included additional suggestions or examples of how to simplify the content. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point provides several suggestions for improvement, including a request to discuss the experiment results more thoroughly and to clarify the realworld applications of the new problem setting. It also raises a question about the computational complexity of the proposed algorithm when applied to ranking problems. While the comment identifies areas that need attention, it does not provide explicit instructions or detailed guidance on how to address these issues. The authors can infer that they need to discuss the experiment results more, clarify the applicability, and consider the computational complexity, but the comment lacks concrete steps or examples to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiment results\" and \"the realworld applications,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific points for improvement, such as discussing the results of the Streetview experiment and clarifying the applicability to sorting/ranking problems. Additionally, it raises a question about the computational complexity of the proposed algorithm when applied to ranking problems. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises several claims, including the need for more discussion of experiment results and the lack of clarity in realworld applications. The comment suggests that the Streetview experiment results may indicate that MaxGapTop2UCB is better than other methods, but it does not provide specific data or analysis to support this claim. Additionally, it questions the applicability to sorting/ranking problems and raises concerns about computational complexity, but these points are not fully substantiated with detailed reasoning or references. The comment lacks sufficient evidence and detailed justification, making it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two main areas for improvement: the discussion of experiment results and the clarity of realworld applications. It suggests that the experiment results could be more thoroughly discussed, particularly in relation to the Streetview experiment, where it questions whether MaxGapTop2UCB is better than other methods. Additionally, it points out the lack of clarity in the realworld applications, specifically mentioning the applicability to sorting/ranking problems and the computational complexity of the proposed algorithm. The comment provides some guidance by questioning the applicability and suggesting a need for more detailed discussion. However, it lacks specific suggestions or examples on how to address these issues, which limits its helpfulness. Therefore, the comment is 3, as it highlights important areas for improvement but could be more comprehensive in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to clarify whether the results for model (3) (Chung et al. 2016) for CsEn were computed by the authors themselves or taken from the papers. It provides a clear action for the authors to take, which is to mention the source of these results. This feedback is concrete and direct, giving the authors a specific step to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results for model (3) (Chung et al. 2016) for CsEn, noting that these results were not taken from the papers and suggesting that the authors should mention if they computed these results themselves. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results for model (3) (Chung et al. 2016) for CsEn were not taken from the papers, as they are not reported. The reviewer suggests that if the authors computed these results themselves, they should mention it. This claim is based on a logical observation and a request for clarification, making it 3. The reviewer provides a clear rationale for the claim, but it lacks specific references or detailed examples to fully substantiate the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in Table 1, noting that the results for model (3) (Chung et al. 2016) for CsEn were not taken from the papers, as they are not reported. The comment suggests that if the authors computed these results themselves, they should mention it. This feedback is clear and actionable, providing the authors with a direct way to improve the transparency and accuracy of their results. By addressing this point, the authors can enhance the credibility and reliability of their work. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively, given that different prompts can lead to varying performance outcomes. While the comment implies that the authors should focus on prompt design and discuss its effectiveness, it does not provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer that they need to enhance the discussion on prompt design without detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively, given that different prompts can result in varying performance outcomes. However, the comment does not specify which part of the paper should focus on prompt design or provide specific guidance on what aspects of prompt design need more emphasis. While the authors can infer that the discussion on prompt design should be enhanced, the comment lacks full grounding as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that more emphasis should be placed on prompt design, given the introduction of several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively, as different prompts can lead to varying performance outcomes. However, the comment lacks specific examples or detailed reasoning to support the claim that prompt design is a critical area for improvement. While the suggestion is logical, it requires more elaboration to be 5. Therefore, the comment is 3, as it provides a general direction but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment suggests that the paper should place more emphasis on prompt design, given the introduction of several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively, as different prompts can lead to varying performance outcomes. This feedback is clear and actionable, as it identifies a specific area for improvement and provides a direction for the authors to enhance their work. However, it could be more helpful if it offered specific suggestions or examples on how to effectively design prompts. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions regarding the choice of 0.6 for glove embedding similarity, the use of kcrossvalidation, and the potential impact of using other influential loss functions. While it implies that the authors should provide more information or justification for their choices, it does not explicitly instruct them to do so. The suggestions are concrete, such as considering kcrossvalidation and alternative loss functions, but the action is not directly stated. Therefore, the comment is 4, as it provides clear guidance on what the authors should consider but does not explicitly instruct them to make changes.", "grounding_specificity_rationale": "The comment raises several questions and suggestions regarding the choice of 0.6 for glove embedding similarity, the use of kcrossvalidation, and the potential impact of using other influential loss functions. However, it does not specify which part of the paper these questions and suggestions relate to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its questions and suggestions but lacks grounding, as it does not provide a clear reference to the specific sections or elements of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and suggestions regarding the choice of 0.6 for glove embedding similarity, the use of kcrossvalidation, and the potential impact of using other influential loss functions. However, it does not provide any supporting evidence, reasoning, or references to justify these questions or suggestions. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the questions and suggestions, rendering the comment 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises several questions and suggestions regarding the choice of 0.6 for glove embedding similarity, the use of kcrossvalidation, and the potential impact of using other influential loss functions. It prompts the authors to provide more information about their methodology and suggests exploring alternative approaches. While the comment identifies areas that could benefit from further explanation or exploration, it lacks specific guidance or actionable steps for the authors to take. The feedback is 3 as it points out potential weaknesses and areas for improvement, but it could be more comprehensive with detailed suggestions or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to make the legends in Tables 1, 2, and 3 longer and to clarify whether the numbers represent percentage errors or percentage correct values. This feedback provides a clear and direct action for the authors to take, ensuring that the legends are more informative and accurate. The comment is specific and concrete, offering a straightforward path for the authors to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the legends should be longer and clarify whether the numbers represent percentage errors or percentage correct values. This provides clear guidance on how to improve the clarity of the tables. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the legends in Tables 1, 2, and 3 should be longer and clarify whether the numbers represent percentage errors or percentage correct values. This is a factual statement requesting clarification, as it does not express an opinion or judgment that requires verification. It is purely descriptive and does not contain any subjective claims or suggestions that need justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the legends in Tables 1, 2, and 3 should be longer and clarify whether the numbers represent percentage errors or percentage correct values. This feedback is clear and directly addresses a potential source of confusion in the paper, offering a concrete step for the authors to improve the clarity and readability of their results. By making these changes, the authors can enhance the understanding of their findings for readers. Therefore, the comment is rated as 5, as it provides detailed guidance that can significantly improve the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit actions for the authors to take, including describing how G is built using the human skeleton, specifying the size and elements of G, and adding the dimensions of G, X, and W to better understand the DGCN. These instructions are clear and concrete, giving the authors a direct understanding of what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as describing how G is built using the human skeleton, specifying the size and elements of G, and adding the dimensions of G, X, and W. This level of detail helps the authors understand exactly what changes are needed to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual requests for clarification and additional information, such as asking for a description of how G is built using the human skeleton and suggesting the inclusion of dimensions for G, X, and W. These are not subjective claims or opinions but rather requests for clarification or additional details. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by asking for a detailed description of how G is built using the human skeleton in Section 3.3. It also suggests adding the dimensions of G, X, and W to better understand the DGCN. This feedback is clear and directs the authors to specific areas where additional information is needed to enhance the clarity and comprehensiveness of their draft. By addressing these points, the authors can improve the readability and understanding of their work. Therefore, the comment is rated as 4, as it offers constructive guidance for improvement but could be further enhanced by providing more detailed suggestions or examples."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that while the concept of energy is introduced in Section 3.1, it would be beneficial to refresh the idea in Section 5.2, where it is used multiple times. The reviewer also suggests providing hints on how to interpret energy, such as its relation to splitting morphemes. Additionally, the comment points out that the concept of peak in Figure 5 is not described. These suggestions are explicit and provide concrete guidance on how to improve the draft by clarifying the use of energy and peak in the paper. The authors know exactly what actions to take to enhance their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 5.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the concept of energy should be refreshed in Section 5.2 and providing hints on how to interpret it. Additionally, it points out the lack of description for the concept of peak in Figure 5. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the concept of energy should be refreshed in Section 5.2, where it is used multiple times, and provides a hint about how to interpret it. It also points out that the concept of peak in Figure 5 is not described. While the comment identifies areas for improvement, it lacks specific reasoning or examples to fully substantiate the claim. The suggestion to refresh the concept of energy and provide hints for interpretation is logical, but the comment could be strengthened by providing more detailed justification or references. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper. First, it suggests that the concept of energy, introduced in Section 3.1, should be refreshed in Section 5.2, where it is used multiple times. This is a clear and actionable suggestion that could enhance the clarity and coherence of the paper. Second, the comment points out that the concept of peak in Figure 5 is not described, which is an important omission that could impact the reader\"s understanding of the results. The reviewer provides a hint about how to interpret energy, which is a valuable suggestion for improving the paper. Overall, the comment is 4 as it offers specific and actionable feedback that can guide the authors in enhancing their draft. However, it could be more comprehensive by providing additional suggestions or examples to fully address the issues raised. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of detail in the paper regarding the models, specifically the grammar over kernels. It questions the explanation of how this approach is applied in practice and asks about the probabilities associated with the grammar and how inference is performed. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these gaps. The authors can infer that they need to provide more detailed explanations, but the comment lacks concrete guidance on what specific details to include or how to present them. Therefore, the comment is 3, as it points out areas for improvement but does not fully direct the authors on how to implement those improvements.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the details of the models\" and \"grammar over kernels,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014details about the grammar over kernels, the associated probabilities, and how inference is performed. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some details of the models are missing, specifically the explanation of grammar over kernels. It questions the understanding of how this approach is applied in practice and asks about the probabilities associated with the grammar and how inference is performed. While the comment raises valid concerns about the lack of detail, it does not provide specific examples or references to support the claim. The reasoning is somewhat logical, but it lacks concrete evidence or detailed explanations, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the explanation of the grammar over kernels. It highlights the need for a more detailed explanation of how this approach is applied in practice, including the probabilities associated with the grammar and how inference is performed. This feedback is clear and actionable, as it directs the authors to provide additional details that would enhance the understanding and applicability of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of similar approaches that could serve as a reference. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that the end of Section 4.2 claims Transfer Lasso shows the best accuracy in feature screening but fails to cite or compare with previous works on Lasso screening, such as Ren et al. \"Safe feature screening for generalized LASSO.\" This feedback is explicit in its request for the authors to include these references for a more comprehensive comparison. However, it does not provide detailed guidance on how to incorporate these references or what specific aspects of the previous works should be discussed. While the action is clear, the lack of detailed instructions makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the end of Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of citation or comparison with previous works on Lasso screening, such as Ren et al. \"Safe feature screening for generalized LASSO.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper fails to cite or compare with previous works on Lasso screening, specifically mentioning Ren et al. \"Safe feature screening for generalized LASSO.\" This claim is verifiable as it provides a specific reference to an external work that should be considered for comparison. The mention of a specific publication and the context of Lasso screening provides a clear basis for the claim, making it 4. However, the comment could be strengthened by explaining why these references are relevant or how they relate to the current work. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the end of Section 4.2 claims Transfer Lasso shows the best accuracy in feature screening but fails to cite or compare with previous works on Lasso screening, such as Ren et al. \"Safe feature screening for generalized LASSO.\" This feedback is helpful as it points out a gap in the literature review and suggests that the authors should include these references for a more comprehensive comparison. By highlighting this omission, the comment provides the authors with a clear direction for improvement, enhancing the draft by ensuring it is more comprehensive and accurate. However, the comment could be more helpful if it offered suggestions on how to integrate these references or what specific aspects of the previous works should be discussed. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests clarifying the title to specify that it refers to machine comprehension of text, rather than human reading comprehension. This is an explicit action that the authors can take to improve their draft. The comment provides a clear direction on what needs to be changed, making it concrete and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the title, suggesting that it is ambiguous and should be clarified to distinguish between machine comprehension of text and human reading comprehension. The comment provides a clear direction for improvement by suggesting how to clarify the title. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the title is ambiguous and could be clarified to specify that it refers to machine comprehension of text, rather than human reading comprehension. The reviewer provides a logical reasoning by explaining the common understanding of \"reading comprehension\" and \"readability,\" which supports the claim that the title is ambiguous. However, the comment could be strengthened by providing specific examples or references to clarify the distinction further. Overall, the claim is 4, as it provides a clear rationale but lacks detailed examples or references to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the title of the paper, suggesting that it could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. This is a clear and actionable suggestion that could help the authors improve the clarity and accuracy of their title. By providing a specific direction for improvement, the comment is 4, as it guides the authors in enhancing the clarity and precision of their work. However, it could be more helpful if it included additional context or examples to further support the suggestion. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the limited evaluation on only two datasets, which are standard in the RNP community. The comment provides specific references to external works that could be used for comparison, such as 1 DiversitySensitive Conditional Generative Adversarial Networks. ICLR 2019, 2 Controlling Selection Bias in Causal Inference. AISTATS 2012, 3 An empirical study on robustness to spurious correlations using pretrained language models. TACL 2020, and 4 On Feature Learning in the Presence of Spurious Correlations. NeurIPS 2022. While the comment implies that the authors should include confidence intervals and evaluate on more datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of confidence intervals for results and the limited evaluation on only two datasets, which are standard in the RNP community. It provides specific references to external works, such as 1 DiversitySensitive Conditional Generative Adversarial Networks. ICLR 2019, 2 Controlling Selection Bias in Causal Inference. AISTATS 2012, 3 An empirical study on robustness to spurious correlations using pretrained language models. TACL 2020, and 4 On Feature Learning in the Presence of Spurious Correlations. NeurIPS 2022. However, the comment does not explicitly mention which part of the paper discusses the results or the evaluation, making it weakly grounded. The authors can infer that it relates to the results or methodology sections, but this inference is not direct. The comment is specific in detailing what is missing, such as confidence intervals and additional datasets. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not provide confidence intervals for their results, making it unclear whether performance gains are statistically significant. It also notes the limited evaluation on only two datasets, which are standard in the RNP community. The comment supports its claim by referencing external works, such as 1 DiversitySensitive Conditional Generative Adversarial Networks. ICLR 2019, 2 Controlling Selection Bias in Causal Inference. AISTATS 2012, 3 An empirical study on robustness to spurious correlations using pretrained language models. TACL 2020, and 4 On Feature Learning in the Presence of Spurious Correlations. NeurIPS 2022. These references provide a basis for the claim that the evaluation should include more datasets and confidence intervals. However, the comment could be strengthened by providing more detailed reasoning or examples of how the lack of confidence intervals affects the interpretation of results. Overall, the claim is 4, as it provides some support but could be further substantiated with more detailed analysis or examples.", "helpfulness_rationale": "The review comment identifies two significant issues with the paper: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the limited evaluation on only two datasets, which are standard in the RNP community. The comment provides specific references to external works that could be used for comparison, such as 1 DiversitySensitive Conditional Generative Adversarial Networks. ICLR 2019, 2 Controlling Selection Bias in Causal Inference. AISTATS 2012, 3 An empirical study on robustness to spurious correlations using pretrained language models. TACL 2020, and 4 On Feature Learning in the Presence of Spurious Correlations. NeurIPS 2022. This feedback is clear and actionable, as it directs the authors to include confidence intervals and evaluate on more datasets, potentially using the referenced works as benchmarks. However, the comment could be more helpful if it provided specific guidance on how to incorporate these elements or suggested alternative datasets for evaluation. Overall, the comment is 4, as it offers valuable insights and references for improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the improvements of the proposed model over the RL without feedback model, noting that the differences are not significant, particularly for BLEU1. The reviewer suggests that the authors should verify if these improvements are statistically significant. While the comment implies that the authors should conduct a statistical analysis to address this concern, it does not provide explicit instructions on how to perform the analysis or what specific tests to use. The action is implicit and somewhat vague, as the authors need to infer the need for a statistical analysis and figure out the details themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"row3 vs. row4 in table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of the improvements not being significant, particularly for BLEU1, and suggests that the authors verify if these improvements are statistically significant. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the improvements of the proposed model over the RL without feedback model are not significant, particularly for BLEU1. The reviewer provides specific references to rows 3 and 4 in Table 6, which allows the authors to verify the claim by examining the data. However, the comment lacks detailed reasoning or examples to fully substantiate the claim of statistical insignificance. While the reference to specific rows in the table provides some basis for the claim, the lack of additional evidence or analysis makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the improvements of the proposed model over the RL without feedback model are not significant, particularly for BLEU1. It suggests that the authors verify if these improvements are statistically significant, which is a clear and actionable piece of feedback. By pointing out this potential issue, the comment helps the authors to focus on a critical aspect of their work that may impact its validity and conclusions. However, the comment could be more helpful if it provided additional guidance on how to conduct the statistical analysis or what specific tests to use. Overall, the comment is 4 as it directs the authors to a significant area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without negatively impacting the performance of the predictive model. While the comment implies that the authors should provide a demonstration or example of this, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify how to achieve this demonstration or what specific aspects of the method should be highlighted. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without negatively impacting the predictive model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, the comment does not provide specific guidance on how to achieve this demonstration or what aspects of the method should be highlighted. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without negatively impacting the performance of the predictive model. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this demonstration is necessary or how it would be beneficial. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without negatively impacting the performance of the predictive model. This is a clear and actionable suggestion that could help the authors improve their draft by providing a more comprehensive evaluation of their method. However, the comment could be more helpful if it offered specific guidance on how to achieve this demonstration or what aspects of the method should be highlighted. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential source of confusion in the manuscript, where the symbol \"P\" is used to represent both a probability and a cumulative distribution function. However, it does not provide explicit guidance on how to resolve this issue or suggest specific actions for the authors to take. The comment implies that the authors should clarify the usage of \"P\" to avoid confusion, but it lacks concrete details on how to achieve this clarification. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific equations (Eqs. (3) and (4)) and a line number (L44) in the appendix, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the confusion caused by the use of \"P\" to represent both a probability and a cumulative distribution function. This provides clear guidance on what needs to be clarified or corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the symbol \"P\" is used inconsistently in the manuscript, sometimes representing a probability and other times a cumulative distribution function. The reviewer provides specific examples by referencing equations (3) and (4) and line 44 in the appendix, which helps to substantiate the claim. This level of detail provides a clear basis for the claim, making it 4. However, the comment could be strengthened by explaining why this inconsistency is problematic or how it affects the understanding of the manuscript. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the manuscript, namely the inconsistent use of the symbol \"P\" to represent both a probability and a cumulative distribution function. It provides examples from the paper, such as Eqs. (3) and (4) and L44 in the appendix, which helps the authors pinpoint the exact locations of the confusion. This feedback is clear and actionable, as it directs the authors to clarify the usage of \"P\" to avoid confusion. However, the comment could be more helpful if it suggested specific ways to resolve the issue, such as recommending a consistent notation or providing examples of how to clarify the text. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity and consistency of their manuscript."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the lack of a clear definition for the \"contrastive gap,\" which is a critical concept in the paper. It acknowledges that an intuitive example is provided but notes that the setting of this example is less convincing. The comment implies that the authors need to provide a clear, formal definition for the contrastive gap. While the action is implicit, it is concrete in suggesting that the authors should define the concept more formally. This provides the authors with a clear direction on how to improve their draft, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"contrastive gap,\" which is a specific concept in the paper. It also provides a clear indication of what is lacking, namely a formal definition for the contrastive gap. The comment suggests that while an intuitive example is given, it is not convincing, and a clear definition is needed. This level of specificity helps the authors understand exactly what needs to be addressed in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed \"contrastive gap\" is unclear and lacks a formal definition. It acknowledges that an intuitive example is provided but questions the setting of this example, suggesting that it is less convincing. The comment implies that a clear definition is necessary but does not provide specific examples or references to support the claim. While the reviewer highlights the issue, the lack of detailed justification or evidence makes the claim 3. The authors would need to infer the specific areas needing clarification or definition, which could be challenging without further guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the lack of a clear definition for the \"contrastive gap,\" which is a central concept in the work. It acknowledges that an intuitive example is provided but notes that the setting of this example is less convincing. The comment highlights the need for a clear, formal definition of the contrastive gap, which is essential for understanding and evaluating the work. This feedback is actionable and provides a clear direction for the authors to improve their draft by addressing the definition and clarity of the contrastive gap. However, the comment could be more helpful if it offered suggestions on how to define the concept or provided examples of similar definitions in related literature. Overall, the comment is 4, as it effectively points out a significant weakness and guides the authors toward improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the notation used in the text and the notation used in Figure 1, specifically noting that \"L_task\" is used in the text but \"L_class\" is used in Figure 1. This comment explicitly identifies the inconsistency and suggests that the authors should ensure consistency in their notation across the paper. However, it does not provide specific guidance on how to resolve this issue, such as suggesting which notation to use or how to update the figure. The action is explicit but somewhat vague, as the authors know what needs to be corrected but may not be entirely sure of the best approach to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in notation, noting that \"L_task\" is used in the text but \"L_class\" is used in Figure 1. This provides clear guidance on what needs to be addressed, ensuring that the authors know exactly what part of the paper requires revision. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about a discrepancy in notation between the text and Figure 1. It does not express an opinion, suggestion, or claim that requires verification. It is purely descriptive, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment identifies a specific inconsistency in notation between the text and Figure 1, noting that \"L_task\" is used in the text but \"L_class\" is used in Figure 1. This feedback is clear and actionable, as it directly points out a potential source of confusion for readers. By addressing this inconsistency, the authors can improve the clarity and consistency of their paper. However, the comment could be more helpful if it suggested which notation should be used consistently throughout the paper. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take, specifically requesting citations for certain statements in the paper. This feedback is clear and direct, leaving no ambiguity about what needs to be done. The authors know exactly which lines to address and what type of information is needed to support the claims. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (7879, 129130, 156158, and 217218), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014citations for certain claims. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements requesting citations for specific claims made in the paper. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying instances where citations are needed to support claims made in the paper. It highlights the importance of referencing previous work and evidence to substantiate assertions, particularly in lines 7879, 129130, 156158, and 217218. This feedback is clear and direct, guiding the authors on how to enhance the credibility and rigor of their work by incorporating necessary citations. However, the comment could be more helpful if it offered suggestions on which specific studies or references might be relevant for the cited claims. Overall, the comment is 4 as it directs the authors to improve the paper\"s documentation and credibility."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests two actions: first, to include the bottomup method 9 in the tables, and second, to evaluate the performance of the method on the standard MS coco dataset to assess any potential drop in performance in easy (nonoccluded) settings. Both suggestions are explicit and provide clear guidance on what the authors should do to improve their draft. The first suggestion is concrete, as it specifies the inclusion of a particular method in the tables, and the second is also concrete, as it outlines a specific evaluation to be conducted. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"the bottomup method 9,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests including the bottomup method in the tables and evaluating the performance on the standard MS coco dataset to assess any potential drop in performance in easy (nonoccluded) settings. This provides clear guidance on what needs to be addressed and improved in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the bottomup method 9 has reported results on the crowdpose dataset that outperform all methods in Table 4, even when using a ResNet50. It recommends including this method in the tables and evaluating the performance on the standard MS coco dataset to assess any potential drop in performance in easy (nonoccluded) settings. While the claim is based on a reference to another work, it lacks specific details or examples from the referenced work to fully substantiate the claim. The authors would need to verify the claim by consulting the referenced work, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting the inclusion of the bottomup method 9 in the tables, as it has reported results outperforming all methods in Table 4, even with a ResNet50. This recommendation is clear and could help the authors improve the comprehensiveness of their results. Additionally, the comment suggests evaluating the performance of the method on the standard MS coco dataset to assess any potential drop in performance in easy (nonoccluded) settings. This suggestion is also constructive and could lead to a more thorough analysis of the method\"s performance. However, the comment could be more helpful if it provided more detailed guidance on how to incorporate these suggestions or why they are important. Overall, the feedback is 4 as it offers specific and actionable suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the experimental section should include comparisons with methods that are aware of point coordinates, such as TFN or SchNet. This is an explicit action that provides specific examples of methods to consider for comparison. The comment is clear and concrete, giving the authors a direct and actionable step to improve their draft by including these comparisons. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a comparison with coordinateaware methods like TFN or SchNet, providing clear guidance on what needs to be addressed in the experimental section. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experimental section should include comparisons with methods that are aware of point coordinates, such as TFN or SchNet. This claim is 3 as it provides a logical reasoning for the comparison, suggesting that including such methods would enhance the evaluation of the paper. However, the comment lacks specific examples or detailed justification for why these methods are relevant or how they would improve the analysis. Therefore, the claim is 3, as it provides a basis for the suggestion but requires more detailed support for full verification.", "helpfulness_rationale": "The review comment identifies a specific limitation in the experimental section, noting that it only compares to methods that are unaware of point coordinates, except for input features. It suggests that a comparison to coordinateaware methods, such as TFN or SchNet, would be appropriate. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their experimental evaluation. By suggesting a comparison to coordinateaware methods, the comment offers a concrete way for the authors to improve the comprehensiveness and validity of their results. Therefore, the comment is rated as 5, as it effectively guides the authors in enhancing their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that further optimization and validation are needed for the binder design provided by ProtPainter, specifically noting that it only offers an empirical conformation estimation. However, the comment does not provide explicit guidance on how to achieve this optimization and validation. The authors are left to infer that they need to conduct additional experiments or analyses to improve the binder design, but without specific instructions on what these experiments should entail or how to validate the results. This lack of concrete guidance makes the action vague and difficult for the authors to implement. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the \"binder design\" aspect of ProtPainter, suggesting that it only provides an empirical conformation estimation and that further optimization and validation are required. However, it does not specify which part of the paper discusses the binder design or where this issue is presented, making it weakly grounded. The comment is specific in identifying the need for further optimization and validation, but without clear references to specific sections or elements of the paper, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that ProtPainter only provides an empirical conformation estimation for binder design and suggests that further optimization and validation are required. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion for further optimization and validation. Therefore, the claim is considered 2, as it provides some basis for the suggestion but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific limitation in the paper, namely that ProtPainter only provides an empirical conformation estimation for binder design and suggests that further optimization and validation are required. This feedback is clear and actionable, as it points out a particular area where the authors could improve their work by conducting additional experiments or analyses. However, the comment could be more helpful if it provided specific suggestions or examples of how to approach this optimization and validation. Despite this, the feedback is 4 as it directs the authors\" attention to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests clarification on the training of the model in Figure 7, specifically asking about the stimulus used and whether the duration of the cycle changes. It also references a specific study (Smirnakis et al. Nature 1997) to provide context for the adaptation time scale. This feedback is clear and direct, providing the authors with specific actions to take to address the reviewer\"s concerns. The inclusion of a reference to a relevant study adds concrete guidance on how to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: the training of the model in Figure 7, including the stimulus used and the potential impact of changing the cycle duration on the adaptation time scale. The reference to Smirnakis et al. (1997) provides additional context and specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the training of the model in Figure 7, specifically asking about the stimulus used and whether the duration of the cycle changes. It also references a study by Smirnakis et al. (1997) to provide context for the adaptation time scale. While the comment raises a valid point, it does not provide any evidence or reasoning to support the claim that the model cannot handle longer time scales. The reference to the study is mentioned but not fully integrated into the argument. Therefore, the comment is 3, as it lacks detailed justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area of concern regarding the training of the model in Figure 7. It asks for clarification on the stimulus used and whether the duration of the cycle changes, which could impact the adaptation time scale. The reference to Smirnakis et al. (1997) provides a relevant context for understanding the potential implications of the model\"s limitations. However, the comment could be more helpful if it offered suggestions on how to address these concerns or provided additional guidance on what specific information should be included in the clarification. Overall, the feedback is clear and actionable, making it 4 for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to plot a figure showing the decline in accuracy of a predictor over time in different settings to support their claim about the motivation. This is a clear and direct action that provides specific guidance on what needs to be done to improve the draft. The authors know exactly what action to take and how to implement it, making this comment 5.", "grounding_specificity_rationale": "The comment addresses the issue of the evidence for the motivation being indirect and suggests that the authors should plot a figure showing the decline in accuracy of a predictor over time in different settings. While it does not explicitly mention a specific section or figure, the authors can infer that it relates to the introduction or motivation section, where the problem is described. The comment is specific in suggesting a particular type of figure that could support the claim, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the evidence for the motivation is not direct and suggests that the authors should plot a figure showing the decline in accuracy of a predictor over time in different settings. This claim is 3 as it provides a logical reasoning for why the evidence is lacking and offers a specific suggestion for improvement. However, the comment could be strengthened by providing examples or references to similar studies that have successfully demonstrated this decline in accuracy. Without these additional details, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the evidence provided for the motivation, noting that it is not direct. It suggests a concrete action for the authors to take by recommending that they plot a figure showing the decline in accuracy of a predictor over time in different settings. This feedback is clear and actionable, providing the authors with a specific way to enhance the evidence supporting their claim. By addressing this suggestion, the authors can strengthen their argument and improve the clarity of their draft. Therefore, the comment is rated as 4, as it offers a constructive and actionable piece of feedback that can significantly enhance the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and requests for clarification regarding the definition and calculation of excessive risk, particularly in relation to the expectation and the representation of fairness. It explicitly asks the authors to explain more about the definition of excessive risk, how it is calculated in practice, and whether the values are comparable among different groups. The comment also questions the use of excessive risk as a representation of fairness. While the questions are clear and direct, the comment does not provide specific guidance on how the authors should address these issues or what specific changes they should make to their draft. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 103,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the definition of excessive risk, how it is calculated, and whether the values are comparable among different groups. The comment further questions the use of excessive risk as a representation of fairness, providing a clear direction for the authors to address these concerns. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions and concerns about the definition and calculation of excessive risk, particularly in relation to its representation in Figures 3 and 7. The reviewer questions the positivity of excessive risk values and their comparability across different groups. While the comment highlights potential issues with the representation of excessive risk, it does not provide specific evidence, examples, or references to support these claims. The lack of detailed reasoning or supporting data makes the claims 3, as the authors would need to delve deeper into the paper to fully understand and address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several important questions and concerns about the definition and calculation of excessive risk, particularly in relation to its representation in Figures 3 and 7. It questions the positivity of excessive risk values and their comparability across different groups, which are critical aspects of the paper. The comment also challenges the use of excessive risk as a representation of fairness, prompting the authors to provide a clearer explanation of their approach. By highlighting these gaps and inconsistencies, the comment provides the authors with actionable feedback to improve the clarity and robustness of their work. However, it could be more helpful if it offered specific suggestions or examples on how to address these issues. Overall, the comment is 4, as it identifies key areas for improvement and encourages the authors to provide more detailed explanations."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include experiments with GPT3.5, a more affordable option, to provide a more comprehensive evaluation of their proposed approach. This is an explicit action with concrete details on how to implement it, as it specifies the alternative model to be used. The authors know exactly what needs to be done to enhance their draft, making this comment 5.", "grounding_specificity_rationale": "The comment suggests including experiments with GPT3.5, a more affordable option, to provide a more comprehensive evaluation of the proposed approach. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to these sections, the authors may find it challenging to determine where to incorporate this suggestion. The comment is specific in suggesting the use of GPT3.5, but it lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests including experiments with GPT3.5 as a more affordable alternative to GPT4, to provide a more comprehensive evaluation of the proposed approach. The claim is 3 as it provides a logical reasoning for the suggestion, noting the expense of GPT4 and the potential benefits of using GPT3.5. However, the comment lacks specific examples or references to support the claim that GPT3.5 would be a suitable or effective alternative. This makes the claim 3, as it requires the authors to infer the potential benefits and feasibility of using GPT3.5 based on the reviewer\"s suggestion.", "helpfulness_rationale": "The review comment suggests including experiments with GPT3.5, a more affordable option compared to GPT4, to provide a more comprehensive evaluation of the proposed approach. This feedback is clear and actionable, as it offers a specific suggestion for enhancing the experimental setup. By incorporating GPT3.5, the authors can gain a better understanding of their approach\"s effectiveness and robustness across different models. However, the comment could be more helpful if it provided additional context or reasoning for why GPT3.5 is a suitable choice or how it might impact the results. Overall, the comment is 4 as it provides a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include bold numbers for the baselines of previous work in Table 4. It also specifies that for WMT17WIKT, the best result in terms of BLEU is actually in the baselines, providing clear guidance on what needs to be corrected. This feedback is direct and concrete, leaving no ambiguity for the authors on how to implement the suggested changes. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear instructions on what needs to be included, namely bold numbers for the baselines of previous work, and specifies that the best result in terms of BLEU for WMT17WIKT is actually in the baselines. This level of detail guides the authors on what changes to make, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification and does not contain a subjective claim or opinion. It is a factual statement asking for a specific change in the presentation of results in Table 4. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by requesting that the authors include bold numbers for the baselines of previous work in Table 4. It also points out a discrepancy in the results for WMT17WIKT, noting that the best result in terms of BLEU is actually in the baselines. This feedback is clear and directs the authors to make a precise correction, which can enhance the clarity and accuracy of their presentation. However, the comment could be more helpful if it offered additional context or explanation for why this correction is important or how it might impact the interpretation of the results. Overall, the comment is 4 as it provides concrete guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for examples of \"unreliable neighbors\" mentioned in lines 170 to 171. This request is clear and direct, providing the authors with a specific action to take to address the comment. The feedback is concrete, as it specifies exactly what the authors need to provide to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 170 to 171, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for examples of \"unreliable neighbors,\" which clearly specifies what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking for examples of \"unreliable neighbors\" mentioned in lines 170 to 171. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of the paper that requires clarification. By asking for examples of \"unreliable neighbors,\" the reviewer highlights a potential gap in the explanation or evidence provided in the paper. However, the comment lacks depth and does not offer suggestions on how the authors might address this issue or provide examples themselves. While it points out a specific area for improvement, it does not provide detailed guidance or actionable steps for the authors to enhance their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the work\"s interesting findings but notes that the novelty is limited. It provides a specific observation that tighter CIs with finetuning are expected due to taskspecific finetuning increasing confidence for a specific task while potentially reducing generalizability. However, the comment does not offer any explicit or implicit actions for the authors to take to address this issue or improve the novelty of their work. It lacks guidance on how the authors might enhance the novelty or address the limitations mentioned. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the work, specifically mentioning the observation of tighter CIs with finetuning. However, it does not specify which part of the paper discusses these findings or where the novelty is limited. The authors might infer that it relates to the results or discussion sections, but this is not explicitly stated. The comment is specific in its critique of the novelty but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the novelty of the work is limited, specifically mentioning that tighter CIs with finetuning are expected due to taskspecific finetuning. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. The reasoning is based on a general understanding of finetuning effects, but without specific data or studies to back it up, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment acknowledges the work\"s interesting findings but notes that the novelty is limited. It provides a specific observation that tighter CIs with finetuning are expected due to taskspecific finetuning increasing confidence for a specific task while potentially reducing generalizability. However, the comment does not offer any actionable suggestions or guidance on how the authors might enhance the novelty or address the limitations mentioned. The feedback is 3 as it identifies a potential area for improvement but lacks depth and specific advice, leaving the authors with limited direction for enhancing their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides a specific and explicit suggestion for improving the readability of Tables 4 and 5. It recommends splitting each table into two separate tables, one for each measure (SFII and SPDI), to enhance clarity. This feedback is clear and actionable, as it gives the authors a direct instruction on how to improve the presentation of their data. The suggestion is concrete, providing a clear path for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improving the readability of these tables by splitting them into two tables each, one for each measure (SFII and SPDI). This detailed guidance helps the authors understand exactly what needs to be done to enhance the clarity of their presentation. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Tables 4 and 5 would be more readable if they were split into two tables each, with one table per measure. This is a logical suggestion based on the structure of the tables, as it would allow for clearer organization and easier comparison of the data. However, the comment does not provide specific examples or references to support why this change would improve readability, making it 3. The authors would need to infer the reasoning behind the suggestion, which could lead to some confusion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the readability of Tables 4 and 5. By recommending that each table be split into two, with one table per measure (SFII and SPDI), the comment offers a clear and concrete way for the authors to enhance the clarity and organization of their data presentation. This feedback is valuable as it directly addresses a potential issue with the current format, allowing the authors to make a tangible improvement to their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should specify what \"valid\" and \"orig\" differ in, as shown in Fig. 5. This is an explicit action that provides clear guidance on what needs to be clarified in the figure. The comment is concrete because it directly instructs the authors on how to improve their draft by providing more detailed information about the differences between \"valid\" and \"orig.\" Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need to explain the difference between \"valid\" and \"orig\" in Fig. 5. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the labels \"valid\" and \"orig\" in Fig. 5. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where the authors could improve their draft by clarifying the differences between \"valid\" and \"orig\" in Fig. 5. This feedback is actionable, as it directs the authors to provide more detailed information in the figure, which could enhance the clarity and understanding of the results. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the feedback is clear and provides a specific direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors could improve their paper by making the comparisons with the related work of Zemel et al. (2013) more systematic. It specifically recommends comparing the best performance of each method, implying that the authors should provide a more detailed and structured comparison. While the comment is explicit in its suggestion, it lacks concrete guidance on how to implement this improvement, such as suggesting specific metrics or analysis techniques to use. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Originality\" and references the work of Zemel et al. (2013), allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be improved, namely making the comparisons with the related work more systematic by comparing the best performance of each method. This provides clear guidance on what the authors need to address. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper could be improved by making comparisons with the related work of Zemel et al. (2013) more systematic. It suggests comparing the best performance of each method, which is a logical and reasonable suggestion. However, the comment does not provide specific examples or detailed reasoning to support why this comparison is necessary or how it would enhance the paper. While the suggestion is clear, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by making the comparisons with the related work of Zemel et al. (2013) more systematic. It recommends comparing the best performance of each method, which could help the authors to better highlight the original contributions of their work. This feedback is clear and actionable, offering a concrete way for the authors to enhance the clarity and impact of their paper. However, the comment could be more helpful if it included additional guidance on how to structure these comparisons or which metrics to use. Overall, the comment is 4 as it provides a valuable direction for improvement, aligning with a score of 4."}
