{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the quality of the artificially created dataset, suggesting that it might contain noise and misinformation. It also implies that the authors should provide more analysis on the dataset quality and the amount of noise it contains. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to address it. The action is implicit and somewhat vague, as the authors are left to infer that they need to analyze the dataset quality. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses concerns about the quality of the artificially created dataset, suggesting that it might contain noise and misinformation. It also implies that the authors should provide more analysis on the dataset quality and the amount of noise it contains. However, the comment does not specify which part of the paper discusses the dataset or where the authors should focus their analysis. This makes it difficult for the authors to pinpoint the exact section or part of the paper that needs attention. While the comment is specific about the issue of dataset quality, it lacks grounding as it does not provide clear references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the quality of the artificially created dataset, suggesting that it might contain noise and misinformation. The reviewer provides an example of the \"pristine\" set of tweets potentially containing misinformation, which implies that the dataset quality needs more analysis. However, the comment lacks specific examples or references to support the claim about the dataset's potential noise and misinformation. Without detailed evidence or examples, the claim is somewhat verifiable, as it provides a basis for concern but lacks thorough justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the quality of the artificially created dataset, suggesting that it might contain noise and misinformation. The reviewer provides an example of the 'pristine' set of tweets potentially containing misinformation, which highlights a concern about the dataset's reliability. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue, such as recommending additional analysis or methods to ensure dataset quality. While it points out a potential problem, it lacks actionable advice, making it somewhat helpful. The authors would need to infer that they should conduct further analysis to address the concerns raised, which limits the comment's effectiveness. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting that it does not explore the theoretical properties of the proposed algorithm, specifically its convergence. While the comment identifies a specific area that needs attention, it does not provide explicit guidance on how the authors should address this gap. The authors are left with the implicit action of expanding the paper to include a discussion of the algorithm's convergence properties, but without concrete steps or suggestions on how to do so. This lack of explicit and detailed guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the paper,\" allowing the authors to accurately identify the part being addressed. It is also specific because it clearly identifies a gap in the paper by noting the absence of a discussion on the convergence properties of the proposed algorithm. This provides the authors with a clear understanding of what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not explore the theory and show the convergence properties of the proposed algorithm. However, the comment lacks specific examples or references to support this claim. Without detailed evidence or references, the authors may find it challenging to understand the basis of the criticism and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of a discussion on the theoretical properties and convergence of the proposed algorithm. This feedback is valuable as it highlights an area where the authors could enhance the depth and rigor of their work. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address this gap, such as recommending additional analysis or literature review. Without such guidance, the authors may struggle to effectively incorporate the suggested improvements. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this selection might affect the underestimation of performances. While the comment implies that the authors should provide a justification for this choice, it does not explicitly instruct them to do so. The action is implicit, as the authors need to infer that they should explain their reasoning. However, the comment lacks concrete guidance on how to address this issue or what specific aspects of the selection process might impact performance estimation. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this might affect the underestimation of performances. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to identify the exact area where the issue needs to be addressed. While the comment is specific in its inquiry about the impact of the selection process, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this might affect the underestimation of performances. However, it does not provide any specific reasoning, examples, or references to support the claim that this selection could lead to an underestimation of performances. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this might affect the underestimation of performances. While it identifies a potential issue with the methodology, it does not provide any suggestions or guidance on how to address this concern. The comment lacks actionable advice or detailed insights that would help the authors improve their draft. Therefore, it is barely helpful, as it highlights a potential weakness but does not offer constructive feedback or suggestions for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the purpose of the average duration reported in Table 1 and notes the absence of a supporting explanation. It also asks whether the average duration includes time spent by the user waiting for the model to generate a response. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify the purpose of the average duration. The action is implicit and somewhat vague, as the authors are left to infer the need for clarification and the specific areas that require attention. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the purpose of the average duration reported in Table 1 and notes the absence of a supporting explanation. It also asks whether the average duration includes time spent by the user waiting for the model to generate a response. However, the comment does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact section that needs clarification. While the comment is specific about the content being questioned, the lack of explicit grounding makes it challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the purpose of the average duration reported in Table 1 and notes the absence of a supporting explanation. It also asks whether the average duration includes time spent by the user waiting for the model to generate a response. This comment raises a valid point about the clarity and completeness of the explanation provided in the paper. However, it lacks specific examples or references to support the claim that the explanation is missing or unclear. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some basis for concern but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a valid concern about the lack of explanation for the average duration reported in Table 1. It questions the purpose of this metric and asks whether it includes user waiting time, which is a crucial aspect for understanding the model's performance. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional information could be included to clarify the metric. While it identifies an area for improvement, the feedback lacks depth and actionable advice, making it somewhat helpful. The authors would need to infer the need for more detailed explanations and examples to fully address the comment, which limits its overall impact.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point requests clarification on the splits used for obtaining the ATIS numbers in Table 4. While it does not explicitly instruct the authors to provide this information, it implies that they should clarify this aspect in their response. The action is implicit, as the authors need to infer that they should address the lack of clarity in the table. However, the comment does not provide specific guidance on how to clarify the splits, making it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs clarification: \"what splits are used for obtaining the ATIS numbers.\" This provides a clear and precise indication of the issue that needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the splits used in Table 4. It does not contain any subjective opinions, judgments, or suggestions that require verification. The comment is factual and descriptive, aligning with the classification of \"No.\" Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment requests clarification on the splits used for obtaining the ATIS numbers in Table 4. While it identifies a specific area that needs clarification, it does not provide any suggestions or guidance on how the authors might address this issue. The comment is vague and lacks actionable advice, making it barely helpful. The authors are left without a clear understanding of what information is needed to improve the clarity of the table. Therefore, the comment aligns with a score of 2: barely helpful.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights an inconsistency in the presentation of data in Table 2 and Table 3, specifically noting that some items have spaces between accuracy and standard deviation while others do not. This inconsistency affects the visual appeal and readability of the tables. However, the comment does not provide any explicit or implicit suggestions on how to address this issue, such as recommending a consistent formatting approach or providing guidance on why the inconsistency is problematic. Without actionable guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2 and Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the inconsistency in the presentation of data, noting that some items have spaces between accuracy and standard deviation while others do not, which affects the visual appeal and readability of the tables. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights an inconsistency in the presentation of data in Table 2 and Table 3, specifically noting that some items have spaces between accuracy and standard deviation while others do not. This inconsistency affects the visual appeal and readability of the tables. However, the comment does not provide any specific reasoning, examples, or references to support why this inconsistency is problematic or how it impacts the overall quality of the paper. Without additional context or justification, the authors may find it challenging to understand the significance of the comment and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of data in Table 2 and Table 3, noting inconsistencies in the formatting of accuracy and standard deviation values. This observation is clear and actionable, as it points out a potential issue with the visual appeal and readability of the tables. However, the comment does not provide any suggestions or guidance on how to address this inconsistency, such as recommending a consistent formatting approach or explaining why the inconsistency is problematic. While the feedback is somewhat helpful in identifying a minor issue, it lacks depth and actionable advice, making it barely helpful overall. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of novelty in the paper, specifically mentioning that adversarial attacks on text have been explored in various NLP and image-text models. It acknowledges that the related work section summarizes these efforts and points out that the paper's novelty lies in applying similar ideas to video-text models. However, the comment does not provide explicit guidance on how the authors should address this lack of novelty or what specific aspects of their work need to be emphasized to differentiate it from existing research. The action is implicit and vague, as it does not specify how the authors can improve the novelty of their work. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, such as a particular section, table, or figure. It also lacks specificity, as it does not detail what aspects of the paper are lacking novelty or how the authors can address this issue. The comment provides a general overview of the related work but does not offer specific guidance on how to improve the novelty of the paper. Therefore, it is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper lacks novelty, as adversarial attacks on text have been explored in various NLP and image-text models. It acknowledges that the related work section summarizes these efforts and suggests that the paper's novelty lies in applying similar ideas to video-text models. However, the comment does not provide specific examples or detailed reasoning to support the claim of novelty. It lacks references or detailed explanations of how the paper's approach differs from existing work, making it difficult for the authors to understand and address the issue. Therefore, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a lack of novelty in the paper, specifically noting that adversarial attacks on text have been explored in various NLP and image-text models. It acknowledges that the related work section summarizes these efforts and points out that the paper's novelty lies in applying similar ideas to video-text models. However, the comment does not provide specific suggestions or guidance on how the authors can address this lack of novelty or enhance the originality of their work. While it highlights an important aspect of the paper, it lacks actionable advice or detailed insights that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out a critical issue but does not offer substantial guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the explanations for lexical features and sentence-level features in Section 3.2 are somewhat intertwined and confusing. It provides a clear action for improvement: organizing the section with separate paragraphs for each type of feature. This explicit instruction gives the authors a clear understanding of what needs to be done to improve the clarity of the section. The action is concrete, as it specifies exactly how the authors should reorganize the section. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the organization of the section by suggesting separate paragraphs for lexical and sentence-level features. This detailed feedback helps the authors understand exactly what needs to be done to enhance the clarity of the section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the explanations for features in Section 3.2 are somewhat intertwined and confusing, suggesting that the section would be more coherent with separate paragraphs for lexical and sentence-level features. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the confusion or how to address it. Without detailed reasoning or examples, the claim is somewhat verifiable, as it lacks sufficient evidence to fully substantiate the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the organization of explanations for features in Section 3.2. It points out that the current presentation is somewhat intertwined, making it confusing for readers. The comment provides a clear suggestion for improvement by recommending that the section be reorganized with separate paragraphs dedicated to lexical features and sentence-level features. This feedback is actionable and constructive, as it offers a specific and actionable suggestion for enhancing the clarity and coherence of the paper. However, it could be more helpful if it included additional guidance on how to effectively present these features or examples of what constitutes clear separation. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded for greater depth and guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the amount of space dedicated to the assumptions section and experimental results, suggesting that it might be excessive. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to the paper. The action is implicit, as the authors need to infer that they should consider reducing the space dedicated to these sections or reorganizing the paper to make it more concise. The comment is somewhat actionable because it identifies a potential issue but lacks concrete details on how to implement the suggested changes. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper is being addressed, such as a particular section or figure. It is also not specific because it does not detail what aspects of the assumptions or experimental results are considered excessive or unuseful. The comment lacks both grounding and specificity, making it difficult for the authors to understand which part of the paper needs revision and what specific issues are being raised. Therefore, this comment is rated as 1: Not Grounded.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a subjective opinion about the usefulness of the information presented in the assumptions section and experimental results, suggesting that it is excessive. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the assertion that the information is not useful or that the space allocation is excessive. As a result, the claim is considered unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a concern about the amount of space dedicated to the assumptions section and experimental results, suggesting that it might be excessive. While the comment identifies a potential issue with the paper's structure and content, it lacks specific guidance or suggestions on how the authors might address this concern. The feedback is somewhat helpful as it points out a potential area for improvement, but it does not provide actionable advice or detailed recommendations for the authors to consider. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the abstract could be improved by providing an example of the inconsistency between \"evaluating with gold answers\" and \"human evaluation.\" However, it does not explicitly instruct the authors to include this example or provide guidance on how to do so. The action is implicit, as the authors would need to infer that they should add an example to the abstract to address the inconsistency. The comment is somewhat actionable because it identifies a specific area for improvement but lacks concrete guidance on how to implement it. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests improving the abstract by providing an example of the inconsistency between \"evaluating with gold answers\" and \"human evaluation.\" This guidance is clear and actionable, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the abstract could be improved by providing an example of the inconsistency between \"evaluating with gold answers\" and \"human evaluation.\" However, the comment does not provide any specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the suggestion effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential improvement to the abstract by suggesting that it could be made more compelling by providing an example of the inconsistency between \"evaluating with gold answers\" and \"human evaluation.\" This feedback is specific and actionable, as it directs the authors to enhance the abstract with a concrete example. However, the comment could be more helpful if it provided additional guidance on how to create or find such an example. Despite this, the feedback is mostly helpful as it offers a clear direction for improvement, allowing the authors to enhance the abstract effectively. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some discussions are required on the convergence of the proposed joint learning process, specifically mentioning the probabilistic metric space and stable points. It implies that readers may find it challenging to understand how these stable points are obtained, which could hinder the repetition of the results. However, the comment does not provide explicit guidance on what specific aspects of the convergence process need to be discussed or how to address the difficulty in understanding the stable points. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the convergence discussion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that some discussions are required on the convergence of the proposed joint learning process, specifically mentioning the probabilistic metric space and stable points. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to include discussions on convergence and stable points, but without clear references to specific sections or figures, the authors may find it challenging to identify the exact areas to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that some discussions are required on the convergence of the proposed joint learning process, specifically mentioning the probabilistic metric space and stable points. It implies that readers may find it challenging to understand how these stable points are obtained, which could hinder the repetition of the results. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that such discussions are necessary. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the suggestion, rendering it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by providing additional discussions on the convergence of the proposed joint learning process. It highlights the importance of explaining how stable points in probabilistic metric spaces are obtained, as this is crucial for readers to understand and potentially replicate the results. However, the comment lacks specific guidance on what aspects of the convergence process need to be discussed or how to address the difficulty in understanding the stable points. While it points out a potential weakness, it does not offer detailed suggestions or examples to enhance the paper, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific instructions for the authors to address certain aspects of their draft. It instructs them to discuss the results for the task of inferring knowledge on objects and to include results for model (B). Additionally, it suggests using consistent terminology for the model in Tables 1 and 2. It also questions why the term \"latent in verbs\" is not mentioned. These instructions are explicit and provide clear guidance on what needs to be done, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment provides specific instructions for the authors to address certain aspects of their draft, such as discussing results for the task of inferring knowledge on objects and including results for model (B). It also suggests using consistent terminology for the model in Tables 1 and 2 and questions why the term \"latent in verbs\" is not mentioned. However, the comment does not explicitly mention sections, tables, or figures, making it weakly grounded. The instructions are specific in terms of what needs to be addressed, but the lack of explicit grounding makes it weakly grounded and specific. Therefore, this comment aligns with category 3: Weakly Grounded and Specific.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point provides specific instructions for the authors to address certain aspects of their draft, such as discussing results for the task of inferring knowledge on objects and including results for model (B). It also suggests using consistent terminology for the model in Tables 1 and 2 and questions why the term \"latent in verbs\" is not mentioned. These instructions are clear and provide actionable guidance, making the comment mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples to fully support the suggestions. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on areas that need improvement in the draft. It instructs the authors to discuss the results for the task of inferring knowledge on objects and to include results for model (B), which are important for a comprehensive understanding of the work. Additionally, it suggests using consistent terminology for the model in Tables 1 and 2, which is a practical and helpful suggestion. The comment also questions why the term \"latent in verbs\" is not mentioned, prompting the authors to consider this aspect. Overall, the feedback is clear, detailed, and provides actionable guidance, making it highly helpful for the authors to improve their draft.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with a sentence in the paper, noting that it is not strictly correct and suggests an alternative phrasing. The comment is explicit in pointing out the error and provides a clear suggestion for improvement. However, it does not offer detailed guidance on how to implement the suggested change or what specific aspects of the sentence need to be revised. While the action is clear, it lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 212,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a factual error in the description of the GRU model and suggests an alternative, more accurate phrasing. This provides clear guidance on what needs to be corrected or revised. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the sentence in line 212 is not strictly correct and suggests an alternative phrasing. While the comment identifies a specific issue, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion for improvement is clear, but the absence of additional evidence or references makes it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with a sentence in the paper, noting that it is not strictly correct and suggests an alternative phrasing. This feedback is clear and actionable, providing the authors with a specific point of improvement. However, the comment could be more helpful if it offered additional guidance on how to revise the sentence or suggested alternative phrasing. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement, allowing them to enhance the accuracy and clarity of their work. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends including additional baselines, such as character embeddings. However, it does not provide explicit guidance on how to implement these baselines or what specific aspects of the extension should be explored. The action is implicit and vague, as the authors are left to infer that they need to add these baselines to their draft. This lack of concrete instructions makes the comment somewhat actionable, as the authors know they need to address the suggestion but are unsure how to proceed. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends including additional baselines, such as character embeddings. However, it does not specify which part of the paper this extension is discussed or how the additional baselines would be integrated. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, while the suggestion to include additional baselines is specific, the comment lacks detailed guidance on how to implement these baselines or what specific aspects of the extension should be explored. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper is a straightforward extension of existing retrofitting work and recommends including additional baselines, such as character embeddings. However, the comment lacks specific details or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. Without further elaboration or examples, the claim is considered unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the paper could benefit from additional baselines, specifically character embeddings. This feedback is somewhat helpful as it points out a specific aspect that could enhance the paper's comprehensiveness and robustness. However, the comment lacks depth and does not provide detailed guidance on how to implement these additional baselines or what specific experiments or analyses would be necessary. The authors are left with a general idea of what to include but without concrete steps to follow, which limits the comment's overall helpfulness. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the y-axis label in Figure 5 might use \"Exact Match ratio\" directly. This is a specific and actionable suggestion, as it provides a clear and direct instruction for the authors to consider changing the label. The authors can easily identify where the label is located and apply this change. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by recommending that the y-axis label may use \"Exact Match ratio\" directly. This feedback is precise and actionable, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the y-axis label in Figure 5 may use \"Exact Match ratio\" directly. This is a specific and actionable suggestion, as it provides a clear and direct instruction for the authors to consider changing the label. However, the comment does not provide any reasoning or justification for why this change is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis for this suggestion. Therefore, the comment is somewhat verifiable, as it is specific but lacks sufficient justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out a specific issue with the y-axis label in Figure 5, suggesting that it may use \"Exact Match ratio\" directly. This is a clear and actionable piece of feedback that the authors can easily address by revising the label. The comment is specific and provides a direct suggestion for improvement, making it highly helpful for the authors to enhance the clarity and accuracy of their presentation. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the lack of description regarding the societal biases of the knowledge bases used in the paper. It questions whether the knowledge bases are free from such biases and whether the issue is affected by these restrictions. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to ensure the knowledge bases are free from societal biases. The action is implicit and vague, as it does not specify how the authors should verify or address the issue. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the societal biases of the knowledge bases used in the paper, questioning whether they are free from such biases and whether the issue is affected by these restrictions. However, the comment does not specify which part of the paper discusses the knowledge bases or where the societal biases are mentioned. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs attention. While the comment is specific in its critique of the knowledge bases, the absence of explicit references or grounding makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the societal biases of the knowledge bases used in the paper, questioning whether they are free from such biases and whether the issue is affected by these restrictions. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issue raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises concerns about the societal biases of the knowledge bases used in the paper, questioning whether they are free from such biases and whether the issue is affected by these restrictions. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what steps they should take to ensure the knowledge bases are free from societal biases. While it identifies a potential area for improvement, it does not provide actionable advice or detailed feedback, making it somewhat helpful. The comment is incomplete and could be more helpful with additional guidance or suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it is easier to demonstrate that something does not work in sequence-to-sequence multi-task learning (MTL) than to identify why it fails and how to make it work. It implies that the authors should focus on understanding the reasons behind the failure of the attention mechanism and explore ways to improve it. However, the comment does not provide explicit guidance on how to identify the reasons for failure or how to change the attention mechanism to make it work. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that it is easier to demonstrate that something does not work in sequence-to-sequence multi-task learning (MTL) than to identify why it fails and how to make it work. However, it does not specify which part of the paper this issue is related to, such as a specific section, table, or figure. The authors cannot confidently determine which part of the paper the comment addresses, making it weakly grounded. The comment is specific in its suggestion to focus on understanding the reasons for failure and exploring ways to improve the attention mechanism, but without grounding, the authors are left to make an educated guess about where to apply this feedback. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it is easier to demonstrate that something does not work in sequence-to-sequence multi-task learning (MTL) than to identify why it fails and how to make it work. This claim is somewhat verifiable as it provides a logical reasoning for why the authors might focus on demonstrating the failure of the attention mechanism rather than addressing it. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to focus on understanding why a particular attention mechanism in sequence-to-sequence multi-task learning (MTL) is not working and how to improve it. It highlights the importance of identifying the reasons behind the failure and exploring ways to make the attention mechanism work. This feedback is valuable as it guides the authors to address a critical aspect of their work, potentially enhancing the value and impact of their research. However, the comment could be more helpful if it provided specific examples or guidance on how to identify the reasons for failure or how to change the attention mechanism. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the lack of strong baselines in Table 3, specifically mentioning the baselines in [1]. It requests the authors to justify their choice of baselines. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific baselines they should include. The action is implicit, as the authors need to infer that they should add more baselines and justify their selection. The comment is vague in terms of how to implement this action, as it does not specify which baselines are missing or how to justify their inclusion. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests the authors to justify the reason for the absence of strong baselines in the comparison, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the lack of strong baselines in Table 3 and requests justification for this choice. However, it does not provide any specific reasoning, examples, or references to support why the baselines in [1] are missing or why the current baselines are insufficient. Without additional context or evidence, the claim is difficult to verify, making it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 3, noting the absence of strong baselines and requesting justification for their inclusion. This feedback is clear and actionable, as it directs the authors to address the lack of comparison with relevant baselines. However, the comment could be more helpful if it provided specific examples of missing baselines or suggested additional baselines that could be included. Despite this, the comment offers a clear direction for improvement, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the paper's reliance on supplemental space, suggesting that the paper is not truly independent due to references to supplemental figures and model comparisons. However, it does not provide explicit instructions or suggestions on how the authors should address this issue. The comment implies that the authors should consider making the paper more self-contained, but it lacks concrete guidance on how to achieve this. As a result, the authors are left without a clear understanding of what steps to take to improve the paper. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"supplemental space\" and \"supplemental figures,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper is not truly independent due to references to supplemental figures and model comparisons, particularly noting the issue with S3.1 reference to Sup. Fig. 6 and the model comparison and span vs. sentence investigation. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper relies on supplemental space, making it not truly independent, and provides specific references to support this claim, such as the mention of \"S3.1 reference to Sup. Fig. 6\" and the model comparison and span vs. sentence investigation. This level of detail and specific examples makes the claim verifiable, as it provides clear evidence to support the authors\\' understanding of the issue. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper's reliance on supplemental space, suggesting that the paper is not truly independent due to references to supplemental figures and model comparisons. This feedback is clear and actionable, as it provides specific examples of where the paper might be lacking in self-containment. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue, such as integrating key information into the main text or providing a more comprehensive description of the supplemental material. Despite this, the comment is mostly helpful as it highlights a critical area for improvement, guiding the authors to enhance the paper\\'s independence and clarity.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more details about the traits of the experts involved in the annotation process and justify why expert annotation is necessary, beyond its commercial value. It also asks for clarification on whether the experts are linguistic or domain experts, and whether the annotation process differs from what non-experts would do. This feedback is explicit and provides clear guidance on what additional information and justification the authors should include in their draft. The comment is specific and actionable, as it directly instructs the authors on what needs to be addressed to improve the clarity and robustness of their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the first point,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed questions and suggestions about the traits of the experts involved in the annotation process, the justification for expert annotation, and the differences between expert and non-expert annotation. This level of detail helps the authors understand exactly what aspects need to be clarified or expanded upon. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the traits of the experts involved in the annotation process and the justification for expert annotation. It asks for clarification on whether the experts are linguistic or domain experts and whether the annotation process differs from what non-experts would do. While the comment is clear and specific, it does not provide any evidence or reasoning to support the claims made. The authors are left to interpret the questions and provide their own justifications, which limits the verifiability of the feedback. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment is mostly helpful as it provides specific questions and suggestions for the authors to consider regarding the traits of the experts involved in the annotation process. It encourages the authors to justify why expert annotation is necessary, beyond its commercial value, and to clarify whether the experts are linguistic or domain experts. This feedback is actionable and constructive, as it prompts the authors to address potential linguistic challenges and provide a more comprehensive understanding of the annotation process. However, the comment could be more helpful if it offered additional guidance on how to address these issues or provided examples of how to justify the need for expert annotation. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors would benefit from including examples of the system applied to actual texts, as opposed to other components or models. While the comment implies that this would be helpful, it does not explicitly instruct the authors to add such examples or specify how to do so. The action is implicit and somewhat vague, as the authors are left to infer that adding examples would improve the paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including examples of the system on actual texts, which implies a specific part of the paper where such examples would be beneficial. However, it does not explicitly mention a particular section, table, or figure, making it weakly grounded. The comment is specific in its suggestion to include examples, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from including examples of the system on actual texts, which implies that the current draft lacks such examples. However, the comment does not provide any specific reasoning or evidence to support why this would be beneficial or how it would improve the paper. Without additional context or justification, the claim remains somewhat vague and lacks sufficient support. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from including examples of the system applied to actual texts, which could enhance the understanding and impact of the work. However, the comment lacks specificity and does not provide detailed guidance on how to incorporate these examples or what aspects of the system should be illustrated. While it offers a general direction for improvement, the feedback is somewhat vague and could be more helpful if it included specific suggestions or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that some claims in the paper would benefit from more in-depth analysis. However, it does not specify which claims need more analysis or provide any guidance on how to conduct this analysis. The action is implicit and vague, as the authors are left to infer that they need to delve deeper into the analysis of certain claims. Without explicit instructions or concrete examples, the authors are unable to understand what specific aspects require more detailed analysis. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that some claims in the paper would benefit from more in-depth analysis. However, it does not specify which claims or sections of the paper are being referred to, nor does it provide any guidance on how to conduct this analysis. The lack of specific information makes it difficult for the authors to identify the exact parts of the paper that need improvement. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that some claims in the paper would benefit from more in-depth analysis. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors are left to interpret the comment, making it difficult to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that some claims in the paper would benefit from more in-depth analysis. However, it lacks specificity and does not provide any guidance on which claims need more analysis or how to conduct this analysis. The comment is vague and does not offer actionable feedback, leaving the authors with limited insight into how to improve their draft. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two hypotheses in lines 078-086 about multilinguality and country/language-specific bias. It acknowledges that the hypotheses are valuable but expresses a concern that the paper does not actually study these hypotheses, nor do they mention or discuss them again. The comment suggests that the paper should have explored these hypotheses more deeply. However, it does not provide specific guidance on how to test or explore these hypotheses, leaving the authors with a general idea of what to do but without concrete steps. The action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the paper by referencing specific lines (078-086) where two hypotheses are raised. This provides full grounding as the authors can accurately identify the part of the paper being discussed. The comment is also specific because it clearly specifies the issue with the hypotheses, noting that the paper does not actually study them, nor do they mention or discuss them again. This provides a clear direction for the authors to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not actually study the hypotheses mentioned in lines 078-086, nor does it discuss them again. This claim is somewhat verifiable as it highlights a potential gap in the paper's content, but it lacks specific examples or references to support the assertion that the hypotheses are not studied or discussed. The authors would need to provide more detailed evidence to fully substantiate this claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue in the paper: the lack of study and discussion of the hypotheses mentioned in lines 078-086. It acknowledges the value of these hypotheses but points out that the paper does not actually explore them, nor does it mention or discuss them again. This feedback is clear and actionable, as it directs the authors to address the gap in their analysis. However, the comment could be more helpful if it provided specific suggestions on how to test or explore these hypotheses, or if it offered guidance on how to integrate them into the discussion. Overall, the comment is mostly helpful, as it highlights a significant area for improvement but could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether feature engineering could improve the performance of the work, referencing Uto et al. (2020) as an example. It suggests that using the same feature set from Uto et al. (2020) might improve the results. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific steps the authors should take to explore this idea. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about whether feature engineering could improve performance, referencing Uto et al. (2020) as an example. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in suggesting that using the same feature set from Uto et al. (2020) might improve the results, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about whether feature engineering could improve performance, referencing Uto et al. (2020) as an example. It suggests that using the same feature set from Uto et al. (2020) might improve the results of this work. However, the comment lacks specific details or evidence to support the claim that the current feature set is suboptimal or that the suggested approach would necessarily lead to improvement. Without additional context or reasoning, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about whether feature engineering could improve the performance of the work, referencing Uto et al. (2020) as an example. It suggests that using the same feature set from Uto et al. (2020) might improve the results of this work. However, the comment does not provide specific guidance or suggestions on how to implement this idea or what steps the authors should take to explore this possibility. While it identifies a potential area for improvement, it lacks actionable advice or detailed reasoning, making it somewhat helpful. The authors would need to infer the necessary steps to address the comment, which limits its overall impact.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the clarity of the use of the Challenge Set (CS) in the paper. It asks whether the CS is used for evaluation purposes and also for augmenting the training material. The comment implies that the authors should clarify how the CS is used and what data split is employed. However, it does not provide explicit instructions or detailed guidance on how to address these questions or improve the clarity of the paper. The action is implicit and somewhat vague, as the authors need to infer the specific areas that require clarification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the clarity of the use of the Challenge Set (CS) in the paper, specifically asking whether it is used for evaluation purposes and also for augmenting the training material. It also inquires about the data split used. However, the comment does not specify which part of the paper discusses the CS or how it is used, making it weakly grounded. The questions are specific and address the clarity of the use of the CS, but without explicit references to sections or figures, the authors may need to infer the relevant parts. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the clarity of the use of the Challenge Set (CS) in the paper, specifically asking whether it is used for evaluation purposes and also for augmenting the training material. It also inquires about the data split used. However, the comment does not provide any evidence, reasoning, or references to support these questions or claims. The questions are based on the authors' own understanding, but without further clarification or justification, they remain speculative. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises questions about the clarity of the use of the Challenge Set (CS) in the paper, specifically asking whether it is used for evaluation purposes and also for augmenting the training material. It also inquires about the data split used. While the comment identifies an area that needs clarification, it does not provide specific guidance or suggestions on how to address these questions or improve the clarity of the paper. The feedback is somewhat helpful as it points out a potential area of confusion for the authors, but it lacks depth and actionable advice, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the claim that the model generalizes to different knowledge, suggesting that the substructure should be represented as a sequence of words rather than using constituent parse as knowledge. It also questions the use of the term \"knowledge\" in the context of the paper, suggesting it might be misleading as it relates to syntax or semantics rather than world or external knowledge. While the comment identifies specific issues with the claim, it does not provide explicit guidance on how the authors should address these concerns or what changes to make to their draft. The action is implicit, as the authors need to infer that they should reconsider the representation of substructures and the use of the term \"knowledge'. However, the comment lacks concrete details on how to implement these suggestions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the claim that the model generalizes to different knowledge, suggesting that the substructure should be represented as a sequence of words rather than using constituent parse as knowledge. It also questions the use of the term \"knowledge\" in the context of the paper, suggesting it might be misleading as it relates to syntax or semantics rather than world or external knowledge. However, the comment does not specify which part of the paper discusses the model's generalization or the use of \"knowledge,\" making it difficult for the authors to pinpoint the exact issue. The comment is specific in its critique of the representation and the use of the term \"knowledge,\" but it lacks grounding as it does not clearly identify the section or part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the claim that the model generalizes to different knowledge, suggesting that the substructure should be represented as a sequence of words rather than using constituent parse as knowledge. It also questions the use of the term \"knowledge\" in the context of the paper, suggesting it might be misleading as it relates to syntax or semantics rather than world or external knowledge. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of substantiation makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises concerns about the claim that the model generalizes to different knowledge, suggesting that the substructure should be represented as a sequence of words rather than using constituent parse as knowledge. It also questions the use of the term \"knowledge\" in the context of the paper, suggesting it might be misleading as it relates to syntax or semantics rather than world or external knowledge. While the comment identifies a potential issue with the representation of substructures and the use of the term \"knowledge,\" it lacks specific guidance on how the authors should address these concerns or what changes to make to their draft. The feedback is somewhat helpful as it points out areas for improvement but does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses concern about the performance of nouns compared to clustering approaches, noting that the oracle GAP for PPDBClus is higher than most clustering approaches. It also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech, as the performance is not uniform. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting specific analyses or improvements to address the performance discrepancy or the contradiction. The authors are left without clear guidance on how to address these issues, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of nouns compared to clustering approaches, specifically mentioning the higher oracle GAP for PPDBClus and contrasting it with the claim of generalizability to all parts of speech. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the performance discrepancy and the contradiction with the claim, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the clustering approach is not generalizable to all parts of speech due to the performance discrepancy observed in the nouns compared to clustering approaches. The reviewer provides specific evidence, such as the higher oracle GAP for PPDBClus, to support this claim. However, the comment lacks detailed reasoning or references to substantiate the claim fully. While the evidence is present, the lack of a comprehensive explanation or additional context makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the performance of nouns compared to clustering approaches, specifically noting that the oracle GAP for PPDBClus is higher than most clustering approaches. This observation is followed by a direct contradiction with the claim that the clustering approach is generalizable to all parts of speech, as the performance is not uniform. The comment provides a clear point of concern and highlights a potential issue with the generalizability of the clustering approach. However, it does not offer specific suggestions or guidance on how the authors might address this issue or improve their draft. While the feedback identifies a significant concern, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the discussion in section 5.2 is abstract and lacks clarity, making it difficult for the authors to understand why the new model is better than MH. It suggests providing examples of spurious structures to clarify the discussion. However, the comment does not explicitly instruct the authors to provide these examples or how to incorporate them into the discussion. While the action is implied, it is vague and lacks concrete guidance on how to implement it. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies a lack of clarity in the discussion regarding the abstract nature of the insights and suggests providing examples of spurious structures to clarify the comparison between the new model and MH. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the abstract nature of the discussion in section 5.2 and suggests providing examples of spurious structures to clarify the comparison between the new model and MH. However, the comment does not offer any specific reasoning, examples, or references to support why the discussion is abstract or how providing examples would clarify the comparison. Without additional context or justification, the claim is considered unverifiable. Therefore, the comment is labeled as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern in the paper, namely the abstract nature of the discussion in section 5.2, which makes it difficult for the authors to understand why the new model is better than MH. The comment suggests providing examples of spurious structures to clarify the discussion, which is a valuable and actionable piece of feedback. However, the comment could be more helpful if it provided specific examples or guidance on how to incorporate these examples into the discussion. Despite this, the feedback is mostly helpful as it directs the authors to a critical area that needs improvement, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding a baseline smaller PCFG with specific parameterizations, which could help in comparing parsing F-1. However, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the comparison should be highlighted. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to apply the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding a baseline smaller PCFG with specific parameterizations, which could help in comparing parsing F-1. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section or context. The comment is not grounded as it lacks specific references or context, and it is also not specific about what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests adding a baseline smaller PCFG with specific parameterizations to compare parsing F-1. However, it lacks detailed reasoning or examples to support why this comparison is necessary or how it would be beneficial. The comment does not provide specific references or logical reasoning to justify the suggestion, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding a baseline smaller PCFG with specific parameterizations to compare parsing F-1. While it provides a potential improvement to the methodology, it lacks detailed guidance on how to implement this suggestion or what specific aspects of the comparison should be highlighted. The comment is somewhat helpful as it identifies a potential area for improvement, but it does not offer comprehensive feedback or actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should state the maximum number of tasks done by any annotator. This is a clear and explicit action that provides specific guidance on what needs to be included in the paper. The authors know exactly what information is missing and how to address it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"241,\" allowing the authors to accurately identify the section of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: stating the maximum number of tasks done by any annotator. This provides the authors with a clear understanding of the issue and how to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should state the maximum number of tasks done by any annotator. This is a factual suggestion that requires no further verification or reasoning. It is a direct request for clarification or additional information, which does not involve making claims or opinions. Therefore, this comment is classified as \"No\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by asking the authors to include the maximum number of tasks done by any annotator. This is a clear and actionable piece of feedback that directly addresses a potential gap in the paper. By providing this information, the authors can enhance the transparency and completeness of their work. However, the comment could be more helpful if it offered additional guidance on how to present or analyze this information. Overall, the feedback is mostly helpful as it directs the authors towards a specific improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests including the hard prompt baseline in Table 1 to observe the performance increase of each method. This is a clear and explicit action that the authors can readily implement by adding the suggested element to their table. The comment provides a concrete instruction on what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including the hard prompt baseline in Table 1 to see the performance increase of each method. However, it does not specify which part of the paper Table 1 is located in, nor does it provide any details about the methods being compared. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment is specific in its suggestion to include a baseline, but without grounding, it is difficult for the authors to understand where to apply this suggestion. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including the hard prompt baseline in Table 1 to observe the performance increase of each method. This is a suggestion for improvement, but it lacks specific reasoning or examples to support why this addition would be beneficial. Without detailed justification or references, the claim is somewhat verifiable, as it provides a direction for improvement but does not fully substantiate the need for the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests including the hard prompt baseline in Table 1 to observe the performance increase of each method. This is a specific and actionable suggestion that could enhance the clarity and comprehensiveness of the paper. By providing a baseline, the authors can better understand the effectiveness of their methods and make more informed comparisons. However, the comment could be more helpful if it included additional guidance on how to interpret or present the results with the new baseline. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of numerical results in the paper, specifically questioning how the proposed method can be applied to popular algorithms and how its performance compares to existing DP algorithms. While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to include numerical results and conduct comparisons with existing algorithms. However, the action is implicit and somewhat vague, as it does not specify which algorithms to use or how to perform the comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of numerical results and questions the application of the proposed method to popular algorithms, specifically comparing its performance with existing DP algorithms. However, it does not specify which algorithms are considered \"popular\" or provide any details on how the comparison should be conducted. The comment is not grounded as it does not mention specific sections, tables, or figures that might contain the numerical results or comparisons. It is also not specific because it lacks details on the algorithms or the nature of the comparison. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper lacks numerical results and questions how the proposed method can be applied to popular algorithms and compared with existing DP algorithms. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors are left to infer the validity of the claim, making it difficult to fully understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of numerical results and the absence of comparisons with existing DP algorithms. This feedback is valuable as it highlights a critical area where the authors can strengthen their work by providing empirical evidence and demonstrating the practical applicability of their method. However, the comment could be more helpful if it suggested specific algorithms or methods for comparison or provided guidance on how to conduct these comparisons. Despite this, the feedback is somewhat helpful as it directs the authors to an important aspect of their research that needs further development. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. This feedback is explicit and provides a clear action for the authors to take, which is to include empirical evidence to substantiate the claim. The comment is specific in its suggestion and offers a concrete direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. However, the comment does not specify which part of the paper discusses the third contribution or the Column Subset Selection problem, making it weakly grounded. It is specific in its suggestion to include empirical evidence, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. However, the comment does not provide any specific examples, references, or detailed reasoning to substantiate this claim. Without additional context or evidence, the authors may find it challenging to understand and address the suggestion effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. This feedback is clear and actionable, as it directs the authors to include empirical evidence to substantiate their claim. By doing so, the authors can strengthen the validity of their contribution and provide a more comprehensive evaluation of their algorithm. However, the comment could be more helpful if it offered specific guidance on how to conduct the empirical evaluation or what kind of evidence would be most effective. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more detailed in its suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the applicability of the robust training scheme to practical datasets, particularly those supported on high-dimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or what changes could be made to improve the scheme. The action is implicit and vague, leaving the authors without a clear understanding of how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the applicability of the robust training scheme to practical datasets, particularly those supported on high-dimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment does not specify which part of the paper discusses the robust training scheme or the datasets used. Without explicit references to sections, tables, or figures, the authors cannot confidently determine where the issue is being addressed. While the comment is specific about the concern regarding scalability, it lacks grounding as it does not provide clear references to the relevant parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the applicability of the robust training scheme to practical datasets, particularly those supported on high-dimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the applicability of the robust training scheme to practical datasets, particularly those supported on high-dimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. This feedback highlights a potential limitation of the proposed method and provides a specific area for the authors to consider. However, the comment lacks detailed guidance or suggestions on how the authors might address this issue or what changes could be made to improve the scheme. While it identifies a potential weakness, it does not offer actionable steps or insights to enhance the paper. Therefore, the comment is somewhat helpful, as it provides a clear area for improvement but lacks depth and specificity in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should make a distinction between hard prompt work updates the frozen model and those that don\\'t. This provides a clear and explicit action for the authors to take, as they can directly implement this suggestion in their draft. The comment is specific in its recommendation, detailing what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 148,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests making a distinction between hard prompt work updates the frozen model and those that don\\'t, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should make a distinction between hard prompt work updates the frozen model and those that do not. While the comment provides a specific suggestion, it lacks detailed reasoning or examples to support why this distinction is important or how it would improve the paper. Without additional context or justification, the claim is somewhat verifiable, as it is based on a logical suggestion but lacks sufficient evidence to fully substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending that the authors make a distinction between hard prompt work updates the frozen model and those that do not. This feedback is actionable and directly addresses a potential area for clarification or enhancement in the paper. By suggesting a clear categorization, the comment offers a concrete way for the authors to improve the organization and clarity of their work. However, the comment could be more helpful if it provided additional context or examples to support the suggestion. Overall, the comment is mostly helpful as it offers a clear and actionable direction for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the conclusion that the direct model is clearly the better of the two, given the significant difference in the amount of data used for training the text disambiguation model and the end-to-end system. However, it does not provide explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might address the issue or what steps they should consider to strengthen their conclusions. As a result, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of the amount of data used to train the text disambiguation model compared to the end-to-end system, questioning the conclusion that the direct model is clearly the better of the two. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the data difference and its impact on the conclusion, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the conclusion regarding the performance of the direct model compared to the end-to-end system, given the difference in the amount of data used for training. However, it does not provide any specific evidence, reasoning, or references to support the claim that the conclusion is questionable. Without additional context or justification, the reviewer's assertion remains speculative and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the conclusion drawn from the comparison between the direct model and the end-to-end system. It points out that the significant difference in the amount of data used for training the text disambiguation model compared to the end-to-end system questions the claim that the direct model is clearly the better of the two. This feedback is somewhat helpful as it identifies a potential issue with the conclusion and suggests that the authors should consider the impact of data differences on their results. However, the comment could be more helpful if it provided additional guidance on how the authors might address this concern or what steps they could take to strengthen their conclusions. Overall, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues with the paper: the lack of clear motivation for GaRare and the need for a more detailed algorithmic presentation, specifically regarding the recovery of updated parameters from projected gradients. While the comment identifies these areas, it does not provide explicit instructions or concrete guidance on how the authors should address these issues. The authors are left to infer that they need to provide a clearer motivation for GaRare and a more detailed explanation of the algorithmic process. This lack of explicit action makes the comment somewhat actionable, as it provides a general direction but lacks specific details on how to implement the changes. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of clear motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the recovery of updated parameters from projected gradients. However, it does not specify which part of the paper discusses GaRare or the algorithmic process, making it weakly grounded. The comment is specific in detailing the issues that need to be addressed, such as the motivation for GaRare and the need for a more detailed algorithmic presentation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks clear motivation for GaRare and does not provide evidence or justification for its advantages over GaLore based on theoretical analysis. It also suggests that a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or justification makes the claim somewhat verifiable, as the authors would need to provide additional information to address the concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two key areas for improvement in the paper: the lack of clear motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the recovery of updated parameters from projected gradients. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address them. The feedback is somewhat helpful as it points out areas that require attention, but it lacks depth and actionable advice, leaving the authors with a general idea of what needs to be improved rather than detailed steps to follow. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It specifically mentions one experiment of interest, ATT(+H), and asks for the performance of the model if it did not consider relevant attention retrieval from the attention memory. While the comment provides a clear action\u2014conducting an ablation study\u2014it does not specify how to implement this action or what data to use for the study. The suggestion is somewhat vague, as it lacks detailed guidance on the methodology or expected results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It specifically mentions one experiment of interest, ATT(+H), and asks for the performance of the model if it did not consider relevant attention retrieval from the attention memory. However, the comment does not specify which part of the paper discusses the visDial dataset or the proposed model, making it difficult for the authors to identify the exact section or figure being referenced. While the comment is specific about the experiment of interest, the lack of grounding makes it challenging for the authors to understand the context and relevance of the suggestion. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It specifically mentions one experiment of interest, ATT(+H), and asks for the performance of the model if it did not consider relevant attention retrieval from the attention memory. However, the comment lacks detailed reasoning or references to support the claim that this ablation study would provide additional validation. It does not provide specific examples or evidence to justify why this experiment is crucial for validating the model. As a result, the claim is somewhat verifiable, as it lacks sufficient support for the authors to understand the significance of the suggested experiment.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the paper by conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It highlights a particular experiment of interest, ATT(+H), and asks for the performance of the model if it did not consider relevant attention retrieval from the attention memory. This feedback is actionable and constructive, as it directs the authors to a specific area for further investigation and provides a clear goal for their work. However, the comment could be more helpful if it included more detailed guidance on how to conduct the ablation study or what specific metrics to consider. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should try to explain why the Wavelet Packet Analysis (WPA) works, particularly with np.ones input, and what the model predicts in this case. It also questions whether any input could serve as a \"white paper\" and notes that Figure 2 suggests Gaussian noise input does not work as well as WPA. The comment implies that the authors should provide more insights into how WPA works, which is crucial for future research directions. However, the comment does not explicitly instruct the authors on how to conduct this analysis or what specific aspects to focus on. While the action is implied, it lacks concrete guidance, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should try to explain why WPA works, particularly with np.ones input, and what the model predicts in this case. It also questions whether any input could serve as a \"white paper\" and notes that Figure 2 suggests Gaussian noise input does not work as well as WPA. The comment implies that the authors should provide more insights into how WPA works, which is crucial for future research directions. However, the comment does not specify which part of the paper this analysis should be conducted on, making it weakly grounded. It is specific in suggesting the need for a deeper explanation of WPA's functionality, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the functionality of WPA, specifically with np.ones input, and suggests that Figure 2 indicates Gaussian noise input does not work as well as WPA. The comment implies that the authors should provide more insights into how WPA works, which is important for future research directions. However, the comment lacks specific examples or detailed reasoning to support the claim that the authors should explore this aspect. It does not provide a clear rationale for why this is a significant issue or how it impacts the paper's conclusions. As a result, the claim is somewhat verifiable, as it is based on logical reasoning but lacks sufficient evidence or references to fully substantiate the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by questioning the functionality of WPA, particularly with np.ones input, and suggests that Figure 2 indicates Gaussian noise input does not work as well as WPA. It highlights that the authors spend considerable time demonstrating WPA's improvement in test performance but fail to provide insights into how WPA works, which is crucial for future research directions. This feedback is valuable as it prompts the authors to delve deeper into the mechanisms of WPA and its implications. However, the comment could be more helpful if it provided specific suggestions or guidance on how to explore these aspects, such as suggesting additional experiments or analyses that could shed light on WPA's functionality. Overall, the comment is somewhat helpful, as it points out an important area for improvement but lacks detailed actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether the method part is similar to a related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" While it suggests that the authors should provide more clarification, it does not explicitly instruct them to do so or offer specific guidance on how to clarify the similarity. The action is implicit, as the authors need to infer that they should clarify the relationship between their method and the cited work. However, the comment lacks concrete details on what aspects of the method need clarification, making it somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the similarity between the method part and a related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, it does not specify which part of the paper this comparison is intended for, leaving the authors uncertain about the exact section being addressed. The comment is not grounded as it does not provide explicit references to sections, tables, or figures. Additionally, it lacks specificity in explaining what aspects of the method are similar to the related work, making it difficult for the authors to understand what needs to be clarified. Therefore, this comment is not grounded and not specific, aligning with a score of 1: Not Grounded.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions whether the method part is similar to a related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" This is a subjective claim, as it expresses an opinion about the similarity between the method and the cited work. However, the comment does not provide any evidence or reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or justification, the claim is unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the similarity between the method part of the paper and a related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" While the comment identifies a potential issue, it does not provide specific suggestions or guidance on how the authors might address this concern. The feedback is somewhat helpful as it prompts the authors to consider the relationship between their method and the cited work, but it lacks actionable advice on how to clarify or resolve the issue. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises two main points: first, it questions the fairness of comparing the proposed method with others due to the use of a proposal generator pretrained on MSCOCO, which aggregates more information. Second, it suggests that the proposed technique could potentially promote existing class incremental semantic segmentation methods. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting specific comparisons or exploring the potential of the technique. The feedback lacks concrete guidance on how to address the concerns or implement the suggestions, leaving the authors without clear directions for improvement. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of a proposal generator pretrained on MSCOCO, questioning the fairness of comparisons with other methods. It also suggests that the proposed technique could potentially promote existing class incremental semantic segmentation methods. However, the comment does not specify which part of the paper discusses the comparison with other methods or the potential for promoting existing methods. This lack of grounding makes it difficult for the authors to identify the exact sections that need attention. While the comment is specific about the issues raised, the absence of explicit references to specific sections or parts of the paper limits its effectiveness. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two main concerns: the fairness of comparing the proposed method with others due to the use of a proposal generator pretrained on MSCOCO, and the potential of the proposed technique to promote existing class incremental semantic segmentation methods. However, the comment lacks specific evidence, examples, or references to support these claims. Without detailed reasoning or references, the claims are difficult to verify, making the comment borderline verifiable. The authors would need to provide more context or evidence to fully understand and address the concerns raised in the comment.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises two main points: first, it questions the fairness of comparing the proposed method with others due to the use of a proposal generator pretrained on MSCOCO, which aggregates more information. This raises a valid concern about the comparability of the results. Second, the comment suggests that the proposed technique could potentially promote existing class incremental semantic segmentation methods, which is a valuable insight for the authors to consider. However, the comment lacks specific guidance or suggestions on how to address the fairness issue or explore the potential of the technique. While it identifies important areas for consideration, it does not provide actionable steps or detailed feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it offers some insights but lacks depth and specificity in addressing the concerns.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by pointing out that while the end of Section 2 discusses two important parameters, the experimental section (Section 3) does not mention or discuss how these parameters are set or how sensitive the performance is with respect to them. This feedback is explicit and provides a clear action for the authors to take, which is to address this gap by including details on parameter settings and sensitivity analysis in the experimental section. The comment is specific and actionable, as it directly instructs the authors on what needs to be added to improve the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the end of Section 2 and the experimental section (Sec. 3), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of mention or discussion of how the two important parameters (minimum cluster size and conductance threshold) are set and how sensitive the performance is with respect to these parameters. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a gap in the paper by pointing out that while the end of Section 2 discusses two important parameters, the experimental section (Section 3) does not mention or discuss how these parameters are set or how sensitive the performance is with respect to them. This feedback is clear and provides a logical reasoning for why the experimental section lacks this information. However, it does not provide specific examples or references to support the claim, which could make it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper by pointing out that while the end of Section 2 discusses two important parameters, the experimental section (Section 3) does not mention or discuss how these parameters are set or how sensitive the performance is with respect to them. This feedback is clear and actionable, as it provides the authors with a specific area to address in their experimental section. By highlighting this omission, the comment encourages the authors to include details on parameter settings and sensitivity analysis, which are crucial for the completeness and rigor of their work. Therefore, the comment is mostly helpful, as it offers clear guidance on what needs to be improved but could be more comprehensive with additional suggestions or examples.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a belief that the use of reinforcement learning for a static VQA task might be a potential weakness, impacting the data efficiency and training difficulty of the models. However, it does not provide any explicit or implicit suggestions on how the authors might address this concern or improve their approach. The comment lacks concrete guidance on what changes could be made to mitigate the potential weakness or how the authors might strengthen their argument. As a result, the authors are left without a clear understanding of how to proceed with their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the potential weakness of using reinforcement learning for a static VQA task, suggesting that it might make the approach less data efficient and harder to train. However, it does not specify which part of the paper this concern relates to, such as a particular section or methodology. The authors cannot confidently determine which aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its critique of the approach but lacks detailed suggestions on how to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses an opinion about the potential weakness of using reinforcement learning for a static VQA task, suggesting that it might make the approach less data efficient and harder to train. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or supporting data, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered borderline verifiable, as it provides a subjective opinion but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the potential weakness of using reinforcement learning for a static VQA task, suggesting that it might make the approach less data efficient and harder to train. While the comment identifies a potential issue, it does not provide specific suggestions or guidance on how the authors might address this concern or improve their approach. The feedback is somewhat helpful as it highlights a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the novelty of the proposed method, noting its similarity to existing attentional modules and ResNeSt. It suggests that the paper should discuss the differences between the proposed method and these existing modules. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the method need to be clarified. The action is implicit, as the authors would need to infer that they should discuss the similarities and differences with the mentioned works. The lack of concrete instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of the proposed method, noting its similarity to existing attentional modules and ResNeSt. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the similarity issue and suggesting that the paper should discuss the differences between the proposed method and existing modules. However, it lacks detailed guidance on how to address this issue or what specific aspects of the method need to be clarified. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the proposed method is limited due to its similarity to existing attentional modules and ResNeSt. The comment provides specific references to previous works [1, 2, 3] and ResNeSt [4], suggesting that the paper should discuss these similarities. However, the comment lacks detailed reasoning or examples to fully support the claim, making it somewhat verifiable. The authors would need to infer the basis for the claim, which could be improved with more explicit justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the novelty of the proposed method, noting its similarity to existing attentional modules and ResNeSt. It provides specific references to previous works, which could help the authors understand the context and differentiate their approach. However, the comment could be more helpful if it offered suggestions on how to address the similarity or how to highlight the unique aspects of the proposed method. While it points out a critical area for improvement, it lacks detailed guidance on how to enhance the paper's contribution. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting the lack of comparison with test-time adaptation (TTA) methods, specifically mentioning [A-B]. It suggests that these methods aim to adapt to out-of-distribution data when the input data is disturbed by noise, and the paper focuses on adjusting the input data while TTA methods primarily focus on updating model parameters. The reviewer questions how to prove that data processing is superior to model parameter adjustment and suggests that a comparison should be made based on experimental results. While the comment identifies a specific area for improvement and provides a clear direction for the authors to address this gap, it does not explicitly instruct the authors on how to conduct the comparison or what specific experiments to include. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to implement the suggested comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of robustness in video action recognition and highlights the lack of comparison with test-time adaptation (TTA) methods, specifically mentioning [A-B]. It suggests that these TTA methods aim to adapt to out-of-distribution data when the input data is disturbed by noise, and the paper focuses on adjusting the input data while TTA methods primarily focus on updating model parameters. The reviewer questions how to prove that data processing is superior to model parameter adjustment and suggests that a comparison should be made based on experimental results. However, the comment does not specify which part of the paper discusses robustness or TTA methods, making it weakly grounded. It is specific in identifying the need for a comparison with TTA methods, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the lack of comparison with test-time adaptation (TTA) methods in the paper, specifically mentioning [A-B]. It questions how to prove that data processing is superior to model parameter adjustment and suggests that a comparison should be made based on experimental results. However, the comment lacks specific examples or detailed reasoning to substantiate the claim, making it somewhat verifiable. The authors would need to infer the need for a comparison and the rationale behind it, which could be challenging. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by pointing out the lack of comparison with test-time adaptation (TTA) methods, specifically mentioning [A-B]. It questions how to prove that data processing is superior to model parameter adjustment and suggests that a comparison should be made based on experimental results. This feedback is somewhat helpful as it highlights a specific area for improvement and provides a clear direction for the authors to address the gap. However, the comment could be more helpful if it provided more detailed guidance on how to conduct the comparison or what specific experiments to include. Overall, the comment offers valuable insights that can guide the authors in enhancing their work, but it could be more comprehensive with additional details.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the first expression for J (\u03b8) in Section 3.2.1 is incorrect and provides the correct expression. This direct feedback allows the authors to identify the specific issue and correct the expression in their draft. The action is explicit and concrete, as it clearly indicates which part of the paper needs revision and what the correct expression should be. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Section 3.2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies that the first expression for J (\u03b8) is incorrect and provides the correct expression, making the comment fully grounded and specific. This level of detail enables the authors to understand exactly what needs to be corrected and how to do it. Therefore, the comment is rated as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first expression for J (\u03b8) in Section 3.2.1 is incorrect and provides the correct expression. However, it does not offer any reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why the expression is incorrect or how to correct it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific error in Section 3.2.1, pointing out that the first expression for J (\u03b8) is incorrect and providing the correct expression. This feedback is clear and actionable, allowing the authors to directly address the issue and improve the accuracy of their paper. By correcting the expression, the authors can enhance the reliability and credibility of their work. The comment is specific and provides a clear direction for improvement, making it highly helpful for the authors. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific examples of capitalization issues in the references, such as \"ai\" in Amodei et al. (2016), \"bayesian\" in many papers, and \"Advances in neural information processing systems\" in several papers. It also mentions specific publications, such as Dusenberry et al. (2020) in ICML 2020, Osawa et al. (2019) in NeurIPS 2019, and Swiatkowski et al. (2020) in ICML 2020, along with a reference to p. 13, supplement, Fig. This explicit instruction to capitalize specific words in the references provides clear guidance on what needs to be addressed, making the comment highly actionable. The authors know exactly which parts of the references require correction and how to implement the suggested changes. Therefore, this comment is rated as 5.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections and references, such as \"p.8\" and \"p. 13, supplement, Fig.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the issue of capitalization errors in the references, providing clear guidance on what needs to be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that various words in the references need capitalization, such as \"ai\" in Amodei et al. (2016), \"bayesian\" in many papers, and \"Advances in neural information processing systems\" in several papers. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies specific issues with the capitalization of words in the references, such as 'ai' in Amodei et al. (2016), 'bayesian' in many papers, and 'Advances in neural information processing systems' in several papers. It also provides specific examples of publications that need correction, such as Dusenberry et al. (2020) in ICML 2020, Osawa et al. (2019) in NeurIPS 2019, and Swiatkowski et al. (2020) in ICML 2020. This feedback is clear and actionable, as it directs the authors to specific areas where capitalization errors need to be addressed. By providing concrete examples and references, the comment helps the authors improve the accuracy and professionalism of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.\", 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions about the lack of clarity regarding parameter values and their selection process. It explicitly asks for the model parameters for task 1, the lambda value for the Boltzmann policy, and how these parameters were chosen, specifically mentioning maximum likelihood estimates. While the comment prompts the authors to provide these details, it does not offer explicit guidance on how to incorporate this information into the draft. The action is implicit, as the authors need to infer that they should include these details in their paper. However, the comment lacks concrete instructions on how to present or integrate this information, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the lack of clarity regarding parameter values and their selection process, specifically mentioning the model parameters for task 1 and the lambda value for the Boltzmann policy. However, it does not specify which part of the paper these parameters are discussed or how they were chosen. The comment is fully grounded in that it mentions specific elements of the paper, but it is not specific about what needs to be addressed. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises questions about the lack of clarity regarding parameter values and their selection process, specifically asking for the model parameters for task 1 and the lambda value for the Boltzmann policy. It also questions how these parameters were chosen, suggesting that maximum likelihood estimates were used. However, the comment does not provide any evidence or reasoning to support these claims, leaving the authors without guidance on how to address these issues. The lack of specific examples or references makes the claim unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises important questions about the lack of clarity regarding parameter values and their selection process, specifically asking for the model parameters for task 1 and the lambda value for the Boltzmann policy. It also questions how these parameters were chosen, suggesting that maximum likelihood estimates were used. This feedback is somewhat helpful as it identifies specific areas where the authors need to provide more detail, but it lacks depth and does not offer suggestions on how to improve the clarity or completeness of the paper. The comment could be more helpful if it provided guidance on how to present or justify the parameter choices, making it a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the authors' claim of achieving state-of-the-art results is not convincing, as the performance is primarily due to the first step, making comparisons with existing detection methods reasonable. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to substantiate their claim. The feedback is somewhat vague and lacks concrete details, leaving the authors uncertain about how to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"state-of-the-art results\" and \"challenging scene text recognition tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the authors' claim, suggesting that the performance is primarily due to the first step, which makes comparisons with existing detection methods reasonable. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' claim of achieving state-of-the-art results is not convincing, as the performance is primarily due to the first step, making comparisons with existing detection methods reasonable. However, the comment lacks specific evidence or examples to support this claim. It does not provide detailed reasoning or references to substantiate the assertion that the performance is primarily due to the first step. Without this additional information, the claim remains somewhat verifiable, as it lacks sufficient justification for the authors to address it effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors\\' claim of achieving state-of-the-art results on challenging scene text recognition tasks. It suggests that the performance is primarily due to the first step, which makes comparisons with existing detection methods reasonable. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or substantiate their claim. While it raises a valid concern, the feedback lacks actionable advice, making it somewhat helpful. The authors would need to conduct additional experiments or provide more detailed analysis to address the concern effectively. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the GuessWhat?! model when Conditional Batch Norm (CBN) is applied to different layers. It asks the authors to provide some insight or explanation for this observation. While the comment suggests that the authors should consider why the performance deteriorates when CBN is applied to layer 2 in addition to layers 3 and 4, it does not provide explicit guidance on how to address this issue or what actions the authors should take. The action is implicit, as the authors need to infer that they should investigate and explain the performance difference. However, the comment lacks concrete details on how to approach this investigation, making it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with applying Conditional Batch Norm (CBN) to layer 2 in addition to layers 3 and 4, and it questions why this approach might deteriorate performance compared to applying CBN to layers 4 and 3 only. This provides a clear direction for the authors to address the concern. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance of the GuessWhat?! model when Conditional Batch Norm (CBN) is applied to different layers. It asks the authors to provide some insight or explanation for why applying CBN to layer 2 in addition to layers 3 and 4 might deteriorate performance compared to applying it to layers 4 and 3 only. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim. Without additional context or explanation, the authors may find it challenging to understand or address the issue raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the performance of the GuessWhat?! model when Conditional Batch Norm (CBN) is applied to different layers. It highlights a potential issue where applying CBN to layer 2 in addition to layers 3 and 4 leads to a performance deterioration compared to applying it to layers 4 and 3 only. This observation is intriguing and prompts the authors to investigate and understand the underlying reasons for this phenomenon. However, the comment lacks detailed guidance or suggestions on how to address this issue or what experiments might be necessary to explore the cause. While it identifies a potential area for improvement, the feedback is somewhat limited in its scope and depth, making it somewhat helpful. The authors would benefit from additional insights or suggestions to fully address the concern.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the lack of comparison to a highly relevant method that utilizes both inter-task and intra-task ensembles. It explicitly mentions that the authors did not include a method comparison or performance comparison with this relevant method. This feedback is clear and provides a direct action for the authors to take, which is to include a comparison with the mentioned method. The comment is explicit and concrete, as it specifies exactly what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of comparison with a highly relevant method, providing clear guidance on what part of the paper needs improvement. It specifies the issue by mentioning the method that should have been compared, which helps the authors understand exactly what needs to be addressed. The comment is also specific, as it clearly identifies the missing comparison and suggests that the authors should include it. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors did not include a comparison with a highly relevant method that utilizes both inter-task and intra-task ensembles. However, the comment lacks specific details or references to support this claim. It does not provide examples of how the comparison could be made or why it is important. Without this additional information, the claim remains somewhat verifiable, as the authors may need to infer the missing details to address the feedback effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of comparison with a highly relevant method that utilizes both inter-task and intra-task ensembles. It highlights that the authors did not include a method comparison or performance comparison with this relevant method, which is a critical oversight. This feedback is clear and actionable, as it directs the authors to address this gap by incorporating a comparison with the mentioned method. By doing so, the authors can enhance the comprehensiveness and depth of their analysis, making the paper more robust and informative. Therefore, the comment is highly helpful, as it provides specific guidance on how to improve the draft.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors' claim that their proposed method cannot handle headpose, suggesting that a previous work (Gafni et al. ICCV 2021) can control both facial expression and headpose. The comment implies that the authors should consider conditioning headpose parameters in NeRF, similar to the approach in the cited work. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific changes are needed in the draft. The action is implicit and vague, leaving the authors uncertain about the exact steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the authors' claim that their proposed method cannot handle headpose, suggesting that a previous work (Gafni et al. ICCV 2021) can control both facial expression and headpose. It implies that the authors should consider conditioning headpose parameters in NeRF, similar to the approach in the cited work. However, the comment does not specify which part of the paper discusses the proposed method or headpose handling, making it weakly grounded. The comment is specific in questioning the authors' claim and suggesting an alternative approach, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' claim that their proposed method cannot handle headpose, suggesting that a previous work (e.g., Gafni et al. ICCV 2021) can control both facial expression and headpose. The comment implies that the authors should consider conditioning headpose parameters in NeRF, similar to the approach in the cited work. However, the comment lacks specific examples or detailed reasoning to fully support the claim, making it somewhat verifiable. The authors would need to provide more evidence or explanation to substantiate the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the authors' claim that their proposed method cannot handle headpose, suggesting that a previous work (Gafni et al. ICCV 2021) can control both facial expression and headpose. The comment implies that the authors should consider conditioning headpose parameters in NeRF, similar to the approach in the cited work. However, the comment lacks specific guidance or suggestions on how to address this issue or improve the draft. While it identifies a potential area for improvement, it does not provide actionable steps or detailed reasoning, making it somewhat helpful. The authors would need to expand on the comment to fully understand how to incorporate the suggested approach into their work. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a similarity between the spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns appearing a few times in the training set. It provides examples of how these triggers have been used in previous work, such as random noise patterns by Chen et al. (2017) and single-pixel or simple patterns by Gu et al. (2019). However, the comment does not explicitly instruct the authors to address this similarity or provide specific guidance on how to improve their draft based on this observation. While the authors might infer that they should discuss or differentiate their spurious features from existing backdoor triggers, the lack of explicit action or detailed guidance makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the similarity between the spurious features and backdoor triggers, providing examples of how these triggers have been used in previous work. This allows the authors to understand what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the spurious features in Section 3.1 and 3.2 are similar to backdoor triggers, noting that both are artificial patterns appearing a few times in the training set. It provides examples of how these triggers have been used in previous work, such as random noise patterns by Chen et al. (2017) and single-pixel or simple patterns by Gu et al. (2019). This claim is supported by logical reasoning and references to specific examples, making it mostly verifiable. The authors can understand the basis of the claim and how it relates to their work, allowing them to address it effectively. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant similarity between the spurious features discussed in Section 3.1 and 3.2 and backdoor triggers, which are artificial patterns that appear only a few times in the training set. It provides examples of how these triggers have been used in previous work, such as random noise patterns by Chen et al. (2017) and single-pixel or simple patterns by Gu et al. (2019). This observation is valuable as it highlights a potential issue with the novelty or distinctiveness of the spurious features discussed in the paper. However, the comment could be more helpful if it provided specific guidance on how the authors might address this similarity or differentiate their work from existing studies. While it offers a starting point for discussion, it lacks detailed suggestions or actionable advice, making it somewhat helpful. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a structural optimization component that has been emphasized multiple times, but it points out that the optimization algorithm is directly derived from previous works. This feedback suggests that the authors should clarify the novelty and contribution of their optimization approach. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects need to be revised. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the novelty of their optimization algorithm. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the structural optimization component of the paper, which is a specific part of the work. However, it does not explicitly mention which section or part of the paper discusses this optimization, making it weakly grounded. The comment is specific in identifying that the optimization algorithm is directly from previous works, which reduces the contribution. This provides clear guidance on what needs to be addressed, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact section to focus on. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the optimization algorithm is directly from previous works, which reduces the contribution. However, the comment does not provide specific examples or references to support this claim. Without detailed evidence or examples, the authors may find it difficult to verify the claim and understand the basis for the criticism. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the structural optimization component of the paper, noting that it seems to be directly derived from previous works. This observation raises concerns about the novelty and contribution of the optimization approach. While the comment highlights a specific area that needs clarification, it does not provide detailed guidance on how to address this issue or suggest specific improvements. The feedback is somewhat helpful as it points out a potential weakness, but it lacks depth and actionable suggestions, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the experimental results, noting that the pipeline method does not yield better average results compared to baseline models. It also points out that the baseline models are not well introduced in the experiments. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes need to be made to the draft. The action is implicit, as the authors would need to infer that they should improve the introduction of baseline models and potentially re-evaluate the experimental results. The lack of concrete instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental results of a pipeline method, specifically noting that it does not yield better average results for both XVNLI and MaRVL. It also points out that the baseline models are not well introduced in the experiments. However, the comment does not specify which part of the paper discusses the experimental results or the introduction of baseline models, making it weakly grounded. The comment is specific in detailing the issue with the results and the lack of introduction of baseline models, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the pipeline method does not yield better average results for both XVNLI and MaRVL, and that the baseline models are not well introduced in the experiments. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to verify the accuracy of the feedback. Without detailed evidence or examples, the claim remains somewhat verifiable, as the authors may need to conduct further investigation to confirm the issues. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the experimental results, noting that the pipeline method does not yield better average results for both XVNLI and MaRVL. It also points out that the baseline models are not well introduced in the experiments. While the comment highlights a potential weakness in the experimental setup, it does not provide detailed guidance on how the authors might address this issue or what specific changes could be made to improve the results or the introduction of baseline models. The feedback is somewhat helpful as it directs the authors' attention to an important aspect of their experimental evaluation, but it lacks depth and actionable suggestions, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the necessity of reproducing a well-known result using a \"coarse\" methodology, suggesting that the observation has been made at each step of the evolution of language models. However, it does not provide explicit or implicit actions for the authors to take, such as suggesting alternative methodologies or providing more detailed analysis. The comment lacks concrete guidance on how the authors might address this concern or improve their draft. As a result, the comment is unactionable, aligning with a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"coarse\" methodology used in reproducing a well-known result in the literature, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the methodology, questioning its necessity given prior observations. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have reproduced a well-known result using a \"coarse\" methodology, questioning the necessity of this approach given prior observations. However, the comment lacks specific examples or detailed reasoning to support the claim that the methodology is indeed \"coarse\" or why it needs to be reproduced. Without additional context or evidence, the claim is difficult to verify, making it unverifiable. Therefore, the comment aligns with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment questions the authors' methodology for reproducing a well-known result, specifically the observation of political bias in language models. It suggests that the authors' approach, which involves passing a binary stance classifier over ChatGPT's output, is 'coarse' and that the observation has been made at each step of the evolution of these models. This raises concerns about the novelty and significance of the authors' findings. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the authors' discussion by noting that they primarily focus on SSC and do not adequately contrast their method with other computationally efficient and theoretically sound subspace clustering methods like TSC and greedy subspace clustering by Park. While the comment identifies a specific area where the authors could improve their discussion, it does not provide explicit guidance on how to address this gap or what specific aspects of the contrast should be included. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their discussion to include these methods. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the focus on SSC and the lack of contrast with other methods like thresholded subspace clustering (TSC) and greedy subspace clustering by Park. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue of not contrasting the proposed method with other computationally efficient and theoretically sound subspace clustering methods, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors primarily focus on SSC and do not adequately contrast their method with other computationally efficient and theoretically sound subspace clustering methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. Without detailed reasoning or examples, the claim is somewhat verifiable, as it provides a general observation but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap in the authors' discussion by pointing out that they primarily focus on SSC without adequately contrasting their method with other computationally efficient and theoretically sound subspace clustering methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. This feedback is somewhat helpful as it highlights an area where the authors could enhance their discussion and provide a more comprehensive comparison of their method with existing approaches. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address this gap, such as suggesting additional comparisons or analyses that could be included in the paper. Overall, the comment offers a clear direction for improvement but lacks the depth needed for full impact.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the term \"semantic\" segmentation is not low-level because the categories are specified for each pixel, implying that the statements about semantic segmentation being a low-level cue should be removed. This comment provides a clear and explicit action for the authors to take, which is to remove the statements about semantic segmentation being a low-level cue. The action is also concrete, as it specifies exactly what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the term \"semantic\" segmentation is not low-level because the categories are specified for each pixel, implying that the statements about semantic segmentation being a low-level cue should be removed. However, the comment does not specify which part of the paper discusses semantic segmentation or low-level cues, making it difficult for the authors to identify the exact section or figure that needs revision. While the comment is specific about the content that needs removal, it lacks grounding as it does not provide explicit references to the relevant sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"semantic\" segmentation is not low-level because the categories are specified for each pixel, suggesting that statements about semantic segmentation being a low-level cue should be removed. However, the comment does not provide any specific reasoning or evidence to support this claim, such as examples or references to other works that might challenge the assumption. Without detailed justification or examples, the claim remains unsubstantiated, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the terminology used in the paper, suggesting that \"semantic\" segmentation is not low-level due to the pixel-specific categories. This feedback is clear and actionable, as it directs the authors to remove potentially misleading statements about semantic segmentation. However, the comment could be more helpful if it provided additional context or examples to support the claim, or if it suggested alternative ways to frame the discussion. Overall, the comment offers valuable guidance for improving the clarity and accuracy of the paper, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a significant weakness in the paper, specifically the limited scope of the experiments section. It highlights that the results are presented only on the CIFAR-10 dataset and suggests considering other datasets from federated learning benchmarks, such as those available on the LEAF benchmark. The comment also recommends exploring relevant works like FedProx and FedMAX for details on different datasets and model types. However, the comment does not provide explicit guidance on how the authors should expand their experiments or what specific datasets or model types they should consider. While the action is implied, it lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experiments, namely that they are limited to the CIFAR-10 dataset and do not consider other datasets from federated learning benchmarks. The comment provides specific examples of relevant datasets and suggests considering additional works for details on different datasets and model types. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments section is a main weakness of the paper, as the results are presented only on the CIFAR-10 dataset and do not consider other datasets from federated learning benchmarks. The comment suggests considering datasets from the LEAF benchmark and recommends exploring relevant works like FedProx and FedMAX for details on different datasets and model types. However, the comment lacks specific examples or detailed reasoning to fully support the claim, making it somewhat verifiable. The authors would need to infer the need for a more comprehensive evaluation based on the provided information, which limits the verifiability of the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the limited scope of the experiments section. It points out that the results are presented only on the CIFAR-10 dataset and suggests considering other datasets from federated learning benchmarks, such as those available on the LEAF benchmark. The comment also recommends exploring relevant works like FedProx and FedMAX for details on different datasets and model types. This feedback is mostly helpful as it provides clear guidance on how the authors can enhance the comprehensiveness of their experimental evaluation, which is crucial for addressing the main weakness of the paper. However, it could be more helpful if it included specific suggestions on which datasets or model types to consider. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the claim that the proposed modules improve in both accuracy and completeness based on a table, asking for clarification. It suggests using another dataset for the ablation study, such as the training set of Tanks & Temples or ETH3D. While the comment implies that the authors should consider using a different dataset, it does not explicitly instruct them to do so or provide detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer that they should use another dataset for the ablation study. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the claim made in the paper regarding the improvement of proposed modules in accuracy and completeness, referencing a table. However, it does not specify which part of the paper the table is located in, making it difficult for the authors to identify the exact section being addressed. The comment suggests using another dataset for the ablation study, such as the training set of Tanks & Temples or ETH3D, but it does not provide specific guidance on how to implement this suggestion or why it is necessary. This lack of grounding and specificity makes it challenging for the authors to understand and address the feedback effectively. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the claim that the proposed modules improve in both accuracy and completeness based on a table, asking for clarification. It suggests using another dataset for the ablation study, such as the training set of Tanks & Temples or ETH3D. However, the comment does not provide any specific reasoning or evidence to support the claim that the current dataset is sufficient or why the suggested datasets would be more appropriate. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment questions the claim that the proposed modules improve in both accuracy and completeness based on a table, asking for clarification. It suggests using another dataset for the ablation study, such as the training set of Tanks & Temples or ETH3D, to provide a more comprehensive evaluation. This feedback is somewhat helpful as it identifies a potential area for improvement in the experimental setup and encourages the authors to consider using additional datasets for a more robust analysis. However, the comment could be more helpful if it provided specific guidance on how to implement the suggestion or why the additional datasets would be beneficial. Overall, the comment offers a clear direction for improvement but lacks depth, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the explanation of how a small degree of bias arises from a clear community structure, noting that Theorem 1 and 2 prove the relationship but do not provide an intuitive understanding. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so or suggest specific ways to improve the explanation. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on the relationship between community structure, degree bias, and the theorems. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the explanation of how a small degree of bias arises from a clear community structure, referencing Theorem 1 and 2. However, it does not specify which part of the paper this explanation is intended for, making it weakly grounded. The comment is specific in its critique of the lack of intuitive understanding of the relationship between community structure, degree bias, and the theorems. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the explanation of how a small degree of bias arises from a clear community structure is insufficient, noting that Theorem 1 and 2 prove the relationship but do not provide an intuitive understanding. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to fully understand and address the issue. The feedback is somewhat verifiable as it identifies a gap in the explanation but does not provide enough detail to guide the authors in improving their understanding. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by providing more detailed explanations. It points out that while Theorem 1 and 2 prove the relationship between community structure and degree bias, the explanation of how a small degree of bias arises from a clear community structure is not intuitive enough. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their explanation. However, it could be more helpful if it suggested specific ways to improve the explanation or provided examples to illustrate the concept. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the construction of clean exemplar manifolds for non-stochastic networks, specifically in the context of the ResNet50 and ATResNet50 networks. It implies that the authors need to clarify how these clean manifolds are constructed, particularly when the exemplar manifolds are derived from stochasticity. However, the comment does not provide explicit guidance on how to address this issue or what specific actions the authors should take. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 182-183, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the construction of clean exemplar manifolds for non-stochastic networks, particularly in the context of the ResNet50 and ATResNet50 networks. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the construction of clean exemplar manifolds for non-stochastic networks, specifically in the context of the ResNet50 and ATResNet50 networks. It questions how these manifolds are constructed when the exemplar manifolds are derived from stochasticity. However, the comment does not provide any evidence, reasoning, or references to support the claim that the construction of clean manifolds for non-stochastic networks is unclear or problematic. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a specific question about the construction of clean exemplar manifolds for non-stochastic networks, particularly in the context of the ResNet50 and ATResNet50 networks. It points out a potential inconsistency in the description of how these manifolds are constructed, as the paper mentions both adversarial perturbations and stochasticity in the construction of exemplar manifolds. This feedback is somewhat helpful as it identifies a potential area of confusion and encourages the authors to clarify their methodology. However, it could be more helpful if it provided additional context or suggested specific ways to address the issue. Overall, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the motivation for the choice of $\\theta = \\frac{\\pi}{2}(1-h)$ from Theorem 3. It points out that the paper states the choice is empirical but does not provide sufficient motivation for this specific form. While the comment suggests that the authors should clarify the motivation, it does not offer concrete guidance on how to do so. The action is implicit, as the authors need to infer that they should provide more detailed reasoning or justification for the choice of $\\theta$. However, the lack of specific guidance on what kind of motivation to include makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the motivation for the choice of $\\theta = \\frac{\\pi}{2}(1-h)$ from Theorem 3, but it does not specify which part of the paper this choice is discussed in. The authors can infer that it relates to the section or theorem where this choice is made, but the comment lacks explicit grounding. However, it is specific in detailing the issue with the motivation, as it points out the lack of clarity and the need for more detailed reasoning. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation for the choice of $\\theta = \\frac{\\pi}{2}(1-h)$ from Theorem 3 is not straightforward and clear. It suggests that the paper states the choice is empirical but lacks detailed motivation for this specific form. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the criticism. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the motivation for the choice of $\\theta = \\frac{\\pi}{2}(1-h)$ from Theorem 3. It points out that the paper states the choice is empirical but lacks detailed motivation for this specific form. This feedback is clear and actionable, as it directs the authors to provide more detailed reasoning or justification for their choice. However, the comment could be more helpful if it suggested specific ways to enhance the motivation, such as providing examples or references that support the empirical basis. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the sufficiency of the evaluation for the shape model invariance study, specifically questioning whether quantitative results on testing images are needed. While the comment implies that the authors should consider including such results, it does not explicitly instruct them to do so or provide detailed guidance on how to incorporate them. The action is implicit and somewhat vague, as the authors are left to infer that they should include quantitative results on testing images. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the shape model invariance study, specifically questioning the sufficiency of evaluation on training images. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table. This makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific about the need for quantitative results on testing images, the lack of grounding makes it challenging for the authors to understand the exact scope of the issue. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the sufficiency of the evaluation for the shape model invariance study, specifically questioning whether quantitative results on testing images are needed. While the comment implies that the authors should consider including such results, it does not provide any specific reasoning or evidence to support this claim. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support to fully address the issue.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a specific concern about the evaluation of the shape model invariance study, questioning whether the current evaluation on training images is sufficient. It suggests that the authors should consider including quantitative results on testing images to fully support their claims. This feedback is clear and actionable, as it provides a direct suggestion for improvement that could enhance the robustness and comprehensiveness of the study. However, the comment could be more helpful if it offered additional guidance on how to conduct the testing or what specific metrics to use. Overall, the comment is mostly helpful, as it identifies a clear area for improvement and provides a specific direction for the authors to follow.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors have missed a related work, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which deals with hypergraph data and tensors. The comment implies that this related work should be discussed and compared against to provide a better understanding of the state-of-the-art. However, it does not explicitly instruct the authors to include or discuss this work in their draft. The action is implicit and somewhat vague, as the authors need to infer that they should address this omission. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the AAAI15 paper by Ghoshdastidar and Dukkipati, allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the authors should discuss and compare their work against this related paper to provide a better understanding of the state-of-the-art. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have missed a related work, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which deals with hypergraph data and tensors. The comment suggests that this related work should be discussed and compared against to provide a better understanding of the state-of-the-art. However, the comment lacks specific examples or detailed reasoning to support why this comparison is necessary or how it would enhance the paper. Without additional context or evidence, the claim is somewhat verifiable, as it provides a basis for improvement but lacks depth and clarity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the related work section by pointing out the omission of a relevant paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati. This paper deals with hypergraph data and tensors, which are pertinent to the authors' work. By suggesting that the authors discuss and compare their approach against this related work, the comment provides a clear direction for improving the paper. It highlights the importance of situating the authors' contribution within the existing literature, thereby enhancing the paper's comprehensiveness and impact. However, the comment could be more helpful if it provided specific guidance on how to discuss or compare the works, such as suggesting specific aspects of the related work that should be addressed. Overall, the comment is mostly helpful as it identifies a crucial area for improvement and offers a clear direction for the authors to follow.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns regarding the scalability of the optimal transport distance computation and the exact method used. It questions whether the method scales on normal machines with a few cores and asks for clarification on how the Sinkhorn method, which produces a doubly stochastic matrix, is used to compute the optimal transport. While the comment explicitly asks for clarification and questions, it does not provide explicit instructions on how to address these issues or what specific actions the authors should take. The actions are implicit and somewhat vague, as the authors are left to infer how to respond. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the scalability of the optimal transport distance computation, specifically questioning whether it scales on normal machines with a few cores. It also asks for clarification on how the Sinkhorn method, which produces a doubly stochastic matrix, is used to compute the exact optimal transport. However, the comment does not specify which part of the paper discusses the optimal transport distance or the Sinkhorn method, making it weakly grounded. The specificity of the comment is moderate as it clearly identifies the issues with scalability and the exact computation method. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the scalability of the optimal transport distance computation and the exact method used, specifically mentioning the Sinkhorn method. It does not contain any subjective opinions or claims that require verification. The questions are factual and seek clarification, aligning with the classification of \"No Claim.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two important questions regarding the scalability of the optimal transport distance computation and the exact method used. It questions whether the method scales on normal machines with a few cores, which is a crucial aspect for practical application. Additionally, it asks for clarification on how the Sinkhorn method, which produces a doubly stochastic matrix, is used to compute the exact optimal transport. These questions are valuable as they highlight potential limitations and areas for further clarification in the paper. However, the comment could be more helpful if it provided some guidance or suggestions on how to address these issues or if it offered more detailed insights into the implications of these questions. Overall, the comment is somewhat helpful as it identifies important areas for improvement but lacks depth and actionable suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that the paper was difficult to follow, specifically mentioning the difficulty in understanding the experimental procedures and evaluations. However, it does not provide any explicit or implicit actions for the authors to take to improve the clarity of the paper. The comment lacks guidance on how the authors might address these issues, such as suggesting specific sections to clarify or providing examples of how to improve the writing. Without concrete suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses difficulty in following the paper, specifically mentioning the difficulty in understanding the experimental procedures and evaluations. However, it does not specify which part of the paper is hard to follow, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need improvement. Additionally, the comment does not provide specific suggestions or guidance on how to address these issues, such as clarifying the procedures or providing additional examples. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a subjective opinion about the difficulty in following the paper, specifically mentioning the difficulty in understanding the experimental procedures and evaluations. However, it does not provide any specific evidence, examples, or references to support this claim. Without any supporting evidence, the claim remains subjective and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment highlights a significant issue with the paper's readability, specifically noting the difficulty in following the experimental procedures and evaluations. This feedback is valuable as it points out a critical area where the authors need to improve the clarity and organization of their work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as providing more detailed explanations, examples, or a clearer structure. While it identifies a clear problem, the absence of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the generalizability of the parameters in Table 1, suggesting that they might be specific to image data and ViT. It implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models like CNNs in the image domain. However, the comment does not provide explicit guidance on how to conduct this exploration or what specific steps the authors should take. While the action is implied, it lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the generalizability of the parameters in Table 1, suggesting that they might be specific to image data and ViT. It implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models like CNNs in the image domain. However, the comment does not specify which part of the paper discusses the parameters or the experiments, making it weakly grounded. It is specific in suggesting that the authors should consider applying the principles to other areas, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the generalizability of the parameters in Table 1, suggesting that they might be specific to image data and ViT. It implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models like CNNs in the image domain. However, the comment lacks specific examples or references to support the claim that the parameters are only applicable to image data and ViT. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it lacks the necessary depth to fully substantiate the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a pertinent question about the generalizability of the parameters in Table 1, suggesting that they might be specific to image data and ViT. It implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models like CNNs in the image domain. This feedback is somewhat helpful as it points out a potential limitation in the scope of the study and encourages the authors to consider broader applicability. However, the comment could be more helpful if it provided specific guidance on how to conduct this exploration or what additional experiments might be necessary. Overall, the comment offers a valuable suggestion for improvement but lacks detailed actionable advice, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should evaluate their TTA methods on more conditions of natural distribution shift, specifically mentioning WILDS [9]. This provides a clear and explicit action for the authors to take, as they know exactly what additional experiments to conduct to strengthen their paper. The comment is specific and concrete, offering a direct path for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests evaluating TTA methods on more conditions of natural distribution shift, specifically mentioning WILDS [9]. This provides a clear and explicit reference to a specific area of the paper where additional evaluation is needed. The authors can easily identify the part of the paper that requires further evaluation, making the comment fully grounded. The comment is also specific, as it specifies the need to evaluate TTA methods on WILDS, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should evaluate their TTA methods on more conditions of natural distribution shift, specifically mentioning WILDS [9]. This claim is somewhat verifiable as it provides a specific example of an additional evaluation that could strengthen the paper. However, it lacks detailed reasoning or references to support why this additional evaluation is necessary or beneficial. The authors would need to infer the importance of this suggestion, which could be improved with more detailed justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the evaluation of TTA methods, specifically noting that using non-standard benchmarks can break popular TTA methods. It suggests that the authors should consider evaluating their TTA methods on more conditions of natural distribution shift, such as WILDS [9], to strengthen the paper. This feedback is clear and actionable, providing a specific direction for the authors to improve their work. However, it could be more helpful if it included additional suggestions or considerations for the evaluation process. Overall, the comment is mostly helpful as it offers a clear and actionable improvement for the authors to consider.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the utility of tensor networks in representing the PMF of discrete variables for machine learning algorithms or analysis. It suggests that the significance of the paper is poor due to this lack of clarity. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the paper need clarification. The action is implicit and vague, as it does not specify which parts of the paper need to be revised or how the authors can demonstrate the utility of tensor networks. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the utility of tensor networks in representing the PMF of discrete variables for machine learning algorithms or analysis, suggesting that the significance of the paper is poor. However, it does not specify which part of the paper this issue is raised in, making it difficult for the authors to pinpoint the exact section that needs addressing. The comment is specific in its critique of the paper's significance but lacks grounding as it does not provide clear references or sections to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the utility of tensor networks in representing the PMF of discrete variables for machine learning algorithms or analysis, suggesting that the significance of the paper is poor. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or evidence to substantiate the assertion that the significance of the paper is poor. As a result, the claim is not well-supported, making the comment unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by questioning the utility of tensor networks in representing the PMF of discrete variables for machine learning algorithms or analysis. It suggests that the significance of the paper is poor due to this lack of clarity. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve the paper's significance. While it highlights an important area for clarification, the feedback lacks actionable advice, making it somewhat helpful. The authors would need to infer how to improve their draft based on this feedback, which limits its overall helpfulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the experimental results of the paper, specifically questioning the motivation for solving a POMDP problem with a non-convex value function. The reviewer provides examples of such problems, including surveillance in museums with thresholded rewards and privacy-preserving data collection. However, the comment does not explicitly instruct the authors to address this concern or provide suggestions on how to improve the experimental section. The authors are left to infer that they need to include experiments or simulations related to the mentioned settings to make the experiments section more useful. While the action is implicit and somewhat vague, it provides a clear direction for improvement, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experimental results of the paper and the specific examples used to motivate the solution of a POMDP problem with a non-convex value function. It also specifies the issue by questioning the lack of experiments or simulations related to these settings, making it clear what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses a concern about the experimental results of the paper, specifically questioning the motivation for solving a POMDP problem with a non-convex value function. The reviewer provides examples of such problems, including surveillance in museums with thresholded rewards and privacy-preserving data collection. However, the comment does not offer any specific evidence, reasoning, or references to support the claim that the experiments are not useful or that the examples are insufficient. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the concern, rendering the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the experimental results of the paper, specifically questioning the motivation for solving a POMDP problem with a non-convex value function. The reviewer provides examples of such problems, including surveillance in museums with thresholded rewards and privacy-preserving data collection, and points out the lack of experiments or simulations related to these settings. This feedback is somewhat helpful as it identifies a potential gap in the experimental section, suggesting that the authors should include more relevant experiments to make the section more useful. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address this issue, such as proposing additional experiments or simulations that align with the examples provided. Overall, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that epoch-wise analysis, particularly in finite sum settings, could provide valuable insights into the behavior of optimization algorithms. It offers specific examples, such as investigating the effects of batch size and different sampling strategies on the algorithms' progress after each full pass of the data. Additionally, it suggests that this analysis could be used for comparative studies between deterministic and stochastic methods. However, the comment does not provide explicit guidance on how the authors should conduct this analysis or what specific aspects of the algorithms to focus on. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that epoch-wise analysis, especially for finite sum settings, could provide insights into the behavior of optimization algorithms. It provides specific examples, such as investigating the effects of batch size and different sampling strategies on the algorithms' progress after each full pass of the data. This guidance is clear and specific, as it outlines potential areas for further analysis and comparison between deterministic and stochastic methods. However, the comment does not explicitly mention which part of the paper this analysis should be applied to, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that epoch-wise analysis, particularly in finite sum settings, could provide valuable insights into the behavior of optimization algorithms. It offers specific examples, such as investigating the effects of batch size and different sampling strategies on the algorithms' progress after each full pass of the data. This claim is somewhat verifiable as it provides a logical reasoning for why such analysis could be beneficial, but it lacks specific references or detailed examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that epoch-wise analysis, especially in finite sum settings, could provide valuable insights into the behavior of optimization algorithms. It offers specific examples, such as investigating the effects of batch size and different sampling strategies on the algorithms' progress after each full pass of the data. This could help with comparative analysis between deterministic and stochastic methods. However, the comment lacks detailed guidance on how the authors should conduct this analysis or what specific aspects of the algorithms to focus on. While it provides a direction for improvement, it does not offer concrete steps or detailed suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the authors' claim about the immense workload but disagrees with the assessment of the paper's contribution as incremental. It suggests that the paper is essentially a combination of GraphRAG and GraphCare [1] and points out that many key baselines were not cited. The comment also notes that essential RAG algorithms for EHR, such as MedRetriever [2], and commonly used GraphRAG algorithms like KGRAG [3], should have been introduced. However, the comment does not provide explicit guidance on how the authors should address these issues, such as suggesting specific sections to revise or how to incorporate the missing information. While the action is implied, it is vague and lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the authors' claim about the immense workload and the incremental contribution of the article, referencing specific works [1], [2], and [3]. It also provides specific suggestions for improvement, such as introducing essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG. This level of detail allows the authors to understand exactly what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' contribution is incremental and suggests that the paper is essentially a combination of GraphRAG and GraphCare [1]. It also points out that many key baselines were not cited and suggests the inclusion of essential RAG algorithms like MedRetriever [2] and commonly used GraphRAG algorithms like KGRAG [3]. However, the comment lacks specific examples or detailed reasoning to fully support these claims. While the suggestions are logical, the absence of detailed evidence or references makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides valuable feedback by acknowledging the authors' claim about the immense workload but disagrees with the assessment of the paper's contribution as incremental. It suggests that the paper is essentially a combination of GraphRAG and GraphCare [1] and points out that many key baselines were not cited. Additionally, the comment highlights the need to introduce essential RAG algorithms for EHR, such as MedRetriever [2], and commonly used GraphRAG algorithms like KGRAG [3]. This feedback is mostly helpful as it offers clear suggestions for improvement, guiding the authors on what aspects of their work need attention. However, it could be more comprehensive if it provided more detailed guidance on how to address these issues or suggested specific sections for revision. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. It also raises a question about whether the performance improvement is due to the network design or the nature of ImageNet. This provides clear guidance on what needs to be done and how to address the concern, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to show a graph of T vs the number of images and Expectation(T) over the ImageNet test set, allowing the authors to accurately identify the parts of the paper that need revision. It is also specific because it provides clear guidance on what needs to be addressed, including the purpose of the graph and the question about the source of performance improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. It also raises a question about whether the performance improvement stems from the network design or the nature of ImageNet. However, the comment lacks specific examples or references to support the claim that these visualizations are necessary or how they would address the concern about performance improvement. Without detailed reasoning or evidence, the claim is difficult to verify, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the paper by requesting the inclusion of a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. It also raises a critical question about whether the performance improvement is due to the network design or the nature of ImageNet, which is important for understanding the source of the improvement. This feedback is actionable and constructive, as it guides the authors on what additional analysis and visualizations are needed to strengthen their claims. However, the comment could be more helpful if it provided more detailed guidance on how to create the graph or what specific aspects of the network design should be analyzed. Overall, the comment is mostly helpful, as it offers clear directions for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should make the paper mathematically correct, but it acknowledges that this might make other equations messy. It also questions the use of the notation L_l, suggesting that it should be introduced beforehand. While the comment provides some guidance on how to improve the paper, it lacks explicit instructions on which parts need to be revised and how to implement the changes. The action is somewhat vague, as the authors are left to infer the specific areas that require attention. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig.\" which implies a specific part of the paper, allowing the authors to accurately identify the section being addressed. It also specifies what needs to be addressed, namely the mathematical correctness of the paper and the introduction of the notation L_l. This provides clear guidance on what changes are required, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the mathematical correctness of the paper and the use of the notation L_l. However, it does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The comment lacks detailed reasoning or evidence, which hinders its verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two key areas for improvement: the mathematical correctness of the paper and the clarity of the notation L_l. It suggests that the authors should ensure the mathematical correctness of the paper, noting that making it mathematically correct might complicate other equations. Additionally, it questions the use of the notation L_l, suggesting that it should be introduced beforehand. While the comment provides some guidance on what needs to be addressed, it lacks specific examples or detailed suggestions on how to improve the mathematical correctness or introduce the notation. The feedback is somewhat helpful as it points out areas for improvement, but it could be more actionable with additional guidance. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a critical limitation in the study of sequential ensembling, specifically the lack of consideration for noise accumulation in homomorphic encryption. It points out that this omission prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to sequential ensembling and noise accumulation in the context of homomorphic encryption. It highlights a limitation that prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem and its implications, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that for sequential ensembling, it is important to study the effect of noise accumulation in the context of homomorphic encryption. It argues that this omission prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence makes it difficult for the authors to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the study of sequential ensembling, particularly the lack of consideration for noise accumulation in the context of homomorphic encryption. It highlights that this omission prevents the use of even single deep neural networks on homomorphically encrypted data, which is a significant issue. However, the comment does not provide specific guidance or suggestions on how the authors might address this limitation or improve their draft. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it identifies a meaningful weakness but lacks detailed guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case, it should be used a standard regularization trick. However, the comment does not provide any explicit or implicit guidance on how to implement this suggestion or what specific aspects of the comparison need to be addressed. The authors are left without a clear understanding of how to apply this feedback, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests using a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case. However, it does not specify which part of the paper this comparison is intended for or which section discusses the previous result. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. While the comment is specific about the type of regularization trick, the absence of explicit references or context makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests using a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case. However, the comment does not provide any specific reasoning, examples, or references to support why this approach is necessary or beneficial. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests using a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case. However, the comment lacks specificity and does not provide any guidance on how to implement this suggestion or what aspects of the comparison need to be addressed. Without additional context or examples, the authors are left without actionable feedback on how to improve their work. Therefore, the comment is barely helpful, as it identifies a potential improvement but does not offer detailed or constructive advice. The score is 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3. This provides a clear and explicit action for the authors to take, as they can directly compare the learning curves and assess the impact of mean teacher regularization. The comment is specific in its suggestion and provides a concrete action for the authors to implement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3. This provides a clear and explicit reference to a specific part of the paper, allowing the authors to accurately identify the section being addressed. The comment is specific in its suggestion, detailing what needs to be added to the graph to facilitate a comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3 to compare its learning behavior with models that have these regularizations. This claim is somewhat verifiable as it provides a specific suggestion for comparison, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the reasoning behind this suggestion, which could be improved by providing more context or justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by proposing the inclusion of a learning curve for a model without mean teacher or pi regularization in Figure 3. This addition would allow the authors to compare the learning behavior of different models and assess the impact of mean teacher regularization. The comment is clear and actionable, offering a concrete way to enhance the analysis and provide a more comprehensive understanding of the results. However, it could be more helpful if it included additional guidance on how to interpret the new data or what specific insights to draw from the comparison. Overall, the comment is mostly helpful as it directs the authors towards a valuable improvement in their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns: the handling of different types of inputs and the disordered citation. For the first part, it suggests that the authors should discuss how they deal with various inputs, such as bio-medical signals or speech, and present their solutions. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be addressed and how to do it. However, the comment does not specify which part of the paper this discussion should be included in, leaving some ambiguity. For the second part, the comment suggests that the citation is disordered, but it does not provide specific guidance on how to correct it. While the action is somewhat explicit for the first part, the second part lacks detail, making the comment somewhat actionable overall.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the handling of different types of inputs, such as bio-medical signals or speech, suggesting that the authors should discuss this and present their solutions. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in suggesting that the authors should discuss how they handle these different types of inputs and present their solutions, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two main concerns: the handling of different types of inputs and the disordered citation. While the comment suggests that the authors should discuss how they deal with various inputs, such as bio-medical signals or speech, it does not provide specific examples or references to support this claim. The suggestion to present solutions is clear, but the lack of detailed reasoning or examples makes the claim somewhat verifiable. The comment also mentions that the citation is disordered, but it does not elaborate on why it is disordered or how it should be corrected, which limits the verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main areas for improvement: the handling of different types of inputs and the disordered citation. It suggests that the authors should discuss how they deal with various inputs, such as bio-medical signals or speech, and present their solutions in the paper. This provides a clear direction for the authors to enhance the paper's content and clarity. However, the comment lacks specific guidance on how to address the disordered citation, which limits its helpfulness. While the feedback is somewhat helpful, it could be more comprehensive if it provided detailed suggestions on how to correct the citation. Therefore, the comment aligns with a score of 3, as it offers some actionable feedback but could be more detailed and comprehensive.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the question answering process, specifically mentioning that the template mapping might cause poor generalization to questions that are not 'Wh-types'/transformable. However, it does not provide any explicit or implicit suggestions on how to address this issue or what changes might be necessary. The comment lacks concrete guidance on how to improve the generalization of the model or what specific modifications could be made to the template mapping. As a result, the authors are left without a clear understanding of how to apply the feedback to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the question answering process, specifically mentioning the template mapping and its potential impact on generalization to questions that are not 'Wh-types'/transformable. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying a potential issue with the template mapping, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the question answering process might cause poor generalization to questions that are not \"Wh-types\"/transformable due to the template mapping. However, the comment lacks specific examples or references to support this claim. Without detailed evidence or examples, the authors may find it difficult to understand the basis of the concern or how to address it. Therefore, the comment is considered borderline verifiable, as it provides a claim but lacks sufficient justification or supporting details.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the question answering process, specifically mentioning that the template mapping might cause poor generalization to questions that are not \"Wh-types\"/transformable. This feedback is somewhat helpful as it highlights a specific area that could be improved, but it lacks detailed guidance on how to address the issue or what changes might be necessary. The authors are left with a general idea of the problem but without actionable steps to resolve it. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the rock-paper-scissors example is inspired by previous work and requests that the authors cite the source appropriately. While the comment implies that the authors should cite the source, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should cite the source. However, the comment provides a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"rock-paper-scissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests that the authors cite the source appropriately, providing clear guidance on what needs to be done. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the rock-paper-scissors example is inspired by an example from previous work and requests that the authors cite the source appropriately. This claim is somewhat verifiable as it suggests a specific action (citing the source) but does not provide detailed reasoning or examples to support why this is necessary. The authors would need to infer that citing the source is important to avoid plagiarism or to give proper credit to previous work. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the rock-paper-scissors example, noting that it is inspired by previous work and requests that the authors cite the source appropriately. This feedback is clear and actionable, as it directs the authors to address a potential oversight in their citation practices. By providing a specific suggestion, the comment helps the authors improve the accuracy and completeness of their work. However, the comment could be more helpful if it offered additional guidance on how to effectively integrate the example or why citing the source is crucial. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the limited nature of the innovations in network architecture design and constraint embedding, suggesting that the performance is constrained by the performance of the oracle expert. However, it does not provide explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve the innovations or the performance of the oracle expert. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the limitations of the innovations in network architecture design and constraint embedding, suggesting that the performance is constrained by the performance of the oracle expert. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or aspect that needs improvement. The comment is specific in its critique but lacks grounding as it does not provide clear references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the innovations of network architecture design and constraint embedding are limited, and that the performance is constrained by the performance of the oracle expert. However, the comment does not provide specific evidence, examples, or references to support this claim. Without detailed reasoning or supporting evidence, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically regarding the limited nature of the innovations in network architecture design and constraint embedding. It also points out that the performance is constrained by the performance of the oracle expert. While the comment highlights an area for improvement, it lacks specific suggestions or guidance on how the authors might address these limitations or enhance their work. The feedback is somewhat helpful as it directs the authors to consider the impact of the oracle expert on performance, but it does not provide actionable steps or detailed insights to improve the paper. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that comparing the model's performance only on pre-trained synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors by showing performance on real-world datasets with different losses. While the comment implies that the authors should provide this additional information, it does not explicitly instruct them to do so or specify how to implement it. The action is implicit and somewhat vague, as the authors are left to infer that they need to include results from fine-tuning on real-world datasets with different losses. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of comparing model performance only on pre-trained synthetic data, which is an important aspect of the paper. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. The comment is clear in its suggestion to demonstrate the importance of the proposed three projection errors by providing performance on real-world datasets with different losses. This makes the comment fully grounded and specific, as it clearly identifies the issue and provides a clear direction for improvement. Therefore, the comment is rated as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that comparing the model's performance only on pre-trained synthetic data is unfair and suggests demonstrating the importance of the proposed three projection errors by showing performance on real-world datasets with different losses. This claim is somewhat verifiable as it provides a logical reasoning for why the comparison might be unfair and suggests a specific way to address it. However, it lacks detailed examples or references to support the claim fully, which could make it less convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of the model's performance, suggesting that it is unfair to only compare results on pre-trained synthetic data. It recommends demonstrating the importance of the proposed three projection errors by providing performance results on real-world datasets with different losses. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by including additional experiments. However, the comment could be more helpful if it included suggestions on how to conduct these additional experiments or what specific metrics to focus on. Overall, the comment is mostly helpful, as it offers valuable guidance for enhancing the paper.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two specific issues related to the paper's content. First, it notes that the range of ID and OOD does not change much after sparsification, as seen in Figure 4. Second, it points out that Lemma 2 requires approximately identical means, which is crucial for DICE but is not well discussed. The comment suggests that the authors should provide more discussion on how to ensure DICE meets these conditions. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to do so. While the action is implied, it is vague and lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the range of ID and OOD does not change much after sparsification, and that Lemma 2 requires approximately identical means, which is crucial for DICE but is not well discussed. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the range of ID and OOD does not change much after sparsification, as seen in Figure 4, and that Lemma 2 requires approximately identical means, which is crucial for DICE but is not well discussed. The comment suggests that the authors should provide more discussion on how to ensure DICE meets these conditions. However, the comment lacks specific examples or references to support the claim that these conditions are crucial for DICE. Without detailed reasoning or evidence, the claim is difficult to verify, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two specific issues in the paper: the lack of change in the range of ID and OOD after sparsification, as shown in Figure 4, and the insufficient discussion of Lemma 2's requirements, particularly the need for approximately identical means for DICE. The comment suggests that the authors should provide more discussion on how to ensure DICE meets these conditions. While the feedback is clear and points out areas for improvement, it lacks detailed guidance or suggestions on how to address these issues. The comment is somewhat helpful as it highlights important areas that need attention, but it could be more helpful with additional actionable advice or examples. Therefore, it aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the integration of environments in the update process, suggesting that it might be necessary to integrate over all possible environments. It also points out that the bolded sections on page 6 are currently a large block of text and suggests breaking them into paragraphs for better readability. While the comment explicitly asks for clarification on the integration process, it does not provide specific guidance on how to integrate over all possible environments. The suggestion to break the bolded sections into paragraphs is concrete and actionable, as it provides a clear direction for improvement. However, the lack of explicit guidance on the integration process makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the integration of environments in the update process, suggesting that it might be necessary to integrate over all possible environments. It also points out that the bolded sections on page 6 are currently a large block of text and suggests breaking them into paragraphs for better readability. However, the comment does not specify which part of the paper these bolded sections are located in, making it difficult for the authors to identify the exact sections that need attention. While the comment is specific about the issue of readability, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the integration of environments in the update process, suggesting that it might be necessary to integrate over all possible environments. It also critiques the formatting of the bolded sections on page 6, noting that they are currently a large block of text and suggests breaking them into paragraphs for better readability. The comment is mostly verifiable as it provides a clear observation about the formatting issue and suggests a specific improvement. However, it lacks detailed reasoning or references to support the claim about the integration process, which could be strengthened by providing more context or examples. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a question about the integration of environments in the update process, suggesting that it might be necessary to integrate over all possible environments. It also critiques the formatting of the bolded sections on page 6, noting that they are currently a large block of text and suggests breaking them into paragraphs for better readability. While the comment identifies a potential issue with the integration process and provides a specific suggestion for improving the presentation, it lacks depth and does not offer detailed guidance or examples to help the authors address the problem. The feedback is somewhat helpful as it points out areas for improvement, but it could be more comprehensive and actionable to fully assist the authors in enhancing their draft. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a citation on differential privacy should be added to line 156 to benefit the reader. The comment is explicit in its suggestion to include a citation, and it provides a specific example of where the citation should be added. This allows the authors to directly apply the action by adding the citation at the specified location. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 156,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a citation on differential privacy, providing a clear direction for improvement. This feedback is actionable and provides a clear path for the authors to enhance their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding a citation on differential privacy to line 156. While the comment provides a specific suggestion, it lacks detailed reasoning or examples to support why this addition would be beneficial. The authors may infer the benefit but do not receive explicit guidance on how to demonstrate the value of the citation. Therefore, the comment is somewhat verifiable, as it provides a suggestion but lacks sufficient justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is specific and actionable, as it suggests adding a citation on differential privacy to line 156. This addition would enhance the clarity and comprehensiveness of the paper by providing readers with additional context and supporting information. However, the comment could be more helpful if it provided more detailed reasoning or examples of why this citation is necessary or beneficial. Overall, the feedback is mostly helpful, as it directs the authors to a specific area for improvement without being overly vague or lacking in guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises two distinct points. First, it questions the claim that the methodology requires \"significant additional assumptions,\" suggesting that the only additional assumption is the test set being drawn from the same distribution as the query set, which is a common assumption in machine learning. This feedback is somewhat actionable as it provides a specific example of a potential overstatement and suggests that the authors should clarify the nature of the additional assumptions. However, it does not provide explicit guidance on how to address this issue or what specific changes are needed. Second, the comment points out an error in the sign of an inequality on line 310, comparing it to the inequality on line 227. This is a concrete action that the authors can take to correct the error. Overall, the comment is somewhat actionable due to the explicit feedback on the inequality sign, but the first part is vague and lacks detailed guidance, making the overall comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2\" and \"line 310,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the claim about \"significant additional assumptions\" and the error in the inequality sign. This provides clear guidance on what revisions are necessary, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point contains two claims: one questioning the claim about \"significant additional assumptions\" in the first paragraph of Section 3.2, and another pointing out an error in the sign of an inequality on line 310, comparing it to the inequality on line 227. The first claim is somewhat verifiable as it provides a specific example of a potential overstatement, suggesting that the authors should clarify the nature of the additional assumptions. However, it lacks detailed reasoning or references to support the claim fully. The second claim is fully verifiable as it points out a specific error in the inequality sign, providing a clear and logical basis for the feedback. Overall, the comment is mostly verifiable due to the combination of a somewhat verifiable claim and a fully verifiable claim. Therefore, the comment aligns with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides specific feedback on two distinct issues. First, it questions the claim that the methodology requires 'significant additional assumptions,' suggesting that the only additional assumption is the test set being drawn from the same distribution as the query set, a common assumption in machine learning. This feedback is somewhat helpful as it prompts the authors to clarify the nature of the additional assumptions and consider whether the claim is too extreme. However, it could be more helpful if it provided specific guidance on how to address this issue or what additional assumptions might be necessary. Second, the comment points out an error in the sign of an inequality on line 310, comparing it to the inequality on line 227. This is a clear and actionable suggestion that the authors should correct the error. Overall, the comment is somewhat helpful as it identifies specific areas for improvement and provides actionable feedback, but it could be more comprehensive with additional guidance on the first point.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should provide a comparison of Shapely values with other methods, such as CaCE or raw gradients, to support their argument for using Shapely values. It also recommends including a discussion on the advantages and disadvantages of transforming high-dimensional data to low-dimensional latent space. These suggestions are clear and provide concrete guidance on how the authors can improve their draft. The comment is fully actionable, as it directly instructs the authors on what specific actions to take to strengthen their paper. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Shapely values\" and \"other methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for a comparison with methods like CaCE or raw gradients, as well as a discussion on the advantages and disadvantages of transforming high-dimensional data to low-dimensional latent space. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors need to provide a comparison of Shapely values with other methods, such as CaCE or raw gradients, to support their argument. It also suggests including a discussion on the advantages and disadvantages of transforming high-dimensional data to low-dimensional latent space. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the argument. The absence of detailed reasoning or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 2: Borderline Verifiable, as it provides some basis for the claim but lacks sufficient detail or evidence to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors should provide a comparison of Shapely values with other methods, such as CaCE or raw gradients, to support their argument for using Shapely values. Additionally, it recommends including a discussion on the advantages and disadvantages of transforming high-dimensional data to low-dimensional latent space. These suggestions are actionable and provide clear guidance on how the authors can enhance their paper. However, the comment could be more helpful if it included specific examples or references to support the claims, which would allow the authors to better understand the rationale behind the suggestions. Overall, the comment is mostly helpful, as it offers valuable feedback that can significantly improve the draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the comprehensiveness of the experiments conducted to validate the efficacy of CATER in different settings, such as architectural mismatch and cross-domain imitation. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might improve their draft or address any specific issues related to the comprehensiveness of their experiments. As a result, the authors are left without any actionable feedback, making this comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments conducted to validate the efficacy of CATER in various settings, including an architectural mismatch and cross-domain imitation. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the experiments conducted, providing clear guidance on the comprehensiveness of the validation process. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point describes the experiments conducted to validate the efficacy of CATER in various settings, including an architectural mismatch and cross-domain imitation. However, it does not provide any specific evidence, reasoning, or references to support the claim that these experiments are comprehensive or effective. Without additional context or justification, the reviewer's assertion remains unsubstantiated, making the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights the comprehensiveness of the experiments conducted to validate the efficacy of CATER in various settings, such as an architectural mismatch between the victim and the imitation model and cross-domain imitation. While this feedback acknowledges the thoroughness of the experiments, it does not provide specific suggestions or guidance on how the authors might further enhance their work or address any potential limitations. The comment lacks actionable insights, leaving the authors with a general understanding of the strengths of their experiments but without clear directions for improvement. Therefore, the comment is somewhat helpful, as it identifies an area of strength but does not offer substantial guidance for enhancement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that Appendix A.2 does not illustrate the state space representation of the environment clearly. While it points out a specific area that needs improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the representation in the appendix, but without specific suggestions or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment specifically mentions \"Appendix A.2,\" providing clear grounding as it allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the state space representation is not illustrated clearly, offering a clear direction for improvement. This comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors are left to question the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the state space representation illustrated in Appendix A.2. While it points out a potential area for improvement, it does not provide any suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it highlights a specific area that needs clarification, but it lacks actionable advice or examples, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors' approach is only applicable to small or medium-scale problems and may not be suitable for large-scale problems due to the limitations of current LP-solvers. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might adapt their approach or what changes could be made to make it applicable to larger problems. Without specific suggestions or actions, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the authors' approach is only applicable to small or medium-scale problems and may not be suitable for large-scale problems due to the limitations of current LP-solvers. However, it does not specify which part of the paper this limitation is discussed or how it affects the applicability of the approach. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in pointing out the limitation of the approach for large-scale problems, but it lacks detailed guidance on how to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' approach is only applicable to small or medium-scale problems and may not be suitable for large-scale problems due to the limitations of current LP-solvers. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand the basis of this claim or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the authors\\' approach, noting that it is only applicable to small or medium-scale problems and may not be suitable for large-scale problems due to the limitations of current LP-solvers. This feedback is somewhat helpful as it highlights a potential constraint on the applicability of the approach, which could guide the authors in refining their method or exploring alternative solutions. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation, making it somewhat helpful but not fully comprehensive. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the motivation behind using characteristic function regularization. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific aspects of the motivation need clarification. Without actionable guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of clarity regarding the motivation behind using characteristic function regularization. However, it does not specify which part of the paper discusses this motivation, making it difficult for the authors to pinpoint the exact section or aspect that needs clarification. The comment is specific in identifying the issue but lacks grounding as it does not provide explicit references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the overall motivation of using characteristic function regularization is not clear. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the motivation is unclear or how to address this issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the motivation behind using characteristic function regularization. However, it lacks specific details or suggestions on how the authors might address this issue or what aspects of the motivation need clarification. Without actionable guidance or examples, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper combines existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. It claims that the combination of these techniques is not surprising and that the contribution could be considered incremental. However, the comment does not provide explicit or implicit actions for the authors to take to address this concern. It lacks guidance on how to improve the paper or what specific aspects need to be addressed to enhance the contribution. As a result, the comment is unactionable, as the authors are left without a clear path forward to improve their draft.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the combination of existing techniques used in the paper, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides a detailed description of the techniques used and suggests that the combination of these techniques is not surprising, implying that the contribution might be incremental. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper combines existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. It suggests that the combination of these techniques is not surprising and that the contribution could be considered incremental. However, the comment lacks specific examples or detailed reasoning to support the claim that the combination is not surprising or that the contribution is incremental. Without further elaboration or evidence, the claim remains somewhat subjective and difficult to verify. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the paper by suggesting that the combination of existing techniques might not be surprising, implying that the contribution could be considered incremental. While the comment points out a specific aspect of the paper that could be further explored or differentiated, it does not provide detailed guidance or suggestions on how to address this limitation or enhance the contribution. The feedback is somewhat helpful as it highlights an area for improvement, but it lacks depth and actionable advice, making it only marginally helpful for the authors to improve their draft.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the aggregation operation after \"Integration\" needs further clarification. It also provides a concrete action by instructing the authors to provide more details in the main paper and acknowledge the structure of other architectures properly. This feedback is clear and specific, allowing the authors to understand exactly what needs to be addressed and how to do it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Multiscale modeling\" and \"Integration,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by requesting more details on the aggregation operation after \"Integration\" and to acknowledge the structure of other architectures properly. This feedback is detailed and actionable, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the aggregation operation after \"Integration\" needs further clarification. While it provides a general direction for improvement, it lacks specific details or examples to guide the authors on how to clarify the operation. The comment does not offer any references or logical reasoning to support the need for clarification, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the need for further clarification on the aggregation operation after \"Integration.\" It provides a clear and actionable suggestion by instructing the authors to provide more details in the main paper and acknowledge the structure of other architectures properly. This feedback is specific and constructive, offering a clear path for the authors to enhance the clarity and completeness of their work. However, the comment could be more helpful if it included additional suggestions or examples of how to improve the clarity of the aggregation operation. Overall, the comment is mostly helpful, as it provides a valuable direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"100 steps\" in the context of search models comparison. It does not provide an explicit action or suggestion for the authors to take, such as clarifying the definition of \"100 steps\" or providing additional context. The comment is vague and lacks concrete guidance on how the authors should address this issue. Therefore, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the meaning of \"100 steps\" in the context of search models comparison, specifically questioning whether it refers to 100 sampled strategies. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or figure being referenced. The comment is specific in its request for clarification but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the meaning of \"100 steps\" in the context of search models comparison, specifically questioning whether it refers to 100 sampled strategies. This is a factual question that requires clarification but does not contain any subjective opinions or claims that need verification. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"100 steps\" in the context of search models comparison, specifically questioning whether it refers to 100 sampled strategies. This is a clear and actionable feedback that helps the authors clarify a potential ambiguity in their methodology or experimental setup. By identifying this specific point of confusion, the comment provides a clear direction for the authors to improve the clarity and precision of their description. However, the comment could be more helpful if it suggested alternative interpretations or provided additional context. Overall, it is somewhat helpful as it identifies a specific area for clarification, but it lacks depth and could be more comprehensive.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the improvement over previous methods is small, around 0.2%-1%, and that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to assess statistical significance. The authors are advised to repeat the experiments and conduct statistical significance analysis. However, the comment does not provide explicit guidance on how to repeat the experiments or conduct the statistical analysis, leaving the authors to infer the necessary steps. The suggestion to reject the paper is a direct action, but the lack of detailed guidance on implementation makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the improvement over previous methods, noting that it is small, around 0.2%-1%. It also points out that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to assess statistical significance. The comment suggests repeating the experiments and conducting statistical significance analysis. However, the comment does not specify which part of the paper contains the results in Table 1 and Fig. 5, making it weakly grounded. The comment is specific in detailing the issues with the results and suggesting improvements, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvement over previous methods is small, about 0.2%-1%, and that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to assess statistical significance. The comment suggests repeating the experiments and conducting statistical significance analysis. However, the claim lacks specific examples or references to support the assertion about the small improvement or the absence of mean and standard deviation in the results. Without detailed evidence or references, the claim is difficult to verify, making it unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, noting that the improvement over previous methods is marginal, around 0.2%-1%. It also points out that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to assess the statistical significance of the findings. The comment suggests repeating the experiments and conducting statistical significance analysis, which are actionable steps for the authors to take. However, the comment could be more helpful if it provided specific guidance on how to conduct the statistical analysis or suggested alternative methods for evaluating the significance of the results. Despite this, the feedback is mostly helpful as it directs the authors towards improving the rigor and clarity of their experimental results. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the method should be evaluated on a different benchmark, such as Atari, to assess its generalizability to other domains. It provides a clear and concrete action for the authors to take, which is to run experiments on this new benchmark. This guidance is specific and detailed, allowing the authors to understand exactly how to apply the suggestion. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluation on a single domain and suggests running experiments on a different benchmark, such as Atari, which is a common practice in the literature. This provides clear guidance on which part of the paper needs improvement. The comment is also specific, as it specifies the need to evaluate the method on a different benchmark to assess its generalizability to other domains. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method is evaluated only on the Meta World domain, making it difficult to judge its generalizability to other domains. The suggestion to run experiments on a different benchmark, such as Atari, is logical and provides a clear rationale for why this would be beneficial. However, the comment lacks specific examples or references to support the claim about the limitations of the current evaluation. While the reasoning is sound, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the evaluation of the method. It highlights the limitation of evaluating the method on a single domain, specifically the Meta World robotic manipulation domain, and suggests running experiments on a different benchmark, such as Atari, to assess the method's generalizability. This recommendation is well-supported and provides a concrete direction for the authors to enhance the robustness and applicability of their work. By suggesting a different benchmark, the comment offers a valuable insight into how the authors can strengthen their evaluation process. Therefore, the comment is highly helpful, as it guides the authors towards a more comprehensive and impactful evaluation.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include an analysis of what the model does, which could be interesting. However, it does not provide explicit instructions or concrete guidance on how to conduct this analysis or what aspects to focus on. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should include an analysis of what the model does, which could be interesting. However, it does not specify which part of the paper this analysis should be included in or what aspects of the model's behavior should be analyzed. The comment lacks grounding as it does not provide clear guidance on which section or part of the paper needs attention. It is also specific in suggesting the inclusion of an analysis, but without detailed guidance on how to conduct it. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include an analysis of what the model does, which could be interesting. However, it does not provide specific examples, references, or detailed reasoning to support this claim. The comment lacks sufficient evidence or justification to be considered fully verifiable. Therefore, it is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges the strengths of the method and experiments but identifies a significant gap: the lack of analysis on what the model does. This feedback is valuable as it highlights an area where the authors could enhance their work by providing a deeper understanding of the model's behavior. However, the comment could be more helpful if it suggested specific ways to conduct this analysis or provided examples of what kind of analysis would be beneficial. Overall, the comment is somewhat helpful as it points out a crucial aspect that needs attention, but it lacks depth and actionable guidance, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the approach section is missing in the main paper, which is a clear indication of an action the authors should take. It also suggests that the supplementary material should be used as additional information rather than an extension of the paper. This feedback provides a direct and concrete action for the authors to improve their draft by ensuring all necessary sections are included and properly integrated. The comment is fully actionable as it clearly specifies what needs to be addressed and how to do it. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"approach section\" in the main paper, allowing the authors to accurately identify the part being addressed. It also specifies that the supplementary material should be used as additional information rather than an extension of the paper, providing clear guidance on what needs to be addressed. This level of detail ensures that the authors understand exactly what part of the paper requires revision and how to do it. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approach section is missing in the main paper, which is a factual observation. However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. The comment lacks detailed reasoning or evidence, which could be improved by providing specific examples or references. Therefore, the claim is considered borderline verifiable, as it is somewhat supported but lacks key elements for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the draft, specifically noting the absence of an \"approach section\" in the main paper. It also suggests that the supplementary material should be treated as additional information rather than an extension of the paper. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft. However, the comment could be more helpful if it included suggestions for how to integrate the supplementary material or how to ensure the main paper is comprehensive. Despite this, the comment is mostly helpful as it highlights a critical oversight and offers a clear path for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the statement in the introduction regarding the biological plausibility of backpropagation is weak and suggests that it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide explicit guidance on how the authors should revise the statement or what specific changes are needed to make it more informative or impactful. The action is implicit, as the authors would need to infer that they should strengthen the statement by providing more context or evidence. The comment is somewhat actionable because it identifies a specific area for improvement, but it lacks concrete details on how to achieve this. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the biological plausibility of backpropagation in the introduction, specifically questioning the claim that it is biologically plausible. However, it does not specify which part of the introduction this claim is made, leaving the authors to infer that it refers to the sentence \"While the backpropagation ..., its biological plausibility remains a subject of debate.\" This lack of explicit grounding makes it difficult for the authors to pinpoint the exact section being addressed. The comment is specific in its critique of the claim, but the lack of grounding reduces its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the statement in the introduction regarding the biological plausibility of backpropagation is weak and suggests that it is widely accepted that backpropagation is biologically implausible. This claim is somewhat verifiable as it provides a logical reasoning by referencing the common understanding of backpropagation's biological plausibility. However, it lacks specific examples or references to support the claim, which could make it less robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue in the introduction regarding the biological plausibility of backpropagation, noting that the statement is weak and that it is widely accepted that backpropagation is biologically implausible. This feedback is somewhat helpful as it highlights a potential area for improvement in the introduction, suggesting that the authors should provide more context or evidence to support their claims. However, the comment could be more helpful if it offered specific suggestions or guidance on how to strengthen the argument or provide additional context. Overall, the comment provides a clear direction for improvement, but it lacks depth and specificity, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the heuristic design of the modulator and suggests that it might be hard to justify due to potential scalability issues and the need for tedious hyperparameter tuning for diverse training data. However, the comment does not provide explicit guidance on how the authors might address these issues or what specific actions they should take to improve the modulator. The feedback is somewhat vague and lacks concrete details, making it difficult for the authors to understand how to apply it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the heuristic design of the modulator and suggests that it might be hard to justify due to potential scalability issues and the need for tedious hyperparameter tuning for diverse training data. However, the comment does not specify which part of the paper discusses the modulator or where the issue of scalability is addressed. This lack of grounding makes it difficult for the authors to pinpoint the exact section or aspect of the paper that needs attention. While the comment is specific in its critique of the modulator's design, the absence of explicit references to the paper's sections or content limits its effectiveness. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the heuristic design of the modulator, suggesting that it might be hard to justify due to potential scalability issues and the need for tedious hyperparameter tuning for diverse training data. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the heuristic design of the modulator, specifically questioning its scalability and the need for tedious hyperparameter tuning for diverse training data. This feedback highlights a concern that could impact the practicality and efficiency of the proposed method. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve the modulator's design. While it points out a potential weakness, it does not provide actionable steps or detailed insights that would help the authors enhance their work. Therefore, the comment is somewhat helpful, as it raises a valid concern but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments performed in the paper incorporate a significant amount of domain knowledge, which might be impractical for less informed functions like f_R/f_P. However, it does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The comment implies that the authors should consider the implications of their current approach and potentially explore alternative methods that require less domain knowledge. While the suggestion is clear, it lacks concrete details on how to implement it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of incorporating domain knowledge into the structure of f_R and f_P, suggesting that less informed versions of these functions might require impractical amounts of data. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or figure being addressed. The comment is specific in its critique of the experimental setup but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments performed in the paper incorporate a significant amount of domain knowledge, which might be impractical for less informed functions like f_R/f_P. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim remains somewhat verifiable, as it lacks the necessary depth and context to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experiments performed in the paper, specifically noting that the incorporation of domain knowledge might be impractical for less informed functions like f_R/f_P. This observation is insightful and raises a valid concern about the generalizability and applicability of the findings. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the robustness of their approach. While it highlights a potential weakness, it lacks actionable advice, making it somewhat helpful. The authors would need to infer how to address the issue, which limits the comment's usefulness. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implications of overparameterization on generalization performance, specifically questioning whether the constructions of ReLU networks for robust memorization lead to robust generalization. While the comment identifies a potential issue with the paper, it does not provide explicit guidance on how the authors should address this concern or what specific actions they should take. The suggestion is implicit, as it implies that the authors should explore the connection between generalization bounds and the constructions of ReLU networks. However, the lack of concrete steps or detailed guidance makes the comment somewhat actionable. Therefore, it aligns with a score of 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the implications of overparameterization on generalization performance, specifically questioning whether the constructions of ReLU networks for robust memorization lead to robust generalization. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its questioning of the connection between memorization and generalization, the absence of explicit grounding makes it challenging for the authors to understand which part of the paper to focus on. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the implications of overparameterization on generalization performance, specifically questioning whether the constructions of ReLU networks for robust memorization lead to robust generalization. The comment suggests that the paper does not clearly address this connection, implying that the authors should explore the relationship between generalization bounds and the constructions of ReLU networks. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the basis for the claim, which could be improved with more detailed reasoning or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the implications of overparameterization on generalization performance, specifically questioning whether the constructions of ReLU networks for robust memorization lead to robust generalization. While the comment identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it points out a gap in the paper's discussion, but it lacks actionable advice or detailed insights that would guide the authors in improving their draft. Therefore, the comment aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper's exploration of the proposed method's implications for other NLP tasks is limited, which somewhat limits the generalizability of the results. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to explore the method's implications for other NLP tasks. The action is implicit and vague, as it does not specify how the authors can enhance the exploration of the method's implications. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"contrastive learning in code search tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the paper does not thoroughly explore the implications of the proposed method for other NLP tasks, which limits the generalizability of the results. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not thoroughly explore the implications of the proposed method for other NLP tasks, which limits the generalizability of the results. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides a general observation but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper by pointing out that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. This observation is somewhat helpful as it highlights a potential area for further exploration and could guide the authors in expanding the scope of their work. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address this limitation, such as suggesting additional experiments or analyses that could be conducted to explore the method's implications for other NLP tasks. Overall, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind the proposed sample selection mechanism and its effectiveness in preserving label distribution. While it highlights a potential area for clarification, it does not provide explicit guidance on how the authors should address this issue or what specific aspects need to be explained. The action is implicit, as the authors would need to infer that they should provide a clearer explanation of the mechanism. However, the comment lacks concrete details on how to improve the explanation, making it somewhat actionable. Therefore, this comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the rationale behind the proposed sample selection mechanism and its effectiveness in preserving label distribution. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section or figure that needs clarification. The comment is specific in its critique of the mechanism's effectiveness but lacks grounding as it does not provide explicit references to the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind the proposed sample selection mechanism and its effectiveness in preserving label distribution. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to infer the basis of the critique, making it difficult to understand and address. Therefore, the comment is considered unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed sample selection mechanism, specifically questioning its effectiveness in preserving label distribution. This feedback highlights a critical aspect of the methodology that needs clarification or further explanation. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. While it points out a potential area for improvement, it does not offer actionable advice or detailed insights, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the evaluation of the results, noting that while the analysis is detailed and comprehensive, it only considers two relatively old and small models. This feedback provides a clear and explicit action for the authors to take, which is to expand the evaluation to include more recent and larger models. The comment is specific in its suggestion, offering concrete guidance on how to enhance the evaluation process. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the results/analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the evaluation is limited to two relatively old and small models, which the authors can address by expanding their evaluation to include more recent and larger models. This provides clear guidance on what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results/analysis, despite being detailed and comprehensive, are limited to only two relatively old and small models. This claim is somewhat verifiable as it provides a specific observation about the scope of the evaluation. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors could benefit from additional context or examples to understand the limitations of the evaluation more clearly.', 'verifiability_label': '3', 'helpfulness_rationale': 'The comment identifies a specific limitation in the evaluation of the results, noting that despite being detailed and comprehensive, the analysis is limited to only two relatively old and small models. This feedback is clear and actionable, as it provides a specific area for improvement by suggesting that the authors should expand their evaluation to include more recent and larger models. By addressing this limitation, the authors can enhance the comprehensiveness and relevance of their results, making the paper more impactful. Therefore, the comment is mostly helpful, as it offers clear guidance on how to improve the evaluation process.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a belief that KD can be viewed as a special form of LS under certain conditions, specifically when the teacher network is uniformly distributed and the temperature is set at 1. However, it does not provide explicit or implicit actions for the authors to take, such as suggesting how to incorporate this perspective into their work or discussing the implications of this view. The comment lacks concrete guidance on how the authors might address this point or integrate it into their draft. Therefore, the comment is not actionable, as it does not provide any direction for the authors to improve their work.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing. It makes a claim about the relationship between KD and LS, but without referencing specific sections, tables, or figures, the authors cannot determine where this discussion is relevant. The comment is also not specific because it does not detail what needs to be addressed or how the authors should approach the relationship between KD and LS. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point makes a claim about the relationship between KD and LS, suggesting that KD can be viewed as a special form of LS under specific conditions. However, the comment lacks detailed reasoning, examples, or references to support this claim. Without further elaboration or evidence, the authors may find it challenging to understand or validate the claim. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a nuanced perspective on the relationship between KD and LS, suggesting that KD can be viewed as a special form of LS under specific conditions. This insight could be valuable for the authors to consider in their work, as it highlights a potential connection that might not have been previously explored. However, the comment lacks actionable guidance or suggestions on how the authors might incorporate this perspective into their research or draft. While it offers a thought-provoking idea, it does not provide concrete steps or insights that would significantly enhance the authors' understanding or contribution. Therefore, the comment is somewhat helpful, as it offers a valuable perspective but lacks depth and actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include more recent competing dynamic-pruning methods and results on large-scale datasets, such as ImageNet, to further verify the effectiveness of the proposed method. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be added to their draft. The comment is specific in its suggestions, detailing which areas require improvement and what kind of results should be included. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"No.3. 2021\" and \"Competing dynamic-pruning methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need to include more recent works and results on large-scale datasets, such as ImageNet, to verify the effectiveness of the proposed method. This provides detailed guidance on what needs to be added to the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper should include more recent competing dynamic-pruning methods and results on large-scale datasets, such as ImageNet, to verify the effectiveness of the proposed method. While the comment suggests the need for additional results, it does not provide specific examples or references to support the claim. This lack of detailed justification makes it difficult for the authors to understand the reasoning behind the suggestion, leading to a score of 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out that the results are limited to small-scale datasets and suggests including more recent competing dynamic-pruning methods, particularly with results on large-scale datasets like ImageNet. This feedback is actionable and provides a clear direction for the authors to enhance the comprehensiveness and impact of their work. By recommending the inclusion of more recent methods and results, the comment offers valuable guidance on how to strengthen the evaluation and verification of the proposed method. Therefore, the comment is mostly helpful, as it effectively directs the authors to improve their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks the authors to provide an explanation for the degradation in performance of the FBN results when additional information is included. While it prompts the authors to address this issue, it does not explicitly instruct them on how to do so or provide specific guidance on what aspects to consider. The action is implicit, as the authors need to infer that they should analyze and explain the performance degradation. However, the comment lacks concrete details on how to approach this analysis, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FBN results (table 5),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks the authors to provide an explanation for the degradation in performance when additional information is included, which is a clear and actionable request. Therefore, this comment is classified as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the degradation in FBN results when additional information is included. However, it does not provide any specific reasoning, examples, or references to support why this degradation might occur. The comment lacks detailed justification or explanation, making it difficult for the authors to understand the basis of the issue or how to address it. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the FBN results, noting that the performance degrades when additional information is included. This observation is clear and highlights a potential area for further investigation or clarification. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or what steps they should take to improve the results. While it points out a problem, it does not provide detailed feedback or constructive advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It suggests that while the choice might be interesting, it is not well-motivated. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the task are interesting. The action is implicit and vague, as it leaves the authors to infer that they need to provide a clearer motivation for their choice. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its critique of the choice but lacks grounding as it does not provide clear guidance on how to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. While the reviewer suggests that this choice is not well-motivated, the comment lacks specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the reasoning behind the critique. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks depth and clarity.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder, suggesting that while the choice might be interesting, it is not well-motivated. This feedback highlights a potential gap in the paper's justification for the chosen experimental setup. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the motivation for their choice. While it identifies a concern, it lacks actionable advice, making it somewhat helpful. The authors would need to infer how to improve the motivation, which limits the comment's usefulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper argues that the proposed method finds flat minima but lacks an analysis of flatness. It highlights that minimizing the averaged loss across noise-injected models does not guarantee flatness. The comment suggests that to claim the minima found by minimizing the loss in Eq (3), an analysis on the losses of the noise-injected models after training is required. This provides a clear and explicit action for the authors to take, which is to conduct an analysis on the losses of the noise-injected models. The action is also concrete, as it specifies exactly what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the analysis about flatness is missing, allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies the issue: the lack of analysis on the losses of noise-injected models after training, which is necessary to support the claim about the minima found by minimizing the loss in Eq (3). This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper argues that the proposed method finds flat minima but lacks an analysis of flatness. It highlights that minimizing the averaged loss across noise-injected models does not ensure the flatness of the minima. The comment suggests that to claim the minima found by minimizing the loss in Eq (3), an analysis on the losses of the noise-injected models after training is required. This claim is mostly verifiable as it provides a logical reasoning for why the analysis is missing and what needs to be done to address the issue. However, it could be more robust with additional references or examples to support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out that while the paper claims the proposed method finds flat minima, it lacks an analysis of flatness. The reviewer provides a clear explanation of why this analysis is missing, specifically noting that minimizing the averaged loss across noise-injected models does not guarantee flatness. The comment suggests that to substantiate the claim about the minima found by minimizing the loss in Eq (3), an analysis on the losses of the noise-injected models after training is required. This feedback is highly helpful as it provides a specific and actionable suggestion for the authors to improve their draft by addressing the missing analysis. It guides the authors to focus on a critical aspect of their work that needs further substantiation, making the comment highly valuable for enhancing the paper.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the readability of the text within a figure and its labels, suggesting that the text should be of the same size as the manuscript text. This feedback is explicit, as it directly instructs the authors to address the issue by adjusting the size of the text. It is also concrete, as it provides a clear and specific action to take. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue with the readability of the text within a figure and its labels, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the text should be roughly the same size as the manuscript text. This provides clear guidance on how to improve the figure and labels. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the text inside the figure and its labels is too small to read without zooming, suggesting that it should be roughly the same size as the manuscript text. This claim is somewhat verifiable as it provides a specific observation about the readability of the text, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the need for improvement based on the comment, which could be more effective with additional context or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the readability of the text within a figure and its labels, noting that the text is too small to read without zooming. It suggests that the text should be roughly the same size as the manuscript text. This feedback is clear and actionable, providing the authors with a direct and specific direction to improve the presentation of their figures. By addressing this issue, the authors can enhance the clarity and accessibility of their work, making it easier for readers to understand the content. Therefore, the comment is highly helpful, as it offers a clear and constructive suggestion for improvement.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the motivation behind the paper is not clear and suggests that the introduction should be revised to make the paper easier to follow. While the comment implies that the authors need to revise the introduction, it does not provide specific guidance on what aspects of the introduction need to be revised or how to make it clearer. The action is implicit and somewhat vague, as the authors are left to infer that they need to revise the introduction. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the motivation is not clear and recommends revising the introduction to make the paper easier to follow. However, it does not specify which part of the introduction needs revision or what aspects of the motivation are unclear. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment is specific in its suggestion to revise the introduction, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation is not clear and suggests that the introduction should be revised to make the paper easier to follow. However, the comment lacks specific details or examples to support this claim. It does not provide any evidence or reasoning to justify why the motivation is unclear or how the introduction could be revised to improve clarity. Without this additional information, the claim remains unsubstantiated, making the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the motivation is not clear and that the introduction should be revised to make the paper easier to follow. This feedback is valuable as it highlights a critical aspect of the paper's structure and clarity, which can help the authors improve the overall presentation and understanding of their work. However, the comment lacks specific suggestions or guidance on how to revise the introduction, making it somewhat helpful. The authors would benefit from additional details on what aspects of the introduction need improvement and how to make it more accessible. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the alignment of relabeled reward data with human annotator judgments, suggesting that this alignment is insufficiently validated. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might validate the alignment or what specific steps they should follow to ensure it is sufficiently validated. Without concrete suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern regarding the alignment of relabeled reward data with human annotator judgments, suggesting that this alignment is insufficiently validated. However, it does not specify which part of the paper this issue is discussed or addressed. The authors cannot confidently determine which section or figure this comment pertains to, making it weakly grounded. Additionally, the comment lacks specificity, as it does not provide details on how the alignment is validated or what aspects need to be improved. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the alignment of relabeled reward data with human annotator judgments remains insufficiently validated. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the alignment of relabeled reward data with human annotator judgments, noting that it remains insufficiently validated. This feedback is clear and actionable, as it highlights a potential weakness in the methodology or experimental setup. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this issue, such as proposing specific validation methods or additional experiments. Without such guidance, the authors may struggle to improve their draft effectively. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model is somewhat complicated and that its presentation in section 4 requires careful reading. It also recommends improving the presentation, possibly by referencing the supplement. The comment further suggests replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. These suggestions are explicit and provide concrete guidance on how the authors can improve their draft. The actions are clear and detailed, allowing the authors to understand exactly what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the model is somewhat complicated and that its presentation in section 4 requires careful reading. It recommends improving the presentation, possibly by referencing the supplement. The suggestion to replace natural language descriptions with notation and add breakout diagrams to illustrate attention mechanisms is also provided. However, the comment does not specify which part of section 4 is particularly challenging or requires careful reading, making it difficult for the authors to pinpoint the exact issue. While the comment is specific about the suggestions for improvement, the lack of grounding makes it less helpful. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the model is somewhat complicated and that its presentation in section 4 requires careful reading. It recommends improving the presentation, possibly by referencing the supplement, and suggests replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. However, the comment lacks specific examples or detailed reasoning to support the claim that the model is complicated or that these suggestions would effectively improve the presentation. Without concrete evidence or examples, the claim is somewhat verifiable, as it provides a general direction for improvement but lacks the necessary depth to fully substantiate the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the complexity of the model and suggests ways to improve its presentation in section 4. It recommends replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms, which could enhance clarity and understanding. While the comment provides specific suggestions for improvement, it lacks detailed guidance on how to implement these changes effectively. The feedback is somewhat helpful as it offers actionable advice, but it could be more comprehensive if it included more detailed instructions or examples. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper, noting that the experiments are conducted on a limited number of molecules and only include in-distribution testing. The reviewer suggests that the value of the method might be limited if it requires training for each molecule individually. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the draft. The action is implicit and vague, as it leaves the authors to infer the need for additional experiments or a more comprehensive evaluation. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of limited experiments on a small number of molecules and the lack of in-distribution testing. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the limitation in the experiments and suggests that the value of the method might be limited if it requires training for each molecule individually. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper only conducts experiments on a limited number of molecules and only provides in-distribution testing. This is a factual observation about the scope of the experiments. However, the comment does not provide any reasoning, examples, or references to support why this limitation is significant or how it affects the value of the method. Without additional context or justification, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically that the experiments are conducted on a limited number of molecules and only include in-distribution testing. This observation is important because it highlights a potential constraint on the generalizability and value of the method. The comment suggests that the value of the method might be limited if it requires training for each molecule individually, which is a relevant concern for the authors to address. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might expand their experiments or address this limitation in future work. Overall, the comment is somewhat helpful as it points out a significant issue that needs attention, but it lacks depth and actionable advice, making it a 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the symbols used in the paper are complicated and time-consuming to understand. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might simplify the symbols or make them more accessible to readers. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the symbols used in the paper are complicated and time-consuming to understand. However, it does not specify which part of the paper contains these symbols, making it difficult for the authors to pinpoint the exact issue. The comment is specific in its critique of the complexity of the symbols but lacks grounding as it does not provide context or references to specific sections or figures. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the symbols used in the paper are complicated and time-consuming to understand. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to address this issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the complexity of symbols used in the paper, which could hinder understanding. However, it lacks specificity and actionable suggestions for improvement. The authors are left without guidance on how to simplify the symbols or make them more accessible to readers. While the feedback points out a potential area for enhancement, it does not provide detailed or constructive advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the red line in Figure 3, specifically asking where the test data comes from and whether there is a ground truth. While the comment identifies a potential issue with the clarity of the figure, it does not provide explicit guidance on how the authors should address this question or what changes might be needed. The action is implicit, as the authors would need to infer that they should clarify the source of the test data and the presence of a ground truth. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the red line in Figure 3, questioning the source of the test data and the presence of a ground truth. This provides the authors with a clear understanding of what needs to be clarified or addressed. Therefore, the comment is classified as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the red line in Figure 3, specifically asking where the test data comes from and whether there is a ground truth. This is a factual question that requires the authors to clarify the source of the test data and the presence of a ground truth in the figure. However, the comment does not provide any additional context, reasoning, or references to support the question. As a result, the claim is not verifiable, and the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, questioning the source of the test data and the presence of a ground truth. This feedback is clear and actionable, as it directs the authors to clarify the figure's content and ensure that the data is well-defined and understandable. However, the comment could be more helpful if it provided additional guidance on how to address the issue or suggested specific ways to improve the clarity of the figure. Despite this, the feedback is mostly helpful as it highlights a critical area for improvement, allowing the authors to enhance the clarity and comprehensibility of their work. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It suggests that the comparison model, which cannot capture periodic relationships, is used in most experiments, except for Experiment 1b, where the relationships involve periodicity. The reviewer questions whether adding periodicity to the spectral kernel would allow it to capture all the results at a similar level to the explicitly compositional model. While the comment poses a question that could lead to further exploration, it does not provide explicit guidance on how to address this question or what actions the authors should take to investigate it. The action is implicit and vague, as the authors are left to infer how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It specifically mentions that the comparison model cannot capture periodic relationships and that most experiments, except for Experiment 1b, involve periodicity. The reviewer questions whether adding periodicity to the spectral kernel would allow it to capture all the results at a similar level to the explicitly compositional model. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the role of periodicity in the results, but without clear references to specific sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It questions whether adding periodicity to the spectral kernel would allow it to capture all the results at a similar level to the explicitly compositional model. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It highlights a specific aspect of the comparison model and questions whether adding periodicity to the spectral kernel could improve its performance. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this question or explore the impact of periodicity on their results. Without actionable advice or insights, the comment is barely helpful, as it leaves the authors without a clear path forward to improve their draft. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concern about the paper's writing quality, suggesting it is rushed and difficult to read. It also points out issues with presentation and formatting, particularly in figures and tables. However, the comment does not provide explicit guidance on what specific aspects need improvement or how the authors should address these issues. The feedback is somewhat vague, as it lacks concrete suggestions or actionable steps for the authors to take. Therefore, the comment is somewhat actionable, aligning with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment expresses concern about the paper\\'s writing quality, suggesting it is rushed and difficult to read. It also points out issues with presentation and formatting, particularly in figures and tables. However, the comment does not specify which part of the paper is being addressed, making it difficult for the authors to pinpoint the exact areas that need improvement. The lack of specific guidance on what aspects of the writing or presentation are lacking makes the comment weakly grounded. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper is not very well-written, possibly hurriedly written, and difficult to read. It also mentions issues with presentation and formatting, particularly in figures and tables. However, the comment lacks specific examples or detailed reasoning to support these claims. Without concrete evidence or examples, the authors may find it challenging to understand the basis of the criticism and how to address it. Therefore, the comment is considered unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s writing quality, suggesting it is rushed and difficult to read. It also points out problems with presentation and formatting, particularly in figures and tables. While the comment highlights areas for improvement, it lacks specific guidance on how the authors might address these issues or what changes could be made to enhance the paper\\'s readability and presentation. The feedback is somewhat helpful as it directs the authors to areas that need attention, but it could be more actionable with detailed suggestions or examples. Therefore, the comment aligns with a score of 3, indicating it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the introduction to orthogonality in Part 2 could be more detailed. While it implies that the authors should expand on this section, it does not provide specific guidance on what aspects of orthogonality need to be elaborated upon. The action is explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not specify which part of the paper this refers to, making it difficult for the authors to identify the exact section that needs improvement. The comment is specific in its suggestion to add detail, but the lack of grounding makes it challenging for the authors to understand which part of the paper to focus on. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide any specific reasoning or examples to support this claim. Without additional context or justification, the authors may find it challenging to understand why this suggestion is important or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the introduction to orthogonality in Part 2 could be more detailed. While it identifies a potential area for improvement, it lacks specific guidance on what aspects of orthogonality need to be elaborated upon. This feedback is somewhat helpful as it directs the authors to enhance the depth of their introduction, but it does not provide detailed suggestions or examples to guide them in making the necessary improvements. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper's main contribution is the result that optimal regularization can remove double descent in certain anisotropic settings, given that prior work has shown sample-wise multiple descent in linear regression. However, it does not provide explicit guidance on how the authors should highlight the novelty of their result in relation to prior results. The comment implies that the authors should do a better job of emphasizing the novelty, but it lacks concrete instructions on how to achieve this. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"main contribution of the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the novelty of the result in relation to prior work. However, the comment does not provide specific examples or detailed guidance on how to highlight the novelty, making it somewhat specific. Therefore, this comment is classified as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper's main contribution is the result that optimal regularization can remove double descent even in certain anisotropic settings, given that prior work has shown sample-wise multiple descent in linear regression. However, the comment does not provide specific examples, detailed reasoning, or references to support this claim. The authors are left to verify the claims independently, which makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential gap in the paper's contribution by pointing out that prior work has already shown sample-wise multiple descent in linear regression. It suggests that the paper's main contribution might be overstated and that the authors should better highlight the novelty of their result in relation to prior findings. However, the comment does not provide specific guidance on how the authors might address this issue or what aspects of their work could be emphasized to clarify the novelty. While it offers a direction for improvement, the feedback lacks depth and actionable suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the proposed methods, suggesting that they are independent and lack an inner connection in terms of intuition and algorithm. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment identifies a potential area for improvement but does not offer guidance on how to make the methods more connected or how to strengthen the connection between them. As a result, the authors are left without a clear path to follow, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a potential issue with the proposed methods, suggesting that they are independent and lack an inner connection in terms of intuition and algorithm. However, it does not specify which part of the paper discusses these methods or where the independence is claimed. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to address the issue of independence or how to strengthen the connection between the methods. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the proposed methods, contrastive training objective and contrastive search, are two independent methods with little inner connection in terms of intuition and algorithm. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without further elaboration or evidence, the authors may find it challenging to understand the basis of this claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed methods, specifically noting that they are described as two independent methods with little inner connection in terms of intuition and algorithm. This observation highlights a potential area for improvement in the paper, suggesting that the authors should explore ways to strengthen the connection between these methods or provide a clearer rationale for their independence. However, the comment lacks specific guidance or suggestions on how to address this issue, leaving the authors with limited actionable feedback. While it points out a potential weakness, it does not provide detailed advice on how to improve the coherence or integration of the methods, making it somewhat helpful but not fully comprehensive. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the goal of the paper, suggesting that the authors should clarify whether the work aims to develop a foundation model or to demonstrate a proof of concept. It also points out the absence of a comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and questions the justification for the method's benefit over these existing approaches. The comment implies that the authors should provide a clearer explanation of their goal and demonstrate the utility of their method through additional experiments or justifications. However, the comment does not explicitly instruct the authors to address these issues, leaving the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the goal of the paper, specifically mentioning the existence of DAS earthquake detectors and the lack of comparison or justification against them. It also suggests that if the claim is about a foundation model, the authors should clarify this and demonstrate future applications. However, the comment does not specify which part of the paper discusses the goal or the comparison with existing methods, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as clarifying the goal and providing comparisons or justifications. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the lack of comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and questions the justification for the method's benefit over these existing approaches. The comment suggests that if the paper's claim is to be a foundation model, it should be clearer and demonstrate future applications. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. The authors would need to provide more evidence or justification to address this concern effectively.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the paper\\'s goal and the lack of comparison with existing DAS earthquake detectors, such as PhaseNet-Das. It highlights the absence of a clear justification for the method\\'s benefit over these existing approaches, which is a crucial aspect for the paper\\'s contribution. The comment also suggests that if the paper aims to present a foundation model, it should be clearer and demonstrate future applications. This feedback is mostly helpful as it provides a clear direction for the authors to address the identified weaknesses and improve the paper\\'s impact. However, it could be more helpful if it included specific suggestions or examples of how to demonstrate the benefit of the method or how to clarify the paper\\'s goal.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the restriction to triplets or a sliding window of length 3, suggesting that it might be a fundamental limitation or that an extension to longer subsequences is possible. While the comment implies that the authors should consider this limitation, it does not provide explicit guidance on how to address it or what specific changes might be necessary. The action is implicit and somewhat vague, as the authors are left to infer the need for further exploration or discussion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the restriction to triplets or a sliding window of length 3, suggesting that it might be a fundamental limitation or that an extension to longer subsequences is straightforward. However, it does not specify which part of the paper this restriction is discussed in, making it difficult for the authors to pinpoint the exact section or figure being addressed. The comment is specific in its inquiry about the limitation but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the restriction to triplets or a sliding window of length 3, suggesting that it might be a fundamental limitation or that an extension to longer subsequences is straightforward. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the assertion, making it difficult to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the restriction to triplets or a sliding window of length 3, suggesting that it might be a fundamental limitation of the approach or that an extension to longer subsequences is straightforward. This feedback is valuable as it prompts the authors to consider the scope and limitations of their method. However, the comment lacks specific guidance or suggestions on how to address this limitation or explore potential extensions. While it identifies an important area for further consideration, the feedback could be more helpful if it provided actionable advice or examples of how to approach the problem. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor), suggesting that they may introduce significant computational overhead. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might mitigate this computational overhead or what steps they should consider to balance model size and accuracy. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the potential computational overhead introduced by the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor). However, it does not specify which part of the paper this issue is discussed or how it affects the overall methodology or results. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to mitigate this computational overhead or what steps the authors should take to balance model size and accuracy. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor) may introduce significant computational overhead. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without detailed reasoning or supporting evidence, the authors may find it challenging to understand the basis of this claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor), suggesting that they may introduce significant computational overhead. This observation is important as it highlights a potential limitation in the pursuit of determining the optimal trade-off between model size and accuracy. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or mitigate the computational overhead. Without actionable advice or detailed recommendations, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks depth and specificity in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests including and learning AccNet as part of a larger predictor for semantic segmentation, which could potentially improve the model. However, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the model should be considered. The action is implicit, as the authors need to infer that they should explore the possibility of integrating AccNet into a larger predictor. While the suggestion is concrete in terms of the idea, the lack of detailed guidance on implementation makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 126\" and the section \"Further Questions,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential improvement by including and learning AccNet as part of a larger predictor for semantic segmentation, which could enhance the model. This provides clear guidance on what needs to be addressed and how the suggestion could be implemented. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests including and learning AccNet as part of a larger predictor for semantic segmentation. However, it does not provide any specific reasoning, examples, or references to support why this suggestion would be beneficial or how it could be implemented. The comment lacks detailed justification, making it difficult for the authors to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including and learning AccNet as part of a larger predictor for semantic segmentation, which could potentially improve the model. However, the comment lacks specific guidance on how to implement this suggestion or what aspects of the model should be considered. While it identifies a potential area for improvement, it does not provide detailed feedback or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it offers a direction for improvement but lacks depth and specificity. The authors would need to infer the exact steps to follow, which limits the comment's usefulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the new proposed metric, noting that it is only tested on a single dataset. This feedback suggests that the authors should consider expanding the evaluation to include more datasets to provide a more comprehensive assessment of the metric. However, the comment does not specify which additional datasets should be included or how this expansion would be implemented. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct further testing. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a limitation of the new proposed metric, noting that it is only tested on a single dataset. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in identifying the issue with the metric's testing, the absence of grounding information makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the new proposed metric is only tested on a single dataset. This is a factual observation, as the paper does not provide evidence of testing on multiple datasets. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer that the metric's limited testing is a potential issue, but the comment does not provide detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation of the new proposed metric, noting that it is only tested on a single dataset. This feedback is valuable as it highlights a potential area for improvement, suggesting that the authors should consider expanding the evaluation to include more datasets to provide a more comprehensive assessment of the metric. However, the comment lacks detailed guidance on which additional datasets to include or how to conduct the expanded testing. While it points out a clear issue, it does not provide actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. It also implies that the authors might be overstating the generality of their work, which could muddle the exposition. However, the comment does not provide explicit guidance on how to clarify the setting or address the issue of overstating generality. The action is implicit and vague, as the authors are left to infer what needs to be done. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the first three paragraphs of section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the setting needs to be spelled out more clearly, and the authors might be overstating the generality of their work. This provides a clear direction for improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand why this is a necessary improvement. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. This feedback is actionable and provides a clear direction for the authors to enhance the clarity and precision of their exposition. However, the comment could be more helpful if it offered additional guidance on how to clarify the setting or suggested specific ways to improve the exposition. Despite this, the feedback is mostly helpful as it directs the authors to a critical area that needs attention, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of baselines used in the experiments, suggesting that the authors should consider more recent 3D CNNs like X3D and SlowFast. It also asks whether the proposed method offers advantages over these approaches. While the comment implies that the authors should explore these alternatives, it does not provide explicit instructions on how to conduct the experiments or what specific comparisons to make. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and comparisons. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the choice of baselines used in the experiments, specifically mentioning the use of older models like R3D and C3D. It suggests that many papers have proposed more recent 3D CNNs, such as X3D and SlowFast, and asks whether the proposed method works on these models or what its advantages are compared to them. However, the comment does not specify which part of the paper discusses the choice of baselines or the experimental setup, making it weakly grounded. The comment is specific in its request for additional experiments or comparisons, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of baselines used in the experiments, specifically mentioning the use of older models like R3D and C3D. It suggests that many papers have proposed more recent 3D CNNs, such as X3D and SlowFast, and asks whether the proposed method also works on these 3D CNNs or what its advantages are compared to them. While the comment raises a valid concern about the choice of baselines, it lacks specific examples or references to support the claim that the proposed method might not be effective on more recent 3D CNNs. The authors would need to provide more detailed reasoning or evidence to fully address this concern. Therefore, the comment is somewhat verifiable, as it provides a basis for discussion but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the choice of baselines used in the experiments, specifically questioning the use of older models like R3D and C3D. It suggests that many papers have proposed more recent 3D CNNs, such as X3D and SlowFast, and asks whether the proposed method also works on these models or what its advantages are compared to them. This feedback is somewhat helpful as it points out a potential area for improvement and encourages the authors to consider more recent and relevant baselines. However, the comment could be more helpful if it provided specific guidance on how to conduct additional experiments or comparisons with these newer models. Overall, the comment offers a clear direction for enhancing the robustness of the experiments, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific questions about the proposed method's performance at different bitrate ranges and suggests a related work for discussion or comparison. The first question asks for clarification on the precise bitrate range used for BD-rate comparison, which is a direct and explicit action for the authors to address. The second part suggests discussing or comparing the proposed method with a related work, which is also an explicit action. However, the comment does not provide detailed guidance on how to address these points, such as specific steps or examples. Therefore, the comment is mostly actionable, as it identifies areas for improvement but lacks concrete details on implementation. This aligns with a score of 4.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses two specific issues related to the performance of the proposed method at different bitrate ranges and suggests a related work for discussion. It explicitly mentions \"the proposed method looks stronger at high bitrate but close to the baselines at low bitrate,\" which allows the authors to identify the specific part of the paper being addressed. Additionally, it suggests discussing or comparing the proposed method with a related work, providing clear guidance on what needs to be addressed. This comment is fully grounded and specific, as it clearly identifies the areas requiring attention and specifies the actions to be taken. Therefore, it aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two questions: first, it asks for clarification on the precise bitrate range used for BD-rate comparison, and second, it suggests discussing or comparing the proposed method with a related work. The first question is factual and requires the authors to provide more information, but it does not contain a subjective claim or opinion. The second part of the comment suggests a related work for discussion, which is a suggestion but not a claim that needs verification. Therefore, the comment is classified as \"No Claim\" as it does not contain any subjective opinions or judgments that require verification.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the performance of the proposed method at different bitrate ranges, noting that it is stronger at high bitrate but close to baselines at low bitrate. This observation provides a clear insight into the method's limitations, which could be valuable for the authors to address. Additionally, the comment suggests discussing or comparing the proposed method with a related work, specifically mentioning \"Guo Lu, et al., \"Content Adaptive and Error Propagation Aware Deep Video Compression.\" ECCV 2020.\" This recommendation offers a concrete direction for further research or comparison, which could enhance the paper's context and contribution. However, the comment could be more helpful if it provided more detailed guidance on how to conduct the comparison or what aspects to focus on. Overall, the comment is mostly helpful as it highlights an area for improvement and suggests a relevant related work for discussion, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point recommends that the authors distinguish the all-or-nothing or cutoff phenomenon from usual statistical bounds, which are familiar to the machine learning and NeurIPS community. This recommendation provides a clear and explicit action for the authors to take, as they need to clarify the distinction between these two concepts in their paper. The action is concrete, as it specifies exactly what needs to be done to improve the clarity of the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should distinguish the all-or-nothing or cutoff phenomenon from usual statistical bounds, which are familiar to the machine learning and NeurIPS community. However, it does not specify which part of the paper this distinction should be made or where the concepts are discussed. This makes it difficult for the authors to identify the exact section or part of the paper that needs clarification. While the comment is specific about the content to be addressed, it lacks grounding as it does not provide clear guidance on where to make the distinction. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should distinguish the all-or-nothing or cutoff phenomenon from usual statistical bounds, which are familiar to the machine learning and NeurIPS community. However, the comment does not provide any specific reasoning, examples, or references to support why this distinction is important or how it might impact the paper. Without additional context or justification, the claim lacks sufficient evidence to be fully verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors should distinguish the all-or-nothing or cutoff phenomenon from usual statistical bounds, which are familiar to the machine learning and NeurIPS community. This feedback is specific and actionable, as it provides a clear direction for the authors to improve the clarity and context of their work. By highlighting the need to differentiate these concepts, the comment helps the authors enhance the understanding of their findings and their relevance to the broader field. However, the comment could be more helpful if it provided additional context or examples to illustrate the importance of this distinction. Overall, the comment is mostly helpful, as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the improvements on three tasks over previous works and self-implemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not provide explicit or implicit actions for the authors to take. The comment implies that the authors should conduct more analysis, but it does not specify how to do so or what kind of analysis would be beneficial. Without concrete guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"improvements on three tasks over the previous works and self-implemented baselines,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the issue of marginal improvements and the need for further analysis beyond the main experiments. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the improvements on three tasks over previous works and self-implemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, the comment does not provide specific evidence, examples, or references to support this claim. Without detailed justification or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the improvements on three tasks over previous works and self-implemented baselines are marginal. It also suggests that further analysis beyond the main experiments is not sufficient. While the comment highlights a concern, it lacks specific guidance or suggestions on how the authors might address this issue or what kind of additional analysis would be beneficial. Without actionable advice or detailed feedback, the authors may find it challenging to improve their draft. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not provide comprehensive guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the theoretical results of the paper, specifically that the utility guarantees are only provided for Gaussian features and noise. It also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. While the comment identifies a specific area for improvement and provides a clear direction for the authors to address it, it does not explicitly instruct them on how to compare the rates or what specific literature to consult. The action is somewhat explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"main (and only) theoretical result\" in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it details the limitation of the theoretical result, which is the requirement for Gaussian features and noise, and suggests a comparison to existing rates in the literature. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main theoretical result in the paper provides utility guarantees only for Gaussian features and noise, which is a strong requirement compared to previous algorithms that do not need this assumption. It also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. However, the comment lacks specific examples or references to support the claim about the comparison to existing rates. While the reasoning is logical, the absence of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the theoretical results of the paper, noting that the utility guarantees are only provided for Gaussian features and noise. This is a significant constraint, as previous algorithms do not require this assumption. The comment also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature, which is a valuable piece of feedback for improving the paper. However, the comment could be more helpful if it provided specific examples or references to existing literature for comparison. Despite this, the feedback is clear and actionable, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it would have been beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on the simulated data. However, the comment does not provide explicit guidance on how to implement this comparison or what specific aspects should be considered. The action is implicit, as the authors would need to infer that they should compare their extension with the original approach, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, it does not specify which part of the paper this comparison should be made or which sections or figures would be relevant. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, while the suggestion is specific in terms of the comparison, the lack of grounding makes it difficult for the authors to understand where to apply the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, the comment does not provide any specific reasoning, examples, or references to support why this comparison would be beneficial or how it would enhance the paper. Without additional context or justification, the claim lacks sufficient evidence to be considered verifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This feedback is somewhat helpful as it identifies a potential area for comparison that could enhance the paper's contribution. However, the comment lacks specificity regarding which aspects of the comparison should be made or how this comparison would be beneficial. The authors would need to infer the intended scope of the comparison, which limits the helpfulness of the comment. Therefore, it aligns with a score of 3, as it provides some direction but lacks depth and actionable guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their proposed method with more baselines, as there are several works that focus on the same questions. It provides specific examples of these works, such as [1, 2, 3], which implies that the authors should include these in their experimental comparisons to better demonstrate the effectiveness of their method. The comment is explicit in suggesting the addition of more baselines and provides concrete examples, making it clear how the authors should apply the feedback. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should compare their proposed method with more baselines, specifically mentioning several works that focus on the same questions, such as [1, 2, 3]. This provides a clear indication of what additional comparisons are needed. However, the comment does not specify which part of the paper discusses the experimental section, making it weakly grounded. The suggestion to add more experimental comparisons is specific, as it clearly outlines what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors should compare their proposed method with more baselines, specifically mentioning several works that focus on the same questions. However, the comment lacks specific examples or references to these works, making it difficult for the authors to understand which baselines are relevant and how to incorporate them into their experiments. Without detailed guidance or examples, the claim is somewhat verifiable, as it provides a general direction but lacks the necessary depth to be fully actionable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the experimental section, noting that the authors only compared their proposed method with two baselines. It suggests that there are other works focusing on similar questions and provides examples of such works, such as [1, 2, 3]. This feedback is clear and actionable, as it directs the authors to include additional comparisons to better demonstrate the effectiveness of their method. By recommending the inclusion of more relevant baselines, the comment provides a concrete and constructive suggestion that can significantly enhance the paper. Therefore, the comment is highly helpful, as it offers specific guidance on how to improve the experimental evaluation.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should present the average results on the test set with clearly defined error bars under different random seeds. This provides a clear and concrete action for the authors to take, as they know exactly what needs to be done to improve their draft. The comment is explicit and specific, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the reporting of results, suggesting the use of the test set instead of the dev set and the inclusion of average results with error bars. This provides detailed guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should present average results on the test set with clearly defined error bars under different random seeds. This claim is somewhat verifiable as it suggests a specific improvement to the presentation of results, but it lacks detailed reasoning or examples to fully support the suggestion. The authors would need to infer the need for such changes to improve the robustness of their results. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific feedback on the presentation of results in Tables 1 and 2. It highlights a critical issue: the use of the dev set for both reporting best results and performing hyper-parameter search and model selection, which is insufficient to be convincing. The suggestion to present average results on the test set with clearly defined error bars under different random seeds is actionable and provides a clear direction for improvement. This feedback is detailed and constructive, offering a concrete way for the authors to enhance the rigor and reliability of their results. Therefore, the comment is rated as 5: Highly Helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should provide more values for \\\\alpha, specifically mentioning 1e-2 and 1e-3. This direct instruction provides clear guidance on how the authors should improve their draft by expanding the ablation study. The action is explicit and concrete, as it clearly specifies the additional values needed for \\\\alpha. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ablation study on \\\\alpha, recommending the inclusion of additional values such as 1e-2 and 1e-3. This provides detailed guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study on \\\\alpha is insufficient because it only includes values of 1e-4, 1e-1, and 5e-1, with a large gap between 1e-4 and 1e-1. The comment suggests that the authors should provide more values, specifically mentioning 1e-2 and 1e-3. However, the comment does not provide any reasoning or justification for why these additional values are necessary or how they would impact the results. Without specific examples or references, the claim lacks sufficient support, making it borderline verifiable. Therefore, the comment is rated as 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the ablation study on \\\\alpha, noting that it only includes a limited set of values (1e-4, 1e-1, and 5e-1) with a large gap between the first two. The comment suggests that the authors should provide more values, such as 1e-2 and 1e-3, to enhance the comprehensiveness of the study. This feedback is clear and actionable, as it directly points out the need for additional values and provides specific examples of what the authors should include. By addressing this suggestion, the authors can improve the robustness and thoroughness of their ablation study, which is crucial for validating the effectiveness of their approach. Therefore, the comment is highly helpful, as it provides clear guidance on how to enhance the draft.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the methodology and dataset description, specifically asking for clarification on the number of topics used, how topic-word parameters were obtained for the \"real\" dataset, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. While the comment explicitly asks for these details, it does not provide any guidance on how the authors should address these questions or what specific actions they should take to improve their draft. The actions are implicit and vague, leaving the authors without clear instructions on how to respond. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises several questions about the methodology and dataset description, specifically asking for clarification on the number of topics used, how topic-word parameters were obtained for the \"real\" dataset, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. However, the comment does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections that need attention. While the questions are specific, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the methodology and dataset description, specifically asking for clarification on the number of topics used, how topic-word parameters were obtained for the \"real\" dataset, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. These questions are factual and require the authors to provide specific details about their methodology and dataset. However, the comment does not offer any additional context, reasoning, or references to support the need for these details. The questions are clear and specific, but the lack of supporting evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises several questions about the methodology and dataset description, specifically asking for clarification on the number of topics used, how topic-word parameters were obtained for the 'real' dataset, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. These questions are factual and require the authors to provide specific details about their methodology and dataset. However, the comment does not offer any guidance or suggestions on how the authors might address these issues or improve their draft. While the questions are clear and specific, the lack of actionable feedback limits the comment's helpfulness. Therefore, the comment is rated as barely helpful, as it identifies areas for improvement but does not provide detailed guidance for the authors to follow.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a preference for focusing on the main point of the paper, which is the effectiveness of prototypes for few-shot learning, rather than the zero-shot version and its connection to density estimation. However, it does not provide any explicit or implicit suggestions on how to address this issue or improve the draft. The comment lacks concrete guidance on what aspects of the paper need to be revised or adjusted to align with the authors' main point. As a result, the authors are left without actionable feedback on how to improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a preference for focusing on the main point of the paper, which is the effectiveness of prototypes for few-shot learning, rather than the zero-shot version and its connection to density estimation. However, it does not specify which part of the paper this preference pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is vague and does not provide specific guidance on how to address the issue or improve the draft. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a preference for focusing on the main point of the paper, which is the effectiveness of prototypes for few-shot learning, rather than the zero-shot version and its connection to density estimation. However, it does not provide any specific reasoning or evidence to support this preference. The comment lacks detailed justification or examples to explain why the zero-shot version and density estimation are considered distracting. Without additional context or reasoning, the claim is difficult to verify, making it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a preference for focusing on the main point of the paper, which is the effectiveness of prototypes for few-shot learning, rather than the zero-shot version and its connection to density estimation. This feedback is somewhat helpful as it highlights a potential area for improvement in the paper's focus and presentation. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the draft. Without actionable advice or detailed reasoning, the feedback is limited in its ability to guide the authors effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of detail regarding the filtering process used to create the Arabic climate change QA dataset. It suggests that more information on the translation and filtering methodology is needed to assess the dataset quality. However, the comment does not provide explicit guidance on what specific aspects of the methodology should be included or how the authors should address this issue. The action is implicit, as the authors can infer that they need to provide more details on the filtering process, but the lack of concrete instructions makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"details around the filtering process used to create the Arabic climate change QA dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what information is lacking, namely \"more information on the translation and filtering methodology,\" which is crucial for assessing the dataset quality. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a lack of detail regarding the filtering process used to create the Arabic climate change QA dataset, suggesting that more information on the translation and filtering methodology is needed to assess the dataset quality. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the dataset quality is lacking. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some indication of a problem but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors could improve their paper by providing more details about the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that requires further elaboration. However, the comment could be more helpful if it suggested specific ways to improve the dataset or provided examples of how to enhance the methodology. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, it does not provide explicit instructions or concrete guidance on how to implement these suggestions. The authors are left to infer that they need to add more varied attacks and analyze the impact of thresholds, but without specific steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to understand where to address the feedback. While the comment is specific in its suggestions, the absence of grounding information makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, the comment lacks specific details or examples to support these claims, making it difficult for the authors to understand the basis of the suggestion. Without additional context or references, the claim remains somewhat verifiable, as it is based on logical reasoning but lacks concrete evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the experiment results by suggesting that they could be enriched with attacks of varying strengths and by exploring the influence of different thresholds on detection performance. This feedback is somewhat helpful as it points out specific aspects that could enhance the depth and comprehensiveness of the experimental analysis. However, the comment lacks detailed guidance or suggestions on how to implement these enhancements, which limits its impact on the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should train a discriminator on the learned model's generations to confirm the claim of reducing exposure bias, similar to Figure 1. However, it does not provide explicit guidance on how to implement this suggestion or what specific steps should be taken. The action is implicit, as the authors need to infer that they should train a discriminator and follow the methodology described in Figure 1. The lack of concrete details makes the action somewhat vague, aligning with a score of 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests training a discriminator on the learned model's generations to confirm the claim of reducing exposure bias, similar to Figure 1. However, it does not specify which part of the paper this should be done in, making it weakly grounded. The comment is specific in its suggestion to train a discriminator and compare it to Figure 1, but without explicit references to sections or figures, the authors may need to infer the exact part of the paper to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that training a discriminator on the learned model's generations is needed to confirm the claim of reducing exposure bias, similar to Figure 1. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand why this approach is necessary or how it aligns with the paper's claims. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific need for the authors to train a discriminator on the learned model's generations to confirm the claim of reducing exposure bias, drawing a parallel to Figure 1. This feedback is clear and actionable, as it provides a concrete suggestion for an additional experiment that could strengthen the paper's claims. However, the comment could be more helpful if it included guidance on how to implement this suggestion or what specific aspects of the discriminator training should be considered. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the impact of using different image sizes and variations of ResNets on the performance difference. While it suggests that the authors should provide more context or analysis regarding this aspect, the comment does not explicitly instruct the authors on how to address this issue or what specific actions they should take. The action is implicit and vague, as it leaves the authors to infer the need for additional analysis or discussion. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific line in the paper (L170), allowing the authors to accurately identify the part being addressed. It also specifies what the authors should consider, namely the impact of using different image sizes and variations of ResNets on the performance difference. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the impact of using different image sizes and variations of ResNets on the performance difference. However, it does not provide any specific evidence, reasoning, or references to support this claim. The comment lacks detailed justification or examples to substantiate the concern, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the impact of using different image sizes and variations of ResNets on the performance difference, which is a relevant concern for the authors to address. However, the comment lacks specificity and actionable guidance, as it does not provide any suggestions or insights on how the authors might explore this issue further. While it identifies an area for improvement, the feedback is vague and does not offer detailed advice or examples, making it somewhat helpful. The authors would need to infer additional steps to address the concern, which limits the comment's effectiveness. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the algorithm should be presented and described in detail to aid in understanding the proposed method. While the comment implies that the authors should provide a detailed description of the algorithm, it does not specify how this detailed description should be presented or what aspects of the algorithm need to be emphasized. The action is explicit but lacks concrete guidance on how to implement it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the algorithm should be presented and described in detail to aid in understanding the proposed method. However, it does not specify which part of the paper this comment refers to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs improvement. While the comment is specific in its suggestion to provide a detailed description of the algorithm, the absence of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the algorithm should be presented and described in detail to aid in understanding the proposed method. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or beneficial. The comment lacks depth and does not offer a clear justification for the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the algorithm should be presented and described in detail to aid in understanding the proposed method. While this feedback is relevant and provides a clear direction for improvement, it lacks specific guidance on how the authors might enhance the description of the algorithm. The comment is somewhat helpful as it identifies a need for more detailed explanation but does not offer concrete suggestions or examples of how to achieve this. Therefore, it aligns with a score of 3, indicating that the feedback is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper mentions the possibility of using Chebyshev polynomials to achieve a speed-up, and it would be interesting to see a runtime comparison at test time. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific aspects of the comparison should be included. The action is implicit and vague, as it does not specify how the authors should conduct the comparison or what data should be presented. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper mentions the possibility of using Chebyshev polynomials to achieve a speed-up and recommends a runtime comparison at test time. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to include a runtime comparison, but without a clear reference to the relevant section, the authors may find it challenging to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper mentions the possibility of using Chebyshev polynomials to achieve a speed-up and recommends a runtime comparison at test time. However, the comment does not provide any specific reasoning, examples, or references to support why this comparison would be interesting or beneficial. Without additional context or justification, the claim lacks sufficient evidence to be considered verifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper mentions the possibility of using Chebyshev polynomials to achieve a speed-up and recommends a runtime comparison at test time. This feedback is somewhat helpful as it identifies a potential area for further exploration and provides a specific suggestion for improvement. However, the comment lacks depth and does not offer detailed guidance on how to conduct the comparison or what aspects of the comparison would be most informative. While it provides a starting point for the authors to consider, it could be more helpful with additional elaboration or examples. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the style design is clean but criticizes the organization of the prompts in Table 6 and 7, noting that all sentences are squeezed together. While the comment identifies a specific issue with the organization and formatting of the prompts, it does not provide explicit guidance on how to improve the organization or formatting. The authors are left to infer that they need to reorganize the prompts and adjust the formatting to prevent sentences from being squeezed. This lack of explicit action makes the comment somewhat actionable, as it provides a clear direction but lacks detailed guidance on how to implement the changes. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6, 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the organization of the prompts and the formatting of the sentences, providing clear guidance on what needs to be improved. Therefore, this comment is classified as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the style design is clean but criticizes the organization of the prompts in Table 6 and 7, noting that all sentences are squeezed together. While the comment identifies a specific issue with the formatting of the prompts, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the need for improvement but are not provided with specific guidance or references to support the critique. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail or evidence to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the organization of the prompts in Table 6 and 7, noting that the sentences are squeezed together. This feedback is clear and actionable, as it provides the authors with a specific area to improve the formatting of their paper. However, the comment could be more helpful if it offered suggestions on how to reorganize the prompts or adjust the formatting to prevent sentences from being squeezed. While the feedback is valuable, it lacks depth and could be expanded to provide more comprehensive guidance. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights issues with the clarity of the figures, specifically mentioning that figure 2 is confusing due to the relationship between its sub-figures and the lack of labels for certain modules like CMAF, L_BT, and VoLTA. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should clarify the relationships between the sub-figures and label the missing modules. This lack of explicit action makes the comment somewhat actionable, as it provides a clear direction but lacks detailed instructions on how to implement the changes. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the clarity of the figures, such as the confusion between sub-figures and the lack of labels for certain modules like CMAF, L_BT, and VoLTA. This provides clear guidance on what needs to be addressed in the figures. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the figures are not clear, specifically mentioning confusion in figure 2 due to the relationship between sub-figures and the lack of labels for modules like CMAF, L_BT, and VoLTA. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or references, the authors are left to question the validity of the feedback, making it difficult to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the figures, particularly in Figure 2, where the relationship between sub-figures is confusing and certain modules are not labeled. This feedback is clear and actionable, as it provides the authors with specific areas to improve the presentation of their figures. However, the comment could be more helpful if it offered suggestions on how to enhance the clarity or labeling of the figures, such as proposing specific design changes or providing examples of clearer labeling practices. Overall, the comment is mostly helpful as it highlights a clear area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: first, it asks how the number of images impacts the model performance, and second, it suggests explaining the BYOL model in the abstract. While the questions are explicit and direct, they do not provide concrete guidance on how to address these issues. The authors are left to infer that they need to conduct further analysis or provide more context on the impact of image numbers and the explanation of BYOL. The lack of explicit instructions or detailed guidance makes the action somewhat vague and leaves the authors with limited actionable steps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions about the impact of the number of images on model performance and suggests explaining the BYOL model in the abstract. However, it does not specify which part of the paper these questions relate to, such as a specific section or figure. This makes it difficult for the authors to pinpoint the exact areas that need attention. While the questions are specific about the impact of image numbers and the need to explain BYOL, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two questions: how the number of images impacts model performance and whether more training images make the performance worse or better. It also suggests explaining the BYOL model in the abstract. While the questions are logical and relevant to the paper's content, the comment lacks specific examples or references to support the claims. The authors are left to infer the relevance and importance of these questions, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two important questions regarding the impact of the number of images on model performance and suggests explaining the BYOL model in the abstract. These questions are relevant and could provide valuable insights for the authors to improve their understanding and presentation of the work. However, the comment lacks detailed guidance or suggestions on how to address these issues, such as specific analyses or experiments that could be conducted. While the feedback is somewhat helpful, it could be more impactful with additional actionable advice. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment questions the rationale behind the method's effectiveness, particularly concerning the L_pixel component. It suggests that the authors should provide stronger arguments or intuitions to explain why these losses are \"bound to help.\" However, the comment does not explicitly instruct the authors to include these explanations or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on the reasoning behind the method's effectiveness. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the rationale behind the method's effectiveness, particularly regarding the L_pixel component. However, it does not specify which part of the paper discusses this component or the method's effectiveness. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. The comment is specific in that it identifies a need for stronger arguments or intuitions regarding why the L_pixel losses are \"bound to help,\" but without explicit grounding, the authors may struggle to locate the relevant section. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind the method's effectiveness, particularly regarding the L_pixel component, suggesting that the authors should provide stronger arguments or intuitions for why these losses are \"bound to help.\" However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the method works effectively. Without additional context or evidence, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by questioning the rationale behind the method's effectiveness, particularly concerning the L_pixel component. It suggests that the authors should provide stronger arguments or intuitions to explain why these particular losses are \"bound to help.\" This feedback is somewhat helpful as it highlights an area where the authors could improve the clarity and depth of their explanation. However, the comment could be more helpful if it provided specific examples or guidance on how to strengthen the arguments. Overall, the comment offers a clear direction for improvement, but it lacks the depth needed for comprehensive guidance, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. It also suggests that LLMs are typically trained on trillions of tokens, implying that the dataset needs to be massive to cover varied domains. However, the comment does not provide explicit guidance on how the authors might address this issue or what specific changes could be made to the dataset. While it identifies a potential problem, the lack of actionable suggestions or concrete steps leaves the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. It also mentions that LLMs are typically trained on trillions of tokens, suggesting that the dataset needs to be massive to cover varied domains. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing the concern about the dataset size and its implications for capturing diverse user traits and personalities. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. It also suggests that LLMs are typically trained on trillions of tokens, implying that the dataset needs to be massive to cover varied domains. The comment provides a logical reasoning by comparing the dataset size to the typical training data of LLMs, making the claim somewhat verifiable. However, it lacks specific examples or references to support the claim fully, which could make it partially verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. It also highlights the typical scale of training data for LLMs, suggesting that the dataset needs to be massive to cover varied domains. This feedback is somewhat helpful as it identifies a potential limitation in the dataset size and its implications for the model's ability to generalize across different user characteristics and content topics. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this issue, such as exploring methods for expanding the dataset or considering alternative approaches to ensure comprehensive coverage. Overall, the comment offers a clear point of concern but lacks actionable advice, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the use of binary classification as a baseline metric, questioning its ability to assess models' understanding of fine-grained errors like technique errors. However, it does not provide any explicit or implicit suggestions on how to address this concern or improve the evaluation. The comment lacks concrete guidance on what alternative metrics or methods could be considered, making it difficult for the authors to take action to address the issue. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the use of binary classification as a baseline metric, questioning its ability to assess models' understanding of fine-grained errors like technique errors. However, it does not specify which part of the paper this concern pertains to, such as a particular section or table. This lack of grounding makes it challenging for the authors to identify the exact area that needs attention. While the comment is specific in its critique of the metric's limitations, the absence of explicit grounding reduces its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a concern about the use of binary classification as a baseline metric, questioning its ability to assess models' understanding of fine-grained errors like technique errors. However, the comment lacks specific examples or references to support the claim that binary classification is inadequate for this purpose. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for concern but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a valid concern about the use of binary classification as a baseline metric, questioning its ability to assess models' understanding of fine-grained errors like technique errors. This feedback is somewhat helpful as it identifies a potential limitation in the evaluation methodology, prompting the authors to consider alternative metrics or methods that might better capture the nuances of model performance. However, the comment could be more helpful if it provided suggestions or examples of alternative metrics or methods that could be used to address this issue. Overall, the comment offers a clear point of improvement but lacks depth and specificity, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing needs improvement and that some points in the paper are unclear. However, it does not provide specific guidance on what aspects of the writing are unclear or how the authors should improve them. The comment lacks explicit actions or concrete suggestions, making it difficult for the authors to know what to address. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the writing needs improvement and that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or provide any guidance on how to address these issues. The authors cannot confidently determine which sections or aspects of the paper require improvement, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what aspects of the writing are unclear or how the authors should improve them. Therefore, this comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the writing should be improved and that some points in the paper are unclear. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or examples, the authors may find it challenging to understand the basis of the feedback and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the writing needs improvement and that some points in the paper are unclear. However, it lacks specific details or actionable feedback on what aspects of the writing are unclear or how the authors can improve them. The comment is vague and does not provide guidance on addressing the identified issues, making it barely helpful. The authors are left without a clear understanding of how to enhance the clarity and coherence of their paper. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should use other metrics to evaluate the Results, such as BERTScore. This provides a clear and explicit action for the authors to take, as they can directly apply this suggestion to improve their draft. The comment is specific in its recommendation, indicating which alternative metrics could be used. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests using other metrics to evaluate the Results, such as BERTScore. However, it does not specify which part of the paper the results are presented in, making it difficult for the authors to identify the exact section that needs revision. While the suggestion is specific in terms of the metrics, the lack of grounding makes it challenging for the authors to understand which part of the paper is being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests using other metrics to evaluate the Results, such as BERTScore. However, it does not provide any reasoning, examples, or references to support why this suggestion is beneficial or how it would improve the evaluation process. The comment lacks specific justification or evidence, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests using other metrics, such as BERTScore, to evaluate the results. This provides a clear and actionable suggestion for the authors to consider, as it offers a specific alternative to the current evaluation method. However, the comment lacks depth and does not elaborate on why these additional metrics would be beneficial or how they might impact the results. While it offers a starting point for improvement, the feedback could be more comprehensive and helpful if it included more detailed reasoning or suggestions for implementation. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare the SynTextBench metric with other metrics proposed in the literature on LLM evaluation. It also highlights the difficulty in understanding when to use SynTextBench over other metrics, such as MMLU or Big Bench, for language generation. While the comment provides a clear action\u2014comparing the metric with others\u2014it does not offer specific guidance on how to conduct this comparison or what aspects to focus on. The action is explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"a large amount of work on LLM evaluation [2]\" and suggests comparing the SynTextBench metric with other metrics proposed in the literature. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific, as it provides a clear direction for comparison and highlights the difficulty in understanding the conditions for using SynTextBench over other metrics, such as MMLU or Big Bench. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there has been a large amount of work on LLM evaluation [2] and suggests comparing the SynTextBench metric with other metrics proposed in the literature. It also highlights the difficulty in understanding when to use SynTextBench over other metrics, such as MMLU or Big Bench, for language generation. However, the comment lacks specific examples or references to support the claim about the amount of work on LLM evaluation or the comparison of metrics. While the reasoning is somewhat logical, the lack of detailed evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides valuable feedback by suggesting that the authors compare the SynTextBench metric with other metrics proposed in the literature on LLM evaluation. It highlights the difficulty in understanding when to use SynTextBench over other metrics, such as MMLU or Big Bench, for language generation. This feedback is clear and actionable, as it directs the authors to a specific area for comparison and provides a clear rationale for why such a comparison is important. However, the comment could be more helpful if it included specific examples or guidance on how to conduct the comparison. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the writing and annotations in the paper are difficult to follow, but it does not provide any specific suggestions or actions for the authors to take to improve this aspect. The comment lacks concrete guidance on how the authors might address the issue of poor writing and annotations, leaving them without a clear path to enhance the clarity of their paper. As a result, the comment is unactionable, as it does not offer any actionable steps or suggestions for improvement.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the exact section that needs improvement. Additionally, the comment is not specific, as it does not detail what aspects of the writing or annotations are hard to follow. Without specific examples or guidance, the authors cannot effectively address the issue. Therefore, this comment is rated as Not Grounded and Not Specific, corresponding to a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing and annotations are \"poor\" and \"hard to follow.\" However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the writing and annotations in the paper, specifically noting that they are \"poor\" and \"hard to follow.\" However, the comment lacks specificity and actionable suggestions. It does not provide examples of what aspects of the writing or annotations are problematic, nor does it offer guidance on how the authors might improve clarity or readability. Without detailed feedback or constructive advice, the authors may struggle to address the issue effectively. Therefore, the comment is barely helpful, as it provides a general observation but lacks depth and actionable guidance.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific questions about the results presented in Table 2. The first question asks why only 8 out of 14 evaluation metrics achieve SOTA performances for the proposed method. The second question inquires about the discrepancy in F1 scores between the overall setting and individual types in the \"Twitter-2017 $\\rightarrow$ Twitter-2015\" setting. While the comment identifies areas that need clarification, it does not provide explicit guidance on how the authors should address these issues or what specific actions they should take. The actions are implicit and vague, as the authors are left to infer how to improve their draft based on these questions. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by questioning the performance of the proposed method and the discrepancy in F1 scores. This provides clear guidance on what aspects of the results require further explanation or analysis. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the results presented in Table 2, specifically regarding the number of evaluation metrics achieving SOTA performances and the discrepancy in F1 scores between the overall setting and individual types. While the questions are clear and specific, they do not contain subjective opinions or claims that require verification. The comment is factual and descriptive, aligning with a score of \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific areas in the results that require further explanation or clarification. It questions why only 8 out of 14 evaluation metrics achieve SOTA performances for the proposed method and why the method achieves the best overall F1 score but not the best F1 score in all single types in the \"Twitter-2017 $\\rightarrow$ Twitter-2015\" setting. This feedback is clear and actionable, as it directs the authors to specific aspects of their results that need further discussion or analysis. However, the comment could be more helpful if it provided suggestions on how to address these issues or what additional analysis might be beneficial. Overall, the comment is mostly helpful, as it provides valuable insights for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper regarding the discussion of scalability bounds, specifically mentioning the absence of a thorough exploration of the upper limits of FedDES's scalability, as well as the lack of discussion on memory requirements or computational complexity. While the comment identifies a specific area that needs attention, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to expand the discussion to include these aspects, but the action is not concrete or detailed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, namely the limited discussion of scalability bounds, memory requirements, and computational complexity. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the areas that need improvement, such as the absence of a thorough exploration of scalability limits and the lack of discussion on memory requirements or computational complexity. This provides clear guidance for the authors to address these issues. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not thoroughly explore the upper limits of FedDES's scalability, specifically mentioning the absence of a discussion on memory requirements or computational complexity. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim remains somewhat verifiable, as the authors may need to infer the basis of the critique themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of a thorough discussion of scalability bounds, memory requirements, and computational complexity. This feedback is valuable as it highlights an area where the authors could enhance the depth and comprehensiveness of their work. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address these issues, such as suggesting additional experiments or analyses that could be included. Without such guidance, the authors may find it challenging to fully address the feedback. Therefore, the comment is mostly helpful, as it identifies an important area for improvement but lacks detailed actionable advice.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the \"Unsupervised Online Adaptation\" setting, suggesting that the training set, which includes documents, quires, and labels, might not align with the claim of being unsupervised. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit, as the authors need to infer that they should reconsider the setting or provide a justification for why the training set includes annotations despite the claim of unsupervised adaptation. The lack of concrete suggestions or detailed guidance makes the action somewhat vague and challenging to implement. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the \"Unsupervised Online Adaptation\" setting, referencing \"Sec 3.1\" to provide context. However, it does not specify which part of the paper this section corresponds to, making it weakly grounded. The comment is specific in questioning the claim that the setting is unsupervised, as it points out that the training set includes annotations, which contradicts the unsupervised nature. This allows the authors to understand the issue and address it, making the comment specific. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the \"Unsupervised Online Adaptation\" setting, suggesting that the training set, which includes documents, quires, and labels, might not align with the claim of being unsupervised. The comment implies that the presence of annotations in the training set contradicts the unsupervised nature of the adaptation process. However, the claim lacks specific examples or detailed reasoning to fully substantiate the argument. The authors would need to provide additional context or evidence to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some basis for questioning the claim but lacks sufficient detail or evidence to be fully convincing.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the \"Unsupervised Online Adaptation\" setting, pointing out that the training set includes documents, quires, and labels, which may contradict the claim of being unsupervised. This feedback is somewhat helpful as it highlights a specific area that needs clarification or adjustment. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this issue or clarify the nature of their adaptation process. Without concrete recommendations, the authors may find it challenging to fully understand and respond to the critique. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not provide specific guidance on which baselines to include or how to implement these suggestions. The comment lacks concrete details on which baselines are relevant or how the authors should integrate them into their draft. As a result, the authors are left with a general idea of what to do but without clear instructions on how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section or figure that needs improvement. While the suggestion is specific in terms of the methods to include, the lack of grounding makes it challenging for the authors to understand the context and apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment lacks specific examples or references to support the claim that these additional baselines would provide a more comprehensive evaluation of the proposed method. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion and how to incorporate it into their work. Therefore, the comment is considered borderline verifiable, as it provides a general direction but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors should include the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is somewhat helpful as it provides a direction for the authors to enhance their work by considering additional baselines. However, the comment lacks specific details on which baselines to include or how to implement these suggestions, making it somewhat vague and incomplete. The authors would benefit from more detailed guidance on which baselines are most relevant and how they could be integrated into their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the synthetic experiment in a non-separable case, suggesting that the data distribution in Figure 1 might be inseparable from the network model. However, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take to clarify or improve the experiment. The comment implies that the authors should consider the nonlinear expression ability of neural networks and how it relates to the data distribution, but it lacks concrete steps or suggestions for implementation. Therefore, the comment is not actionable, as it does not provide clear guidance on how the authors can address the issue or improve their draft.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the synthetic experiment in a non-separable case, specifically questioning the inseparability of the data distribution illustrated in Figure 1 from the network model. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or figure being addressed. While the comment is specific about the issue, the lack of grounding makes it challenging for the authors to understand where to focus their attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the synthetic experiment in a non-separable case, specifically questioning the inseparability of the data distribution illustrated in Figure 1 from the network model. The comment does not provide any evidence, reasoning, or references to support the claim that the data distribution is inseparable from the network model. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the synthetic experiment in a non-separable case, specifically questioning the inseparability of the data distribution illustrated in Figure 1 from the network model. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the experiment. It lacks actionable advice, making it difficult for the authors to understand the problem and how to resolve it. As a result, the comment is not helpful in terms of providing constructive feedback or suggestions for improvement. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the results are presented in a convoluted manner and specifically mentions that the results disregard the safety violations of the agent in the first 1000 episodes. It also notes that the reason for this presentation is unclear. While the comment identifies a potential issue with the clarity of the results and the omission of safety violations, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to clarify the presentation and include the safety violations in their results. This makes the action implicit and somewhat vague, as the authors need to deduce the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the results being presented in a convoluted way and specifically points out the omission of safety violations in the first 1000 episodes. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed: the convoluted presentation of results and the disregard for safety violations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results are presented in a convoluted way and specifically mentions that the results disregard the safety violations of the agent in the first 1000 episodes. The comment also states that the reason for this presentation is unclear. However, the comment lacks specific examples or detailed reasoning to support the claim that the results are convoluted or that the omission of safety violations is a significant issue. Without additional context or evidence, the authors may find it challenging to fully understand and address the feedback. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks depth and clarity.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results, noting that they are convoluted and that the safety violations of the agent in the first 1000 episodes are disregarded. The comment also points out that the reason for this presentation is unclear. This feedback is somewhat helpful as it highlights a potential area for improvement in the clarity and completeness of the results section. However, it lacks detailed suggestions or guidance on how the authors might address these issues, such as providing a clearer explanation of the convoluted presentation or including the safety violations in the results. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to define the bounds for \\\\tau_i^l, which is crucial for understanding the time-warp function. This provides a clear and direct action for the authors to take, as they know exactly what needs to be addressed. The comment is specific and concrete, giving the authors a precise task to complete. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific part of the paper, indicated by the line number (l111). This allows the authors to accurately identify the section where the bounds for \\\\tau_i^l need to be defined. The comment is also specific because it clearly specifies what is missing in the paper, namely the definition of the bounds for \\\\tau_i^l, which is essential for understanding the time-warp function. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification and a specific question about the definition of \\\\tau_i^l, which is important for understanding the time-warp function. It does not contain a subjective claim or opinion, but rather a request for more information or clarification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is specific and actionable, as it requests the authors to define the bounds for \\\\tau_i^l, which is crucial for understanding the time-warp function. This feedback is clear and provides a direct instruction for improvement, allowing the authors to address a specific aspect of their work. However, the comment could be more helpful if it offered additional guidance or suggestions on how to define these bounds effectively. Overall, the comment is mostly helpful as it identifies a clear area for improvement and provides a specific action for the authors to take.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques a statement on line 134, which claims that the sigmoid function is only true for standard sigmoid and depends on the maximum slope. It then references Theorem 4.1 and suggests that it would be useful to elaborate more in the main text why this holds, specifically mentioning that the RNN, unlike the URNN, will converge to the nearest fixed point. However, the comment does not provide explicit guidance on how to elaborate on this point or what specific aspects of the explanation should be included. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the explanation of the theorem. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 134\" and \"Theorem 4.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, elaborating on why the statement holds, particularly in the context of the RNN converging to the nearest fixed point compared to the URNN. This provides clear guidance on what aspects of the paper require attention. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques a statement on line 134, which claims that the sigmoid function is only true for standard sigmoid and depends on the maximum slope. It then references Theorem 4.1 and suggests that it would be useful to elaborate more in the main text why this holds, specifically mentioning that the RNN, unlike the URNN, will converge to the nearest fixed point. However, the comment does not provide any specific examples, detailed reasoning, or references to support the claim that elaborating on this point would be beneficial. The lack of detailed explanation or evidence makes it difficult for the authors to understand the basis of the suggestion, leaving them uncertain about how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific point in the paper that requires further elaboration, specifically on line 134 and Theorem 4.1. It suggests that the authors should elaborate more in the main text to explain why the statement holds, particularly in the context of the RNN converging to the nearest fixed point compared to the URNN. This feedback is clear and actionable, as it provides a specific area for improvement and guidance on how to enhance the explanation. However, the comment could be more helpful if it included examples or detailed reasoning to support the suggestion. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement and provides a clear direction for action.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the efficiency of pairwise matching, noting that it is very low and difficult to be used in practical application systems. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might improve the efficiency of their method or what changes could be made to enhance its practical applicability. As a result, the authors are left without a clear understanding of how to proceed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the efficiency of pairwise matching, noting that it is very low and difficult to be used in practical application systems. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or context. The comment is specific in its critique of the efficiency of pairwise matching, but it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the efficiency of pairwise matching is very low, making it difficult to be used in practical application systems. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the efficiency of pairwise matching, noting that it is very low and may limit its practical application. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the efficiency of their method. Without actionable advice or examples of how to enhance the efficiency, the authors may find it challenging to incorporate this feedback into their draft. Therefore, the comment is barely helpful, as it points out a problem but does not provide sufficient direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the allocation of Figure 1 is too naive and suggests that the authors could have edited the space of the main paper more wisely. While the comment identifies a potential issue with the figure's allocation, it does not explicitly instruct the authors on how to improve the space allocation or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the allocation of Figure 1, indicating that the authors need to consider how to improve the space allocation. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the allocation of Figure 1 is \"too naive\" and suggests that the authors could have edited the space of the main paper more wisely. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any evidence or references to substantiate the assertion that the allocation is indeed \"too naive\" or why the authors should consider editing the space more wisely. Without concrete examples or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive and that the authors could have edited the space of the main paper more wisely. While the comment points out a potential issue, it lacks specific guidance or suggestions on how to address this concern. The feedback is somewhat helpful as it highlights an area for improvement, but it does not provide detailed actionable advice or examples to help the authors enhance their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the first sentence of the abstract should be re-written. This is an explicit action that the authors can directly implement by revising the sentence. However, the comment does not provide specific guidance on how to re-write the sentence or what aspects need improvement. While the action is clear, the lack of detail makes it somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the first sentence of the abstract needs to be re-written. However, it does not specify which part of the abstract this refers to, making it difficult for the authors to pinpoint the exact section that requires revision. Additionally, the comment lacks specificity, as it does not provide details on what aspects of the sentence need to be re-written or why it needs to be revised. Therefore, this comment is not grounded and not specific, aligning with a score of 1: Not Grounded.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the first sentence of the abstract needs to be re-written. However, it does not provide any reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this change is necessary or how it would improve the abstract. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the first sentence of the abstract needs to be re-written. While this provides a clear indication of an area for improvement, it lacks specificity and does not offer any guidance on how the sentence should be re-written or what aspects need to be addressed. The comment is vague and does not provide actionable feedback, making it barely helpful. Therefore, the comment is rated as 2: Barely Helpful.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should report results for multiple train/test splits or folds to provide a more accurate illustration of the method\\u2019s performance. It acknowledges that this might be time-consuming due to the size of the datasets but encourages the authors to consider it. The comment is explicit in its suggestion and provides a clear action for the authors to take, which is to carry out the experiment with multiple splits. However, it lacks specific guidance on how to implement this suggestion, such as which metrics to use or how to analyze the results. Therefore, the comment is mostly actionable, as it provides a clear direction but could be more detailed in its implementation guidance.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of reporting results for a single held-out test set, which is a specific part of the paper. It also provides a clear suggestion to use multiple train/test splits or folds, which is a specific action to improve the accuracy of the method\\u2019s performance. The comment is specific in its focus on the experimental methodology and provides clear guidance on how to address the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results are reported for a single held-out test set, which is not standard practice in many papers on Gaussian Processes (GPs). The reviewer suggests that using multiple train/test splits or folds would provide a more accurate illustration of the method\\u2019s performance. While the comment highlights a deviation from standard practice, it does not provide specific examples or references to support the claim that this is a common issue or how it affects the results. The reasoning is somewhat vague, as it lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental methodology, specifically the use of a single held-out test set, which is not standard practice in many papers on Gaussian Processes (GPs). It suggests that using multiple train/test splits or folds would provide a more accurate illustration of the method\\u2019s performance. While the comment does not provide specific guidance on how to implement this suggestion, it offers a clear direction for improvement. The feedback is somewhat helpful as it highlights a potential weakness and encourages a more robust evaluation, but it could be more comprehensive with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the method described in the paper is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, it does not provide explicit guidance or suggestions on how the authors might simplify the method or identify the simpler principle. The action is implicit and vague, as it leaves the authors to infer the need for simplification and the potential underlying principle. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the method described in the paper is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, it does not specify which part of the paper this observation pertains to, such as a particular section, table, or figure. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is somewhat specific in that it suggests a potential simplification, but it does not provide detailed guidance on how to achieve this. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the method described in the paper is more involved than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, the comment lacks specific details or examples to support this claim. It does not provide any references or logical reasoning to substantiate the assertion that the method is overly complex or that a simpler principle exists. Without additional context or evidence, the claim remains speculative and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the complexity of the method described in the paper, suggesting that it might be more involved than necessary. It implies that there could be a simpler underlying principle driving the quality gains, which could be a valuable insight for the authors to consider. However, the comment lacks specific suggestions or guidance on how to simplify the method or identify the simpler principle. While it points out a potential area for improvement, it does not provide actionable steps or detailed advice, making it somewhat helpful. The authors would need to infer the need for simplification and explore potential underlying principles on their own, which limits the comment's impact. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. While the comment acknowledges the potential benefit of the approach, it does not provide explicit guidance on how to implement this method or what specific aspects of transferability it aims to improve. The action is implicit, as the authors would need to infer that they should consider adding such a method to enhance transferability. However, the comment lacks concrete details on how to achieve this, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its critique of the contribution, but without clear grounding, the authors may struggle to identify the exact section or aspect of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or logical arguments to substantiate the assertion that this approach is not a significant contribution. As a result, the claim is considered unverifiable due to the absence of supporting evidence or justification. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. While the comment provides a brief critique of the approach, it lacks depth and does not offer specific guidance or suggestions for improvement. The authors would need to infer that they should consider adding such a method to enhance transferability, but the comment does not provide detailed insights or actionable advice. Therefore, the feedback is somewhat helpful, as it identifies a potential area for improvement but does not fully address the authors' needs for enhancing their work.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the challenges in analyzing Adam under the (L0,L1)-smoothness condition and suggests that it might be possible to directly apply standard analysis. It also recommends explaining the differences between this analysis and that of Zhang et al. However, the comment does not provide explicit guidance on how to address these challenges or what specific aspects need clarification. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the challenges in analyzing Adam under the (L0,L1)-smoothness condition and suggests that it might be possible to directly apply standard analysis. It recommends explaining the differences between this analysis and that of Zhang et al. However, the comment does not specify which part of the paper discusses the analysis of Adam or the (L0,L1)-smoothness condition, making it difficult for the authors to pinpoint the exact section or part that needs clarification. While the comment is specific about the issue of challenges and differences, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the challenges in analyzing Adam under the (L0,L1)-smoothness condition and suggests that it might be possible to directly apply standard analysis. It recommends explaining the differences between this analysis and that of Zhang et al. However, the comment lacks specific examples or detailed reasoning to support the claim that standard analysis might be directly applicable. Without further elaboration or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific area of concern regarding the analysis of Adam under the (L0,L1)-smoothness condition. It questions whether the challenges are significant enough to warrant detailed explanation and suggests that standard analysis might be directly applicable. This feedback is somewhat helpful as it highlights a potential gap in the paper's analysis and encourages the authors to clarify the challenges and differences with Zhang et al.'s work. However, the comment could be more helpful if it provided specific examples or guidance on how to address these challenges. Overall, the comment offers a clear direction for improvement, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that most person re-ID methods build on pedestrian detectors and mentions the existence of end-to-end methods. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. The comment lacks guidance on how the authors might address this point or incorporate it into their work. As a result, the authors are left without a clear understanding of what steps to follow to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a general overview of person re-ID methods, categorizing them as building on pedestrian detectors or being end-to-end. However, it does not specify which part of the paper this observation relates to, making it difficult for the authors to pinpoint the exact areas that need attention. Additionally, the comment lacks specificity in detailing what aspects of these methods are being discussed or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that most person re-ID methods build on pedestrian detectors and mentions the existence of end-to-end methods. However, it lacks specific examples or references to support this claim, making it difficult for the authors to verify the accuracy of the statement. Without detailed evidence or examples, the claim remains somewhat unverifiable, as it is based on a general observation without thorough justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a brief overview of person re-ID methods, categorizing them as building on pedestrian detectors or being end-to-end. While this observation is relevant to the field, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue in their work. It does not provide actionable feedback or insights that could help the authors improve their draft. Therefore, the comment is barely helpful, as it identifies a relevant aspect but does not offer substantial assistance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of citations to recent works on self-play and population-play in the context of exploration and coordination within MARL. It provides specific examples of relevant papers, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019, which suggests that the authors should include these citations to set the context of their work. However, the comment does not explicitly instruct the authors on how to incorporate these citations or where to place them in the paper. While the action is implied, it is vague and lacks detailed guidance, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for citations to recent works on self-play and population-play in the context of exploration and coordination within MARL, providing specific examples of relevant papers. This allows the authors to accurately identify the part of the paper that needs attention. The comment is also specific because it clearly specifies what needs to be addressed, namely the missing citations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks citations to recent works on self-play and population-play in the context of exploration and coordination within MARL. It provides specific examples of relevant papers, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019, which supports the claim. However, the comment does not explain why these specific papers are relevant or how they relate to the paper's content, making it somewhat verifiable. The inclusion of these references would enhance the paper's context and relevance, but the lack of detailed reasoning or examples limits the verifiability.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of citations to recent works on self-play and population-play in the context of exploration and coordination within MARL. It provides specific examples of relevant papers, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019, which are crucial for setting the context of the paper. This feedback is clear and actionable, as it directs the authors to include these citations to enhance the paper's relevance and comprehensiveness. However, the comment could be more helpful if it offered guidance on where to place these citations or how they might impact the paper's overall argument. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their method with other self-supervised learning methods that are not based on contrastive learning. This provides a clear and explicit action for the authors to take, as they can directly compare their method with relevant baselines. The comment is specific in its suggestion, guiding the authors on what kind of comparisons would be beneficial. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests comparing the authors' method with other self-supervised learning methods that are not based on contrastive learning. However, it does not specify which part of the paper this comparison should be made or where these methods are discussed. The authors cannot confidently determine which section or part of the paper this suggestion relates to, making it weakly grounded. Additionally, while the suggestion is specific in terms of the type of comparison, it lacks detail on how to implement or execute this comparison. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the authors\\' method with other self-supervised learning methods that are not based on contrastive learning. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this comparison is necessary or how it would benefit their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests comparing the authors\\' method with other self-supervised learning methods that are not based on contrastive learning. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their work by including additional comparisons. By comparing their method with other relevant approaches, the authors can better position their work within the existing literature and demonstrate its unique contributions. This feedback is mostly helpful as it offers a clear and constructive suggestion for improvement, though it could be further expanded to include specific examples or references. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the abstention process and its distinction from a decision threshold used by models. It does not provide explicit instructions or suggestions on how the authors should address this issue or clarify the difference. The comment is vague and lacks concrete guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the abstention process and its distinction from a decision threshold used by models. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is not grounded as it does not provide explicit references or context. Additionally, it does not specify what needs to be clarified or addressed, leaving the authors with no clear direction. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the abstention process and its distinction from a decision threshold used by models. It does not contain a claim or assertion that requires verification. The comment is factual and descriptive, asking for clarification rather than making an opinion or suggestion. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the abstention process and its distinction from a decision threshold used by models. It prompts the authors to clarify this aspect, which is a critical point for understanding the methodology. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or clarify the distinction. While it identifies an important area for improvement, the feedback is somewhat helpful as it highlights a potential area of confusion that needs clarification. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}'"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the paper for some conclusions that are not convincing, specifically mentioning the claim that \"continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality.\" The authors are encouraged to explore the impact of different combination methods, particularly in rehearsal-free continual learning, where feature-replay methods have shown promise. The review suggests considering more recent works, such as [R3], which employ feature replay to continually adjust the feature space. However, the comment does not provide explicit guidance on how to address these issues or what specific actions the authors should take to improve their draft. The feedback is somewhat vague and lacks detailed instructions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the issue of conclusions not being convincing is discussed, allowing the authors to accurately identify the section being addressed. It also specifies what needs to be addressed by suggesting that the authors explore the impact of different combination methods, particularly in rehearsal-free continual learning, and consider more recent works like [R3]. This provides clear guidance on how to improve the paper, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the paper for some conclusions that are not convincing, specifically mentioning the claim that \"continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality.\" The authors are encouraged to explore the impact of different combination methods, particularly in rehearsal-free continual learning, where feature-replay methods have shown promise. The review suggests considering more recent works, such as [R3], which employ feature replay to continually adjust the feature space. However, the comment lacks specific examples or detailed reasoning to fully support the claim, making it somewhat verifiable. The authors would benefit from a more detailed explanation of how the suggested methods could address the issue of noise accumulation and improve representation quality. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern in the paper, noting that some conclusions are not convincing. It provides a detailed critique of the claim that \"continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality.\" The authors are encouraged to explore the impact of different combination methods, particularly in rehearsal-free continual learning, where feature-replay methods have shown promise. The review suggests considering more recent works, such as [R3], which employ feature replay to continually adjust the feature space. This feedback is mostly helpful as it offers clear guidance on how the authors might address the issue and improve their draft by exploring alternative methods and referencing recent work. However, it could be more comprehensive if it provided specific suggestions or examples of how to implement these changes. Overall, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set. It also asks about the generalization of this approach to scenarios where labels are not available. While the comment prompts the authors to clarify their methodology, it does not provide explicit instructions or suggestions on how to address the question or improve the draft. The action is implicit, as the authors need to infer that they should clarify their methodology and discuss the generalization of their approach. However, the comment lacks concrete guidance on how to implement these suggestions, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set. It also asks about the generalization of this approach to scenarios where labels are not available. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or figure. This makes it difficult for the authors to identify the exact area they need to address. While the comment is specific in its questioning, the lack of grounding makes it challenging for the authors to understand the context. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the methodology of pretraining the cardiac signal representation learning model, specifically whether it is done on the entire dataset or just the training set. It also asks about the generalization of this approach to scenarios where labels are not available. While the comment highlights a potential concern regarding the generalizability of the model, it does not provide any specific evidence, reasoning, or references to support the claim. The authors are left to infer the implications of this question, which makes the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the methodology of pretraining the cardiac signal representation learning model, specifically whether it is done on the entire dataset or just the training set. It also inquires about the generalization of this approach to scenarios where labels are not available. While the comment highlights a potential concern regarding the generalizability of the model, it does not provide specific guidance or suggestions on how to address this issue or improve the draft. The feedback is somewhat helpful as it identifies a potential area for clarification, but it lacks depth and actionable advice, making it only somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the accuracy of the ground truth and the significance of the differences observed in the ablation study results. It does not provide explicit instructions or suggestions on how the authors should address these concerns, such as suggesting alternative methods for evaluating the ground truth or providing more detailed analysis of the results. The actions are implicit and vague, as the authors are left to infer what needs to be done. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the accuracy of the ground truth and the significance of the differences observed in the ablation study results, specifically referencing \"Tab.\" However, it does not specify which part of the paper \"Tab.\" refers to, making it difficult for the authors to pinpoint the exact section being addressed. The comment is specific in its questioning but lacks grounding as it does not provide clear guidance on how to address the issues. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the accuracy of the ground truth and the significance of the differences observed in the ablation study results, specifically referencing \"Tab.\" However, it does not provide any evidence, reasoning, or references to support these claims. The questions are open-ended and do not offer specific guidance or justification for the concerns raised. As a result, the comment is considered unverifiable, as it lacks the necessary support for the authors to address the issues effectively.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises important questions about the accuracy of the ground truth and the significance of the differences observed in the ablation study results. It specifically references 'Tab.' but does not provide detailed feedback or suggestions on how the authors might address these concerns. While the comment identifies areas for improvement, it lacks actionable guidance or depth, making it somewhat helpful. The authors are left to infer what steps to take, which limits the comment's overall impact. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the lack of new evaluation metrics and the need for an in-depth exploration of the reasons behind the experimental results. However, it does not provide explicit or implicit actions for the authors to take. The authors are left without guidance on how to address these issues, such as suggesting the development of new metrics or the inclusion of a detailed analysis of the experimental results. The comment lacks concrete details on how to implement these suggestions, making it unactionable. Therefore, this comment is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the lack of new evaluation metrics and the need for an in-depth exploration of experimental results, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine which section or aspect of the paper is being discussed, making the comment weakly grounded. However, the comment is specific in detailing the issues that need to be addressed, such as the absence of new metrics and the need for a deeper analysis of experimental results. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks new evaluation metrics and only uses linearly combined existing metrics. It also suggests that the experimental analysis section needs an in-depth exploration of the reasons behind the results. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two key areas for improvement in the paper: the lack of new evaluation metrics and the need for a deeper exploration of the reasons behind the experimental results. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address them. The feedback is somewhat helpful as it points out areas that require attention, but it lacks actionable advice or detailed examples, which could have been more beneficial for the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how historical observations are combined with inputs known over all time, specifically addressing the differences in sequence lengths (L vs L+M). It mentions that the text discusses separate embedding and addition with positional encoding but notes that clarifications are needed on how the embeddings are combined and fed into the CSCM. This feedback is explicit and provides a clear action for the authors to take, which is to clarify the combination and feeding of embeddings. However, the action is somewhat vague as it does not specify the exact steps or methods that need clarification. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific question about how historical observations are combined with inputs known over all time, particularly focusing on the differences in sequence lengths (L vs L+M). It mentions that the text discusses separate embedding and addition with positional encoding but highlights the need for clarifications on how the embeddings are combined and fed into the CSCM. This feedback is fully grounded as it explicitly mentions the part of the paper being addressed, allowing the authors to accurately identify the section. The comment is also specific, as it clearly specifies what needs clarification regarding the combination and feeding of embeddings. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about how historical observations are combined with inputs known over all time, specifically addressing the differences in sequence lengths (L vs L+M). It mentions that the text discusses separate embedding and addition with positional encoding but notes that clarifications are needed on how the embeddings are combined and fed into the CSCM. This feedback is somewhat verifiable as it points out a specific area where the paper lacks clarity, but it does not provide detailed reasoning or examples to support the claim. The authors would need to infer the need for clarification based on the feedback, which could be improved with more explicit guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely how historical observations are combined with inputs known over all time, particularly concerning the differences in sequence lengths (L vs L+M). It points out that while the text mentions separate embedding and addition with positional encoding, it lacks clarity on how the embeddings are combined and fed into the CSCM. This feedback is clear and actionable, as it directs the authors to clarify a specific aspect of their methodology. However, the comment could be more helpful if it provided additional context or examples to guide the authors in addressing this issue. Overall, the comment is mostly helpful, as it effectively highlights a need for clarification and improvement in the paper.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the paper, noting that the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\lambda$ is not discussed and their values are not specified. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue, such as suggesting a method for analyzing hyper-parameter sensitivity or specifying their values. The action is implicit and vague, as the authors are left to infer how to improve the paper. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the hyper-parameters $m_1$, $m_2$, and $\\lambda$, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of discussion and specification of the sensitivity of these hyper-parameters. This provides the authors with a clear understanding of what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\lambda$ is not discussed and their values are not specified in the paper. This is a factual observation that requires no further verification or evidence. The comment is clear and specific, providing a direct observation about the absence of discussion and specification of these hyper-parameters. Therefore, it is classified as \"3: Somewhat Verifiable\" as it is clear but lacks some depth in terms of suggesting how the authors might address this issue.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\lambda$ is not discussed and their values are not specified. This is a clear and actionable feedback that highlights a gap in the paper. By pointing out the lack of discussion and specification of these hyper-parameters, the comment provides the authors with a clear direction for improvement. However, it could be more helpful if it suggested specific methods or approaches for analyzing the sensitivity of these hyper-parameters or specifying their values. Despite this, the comment is mostly helpful as it directs the authors to an important area that needs attention, enabling them to enhance the completeness and clarity of their work. Therefore, the comment is rated as 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the first two bullets about contributions in the introduction can be combined. This is a clear and explicit action that the authors can easily understand and implement. The comment provides a specific instruction on how to improve the draft by merging two related points. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the first two bullets about contributions in the introduction can be combined. However, it does not specify which part of the introduction these bullets are located in, making it difficult for the authors to identify the exact section to address. While the comment is specific about the action to be taken, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the first two bullets about contributions in the introduction can be combined. This is a suggestion for improvement, but it does not provide any specific reasoning, examples, or references to support why this combination would be beneficial. The comment lacks depth and does not offer a clear justification for the suggestion, making it difficult for the authors to understand the rationale behind it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the first two bullets about contributions in the introduction can be combined. This is a specific and actionable suggestion that could improve the clarity and conciseness of the introduction. By merging the two bullets, the authors can present their contributions more effectively and avoid redundancy. However, the comment does not provide additional guidance or suggestions on how to combine the bullets or what aspects to focus on. While it offers a clear direction for improvement, it lacks depth and could be more helpful if it included more detailed feedback or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the types of situations or social norms discussed in the main paper. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific aspects need clarification. Without actionable guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of clarity regarding the types of situations or social norms discussed in the main paper. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact area that needs clarification. The comment is specific in its critique but weakly grounded as it does not provide explicit references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the types of situations or social norms discussed in the main paper are not clear. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the types of situations or social norms discussed in the main paper. However, it lacks actionable guidance or suggestions on how the authors might address this lack of clarity. Without specific advice on how to improve the clarity or provide more detailed explanations, the authors may find it challenging to effectively respond to the comment. Therefore, the comment is barely helpful, as it points out a problem but does not provide sufficient direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the extent to which the paper improves over existing solutions, particularly in the context of segmentation problems and robustness against weak boundaries. It suggests that the authors should refer to more recent trends in the vision community to demonstrate the algorithm's effectiveness. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the paper need to be improved. The action is implicit and vague, as it does not specify which parts of the paper should be revised or how the authors should incorporate the suggested references. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paper targets a problem that somewhat differs from general segmentation problems, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the importance of demonstrating the algorithm's ability to find closed contours and its robustness against weak boundaries, particularly for bottom-up methods. This provides clear guidance on what aspects of the paper need improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the extent to which the paper improves over existing solutions, particularly in the context of segmentation problems and robustness against weak boundaries. It suggests that the authors should refer to more recent trends in the vision community to demonstrate the algorithm's effectiveness. However, the comment lacks specific examples or references to support the claim that the paper needs to address these issues. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it provides a general direction for improvement but lacks depth and specificity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the extent to which the paper improves over existing solutions, particularly in the context of segmentation problems and robustness against weak boundaries. It suggests that the authors should refer to more recent trends in the vision community to demonstrate the algorithm's effectiveness. However, the comment lacks specific guidance on how to address this issue or what aspects of the paper need to be improved. While it identifies an important area for improvement, it does not provide actionable feedback or detailed suggestions, making it somewhat helpful. The authors would need to infer the need for more detailed comparisons with recent trends and how to incorporate this into their work, which limits the comment's helpfulness. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include more baselines and test on more domains to strengthen their empirical results. It also mentions that the choices of weighting and learning density functions are not strongly motivated. However, the comment does not provide explicit guidance on how to select additional baselines or domains, nor does it offer concrete steps on how to address the lack of motivation for the current choices. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should include more baselines and test on more domains to strengthen their empirical results. It also mentions that the choices of weighting and learning density functions are not strongly motivated. However, the comment does not specify which parts of the paper these suggestions relate to, such as specific sections or tables. This makes it difficult for the authors to pinpoint exactly where to address these issues. While the comment is specific about the need for more baselines and domains, it lacks grounding as it does not provide clear references to the sections or parts of the paper that need improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include more baselines and test on more domains to strengthen their empirical results. It also mentions that the choices of weighting and learning density functions are not strongly motivated. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the reasoning behind the suggestions. The absence of detailed reasoning or examples makes the claim somewhat verifiable, as the authors may need to infer the basis for the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides feedback on the need for more baselines and domains to be tested, as well as the lack of strong motivation for certain design choices. It suggests that the authors should include baselines with other design choices and test on more domains to strengthen their empirical results. However, the comment lacks specific guidance on which baselines or domains to include, making it somewhat helpful. The feedback is clear and identifies areas for improvement, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern that the results are not comparable to existing methods, which may limit the significance of the proposed methods. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the comparability of their results. The comment lacks concrete guidance on what specific steps the authors should take to make their results more comparable or to enhance the significance of their proposed methods. As a result, the authors are left without a clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses concern about the comparability of the results to existing methods, suggesting that the proposed methods may not have significant value. However, it does not specify which part of the paper this issue is related to, such as the results section, the discussion, or the methodology. Without clear grounding, the authors cannot confidently identify where the issue lies, making it difficult to address the concern effectively. Additionally, the comment lacks specificity in detailing what aspects of the results need to be improved to enhance comparability or significance. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a concern that the results are not comparable to existing methods, which may limit the significance of the proposed methods. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without detailed reasoning or references, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a concern regarding the comparability of the results to existing methods, suggesting that the proposed methods may not have significant value. However, the comment lacks specific details or suggestions on how the authors might address this issue or improve the significance of their methods. It does not provide actionable guidance or insights into potential improvements, leaving the authors with limited information on how to enhance their work. As a result, the comment is barely helpful, as it highlights a potential problem but does not offer a clear path forward for the authors to address it. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the limited novelty of the paper, suggesting that it primarily applies existing literature, specifically DeCorr, to a specific application domain. It mentions that the contribution is mainly the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. However, the comment does not provide explicit or implicit actions for the authors to take to address this issue. It lacks concrete guidance on how to enhance the novelty or provide deeper insights into the unique challenges of overcorrelation in recommender systems. As a result, the authors are left without clear directions on how to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"DeCorr\" and \"graph collaborative filtering,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of limited novelty and the lack of unique insights into overcorrelation in recommender systems, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks novelty, as it primarily applies existing literature, specifically DeCorr, to a specific application domain. It suggests that the contribution is mainly the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence weakens the verifiability of the claim, aligning with a score of 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper's novelty, suggesting that it primarily applies existing literature, specifically DeCorr, to a specific application domain. The authors are informed that the contribution is mainly the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. However, the comment highlights that the paper lacks deeper insights into the unique challenges of overcorrelation in recommender systems. This feedback is somewhat helpful as it points out a critical area for improvement, but it could be more actionable with additional suggestions or guidance on how to enhance the novelty and provide unique insights. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of ELM (male or female) and suggests that this choice might require knowing the speaker's gender beforehand, which could be a drawback. It implies that the accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not provide explicit guidance on how to address this issue or what specific actions the authors should take to improve their draft. The suggestion is implicit and lacks concrete details, making it difficult for the authors to understand how to implement the feedback. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the choice of ELM (male or female) and suggests that this choice might require knowing the speaker\\'s gender beforehand, which could be a drawback. It implies that the accuracy should be calculated after using a gender detection model in the pipeline, at least in cases where vocal traits match speaker identity. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or table discussing the selection of ELMs. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific about the issue of gender detection and its impact on accuracy, it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of ELM (male or female) and suggests that this choice might require knowing the speaker\\'s gender beforehand, which could be a drawback. The comment implies that the accuracy should be calculated after using a gender detection model in the pipeline, at least in cases where vocal traits match speaker identity. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence to fully substantiate the assertion, making it somewhat verifiable. Therefore, the comment aligns with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the choice of ELM (male or female) and suggests that this choice might require knowing the speaker\\'s gender beforehand, which could be a drawback. It implies that the accuracy should be calculated after using a gender detection model in the pipeline, at least in cases where vocal traits match speaker identity. This feedback highlights a potential issue with the methodology and suggests that the accuracy calculation might be affected by the gender detection model. However, the comment does not provide specific guidance or suggestions on how to address this issue or improve the draft. While it identifies a potential area for improvement, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that the writing is difficult to follow in many places and suggests that it could be simplified. However, it does not provide any specific guidance or suggestions on how to simplify the writing or what aspects of the writing are particularly challenging. The comment lacks concrete actions or detailed feedback on what needs to be improved, leaving the authors with no clear direction on how to address the issue. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the writing is difficult to follow in many places and could be simplified. However, it does not specify which sections or parts of the paper are particularly challenging to understand. Without explicit references to specific sections, tables, figures, or unique aspects of the paper, the authors cannot confidently identify the areas that need improvement. The comment is vague and lacks specificity, making it difficult for the authors to address the issue effectively. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing is difficult to follow in many places and suggests that it could be simplified. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the writing is unclear or challenging, the authors may find it difficult to understand the basis of the feedback or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the writing, noting that it is difficult to follow in many places and suggests that it could be simplified. However, the comment lacks specific details or actionable suggestions on how to improve the writing. While it highlights a general area for improvement, it does not provide the authors with concrete guidance on what aspects of the writing need to be revised or how to simplify it. This lack of specificity and detail makes the comment somewhat helpful, as it points out a critical issue but does not offer a comprehensive solution. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is incremental and lacks technical substance, primarily adding a new loss to [31]. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve the technical depth or substance of their work. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper is incremental and lacks technical substance, primarily adding a new loss to [31]. However, it does not specify which part of the paper this issue is related to, such as the introduction, methodology, or results sections. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need improvement. Additionally, the comment is specific in its critique of the paper's incremental nature and the addition of a new loss, but without clear guidance on how to address these issues, the authors may struggle to make meaningful improvements. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is incremental and lacks technical substance, primarily adding a new loss to [31]. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, suggesting that it is incremental and lacks technical substance, primarily adding a new loss to [31]. While this feedback highlights an area for improvement, it does not provide specific guidance or suggestions on how the authors might address this issue. The comment lacks actionable advice, such as recommending additional experiments, deeper analysis, or more detailed explanations to enhance the paper's technical depth. Without concrete suggestions, the authors may struggle to understand how to improve their work. Therefore, the comment is somewhat helpful, as it points out a significant area for improvement but does not provide sufficient guidance for the authors to act upon.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more intuition about the proof of Theorem 1, particularly regarding the invertible function $f^*$ and its dependence on the fixed $P^*$. It also asks for practical guidance on how to determine which $P^*$ to fix. While the comment provides some direction for improvement, it lacks explicit instructions on how to incorporate this feedback into the draft. The authors are left to infer that they need to add more explanation and practical advice, but the action is not fully concrete. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests providing more intuition about the proof of Theorem 1, specifically regarding the invertible function $f^*$ and its dependence on the fixed $P^*$. It also raises questions about the practical determination of $P^*$. However, the comment does not specify which part of the paper this feedback pertains to, making it weakly grounded. The suggestion to provide intuition and practical guidance is specific, but without clear references to the relevant sections, the authors may struggle to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the intuition behind the proof of Theorem 1, particularly regarding the invertible function $f^*$ and its dependence on the fixed $P^*$. It also asks for practical guidance on determining which $P^*$ to fix. While the questions are logical and relevant to the paper, they do not provide specific examples or references to support the claims. The feedback is somewhat verifiable as it offers clear reasoning but lacks detailed evidence or references, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the paper, such as offering more intuition about the proof of Theorem 1, particularly regarding the invertible function $f^*$ and its dependence on the fixed $P^*$. It also raises questions about the practical determination of $P^*$, which could guide the authors in enhancing the clarity and practical relevance of their work. However, the comment could be more helpful if it provided more detailed guidance or examples on how to incorporate these suggestions into the draft. Overall, the feedback is somewhat helpful as it identifies areas for improvement but lacks depth and specificity, leaving the authors with a clear direction but not a fully comprehensive guide.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of different variables in equations (7) and (10), questioning why they are not analogous. However, it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what changes could be made to the equations. Without specific advice or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the use of different variables in equations (7) and (10), specifically asking why they are not analogous. However, it does not provide any guidance or suggestions on how to address this issue or what changes might be necessary. The authors are left without a clear understanding of what part of the paper needs revision or improvement. The comment is not grounded as it does not specify which section or part of the paper is being addressed, and it is not specific because it does not offer any suggestions or guidance. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the use of different variables in equations (7) and (10), questioning why they are not analogous. However, it does not provide any claim or suggestion that requires verification or justification. The comment is purely analytical and does not offer any new information or critique that would need to be substantiated. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the use of different variables in equations (7) and (10), specifically questioning why they are not analogous. This feedback highlights a potential inconsistency or lack of clarity in the equations, which could be a point of confusion for readers. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what changes could be made to improve the consistency of the equations. Without actionable feedback or suggestions, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it identifies a potential issue but lacks depth and direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the applicability of the model to real-world diffusion processes. It acknowledges that the authors have defined an interesting problem with elegant solutions but suggests that providing empirical evidence would be beneficial. However, the comment does not explicitly instruct the authors on how to provide this evidence or what specific aspects of the model should be tested. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct empirical evaluations to support the model's applicability. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the applicability of the model to real-world diffusion processes, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper discusses this applicability, making it weakly grounded. The comment is specific in suggesting that the authors should provide empirical evidence to support the model's applicability, which is clear and actionable. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the applicability of the model to real-world diffusion processes, suggesting that the authors should provide empirical evidence to support this claim. However, the comment lacks specific details or examples of how this evidence could be provided, making it difficult for the authors to understand and address the concern effectively. The claim is somewhat verifiable as it points out a potential area for improvement but does not provide sufficient guidance or references to support the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the applicability of the proposed model to real-world diffusion processes. It acknowledges that while the authors have defined an interesting problem with elegant solutions, the lack of empirical evidence to support the model's applicability in real-world scenarios is a notable weakness. The comment suggests that the authors should provide empirical evidence to address this concern, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific guidance on how to conduct these empirical evaluations or what types of evidence would be most effective. Overall, the comment is mostly helpful as it highlights a critical area for improvement and encourages the authors to strengthen their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the main contribution of combining attention with other linear mechanisms is not novel, referencing the paper itself. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. The comment lacks actionable steps or concrete advice, leaving the authors without a clear path to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section or aspect being discussed. It mentions the \"main contribution\" of combining attention with other linear mechanisms but does not provide specific details or examples of what is being criticized or improved. The comment is also not specific because it lacks detailed feedback on what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the main contribution of combining attention with other linear mechanisms is not novel, referencing the paper itself. However, the comment lacks specific evidence or detailed reasoning to support this claim. It does not provide examples of existing alternatives or explain why the contribution is not novel. Without this additional information, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the paper's main contribution, specifically the combination of attention with other linear mechanisms. However, it lacks depth and specificity, as it does not provide detailed reasoning or examples to support the claim that the contribution is not novel. Without additional context or suggestions for improvement, the authors may find it challenging to address the feedback effectively. Therefore, the comment is barely helpful, as it offers a general observation but lacks actionable guidance.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the novelty of the paper is limited, noting that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into D and Phi_v. However, the comment does not provide explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to enhance the novelty of the paper or what specific aspects need to be improved. Without concrete suggestions or actionable steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the methodology aspect of the paper, specifically mentioning the ENCODE part and the decomposition part. It provides a detailed explanation of the novelty of the paper, noting that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. This provides clear grounding as the authors can accurately identify the section of the paper being discussed. Additionally, the comment specifies what needs to be addressed, highlighting the limited novelty and suggesting that the authors should enhance the novelty of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. While the comment provides a specific claim about the novelty of the paper, it lacks detailed reasoning or references to support the assertion that the ENCODE part is already proposed in [10]. Without further elaboration or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the novelty of the paper, specifically pointing out that the ENCODE part is already proposed in [10]. It also highlights that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. While the comment provides a clear observation about the novelty of the paper, it lacks actionable suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without specific advice or suggestions, the authors are left with limited insight on how to improve their draft. Therefore, the comment is somewhat helpful, as it identifies a weakness but does not provide sufficient guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance comparison of the proposed CLN (region proposal generation algorithm) with another work, [A]. However, it does not provide any explicit or implicit suggestions on how the authors should address this comparison or what specific aspects of the comparison should be considered. The comment lacks concrete guidance on how to conduct the comparison or what data or metrics should be used. As a result, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the performance comparison of the proposed CLN (region proposal generation algorithm) with another work, [A]. However, it does not specify which part of the paper this comparison should be made or which sections of the paper are relevant to this discussion. The authors cannot confidently determine which part of the paper the comment addresses, making it weakly grounded. Additionally, the comment does not provide specific guidance on how to conduct the comparison or what aspects of the comparison should be considered. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the performance comparison of the proposed CLN (region proposal generation algorithm) with another work, [A]. However, it does not provide any specific evidence, reasoning, or references to support the claim that such a comparison is necessary or beneficial. The comment lacks detailed justification or examples to substantiate the need for this comparison, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the performance comparison of the proposed CLN (region proposal generation algorithm) with another work, [A]. However, it does not provide any suggestions or guidance on how the authors might address this comparison or what aspects of the comparison are important. The comment lacks actionable feedback, leaving the authors without a clear understanding of how to improve their draft. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review comment identifies issues with the presentation of the paper, specifically noting that it is too equation-driven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure of the key concepts in section 3 would have been helpful. While the comment explicitly states the issue and provides a suggestion for improvement, it does not offer concrete guidance on how to create or integrate the figure into the paper. The action is implicit and somewhat vague, as the authors would need to infer that they should create a figure to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"chapter 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies the issue as the presentation being \"equation-driven\" and the notation being \"convoluted and hard to follow,\" and suggests that an illustrative figure would have been helpful. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the presentation is \"equation-driven\" and that the notation in chapter 3 is \"convoluted and hard to follow.\" It suggests that an illustrative figure would have been helpful. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the exact nature of the issue or how to address it. The reasoning is somewhat vague, and the suggestion for an illustrative figure is not fully substantiated. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of the paper, noting that it is too equation-driven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure of the key concepts in section 3 would have been helpful. This feedback is clear and actionable, providing the authors with a specific direction for improvement. However, the comment could be more helpful if it offered additional suggestions or guidance on how to create or integrate the figure effectively. Overall, the comment is mostly helpful as it highlights a significant area for improvement and provides a clear suggestion for addressing it.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the visual presentation of the data in Figure 3, specifically the subscripts, could be enhanced for better readability and aesthetic appeal. However, it does not provide any explicit or implicit actions for the authors to take to improve the presentation. The comment lacks guidance on how to enhance the subscripts or what specific improvements could be made. As a result, the authors are left without a clear understanding of what steps to undertake to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the visual presentation, particularly the subscripts, and suggests that enhancing readability and aesthetic appeal would improve the presentation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the visual presentation of data in Figure 3, specifically the subscripts, could be enhanced for better readability and aesthetic appeal. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to improve the presentation. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the visual presentation of data in Figure 3, noting that the subscripts could be enhanced for better readability and aesthetic appeal. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address. However, the comment could be more helpful if it offered suggestions on how to enhance the subscripts or provided examples of improved presentation. Despite this, the comment is mostly helpful as it directs the authors to a concrete area for improvement, allowing them to make targeted revisions to their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the technical details and formulations are limited, suggesting that the novelty of the scheme or procedure is unclear. However, it does not provide explicit guidance on what specific aspects of the technical details or formulations need to be expanded or clarified. The comment implies that the authors should elaborate on the technical details and formulations to better showcase the novelty of their scheme or procedure, but it lacks concrete instructions on how to achieve this. As a result, the authors are left with a vague understanding of what needs to be addressed, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"technical details and formulations,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies that the novelty of the scheme or procedure is unclear, providing clear guidance on what needs to be addressed. This makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical details and formulations are limited, suggesting that the novelty of the scheme or procedure is unclear. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by pointing out that the technical details and formulations are limited, which may hinder the demonstration of the scheme or procedure's novelty. However, the comment lacks specific guidance or suggestions on how the authors might address this issue. It does not provide actionable advice or examples of what could be expanded to enhance the paper's clarity and impact. As a result, while it highlights an area for improvement, it does not offer sufficient direction for the authors to effectively address the feedback. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the update mechanism of archetype positions in Algorithm 2, specifically after initialisation. It does not provide explicit instructions or suggestions on how to address this issue, nor does it offer concrete guidance on how to update the archetypes. The comment is vague and lacks actionable steps for the authors to take. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the update mechanism of archetype positions after initialisation, providing a clear direction for the authors to address the concern. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the update mechanism of archetype positions in Algorithm 2, specifically after initialisation. It does not contain a claim or assertion that requires verification. The comment is factual and descriptive, as it seeks clarification on a specific aspect of the algorithm. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the update mechanism of archetype positions in Algorithm 2, specifically after initialisation. It points out a lack of clarity regarding how these positions are updated, which could hinder the understanding and implementation of the algorithm. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the clarity of the algorithm. As a result, the feedback is somewhat helpful, as it identifies a potential area for improvement but lacks actionable advice. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several areas where additional information is missing from the empirical study, such as recording parameters for the MRI, preprocessing steps, the condition of the resting-state recording (eyes-open or eyes-closed), and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. These suggestions are explicit and provide clear guidance on what information needs to be included to improve the paper. The authors can directly apply these actions to enhance the completeness and clarity of their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for additional information in the empirical study, such as recording parameters for the MRI, preprocessing steps, the condition of the resting-state recording (eyes-open or eyes-closed), and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. This provides clear guidance on what specific aspects of the study need to be addressed, allowing the authors to accurately identify the parts of the paper that require improvement. The comment is specific in detailing what information is missing and what should be included, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of several claims that are supported by logical reasoning and specific examples. It suggests that the authors should include information about recording parameters for the MRI, preprocessing steps, the condition of the resting-state recording (eyes-open or eyes-closed), and a brief explanation of the harmonization technique. Additionally, it recommends mentioning the number of regions in the parcellation in the main text. These suggestions are clear and provide specific guidance on what information is missing, making the claim fully verifiable. The comment is well-supported and provides actionable feedback for the authors to improve their draft.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on several aspects of the empirical study, such as the need for additional information about recording parameters, preprocessing steps, and the resting-state recording condition. It also suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. These suggestions are clear and detailed, offering the authors concrete guidance on how to enhance the completeness and clarity of their draft. By addressing these points, the authors can significantly improve the comprehensiveness and rigor of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the statement about over-parametrization leading to overfitting and worse performance, suggesting that over-parametrization can be beneficial in practice. It also mentions theoretical work supporting the benefits of over-parametrization. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting specific changes to their draft or addressing the issue. The feedback lacks concrete guidance on how to incorporate or discuss the benefits of over-parametrization. As a result, the authors are left without clear direction on how to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 47 - 48,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider, namely that over-parametrization can be beneficial in practice and provides references to theoretical work supporting this claim. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the statement about over-parametrization leading to overfitting and worse performance, suggesting that over-parametrization can be beneficial in practice. It references theoretical work supporting this claim, providing a basis for the critique. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. The authors would benefit from a more detailed explanation or examples to understand the nuances of over-parametrization and its benefits.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques a statement about over-parametrization, suggesting that it is not always detrimental and can be beneficial in practice. It references theoretical work that supports the benefits of over-parametrization, providing a counterpoint to the initial statement. However, the comment lacks specific guidance on how the authors might address this issue in their draft or what changes could be made to better align with the critique. While it offers a valuable perspective, the feedback could be more helpful if it included actionable suggestions or examples of how to incorporate the benefits of over-parametrization into the paper. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the time-consuming nature of the training process due to the pixel-level shape model and the independent training on all font images and characters. It also mentions the complexity of the parsing model as a high-order factor graph with four types of factors. However, the comment does not provide explicit or implicit actions for the authors to take to address this issue. It lacks concrete guidance on how to improve the efficiency of the training process or how to compare the processing efficiency with existing work. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the time-consuming nature of the training process due to the pixel-level shape model and the independent training on all font images and characters. It also mentions the complexity of the parsing model as a high-order factor graph with four types of factors. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section being addressed. While the comment is specific about the issues raised, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the time-consuming nature of the training process due to the pixel-level shape model and the independent training on all font images and characters. It also mentions the complexity of the parsing model as a high-order factor graph with four types of factors. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the training process is time-consuming or that the parsing model is complex. Without these elements, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the time-consuming nature of the training process due to the pixel-level shape model and the independent training on all font images and characters. It also highlights the complexity of the parsing model as a high-order factor graph with four types of factors. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve the efficiency of their training process. Without actionable advice or detailed feedback, the authors may find it challenging to incorporate these points into their draft. Therefore, the comment is barely helpful, as it points out a potential area for improvement but does not provide sufficient guidance for the authors to act upon.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a discussion on the creation of the prompt dataset used in the few-shot case, along with its source. This is a clear and explicit action that the authors can readily follow. The comment provides specific guidance on what needs to be included in the discussion, making it highly actionable. Therefore, this comment is rated as 5: Highly Actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should include a discussion on the creation of the prompt dataset used in the few-shot case, along with its source. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to know exactly where to apply the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include a discussion on the creation of the prompt dataset used in the few-shot case, along with its source. This is a suggestion for improvement, but it lacks specific details or references to support why this discussion is necessary or how it would enhance the paper. Without additional context or justification, the claim is somewhat verifiable, as it provides a general direction for improvement but lacks depth. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should include a discussion on the creation of the prompt dataset used in the few-shot case, along with its source. This feedback is clear and actionable, as it provides a specific area for improvement that could enhance the transparency and reproducibility of the research. By addressing this suggestion, the authors can improve the clarity and completeness of their paper. However, the comment could be more helpful if it provided additional guidance on how to structure or present this discussion effectively. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details. Therefore, it is rated as 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an ablation study on the weighting method of the cross-entropy loss would be beneficial. It also mentions an example where the authors' method underperforms due to repetitive background sounds, which the reviewer expects the weighting method to address. While the comment provides a clear action\u2014asking for an ablation study\u2014it does not specify how the authors should conduct this study or what aspects of the weighting method should be explored. The action is explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests an ablation study on the weighting method of the cross-entropy loss, referencing an example where the authors' method underperforms due to repetitive background sounds. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting an ablation study, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests an ablation study on the weighting method of the cross-entropy loss, referencing an example where the authors' method underperforms due to repetitive background sounds. However, the comment lacks specific details or examples to substantiate the claim that the weighting method could have helped remedy this issue. Without further explanation or evidence, the claim remains somewhat verifiable, as it is based on an inference rather than a direct observation or logical reasoning. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests an ablation study on the weighting method of the cross-entropy loss, noting that the authors' method underperforms due to repetitive background sounds. This feedback is somewhat helpful as it identifies a potential area for improvement and provides a specific example of a scenario where the weighting method might have been beneficial. However, the comment lacks detailed guidance on how to conduct the ablation study or what specific aspects of the weighting method should be explored. While it offers a direction for improvement, the feedback could be more comprehensive and actionable if it included more detailed suggestions or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a critical weakness in the paper, stating that it lacks novelty and is incremental in nature. It also critiques the approach of designing a new dataset as a different train/test split of an existing dataset, SQUALL, and mentions another synthetic benchmark paper based on a single question template. However, the comment does not provide any explicit or implicit suggestions on how the authors might address these issues or improve the paper. The authors are left without guidance on how to enhance the novelty or significance of their work, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It also critiques the approach of designing a new dataset as a different train/test split of an existing dataset, SQUALL, and mentions another synthetic benchmark paper based on a single question template. However, the comment does not specify which part of the paper discusses the dataset or the approach, making it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific in its critique of the novelty and approach, it lacks grounding as it does not provide clear references to specific sections or parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks novelty and is incremental in nature, criticizing the approach of designing a new dataset as a different train/test split of an existing dataset, SQUALL, and mentioning another synthetic benchmark paper based on a single question template. However, the comment does not provide specific examples, detailed reasoning, or references to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It critiques the approach of designing a new dataset as a different train/test split of an existing dataset, SQUALL, and mentions another synthetic benchmark paper based on a single question template. However, the comment does not provide any actionable suggestions or insights on how the authors might address these issues or improve the novelty of their work. Without specific guidance or suggestions, the authors are left without a clear path forward, making the comment barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, it does not provide specific guidance on how to demonstrate the importance of these assumptions or what kind of examples would be effective. The action is implicit, as the authors need to infer that they should provide detailed explanations and examples to support their claim. The comment lacks concrete details on how to implement this action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in its request for detailed examples to support the claim, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area where the explanation should be provided. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors should explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work. However, the comment could be more helpful if it included examples or guidance on how to demonstrate the importance of these assumptions. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but lacks some depth in terms of specific examples or detailed guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data, with its exact labels, could provide effective information for the model. However, the comment does not provide explicit guidance or suggestions on how to implement this idea or what specific aspects of the model or training process might benefit from this approach. The action is implicit and vague, as it does not specify how the authors should explore or incorporate labeled data into their consistency training. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection, specifically mentioning the idea that labeled data could provide effective information for the model. It also provides references to two papers, [a] Graph Contrastive Learning Automated and [b] Graph Contrastive Learning with Adaptive Augmentation, which are relevant to the discussion. However, the comment does not specify which part of the paper it is addressing, such as a particular section or figure, making it weakly grounded. The comment is specific in its suggestion about the potential benefits of using labeled data, but the lack of grounding makes it difficult for the authors to pinpoint the exact area where this suggestion should be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection, suggesting that labeled data could provide effective information for the model. It provides references to two papers, [a] Graph Contrastive Learning Automated and [b] Graph Contrastive Learning with Adaptive Augmentation, which are relevant to the discussion. However, the comment does not offer a detailed explanation or reasoning for why labeled data might be beneficial, nor does it provide specific examples or comparisons to support the claim. The references are provided, but the lack of detailed reasoning or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection, suggesting that labeled data could provide effective information for the model. It provides references to two relevant papers, which could be helpful for the authors to understand the context and explore the idea further. However, the comment lacks specific guidance on how the authors might incorporate labeled data into their consistency training or what specific aspects of their model or training process might benefit from this approach. While it identifies an interesting area for exploration, the feedback could be more helpful if it offered concrete suggestions or examples of how to implement the idea. Therefore, the comment is somewhat helpful, as it provides a starting point for the authors to consider but lacks detailed guidance.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental part needs to be reorganized and further improved. It highlights that the current experimental content in the main text does not effectively showcase the superiority of the method. The comment implies that the authors should reorganize the experimental section to better highlight the method's advantages. However, it does not provide specific guidance on how to reorganize the content or what aspects should be emphasized. The action is implicit and somewhat vague, as the authors need to infer the need for reorganization and improvement. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experimental part needs to be reorganized and further improved, indicating that the authors should reorganize the experimental section to better highlight the method\\'s superiority. However, the comment does not specify which part of the paper the experimental section is located in, making it weakly grounded. It is specific in suggesting that the experimental content should include certain suggestions to highlight the method\\'s superiority, but without explicit references to sections or figures, the authors may need to infer the exact part to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experimental part needs to be reorganized and further improved, indicating that the current content does not effectively showcase the superiority of the method. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the exact issues or how to address them. Without additional information or guidance, the claim is not fully verifiable, aligning with a score of 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a need for reorganization and improvement in the experimental part of the paper. It highlights that the current content in the main text does not effectively showcase the superiority of the method, suggesting that the experimental section should be reorganized to better emphasize this aspect. However, the comment lacks specific guidance or suggestions on how to reorganize the content or what specific improvements should be made. While it points out a critical area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear direction but lacks depth and actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practical implementation and testing of recognition lists, particularly in the context of old vs. new judgments. It questions how an exhaustive list could be effectively implemented and how concrete predictions could be tested with simulations. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or what specific actions they should take to improve their draft. The action is implicit and vague, leaving the authors without clear direction on how to respond. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a concern about the implementation and testing of recognition lists, specifically questioning how an exhaustive list could be effectively implemented and how concrete predictions could be tested with simulations. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the implementation and testing of recognition lists, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the practical implementation and testing of recognition lists, specifically questioning how an exhaustive list could be effectively implemented and how concrete predictions could be tested with simulations. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that this is a significant issue. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the practical implementation and testing of recognition lists, particularly in the context of old vs. new judgments. It questions how an exhaustive list could be effectively implemented and how concrete predictions could be tested with simulations. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or what changes could be made to improve their draft. While it identifies a potential weakness, it does not provide actionable advice or detailed insights, making it somewhat helpful. The authors would need to infer the need for further clarification or discussion on this topic, which limits the comment's overall impact.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should consider using better meta-data embeddings for their zero-shot learning results on the CUB dataset. It provides a specific reference to a related work, \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016,\" which suggests that better meta-data embeddings are available. The comment also indicates that the authors should update their paper with this suggestion. This feedback is explicit and provides a clear action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the results of zero-shot learning on CUB dataset\" and \"Table 3 page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests considering better meta-data embeddings and provides a reference to a related work, \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016,\" which helps the authors understand the suggestion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the meta-data used in the zero-shot learning results on the CUB dataset are \"attribute,\" which is good for fair comparison. However, it suggests that better meta-data embeddings options are available and recommends exploring their performance. The comment provides a reference to a related work, \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016,\" which supports the suggestion. This provides a logical reasoning and specific reference, making the claim mostly verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific feedback on the results of zero-shot learning on the CUB dataset, noting that the meta-data used is \"attribute,\" which is good for fair comparison. However, it suggests that better meta-data embeddings options are available and recommends exploring their performance. The comment also references a related work, \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016,\" which provides context for the suggestion. This feedback is mostly helpful as it offers actionable insights and a reference for further exploration, guiding the authors to improve their work. However, it could be more comprehensive if it included a detailed discussion of the potential impact of using better meta-data embeddings or suggested specific experiments to evaluate this. Overall, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the reasonableness of the training time difference between the German and Law school datasets in the context of the Gerrymandering experiment compared to the Independent experiment. It also suggests that the main advantage of the proposed method is its computational time, and it recommends publishing the code. However, the comment does not provide explicit guidance on how to address the question or what specific actions the authors should take to improve their draft. The actions are implicit and vague, leaving the authors uncertain about how to respond or what changes to make. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the reasonableness of the training time difference between the German and Law school datasets in the context of the Gerrymandering experiment compared to the Independent experiment. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. While the comment is specific in its inquiry about the training time difference, the lack of grounding makes it challenging for the authors to understand the context and relevance of the question. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the reasonableness of the training time difference between the German and Law school datasets in the context of the Gerrymandering experiment compared to the Independent experiment. It also suggests that the main advantage of the proposed method is its computational time and recommends publishing the code. However, the comment lacks specific reasoning or evidence to support the claim that the training time difference is reasonable or that the code should be published. Without detailed justification or examples, the claim is difficult to verify, making it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the reasonableness of the training time difference between the German and Law school datasets in the context of the Gerrymandering experiment compared to the Independent experiment. It also suggests that the main advantage of the proposed method is its computational time and recommends publishing the code. However, the comment lacks specific guidance or detailed reasoning to support the claim, making it difficult for the authors to understand the basis for the question or how to address it. The feedback is somewhat helpful as it identifies an area for clarification but does not provide actionable steps or suggestions for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the strong assumptions made for the termination states of instructions, particularly in the general case where manual labeling of large datasets is expensive. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment identifies a potential problem but lacks guidance on how to resolve it or what changes might be necessary. As a result, the authors are left without a clear path to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the assumption for termination states of instructions, noting that it is strong and expensive to label data manually in the general case. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or figure that needs attention. While the comment is specific about the nature of the issue, the lack of grounding makes it challenging for the authors to fully understand and address the concern. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the assumption for termination states of instructions is strong and expensive to label data manually in the general case. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand the basis of the claim or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the assumptions made for the termination states of instructions, specifically noting that it is expensive to label data manually in the general case. This feedback highlights a practical concern that could impact the feasibility and applicability of the research. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or improve their draft. Without specific recommendations or examples, the authors may find it challenging to incorporate this feedback into their work. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not provide detailed guidance for action.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the nature of the contribution with respect to ECE_sweep. It suggests that the paper should be more explicit about the contribution, noting that it involves choosing the number of bins using data, which is essentially autotuning a hyperparameter. The reviewer expresses confusion about the paper's point until this clarification is provided. While the comment identifies a specific issue and suggests a way to address it, it does not provide explicit guidance on how to make the contribution clearer or how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the contribution in the paper. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the nature of the contribution with respect to ECE_sweep, specifically mentioning that it involves choosing the number of bins using data, which is autotuning a hyperparameter. This provides a clear reference point for the authors to understand the specific aspect of the contribution being discussed. However, the comment does not specify what needs to be addressed in this part, such as how the contribution differs from existing methods or how it should be presented. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not clearly describe the nature of the contribution with respect to ECE_sweep, specifically mentioning that it involves choosing the number of bins using data, which is essentially autotuning a hyperparameter. The reviewer suggests that the paper should be more explicit about this contribution. However, the comment lacks specific examples or detailed reasoning to support the claim that the contribution is not clearly described. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides a general observation but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the nature of the contribution with respect to ECE_sweep. It highlights that the contribution involves choosing the number of bins using data, which is essentially autotuning a hyperparameter. The reviewer expresses confusion about the paper's point until this clarification is provided, suggesting that the paper should be more upfront about its contribution. While the comment points out a specific area for improvement, it does not provide detailed guidance or suggestions on how to make the contribution clearer or more impactful. The feedback is somewhat helpful as it directs the authors to a specific area of concern, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the clarity of the term \"efficient proxy\" used in the paper. It suggests that the authors might be referring to a particular proxy or a family of efficient proxies, but the paper does not provide a clear definition or context. While the comment implies that the authors need to clarify this term, it does not explicitly instruct them to do so or provide guidance on how to address the issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the term. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the clarity of the term \"efficient proxy\" used in the paper, suggesting that it might refer to a particular proxy or a family of efficient proxies. However, the comment does not specify which part of the paper this issue is discussed, making it difficult for the authors to pinpoint the exact location. Additionally, the comment does not provide specific guidance on how to clarify the term or address the potential ambiguity. As a result, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the clarity of the term \"efficient proxy\" used in the paper, suggesting that it might refer to a particular proxy or a family of efficient proxies. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or explanation, the authors are left to interpret the ambiguity themselves, making the claim unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the clarity of the term \"efficient proxy\" used in the paper, suggesting that it might refer to a particular proxy or a family of efficient proxies. This raises a potential ambiguity that could affect the understanding of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify the term. Without actionable feedback or specific advice, the authors are left to interpret the ambiguity themselves, which limits the helpfulness of the comment. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point describes a specific combination of methods used in the paper, including stacking methods from Mirzasoleiman et al., 2020 and Group-learning setting, and then using DBSCAN for clustering. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this combination of methods or why it is being used. Without further clarification or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment describes a specific combination of methods used in the paper, including stacking methods from Mirzasoleiman et al., 2020 and Group-learning setting, and then using DBSCAN for clustering. However, it does not specify which part of the paper this combination is discussed in, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in detailing the methods used, it lacks grounding as it does not provide clear references to the paper sections. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point describes a specific combination of methods used in the paper, including stacking methods from Mirzasoleiman et al., 2020 and Group-learning setting, and then using DBSCAN for clustering. However, it does not provide any claim or suggestion that requires verification. The comment is purely descriptive and does not offer any critical feedback or reasoning that would help the authors understand why this combination of methods might be problematic or how it could be improved. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment describes a specific combination of methods used in the paper, including stacking methods from Mirzasoleiman et al., 2020 and Group-learning setting, and then using DBSCAN for clustering. However, it does not provide any critical feedback, suggestions, or reasoning that would help the authors understand why this combination of methods might be problematic or how it could be improved. The comment lacks actionable insights and does not offer any guidance on addressing the described approach. As a result, it is not helpful to the authors in improving their draft. Therefore, it should be rated as 1: Not Helpful at All.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses an opinion about the model's simplicity, suggesting that it is both a feature and a bug. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks actionable steps or concrete advice on how to improve the model or justify its complexity. As a result, the authors are left without a clear understanding of what changes are needed or how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the model's simplicity, suggesting that it is both a feature and a bug. However, it does not specify which part of the paper this observation pertains to, such as a particular section, table, or figure. Without this context, the authors cannot accurately identify where the issue lies or how to address it. The comment is not grounded, as it lacks specific references to the paper, making it difficult for the authors to understand the scope of the feedback. Therefore, this comment is not grounded and does not provide specific guidance, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses an opinion about the model being overly simple, suggesting it is both a feature and a bug. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses an opinion about the model being overly simple, suggesting that it is both a feature and a bug. However, it does not provide any specific feedback or suggestions on how the authors might address this issue or improve the model. The comment lacks actionable guidance, leaving the authors without a clear understanding of what changes are needed or how to proceed. As a result, the feedback is not helpful in terms of providing direction or improvement suggestions. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper to motivate the method. It also recommends including a rough example of run-times in the experiments to aid readers in applying the method. While the comment provides explicit actions\u2014mentioning the computational cost and including run-time examples\u2014it does not specify how to integrate these elements into the main paper or experiments. The actions are clear and concrete, but the lack of detailed guidance on implementation makes the comment somewhat actionable. Therefore, the comment aligns with a score of 4: Mostly Actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper to motivate the method and include a rough example of run-times in the experiments. However, it does not specify which part of the paper this should be included in, making it weakly grounded. The comment is specific in its suggestions regarding the inclusion of computational cost and run-time examples, which would help the authors improve their paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper to motivate the method and include a rough example of run-times in the experiments. This claim is somewhat verifiable as it provides a logical suggestion for improving the paper's clarity and motivation. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the paper by mentioning the negligible computational cost of CHR and suggesting the inclusion of a rough example of run-times in the experiments. This feedback is actionable and offers concrete guidance on how the authors can enhance the motivation and clarity of their work. By addressing these points, the authors can better motivate their method and provide readers with a clearer understanding of its practical implications. Therefore, the comment is mostly helpful, as it offers clear and actionable feedback that would significantly benefit the authors.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors for using the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. The reviewer suggests that this approach does not directly address the problem. However, the comment does not provide explicit guidance on how the authors should revise their approach to address the problem more directly. The action is implicit and vague, as it does not specify what changes need to be made to the method or how the authors should approach the problem differently. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the authors for using the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. However, it does not specify which part of the paper this critique refers to, such as a particular section or table. This makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its critique of the approach, the lack of grounding makes it challenging for the authors to address the issue effectively. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the authors for using the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. This critique suggests that the approach does not directly address the problem. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment critiques the authors for using the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. The reviewer suggests that this approach does not directly address the problem. However, the comment lacks specific guidance or suggestions on how the authors might improve their approach to better address the problem. While it identifies a potential issue, it does not provide actionable steps or alternative methods for the authors to consider. As a result, the comment is somewhat helpful, as it highlights a potential area for improvement but does not offer detailed guidance on how to address it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include baselines for code completion tasks, specifically mentioning Copilot as an example. It implies that the authors should compare their work with existing commercial code completion applications. However, the comment does not provide explicit guidance on how to implement this suggestion, such as which specific aspects of the comparison should be included or how the comparison should be conducted. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including baselines for code completion tasks, specifically mentioning Copilot as an example. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to compare with existing commercial code completion systems, but without a clear reference to a specific section or part of the paper, the authors may find it challenging to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include baselines for code completion tasks, specifically mentioning Copilot as an example. While the suggestion is logical and relevant to improving the paper, it lacks specific details or references to support the claim. The authors would need to infer the exact nature of the comparison and how it would benefit the paper. Therefore, the comment is somewhat verifiable, as it provides a clear direction but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting the inclusion of baselines for code completion tasks, such as Copilot. This feedback is actionable as it provides a clear direction for the authors to enhance their work by comparing their approach with existing commercial code completion systems. However, the comment could be more helpful if it offered additional guidance on how to conduct the comparison or what specific aspects of the comparison should be included. Overall, the comment is mostly helpful as it directs the authors towards a meaningful improvement but lacks some depth in terms of detailed suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the introduction, specifically the lack of clarity regarding what is being modelled in the second paragraph. While it points out that the authors may be assuming tumour growth, it does not provide explicit guidance on how to address this ambiguity. The comment suggests that the authors should clarify the modelling process, but it does not offer specific steps or examples on how to do so. As a result, the authors are left with a vague understanding of what action to take, making the comment somewhat actionable. Therefore, this comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the second paragraph of the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue: the lack of clarity regarding what is being modelled in the context of modelling curves, particularly the assumption of tumour growth. This provides the authors with a clear understanding of what needs to be addressed to improve the clarity of the introduction. Therefore, this comment is classified as fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the second paragraph of the introduction is unclear about what is being modelled, specifically mentioning tumour growth. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in the introduction, noting that the second paragraph discusses modelling curves but lacks clarity on what is being modelled, particularly the assumption of tumour growth. This feedback is somewhat helpful as it points out a potential area of confusion for the reader. However, the comment does not provide detailed suggestions or guidance on how the authors might address this issue, such as clarifying the modelling process or providing additional context. While it highlights a need for improvement, the lack of actionable advice limits its overall helpfulness. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions regarding the use of shifted-MNIST and the performance of the model and baselines on test samples from the observational (in) distribution. The first question asks why shift=0 is better than shift~ N ( 0 , \u03c3 2 ) , which implies that the authors should clarify the rationale behind this choice. The second question suggests showing performance on test samples from the observational (in) distribution, indicating that the authors should provide this information to better understand the model's performance. While the comment provides explicit questions that guide the authors to clarify and provide additional information, it lacks concrete guidance on how to address these questions or what specific actions to take. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two specific issues related to the use of shifted-MNIST and the performance of the model and baselines on test samples from the observational (in) distribution. It explicitly mentions \"shifted-MNIST\" and \"test samples from the observational (in) distribution,\" providing clear grounding for the parts of the paper being discussed. The comment is specific in its suggestions, as it requests clarification on the rationale behind the choice of shift values and the inclusion of performance metrics on test samples from the observational (in) distribution. This allows the authors to understand exactly what needs to be addressed and how to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two questions regarding the use of shifted-MNIST and the performance of the model and baselines on test samples from the observational (in) distribution. The first question asks why shift=0 is better than shift~ N ( 0 , \u03c3 2 ) , which implies that the authors should clarify the rationale behind this choice. The second question suggests showing the performance of the model and baselines on test samples from the observational (in) distribution, indicating that the authors should provide this information to better understand the model's performance. However, the comment does not provide any specific reasoning, examples, or references to support these claims, making it difficult for the authors to understand the basis for the questions. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises two important questions regarding the use of shifted-MNIST and the performance of the model and baselines on test samples from the observational (in) distribution. The first question asks why shift=0 is better than shift~ N ( 0 , \u03c3 2 ) , which implies that the authors should clarify the rationale behind this choice. The second question suggests showing the performance of the model and baselines on test samples from the observational (in) distribution, indicating that the authors should provide this information to better understand the model's performance. While the comment identifies areas for improvement, it lacks specific guidance on how to address these questions or what additional information would be beneficial. The feedback is somewhat helpful as it points out important aspects that need clarification and further analysis, but it could be more comprehensive with detailed suggestions or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should provide more explanation to clarify certain aspects, particularly regarding the \"expected\" nature of some elements. It also recommends discussing different optimization strategies and their corresponding results, specifically mentioning the impact of minimizing both inter and intra terms in Eq 3 or only the first term. While the comment provides explicit guidance on what needs to be discussed, it lacks concrete details on how to implement these suggestions or what specific aspects require clarification. The action is somewhat vague, as the authors are not given clear instructions on how to expand the discussion or what specific results to include. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should provide more explanation to clarify certain aspects, particularly regarding the \"expected\" nature of some elements. It also recommends discussing different optimization strategies and their corresponding results, specifically mentioning the impact of minimizing both inter and intra terms in Eq 3 or only minimizing the first term. However, the comment does not specify which part of the paper these suggestions pertain to, such as specific sections or figures. This makes it difficult for the authors to identify the exact areas that need improvement. While the comment is specific about the type of explanation and discussion required, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should provide more explanation to clarify certain aspects, particularly regarding the \"expected\" nature of some elements. It also recommends discussing different optimization strategies and their corresponding results, specifically mentioning the impact of minimizing both inter and intra terms in Eq 3 or only minimizing the first term. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the suggestions. The feedback is somewhat verifiable as it provides a general direction for improvement but lacks detailed reasoning or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a need for more explanation in the paper, particularly regarding the \"expected\" nature of certain elements. It also suggests discussing different optimization strategies and their corresponding results, specifically mentioning the impact of minimizing both inter and intra terms in Eq 3 or only minimizing the first term. This feedback is somewhat helpful as it provides a clear direction for improvement, encouraging the authors to expand on their discussion and provide more detailed explanations. However, the comment could be more helpful if it included specific examples or guidance on how to address these points. Overall, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests including a formal or intuitive definition of treewidth, which is central to the paper\\'s proofs. This provides a clear and explicit action for the authors to take, as they can directly incorporate this definition into their draft. The comment is specific in its suggestion, detailing exactly what needs to be added to improve the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including a formal or intuitive definition of treewidth, which is central to the paper\\'s proofs. However, it does not specify which part of the paper this definition should be included in, such as a specific section or paragraph. This lack of grounding makes it difficult for the authors to identify the exact location where the definition should be added. While the comment is specific in its suggestion, the absence of grounding information makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including a formal or intuitive definition of treewidth, which is central to the paper\\'s proofs. This is a clear and logical suggestion that provides a specific action for the authors to take. However, the comment does not provide any additional context, examples, or references to support the claim that this definition is necessary or beneficial. While the suggestion is logical and actionable, it lacks depth and specific guidance, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests including a formal or intuitive definition of treewidth, which is central to the paper\\'s proofs. This feedback is clear and actionable, as it provides a specific and logical suggestion for improvement. By adding this definition, the authors can enhance the clarity and comprehensibility of their paper, making it easier for readers to understand the theoretical foundations of their work. However, the comment could be more helpful if it provided additional context or examples of how this definition might be used in the proofs. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be expanded for greater depth. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how information redundancy is built into the Fill, Propagate, and Decode algorithms, specifically referencing a sentence in the paper. It does not provide explicit instructions or suggestions on how to address this question or improve the paper. The comment is vague and lacks concrete guidance, leaving the authors uncertain about what action to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about how information redundancy is built into the Fill, Propagate, and Decode algorithms, referencing a specific sentence in the paper. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its request for clarification but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about how information redundancy is built into the Fill, Propagate, and Decode algorithms, referencing a specific sentence in the paper. However, it does not provide any evidence, reasoning, or references to support the claim or question raised. Without additional context or justification, the authors are left without a clear understanding of the basis for the question, making it difficult to address or provide feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about how information redundancy is built into the Fill, Propagate, and Decode algorithms, referencing a specific sentence in the paper. However, it does not provide any suggestions or guidance on how to address this question or improve the paper. The comment lacks actionable feedback, leaving the authors without a clear understanding of what to do or how to enhance their work. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the necessity of the added complexity of using multiple INs at different speeds in the dynamics predictor. It suggests that the design choice is not ablated, and the authors should consider whether one IN would suffice. However, the comment does not provide explicit guidance on how to address this question or what actions the authors should take to clarify or resolve it. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the necessity of using multiple INs at different speeds in the dynamics predictor, suggesting that the design choice is not ablated. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact area of concern. While the comment is specific in questioning the design choice, the absence of explicit grounding makes it challenging for the authors to address the issue effectively. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the necessity of using multiple INs at different speeds in the dynamics predictor, suggesting that the design choice is not ablated. However, it does not provide any evidence, reasoning, or references to support the claim that this design choice is important or how it impacts the model. Without specific justification or examples, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the necessity of using multiple INs at different speeds in the dynamics predictor, suggesting that the design choice is not ablated. It prompts the authors to consider whether one IN would suffice, which is a relevant and important question for understanding the model's complexity and efficiency. However, the comment does not provide any guidance or suggestions on how to address this question or what experiments might be needed to substantiate the claim. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific observation about the experimental results, noting that the opponent's performance is not as good as expected because it does not aim to maximize the multi-agent payoff. However, it does not provide explicit or implicit actions for the authors to take in response to this observation. The comment lacks guidance on how the authors might address this issue or what changes could be made to the experiments. As a result, the authors are left without a clear understanding of what steps to follow to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the opponent's performance in the experiments, explaining why the opponent is not outperformed with respect to the multi-agent payoff. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the opponent's performance is not as good as expected because it does not aim to maximize the multi-agent payoff. The reviewer provides an example, stating that the opponent maximizes classical SE and AE. This reasoning is logical and provides a clear explanation of why the opponent's performance is not as expected. However, the comment lacks specific references or detailed examples to fully substantiate the claim. Therefore, the claim is mostly verifiable, as it is supported by logical reasoning but could benefit from additional evidence or references. The label aligns with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue in the experiments, noting that the opponent's performance is not as expected because it does not aim to maximize the multi-agent payoff. The reviewer provides a clear explanation, suggesting that the opponent maximizes classical SE and AE instead. This feedback is somewhat helpful as it highlights a potential area for improvement in the experimental design or analysis. However, it could be more helpful if it provided suggestions on how the authors might address this issue or what changes could be made to the experiments to better align with the expected outcomes. Overall, the comment offers some insight but lacks depth and actionable guidance, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or what steps they should consider to clarify the issue. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, it does not specify which part of the paper this statement is located in, making it difficult for the authors to pinpoint the exact issue. The comment is not grounded as it does not provide clear references or sections to address. Additionally, it does not specify what needs to be addressed or how the authors might clarify the confusion. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this confusion or clarify the statement. Without actionable feedback or detailed reasoning, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include experimental results of excluding the mixup technique from the proposed method to demonstrate its pure contribution. This provides a clear and explicit action for the authors to take, as they can directly apply this suggestion to their draft. The comment is specific in its request for additional experiments, which helps the authors understand exactly what needs to be done to strengthen their claims. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need for experimental results that exclude the mixup technique to demonstrate the pure contribution of the proposed method. This provides the authors with a clear understanding of what additional experiments are required to support their claims. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should include experimental results of excluding the mixup technique from the proposed method to demonstrate its pure contribution. This claim is somewhat verifiable as it provides a clear suggestion for an additional experiment that could strengthen the paper. However, it lacks specific examples or references to existing literature that could support the claim, making it somewhat verifiable. The authors would need to conduct additional experiments to substantiate this suggestion, which aligns with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors include experimental results of excluding the mixup technique from their proposed method. This is a clear and actionable suggestion that could help demonstrate the pure contribution of the proposed method. By providing this feedback, the reviewer offers a concrete way for the authors to strengthen their experimental results and claims. However, the comment could be more helpful if it provided additional guidance on how to conduct these experiments or what specific metrics to use. Overall, the comment is mostly helpful as it directs the authors towards a valuable improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific questions about the object detection based attention mechanism, asking whether it is performed on the image or a convolutional feature map and whether rescaling is involved. These questions are explicit and provide clear guidance on what the authors should clarify in their draft. The feedback is concrete, as it directly instructs the authors to address these specific aspects of their method. Therefore, the comment is highly actionable, as it provides explicit and detailed instructions for improvement.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises two specific questions about the object detection based attention mechanism, asking whether it is performed on the image or a convolutional feature map and whether rescaling is involved. This provides clear guidance on what aspects of the method need clarification. However, the comment does not explicitly mention a specific section or part of the paper where this clarification is needed, making it weakly grounded. The questions are specific and detailed, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two specific questions about the object detection based attention mechanism, asking whether it is performed on the image or a convolutional feature map and whether rescaling is involved. These questions are factual and require the authors to clarify their methodology. However, the comment does not provide any additional context, reasoning, or references to support the questions, making it difficult for the authors to understand the basis of the inquiry. As a result, the comment is considered borderline verifiable, as it lacks sufficient justification or evidence to fully substantiate the need for clarification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises two specific questions about the object detection based attention mechanism, asking whether it is performed on the image or a convolutional feature map and whether rescaling is involved. These questions are clear and actionable, providing the authors with specific areas to clarify in their draft. By addressing these questions, the authors can improve the clarity and completeness of their methodology description. However, the comment could be more helpful if it suggested specific ways to clarify these aspects or provided examples of how to present the information effectively. Overall, the feedback is mostly helpful as it identifies key areas for improvement and guides the authors toward enhancing their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence, specifically in the high-frequency range. It suggests that the authors may have overlooked this aspect or that it is not adequately analyzed. However, the comment does not provide explicit guidance on what needs to be addressed or how to improve the analysis. The authors are left to infer that they should either provide a more detailed analysis or address the question raised. This lack of explicit action or guidance makes the comment somewhat actionable, as it points out a potential area for improvement but does not offer concrete steps for the authors to take. Therefore, the comment aligns with a score of 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence, specifically in the high-frequency range. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its focus on the theoretical support, the absence of explicit grounding makes it challenging for the authors to understand which part of the paper to address. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence, specifically in the high-frequency range. It suggests that the authors may have overlooked this aspect or that it is not adequately analyzed. However, the comment does not provide any specific evidence, examples, or references to support the claim that this theoretical support is essential. Without additional context or justification, the claim remains somewhat verifiable, as it lacks sufficient evidence to fully substantiate the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence, specifically in the high-frequency range. It suggests that the authors may have overlooked this aspect or that it is not adequately analyzed. This feedback highlights a potential gap in the paper's theoretical foundation, which is crucial for understanding the merits of Fourier features. However, the comment does not provide specific guidance on how to address this gap or what additional analysis might be necessary. While it identifies an important area for improvement, the lack of actionable suggestions limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether an error in the initial calibration steps of the algorithm might explain the speed disparities observed between the RSPs and FDs. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what steps they should take to investigate or correct the error. The comment lacks concrete guidance on how to proceed, leaving the authors without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to \"Section III of \u201cRecognition and Velocity Computation of Large Moving Objects in Images\u201d,\" which provides full grounding as the authors can accurately identify the section being addressed. It also specifies the issue by questioning whether an error in the initial calibration steps might explain the speed disparities observed between the RSPs and FDs. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about potential errors in the initial calibration steps of the algorithm, which might explain the observed speed disparities between RSPs and FDs. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the reviewer's assertion remains speculative and lacks verifiability. Therefore, the comment is classified as unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about potential errors in the initial calibration steps of the algorithm, which might explain the observed speed disparities between RSPs and FDs. This feedback is somewhat helpful as it identifies a potential issue that could impact the results, prompting the authors to investigate and address it. However, the comment lacks specific guidance on how to identify or correct the error, making it incomplete. The authors would need to conduct further analysis or seek additional information to fully address the concern. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the claim that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, it does not provide any explicit or implicit suggestions or actions for the authors to take to address this concern. The comment lacks guidance on how the authors might address this issue or what changes could be made to their draft to clarify or support their claims. As a result, the authors are left without any actionable feedback, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the relevant section. It also lacks specificity, as it does not detail what needs to be addressed or how the authors should respond to the claim. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without supporting evidence, the authors are left without a basis to understand or address the claim. Therefore, the comment is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the claim that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, the comment does not provide any specific feedback or suggestions on how the authors might address this concern or clarify their claims. It lacks actionable guidance, making it difficult for the authors to improve their draft based on this feedback. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of non-parametric emission distributions on inference in HMMs, specifically focusing on common inference tasks. It asks which tasks can be computed exactly or approximately with an NP-SPEC-HMM. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks concrete actions or detailed feedback, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the focus on learning HMMs with non-parametric emission distributions, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the impact of these distributions on inference and asks about common inference tasks in discrete HMMs, such as filtering, smoothing, and marginal observation likelihood. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the impact of non-parametric emission distributions on inference in HMMs, specifically asking which common inference tasks can be computed exactly or approximately with an NP-SPEC-HMM. While the question is clear and directly relates to the paper's focus, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The comment lacks depth and does not offer any guidance or justification for the question posed. Therefore, it is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the impact of non-parametric emission distributions on inference in HMMs, specifically asking which common inference tasks can be computed exactly or approximately with an NP-SPEC-HMM. This question highlights a potential area for further exploration and clarification in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a relevant area for discussion, it lacks actionable feedback, making it somewhat helpful. The authors would need to infer how to address the question, which limits the comment's usefulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind considering only 10 out of 120 datasets for comparison, specifically asking why the authors did not compare batch and greedy methods in the remaining 110 datasets. While the comment implies an action\u2014namely, to provide a justification for the selection of datasets\u2014it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to explain their dataset selection process. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the rationale behind considering only 10 out of 120 datasets for comparison, specifically asking why the authors did not compare batch and greedy methods in the remaining 110 datasets. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification regarding the dataset selection process, but without explicit grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind considering only 10 out of 120 datasets for comparison, specifically asking why the authors did not compare batch and greedy methods in the remaining 110 datasets. However, the comment does not provide any justification or reasoning for this choice, nor does it offer any references or examples to support the claim. Without additional context or explanation, the authors are left to infer the reasoning behind the dataset selection, making the claim unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind considering only 10 out of 120 datasets for comparison, specifically asking why the authors did not compare batch and greedy methods in the remaining 110 datasets. This question highlights a potential gap in the analysis or methodology, prompting the authors to provide a clearer explanation of their dataset selection process. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve their analysis. While it identifies a potential area for improvement, it does not provide specific steps or insights that would help the authors enhance their work. Therefore, the comment is somewhat helpful, as it points out a potential area for clarification but does not offer detailed guidance on how to address it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the necessity of the low-rank factorization in the introduction, given that the main result focuses on polytopes. It suggests that if the result has implications for low-rank matrix factorization, these should be explicitly discussed. However, the comment does not provide explicit guidance on how the authors should address this point or what specific aspects of the introduction need revision. The action is implicit and somewhat vague, as the authors are left to infer the necessary changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the motivation in the introduction, specifically questioning the necessity of low-rank factorization given the focus on polytopes. However, it does not specify which part of the introduction this question pertains to, making it weakly grounded. The comment is specific in suggesting that if the result has implications for low-rank matrix factorization, these should be explicitly discussed. This provides clear guidance on what needs to be addressed, but the lack of explicit grounding makes it weakly grounded and specific. Therefore, the comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the necessity of the low-rank factorization in the introduction, given that the main result focuses on polytopes. It suggests that if the result has implications for low-rank matrix factorization, these should be explicitly discussed. However, the comment does not provide any specific reasoning, examples, or references to support why the low-rank factorization is considered unnecessary or how it relates to the main result. Without these elements, the claim is difficult to verify, making the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the necessity of the low-rank factorization in the introduction, given that the main result focuses on polytopes. It suggests that if the result has implications for low-rank matrix factorization, these should be explicitly discussed. This feedback is somewhat helpful as it points out a potential area for clarification and expansion, but it lacks depth and specificity. The authors are left to infer the exact nature of the implications and how to address them, which limits the comment's usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is incremental with respect to [31], as it adapts the existing architecture for the multi-person case and produces identity/tag heatmaps with joint heatmaps. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the draft or what specific changes are needed to make it more substantial. Without actionable feedback, the authors are left without a clear path to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"with respect to [31]\", allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors are adapting and producing, namely \"identity/tag heatmaps with the joint heatmaps.\" This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is \"rather incremental\" with respect to [31], as it adapts the existing architecture for the multi-person case and produces identity/tag heatmaps with joint heatmaps. However, the comment lacks specific evidence or references to support this claim. Without detailed reasoning or examples, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered borderline verifiable, as it provides a subjective assessment but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, suggesting that it is incremental with respect to [31]. The authors adapt an existing architecture for a multi-person case, producing identity/tag heatmaps with joint heatmaps. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the paper's contribution. While it highlights a concern, it lacks actionable feedback that would help the authors enhance their work. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not offer detailed guidance on how to achieve it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point mentions that an alternating direction method is used to solve a min-min problem but does not specify which method is being referred to. This lack of specificity makes it difficult for the authors to understand which method is being discussed and how it relates to the min-min problem. Without this information, the authors are left without a clear action to take, as they cannot identify the specific method or understand its relevance. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is referring to, such as a particular section or figure. It mentions an alternating direction method used to solve a min-min problem but does not provide any context or detail about where this method is discussed or how it relates to the paper. This lack of grounding makes it difficult for the authors to understand the relevance of the comment and what part of the paper needs attention. Therefore, the comment is not grounded and does not provide specific guidance, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a factual statement about the use of an alternating direction method to solve a min-min problem. It does not contain any subjective opinions, suggestions, or claims that require verification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is brief and lacks specificity, as it only mentions that an alternating direction method is used to solve a min-min problem without specifying which method is being referred to. This lack of detail makes it difficult for the authors to understand the context or relevance of the comment. Without additional information, the authors are left without actionable feedback on how to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the effectiveness of lower bound double q-learning, specifically questioning its performance in the MsPacman environment of Figure 2, where it shows a slight performance decrease compared to Clipped DDQN. It also notes that the algorithm converges to the same solutions in environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone, and suggests that it overestimates the true maximum value. While the comment identifies specific areas of concern, it does not provide explicit guidance on how the authors should address these issues or what changes might be necessary. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the effectiveness of lower bound double q-learning, specifically mentioning the MsPacman environment in Figure 2 and noting a slight performance decrease compared to Clipped DDQN. It also highlights convergence to the same solutions in other environments and suggests that the algorithm overestimates the true maximum value. However, the comment does not specify which part of the paper discusses these issues or environments, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issues raised, the lack of grounding makes it challenging for the authors to fully understand and address the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the effectiveness of lower bound double q-learning, specifically questioning its performance in the MsPacman environment of Figure 2, where it shows a slight performance decrease compared to Clipped DDQN. It also notes that the algorithm converges to the same solutions in environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone, and suggests that it overestimates the true maximum value. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence weakens the verifiability of the claim, as the authors may struggle to address the concerns effectively. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises concerns about the effectiveness of lower bound double q-learning, specifically questioning its performance in the MsPacman environment of Figure 2, where it shows a slight performance decrease compared to Clipped DDQN. It also notes that the algorithm converges to the same solutions in other environments, such as WizardOfWor, Zaxxon RoadRunner, and BattleZone, and suggests that it overestimates the true maximum value. While the comment identifies specific areas of concern, it lacks detailed guidance on how the authors might address these issues or what changes could be made to improve the algorithm's performance. The feedback is somewhat helpful as it points out potential weaknesses, but it could be more actionable with additional suggestions or recommendations. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda is small, referencing figures 3 and 4. It suggests that the authors should clarify why the performance is worse and why it approaches from below rather than above. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the draft. The action is implicit, as the authors need to infer that they should clarify the performance discrepancy and provide an explanation. While the action is somewhat vague, it is clear that the authors need to address this issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig.3-4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance of DNN+MMA compared to vanilla DNN when lambda is small, and it questions the expected behavior of the performance. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda is small, referencing figures 3 and 4. It suggests that the authors should clarify why the performance is worse and why it approaches from below rather than above. However, the comment does not provide any specific reasoning, examples, or references to support the claim that the performance is worse or why it approaches from below. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the performance of DNN+MMA compared to vanilla DNN when lambda is small, referencing figures 3 and 4. It points out that the performance is worse and questions why it approaches from below rather than above, which is unexpected. This feedback highlights a potential area of confusion or a need for clarification in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their results. While it identifies a specific area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap in the paper by noting that it does not compare the results with some earlier research work from 2020. While the authors have explained their reasons for not comparing with state-of-the-art systems, they have compared their results with earlier systems that have worse performance, such as Taghipour and Ng (2016). However, the comment does not provide explicit guidance on how the authors should address this issue or what specific comparisons would be beneficial. The action is implicit and somewhat vague, as it leaves the authors to infer the need for additional comparisons and the specific areas where they should focus. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison of results with earlier research work from 2020, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by highlighting the lack of comparison with state-of-the-art systems and suggesting comparisons with earlier systems like Taghipour and Ng (2016). This provides clear guidance on what aspects of the paper require attention. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not compare the results with some earlier research work from 2020. While the authors have explained their reasons for not comparing with state-of-the-art systems, they have compared their results with earlier systems that have worse performance, such as Taghipour and Ng (2016). However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. It does not provide a clear justification for why the comparison with earlier systems is insufficient or how it impacts the paper's conclusions. As a result, the claim is somewhat verifiable, as it is based on the authors' explanation but lacks comprehensive evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap in the paper by noting the absence of comparisons with earlier research work from 2020. While the authors have explained their reasons for not comparing with state-of-the-art systems, the comment highlights the need for such comparisons to provide a more comprehensive evaluation of their work. However, the feedback lacks specific suggestions or guidance on which earlier systems should be compared or how these comparisons would enhance the paper's impact. The comment is somewhat helpful as it points out an important area for improvement but does not provide detailed actionable advice. Therefore, it aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should elaborate on the conditions under which Hoeffding\\'s bound holds, particularly in the context of stochastic algorithms. It implies that the current explanation is insufficient and that the authors should provide more detail to clarify this point. The action is explicit, as it directly instructs the authors to elaborate on the conditions for Hoeffding\\'s inequality to hold. However, the comment lacks specific guidance on how to elaborate, such as suggesting additional details or examples. Therefore, the action is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, namely lines 124-125. This allows the authors to accurately identify the section being discussed. The comment is also specific because it provides a clear request for elaboration on the conditions under which Hoeffding\\'s bound holds, particularly in the context of stochastic algorithms. This guidance is detailed and specific, allowing the authors to understand exactly what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should elaborate on the conditions under which Hoeffding\\'s bound holds, particularly in the context of stochastic algorithms. The comment provides a logical reasoning by explaining that the bound holds under specific conditions, such as independent samples, and that stochastic algorithms further guarantee its validity. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would benefit from additional details or examples to fully understand and address the point. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area in the paper where the authors could provide more elaboration, particularly regarding the conditions under which Hoeffding\\'s bound holds. It suggests that the authors should elaborate on how stochastic algorithms guarantee the validity of the inequality. This feedback is clear and actionable, as it provides a specific direction for improvement. However, the comment could be more helpful if it offered additional guidance on what kind of elaboration would be beneficial or suggested specific areas where the authors could expand their discussion. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement but could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding an optimization-based meta-learning approach, such as MAML or implicit-MAML, to Table-1. While it implies that this addition would be beneficial, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the table would benefit from such an addition. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to incorporate the suggested approach. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding an optimization-based meta-learning approach, such as MAML or implicit-MAML, to Table-1. However, it does not specify which part of Table-1 would benefit from this addition or what specific issues the authors are addressing. The comment lacks grounding as it does not provide clear guidance on which section or aspect of the paper needs improvement. It is also specific in suggesting a particular approach, but without context, it is difficult for the authors to understand how to apply this suggestion. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding an optimization-based meta-learning approach, such as MAML or implicit-MAML, to Table-1. However, it does not provide any justification or reasoning for why this addition would be beneficial or how it would improve the paper. Without specific examples or references, the claim lacks support and is therefore unverifiable. The comment is purely speculative and does not offer any actionable guidance for the authors to follow.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding an optimization-based meta-learning approach, such as MAML or implicit-MAML, to Table-1. This feedback is somewhat helpful as it points out a potential area for improvement by suggesting a specific technique that could enhance the paper. However, the comment lacks depth and does not provide detailed reasoning or guidance on why this addition would be beneficial or how it would impact the overall contribution of the paper. The authors are left to infer the exact steps needed to incorporate this suggestion, which limits the comment's helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point on page 1 suggests that the term \"causal mechanisms\" should be used carefully, as it is different from a temporal relationship. However, it does not provide explicit guidance on how the authors should revise the text to address this concern. The comment implies that the authors need to clarify their use of the term, but it lacks specific instructions or examples of how to do so. As a result, the authors are left without a clear understanding of what changes are needed to align with the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term \"causal mechanisms,\" recommending that the authors use the terms carefully to distinguish them from temporal relationships. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point on page 1 suggests that the term \"causal mechanisms\" should be used carefully, as it is different from a temporal relationship. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment on page 1 points out a potential issue with the use of the term \"causal mechanisms,\" suggesting that it should be used carefully as it is different from a temporal relationship. This feedback is clear and identifies a specific area for improvement in the paper. However, it lacks detailed guidance on how the authors should revise the text to address this concern. While it provides a starting point for the authors to consider, it does not offer comprehensive suggestions or examples of how to clarify the use of the term. Therefore, the comment is somewhat helpful, as it highlights an important aspect of the paper that needs attention but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a discussion of how their results relate to the lower bounds on kernel learning using low-rank approximation, as discussed in the paper \"On the Complexity of Learning with Kernels\". However, the comment does not provide explicit guidance on how to incorporate this discussion into the draft or what specific aspects of the results should be addressed. The action is implicit, as the authors need to infer that they should add a discussion related to the mentioned paper. While the suggestion is concrete in terms of the topic, the lack of explicit guidance on how to implement it makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should include a discussion of how their results relate to the lower bounds on kernel learning using low-rank approximation, as discussed in the paper \"On the Complexity of Learning with Kernels\". However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. It is specific in that it clearly identifies the area where the discussion should be added, but the lack of grounding makes it difficult for the authors to pinpoint the exact section. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include a discussion of how their results relate to the lower bounds on kernel learning using low-rank approximation, as discussed in the paper \"On the Complexity of Learning with Kernels\". However, the comment does not provide any specific reasoning, examples, or references to support why this discussion is necessary or how it would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include a discussion of how their results relate to the lower bounds on kernel learning using low-rank approximation, as discussed in the paper \"On the Complexity of Learning with Kernels\". This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their draft by connecting their findings to existing research. However, the comment could be more helpful if it offered additional guidance on how to integrate this discussion into the paper or what specific aspects of the results should be addressed. Overall, the comment is mostly helpful, as it provides a valuable suggestion for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment questions the novelty of using PCA to reduce the interaction count and suggests that the significance of the paper's results is unclear. It also provides a rationale for why PCA might be intuitive and references a paper to support the claim that certain assumptions are met. However, the comment does not explicitly instruct the authors to address these points or provide specific guidance on how to improve the paper. The action is implicit, as the authors need to infer that they should discuss the novelty and significance of their results and ensure that the assumptions of PCA are well-justified. The comment is somewhat actionable as it provides a direction for improvement but lacks concrete details on how to implement it. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of using PCA to reduce the interaction count and questions the significance of the paper's results. It provides a rationale for why PCA might be intuitive and references a specific paper to support the claim that certain assumptions are met. However, the comment does not explicitly mention which part of the paper discusses the use of PCA or the significance of the results, making it weakly grounded. The comment is specific in detailing the issue with the novelty and significance of the results, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the incremental nature of using PCA to reduce the interaction count and questions the clarity of the paper's results. It provides a rationale for why PCA might be intuitive, referencing a specific paper to support the claim that certain assumptions are met. However, the comment lacks detailed examples or specific references to substantiate the claim fully. While the reasoning is logical, the absence of comprehensive evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the novelty of using PCA to reduce the interaction count and questions the clarity of the paper's results. It provides a rationale for why PCA might be intuitive and references a specific paper to support the claim that certain assumptions are met. However, the comment lacks detailed guidance on how the authors might address these issues or improve the significance of their results. While it identifies a potential weakness, it does not offer specific suggestions or actionable steps for the authors to take, making it somewhat helpful. The feedback is clear but could be more comprehensive to fully assist the authors in improving their draft.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the use of few-shot RC models in the paper, suggesting that they are not state-of-the-art and asks for a comparison with relation extraction/generation models in few-shot settings. While the comment identifies a potential issue with the choice of models, it does not provide explicit guidance on how the authors should address this concern or what specific changes might be necessary. The action is implicit, as the authors would need to infer that they should consider using more advanced models or compare their performance with relation extraction/generation models. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the use of few-shot RC models in the paper, suggesting that they are not state-of-the-art and requests a comparison with relation extraction/generation models in few-shot settings. However, the comment does not specify which part of the paper discusses the choice of models or where the authors should compare their performance. This lack of grounding makes it difficult for the authors to identify the exact section or part of the paper that needs attention. While the comment is specific in its request for comparison, the absence of explicit references or sections makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of few-shot RC models in the paper, suggesting that they are not state-of-the-art and requests a comparison with relation extraction/generation models in few-shot settings. The comment provides specific references to support the claim that the models used are not state-of-the-art, which helps the authors understand the basis for the critique. However, the request for a comparison with relation extraction/generation models lacks detailed guidance or examples, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the choice of few-shot RC models used in the paper, suggesting that they are not state-of-the-art. It also requests a comparison of the performance of these models with relation extraction/generation models in few-shot settings. This feedback is valuable as it highlights a gap in the paper's analysis and provides a direction for further investigation. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might address this issue or what additional experiments could be conducted. Overall, the comment is somewhat helpful, as it points out an area for improvement but lacks detailed actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide results for the discussion of using sequential MCB vs a single MCT layers for the decision head. However, it does not specify how the authors should present these results or what aspects of the results are important to highlight. The comment implies that the authors should include results, but it lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the discussion of using sequential MCB vs a single MCT layers for the decision head, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests more information about what was observed in this discussion, indicating that the authors need to provide results or detailed observations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the discussion of using sequential MCB vs a single MCT layers for the decision head, noting that no results were shown. However, it does not provide any specific reasoning, examples, or references to support why this observation is important or how it impacts the paper. The comment lacks detailed justification or context, making it difficult for the authors to understand the significance of the question. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that requires further clarification, namely the discussion of using sequential MCB versus a single MCT layer for the decision head. It notes that no results were shown, which is a significant gap in the analysis. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what results they should include. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a critical omission but does not offer concrete suggestions for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several minor language issues in the paper, such as \"we typically considers\" in the context of (7), \"two permutation\" in the context of Theorem 1, and \"until converge\" in the context of (14). It also suggests that the authors should proofread the paper to fix all language problems. While the comment identifies specific instances of language issues, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The action is implicit, as the authors need to infer that they should correct the language and proofread the paper. However, the lack of concrete instructions on how to correct the language makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific instances of language issues in the paper, such as \"we typically considers\" in the context of (7), \"two permutation\" in the context of Theorem 1, and \"until converge\" in the context of (14). This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the exact language issues that need to be corrected. However, it does not provide any suggestions or guidance on how to address these issues, which limits its overall impact. Therefore, this comment is fully grounded and specific, but it lacks actionable guidance, making it somewhat helpful.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of minor comments on language usage, such as \"we typically considers\" in the context of (7), \"two permutation\" in the context of Theorem 1, and \"until converge\" in the context of (14). These comments are factual observations about the language used in the paper. However, they do not contain any subjective opinions, suggestions, or judgments that require verification. Therefore, the comment is classified as \"No Claim\" as it does not provide any claims or assertions that need to be substantiated.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies several minor language issues in the paper, such as \"we typically considers\" in the context of (7), \"two permutation\" in the context of Theorem 1, and \"until converge\" in the context of (14). It also suggests that the authors should proofread the paper to fix all language problems. While the comment points out specific instances of language issues, it lacks detailed guidance on how to address these problems or what specific changes should be made. The feedback is somewhat helpful as it provides a clear direction for improvement, but it could be more comprehensive if it offered more detailed suggestions or examples of how to correct the language. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of 20 distribution sets and suggests exploring the impact of using fewer sets. While it implies that the authors should consider this aspect, it does not provide explicit guidance on how to control the number of distribution sets or what specific actions should be taken. The comment is somewhat vague, as it leaves the authors to infer the need for further exploration and experimentation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of 20 distribution sets and suggests exploring the impact of using fewer sets. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact section they need to address. While the comment is specific in its request for clarification and exploration, the lack of grounding makes it challenging for the authors to understand the context. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of 20 distribution sets and suggests exploring the impact of using fewer sets. However, it does not provide any specific reasoning, examples, or references to support why this choice is unclear or problematic. The comment lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of 20 distribution sets and suggests exploring the impact of using fewer sets. This feedback is somewhat helpful as it points out a potential area for further investigation and experimentation. However, it lacks depth and does not provide specific guidance or suggestions on how the authors might approach this exploration. The comment could be more helpful if it offered actionable advice or examples of how to conduct the analysis. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the evaluative framework is somewhat limited in scope, as it only considers three Question-Answering tasks and two language models. The comment expresses reservations about the method's broader applicability, particularly regarding its potential to generalize to other reasoning or generation tasks or more advanced models like vicunna or alpaca. However, the comment does not provide explicit guidance on how the authors might address these limitations or expand the framework. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps to improve the framework. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the evaluative framework's limited scope, specifically mentioning the consideration of only three Question-Answering tasks and two language models. This provides some grounding as the authors can infer the part of the paper being addressed, although it is not explicitly mentioned. The comment is specific in detailing the limitations of the framework, suggesting that it may not be applicable to other reasoning or generation tasks or more advanced models like vicunna or alpaca. This specificity is clear, as it specifies the areas where the framework's scope is limited. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluative framework is somewhat limited in scope, as it only considers three Question-Answering tasks and two language models. This claim is somewhat verifiable because it provides a specific example of the limited scope, but it lacks detailed reasoning or references to support the claim fully. The authors could benefit from additional context or examples to better understand the limitations of the framework. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the scope of the evaluative framework, noting that it is restricted to only three Question-Answering tasks and two language models. This observation raises concerns about the method's broader applicability and suggests that it may not be generalizable to other reasoning or generation tasks or more advanced models like vicunna or alpaca. While the comment highlights a potential area for improvement, it does not provide specific guidance or suggestions on how the authors might address these limitations or expand the framework. The feedback is somewhat helpful as it points out a critical issue that needs attention, but it lacks actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the perplexity experiments should be conducted using transformer-based language models, which are more current and relevant to the field. It provides a clear and explicit action for the authors to take, namely to replace the current models with transformer-based ones. This action is also concrete, as it specifies the exact models that should be used. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the perplexity experiments should be conducted using transformer-based language models, which are more current and relevant to the field. However, it does not specify which part of the paper discusses the perplexity experiments or which section should be revised. This makes it difficult for the authors to identify the exact part of the paper that needs to be addressed. While the comment is specific about the type of models to use, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the perplexity experiments should be conducted using transformer-based language models, which are more current and relevant to the field. This claim is somewhat verifiable as it provides a logical reasoning for why transformer-based models are more appropriate, aligning with current NLP trends. However, it lacks specific references or examples to fully substantiate the claim, which could make it partially verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the perplexity experiments, noting that they are conducted on obsolete language models that are rarely used in current NLP research. The comment suggests that the authors should consider using transformer-based language models, which are more relevant and widely adopted in the field. This feedback is clear and actionable, providing a specific direction for improvement. By recommending the use of more current models, the comment helps the authors align their work with contemporary trends and enhance its relevance. However, it could be more helpful if it included additional suggestions or considerations for the experiments. Overall, the comment is mostly helpful, as it provides a clear and actionable recommendation for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the estimation of mu, which is described as the proportion of missing observations. However, it does not provide any explicit or implicit suggestions on how to address this issue or improve the estimation process. The comment lacks concrete guidance on what needs to be done to clarify or improve the estimation of mu. As a result, the authors are left without a clear understanding of how to respond to this feedback, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the estimation of mu, which is described as the proportion of missing observations. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or context. The comment is vague and does not provide specific guidance on how to address the issue of misestimation. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the estimation of mu, which is described as the proportion of missing observations. However, it does not provide any specific reasoning, examples, or references to support why this estimation is unclear or problematic. The comment lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the concern. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the estimation of mu, which is described as the proportion of missing observations. However, it does not provide any specific guidance or suggestions on how to address this issue or improve the estimation process. The comment lacks depth and actionable advice, leaving the authors without a clear understanding of how to respond or enhance their work. Therefore, the comment is barely helpful, as it does not offer substantial insights or constructive feedback to the authors.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests a specific way to present the sensitivity of the performance to initialization by varying the distance of the initialization matrix M^0 from the ground-truth matrix M^*. It provides a clear and concrete action for the authors to take, which is to include this analysis in their draft. The comment is explicit and provides detailed guidance on how to implement the suggested action, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests a specific way to present the sensitivity of performance to initialization by varying the distance of the initialization matrix M^0 from the ground-truth matrix M^*. It provides a clear and detailed explanation of how this analysis should be conducted, including the range of distances to be considered and the expected impact on mean error and variance. However, it does not explicitly mention which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in detailing the proposed analysis, but the lack of explicit grounding makes it weakly grounded and specific. Therefore, it aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests a specific way to present the sensitivity of performance to initialization by varying the distance of the initialization matrix M^0 from the ground-truth matrix M^*. It provides a clear and detailed explanation of how this analysis should be conducted, including the range of distances to be considered and the expected impact on mean error and variance. However, it does not offer any references or examples to support the claim that this analysis would be beneficial or how it aligns with existing literature. The lack of supporting evidence makes the claim somewhat verifiable, as it provides a logical suggestion but lacks depth and justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the presentation of the paper by analyzing the sensitivity of performance to initialization. It proposes a method to vary the distance of the initialization matrix M^0 from the ground-truth matrix M^* and reports the performance accordingly. This feedback is actionable and offers a clear direction for the authors to enhance their draft by including this analysis. However, the comment could be more helpful if it provided additional guidance on how to implement this suggestion or discussed the expected outcomes in more detail. Overall, the comment is mostly helpful as it directs the authors towards a specific improvement, but it could be more comprehensive with additional details or examples. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper only provides bounds in expectation and recommends exploring the possibility of obtaining high-probability bounds, similar to those used in the experiments. It also suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to implement these suggestions. The action is implicit, as the authors can infer that they need to explore high-probability bounds and add robustness measures. However, the comment lacks concrete guidance on how to achieve these improvements, such as specific methods or techniques to use. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of only providing bounds in expectation and suggests exploring high-probability bounds, similar to those used in the experiments. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific, as it provides clear suggestions for improvement, such as using ensemble methods and adding measures of robustness like error bars or standard deviation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that only bounds in expectation are provided and suggests exploring high-probability bounds, similar to those used in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim about the current bounds. The authors would need to infer the need for high-probability bounds and robustness measures, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the paper only provides bounds in expectation and recommends exploring the possibility of obtaining high-probability bounds, similar to those used in the experiments. It also suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is clear and actionable, providing the authors with specific directions for enhancing the rigor and comprehensiveness of their work. By addressing these suggestions, the authors can significantly improve the quality and impact of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the results are less impressive and recommends evaluating them from more aspects, such as actual latency on the target device, memory consumption during inference, and actual network size. However, it does not provide explicit guidance on how to conduct this additional evaluation or what specific metrics should be used. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve their results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the areas where the results should be evaluated, such as actual latency on the target device, memory consumption during inference, and actual network size. This provides clear guidance for the authors to focus on specific aspects of their results. The comment is also specific, as it suggests evaluating the results from these additional perspectives to enhance their impressiveness. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the results are less impressive and recommends evaluating them from additional aspects, such as actual latency on the target device, memory consumption during inference, and actual network size. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors may need to infer the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the results section, suggesting that the findings are less impressive and could be strengthened by evaluating them from additional aspects. It specifically mentions the importance of considering actual latency on the target device, memory consumption during inference, and actual network size. This feedback is somewhat helpful as it provides a direction for improvement, but it lacks depth and specificity. The authors are left to infer the exact steps needed to enhance their results, which limits the comment's impact. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the paper's motivation of \"diversity,\" noting that the word is in the title but the model does not explicitly enforce it. The reviewer expresses disappointment that the diversity term is not incorporated into the model, despite the initial excitement. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the model to explicitly enforce diversity. The authors are left without guidance on how to proceed, making the comment unactionable. Therefore, this comment is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the title of the paper, which includes the word \"diversity.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the concern: the paper motivates \"diversity\" extensively but does not enforce it explicitly in the model, leading to a disappointment. This provides a clear direction for the authors to address the issue. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses a concern about the paper's motivation of \"diversity,\" noting that the word is in the title but the model does not explicitly enforce it. The reviewer expresses disappointment that the diversity term is not incorporated into the model, despite the initial excitement. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the model does not enforce diversity explicitly. Without additional context or evidence, the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment highlights a significant concern regarding the paper's motivation of 'diversity,' noting that the word is present in the title but the model does not explicitly enforce it. The reviewer expresses disappointment with this discrepancy, which suggests that the authors may have missed an opportunity to incorporate diversity into their model. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their model to explicitly enforce diversity. While it identifies a potential area for improvement, the feedback is somewhat limited in its actionable value, making it somewhat helpful. Therefore, the comment aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any guidance on what these missing experiments should include or how they should be conducted. The authors are left without any actionable steps to take, as they do not know what additional experiments to perform or how to address the missing ones. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments are intended to address or how they relate to the overall content. The authors cannot confidently determine which sections or parts of the paper need additional experiments. While the comment is specific about the type of experiments missing, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any justification or reasoning for why these experiments are missing or how their absence impacts the paper. Without additional context or explanation, the authors are left without a clear understanding of why these experiments are important or how they should be addressed. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where experiments are missing, namely contrastive learning and adversarial learning. This feedback is clear and actionable, as it provides the authors with a specific direction to improve their draft by including these additional experiments. However, the comment could be more helpful if it suggested specific ways to conduct these experiments or how they would enhance the paper's contribution. Despite this, the feedback is mostly helpful as it directs the authors towards a clear area for improvement, allowing them to enhance the comprehensiveness of their work. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that while FIDs are still used, there are flaws associated with them and the Inception network. It recommends using DinoV2 Frechet Distances for comparisons, in addition to FID. However, the comment does not provide explicit guidance on how the authors should implement this suggestion or what specific aspects of their draft need to be addressed. The action is implicit and vague, as it does not specify which parts of the paper should be revised or how the authors should incorporate the suggested changes. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FIDs\" and \"Inception network,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear recommendation to use DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. This guidance is detailed and actionable, as it specifies what needs to be done to improve the evaluation process. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there have been clear flaws associated with FIDs and the Inception network, suggesting the use of DinoV2 Frechet Distances for comparisons. However, the comment lacks specific examples or references to support the claim about the flaws of FIDs and the Inception network. Without detailed evidence or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides a general suggestion but lacks sufficient justification or supporting details.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of FIDs and the Inception network, suggesting that there are flaws associated with them. It recommends using DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. This feedback is somewhat helpful as it points out a specific area for improvement and provides a clear suggestion for alternative evaluation methods. However, the comment could be more helpful if it included more detailed reasoning or examples of the flaws with FIDs and the Inception network, or if it suggested specific ways to incorporate the new metric into the draft. Overall, the comment provides a starting point for improvement but lacks depth and specificity, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment questions the novelty of the paper, suggesting that it might be incremental and similar to a previous work. It does not provide explicit instructions or suggestions on how to address this concern, such as detailing the differences between the current paper and the cited work or suggesting ways to enhance the novelty. The comment is vague and lacks concrete guidance, making it difficult for the authors to understand what actions they should take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the novelty of the paper and asks for clarification on how it differs from a specific previous work. However, it does not specify which part of the paper this question pertains to, such as the introduction, methodology, or results sections. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its request for comparison, the absence of explicit grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty of the paper and asks for clarification on how it differs from a specific previous work. However, it does not provide any evidence, reasoning, or references to support the claim that the paper is incremental or similar to the cited work. Without specific examples or detailed comparisons, the authors may find it challenging to address the reviewer's concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the novelty of the paper, questioning whether it is incremental or similar to a previous work. It prompts the authors to clarify the differences between their paper and the cited work, specifically asking if the novelty is merely a result of applying a similar methodology to a new task. This feedback is somewhat helpful as it identifies a potential area for improvement in terms of differentiating the paper's contributions. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address the novelty concern, making it somewhat helpful but not fully comprehensive. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the results of the ablation studies in Table 2, specifically noting that the complete loss function performed worse than those with some terms missing. However, it does not provide any explicit or implicit suggestions or actions for the authors to take to address this issue. The comment lacks guidance on how the authors might investigate or resolve this discrepancy, leaving them without a clear path forward. As a result, the comment is unactionable, as it does not offer any actionable feedback or suggestions for improvement.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to \"the reported ablation studies in Table 2,\" which provides a clear reference point for the authors to understand the context of the issue. It specifically mentions the performance of the complete loss function compared to those with some terms missing on the CUB and SOP datasets, questioning why this does not make sense. This allows the authors to accurately identify the part of the paper being addressed. The comment is specific in detailing what needs to be addressed, as it points out a discrepancy in the results of the ablation studies. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the results of the ablation studies in Table 2, specifically noting that the complete loss function performed worse than those with some terms missing. However, the comment does not provide any supporting evidence, reasoning, or references to explain why this observation is significant or how it might impact the conclusions of the paper. Without additional context or justification, the claim remains unverifiable, as the authors are left without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in the ablation studies presented in Table 2, noting that the complete loss function performed worse than those with some terms missing. This observation raises a question about the results and their implications, which the authors may need to address to ensure the validity and robustness of their findings. However, the comment does not provide any suggestions or guidance on how the authors might investigate or resolve this discrepancy. While it highlights a potential area for further analysis, it lacks actionable advice, making it somewhat helpful. The authors would need to conduct additional analysis or provide an explanation for this unexpected result, but the comment does not offer a clear path forward. Therefore, it aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider introducing inverse triples in other embedding models besides CP, as they did not test such cases in their experiments. However, it does not provide explicit guidance on how to implement this suggestion or what specific changes should be made to the draft. The action is implicit, as the authors can infer that they need to test inverse triples in other models, but the lack of concrete details makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider introducing inverse triples in other embedding models besides CP, as they did not test such cases in their experiments. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its suggestion but lacks grounding as it does not provide clear guidance on which part of the paper to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should consider introducing inverse triples in other embedding models besides CP, as they did not test such cases in their experiments. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind it. Without additional context or evidence, the claim remains somewhat verifiable, as it is based on an observation without detailed justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out a potential area for improvement by suggesting that the authors consider introducing inverse triples in other embedding models besides CP, as they did not test such cases in their experiments. This feedback is somewhat helpful as it identifies a specific aspect that could enhance the paper's comprehensiveness and robustness. However, the comment lacks depth and does not provide detailed guidance on how to implement this suggestion or what specific changes should be made to the draft. While it offers a direction for improvement, it does not fully empower the authors to address the issue comprehensively. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the clarity of a specific statement in the abstract, suggesting that it is unclear and that the abstract should be more high-level, omitting technical details. While the comment implies that the authors should revise the abstract to make it clearer, it does not provide explicit guidance on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer that they need to rephrase the abstract to remove the technical details and make it more accessible. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly identifies a problem with the abstract, namely that the statement is unclear and contains technical details that are not necessary for a high-level abstract. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of a statement in the abstract, suggesting that it is unclear and contains technical details that are not necessary for a high-level abstract. However, the comment does not provide any specific examples or references to support the claim that the statement is unclear or contains unnecessary technical details. Without additional context or evidence, the authors may find it difficult to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the abstract, noting that the statement is unclear and contains technical details that are not necessary for a high-level abstract. This feedback is clear and actionable, as it directs the authors to rephrase the abstract to make it more accessible and high-level. By addressing this issue, the authors can improve the clarity and impact of their paper. However, the comment could be more helpful if it provided specific suggestions on how to rephrase the abstract or examples of what constitutes a high-level statement. Overall, the comment is mostly helpful as it highlights a significant area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that there is room to improve the complexity of Algorithm 2. However, it does not provide any specific guidance or suggestions on how to achieve this improvement. The comment lacks concrete details or actionable steps for the authors to take, leaving them uncertain about what aspects of the algorithm's complexity need to be addressed. As a result, the authors are left without a clear understanding of how to enhance the algorithm, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that there is room to improve the complexity of Algorithm 2, but it does not specify which part of the paper Algorithm 2 is located in or provide any details on what aspects of the algorithm's complexity need improvement. This lack of grounding makes it difficult for the authors to understand which section of the paper is being referred to and what specific issues need to be addressed. The comment is specific in its suggestion but lacks grounding, as it does not provide context or references to the algorithm. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that there is room to improve the complexity of Algorithm 2. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left without a clear understanding of why this improvement is necessary or how it might be achieved. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that there is room to improve the complexity of Algorithm 2, which is a specific area for potential enhancement. However, the comment lacks detailed guidance or suggestions on how to achieve this improvement. It does not specify which aspects of the algorithm's complexity need to be addressed or provide any examples or strategies for improvement. While it identifies a potential area for enhancement, the lack of actionable feedback limits its helpfulness to the authors. Therefore, the comment is somewhat helpful, as it highlights a potential area for improvement but does not provide sufficient guidance for the authors to act upon.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the use of Gaussian Process (GP) is straightforward and naive, suggesting that dynamical modeling has been widely investigated in the GP community, particularly since the introduction of Gaussian Process Dynamical Models in NIPs 2005. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of their work need improvement. While it identifies a potential area for enhancement, it lacks concrete suggestions or actionable steps for the authors to take. Therefore, the comment is somewhat actionable, as it highlights a concern but does not provide detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the straightforward and naive use of Gaussian Process (GP) in the paper, referencing the GP community's investigation into dynamical modeling since the introduction of Gaussian Process Dynamical Models in NIPs 2005. However, the comment does not specify which part of the paper discusses the use of GP or how the authors might address this issue. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, while it points out a potential area for improvement, it does not provide specific guidance on how to enhance the use of GP or what aspects of the paper need revision. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the use of Gaussian Process (GP) is straightforward and naive, suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of Gaussian Process Dynamical Models in NIPs 2005. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim remains somewhat verifiable, as it is based on a general observation without thorough justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the straightforward and naive use of Gaussian Process (GP) in the paper, suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of Gaussian Process Dynamical Models in NIPs 2005. While the comment highlights a concern about the approach, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their methodology. The feedback is somewhat helpful as it points out a potential area for enhancement, but it lacks actionable advice or detailed examples, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the claim made in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LMs) compared to GAN models to avoid overfitting. It provides a counter-argument based on the reviewer's experience with high-dimensional LSTMs and suggests that the baseline models might not be properly regularized. The comment implies that the authors should investigate the regularization techniques used in their models, specifically questioning whether dropout is applied to the hidden states as well. However, the comment does not explicitly instruct the authors to conduct this investigation or provide detailed guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should explore the regularization techniques and potentially adjust their models accordingly. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"supplemental section D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the claim made in that section, suggesting that the baseline models might not be properly regularized and that the authors should investigate whether dropout is applied to the hidden states. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the regularization techniques used in the baseline models, specifically questioning whether dropout is applied to the hidden states. The reviewer provides a counter-argument based on their experience with high-dimensional LSTMs, suggesting that the baseline models might not be properly regularized. However, the comment lacks specific examples or references to support the claim that the baseline models are not properly regularized. While the reviewer provides a logical argument, the absence of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue in the supplemental section D.4, questioning the claim that smaller architectures are necessary for language models (LMs) compared to GAN models to avoid overfitting. It provides a counter-argument based on the reviewer's experience with high-dimensional LSTMs, suggesting that the baseline models might not be properly regularized. The comment also raises a specific question about whether dropout is applied to the hidden states, which could be a valuable point for clarification and further investigation. However, the comment could be more helpful if it provided more detailed guidance on how to address the issue or suggested specific experiments to validate the claim. Overall, the feedback is somewhat helpful as it highlights an area for improvement and encourages the authors to explore the regularization techniques used in their models.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that some ablations mentioned in previous sections are difficult to find in the subsequent content, suggesting that the writing in this part could be improved. However, it does not provide explicit guidance on what specific aspects need improvement or how the authors should address this issue. The action is implicit and vague, as it leaves the authors to infer that the writing needs improvement but does not specify what needs to be improved or how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that some ablations mentioned in previous sections are difficult to locate in the following content, implying that the writing in this part could be improved. However, it does not specify which sections or parts of the paper contain these ablations, making it weakly grounded. The comment is specific in identifying the issue of difficulty in locating ablations, but without explicit references, it is challenging for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some ablations mentioned in previous sections are difficult to locate in the following content, suggesting that the writing in this part could be improved. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that some ablations mentioned in previous sections are difficult to locate in the subsequent content, suggesting that the writing in this part could be improved. However, the comment lacks specific details or suggestions on how the authors might address this issue. It identifies a potential area for improvement but does not provide actionable guidance or examples, making it somewhat helpful. The authors may gain some insight into the need for better organization or clarity, but the feedback is incomplete and could be more comprehensive to be fully helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the differential privacy application is \"half-baked\" and encourages the authors to think through it more clearly. It also recommends moving the experimental results from the appendix to the main paper. However, the comment does not provide explicit guidance on how to address these issues or what specific changes should be made to the draft. The actions are implicit and vague, leaving the authors without clear direction on how to improve their work. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"given2)-5)\" and \"differential privacy application,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies that the authors should \"think through it more clearly\" and \"move the experimental results from the appendix to the main paper,\" providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses an opinion that the differential privacy application is \"half-baked\" and suggests that the authors should think more clearly about it. However, it does not provide specific examples, reasoning, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the differential privacy application, suggesting that it is \"half-baked\" and could benefit from more clarity. It also recommends moving the experimental results from the appendix to the main paper, which is a constructive suggestion for improving the presentation of the work. However, the comment lacks specific guidance on how to address the \"half-baked\" nature of the differential privacy application or what specific aspects need clarification. While it provides a general direction for improvement, it could be more helpful with additional details or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the contribution of multilingual chain-of-thought is incremental compared to the villa chain-of-thought. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. The comment lacks actionable steps or concrete advice, leaving the authors without a clear path to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is referring to, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment is specific in that it critiques the contribution of multilingual chain-of-thought as being incremental compared to villa chain-of-thought. However, without grounding, the authors cannot confidently determine which part of the paper needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the contribution of multilingual chain-of-thought is incremental compared to the villa chain-of-thought. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or supporting evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the incremental nature of the contribution of multilingual chain-of-thought compared to the villa chain-of-thought. While it identifies a potential weakness in the paper's contribution, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance their work. The comment lacks actionable advice, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide METEOR results, which are also reported in recent works. This is an explicit action that the authors can readily follow, as it clearly indicates what additional information is needed to improve the draft. The comment is specific in its request, detailing the exact metric (METEOR) that should be included. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide METEOR results, which are also reported in recent works. However, it does not specify which part of the paper this information should be included in or how it relates to the content of the paper. The comment lacks grounding as it does not provide clear guidance on where the METEOR results should be added or discussed. It is also specific in its request for METEOR results, but without context, it is difficult for the authors to understand the exact need. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide METEOR results, which are also reported in recent works. However, the comment does not provide any specific reasoning or evidence to support why this is necessary or how it would benefit the paper. It lacks detailed justification or references to specific sections or studies that would help the authors understand the importance of including these results. As a result, the claim is unverifiable, as it lacks sufficient support or explanation. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide METEOR results, which are also reported in recent works. This feedback is specific and actionable, as it directs the authors to include additional information that aligns with current standards and practices in the field. By providing these results, the authors can enhance the comprehensiveness and comparability of their work. However, the comment could be more helpful if it offered guidance on how to present or interpret these results effectively. Overall, the feedback is mostly helpful, as it provides a clear direction for improvement but could be more detailed in its suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the comparability of G-effect values across different unlearning objectives and approaches, given that the study examines each objective in isolation. However, it does not provide explicit or implicit actions for the authors to take to address this concern. The comment suggests that the authors should consider the comparability of G-effect values, but it does not offer specific guidance on how to do so. Without concrete suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4\" of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the concern regarding the comparability of G-effect values across different unlearning objectives and approaches, providing clear guidance on what needs to be addressed. This makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the comparability of G-effect values across different unlearning objectives and approaches, noting that the study examines each objective in isolation. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential concern regarding the comparability of G-effect values across different unlearning objectives and approaches, as the study examines each objective in isolation. This is a valid point that could impact the interpretation and comparability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the comparability of their findings. While it highlights an important consideration, the feedback is somewhat limited in its actionable value, as it does not provide detailed steps or insights for the authors to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider the reason why information value is a stronger predictor for dialogue, specifically referencing pages 7 or 8. It also asks if there is any existing linguistic theory that could explain this, implying that adding such theory would strengthen the paper. While the comment provides a clear direction for the authors to explore and potentially enhance their work, it lacks specific guidance on how to conduct this exploration or what linguistic theories might be relevant. The action is explicit but somewhat vague, as it does not provide detailed steps or examples for the authors to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider the reason why information value is a stronger predictor for dialogue, specifically referencing pages 7 or 8. This provides full grounding as the authors can accurately identify the sections where the discussion takes place. The comment is also specific, as it asks the authors to consider existing linguistic theories that could explain the phenomenon, providing a clear direction for potential additions or further exploration. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should consider the reason why information value is a stronger predictor for dialogue, specifically referencing pages 7 or 8. It also asks if there is any existing linguistic theory that could explain this phenomenon. While the comment provides a clear direction for the authors to explore and potentially enhance their work, it lacks specific examples or references to support the claim that information value is a stronger predictor. The suggestion to consider existing linguistic theories is vague and does not provide detailed guidance on which theories might be relevant or how they could be integrated into the paper. Therefore, the comment is somewhat verifiable, as it provides a general direction but lacks the necessary depth and specificity to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by questioning the reason why information value is a stronger predictor for dialogue, referencing specific sections of the paper (pages 7 or 8). It also prompts the authors to consider existing linguistic theories that could explain this phenomenon, suggesting that adding such theories would strengthen the paper. This feedback is clear and actionable, offering a concrete direction for the authors to enhance their work. However, it could be more helpful if it provided more detailed guidance on which theories might be relevant or how to integrate them into the discussion. Overall, the comment is mostly helpful as it identifies a specific area for improvement and offers a clear suggestion for action.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific aspect of the paper that could be improved by providing more detailed commentary on the use of AutoML approaches, particularly in extracting hints for future network architecture design. It suggests that the authors should elaborate on the takeaways from the found architecture. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of AutoML approaches, specifically focusing on extracting hints for future network architecture design. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to provide more detailed commentary on these aspects, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors did not spend much time commenting on the use of AutoML approaches, particularly in extracting hints for future network architecture design. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim remains somewhat verifiable, as it is based on an observation without thorough justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting that the authors did not adequately comment on the use of AutoML approaches, particularly in extracting hints for future network architecture design. This feedback is somewhat helpful as it highlights a potential gap in the paper's discussion and suggests that the authors should provide more detailed commentary on this aspect. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address this issue, such as recommending additional sections or analyses that could be included. Overall, the comment provides a clear direction for improvement but lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the definition of T_a(t), noting that it is used in Section 3.1 but only defined in Section 4. This suggests that the authors may need to ensure that all terms are defined before they are used in the paper. However, the comment does not provide explicit guidance on how to address this issue, such as suggesting where the definition should be placed or how to clarify its usage. The action is implicit and somewhat vague, as the authors need to infer that they should define T_a(t) before using it in Section 3.1. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly points out that the term T_a(t) is used in Section 3.1 but only defined in Section 4, highlighting a potential issue with clarity and consistency. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the term T_a(t) is used in Section 3.1 but only defined in Section 4. This is a factual observation about the structure of the paper, and it does not require any additional evidence or reasoning to be considered verifiable. The comment is clear and specific, providing a clear indication of a potential issue with the paper\\'s organization and clarity. Therefore, the comment is classified as fully verifiable, aligning with a score of 5.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the term T_a(t) is used in Section 3.1 but is only defined in Section 4. This observation highlights a potential inconsistency or lack of clarity in the paper\\'s structure and presentation. While the comment points out a specific area that needs attention, it does not provide detailed guidance or suggestions on how to address this issue. The feedback is somewhat helpful as it directs the authors to a particular area for improvement, but it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and that the inclusion of empirical results would be beneficial. While the comment provides a general direction for improvement, it lacks specific guidance on how to achieve conciseness or what specific aspects of the introduction should be revised. The suggestion to include empirical results is vague and does not offer concrete steps on how to incorporate them. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the main part of the paper, especially the introduction, could be more concise and that including empirical results would be beneficial. However, it does not specify which part of the paper is being addressed, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is vague and lacks specificity, as it does not provide detailed guidance on how to make the introduction more concise or how to include empirical results. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the main part of the paper, particularly the introduction, could be more concise and that including empirical results would be beneficial. However, the comment lacks specific details or examples to support these claims, making it difficult for the authors to understand the reasoning behind the suggestions. Without clear justification or references, the claim remains somewhat verifiable, as it provides a general direction for improvement but lacks the necessary depth and specificity to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and that the inclusion of empirical results would be beneficial. While the comment identifies areas for improvement, it lacks specific guidance on how to achieve these changes. The feedback is somewhat helpful as it points out potential areas for enhancement, but it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is rated as 3: Somewhat Helpful, as it offers some insight but requires further elaboration to be fully beneficial.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper's primary contribution is an incremental advancement in efficiency over the TACTiS approach. However, it does not provide explicit guidance on what specific evidence or arguments are needed to establish this contribution as significant. The comment implies that the authors should provide more detailed evidence or arguments, but it lacks concrete instructions on how to do so. Therefore, the comment is somewhat actionable, as it identifies a need for more evidence but does not offer specific guidance on how to achieve this.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper's primary contribution is an incremental advancement in efficiency over the TACTiS approach. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to pinpoint the exact section or aspect that needs to be addressed. The comment is specific in its critique of the contribution, but it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper's primary contribution is an incremental advancement in efficiency over the TACTiS approach. However, it does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the claim remains unsubstantiated, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by suggesting that the primary contribution is an incremental advancement in efficiency over the TACTiS approach. While it highlights the need for more substantial evidence to establish the significance of this contribution, it does not provide specific guidance or suggestions on how to strengthen the evidence or arguments. The comment is somewhat helpful as it points out an area for improvement, but it lacks depth and actionable advice, making it less impactful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited. It also notes that many previous works focus on this topic and that adding topic entities seems incremental. However, the comment does not provide specific guidance or suggestions on how to address these issues or improve the paper. The authors are left without a clear understanding of what needs to be done to enhance their work, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited, implying that the authors should consider adding topic entities. However, it does not specify which part of the paper discusses the improvements on different datasets or the novelty of the paper. The comment lacks grounding as the authors cannot confidently determine which sections or aspects of the paper are being addressed. It is also specific in suggesting that adding topic entities seems incremental, but without a clear reference to the relevant sections, the authors may struggle to apply this feedback. Therefore, this comment is weakly grounded and somewhat specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvements on different datasets are trivial and that the novelty of the paper is limited, suggesting that adding topic entities seems incremental. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim remains somewhat verifiable, as the authors may need to infer the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper, suggesting that the improvements on different datasets are trivial and that the novelty of the paper is limited. It also implies that adding topic entities might seem incremental. However, the comment lacks specific guidance or suggestions on how to address these issues or enhance the paper's novelty. While it points out areas for improvement, it does not provide actionable steps or detailed feedback that would help the authors make meaningful revisions. As a result, the comment is somewhat helpful, as it offers some insight but lacks depth and specificity to fully assist the authors in improving their draft.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the authors claim their method performs better than baselines, but the error range is high, suggesting that the performance differences are not significant. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of their method need improvement to make the performance more distinguishable from the baselines. The action is implicit and vague, as it does not specify how the authors should modify their method or data to achieve better performance. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of marginal improvements over baselines and the high error range, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the concern regarding the performance differences between methods and the need for the authors to address this issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' method only marginally improves over baselines, with performance differences within the error bar range. This claim is supported by the observation that the error range is high, suggesting that the performance differences are not significant. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors could strengthen the comment by providing more detailed evidence or examples to substantiate their claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the authors' claim of marginal improvement over baselines, noting that the performance differences are within the error bar range. This feedback is valuable as it highlights a critical aspect of the results that needs to be addressed. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might improve their method or data to achieve more distinguishable performance. While it points out a weakness, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method. It also asks for clarification on how to select representative images. However, the comment does not provide explicit guidance or suggestions on how to address these issues. The authors are left without a clear path to improve their draft, as the action is implicit and vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method, as well as the selection of representative images. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its request for clarification but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method and how to select representative images. However, it does not provide any specific reasoning, examples, or references to support why this is an issue or how it could be addressed. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method, as well as the selection of representative images. This feedback highlights a potential area for improvement in the paper, specifically regarding the clarity and comprehensiveness of the evaluation methodology. However, the comment lacks specific guidance or suggestions on how to address these issues, leaving the authors without actionable steps to enhance their work. While it identifies a relevant area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear direction for improvement but does not offer comprehensive guidance.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy. It also recommends providing a brief overview of the original DPO algorithm to clarify the modifications proposed in the methods section. These suggestions are clear and direct, allowing the authors to understand exactly what needs to be added to their draft. The comment is fully actionable as it provides concrete guidance on how to improve the paper. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy. It also recommends providing a brief overview of the original DPO algorithm to clarify the modifications proposed in the methods section. However, the comment does not specify which part of the paper this suggestion relates to, making it weakly grounded. While it provides some specificity by mentioning the need for a background section and a brief overview of the DPO algorithm, it does not detail how these additions would enhance the paper. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors should include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy, to clarify the RL context being considered. It also suggests providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. While the comment provides a logical reasoning for the need for these additions, it lacks specific examples or references to support the claim fully. The authors would need to infer the importance of these additions, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting that the authors include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy. This would help readers understand the context of the paper. Additionally, the comment recommends providing a brief overview of the original DPO algorithm to clarify the modifications proposed in the methods section. This feedback is detailed and constructive, offering specific guidance on how to improve the clarity and comprehensibility of the paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of the proposed method when users continuously add new languages due to limited model capacity. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment identifies a problem but does not offer guidance on how to mitigate it or suggest potential solutions. As a result, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the proposed method's limitation when users continuously add new languages due to limited model capacity. However, it does not specify which part of the paper this issue is related to, such as a specific section, table, or figure. Without this context, the authors may find it challenging to identify the exact area that needs attention. While the comment is specific in its critique, the lack of grounding makes it difficult for the authors to fully understand and address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the proposed method's limitation when users continuously add new languages due to limited model capacity. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed method, specifically that it may encounter issues when users continuously add new languages due to limited model capacity. This feedback highlights a critical area that needs attention and suggests that the authors should consider how to address this limitation. However, the comment lacks specific guidance or suggestions on how to mitigate this issue, such as potential solutions or strategies for handling the continuous addition of languages. While it points out a significant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear area for improvement but does not offer detailed guidance on how to achieve it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the S2D structure, specifically questioning why the number of parameters does not change when the kernel height and width remain the same. The reviewer suggests that if the kernel height and width stay the same, the depth would increase, resulting in more parameters. The comment implies that more details are needed to clarify this aspect. However, the action is implicit, as the authors need to infer that they should provide more details to address the question. The action is vague because it does not specify exactly what additional details are needed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the S2D structure, specifically questioning why the number of parameters does not change when the kernel height and width remain the same. It suggests that if the kernel height and width stay the same, the depth would increase, resulting in more parameters. The comment implies that more details are needed to clarify this aspect. However, the authors cannot confidently determine which part of the paper this comment refers to, as it is not explicitly mentioned. The comment is specific in its critique of the parameter count in the S2D structure, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the S2D structure, specifically questioning why the number of parameters does not change when the kernel height and width remain the same. The reviewer provides a logical explanation, suggesting that if the kernel height and width stay the same, the depth would increase, resulting in more parameters. This reasoning is clear and logical, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue in the S2D structure, questioning why the number of parameters does not change when the kernel height and width remain the same. The reviewer provides a logical explanation, suggesting that if the kernel height and width stay the same, the depth would increase, resulting in more parameters. This feedback is clear and actionable, as it points out a potential inconsistency in the explanation and suggests that more details should be provided to clarify the parameter count. However, the comment could be more helpful if it offered specific suggestions or examples to address the issue. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the similarity between the proposed method and a method in [10], suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. It implies that the authors should consider why [10] cannot use these side information. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit and vague, as it does not specify how the authors should explore or incorporate the suggestions. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the similarity between the proposed method and a method in [10], suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. It implies that the authors should consider why [10] cannot use these side information. However, the comment does not specify which part of the paper discusses the proposed method or the method in [10], making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issue of similarity and the potential use of side information, it lacks grounding as it does not explicitly mention the sections or parts of the paper being discussed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the similarity between the proposed method and a method in [10], suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. It implies that the authors should consider why [10] cannot use these side information. However, the comment lacks specific reasoning or examples to support the claim that the method in [10] could be equipped with these features. Without detailed justification or references, the claim remains somewhat verifiable, as it is based on an assumption rather than a well-supported argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the similarity between the proposed method and a method in [10], suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. It implies that the authors should consider why [10] cannot use these side information. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or incorporate these ideas into their work. It lacks actionable insights and detailed reasoning, making it barely helpful. The authors are left with a vague question but no clear direction on how to improve their draft.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the Atari game results, noting that they are based on a single game and a single baseline, making it difficult to interpret. However, it does not provide any explicit or implicit suggestions on how to address this issue or improve the analysis. The comment lacks concrete guidance on what changes could be made to the results or how the authors might enhance their interpretation. As a result, the authors are left without a clear understanding of how to proceed with the feedback, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper the Atari game results are discussed in, nor does it provide any context or explanation for why the results are limited to a single game and baseline. The authors cannot confidently determine which section or part of the paper is being addressed, making it difficult to understand the issue being raised. Additionally, the comment is not specific because it does not detail what aspects of the results are difficult to interpret or what suggestions could be made to improve the analysis. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point highlights a limitation in the Atari game results, noting that they are based on a single game and a single baseline, making it difficult to interpret. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the Atari game results, noting that they are based on a single game and a single baseline, making it difficult to interpret. While the comment points out a potential issue with the scope of the results, it does not provide specific suggestions or guidance on how the authors might address this limitation or improve the analysis. The feedback is somewhat helpful as it highlights an area for improvement, but it lacks actionable advice or detailed suggestions, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the presentation of the simulation study is not effective in supporting the authors. It specifically notes that the authors do not comment on why the GPC (benchmark) performs better than BPC (their method). The comment suggests that it would be beneficial to reiterate that this difference is due to the bandit feedback and not the use of information about the form of the cost function. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their presentation. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"presentation of the simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of comment on why the GPC (benchmark) performs better than BPC (the authors' method) and suggests that this difference is due to bandit feedback and not the use of information about the cost function form. This provides a clear direction for the authors to improve their presentation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the presentation of the simulation study is not effective in supporting the authors, specifically noting that the authors do not comment on why the GPC (benchmark) performs better than BPC (their method). The comment suggests that it would be beneficial to reiterate that this difference is due to bandit feedback and not the use of information about the cost function form. However, the comment lacks specific examples or detailed reasoning to substantiate this claim, making it somewhat verifiable. The authors would need to infer the basis for the claim, which limits its verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the presentation of the simulation study, noting that the authors do not adequately explain why the GPC (benchmark) performs better than BPC (their method). It suggests that this difference is due to bandit feedback and not the use of information about the cost function form. This feedback is clear and actionable, as it provides a specific area for improvement and a clear rationale for why the authors should address this issue. However, the comment could be more helpful if it offered suggestions on how to reiterate this point or provide additional context. Overall, the comment is mostly helpful, as it guides the authors to improve their presentation but could be more comprehensive.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the reported perplexity values in Figure 1, noting that they are over 30 and contradict better BLEU scores. It also asks for clarification on how the perplexity was calculated. While the comment identifies a potential issue with the reported perplexity values and requests clarification on the calculation method, it does not provide explicit guidance on how to address the issue or improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the discrepancy and provide a detailed explanation of the perplexity calculation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reported perplexity values, which are over 30, and contrasts them with the better BLEU scores the reviewer has observed. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the reported perplexity values in Figure 1, noting that they are over 30 and contradict better BLEU scores. It requests clarification on how the perplexity was calculated. While the comment identifies a potential issue with the reported perplexity values, it lacks specific evidence or references to support the claim that the perplexity is unusually high or contradictory to the BLEU scores. The authors are left to infer the basis of the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reported perplexity values in Figure 1, noting that they are over 30 and contradict better BLEU scores. This observation raises a question about the accuracy or interpretation of the perplexity calculation. The comment requests clarification on how the perplexity was calculated, which is a valuable piece of feedback for the authors to address. However, the comment could be more helpful if it provided additional context or suggested specific steps the authors could take to investigate or address the issue. Overall, the comment is somewhat helpful as it highlights a potential area for improvement and encourages the authors to clarify their perplexity calculation method. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the evaluation of the paper needs to include experiments on distributed deployment and a larger model. While it provides a clear direction for improvement, it does not specify which parts of the paper should be revised or how the authors should conduct these additional experiments. The action is explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this feedback is intended for, making it difficult for the authors to identify the exact sections that require revision. The comment is specific in its suggestion but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not provide any specific reasoning, examples, or references to support why these experiments are necessary or how they would enhance the paper. Without detailed justification or evidence, the claim remains unverifiable, as the authors cannot confidently understand the basis for the suggestion. Therefore, this comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the evaluation of the paper needs to include experiments on distributed deployment and a larger model. This feedback is somewhat helpful as it points out specific areas where the evaluation could be strengthened. However, it lacks detailed guidance on how to conduct these additional experiments or what specific aspects of the evaluation would benefit from these changes. The comment provides a clear direction for improvement but does not offer comprehensive suggestions or detailed instructions, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper where the authors define rooted patterns but do not elaborate on their importance or how the roots are chosen. It suggests that a brief discussion is expected or that the discussion could be limited to the supplementary material if non-rooted patterns are sufficient. While the comment implies that the authors should provide more context and explanation, it does not explicitly instruct them to add a discussion or clarify the choice of roots. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on the importance and selection of rooted patterns. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where rooted patterns are defined, allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies the issue: the lack of elaboration on the importance of rooted patterns and the absence of a discussion on how the roots are chosen. The comment suggests that a brief discussion is expected or that the discussion could be limited to the supplementary material if non-rooted patterns are sufficient. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors define rooted patterns but do not elaborate on their importance or how they choose the roots. It suggests that a brief discussion is expected or that the discussion could be limited to the supplementary material if non-rooted patterns are sufficient. This claim is somewhat verifiable as it provides a logical reasoning for why the lack of elaboration is a concern, but it lacks specific examples or references to support the claim fully. The authors would need to infer the importance of rooted patterns and the rationale behind choosing specific roots, which could be challenging. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area where the authors could improve their paper by providing more context and explanation regarding the definition of rooted patterns. It highlights the lack of elaboration on why rooted patterns are important and how the roots are chosen, suggesting that a brief discussion is expected or that the discussion could be limited to the supplementary material if non-rooted patterns are sufficient. This feedback is clear and actionable, as it directs the authors to address a specific gap in their explanation, which could enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided additional guidance on how to elaborate on the importance or selection of rooted patterns. Overall, the comment is mostly helpful, as it effectively points out an area for improvement but could be more detailed in its suggestions.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would be improved by including some failure cases and related discussion. While the comment implies that this addition would enhance the paper, it does not explicitly instruct the authors to include specific examples or details about these failure cases. The action is implicit, as the authors need to infer that they should add this information, but it lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including some failure cases and related discussion in the paper. However, it does not specify which part of the paper this should be included in, nor does it provide any guidance on what kind of discussion or examples would be beneficial. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity, as it does not detail what aspects of failure cases or discussion would be most valuable. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the paper would benefit from including some failure cases and related discussion. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or justification, the authors may find it challenging to understand why this suggestion is important or how to incorporate it into their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper would be improved by including some failure cases and related discussion. While this feedback provides a clear direction for improvement, it lacks specific details or examples of what kind of failure cases or discussions would be beneficial. The authors are left with a general idea of what to include but without actionable guidance on how to do so. This makes the comment somewhat helpful, as it identifies an area for enhancement but does not fully support the authors in making the necessary changes. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the necessity of the base layer GNN encoding in the proposed method, suggesting that an ablation study would be helpful. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to perform an ablation study to address the question. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the necessity of the base layer GNN encoding in the proposed method, suggesting that an ablation study would be helpful. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This makes it difficult for the authors to identify the exact section they need to address. While the comment is specific in its suggestion to conduct an ablation study, the lack of grounding makes it challenging for the authors to understand the context. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of the base layer GNN encoding in the proposed method and suggests that an ablation study would be helpful. However, the comment does not provide any specific reasoning, examples, or references to support why the base layer GNN encoding is unclear or why an ablation study is necessary. This lack of justification makes the claim somewhat verifiable, as the authors may need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method, specifically questioning the necessity of the base layer GNN encoding. It suggests that an ablation study would be helpful to address this concern. While the comment highlights a specific area for improvement, it lacks depth and does not provide detailed guidance on how to conduct the ablation study or what specific results would be expected. This makes the feedback somewhat helpful, as it points out a potential weakness but does not fully address the authors' needs for improvement. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the discussion of computational complexity, specifically the lack of detailed explanation or explicit mention of upper bounds for counting homomorphisms. It suggests that the authors should consider adding this information and potentially elaborating on empirical runtimes. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to do so, such as suggesting specific sections or types of analysis to include. The action is somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the issue of computational complexity is discussed, allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies the issue by pointing out the lack of detailed discussion on the computational complexity of counting homomorphisms and suggests that the authors should consider adding upper bounds and elaborating on empirical runtimes. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms, noting that the paper makes brief statements but lacks detailed discussion or explicit mention of upper bounds. The comment suggests that it would be beneficial for the paper to include this information and potentially elaborate on empirical runtimes. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the discussion is inadequate. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the basis for the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area where the paper could be improved by discussing the computational complexity of counting homomorphisms. It points out that the current discussion is brief and suggests that the authors should consider adding upper bounds and elaborating on empirical runtimes. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their draft. However, the comment could be more helpful if it offered additional guidance on how to incorporate this information or suggested specific sections where the discussion could be expanded. Overall, the comment is mostly helpful as it highlights an important aspect of the paper that needs attention.\", 'helpfulness_label': '4'}<jupyter_start><s a breakdown of the thinking process to evaluate the review point:\n\n1. **Actionability Analysis:**\n\n   * **Initial Assessment:** The comment points out a lack of detailed discussion on computational complexity and suggests adding upper bounds and elaborating on empirical runtimes. This indicates an implicit action, as the authors need to infer that they should address this gap.\n   * **Explicitness:** The comment is explicit in identifying the issue (lack of detailed discussion) and suggesting specific actions (adding upper bounds, elaborating on runtimes).\n   * **Concreteness:** The suggestions are concrete, providing clear directions on what needs to be added to the paper.\n   * **Evaluation:** Based on the criteria, the comment is somewhat actionable because it is explicit but could be more direct. Therefore, it aligns with a score of 3.\n\n2. **Grounding Specificity Analysis:**\n\n   * **Grounding:** The comment explicitly mentions \"L 145,\" which directly points to a specific location in the paper where the issue is discussed. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded.\n   * **Specificity:** The comment clearly specifies the issue by highlighting the lack of detailed discussion on computational complexity and suggesting that the authors should consider adding upper bounds and elaborating on empirical runtimes. This provides specific guidance on what needs to be addressed.\n   * **Evaluation:**  The comment is fully grounded and specific, aligning with a score of 5.\n\n3. **Verifiability Analysis:**\n\n   * **Claim Identification:** The comment claims that the authors do not adequately discuss the computational complexity of counting homomorphorphisms, noting that the paper makes brief statements but lacks detailed discussion or explicit mention of upper bounds.\n   * **Support for Claim:** The comment provides a specific example (L 145) where a brief statement is made, but it lacks detailed reasoning or references to support the claim that the discussion is inadequate. Without further elaboration or evidence, the authors would need to infer the basis for the claim.\n   * **Evaluation:** The comment is somewhat verifiable, as it provides some justification but lacks key elements like examples or references. Therefore, it aligns with a score of 3.\n\n4. **Helpfulness Analysis:**\n\n   * **Feedback Value:** The comment identifies a specific area for improvement by"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the study, specifically the lack of analysis of inference time. It suggests that since the method is direct and does not require detection or keypoint grouping, it would be beneficial to compare its inference speed to previous top-down and bottom-up pose estimation methods. However, the comment does not provide explicit guidance on how the authors should conduct this analysis or what specific metrics to use. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the study of inference time, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a comparison of inference speed with previous top-down and bottom-up pose estimation methods, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the study lacks an analysis of inference time, suggesting that it would be beneficial to compare the inference speed of the proposed method with previous top-down and bottom-up pose estimation methods. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional justification or evidence, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the study by pointing out the absence of an analysis of inference time. It suggests that since the method is direct and does not require detection or keypoint grouping, it would be valuable to compare its inference speed with previous top-down and bottom-up pose estimation methods. This feedback is clear and actionable, as it provides a specific area for improvement and guidance on how to address it. However, the comment could be more helpful if it included suggestions on which metrics to use for comparison or how to present the results effectively. Overall, the comment is mostly helpful, as it highlights a crucial aspect that needs attention and offers a clear direction for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses an opinion about the claim regarding evolutional dropout and internal covariate shift, suggesting that it is limited. It also mentions Batch Normalization as a method that standardizes variance and centers activations, implying that these should be discussed explicitly. However, the comment does not provide explicit instructions or suggestions on how to address these points or what specific changes should be made to the paper. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the limitations of the claim regarding evolutional dropout and internal covariate shift, suggesting that it is limited to increasing the variance of low-variance units. It also mentions Batch Normalization as a method that standardizes variance and centers activations, implying that these should be discussed explicitly. However, the comment does not specify which part of the paper discusses the claim or the limitations, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to identify the exact section to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses an opinion about the claim regarding evolutional dropout and internal covariate shift, suggesting that it is limited. It mentions Batch Normalization as a method that standardizes variance and centers activations, implying that these should be discussed explicitly. However, the comment lacks specific examples or detailed reasoning to support the claim that the limitations of the claim are limited to increasing the variance of low-variance units. Without clear examples or references, the claim is difficult for the authors to fully understand and address. Therefore, the comment is barely verifiable, as it provides some reasoning but lacks depth and specificity.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the claim regarding evolutional dropout and internal covariate shift, suggesting that it is limited to increasing the variance of low-variance units. It also points out that Batch Normalization standardizes variance and centers activations, implying that these should be discussed explicitly. While the comment highlights an important aspect that needs clarification, it does not provide detailed guidance or suggestions on how to address this limitation or improve the discussion. The feedback is somewhat helpful as it directs the authors to a specific area that requires attention, but it lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should add more description about the contribution of the paper. However, it does not specify which part of the paper needs more description or what kind of additional information should be included. The action is implicit and vague, as it does not provide concrete guidance on how to enhance the description of the paper\\'s contribution. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the authors should add more description about the contribution of the paper. However, it does not specify which part of the paper this description should be added to or what aspects of the contribution need more detail. This lack of specificity makes it difficult for the authors to understand exactly where and what to add. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should add more description about the contribution of the paper. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this suggestion is necessary or how to implement it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should add more description about the contribution of the paper. However, it lacks specificity and does not provide any guidance on what aspects of the contribution need more detail or how to enhance the description. Without additional context or suggestions, the authors may find it challenging to understand the need for more description or how to improve it. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific suggestions for improving the organization of the paper by suggesting that the main contributions, particularly the introduction of two types of attention for deep VAEs, should be described in a separate section before discussing the generative and inference models. It also suggests that tricks like normalization or feature scaling could be referenced in a separate section. However, the comment does not explicitly instruct the authors on how to implement these suggestions, such as where to add these sections or how to integrate the tricks. While the suggestions are clear, the lack of explicit guidance on implementation makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment provides specific suggestions for improving the organization of the paper, such as separating the description of the main contributions and the generative/inference models, and referencing tricks like normalization or feature scaling in a separate section. However, it does not explicitly mention which sections or parts of the paper these suggestions relate to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of explicit grounding makes it weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of minor comments and suggestions regarding the organization and structure of the paper. It suggests that the main contributions, particularly the introduction of two types of attention for deep VAEs, should be described in a separate section before discussing the generative and inference models. Additionally, it recommends referencing tricks like normalization or feature scaling in a separate section. However, the comment lacks specific examples, detailed reasoning, or references to support these suggestions, making it difficult for the authors to understand and implement the changes. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment provides specific suggestions for improving the organization and structure of the paper. It suggests that the main contributions, particularly the introduction of two types of attention for deep VAEs, should be described in a separate section before discussing the generative and inference models. This would help improve the clarity and flow of the paper. Additionally, the comment recommends referencing tricks like normalization or feature scaling in a separate section, which could enhance the paper's clarity and completeness. However, the comment lacks detailed guidance on how to implement these suggestions, such as specific section titles or formatting recommendations. While the feedback is somewhat helpful, it could be more comprehensive with additional details, making it a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the paper: the minimal performance differences between methods and the use of outdated and saturated benchmarks. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment suggests that the authors should consider re-evaluating their results or selecting more appropriate benchmarks, but it does not offer specific guidance on how to do so. Without concrete steps or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance differences between methods and the use of outdated benchmarks, but it does not specify which part of the paper these issues are discussed in. The authors cannot confidently determine which sections or figures are being referred to, making the comment weakly grounded. However, it provides specific feedback on the minimal performance differences and the need for more appropriate benchmarks, which is clear and specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance differences between methods are minimal across evaluations, with differences less than 1 percentage point, potentially due to random variation. It also suggests that the benchmarks used are outdated and likely saturated, referencing a specific paper [1] to support the claim about the benchmarks. The claim is supported by logical reasoning and specific references, making it mostly verifiable. However, the reasoning could be more detailed to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the performance differences between methods are minimal across evaluations, with differences less than 1 percentage point. This observation suggests that the results may be due to random variation, which is a critical point for the authors to address. Additionally, the comment points out that the benchmarks used are outdated and likely saturated, indicating a need for more appropriate benchmarks. The reference to a specific paper [1] provides additional context and support for the claim about the benchmarks. While the comment highlights important areas for improvement, it lacks detailed suggestions or guidance on how to address these issues. Therefore, the comment is somewhat helpful, as it provides valuable insights but could be more comprehensive in offering actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggestions for the authors to consider. It questions the effectiveness of the method on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with non-deterministic dynamics to assess its empirical efficacy. Additionally, it asks why BEAR is missing from the baselines. While the comment provides some guidance, it lacks explicit instructions on how to address these points or what specific actions the authors should take. The suggestions are somewhat vague and do not offer detailed guidance on how to conduct the additional evaluations or why BEAR is missing from the baselines. Therefore, the comment is somewhat actionable, aligning with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the method's effectiveness on Hopper, a domain with deterministic dynamics, and suggests evaluating it on domains with non-deterministic dynamics to assess its empirical efficacy. It also questions why BEAR is missing from the baselines. However, the comment does not specify which part of the paper discusses the method's application or evaluation on Hopper, making it weakly grounded. While it provides some specificity by questioning the method's effectiveness and suggesting additional evaluations, the lack of explicit grounding makes it difficult for the authors to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the method's effectiveness on Hopper, a domain with deterministic dynamics, and suggests evaluating it on domains with non-deterministic dynamics to assess its empirical efficacy. It also questions why BEAR is missing from the baselines. However, the comment lacks specific reasoning or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The questions are open-ended and do not provide clear guidance or evidence, leaving the authors uncertain about the validity of the concerns. Therefore, the comment is considered unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises several questions and suggestions for the authors to consider, which could help them improve their draft. It questions the method's effectiveness on Hopper, a domain with deterministic dynamics, and suggests evaluating it on domains with non-deterministic dynamics to assess its empirical efficacy. This provides a clear direction for further experimentation and analysis. Additionally, the comment asks why BEAR is missing from the baselines, which could highlight a gap in the evaluation and encourage the authors to include it. However, the comment lacks depth and specificity, as it does not provide detailed guidance on how to conduct these evaluations or why BEAR is missing from the baselines. While it offers some actionable feedback, the lack of comprehensive suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a theocratical justification for why co-training and weight averaging improve results. While the comment implies that this justification is necessary, it does not explicitly instruct the authors to include it in their draft. The action is implicit, as the authors need to infer that they should add a theoretical or conceptual explanation for the effectiveness of these techniques. However, the comment lacks concrete guidance on how to provide this justification, such as suggesting specific types of theocratical reasoning or examples. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide a theocratical justification for why co-training and weight averaging improve results. However, it does not specify which part of the paper this justification should be included in, making it weakly grounded. The comment is specific in its request for a justification, but without clear guidance on where to include it, the authors may struggle to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide a theocratical justification for why co-training and weight averaging improve results. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand how to address it. Without clear guidance or references, the claim remains vague and challenging to implement. Therefore, the comment is considered borderline verifiable, as it provides a general suggestion but lacks sufficient evidence or explanation.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors provide a theocratical justification for why co-training and weight averaging improve results. This feedback is clear and actionable, as it directs the authors to enhance the theoretical or conceptual basis of their findings. However, the comment could be more helpful if it provided specific examples or guidance on how to construct such a justification. Despite this, the feedback is mostly helpful as it offers a clear direction for improvement, allowing the authors to address a key aspect of their work. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide explicit guidance on what specific aspects of the method need to be elaborated upon or how the authors should present these details. The action is implicit and vague, as it leaves the authors to infer the exact areas that require additional explanation. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not specify which part of the paper this feedback pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact areas that need improvement. While the comment is specific in its request for more details, the absence of grounding information limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide any specific examples, references, or reasoning to support why these details are important or how they would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper by suggesting that more details about the proposed method should be presented. It highlights the need for a clearer explanation of how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment lacks specificity in terms of which parts of the paper need to be expanded or what specific aspects of the method should be elaborated upon. While it provides a general direction for improvement, it does not offer detailed guidance or examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of the proposed method in detecting hallucinations in open-ended responses, providing a specific example to illustrate the issue. It suggests that the method might struggle with prompts like \"introduce a sports celebrity to me,\" where sampled responses could pertain to different individuals, making it challenging to identify shared information for consistency checking. However, the comment does not provide explicit guidance on how the authors might address this issue or what specific improvements could be made to the method. The action is implicit and somewhat vague, as it leaves the authors to infer the need for further investigation or modification. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the proposed method, noting its potential struggle to detect hallucinations in open-ended responses. It provides a concrete example, such as the prompt \"introduce a sports celebrity to me,\" to illustrate the challenge. However, the comment does not explicitly mention a specific section or part of the paper where this issue is discussed, making it weakly grounded. The specificity of the comment is high as it clearly identifies the problem and provides an example, guiding the authors on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method might struggle to detect hallucinations in open-ended responses, providing an example of a prompt that could lead to this issue. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to understand the basis of the concern or how to address it. Without additional context or examples, the claim is not fully verifiable, as it relies on the authors' interpretation of the method's limitations. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential limitation of the proposed method in detecting hallucinations in open-ended responses, providing a specific example to illustrate the issue. This feedback is valuable as it highlights a gap in the method's ability to handle certain types of prompts, which could impact the reliability of the results. However, the comment could be more helpful if it offered suggestions or guidance on how the authors might address this limitation or improve the method's robustness. Without specific recommendations or actionable steps, the feedback is somewhat helpful, as it provides insight into an area that needs improvement but lacks detailed guidance. Therefore, the comment aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of how theoretical findings relate to real-world deep learning models. It suggests that the authors should verify the conclusion about label noise and model size on MNIST using CNNs. However, the comment does not provide explicit guidance on how to verify this claim or what specific steps the authors should take. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"theoretical findings\" and suggests verifying the conclusion about \"label noise and model size on MNIST and CNN.\" This provides clear guidance on which parts of the paper need attention. However, the comment lacks specificity in detailing what aspects of the findings need verification or how the authors should approach this verification. It does not provide specific examples or detailed instructions, making it somewhat specific. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point raises a concern about the clarity of how theoretical findings relate to real-world deep learning models. It suggests verifying the conclusion about label noise and model size on MNIST using CNNs. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the findings are unclear or need verification. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper by questioning the clarity of how theoretical findings relate to real-world deep learning models. It suggests that the authors should verify the conclusion about label noise and model size on MNIST using CNNs. However, the comment lacks specific guidance on how to verify this claim or what steps the authors should take to address it. While it points out an area for improvement, it does not provide detailed suggestions or actionable advice, making it somewhat helpful. The feedback is incomplete and could be more comprehensive with additional details or examples, which would enhance its usefulness for the authors. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should explicitly mention the requirement of choosing a Gaussian distribution for p(y | H_f(t_n)) to enable Kalman Filtering and Smoothing and CVI. It also notes that this assumption is already made in the ELBOs section. However, the comment does not provide specific guidance on how the authors should address this point or what changes are needed in their draft. The action is implicit and vague, as the authors are left to infer that they need to clarify this requirement. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the issue of choosing a Gaussian distribution for p(y | H_f(t_n)) is discussed. It also specifies the consequence of this choice, namely the applicability of Kalman Filtering and Smoothing and CVI. This provides clear guidance for the authors to address the issue. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should explicitly mention that p(y | H_f(t_n)) must be chosen as a Gaussian distribution for Kalman Filtering and Smoothing and CVI to be possible. It also notes that this assumption is already made in the ELBOs section. However, the comment lacks specific examples or detailed reasoning to support why this assumption is necessary. While it provides a logical argument, the absence of concrete evidence or references makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that the choice of p(y | H_f(t_n)) being Gaussian is crucial for the applicability of Kalman Filtering and Smoothing and CVI. It also points out that this assumption is already made in the ELBOs section. This feedback is clear and actionable, as it directs the authors to explicitly mention the requirement for a Gaussian distribution to ensure the validity of their methodology. By highlighting this detail, the comment provides a clear path for improvement, enhancing the clarity and completeness of the paper. Therefore, the comment is mostly helpful, as it offers a specific and actionable suggestion that would benefit the authors.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of qualitative experiments to demonstrate the validity of the conditional independence model. It suggests providing illustrative experimental results to show that minimizing HSICcond-i could perform better than minimizing HSIC_HOOD, and proposes using a toy dataset to demonstrate the separability of inlier and outlier features. Additionally, it points out the absence of correctness tests and comparative experiments with other metrics, suggesting the inclusion of visualization results or schematic diagrams to aid understanding. While the comment provides several specific suggestions for improvement, it does not explicitly instruct the authors to implement these suggestions. The actions are somewhat concrete, as the authors know what needs to be done, but the lack of explicit instructions makes the comment somewhat actionable. Therefore, the comment is categorized as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of qualitative experiments to demonstrate the validity of the conditional independence model, suggesting the inclusion of illustrative experimental results. It specifically proposes using a toy dataset to demonstrate the separability of inlier and outlier features, which provides a clear direction for the authors to address the issue. However, the comment does not mention specific sections or parts of the paper that need to be revised, making it weakly grounded. The comment is specific in its suggestions for improvement, such as providing visualization results or schematic diagrams to aid understanding. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of qualitative experiments to demonstrate the validity of the conditional independence model. It suggests providing illustrative experimental results, such as using a toy dataset to demonstrate the separability of inlier and outlier features. Additionally, it points out the absence of correctness tests and comparative experiments with other metrics, recommending the inclusion of visualization results or schematic diagrams to aid understanding. While the comment provides some suggestions for improvement, it lacks specific examples or detailed reasoning to fully substantiate the claim. The lack of detailed examples or references makes it somewhat verifiable, as the authors would need to infer the need for these additional experiments and visualizations to fully understand the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of qualitative experiments to demonstrate the validity of the conditional independence model. It provides specific suggestions for improvement, such as including illustrative experimental results using a toy dataset to show the separability of inlier and outlier features. Additionally, the comment highlights the absence of correctness tests and comparative experiments with other metrics, suggesting the inclusion of visualization results or schematic diagrams to aid understanding. These suggestions are clear and actionable, providing the authors with concrete guidance on how to strengthen their work. However, the comment could be more helpful if it included more detailed examples or a broader range of suggestions. Overall, the feedback is mostly helpful as it offers valuable insights and constructive advice for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether the proposed method requires significantly more computation than other methods, given that the authors describe an online version of the algorithm due to the impracticality of training multiple iterations/epochs with large models and datasets. While the comment implies that the authors should compare the computational complexity of their method with others, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to perform a comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the authors describe an online version of the algorithm, allowing the authors to accurately identify the section being addressed. It is also specific because it requests a comparison of the computational complexity of the proposed method with other methods, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the computational complexity of the proposed method compared to other methods, which is a relevant concern for the authors to address. However, the comment does not provide any specific evidence, reasoning, or references to support the claim that the proposed method requires significantly more computation. Without additional context or justification, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a pertinent question about the computational complexity of the proposed method compared to other methods, which is a crucial aspect for evaluating the efficiency and practicality of the approach. By questioning whether the proposed method requires significantly more computation, the reviewer highlights a potential area for improvement or further analysis. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as providing a detailed comparison of computational complexity or suggesting alternative approaches. While the feedback identifies an important concern, it could be more helpful if it included actionable steps or examples to guide the authors in addressing the issue. Therefore, the comment is somewhat helpful, as it points out a relevant area for improvement but does not provide comprehensive guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a systematic study of the impact of the cost of incentivization on performance would be helpful. It provides specific examples, such as examining the reward incentives for different values of \\alpha and the collective return. The comment implies that the authors should conduct this analysis to address the concern about the emergence of roles between \"winners\" and \"cooperators.\" However, the comment does not explicitly instruct the authors to perform this analysis or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a systematic study of the impact of the cost of incentivization on performance, providing specific examples such as examining reward incentives for various values of \\u03b1 and the collective return. However, it does not explicitly mention which part of the paper this analysis should be conducted in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact section or part of the paper to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a systematic study of the impact of the cost of incentivization on performance would be helpful, providing specific examples such as examining reward incentives for various values of \\u03b1 and the collective return. The comment implies that the authors should conduct this analysis to address the concern about the emergence of roles between \"winners\" and \"cooperators.\" However, the comment lacks specific references or detailed reasoning to fully support the claim, making it somewhat verifiable. The authors would need to infer the basis for the suggestion, which could be improved with more detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests a systematic study of the impact of the cost of incentivization on performance, providing specific examples such as examining reward incentives for various values of \\u03b1 and the collective return. This feedback is somewhat helpful as it identifies a potential area for further analysis that could enhance the paper's depth and impact. However, the comment could be more helpful if it provided more detailed guidance on how to conduct this analysis or suggested specific methods for examining the relationship between incentivization cost and performance. Without these additional details, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the approach description in Section 3 is difficult to follow and recommends using the additional page of the camera-ready version to extend this description rather than adding more experiments. This provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve the clarity of the approach description. The comment is explicit and concrete, giving the authors a precise understanding of how to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the approach description in Section 3 is difficult to follow and recommends using the additional page of the camera-ready version to extend this description. However, it does not specify which part of Section 3 is particularly challenging or what specific issues need to be addressed. The authors cannot confidently determine which part of the paper is being referred to, making the comment weakly grounded. Additionally, while it suggests extending the description, it does not provide specific guidance on how to do so, leaving the authors with a vague idea of what to improve. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the approach description in Section 3 is difficult to follow and suggests using the additional page of the camera-ready version to extend it. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the description is difficult to follow or how the suggested extension would address this issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the approach description, noting that it is partially difficult to follow. It suggests that the additional page of the camera-ready version should be used to extend the approach description rather than adding more experiments. This feedback is clear and actionable, providing the authors with a specific direction for improving the clarity and completeness of their approach description. By recommending the use of the additional page, the comment offers a concrete suggestion for enhancing the draft, making it mostly helpful. However, it could be more helpful if it provided additional guidance on how to extend the description or what specific aspects to focus on. Overall, the comment is mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues with the experiments section: the lack of interpretive insights into why the proposed gyro-structures outperform existing methods and the absence of comparisons with other state-of-the-art methods that do not rely on gyro-structures. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The authors are left to infer that they need to include more detailed discussions and comparisons to strengthen the paper. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks concrete steps for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experiments part of the paper, specifically mentioning the lack of interpretive insights into why the proposed gyro-structures outperform existing methods. It also highlights the absence of comparisons with other state-of-the-art methods that do not rely on gyro-structures, making it unclear whether the proposed approach outperforms simpler or more commonly used techniques in manifold-based learning. However, the comment does not specify which part of the experiments section this issue is related to, such as specific tables or figures. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in detailing the issues with the experiments, such as the lack of interpretive insights and the absence of comparisons with other state-of-the-art methods. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments part lacks interpretive insights into why the proposed gyro-structures outperform existing methods. It also notes the absence of comparisons with other state-of-the-art methods that do not rely on gyro-structures, making it unclear whether the proposed approach outperforms simpler or more commonly used techniques. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of interpretive insights into why the proposed gyro-structures outperform existing methods. It also highlights the absence of comparisons with other state-of-the-art methods that do not rely on gyro-structures, making it unclear whether the proposed approach is truly superior. This feedback is valuable as it directs the authors to enhance the depth and comprehensiveness of their experimental analysis. However, the comment could be more helpful if it provided specific suggestions or examples of how to include additional comparisons or interpretive insights. Overall, the comment is somewhat helpful, as it directs the authors to areas for improvement but lacks detailed guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Figure 5 is difficult to comprehend and suggests that the authors should provide more details about the two baselines presented in the figure. It also notes that the study is limited to English-centric datasets and suggests that the authors could extend CATER to other languages in the future. While the comment explicitly mentions the need for more details about the baselines and suggests a potential future direction, it does not provide specific guidance on how to enhance the comprehensibility of Figure 5 or how to extend CATER to other languages. The action is somewhat vague, as the authors are left to infer the exact steps needed to address these issues. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed: the comprehensibility of Figure 5 and the need for more details about the two baselines. Additionally, the comment suggests extending CATER to other languages, which is a specific and actionable suggestion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 5 is hard to comprehend and suggests providing more details about the two baselines presented in the figure. It also notes that the study is limited to English-centric datasets and suggests extending CATER to other languages. While the comment identifies a potential issue with the comprehensibility of Figure 5 and suggests a future direction for the study, it lacks specific examples or detailed reasoning to fully substantiate these claims. The suggestion to extend CATER to other languages is somewhat vague, as it does not provide concrete guidance on how to achieve this. Therefore, the claim is somewhat verifiable, as it provides some basis for the feedback but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 5, noting that it is difficult to comprehend and lacks details about the two baselines presented. It also points out that the study is limited to English-centric datasets, which is a valid observation. The comment suggests extending CATER to other languages, which could be a valuable direction for future work. However, the feedback could be more helpful if it provided specific suggestions or guidance on how to improve the comprehensibility of Figure 5 or how to extend CATER to other languages. Overall, the comment is somewhat helpful as it highlights areas for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need for improvement in the literature review, specifically mentioning that it is unclear what the main contribution of the proposed method is and how it distinguishes itself from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. However, it does not provide specific guidance on how to improve the literature review or what aspects of the analysis need to be expanded. The action is implicit and vague, as the authors are left to infer the necessary steps to address the issue. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the need for improvement in the literature review, specifically mentioning that it is unclear what the main contribution of the proposed method is and how it distinguishes itself from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. However, the comment does not specify which part of the paper the literature review is located, making it weakly grounded. It is specific in detailing the issue with the literature review, such as the lack of clarity regarding the main contribution and the distinction from existing work. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the literature review is unclear and needs improvement, specifically regarding the main contribution of the proposed method and its distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or examples makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique to address it effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the lack of clarity in the literature review. It highlights that the main contribution of the proposed method and its distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation, are not adequately addressed. The comment suggests that the paper should provide a more explicit and comparative analysis of related work, which is a valuable piece of feedback for the authors. However, the comment could be more helpful if it provided specific examples or guidance on how to improve the literature review. Overall, the feedback is somewhat helpful as it points out an important area for improvement, but it lacks depth and specificity, leaving the authors with a clear direction to enhance their draft.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that section 3.2 can be eliminated, implying that readers are likely to be familiar with the Gumbel-Softmax/Concrete distribution. However, it does not provide any explicit guidance on how the authors should eliminate this section or what specific content should be removed. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that section 3.2 can be eliminated, implying that readers are likely familiar with the Gumbel-Softmax/Concrete distribution. However, it does not specify which part of the paper section 3.2 corresponds to, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment does not provide specific guidance on what content should be removed or how the elimination would impact the paper. As a result, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that section 3.2 can be eliminated because readers are likely familiar with the Gumbel-Softmax/Concrete distribution. However, the comment lacks specific reasoning or examples to support this claim. It does not provide any evidence or references to justify why this section might be redundant or unnecessary. Without detailed explanation or supporting evidence, the claim remains somewhat verifiable, as it lacks the depth needed for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that section 3.2 can be eliminated because readers are likely familiar with the Gumbel-Softmax/Concrete distribution. This feedback is somewhat helpful as it points out a potential area for simplification in the paper. However, it lacks specific guidance on which parts of section 3.2 could be removed or how the elimination would affect the overall understanding of the paper. The comment does not provide actionable advice or detailed suggestions, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests adding performance on word similarity and sentence translation tasks, referencing the MUSE paper, to enhance the credibility of the framework. It also mentions the inclusion of morphologically rich and low-resource languages in the experiments as additional points. However, the comment does not provide explicit instructions or detailed guidance on how to implement these suggestions, such as which specific metrics to use or how to conduct the experiments. The actions are implicit and somewhat vague, as the authors need to infer how to apply the suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding performance on word similarity and sentence translation tasks, referencing the MUSE paper, to enhance the credibility of the framework. It also mentions the inclusion of morphologically rich and low-resource languages in the experiments as additional points. However, the comment does not specify which part of the paper these suggestions relate to, such as specific sections or tables. This makes it difficult for the authors to identify the exact areas where these additions should be made. While the suggestions are specific, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding performance on word similarity and sentence translation tasks, referencing the MUSE paper, to enhance the credibility of the framework. It also recommends including morphologically rich and low-resource languages in the experiments. However, the comment lacks specific details or examples to support these suggestions, making it difficult for the authors to understand the reasoning behind the claims. Without clear justification or references, the claim is considered unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the experiments section by adding performance on word similarity and sentence translation tasks, referencing the MUSE paper. This addition would enhance the credibility and robustness of the framework. Additionally, the comment suggests including morphologically rich and low-resource languages in the experiments, which would broaden the scope and applicability of the research. However, the comment lacks detailed guidance on how to implement these suggestions, such as specific metrics or experimental designs. While the feedback is somewhat helpful in identifying areas for improvement, it could be more actionable with additional details. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment provides two specific actions for the authors to take: first, to explain the link between IP and the terms/equations more explicitly and prominently, and second, to include labels for subfigures in Figures 3 and 4 instead of just stating it in the captions. These actions are explicit and concrete, as they clearly instruct the authors on what needs to be done. The comment is fully actionable, as it provides precise guidance on how to improve the draft. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions Figures 3 and 4, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved: explaining the link between IP and the terms/equations more explicitly and prominently, and including labels for subfigures in Figures 3 and 4. This level of detail helps the authors understand exactly what changes are required. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts: first, it suggests that the link between IP and the terms/equations could be explained more explicitly and prominently, and second, it recommends including labels for subfigures in Figures 3 and 4. While the first part is somewhat verifiable as it implies the need for clearer explanation, the second part is fully verifiable as it provides specific guidance on how to improve the presentation of figures. However, the overall comment lacks a detailed rationale or examples to fully substantiate the claims, making it somewhat verifiable overall.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on two key areas: the clarity of the link between IP and the terms/equations, and the labeling of subfigures in Figures 3 and 4. By suggesting that the link should be explained more explicitly and prominently, the comment helps the authors improve the clarity and readability of their paper. Additionally, the recommendation to include labels for subfigures in Figures 3 and 4 addresses a specific presentation issue, which is crucial for the reader's understanding. The feedback is clear and constructive, offering concrete suggestions that the authors can easily implement. Therefore, the comment is mostly helpful, as it provides actionable and specific guidance for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to improve understanding of the trade-offs between annotation effort and training performance. While the comment implies that the authors should highlight these observations, it does not provide explicit instructions on how to do so. The action is somewhat explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the observations and conclusions are hidden in the experimental section, implying that the authors should highlight them. However, it does not specify which part of the experimental section contains these observations or conclusions, making it weakly grounded. The comment is specific in recommending highlighting these observations to improve understanding of the trade-offs between annotation effort and training performance. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to improve understanding of the trade-offs between annotation effort and training performance. However, the comment lacks specific examples or detailed reasoning to support why highlighting these observations would be beneficial. It does not provide any references or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting that the observations and conclusions are hidden in the experimental section. It suggests that highlighting these observations would enhance the reader's understanding of the trade-offs between annotation effort and training performance. While the comment provides a clear direction for improvement, it lacks specific guidance on how to highlight the observations or examples of what might be highlighted. This makes the feedback somewhat helpful, as it offers a general idea but could be more comprehensive with additional details or suggestions. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide ablation experiments to validate the model performance further, given that several modifications mentioned in Section 3.4 were used. This comment is explicit in its suggestion to conduct ablation experiments, which are necessary to validate the model performance. The action is clear and concrete, as it specifies exactly what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide ablation experiments to validate the model performance further, given that several modifications mentioned in Section 3.4 were used. However, it does not specify which part of the paper these modifications are detailed in, making it weakly grounded. The comment is specific in its suggestion to conduct ablation experiments, which would help validate the model performance. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide ablation experiments to validate the model performance further, given that several modifications mentioned in Section 3.4 were used. However, the comment lacks specific details or references to support why these ablation experiments are necessary or how they would validate the model performance. Without additional context or justification, the claim is difficult to verify, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors should provide ablation experiments to validate the model performance further, given that several modifications were mentioned in Section 3.4. This feedback is clear and actionable, as it directly points out the need for additional experiments to substantiate the effectiveness of the modifications. By providing ablation studies, the authors can better demonstrate the impact of these changes on the model's performance, enhancing the credibility and robustness of their results. However, the comment could be more helpful if it provided specific guidance on how to conduct these experiments or what metrics to use. Overall, the comment is mostly helpful as it identifies a crucial area for improvement and offers a clear direction for action.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance comparison of KDE and other approaches when the decision space is beyond binary. It references Remark 1 and a specific paper by Zhang et al. [44], suggesting that the authors should consider this comparison. However, the comment does not provide explicit instructions or detailed guidance on how to conduct this comparison or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment references \"Remark 1\" and a specific paper by Zhang et al. [44], suggesting that the authors should consider a performance comparison of KDE and other approaches when the decision space is beyond binary. However, the authors cannot confidently determine which part of the paper this remark is located in, as it is not explicitly mentioned. The comment is specific in its suggestion to compare performance on datasets with a decision space beyond binary, but the lack of grounding makes it difficult for the authors to identify the exact section or part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the performance comparison of KDE and other approaches when the decision space is beyond binary, referencing Remark 1 and a specific paper by Zhang et al. [44]. While the comment suggests that this comparison might be necessary, it does not provide a detailed explanation or justification for why this comparison is important or how it would impact the paper. The lack of specific reasoning or examples makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a question about the performance comparison of KDE and other approaches when the decision space is beyond binary, referencing Remark 1 and a specific paper by Zhang et al. [44]. While the comment identifies a potential area for further exploration, it does not provide specific guidance or suggestions on how to conduct this comparison or what aspects of the performance should be considered. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: \"How the capacity of the SR model affects the FID\" and \"since the proposed method is pipelining, there are some unexpected artifacts.\" While the first question prompts the authors to explore the relationship between model capacity and FID, it does not provide explicit guidance on how to address this. The second part acknowledges unexpected artifacts but does not offer specific suggestions or actions for the authors to take. The comment lacks explicit and concrete actions or suggestions for the authors to address these issues, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises two questions: \"How the capacity of the SR model affects the FID\" and \"since the proposed method is pipelining, there are some unexpected artifacts.\" However, it does not specify which part of the paper these questions relate to, such as specific sections, tables, or figures. This makes it difficult for the authors to identify the exact areas that need attention. While the questions are specific about the issues, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two questions: \"How the capacity of the SR model affects the FID\" and \"since the proposed method is pipelining, there are some unexpected artifacts.\" These questions are open-ended and do not contain specific claims or opinions that require verification. They are more like requests for clarification or further exploration, which do not align with the criteria for a claim. Therefore, the comment is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions about the impact of the SR model's capacity on the FID and notes the presence of unexpected artifacts due to the pipelining of the proposed method. While the questions highlight potential areas for further investigation and clarification, they do not provide specific guidance or suggestions on how to address these issues. The feedback is somewhat helpful as it identifies areas that require attention, but it lacks depth and actionable advice, making it only marginally helpful for the authors to improve their draft.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two main issues: the lack of content in Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It questions whether the proposition is merely an illustration of the partitioning principle of K-means and notes the absence of a \"proof.\" However, the comment does not provide explicit guidance on how the authors should address these issues, such as suggesting what content should be added to Appendix A or how to clarify the purpose of Proposition B.1. The feedback is vague and lacks concrete steps for improvement, making it difficult for the authors to know what actions to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the content of Appendix A, noting that it is left blank, and questions the purpose of Proposition B.1 in Appendix B, suggesting it may be merely an illustration of the partitioning principle of K-means. It also points out the absence of a \"proof.\" However, the comment does not specify which part of the paper Appendix A or Appendix B corresponds to, making it difficult for the authors to pinpoint the exact sections being referred to. While the comment is specific about the issues raised, the lack of grounding makes it challenging for the authors to understand which parts need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two main issues: the lack of content in Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It questions whether the proposition is merely an illustration of the partitioning principle of K-means and notes the absence of a \"proof.\" However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies two key issues with the paper: the lack of content in Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It questions whether the proposition is merely an illustration of the partitioning principle of K-means and notes the absence of a 'proof.' However, the comment does not provide specific suggestions or guidance on how the authors might address these issues, such as what content could be added to Appendix A or how to clarify the purpose of Proposition B.1. While it highlights important areas for improvement, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is rated as barely helpful, aligning with a score of 2.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. While it suggests that these experiments are needed, it does not provide explicit guidance on how to conduct them or what specific aspects of the paper should be compared or analyzed. The action is implicit and somewhat vague, as the authors need to infer that they should perform these experiments to address the lack of additional experiments. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. However, it does not specify which part of the paper these experiments are missing from or where they should be added. This makes it difficult for the authors to identify the exact areas that need improvement. The comment is fully grounded in terms of identifying the need for additional experiments but is not specific in detailing what is missing. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. However, it does not provide any specific reasoning or examples to support this claim. Without detailed justification or references to similar studies, the authors may find it challenging to understand why these experiments are necessary or how they would enhance the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is valuable as it highlights specific areas where the paper could be strengthened to provide a more comprehensive evaluation of the proposed method. However, the comment could be more helpful if it suggested specific ways to conduct these experiments or provided examples of how they could be implemented. Despite this, the comment offers a clear direction for improvement, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed model demonstrates impressive performance on many benchmarks, setting new SoTA scores. However, it points out that more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model through \"data curation\" processes. The comment implies that the authors should provide more details about the evaluation procedures to address this concern. While the action is implicit, it is clear that the authors need to provide more information about their evaluation methods to ensure the robustness of their results. The comment is somewhat actionable as it provides a clear direction for improvement, but it lacks specific guidance on what details to include in the evaluation procedures. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the proposed model demonstrates impressive performance on many benchmarks, setting new SoTA scores, but it highlights the need for more careful analysis, especially for \"old\" benchmarks where the data might have been indirectly seen by the model through \"data curation\" processes. It also recommends providing more details about the evaluation procedures. However, the comment does not specify which part of the paper discusses the evaluation procedures or the \"old\" benchmarks, making it weakly grounded. The comment is specific in its suggestion to provide more details about the evaluation procedures, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas that need improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed model demonstrates impressive performance on many benchmarks, setting new SoTA scores, but suggests that more careful analysis is needed, especially for \"old\" benchmarks where the data might have been indirectly seen by the model through \"data curation\" processes. The comment also recommends providing more details about the evaluation procedures. However, the claim lacks specific examples or references to support the need for more careful analysis, making it somewhat verifiable. The authors would need to provide more context or evidence to fully understand the reasoning behind the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges the impressive performance of the proposed model on several benchmarks, setting new SoTA scores. However, it suggests that a more careful analysis is needed, particularly for 'old' benchmarks where the data might have been indirectly seen by the model through 'data curation' processes. The comment also recommends providing more details about the evaluation procedures. This feedback is somewhat helpful as it highlights a potential area for improvement and suggests a specific aspect that requires further attention. However, it could be more helpful if it provided more detailed guidance on what specific aspects of the evaluation procedures need to be clarified or expanded upon. Overall, the comment offers a clear direction for improvement, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments lack collaborative games and recommends exploring the behavior of evaluated methods in both collaborative and competitive settings. While the comment implies that the authors should consider adding collaborative games to their experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add collaborative games to their experiments. However, the comment provides a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments lack collaborative games and recommends exploring the behavior of evaluated methods in both collaborative and competitive settings. However, it does not specify which part of the paper discusses the experiments or where the suggestion should be addressed. The authors cannot confidently determine which section or part of the paper this comment refers to, making it weakly grounded. The comment is specific in its suggestion to include collaborative games, but without grounding, the authors may struggle to apply it effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments lack collaborative games and recommends exploring the behavior of evaluated methods in both collaborative and competitive settings. However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is important or how it would enhance the paper. Without additional context or justification, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the experiments by suggesting the inclusion of collaborative games. This feedback is valuable as it points out a specific aspect that could enhance the comprehensiveness and depth of the study. However, the comment lacks detailed guidance on how to incorporate collaborative games or what specific aspects of the methods should be evaluated in this new setting. While it provides a direction for improvement, it does not offer a comprehensive or actionable suggestion, making it somewhat helpful. The authors would need to infer that they should consider adding collaborative games to their experiments, but the comment does not provide enough detail to fully address their needs. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with the paper, noting that the experimental settings for Figures 1 through 9 are missing, making it difficult for the authors to be convinced of the results. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue. It lacks concrete guidance on what specific information should be included or how the authors should present the experimental settings to make the figures more convincing. Without actionable steps or detailed guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figures 1 to 9,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly identifies the issue as the missing experimental settings for these figures, which makes them hard to be convincing. This provides the authors with a clear understanding of what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental settings for Figures 1 to 9 are missing, making it difficult for the authors to be convinced of the results. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the experimental settings are missing and how this impacts the persuasiveness of the figures. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the experimental settings for Figures 1 through 9 are missing, which makes it difficult for the authors to be convinced of the results. This feedback is clear and actionable, as it highlights a critical gap in the paper that needs to be addressed. However, the comment could be more helpful if it provided some guidance on how the authors might include or present the experimental settings to make the figures more convincing. Despite this, the comment is mostly helpful as it directs the authors to a specific area that requires improvement, allowing them to enhance the clarity and persuasiveness of their work. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the rationale behind the work, suggesting that some parameter isolation methods are specifically tailored to leverage sparsity. However, it does not provide explicit guidance on how the proposed method avoids impeding the learning of new task knowledge. The comment implies that the authors need to clarify this aspect, but it lacks concrete instructions on how to do so. Therefore, the comment is somewhat actionable, as it identifies a need for clarification but does not provide detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the rationale behind the work, specifically mentioning the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. It suggests pathway protection based on the sparsity exhibited by activation channels in deep networks. However, the comment does not specify which part of the paper this observation is made or where the authors discuss the proposed method in detail. This makes it weakly grounded, as the authors cannot confidently determine which section or part of the paper is being addressed. The comment is specific in that it highlights a potential issue with the rationale and suggests a clarification, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some parameter isolation methods are specifically tailored to leverage sparsity, which contradicts the authors' suggestion that their method avoids impeding the learning of new task knowledge. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand and address the issue. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it is based on an assumption without clear justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the rationale behind the work, specifically questioning how the proposed method avoids impeding the learning of new task knowledge. It highlights that some parameter isolation methods are tailored to leverage sparsity, which contradicts the authors' claim. However, the comment does not provide detailed guidance or suggestions on how the authors might address this issue or clarify their rationale. While it points out a potential weakness, it lacks actionable advice, making it somewhat helpful. The authors would need to infer how to improve their draft based on this feedback, which limits the comment's usefulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct comparisons with existing fairness algorithms in the experimental section. It provides a clear action for the authors to take, which is to integrate benchmark comparisons against state-of-the-art fairness algorithms. This action is explicit and concrete, as it specifies exactly what needs to be done to enhance the paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should conduct comparisons with existing fairness algorithms in the experimental section, which is a specific part of the paper. It provides a clear action for the authors to take, which is to integrate benchmark comparisons against state-of-the-art fairness algorithms. This action is fully grounded as it explicitly mentions the part of the paper where the comparison should be made, and it is specific in detailing what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should conduct comparisons with existing fairness algorithms in the experimental section to enhance the paper. This claim is somewhat verifiable as it suggests a logical improvement to the paper, but it lacks specific examples or references to existing fairness algorithms that could be used for comparison. Without concrete examples or references, the authors may find it challenging to understand how to implement the suggested improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the experimental section by pointing out the absence of comparisons with existing fairness algorithms. It suggests that integrating benchmark comparisons against state-of-the-art fairness algorithms would enhance the paper by providing tangible evidence of the proposed method's performance and positioning the ManyFairHPO framework within the existing FairML research landscape. This feedback is clear, actionable, and constructive, offering a specific direction for improvement that could significantly strengthen the paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should discuss the iteration cost of their proposed method and compare it with related methods, including baseline methods. While the comment provides a clear direction for the authors to improve their draft by addressing the computational budget and iteration cost, it does not specify which aspects of the iteration cost need to be discussed or how to compare it with other methods. The action is explicit but somewhat vague in terms of providing detailed guidance on implementation. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the authors should discuss the iteration cost of their proposed method and compare it with related methods, including baseline methods. However, it does not specify which part of the paper this discussion should be included in, making it difficult for the authors to identify the exact section to address. The comment is specific in its suggestion to discuss iteration cost and compare it with related methods, but it lacks grounding as it does not mention specific sections or parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should discuss the iteration cost of their proposed method and compare it with related methods, including baseline methods. However, the comment lacks specific details or references to support the claim that this discussion is necessary or beneficial. Without additional context or evidence, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should discuss the iteration cost of their proposed method and compare it with related methods, including baseline methods. This feedback is clear and actionable, as it provides a specific area for improvement by highlighting the importance of discussing computational efficiency. However, the comment could be more helpful if it offered additional guidance on how to analyze or present the iteration cost effectively. Overall, the comment is mostly helpful as it directs the authors to an important aspect of their work that needs attention.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors' reasoning for using the center correlation in Figure 4 A&B, despite stating on lines 80-82 that it was not insightful for discriminating model defenses. The comment implies that the authors should clarify why they found the metric useful in the figure and what they meant by the statement on lines 80-82. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and then determine how to address it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 80-82, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors are questioning, namely the use of the center correlation in Figure 4 A&B despite its stated lack of insight for discriminating model defenses. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the authors' reasoning for using the center correlation in Figure 4 A&B, despite stating on lines 80-82 that it was not insightful for discriminating model defenses. The comment implies that the authors should clarify why they found the metric useful in the figure and what they meant by the statement on lines 80-82. However, the comment does not provide any specific examples, reasoning, or references to support the claim that the center correlation is useful in this context. This lack of detailed explanation or justification makes the claim somewhat verifiable, as the authors would need to infer the reasoning behind the use of the metric. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid question about the use of the center correlation in Figure 4 A&B, despite the authors' claim that it was not insightful for discriminating model defenses. This feedback highlights a potential inconsistency or lack of clarity in the paper, prompting the authors to reconsider their approach and provide a more detailed explanation of why they chose to use this metric. By identifying this inconsistency, the comment encourages the authors to improve the clarity and coherence of their presentation, making it somewhat helpful. However, the comment could be more helpful if it provided specific guidance on how to address the issue or what additional context might be needed. Therefore, it is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the name used to describe a phenomenon, suggesting that \"distributional generalization\" might be too strong and that the empirical phenomenon is better described as the ideal of the total variation between the test and train distributions of the network\u2019s outputs vanishing to zero. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to the paper. The action is implicit, as the authors would need to infer that they should reconsider the name or provide a more nuanced description of the phenomenon. The comment is somewhat actionable because it points out a specific issue but lacks concrete details on how to implement the suggested changes. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the name used to describe a phenomenon, suggesting that \"distributional generalization\" might be too strong and that the empirical phenomenon is better described as the ideal of the total variation between the test and train distributions of the network\u2019s outputs vanishing to zero. However, the comment does not specify which part of the paper discusses this phenomenon, making it weakly grounded. It is specific in detailing what the issue is and why the name might be problematic, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the name \"distributional generalization\" used to describe a phenomenon, suggesting that it might be too strong and that the empirical phenomenon is better described as the ideal of the total variation between the test and train distributions of the network\u2019s outputs vanishing to zero. The comment provides a logical explanation for why the name might be too strong, but it lacks specific examples or references to support the claim. Without detailed reasoning or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the name used to describe a phenomenon, suggesting that \"distributional generalization\" might be too strong and that the empirical phenomenon is better described as the ideal of the total variation between the test and train distributions of the network\u2019s outputs vanishing to zero. This feedback is somewhat helpful as it points out a specific area for improvement and provides a clear rationale for why the current name might be misleading. However, the comment could be more helpful if it offered suggestions for alternative names or ways to clarify the phenomenon's description. Overall, the comment provides a valuable insight that could guide the authors in refining their terminology and enhancing the clarity of their work. Therefore, it is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the use of \"above/below diagonal\" versus \"above/below 45 degree\" for labeling elements in a plot, suggesting that the former is easier to interpret. However, it does not provide explicit guidance on how the authors should implement this change or any other specific actions to improve their draft. The comment lacks concrete instructions or suggestions, leaving the authors uncertain about how to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the use of \"above/below diagonal\" versus \"above/below 45 degree\" for labeling elements in a plot, suggesting that the former is easier to interpret. However, it does not specify which part of the paper this critique refers to, such as a particular figure or table. This lack of grounding makes it difficult for the authors to identify the exact section being addressed. While the comment is specific in its critique of the labeling method, the absence of explicit grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the use of \"above/below diagonal\" versus \"above/below 45 degree\" for labeling elements in a plot, suggesting that the former is easier to interpret. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the use of \"above/below diagonal\" versus \"above/below 45 degree\" for labeling elements in a plot, suggesting that the former is easier to interpret. This feedback is specific and provides a clear point of comparison, which could help the authors improve the clarity and effectiveness of their visualizations. However, the comment lacks broader guidance on how to enhance the overall presentation or structure of the paper. While it offers a specific suggestion, it does not provide a comprehensive set of recommendations or address other potential areas for improvement. Therefore, the comment is somewhat helpful, as it offers a focused critique but could be more comprehensive to fully assist the authors in enhancing their draft.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the scientific insight gained from the proposed model and formalism compared to prior task-optimized approaches. It specifically asks for clarification on whether the model, as described in Section 2.3, serves as a prototype approximation for non-linear RNN models exhibiting emergent behavior. The comment implies that the authors should provide a clearer explanation of how their work offers additional insights or explanations beyond what is already known. However, the comment does not explicitly instruct the authors to address these questions or provide specific guidance on how to improve the clarity of their explanation. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the scientific insight and provide a more detailed explanation of the model's relevance. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the scientific insight gained from the model and formalism compared to prior task-optimized approaches, and it highlights a specific issue with the model formulation in Section 2.3. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the scientific insight gained from the proposed model and formalism compared to prior task-optimized approaches. It specifically asks for clarification on whether the model, as described in Section 2.3, serves as a prototype approximation for non-linear RNN models exhibiting emergent behavior. The comment implies that the authors should provide a clearer explanation of how their work offers additional insights or explanations beyond what is already known. However, the comment lacks specific examples or detailed reasoning to support the claim that the model does not serve as a prototype approximation. Without additional context or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical question about the scientific insight gained from the proposed model and formalism compared to prior task-optimized approaches. It specifically points out that the model, as described in Section 2.3, is not shown to be a prototype approximation for non-linear RNN models that exhibit emergent behavior. This raises concerns about whether the work provides additional explanations or insights beyond what is already known. The comment is somewhat helpful as it identifies a key area for clarification and encourages the authors to provide a more detailed explanation of the model's relevance and scientific contribution. However, it could be more helpful if it provided specific suggestions or guidance on how to address this issue. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the experimental results, suggesting that replacing normal convolutions with adaptive convolutions is not always beneficial. It points out that the placement of adaptive convolutions is important but notes the absence of analysis or comments on this aspect. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take. The action is implicit and somewhat vague, as the authors are left to infer that they need to analyze the importance of adaptive convolution placement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table-3\" and \"ACNN-v3\" and \"ACNN-v2\", allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a discrepancy in the experimental results, noting that ACNN-v3 performed worse than ACNN-v2, and points out the lack of analysis regarding the placement of adaptive convolutions. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that replacing normal convolutions with adaptive convolutions is not always beneficial, based on the experimental results presented in Table-3. It highlights a specific observation that ACNN-v3 performed worse than ACNN-v2, suggesting that the placement of adaptive convolutions is important. However, the comment lacks detailed reasoning or examples to fully support the claim. While it provides a basis for the argument, it does not offer a comprehensive explanation or evidence to substantiate the claim fully. Therefore, the comment is somewhat verifiable, as it provides some justification but lacks depth and detail.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the experimental results, specifically noting that replacing normal convolutions with adaptive convolutions is not always beneficial. It highlights a discrepancy in Table-3, where ACNN-v3 performed worse than ACNN-v2, suggesting that the placement of adaptive convolutions is important. However, the comment does not provide detailed analysis or suggestions on how the authors might address this issue or improve their experimental design. While it points out a gap in the analysis, it lacks actionable guidance or specific recommendations for the authors to enhance their work. Therefore, the comment is somewhat helpful, as it provides a clear observation but does not offer comprehensive feedback or suggestions for improvement.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the discussion section could benefit from including a brief discussion on the empirical motivation for using time-varying Q^t and S_t, as opposed to a fixed approach. It provides specific examples, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals. However, it does not explicitly instruct the authors to include this discussion or provide detailed guidance on how to incorporate it into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should add this discussion and understand the specific aspects to address. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including a brief discussion on the empirical motivation for using time-varying Q^t and S_t, as opposed to a fixed approach, and provides specific examples to consider. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including a brief discussion on the empirical motivation for using time-varying Q^t and S_t, as opposed to a fixed approach, and provides specific examples to consider. However, it lacks detailed reasoning or references to support why this discussion is necessary or how it would enhance the paper. The comment does not provide specific examples or evidence to justify the claim, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by suggesting that the discussion section could benefit from including a brief discussion on the empirical motivation for using time-varying Q^t and S_t, as opposed to a fixed approach. It offers specific examples, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals, which could guide the authors in enhancing their discussion. However, the comment could be more helpful if it provided additional guidance on how to conduct this analysis or what specific data or experiments would be relevant. Overall, the comment is somewhat helpful as it identifies a meaningful area for improvement and offers some direction, but it could be more comprehensive with additional details.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concerns about the paper's readability and the lack of clear intuition connecting the pieces, as well as the limited context provided by the experiments. However, it does not explicitly suggest specific actions or provide detailed guidance on how to improve the paper. The authors are left to infer that they need to enhance the clarity of the presentation and provide more context for the experiments. While the comment identifies a general issue, it lacks concrete suggestions or detailed guidance on how to address it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment expresses concerns about the paper's readability and the lack of clear intuition connecting the pieces, as well as the limited context provided by the experiments. However, it does not specify which part of the paper is difficult to follow or lacks context. The authors cannot confidently determine which sections or aspects of the paper are being referred to, making the comment weakly grounded. Additionally, the comment is somewhat specific in that it identifies the issues with clarity and context, but without explicit references to sections or figures, it remains weakly grounded and specific. Therefore, this comment aligns with the label 3: Weakly Grounded and Specific.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses concerns about the paper's readability and the lack of clear intuition connecting the pieces, as well as the limited context provided by the experiments. However, it does not provide specific examples, references, or detailed reasoning to support these claims. The authors are left to infer the issues, which makes the comment somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper's readability, noting that it is not particularly easy to follow and lacks a clear intuition for how the pieces fit together. Additionally, the reviewer points out that the experiments have little context, which can make it difficult for readers to understand their relevance. While the comment highlights these areas for improvement, it does not provide specific suggestions or guidance on how to enhance the clarity or provide more context for the experiments. The feedback is somewhat helpful as it directs the authors to areas that need attention, but it lacks depth and actionable advice, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scaling of the refined region vector and suggests an alternative approach by introducing a scaling variable before the attention weight. While the comment implies that the authors should consider this alternative, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given a clear direction on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider, namely the scaling of the refined region vector and the suggestion of introducing a scaling variable before the attention weight. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the scaling of the refined region vector and suggests an alternative approach by introducing a scaling variable before the attention weight. While the comment provides a specific question and suggestion, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the implications and potential benefits of the suggested change, which could be more effectively supported with additional explanation or evidence. Therefore, the comment is rated as borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific aspect of the paper that could be improved by questioning the scaling of the refined region vector. It suggests an alternative approach by introducing a scaling variable before the attention weight, which could potentially enhance the model's performance. However, the comment lacks depth and does not provide detailed reasoning or examples to support the claim. While it offers a direction for improvement, it does not fully guide the authors on how to implement or evaluate the suggested change. Therefore, the comment is somewhat helpful, as it provides a starting point for the authors to consider but lacks comprehensive guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue related to goal misspecification in the ALFRED benchmark, noting that the LLM did not accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might improve their draft to address this problem, such as suggesting specific changes or improvements to the methodology or experimental setup. Without actionable steps or suggestions, the authors are left without a clear path to resolve the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to goal misspecification in the ALFRED benchmark, noting that failures occurred due to the LLM's inability to accurately recover the formal goal predicate, especially with ambiguities in human language. However, the comment does not specify which part of the paper this issue is discussed in, such as a particular section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in detailing the problem, the absence of explicit grounding information makes it challenging for the authors to understand where to focus their improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that failures on the ALFRED benchmark often occurred due to goal misspecification, where the LLM did not accurately recover the formal goal predicate, especially when faced with ambiguities in human language. This claim is somewhat verifiable as it provides a specific example of a problem observed in the ALFRED benchmark, but it lacks detailed reasoning or references to support the claim fully. The authors could benefit from additional evidence or examples to strengthen the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue related to goal misspecification in the ALFRED benchmark, noting that the LLM did not accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. This feedback is somewhat helpful as it highlights a potential area for improvement in the draft, specifically regarding the clarity and accuracy of goal specification. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue, such as proposing specific changes or improvements to the methodology or experimental setup. Without detailed guidance, the authors may find it challenging to effectively incorporate this feedback into their work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns: the small improvement of the proposed method over SOTA methods like IGEV and the question of whether there is a multi-peak distribution problem in iterative optimization schemes similar to IGEV. The comment suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. It also raises a concern about the difficulty of Sampling-Gaussian to significantly improve such frameworks. However, the comment does not provide explicit guidance on how the authors should analyze the distribution or address the concern about the difficulty of improvement. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises two specific concerns about the improvement of the proposed method over SOTA methods like IGEV and questions the existence of a multi-peak distribution problem in iterative optimization schemes similar to IGEV. However, it does not explicitly mention which part of the paper these concerns relate to, making it weakly grounded. The comment is specific in detailing the concerns and suggesting an analysis of disparities, but without explicit references to sections or figures, the authors may struggle to identify the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two questions about the improvement of the proposed method over SOTA methods like IGEV and the existence of a multi-peak distribution problem in iterative optimization schemes similar to IGEV. The first question suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. This implies a need for a detailed analysis, but it lacks specific examples or references to support the claim. The second part of the comment raises a concern about the difficulty of Sampling-Gaussian to significantly improve such frameworks, but it does not provide any evidence or reasoning to support this claim. Overall, the comment is somewhat verifiable as it provides some direction but lacks detailed justification or references, making it difficult for the authors to fully understand and address the concerns.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two main concerns: the small improvement of the proposed method over SOTA methods like IGEV and the question of whether there is a multi-peak distribution problem in iterative optimization schemes similar to IGEV. The comment suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. This provides a clear direction for the authors to investigate and address the issue. However, the comment lacks specific guidance on how to conduct this analysis or what specific aspects to focus on, which limits its helpfulness. Additionally, the concern about the difficulty of Sampling-Gaussian to significantly improve such frameworks is raised but not elaborated upon, leaving the authors with limited actionable insights. Overall, the comment is somewhat helpful as it identifies areas for improvement but could be more comprehensive and detailed to fully assist the authors.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the notations $h, g$ and $\\delta$ are introduced without clear definitions of their input and output domains. While the comment identifies a specific issue with the clarity of the notations, it does not provide explicit guidance on how the authors should address this problem. The authors are left to infer that they need to clarify the notations, but the comment lacks concrete instructions on how to do so. Therefore, the comment is somewhat actionable, as it identifies a clear area for improvement but does not provide detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the notations $h, g$ and $\\delta$ by pointing out that their input and output domains are not clearly defined. However, it does not specify which part of the paper these notations are introduced in, making it difficult for the authors to pinpoint the exact location. The comment is specific in detailing the problem with the notations but lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a specific issue with the notations $h, g$ and $\\delta$ by pointing out that their input and output domains are not clearly defined. This is a factual observation that requires no further verification or explanation. The comment is clear and specific, making it fully verifiable. Therefore, the label is 5.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notations $h, g$ and $\\delta$ by pointing out that their input and output domains are not clearly defined. This is a clear and actionable feedback that helps the authors improve the clarity and precision of their notation usage. However, the comment could be more helpful if it provided additional guidance on how to define these domains or suggested specific ways to improve the clarity of the notation. Despite this, the feedback is mostly helpful as it directs the authors to a critical area for improvement, allowing them to enhance the quality of their paper.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the paper, noting that it is unclear how much performance gain is attributed to the task formulation versus the use of pre-trained language models. It suggests including results using the GCPG model without pre-trained initializations to address this ambiguity. While the comment identifies a clear action\u2014performing additional ablation studies\u2014it does not provide explicit guidance on how to conduct these studies or what specific results to include. The action is somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"missing ablations,\" which allows the authors to accurately identify the part of the paper being addressed. It specifies the issue by questioning the attribution of performance gains to the task formulation versus pre-trained language models, suggesting the inclusion of results using the GCPG model without pre-trained initializations. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the attribution of performance gains in the paper, specifically questioning whether the gains are due to the task formulation or the use of pre-trained language models. While the comment does not provide a direct claim or suggestion, it implies that the authors should consider including results using the GCPG model without pre-trained initializations to address this ambiguity. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the need for additional experiments to address the issue, which limits the verifiability of the comment.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue in the paper, specifically the lack of clarity regarding the attribution of performance gains. It questions whether the observed improvements are due to the task formulation or the use of pre-trained language models. The comment suggests including results using the GCPG model without pre-trained initializations to address this ambiguity. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by conducting additional experiments. However, the comment could be more helpful if it included suggestions on how to conduct these experiments or what specific results to focus on. Overall, the comment is mostly helpful, as it offers valuable guidance for the authors to enhance the clarity and robustness of their findings.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a difficulty in understanding the axes of Figure 1, but it does not provide any explicit or implicit suggestions on how to address this issue. The authors are left without guidance on how to clarify the axes or improve the figure's clarity. As a result, the comment lacks actionable information, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper Figure 1 is located in, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment is specific in that it points out a lack of clarity regarding the axes of the figure, which is a clear issue that needs to be addressed. However, without specific guidance on how to improve the clarity of the axes, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point states that it is hard to understand what the axes are for Figure 1. This is a subjective observation about the clarity of the figure, but it does not provide any specific reasoning or examples to support why this is a problem. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of Figure 1, noting that it is difficult to understand what the axes represent. This feedback is clear and actionable, as it directly points out a potential problem with the figure's presentation. However, it lacks broader context or suggestions on how to improve the clarity of the axes, such as adding labels or explanations. While the comment is helpful in identifying a specific area for improvement, it could be more helpful if it provided additional guidance or suggestions. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the results on ImageNet could be more convincing of the proposed method. However, it does not provide any specific guidance or action for the authors to take to improve the results. The comment lacks explicit instructions on how to enhance the results or what specific steps should be taken to make them more convincing. As a result, the authors are left without a clear understanding of how to address the feedback, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that results on ImageNet could be more convincing of the proposed method. However, it does not specify which part of the paper discusses the results on ImageNet or provide any details on how to make them more convincing. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide guidance on how to improve the results or what aspects need to be considered. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that results on ImageNet could be more convincing of the proposed method. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left to interpret the comment, making it difficult to understand and address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the results on ImageNet could be more convincing of the proposed method. While this feedback provides a direction for improvement, it lacks specific guidance or suggestions on how to enhance the results or what aspects of the results might need to be strengthened. The comment is somewhat helpful as it identifies a potential area for improvement, but it does not offer detailed or actionable advice, leaving the authors with limited insight into how to address the feedback effectively. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of direct runtime comparisons with existing methods, suggesting that such comparisons are necessary to demonstrate the efficiency of the proposed approach. It implies that the authors should include these comparisons to provide a more comprehensive evaluation of their method. However, the comment does not specify which existing methods should be compared or how the comparisons should be conducted, leaving the action somewhat vague. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of missing direct runtime comparisons with existing methods, which is a specific aspect of the paper. It highlights the importance of these comparisons to demonstrate the efficiency of the proposed approach. However, the comment does not explicitly mention which part of the paper discusses the runtime comparisons or where these comparisons should be included. This makes it weakly grounded, as the authors may need to infer the specific section or part of the paper being addressed. The comment is specific in detailing the need for these comparisons, but the lack of explicit grounding makes it weakly grounded and specific. Therefore, the comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that direct runtime comparisons with existing methods are missing, which is a valid concern as it is essential for demonstrating the efficiency of the proposed approach. The comment provides a logical reasoning by stating that implicit differentiation usually requires additional computational costs, thus necessitating direct runtime comparisons. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would benefit from additional evidence or references to strengthen the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of direct runtime comparisons with existing methods. This is a crucial aspect for evaluating the efficiency and practicality of the proposed approach. By highlighting this omission, the comment provides a clear and actionable suggestion for the authors to include these comparisons, which would strengthen the paper\\'s claims and provide a more comprehensive evaluation of the proposed method. However, the comment could be more helpful if it suggested specific methods for comparison or provided guidance on how to conduct these comparisons effectively. Overall, the comment is mostly helpful as it directs the authors to an important area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the proposed framework is a simple combination of meta-learning and federated learning and that it lacks any technical contribution. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment does not suggest how the authors might enhance the technical contribution of their framework or what specific aspects need to be improved. As a result, the authors are left without guidance on how to respond to this feedback, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section or aspect being discussed. It is also not specific because it does not detail what the authors should do to address the issue of the framework being a simple combination of meta-learning and federated learning. The comment lacks both grounding and specificity, making it unsuitable for guiding the authors effectively. Therefore, this comment is rated as 1: Not Grounded.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed framework is a simple combination of meta-learning and federated learning and that it lacks any technical contribution. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why the framework is considered a simple combination or how it lacks technical contribution. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed framework, suggesting that it is a simple combination of meta-learning and federated learning and lacks any technical contribution. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the technical contribution of their framework. Without actionable feedback or suggestions, the authors may find it challenging to improve their draft based on this comment alone. Therefore, the comment is rated as barely helpful, as it highlights a concern but does not offer substantial assistance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a major concern about the sufficiency of the paper's contribution, suggesting that it primarily focuses on studying the connection between complementary and model robustness without providing further insights or solutions on how to leverage this connection to improve model robustness. The comment implies that the conclusion could be easily obtained and suggests that the paper lacks insightful findings or possible solutions. However, it does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve the paper. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the analysis and provide more insightful findings or solutions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a major concern about the sufficiency of the paper's contribution, specifically questioning whether the authors have adequately explored how to leverage the connection between complementary and model robustness to improve model robustness. However, the comment does not specify which part of the paper addresses this issue, making it difficult for the authors to pinpoint the exact section or aspect that needs improvement. While the comment is specific in its critique of the contribution, it lacks grounding as it does not provide clear guidance on which part of the paper should be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sufficiency of the paper's contribution, specifically questioning whether the authors have adequately explored how to leverage the connection between complementary and model robustness to improve model robustness. The comment suggests that the conclusion could be easily obtained and implies a lack of insightful findings or solutions. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional evidence or justification, the authors may find it challenging to fully understand and address the concern. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a significant concern about the sufficiency of the paper's contribution, specifically questioning whether the authors have adequately explored how to leverage the connection between complementary and model robustness to improve model robustness. The comment suggests that the conclusion could be easily obtained and implies a lack of insightful findings or solutions. While the comment identifies a critical gap in the paper's contribution, it lacks specific guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it highlights an important area for improvement, but it could be more actionable with additional details or recommendations. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of focusing on which clusters are \"best\" rather than the differences in representation between them, given the paper\\'s motivation. While it raises a valid concern about the focus, it does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit, as the authors would need to infer that they should consider the differences in representation and potentially adjust their focus. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the choice of focusing on which clusters are \"best\" rather than the differences in representation between them, given the paper\\'s motivation. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the focus, the absence of grounding information limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of focusing on which clusters are \"best\" rather than the differences in representation between them, given the paper\\'s motivation. This is a subjective opinion that raises a valid concern about the focus of the paper. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a valid concern about the focus of the paper, specifically questioning why the authors chose to focus on which clusters are \"best\" rather than the differences in representation between them. This critique is relevant to the paper\\'s motivation and could provide valuable insight for the authors to consider in revising their approach. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what changes could be made to better align with the paper\\'s motivation. While it identifies an important point, the feedback could be more helpful if it provided actionable advice or examples of how to improve the focus of the paper. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out several issues with the organization and presentation of the paper, such as the small font size of annotations in Figure 1 and Figure 2, the lack of explicitness in the figures, the incorrect placement of Table 2, and the incorrect format of the top two lines on page 6. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors are left to infer how to make the necessary changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1 and Figure 2\" and \"Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the font size, explicitness of figures, and incorrect placement of Table 2. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not well organized and the layout is rushed, citing specific issues such as small font sizes in Figure 1 and 2, lack of explicitness in the figures, incorrect placement of Table 2, and incorrect formatting on page 6. While the comment provides specific examples of these issues, it lacks detailed reasoning or references to support the claim that these issues significantly impact the paper's organization or presentation. The authors are left to infer the significance of these observations, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several issues with the organization and presentation of the paper, such as the small font size of annotations in Figure 1 and Figure 2, the lack of explicitness in the figures, the incorrect placement of Table 2, and the incorrect format of the top two lines on page 6. While the comment provides specific examples of these problems, it lacks detailed guidance on how the authors might address these issues or what specific changes would be beneficial. The feedback is somewhat helpful as it highlights areas for improvement, but it could be more actionable with additional suggestions or recommendations. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights an issue with the notation {\\cal P} with a subscript being used multiple times in the same section without being defined. This feedback is explicit, as it directly points out a lack of definition for the notation, which the authors should address. The action is also concrete, as it clearly specifies what needs to be done: define the notation {\\cal P} with a subscript. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment points out an issue with the notation {\\cal P} with a subscript being used multiple times in the same section without being defined. This provides full grounding as the authors can accurately identify the section where the issue occurs. The comment is also specific, as it clearly specifies what needs to be addressed: the lack of definition for the notation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights an issue with the notation {\\cal P} with a subscript being used multiple times in the same section without being defined. This is a factual observation that requires no further explanation or justification to be understood. The comment does not contain any subjective opinions or suggestions, making it a factual statement. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that the notation {\\cal P} with a subscript is used multiple times in the same section without being defined. This is a clear and actionable feedback that highlights a lack of clarity in the notation, which could hinder the reader's understanding of the content. By pointing out this issue, the comment provides the authors with a specific area to address and improve the clarity of their paper. However, the comment could be more helpful if it suggested ways to define the notation or how to ensure consistency in its usage. Overall, the feedback is somewhat helpful as it identifies a clear issue that needs attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the clarity and consistency of the paper. It questions the definition of \"upper faces\" of the convex hull, suggesting that the dual subdivision and projection \u03c0 need to be explained better. Additionally, it points out that the variable 'p' is not explicitly defined, which is problematic given its extensive use throughout the paper. The comment implies that moving the definition of 'p' would improve the paper, but it does not provide specific guidance on how to address the issues with the \"upper faces\" or the projection \u03c0. While the authors can infer that they need to clarify these concepts, the lack of explicit instructions or detailed guidance makes the comment somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises specific issues regarding the clarity of certain concepts in the paper, such as the \"upper faces\" of the convex hull and the variable 'p' in the context of decision boundaries of neural networks. It suggests that the dual subdivision and projection \u03c0 need to be explained better, and that the variable 'p' should be explicitly defined. However, the comment does not specify which part of the paper these issues are located in, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in its suggestions, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises specific questions about the clarity of certain concepts in the paper, such as the \"upper faces\" of the convex hull and the variable 'p' in the context of decision boundaries of neural networks. It suggests that the dual subdivision and projection \u03c0 need to be explained better, and that the variable 'p' should be explicitly defined. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. The lack of evidence or justification makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper could be improved, such as the clarity of the \"upper faces\" of the convex hull and the definition of the variable 'p'. It provides actionable feedback by suggesting that the authors should explain the dual subdivision and projection \u03c0 better and explicitly define the variable 'p'. However, the comment could be more helpful if it offered additional guidance on how to improve the clarity of these concepts or provided examples of how to better explain them. While the feedback is somewhat helpful, it lacks depth and could be expanded to provide more comprehensive suggestions. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the separate treatment of images and their augmentations, suggesting that they might be interchangeable. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what changes they should consider making to their draft. Without specific suggestions or instructions, the authors are left without a clear path to improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a concern about the separate treatment of images and their augmentations, suggesting that they might be interchangeable. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to address this concern or what changes might be necessary. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point expresses a concern about the separate treatment of images and their augmentations, suggesting that they might be interchangeable. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the separate treatment of images and their augmentations, suggesting that they might be interchangeable. However, the comment lacks specific details or suggestions on how the authors might address this concern or what changes could be made to their draft. Without actionable guidance or examples, the authors may find it difficult to understand the implications of this feedback or how to improve their work. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that some pieces of the paper use existing methods, specifically mentioning equation (12), and notes that the presentation of these methods is vague, requiring the authors to check the original paper to understand them. While the comment identifies a potential issue with the clarity of the presentation, it does not provide explicit guidance on how the authors should address this problem. The authors are left to infer that they need to improve the clarity of their presentation, but without specific instructions on how to do so, the action remains implicit and somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"some pieces\" and \"equation (12),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies that the presentation of these methods is vague and requires checking the original paper for understanding. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some pieces of the paper use existing methods, specifically mentioning equation (12), and notes that the presentation of these methods is vague, requiring the authors to check the original paper to understand them. While the comment identifies a potential issue with the clarity of the presentation, it lacks specific examples or references to support the claim. The authors are left to infer that the presentation needs improvement, but without detailed guidance or evidence, the claim is somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of certain pieces of the paper, noting that some methods are using existing approaches and that their presentation is vague, requiring the authors to consult the original paper to understand them. This feedback is clear and actionable, as it highlights a potential area for improvement in the clarity and organization of the paper. However, the comment could be more helpful if it provided suggestions on how the authors might improve the presentation or clarify the methods. Despite this, the comment offers valuable guidance for the authors to enhance the readability and understanding of their work. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the writing and presentation of the paper, noting that it is \"jumbled at times.\" However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on what aspects of the writing are jumbled or how the authors can improve the clarity and organization of their presentation. Without concrete suggestions or actionable steps, the authors are left without a clear path to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a concern about the writing and presentation of the paper, noting that it is \"jumbled at times.\" However, it does not specify which part of the paper is affected by this issue, making it difficult for the authors to pinpoint the exact areas that need improvement. The comment lacks specificity in identifying the sections or aspects of the paper that are jumbled, and it does not provide any guidance on how to address this issue. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a subjective opinion about the writing and presentation of the paper, noting that it is \"jumbled at times.\" This is a subjective assessment and lacks specific evidence or reasoning to support the claim. Without detailed examples or references, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a concern about the writing and presentation of the paper, noting that it is \"jumbled at times.\" However, the comment lacks specificity and does not provide any actionable suggestions or guidance on how the authors might improve the clarity or organization of their writing. Without concrete examples or detailed feedback, the authors are left without a clear understanding of what aspects of the paper need revision. As a result, the comment is barely helpful, as it does not offer any meaningful insights or actionable advice to the authors.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the stability definition needs better justification, specifically pointing out that the left side can be arbitrarily small under certain constructions of \\\\(\\\\tilde{g}\\\\). It proposes a more reasonable treatment by making the definition lower bounded. While the comment provides a clear action\u2014improving the justification of the stability definition\u2014it does not specify how to achieve this improvement. The suggestion to make the definition lower bounded is concrete, but the lack of detailed guidance on how to implement this change makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the stability definition, which is a specific part of the paper. It provides a clear and specific suggestion to improve the justification of the definition by making it lower bounded. This allows the authors to accurately identify the part of the paper being addressed and understand the specific issue that needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the stability definition needs better justification, specifically noting that the left side can be arbitrarily small under some construction of \\\\(\\\\tilde{g}\\\\). The comment suggests making the definition lower bounded as a more reasonable treatment. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, as it does not provide detailed explanations or evidence to substantiate the claim. Therefore, the comment is rated as borderline verifiable, as it provides a basis for improvement but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the stability definition, noting that the left side can be arbitrarily small under certain constructions of \\\\(\\\\tilde{g}\\\\). It suggests that the definition should be made lower bounded for a more reasonable treatment. This feedback is clear and actionable, providing the authors with a specific direction to improve their work. However, it could be more helpful if it included additional suggestions or examples of how to implement the lower bound. Overall, the comment is mostly helpful as it offers a clear and actionable improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the importance of the annealing scheme in Section 4, particularly when $\\alpha$ is not decreased to 0. It suggests that this scheme might introduce a bias that could outweigh the bias reductions achieved by using IWAE. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or what changes could be made to the annealing scheme. The action is implicit and vague, as it does not specify how the authors should investigate or resolve the issue. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the importance of the annealing scheme in Section 4, specifically when $\\alpha$ is not decreased to 0. It suggests that this scheme might introduce a bias that could outweigh the bias reductions achieved by using IWAE. However, the comment does not specify which part of Section 4 is being referred to, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific in its questioning of the annealing scheme's importance, the lack of explicit grounding makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the importance of the annealing scheme in Section 4, particularly when $\\alpha$ is not decreased to 0. It suggests that this scheme might introduce a bias that could outweigh the bias reductions achieved by using IWAE. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the importance of the annealing scheme in Section 4, particularly when $\\alpha$ is not decreased to 0. It suggests that this scheme might introduce a bias that could outweigh the bias reductions achieved by using IWAE. However, the comment does not provide any specific guidance or suggestions on how the authors might address this concern or what changes could be made to the annealing scheme. While it identifies a potential issue, it lacks actionable advice or detailed reasoning, making it barely helpful. The authors would need to infer how to improve their draft based on this feedback, which limits its usefulness. Therefore, the comment is rated as barely helpful.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the computational complexity of the proposed method compared to other methods, specifically mentioning emerging convolutions. It also suggests considering the power demand on a mobile device. However, the comment does not provide explicit guidance on how to address this concern or what specific actions the authors should take to improve their draft. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to respond. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the computational complexity of the proposed method compared to other methods, specifically mentioning emerging convolutions. It also suggests considering the power demand on a mobile device. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in its inquiry about computational complexity and power demand, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the computational complexity of the proposed method compared to other methods, specifically mentioning emerging convolutions. It also suggests considering the power demand on a mobile device. However, the comment does not provide any evidence, reasoning, or references to support the claim that the computational complexity is a concern or that it could cause significant power demand on a mobile device. Without specific examples or references, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the computational complexity of the proposed method compared to other methods, specifically mentioning emerging convolutions. It also suggests considering the power demand on a mobile device, which is a relevant concern for practical applications. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their draft in this regard. While it identifies a potential area for improvement, it does not provide actionable advice or detailed insights, making it somewhat helpful. The feedback is valuable but could be more impactful with additional guidance on how to address the computational complexity and power demand concerns.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the authors' claim about the primary attention of the Induction, Duplicate Token, and Previous Token heads to the S2 token is incorrect, referencing Section 3 of Wang et al., 2023. It provides a specific correction, indicating that these heads are active at the S2 token but do not primarily attend to it. This feedback is clear and actionable, as it directs the authors to correct their understanding and potentially revise their draft. The comment is fully actionable because it provides a direct and concrete instruction for the authors to address the issue. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the base IOI circuit\" and \"Section 3 of Wang et al., 2023,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is incorrect in the authors' claim regarding the primary attention of certain heads to the S2 token, providing a detailed explanation of the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' statement about the primary attention of certain heads to the S2 token is incorrect, referencing Section 3 of Wang et al., 2023. This claim is supported by a specific reference to external literature, which provides a basis for verification. However, the comment could be more verifiable by including a brief summary or explanation of the relevant section in Wang et al., 2023, to enhance clarity and understanding. Overall, the comment is mostly verifiable, as it provides a clear basis for verification but lacks some depth in explanation or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue in the authors' claim regarding the primary attention of certain heads in the base IOI circuit, referencing Section 3 of Wang et al., 2023. It provides a clear correction, stating that these heads are active at the S2 token but do not primarily attend to it. This feedback is actionable and constructive, as it directs the authors to correct their understanding and potentially revise their draft. By highlighting a specific error and providing a clear explanation, the comment offers valuable guidance for improvement. However, it could be more helpful if it suggested specific ways to revise the draft or provided additional context. Overall, the comment is mostly helpful, as it effectively points out a critical issue and offers a clear path for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the method, suggesting that it may not be feasible to run on a single instance due to the size of real-world datasets. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might develop a distributed version of the method or what specific steps they should consider. Without concrete suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the scalability of the method, suggesting that it may not be feasible to run on a single instance due to the size of real-world datasets. However, it does not specify which part of the paper this issue is related to, such as the methodology or experimental setup. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Additionally, the comment does not provide specific suggestions or guidance on how to address the scalability issue, such as proposing a distributed version of the method or alternative approaches. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the scalability of the method, suggesting that it may not be feasible to run on a single instance due to the size of real-world datasets. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the scalability of the method, suggesting that it may not be feasible to run on a single instance due to the size of real-world datasets. This feedback highlights a critical limitation that could affect the practical applicability of the method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing a distributed version of the method or alternative approaches. While it points out a significant concern, the absence of actionable advice limits its helpfulness to the authors. Therefore, the comment is somewhat helpful, as it provides a clear area for improvement but lacks depth and specificity in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: first, it notes that the proposed sensitive-layer selection against randomized selection does not make a significant difference in terms of StableDiffusion, and the authors do not discuss this observation further. Second, it points out the lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to provide further discussion and justification, but the action is not concrete. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig.5\" and \"the third figure,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the proposed sensitive-layer selection and the lack of mathematical or theoretical justification for Algorithm.1, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed sensitive-layer selection against randomized selection does not make a significant difference in terms of StableDiffusion and that the authors do not further discuss this observation. It also notes the lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate these claims. The authors are left to infer the significance of the observation and the need for justification, which could be challenging. Therefore, the comment is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two key areas for improvement in the paper. First, it points out that the proposed sensitive-layer selection against randomized selection does not make a significant difference in terms of StableDiffusion, and the authors do not provide further discussion on this observation. This feedback highlights a gap in the analysis and suggests that the authors should elaborate on the implications of their findings. Second, the comment notes the lack of mathematical or theoretical justification for the proposed Algorithm.1, which is a critical aspect that needs to be addressed for the paper to be more robust and credible. By pointing out these specific areas, the comment provides clear guidance for the authors to improve their draft. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to strengthen the justification. Overall, the comment is mostly helpful as it identifies important areas for improvement and encourages the authors to expand their analysis and theoretical grounding.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that triples denoted as $(e_1, r, e_2)$ would clearly show their tuple-like structure instead of sets. This provides a specific and explicit action for the authors to take, as they can directly address this suggestion by revising the notation to better reflect the tuple structure. The comment is clear and concrete, offering a direct and actionable improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by recommending that triples denoted as $(e_1, r, e_2)$ should be represented to show their tuple-like structure instead of sets. This provides a clear direction for the authors to enhance the clarity of their notation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that triples denoted as $(e_1, r, e_2)$ would clearly show their tuple-like structure instead of sets. This is a specific and actionable suggestion that could improve the clarity of the paper. However, the comment does not provide any reasoning or examples to support why this change would be beneficial or how it would enhance the understanding of the triples. Without additional context or justification, the claim is somewhat verifiable, as it lacks sufficient evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by pointing out that triples denoted as $(e_1, r, e_2)$ would be clearer if they were represented to show their tuple-like structure instead of sets. This feedback is actionable and directly addresses a potential area for enhancing the clarity of the paper. By suggesting a specific change, the comment empowers the authors to improve the presentation of their work, making it more accessible and understandable. However, the comment could be more helpful if it included additional context or examples to illustrate why this change would be beneficial. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the scalability of optimal quantization, suggesting that it is costly to both the number of data points (N) and the dimension (M). It also points out that the paper aims to speed up variational inference (VI) through fast convergence, but quantization is a bottleneck in this process, making the method less effective for big data and big model settings. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks concrete guidance on how to improve the method or what specific changes might be necessary. As a result, the authors are left without clear direction on how to respond or improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the scalability of optimal quantization, a topic mentioned in the abstract and introduction. It highlights the cost associated with both the number of data points (N) and the dimension (M), and suggests that quantization is a bottleneck for variational inference (VI) in big data and big model settings. However, the comment does not specify which part of the paper discusses the scalability of quantization or how it relates to the overall argument. This makes it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific about the issue of scalability, it lacks full grounding as it does not provide explicit references to sections or figures. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that optimal quantization is not scalable, which is mentioned in the paper. It argues that even with clustering, it is costly to both the number of data points (N) and the dimension (M). The paper aims to speed up variational inference (VI) through fast convergence, but the reviewer suggests that quantization is a bottleneck, making the method less effective for big data and big model settings. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. It does not provide references or detailed explanations to support the assertion that quantization is a bottleneck for big data and big model settings. As a result, the claim is somewhat verifiable, as it provides a basis for the authors to consider but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the scalability of optimal quantization, which is a significant concern for the paper's claims about speeding up variational inference. It highlights that even with clustering, quantization remains costly in terms of both the number of data points (N) and the dimension (M). The reviewer also points out that this bottleneck limits the method's effectiveness for big data and big model settings, questioning the method's relevance. However, the comment lacks specific suggestions or actionable advice on how the authors might address this issue or improve the method. While it raises an important point, the feedback is somewhat helpful as it directs the authors to consider the scalability of their method and its applicability to large-scale problems. However, it could be more helpful with additional guidance on potential solutions or alternative approaches. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and addresses issues mentioned above. It also implies that the paper should aim for a more application-oriented venue if it does not address the notations issues. However, the comment lacks explicit guidance on how to compare the methods or what specific aspects of the notations need to be addressed. The actions are implicit and vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the effectiveness of the proposed method against existing methods, such as contrastive decoding, and addresses issues mentioned above. It also implies that the paper should aim for a more application-oriented venue if it does not address the notations issues. However, the comment does not specify which part of the paper discusses the methodology or the issues mentioned above, making it weakly grounded. The comment is specific in suggesting comparisons and addressing notations issues, but without clear references, it remains weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and addresses issues mentioned above. It also implies that the paper should aim for a more application-oriented venue if it does not address the notations issues. However, the comment lacks specific examples or detailed reasoning to support the claim that the paper should compare against existing methods or address notations issues. The feedback is somewhat verifiable as it provides a general direction but lacks depth and specific guidance. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and addresses issues mentioned above. It also implies that the paper should aim for a more application-oriented venue if it does not address the notations issues. However, the comment lacks specific guidance on how to compare the methods or what aspects of the notations need to be addressed. While it provides a general direction for improvement, it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it identifies areas for improvement but lacks depth and specificity, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises several concerns about the algorithm's effectiveness, particularly its reliance on the entire training dataset. It questions whether the algorithm can operate effectively when the training dataset is not fully perceptible. The comment also critiques the comprehensiveness of the validation experiments, the lack of analysis regarding time complexity and algorithm efficiency, and the need for the authors to further elucidate the technical contribution rather than the form of the attack. While the comment identifies several areas for improvement, it does not provide explicit guidance on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors are left to infer how to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the effectiveness of the algorithm, specifically mentioning its reliance on the entire training dataset. It also critiques the comprehensiveness of the validation experiments, the lack of analysis regarding time complexity and algorithm efficiency, and the need for the authors to further elucidate the technical contribution rather than the form of the attack. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The specificity of the comment is moderate as it clearly identifies areas that need improvement, such as the algorithm's performance with incomplete datasets and the comprehensiveness of the validation experiments. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several concerns about the algorithm's effectiveness, particularly its reliance on the entire training dataset. It questions whether the algorithm can operate effectively when the training dataset is not fully perceptible. The comment also critiques the comprehensiveness of the validation experiments, the lack of analysis regarding time complexity and algorithm efficiency, and the need for the authors to further elucidate the technical contribution rather than the form of the attack. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand and address the issues effectively. The feedback is somewhat verifiable as it provides a general overview of the concerns but lacks detailed evidence or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises several important points regarding the algorithm's effectiveness, particularly its reliance on the entire training dataset. It questions whether the algorithm can operate effectively when the training dataset is not fully perceptible, which is a crucial aspect for practical applications. The comment also critiques the comprehensiveness of the validation experiments, the lack of analysis regarding time complexity and algorithm efficiency, and the need for the authors to further elucidate the technical contribution rather than the form of the attack. These points provide valuable feedback on areas where the authors could improve their draft, such as enhancing the algorithm's robustness and providing a more comprehensive analysis of its performance. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address these issues. Overall, the feedback is somewhat helpful as it identifies key areas for improvement but lacks detailed actionable advice, making it a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with the claim that every kernel can be described by a feature space parameterized by a neural network. It provides a counterexample using RBF kernels, explaining that they require infinite-dimensional RKHSs, which cannot be represented by neural networks with finite width. The comment suggests that this limitation should be made clearer. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting specific sections to revise or examples to include. The action is implicit and somewhat vague, as the authors need to infer how to improve the paper based on the feedback. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific part of the paper, line 104, allowing the authors to accurately identify the section being addressed. It also provides specific details by explaining that the claim about neural networks representing kernels is trivially not true, using an example of RBF kernels and their infinite-dimensional RKHSs. This level of detail helps the authors understand what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement \"every kernel can be described by a feature space parameterized by a neural network\" is trivially not true, providing a counterexample with RBF kernels and their infinite-dimensional RKHSs. The comment is somewhat verifiable as it offers a specific example to support the claim, but it lacks detailed reasoning or references to further substantiate the argument. The authors would benefit from a more comprehensive explanation or additional evidence to fully understand the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with a claim made in the paper, noting that the assertion that every kernel can be described by a feature space parameterized by a neural network is not entirely accurate. It provides a counterexample using RBF kernels, explaining that their RKHS is infinite-dimensional, which cannot be represented by neural networks with finite width. This feedback is clear and actionable, as it directs the authors to reconsider the accuracy of their claim and provide a more nuanced explanation. However, the comment could be more helpful if it suggested specific ways to revise the claim or include additional examples to support the argument. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the linear attention mechanism handles autoregressive decoding during the generation phase, specifically noting that only a limited number of tokens are used for inference. While the comment highlights a potential issue with the efficiency of the inference process, it does not provide explicit guidance on how to address this concern or suggest any specific actions to improve the draft. The authors are left to infer that they need to clarify the handling of autoregressive decoding in their linear attention mechanism, but the comment lacks concrete details on how to do so. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide clear instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about how the linear attention mechanism handles autoregressive decoding during the generation phase, specifically noting that only a limited number of tokens are used for inference. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or figure being addressed. While the comment is specific in its questioning of the mechanism, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about how the linear attention mechanism handles autoregressive decoding during the generation phase, specifically noting that only a limited number of tokens are used for inference. However, it does not provide any evidence, reasoning, or references to support the claim that this is a problem or an issue that needs to be addressed. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the handling of autoregressive decoding in the linear attention mechanism, specifically noting that only a limited number of tokens are used during the generation phase. This observation highlights a potential issue with the efficiency of the inference process. However, the comment does not provide any suggestions or guidance on how to address this concern or improve the draft. While it identifies a potential area for improvement, it lacks actionable advice or detailed insights that would help the authors enhance their work. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not offer substantial guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggestions regarding the analysis presented in Figure 4. It questions whether GPI with noise added could reproduce the data similarly well and suggests exploring other measures to demonstrate that GPI cannot have as good a fit with behavioral data, such as behavioral trajectories or time to goal. Additionally, the comment suggests that the approach seems suitable for modeling pattern separation tasks, which have behavioral data available, and recommends including a discussion on this. While the comment provides several specific suggestions, it does not explicitly instruct the authors to address these points in their draft. The actions are somewhat implicit, as the authors need to infer how to incorporate these suggestions into their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the possibility of GPI with noise added reproducing the data similarly well and suggests exploring other measures to show that GPI cannot have as good a fit with behavioral data. Additionally, the comment suggests discussing the suitability of the approach for modeling pattern separation tasks, which have behavioral data available. This provides clear guidance on what aspects of the paper need attention. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the analysis presented in Figure 4, specifically regarding the reproducibility of data with GPI and noise. It suggests exploring alternative measures to demonstrate that GPI cannot have as good a fit with behavioral data, such as behavioral trajectories or time to goal. Additionally, the comment suggests discussing the suitability of the approach for modeling pattern separation tasks, which have behavioral data available. While the comment provides some guidance and questions, it lacks detailed reasoning or specific references to support the claims. The suggestions are somewhat vague and could benefit from more detailed explanations or examples. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some basis for the claims but lacks sufficient depth and clarity to fully substantiate them.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several specific and actionable suggestions for improving the analysis presented in Figure 4. It questions the reproducibility of data with GPI and noise, suggesting the exploration of alternative measures to demonstrate that GPI cannot have as good a fit with behavioral data. The comment also recommends discussing the suitability of the approach for modeling pattern separation tasks, which have behavioral data available. These suggestions are clear and provide the authors with concrete directions for enhancing their work. However, the comment could be more helpful if it included more detailed guidance on how to implement these suggestions or provided examples of alternative measures. Overall, the feedback is mostly helpful, as it offers valuable insights and actionable advice for the authors to consider.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the fairness of the comparison between the proposed method and other methods. It points out that the proposed method uses AdamW with cosine learning rate, while the compared methods use Adam with fixed learning rate. The reviewer suggests that it would be better to reproduce the results using the same setting, as most recent methods have their code released. However, the comment does not provide explicit guidance on how to reproduce the results or what specific steps should be taken to ensure a fair comparison. While the action is implied, it lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of AdamW with cosine learning rate for training the proposed method, while comparing it with methods that use Adam with fixed learning rate. This provides a specific point of comparison and highlights a potential issue with the fairness of the comparison. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the learning rate settings, but without explicit references to sections or figures, the authors may need to infer the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison between the proposed method and other methods is unfair because the proposed method uses AdamW with cosine learning rate, while the compared methods use Adam with fixed learning rate. The reviewer suggests that it would be better to reproduce the results using the same setting, as most recent methods have their code released. However, the comment lacks specific examples or references to support the claim about the unfairness of the comparison. It does not provide detailed reasoning or evidence to justify why the proposed method's use of AdamW with cosine learning rate is unfair. Therefore, the claim is not fully verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the comparison between the proposed method and other methods. It highlights that the proposed method uses AdamW with cosine learning rate, while the compared methods use Adam with fixed learning rate. The reviewer suggests that it would be better to reproduce the results using the same setting, as most recent methods have their code released. This feedback is somewhat helpful as it points out a specific area for improvement and suggests a potential approach to address it. However, it could be more helpful if it provided more detailed guidance on how to reproduce the results or what specific steps should be taken to ensure a fair comparison. Overall, the comment offers a clear direction for improvement, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of specific information on the feedback network, specifically asking about the performance with and without certain types of information. While it prompts the authors to consider the value of this information, it does not provide explicit guidance on how to address this question or what actions should be taken. The comment is somewhat vague, as it does not specify how the authors should analyze the performance or what kind of analysis would be beneficial. Therefore, the comment is somewhat actionable, as it provides a direction but lacks concrete steps for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the impact of specific information on the feedback network, specifically asking about the performance with and without certain types of information. However, it does not specify which part of the paper this question pertains to, such as a particular section or table. This makes it difficult for the authors to identify the exact area where the comment is relevant. While the question is specific about the type of information being considered, the lack of grounding makes it challenging for the authors to address the comment effectively. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the impact of specific information on the feedback network, specifically asking about the performance with and without certain types of information. However, it does not provide any evidence, reasoning, or references to support the claim that this information is important or how it might affect the feedback network. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the impact of specific information on the feedback network, specifically asking about the performance with and without certain types of information. This question is relevant as it seeks to understand the value of the information provided in the paper. However, the comment does not offer any suggestions or guidance on how the authors might address this question or what actions they could take to improve their draft. While it identifies an area for improvement, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that Table 1 does not show standard deviations, which is a specific and actionable piece of feedback. It also suggests that the experiments should be more extensive, providing a clear direction for improvement. The comment is explicit and concrete, allowing the authors to understand exactly what needs to be addressed and how to enhance their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the absence of standard deviations in Table 1 and suggests that the experiments should be more extensive, providing clear guidance on what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 1 does not show standard deviations, which is a factual observation. However, it does not provide any reasoning or justification for why this omission is significant or how it impacts the overall findings. The comment suggests that the experiments should be more extensive, but it lacks specific examples or references to support this claim. Without additional context or evidence, the claim is difficult to verify, making it borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Table 1, noting the absence of standard deviations. It also suggests that the experiments should be more extensive to strengthen the submission. This feedback is clear and actionable, providing the authors with a direct understanding of what needs to be addressed to improve the quality and impact of their work. However, the comment could be more helpful if it offered additional guidance on how to conduct more extensive experiments or suggested specific ways to enhance the presentation of the results. Despite this, the comment is mostly helpful as it highlights important areas for improvement and encourages the authors to consider expanding their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is hard to follow and recommends improving the structure, specifically mentioning the introduction, method, and experiments sections. It also suggests focusing more on the IEM in Figure 3 and improving the visualization of Figures 7 and Figure. However, the comment does not provide explicit guidance on how to improve the structure or visualize the figures. The actions are implicit and somewhat vague, as the authors need to infer what specific changes to make. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improving the structure of the paper, specifically mentioning the introduction, method, and experiments sections. It also recommends focusing more on the IEM in Figure 3 and improving the visualization of Figures 7 and Figure. However, the comment does not specify which parts of the paper these sections or figures correspond to, making it difficult for the authors to identify the exact areas that need improvement. While the comment is somewhat specific about the content of the suggested improvements, the lack of explicit grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and somewhat specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper is hard to follow and recommends improving the structure, particularly the introduction, method, and experiments sections. It also suggests focusing more on the IEM in Figure 3 and improving the visualization of Figures 7 and Figure. However, the comment lacks specific examples or detailed reasoning to support these claims. The authors are left to infer the issues and the suggestions, which makes the feedback somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's readability, noting that several sections require multiple reading passes. It suggests improving the structure, specifically mentioning the introduction, method, and experiments sections, and recommends focusing more attention on the IEM in Figure 3, which the reviewer views as the main figure. Additionally, the comment suggests improving the visualization of Figures 7 and Figure. However, the feedback lacks specific guidance on how to improve the structure or visualize the figures, leaving the authors with a general idea of what needs to be addressed but without concrete steps to take. This makes the comment somewhat helpful, as it provides a direction for improvement but could be more actionable with detailed suggestions.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the final used learning rates for the deep models, specifically mentioning CIFAR-10 and CIFAR-100. It also notes that the authors only searched four different learning rates, suggesting that the optimal learning rate for the baseline might be outside the tested interval, potentially affecting the results. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to ensure the robustness of their results. The action is implicit and vague, as it does not specify how the authors should determine the final learning rates or how they should address the concern about the tested interval. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the relevant section. It also lacks specificity, as it does not detail what needs to be addressed regarding the learning rates or the potential impact of the tested interval. Without explicit references or detailed guidance, the authors cannot effectively respond to the comment. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the final used learning rates for deep models, particularly CIFAR-10 and CIFAR-100, and suggests that the authors only searched four different learning rates. It implies that the optimal learning rate for the baseline might be outside the tested interval, potentially affecting the results. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of evidence or justification makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the final used learning rates for the deep models, specifically mentioning CIFAR-10 and CIFAR-100. It notes that the authors only searched four different learning rates, which could potentially affect the results if the optimal learning rate for the baseline is outside the tested interval. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what steps they could take to ensure the robustness of their results. While it identifies a potential concern, it lacks actionable advice or detailed feedback, making it somewhat helpful but not fully comprehensive. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the impact of mitigation strategies on the model's overall performance, suggesting a potential trade-off between reducing memorization and maintaining utility. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to mitigate the potential impairment. The comment implies that the authors should consider the trade-off and its implications, but it lacks concrete suggestions or detailed instructions on how to implement this consideration. Therefore, the comment is somewhat actionable, as it identifies a potential issue but does not provide clear guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the impact of mitigation strategies on the model\\'s overall performance, suggesting a potential trade-off between reducing memorization and maintaining utility. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the concern about the trade-off, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area of concern. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the impact of mitigation strategies on the model\\'s overall performance, suggesting a potential trade-off between reducing memorization and maintaining utility. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence or justification to be considered fully verifiable. Therefore, the comment is rated as 2: Borderline Verifiable, as it hints at a concern but lacks the necessary details to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the impact of mitigation strategies on the model\\'s overall performance, suggesting a potential trade-off between reducing memorization and maintaining utility. It highlights that if these strategies significantly impair the model\\'s utility, it might deter their adoption. While the comment identifies a potential issue, it does not provide specific suggestions or guidance on how the authors might address this concern or improve the mitigation strategies. The feedback is somewhat helpful as it points out a critical area for consideration, but it lacks actionable advice or detailed insights that would guide the authors in enhancing their work. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the necessity of using 6-fold cross-validation, noting that other comparable papers did not employ it. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the cross-validation process need clarification. The action is implicit, as the authors would need to infer that they should explain the rationale behind the choice of cross-validation or provide a comparison with other methods. The lack of concrete instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the necessity of using 6-fold cross-validation, noting that other comparable papers did not employ it. However, it does not specify which part of the paper this issue is related to, such as the methodology or experimental setup. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. The comment is specific in questioning the rationale behind the choice of cross-validation, but without clear grounding, it is difficult for the authors to focus their attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of using 6-fold cross-validation, suggesting that other papers did not employ it. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the criticism. Without detailed justification or evidence, the claim is considered borderline verifiable, as it provides some context but lacks depth and clarity.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a valid concern about the lack of explanation for the use of 6-fold cross-validation, particularly in comparison to other papers that did not employ it. This feedback is somewhat helpful as it highlights a potential gap in the paper's justification for the chosen methodology. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue, such as explaining the rationale behind the choice of cross-validation or comparing it with other methods. Without such detailed feedback, the authors may struggle to fully understand and address the concern, making the comment somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the proposed approaches only outperform the baselines in one out of three setups, and there is no consistent trend in the results. It suggests that the results are insufficient to prove the benefits of the proposed methods and recommends additional experiments or more in-depth analysis. This feedback provides a clear and explicit action for the authors to take, which is to conduct additional experiments or perform more detailed analysis to strengthen the paper. The comment is concrete, as it specifies exactly what needs to be done to improve the results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results, noting that the proposed approaches only outperform the baselines in one out of three setups and that there is no consistent trend, making the results insufficient to justify the claims. The comment suggests that additional experiments or more in-depth analysis are necessary to address these issues. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods. It provides specific evidence, such as the fact that the proposed approaches only outperform the baselines in one out of three setups and that there is no consistent trend in the results. This detailed explanation supports the claim, making it mostly verifiable. However, the comment could be strengthened by providing additional context or examples to further substantiate the claim. Overall, the feedback is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one out of three setups and that there is no consistent trend in the results. This observation is significant because it questions the effectiveness and reliability of the proposed methods. The comment suggests that additional experiments or more in-depth analysis are necessary to better justify the claims made in the paper. This feedback is clear, actionable, and provides a clear direction for the authors to improve their draft by addressing the identified limitations. Therefore, the comment is highly helpful, as it offers specific and constructive guidance for enhancing the paper.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the effectiveness of the proposed engineering method for ReC and notes the incorporation of combinatorial and heuristic aspects, particularly the Non-Ambiguous Query Generation procedure, which relies on a sophisticated filtering template. The comment requests clarification on the impact of these heuristic components. While the comment identifies an area for clarification, it does not provide explicit guidance on how to address this request or what specific aspects of the heuristic components need clarification. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on the impact of these components. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the Non-Ambiguous Query Generation procedure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need for clarification regarding the impact of heuristic components, particularly the sophisticated filtering template used in this procedure. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper presents a highly effective engineering method for ReC but notes the incorporation of combinatorial and heuristic aspects, particularly the Non-Ambiguous Query Generation procedure, which relies on a sophisticated filtering template. The comment requests clarification on the impact of these heuristic components. While the claim is based on the observation of the method's components, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors are left to infer the basis of the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the effectiveness of the proposed engineering method for ReC but highlights the incorporation of combinatorial and heuristic aspects, particularly the Non-Ambiguous Query Generation procedure, which relies on a sophisticated filtering template. The comment requests clarification on the impact of these heuristic components. This feedback is somewhat helpful as it identifies a specific area where the authors could provide more detail or explanation. However, the comment could be more helpful if it offered suggestions on how to address the request for clarification or provided examples of how to elaborate on the impact of these components. Overall, the comment provides a clear direction for improvement but lacks depth and actionable guidance, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses doubt about the proposed method's ability to function without camera information, specifically questioning the necessity of \"knowledge of CAD model correspondences\" and the feasibility of ray marching without viewpoint information. It raises concerns about the method's reliance on camera data and the lack of clarity on how the method determines the origin of rays. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the method. The action is implicit and vague, as the authors are left to infer what changes might be needed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the proposed method's ability to function without camera information, specifically questioning the necessity of \"knowledge of CAD model correspondences\" and the feasibility of ray marching without viewpoint information. It references Line 223, which suggests that the method relies on this information. However, the comment does not specify which part of the paper discusses the method's reliance on camera information or CAD model correspondences, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific in its questioning of the method's functionality without camera information, the lack of explicit grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses doubt about the proposed method's ability to function without camera information, specifically questioning the necessity of \"knowledge of CAD model correspondences\" and the feasibility of ray marching without viewpoint information. The reviewer questions how the method determines the origin of rays without knowing the viewpoint. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the method cannot function without camera information. Without additional context or evidence, the reviewer's concern remains speculative and difficult to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a valid concern about the proposed method's reliance on camera information, specifically questioning the necessity of 'knowledge of CAD model correspondences' and the feasibility of ray marching without viewpoint information. It highlights a potential gap in the method's ability to function without camera data, which could be a significant limitation. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the method's robustness. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful. The authors would need to infer how to improve the method based on the feedback, which limits the comment's overall impact. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. However, it does not provide explicit guidance on how to achieve this detailed comparison or what specific aspects of the comparison should be emphasized. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from a more detailed comparison with related work, particularly in terms of time complexity and competitiveness. However, it does not specify which part of the paper this comparison should be made or which sections of the related work are relevant. The comment is weakly grounded as it does not provide specific guidance on where to make the comparison, and it is specific in terms of the suggested improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a more detailed comparison with related work, specifically in terms of time complexity and competitiveness. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand how to improve their draft based on this feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper would benefit from a more detailed comparison with related work, particularly in terms of time complexity and competitiveness. This feedback is somewhat helpful as it identifies a specific area for improvement, but it lacks depth and specificity. The authors are left with a general idea of what to address but without clear guidance on how to implement the suggested comparison. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages conducting experiments on the full dataset instead of the low-resource regime. While the comment provides a clear direction for improvement, it does not specify which additional datasets should be used or how the experiments should be conducted. The action is explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages conducting experiments on the full dataset instead of the low-resource regime. However, the comment does not specify which datasets are being referred to or which parts of the paper are being addressed. This makes it difficult for the authors to identify the specific sections or parts of the paper that need improvement. Therefore, the comment is not grounded, as it does not provide clear guidance on which parts of the paper to focus on. Additionally, the comment is specific in suggesting the need for more datasets and the use of the full dataset, but without explicit references, it remains weakly grounded. This aligns with a score of 3: Weakly Grounded and Specific.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages conducting experiments on the full dataset instead of the low-resource regime. However, the comment lacks specific details or examples to support the claim that more datasets would enhance the evaluation comprehensively. It does not provide any reasoning or references to justify why additional datasets are necessary or how they would improve the evaluation. As a result, the claim is not fully verifiable, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of experimental results on more datasets. It suggests that conducting experiments on additional datasets would provide a more comprehensive evaluation of the proposed method, which is a valuable and actionable piece of feedback. The comment also encourages conducting experiments on the full dataset instead of the low-resource regime, further enhancing the depth of the evaluation. This feedback is clear, specific, and provides a clear direction for the authors to improve their draft. However, it could be more helpful if it included suggestions on which datasets to consider or how to conduct the additional experiments. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers actionable guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the lack of clarity in how the generic argument task and the random argument task support the authors' claims, and the cumbersome nature of the dataset transformation and experimental setup. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to clarify the tasks or improve the experimental setup. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the clarity of the generic argument task and the random argument task in relation to the authors' claims, as well as the cumbersome nature of the dataset transformation and experimental setup. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the tasks and the experimental setup, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the generic argument task and the random argument task did not clearly prove the authors' claims, and that the dataset transformation and experimental setup were cumbersome and unclear. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper: the lack of clarity in how the generic argument task and the random argument task support the authors' claims, and the cumbersome nature of the dataset transformation and experimental setup. While the comment highlights these areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it points out areas that need clarification, but it lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the comparison of the PL condition used in the paper with the PL conditions proposed in a specific reference. While it prompts the authors to consider this comparison, it does not provide explicit guidance on how to address it or what specific aspects of the comparison should be explored. The action is implicit, as the authors need to infer that they should compare their PL condition with the one mentioned in the reference. However, the lack of detailed guidance on how to conduct this comparison makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the comparison of the PL condition used in the paper with the PL conditions proposed in a specific reference. However, it does not specify which part of the paper this comparison should be made or how the authors should approach it. The comment lacks grounding as it does not provide clear guidance on which section or aspect of the paper needs attention. It also does not specify what needs to be compared or how the comparison should be conducted. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the comparison of the PL condition used in the paper with the PL conditions proposed in a specific reference. However, it does not provide any claim, assertion, or suggestion that requires verification or justification. The comment is purely factual and descriptive, lacking any critical or analytical elements. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the comparison of the PL condition used in the paper with the PL conditions proposed in a specific reference. While it identifies an area for further exploration, it does not provide any guidance or suggestions on how to approach this comparison or what aspects of the comparison might be relevant. The comment lacks depth and actionable insights, making it barely helpful. The authors are left without a clear direction on how to address this question, which limits the feedback's usefulness.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about a potential trap in the experiments conducted with AutoAugment, specifically regarding the possibility of information leakage due to the supervised training on ImageNet. It also questions the conclusion drawn in the paper regarding the pretraining dataset matching the target dataset for linear classification and its implications for self-supervised learning (SSL) algorithms. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to mitigate the potential trap or clarify the implications for SSL algorithms. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to proceed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the experiments conducted in Section 4.2, particularly the use of AutoAugment as a stronger augmentation strategy. It raises a concern about potential information leakage due to the supervised training on ImageNet, which is a specific aspect of the paper. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about information leakage and its implications for the conclusions drawn in the paper, particularly regarding the pretraining dataset matching the target dataset for linear classification and its relevance to SSL algorithms. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about a potential trap in the experiments conducted with AutoAugment, specifically regarding the possibility of information leakage due to the supervised training on ImageNet. It questions the conclusion drawn in the paper regarding the pretraining dataset matching the target dataset for linear classification and its implications for self-supervised learning (SSL) algorithms. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that this is a significant issue. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the concern and how it might impact their results. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about a potential trap in the experiments conducted with AutoAugment, specifically regarding the possibility of information leakage due to the supervised training on ImageNet. It questions the conclusion drawn in the paper regarding the pretraining dataset matching the target dataset for linear classification and its implications for self-supervised learning (SSL) algorithms. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or clarify the implications for SSL algorithms. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as barely helpful, as it provides some insight but lacks depth and practical guidance for the authors.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper has weak analysis on the alignment of entity representations, particularly for language-agnostic characters. It recommends adding more analysis, visualizations, or case studies for different languages, including language families, and specifically mentions the alignment of entities from low-resourced languages with high-resourced ones. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to conduct this analysis or what specific aspects to focus on. The action is somewhat vague, as it leaves the authors to infer the exact steps needed to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper has weak analysis on the alignment of entity representations, particularly for language-agnostic characters. It recommends adding more analysis, visualizations, or case studies for different languages, including language families, and specifically mentions the alignment of entities from low-resourced languages with high-resourced ones. However, the comment does not specify which part of the paper discusses entity representations or where the analysis is lacking. This makes it difficult for the authors to pinpoint the exact section that needs improvement. While the comment is specific about the type of analysis and the languages to consider, the lack of grounding makes it challenging to fully understand the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper has weak analysis on the alignment of entity representations, particularly for language-agnostic characters. It suggests that the authors should add more analysis, visualizations, or case studies for different languages, including language families, and specifically mention the alignment of entities from low-resourced languages with high-resourced ones. However, the comment lacks specific examples or references to support the claim that the analysis is weak. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks depth and clarity.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the analysis of entity representations, particularly for language-agnostic characters. It suggests that the authors should provide more analysis, visualizations, or case studies to address this gap. The comment is clear and actionable, offering specific directions for the authors to enhance their work. However, it could be more helpful if it included examples of how to conduct the analysis or visualizations, or if it suggested specific types of case studies to include. Overall, the comment is mostly helpful as it provides a clear and constructive suggestion for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the references list: the presence of duplicates and the absence of publication venues and years for many papers. While it identifies specific areas that need attention, it does not provide explicit instructions on how to correct these issues or what steps the authors should take to address them. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"references list,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the references list, such as the presence of duplicates and missing publication venues and years. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the references list contains duplicates and that publication venues and years are missing. However, it does not provide any specific examples or references to support these claims. Without detailed evidence or examples, the authors may find it challenging to verify the accuracy of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies two specific issues with the references list: the presence of duplicates and the absence of publication venues and years for many papers. While it points out these problems, it does not provide any suggestions or guidance on how the authors might address these issues. The feedback is clear and identifies areas for improvement, but it lacks actionable advice or detailed suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the theoretical analysis presented in Theorem 1, specifically questioning the meaning of the error bound. It suggests that the authors need to analyze and compare their theoretical results with those of comparable methods. However, the comment does not provide explicit guidance on how the authors should analyze or compare the results, nor does it offer concrete steps on what specific comparisons should be made. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical analysis, namely the lack of clarity regarding the error bound and the need for comparison with other comparable methods. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically questioning the meaning of the error bound. It suggests that the authors need to analyze and compare their theoretical results with those of comparable methods. However, the comment lacks specific examples or references to support the claim about the lack of clarity or the need for comparison. Without detailed reasoning or evidence, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the theoretical analysis in Theorem 1, noting that the error bound is unclear and lacks comparison with other comparable methods. This feedback is actionable as it provides a clear direction for the authors to improve the clarity and depth of their theoretical analysis. However, the comment could be more helpful if it offered specific suggestions or guidance on how to analyze and compare the results with other methods. Despite this, the comment is mostly helpful as it highlights a significant area for improvement, allowing the authors to focus on enhancing the theoretical foundation of their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of explicit and implicit methods on locomotion tasks and notes the absence of a pseudo-code for the proposed method. While it prompts the authors to explain the performance difference, it does not provide explicit guidance on how to address this issue or what specific actions should be taken. The comment is somewhat actionable as it identifies a potential area for clarification and suggests a missing element, but it lacks detailed guidance on how to implement these suggestions. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the performance of explicit and implicit methods on locomotion tasks, suggesting that the authors should explain why explicit methods perform better. It also mentions the absence of a pseudo-code for the proposed method, which is a specific issue that needs to be addressed. However, the comment does not explicitly mention which part of the paper discusses locomotion tasks or the pseudo-code, making it weakly grounded. The specificity of the comment is high as it clearly identifies the issue and what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the performance of explicit and implicit methods on locomotion tasks and notes the absence of a pseudo-code for the proposed method. While it prompts the authors to explain the performance difference, it does not provide specific evidence or reasoning to support the claim that explicit methods perform better. The comment lacks detailed justification or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the performance of explicit and implicit methods on locomotion tasks, suggesting that the authors should explain why explicit methods perform better. It also points out the absence of a pseudo-code for the proposed method, which is a specific issue that needs to be addressed. While the comment identifies a potential area for clarification and highlights a missing element, it lacks detailed guidance on how the authors might address these issues or what specific actions they should take. The feedback is somewhat helpful as it provides a clear direction for improvement but could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the use of low-resource language pairs further fine-tunes a multilingual model and uses the method like R3F to maintain generalization ability. It also notes that the improvement of 0.8 in some low-resource language translations from 1.2 to 2.0 is insignificant in a practical sense. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the model or the results. The feedback lacks concrete steps or suggestions, making it difficult for the authors to understand how to apply it. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of low-resource language pairs and the method like R3F to maintain generalization ability in a multilingual model. It highlights that the improvement of 0.8 in some low-resource language translations is insignificant in a practical sense. However, the comment does not specify which part of the paper discusses the use of low-resource language pairs or the method like R3F. This lack of grounding makes it difficult for the authors to identify the exact section or part of the paper that needs attention. While the comment is specific about the issue of insignificant improvement, it is not grounded because it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvement of 0.8 in some low-resource language translations is insignificant in a practical sense. However, the comment does not provide specific examples or references to support this claim. Without detailed evidence or examples, the authors may find it challenging to understand the basis of this claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of low-resource language pairs in fine-tuning a multilingual model, specifically noting that the improvement of 0.8 in some translations is insignificant in a practical sense. It also points out a missing reference to a relevant work by Aghajanyan et al. While the comment highlights a potential area for improvement and provides a specific example of a missing reference, it lacks detailed guidance on how the authors might address the issue or what specific actions they should take. The feedback is somewhat helpful as it directs the authors to consider the practical significance of their results and to include a relevant reference, but it could be more comprehensive with additional suggestions or guidance. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should visualize the effect of increasing data dimensionality on the performance of existing PU learning methods. It implies that this visualization is crucial for supporting the research motivation of the paper. However, the comment does not provide explicit guidance on how to create the visualization or what specific aspects of the visualization should be included. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to implement the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should visualize the effect of increasing data dimensionality on the performance of existing PU learning methods, which is important for supporting the research motivation of the paper. However, the comment does not specify which part of the paper this visualization should be included in, making it weakly grounded. It is specific in suggesting the need for visualization, but the lack of explicit mention of a particular section or figure makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that existing PU learning methods will suffer a gradual decline in performance as the dimensionality of the data increases. This is a logical and well-supported claim based on common knowledge in the field of machine learning and data analysis. The comment suggests that the authors should visualize this effect, which is a reasonable and actionable suggestion. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors' claim regarding the performance decline of PU learning methods with increasing data dimensionality. It suggests that visualizing this effect would be beneficial for supporting the research motivation of the paper. While the comment highlights an important aspect that could enhance the paper's impact, it lacks specific guidance on how to create the visualization or what aspects of the visualization should be included. This makes the feedback somewhat helpful, as it provides a direction for improvement but does not offer detailed actionable steps. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the convoluted nature of result descriptions, providing an example of a sentence that is difficult to understand. It suggests that the authors should consider simplifying these descriptions. The comment also offers specific suggestions, such as referencing related work on speaker-listener communication and the importance of checking for useful communication. However, the feedback lacks concrete guidance on how to simplify the descriptions or what specific aspects of the descriptions need to be revised. The suggestions are somewhat vague and do not provide detailed steps for implementation. Therefore, the comment is somewhat actionable, as it identifies an issue but does not offer explicit or detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the convoluteness of result descriptions and provides specific suggestions for improvement, such as referencing related work on speaker-listener communication and the importance of checking for useful communication. However, the comment does not explicitly mention which part of the paper these issues are present in, making it weakly grounded. The suggestions are specific and provide direction for improvement, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the convoluted nature of result descriptions, providing an example of a sentence that is difficult to understand. It suggests that the authors should consider simplifying these descriptions. The comment also offers specific suggestions, such as referencing related work on speaker-listener communication and the importance of checking for useful communication. However, the feedback lacks detailed reasoning or references to support the claim that the descriptions are convoluted or difficult to understand. The suggestions are somewhat vague and do not provide specific examples or detailed guidance on how to simplify the descriptions. Therefore, the comment is rated as 2: Borderline Verifiable, as it provides some support but lacks key elements for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific issue with the convoluted nature of result descriptions, providing an example of a sentence that is difficult to understand. It offers suggestions for improvement, such as referencing related work on speaker-listener communication and the importance of checking for useful communication. However, the feedback lacks detailed guidance on how to simplify the descriptions or what specific aspects of the descriptions need to be revised. While the comment provides some actionable feedback, it could be more helpful if it included concrete steps or examples for simplification. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the need for human labor in building text descriptions for each task and questions the optimality of textual formats for policy learning. It also mentions that the long-text input could restrict the scalability of the framework, referencing a previous question. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting alternative approaches or providing guidance on how to address these issues. The feedback lacks concrete steps or suggestions, leaving the authors without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses concerns about the need for human labor in building text descriptions for each task and questions the optimality of textual formats for policy learning. It also mentions that the long-text input could restrict the scalability of the framework, referencing a previous question. However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific in its critique of the need for human labor and the limitations of long-text inputs, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the need for human labor in building text descriptions for each task and questions the optimality of textual formats for policy learning. It also mentions that the long-text input could restrict the scalability of the framework, referencing a previous question. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is somewhat verifiable as it provides some context but lacks depth and clarity, which could be improved with more detailed explanations or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises concerns about the need for human labor in building text descriptions for each task and questions the optimality of textual formats for policy learning. It also mentions that the long-text input could restrict the scalability of the framework, referencing a previous question. However, the comment lacks specific suggestions or actionable feedback on how the authors might address these issues. While it identifies potential areas for improvement, it does not provide detailed guidance or examples, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is somewhat helpful, as it highlights important considerations but does not offer comprehensive advice for improvement.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the significance of the performance improvement of the proposed methods, as shown in Figure 3, where the improvement is only ~0.02. It also suggests that using tables to directly show key improvements could be more intuitive and detailed. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit, as the authors need to infer that they should consider the significance of the improvement and potentially use tables to present the data more effectively. While the comment is somewhat actionable, it lacks concrete details on how to implement the suggested changes, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the significance of the performance improvement and suggests using tables to show key improvements. This provides clear guidance on how the authors should revise their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance improvement of the proposed methods, as shown in Figure 3, is not significant, with the biggest improvement being only ~0.02. It also suggests that using tables to directly show key improvements would be more intuitive and detailed. However, the comment lacks specific examples or references to support the claim about the significance of the improvement. Without additional context or evidence, the authors may find it challenging to fully understand and address the feedback. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance improvement of the proposed methods, noting that the improvement shown in Figure 3 is not significant, with the largest increase being only ~0.02. It also suggests that using tables to directly show key improvements could be more intuitive and detailed. This feedback is somewhat helpful as it highlights a potential area for improvement in the presentation of results. However, the comment could be more helpful if it provided specific guidance on how the authors might address the issue of the small performance improvement or suggested alternative ways to present the data that would make the results more impactful. Overall, the comment offers some insight but lacks depth and actionable suggestions, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the experimental validation, including the use of only shallow networks and the lack of description of the optimization strategy, such as the grid search for hyperparameter selection. It also points out a minor issue regarding the positioning of the work with respect to related works, specifically mentioning the consideration of layer redundancy in the context of network pruning. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. The authors are left without guidance on how to improve their experimental validation or positioning, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experimental validation of the paper, specifically mentioning the use of only shallow networks (2 or 3 layers) and the lack of description of the optimization strategy, including the grid search for hyperparameter selection. It also points out a minor issue regarding the positioning of the work with respect to related works, such as the consideration of layer redundancy in the context of network pruning, providing a specific example. The comment is fully grounded as it explicitly mentions the sections of the paper that need improvement, and it is specific because it details the issues with the experimental validation and the positioning of the work. Therefore, this comment is labeled as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental validation is not convincing, citing the use of only shallow networks (2 or 3 layers) and the lack of description of the optimization strategy, including the grid search for hyperparameter selection. It also mentions a minor issue regarding the positioning of the work with respect to related works, specifically the consideration of layer redundancy in the context of network pruning, providing a specific example. The claim is somewhat verifiable as it provides some justification for the criticism, but it lacks detailed reasoning or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several weaknesses in the experimental validation of the paper, specifically noting the use of only shallow networks (2 or 3 layers) and the lack of description of the optimization strategy, including the grid search for hyperparameter selection. It also points out a minor issue regarding the positioning of the work with respect to related works, such as the consideration of layer redundancy in the context of network pruning, providing a specific example. While the comment highlights these areas for improvement, it does not offer detailed guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it points out areas that need attention, but it lacks depth and actionable advice, making it only marginally helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the use of a specific type of loss in a particular setting might be new, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what steps they should consider to prove new theoretical results. Without specific suggestions or actions, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"this work,\" which implies a specific part of the paper being addressed. It also specifies the issue by stating that the use of a specific type of loss in a particular setting might be new, but the authors do not prove any new theoretical results. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of a specific type of loss in a particular setting might be new, but it does not provide any evidence or reasoning to support this claim. Without additional context or justification, the authors are left to question the validity of the claim, making it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the work, specifically questioning whether the use of a particular type of loss in a specific setting has been previously explored. However, it does not provide any suggestions or guidance on how the authors might address this issue or what additional analysis could be conducted to strengthen the novelty claim. The feedback is somewhat helpful as it highlights a potential area for improvement, but it lacks depth and actionable suggestions, leaving the authors with limited insight into how to enhance their work.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests a hypothesis about the nature of the \"trivial\" and \"impossible\" parts of the data and proposes that human test results might support it. However, it does not provide explicit guidance on how the authors should test this hypothesis or what evidence they should present to either prove or disprove it. The action is implicit, as the authors need to infer that they should provide more evidence to support or disprove the hypothesis. The comment is vague and lacks concrete details on how to implement the suggested action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the relevant section. It also lacks specificity, as it does not provide detailed guidance on what evidence should be presented to support or disprove the hypothesis. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a hypothesis about the nature of \"trivial\" and \"impossible\" parts of the data and suggests that human test results might support it. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the claim remains speculative and difficult to verify. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a hypothesis about the nature of \"trivial\" and \"impossible\" parts of the data, suggesting that the \"trivial\" part might be highly consistent with the training set, while the \"impossible\" part might involve ambiguous labels or atypical object poses. The comment questions whether the authors could provide more evidence to support or disprove this hypothesis, which is a valuable suggestion for improving the paper. However, the comment lacks specific guidance on how to test this hypothesis or what kind of evidence would be most effective. While it provides a direction for improvement, it could be more helpful with additional details on how to conduct the analysis or what specific data would be relevant. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that it is difficult for the authors to follow Section 3.2 and suggests that they may improve it by providing more illustrations and examples. While the comment explicitly suggests an action\u2014improving the section and providing additional illustrations and examples\u2014it does not specify how the authors should go about improving the section or what kind of illustrations and examples would be beneficial. The action is clear and direct, but it lacks concrete details on how to implement it. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that it is difficult for the authors to follow Section 3.2 and recommends improving it by providing more illustrations and examples. However, it does not specify which part of Section 3.2 is particularly challenging to follow, nor does it provide any guidance on what kind of illustrations or examples would be helpful. The comment lacks grounding as it does not pinpoint the specific section or part of the paper that needs improvement. It is also specific in terms of suggesting improvements, but without grounding, the authors cannot determine where to focus their efforts. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that it is difficult to follow Section 3.2 and suggests that the authors may improve it by providing more illustrations and examples. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the exact nature of the difficulty or how to address it. Without additional context or evidence, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of Section 3.2, suggesting that it is difficult for the authors to follow. It provides a specific suggestion for improvement by recommending that the authors enhance the section with more illustrations and examples. While the comment highlights a specific area for improvement and offers a clear direction for action, it lacks broader context or suggestions for other areas that might need attention. The feedback is actionable and provides a clear path for the authors to enhance their draft, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and self-supervised learning (SSL) for these models. This provides a clear and explicit action for the authors to take, as they can directly implement this suggestion by adding the baselines to the table. The action is also concrete, as it specifies exactly what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, it does not specify which part of the paper Table 1 is located in, making it weakly grounded. The comment is specific in its suggestion, as it clearly indicates what needs to be added to the table to improve understanding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. While the suggestion is logical and provides a clear direction for improvement, it lacks specific examples or references to support the claim. The authors would need to infer the need for such baselines to enhance the understanding of the gap. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks detailed justification or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and self-supervised learning (SSL) for these models. This feedback is specific and actionable, as it provides a clear direction for the authors to improve their draft by including additional baselines. By adding these baselines, the authors can gain a more comprehensive understanding of the performance differences between fully supervised and SSL methods. This feedback is valuable and directly addresses a potential area for improvement in the paper, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the time complexity of the proposed algorithm, specifically concerning the repeated calculation of hypervolume in LaMOO. It highlights that this calculation could be time-consuming, especially for problems with many objectives, potentially making the algorithm impractical. However, the comment does not provide explicit guidance or suggestions on how to address this issue, such as proposing alternative methods or optimizations. The action is implicit and vague, as the authors are left to infer that they need to consider the time complexity and potential improvements. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the time complexity of the proposed algorithm, specifically mentioning the repeated calculation of hypervolume in LaMOO. It highlights that this calculation could be time-consuming, especially for problems with many objectives, potentially making the algorithm impractical. However, the comment does not specify which part of the paper discusses the algorithm or the hypervolume calculation, making it difficult for the authors to pinpoint the exact section or figure being addressed. While the comment is specific about the issue of time complexity, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the time complexity of the proposed algorithm, specifically concerning the repeated calculation of hypervolume in LaMOO. It highlights that this calculation could be time-consuming, especially for problems with many objectives, potentially making the algorithm impractical. However, the comment does not provide any specific evidence, reasoning, or references to support the claim that the repeated calculation of hypervolume is time-consuming. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how it relates to the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the time complexity of the proposed algorithm, specifically concerning the repeated calculation of hypervolume in LaMOO. It highlights that this calculation could be time-consuming, especially for problems with many objectives, potentially making the algorithm impractical. While the comment identifies a potential issue with the algorithm's efficiency, it does not provide specific suggestions or guidance on how to address this concern. The feedback is somewhat helpful as it points out a potential limitation that the authors should consider, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should delve deeper into the limitations of evolutionary methods, specifically mentioning the importance of leveraging state, reactiveness, and learning during an episode. It also critiques the title as being too generic and suggests that the authors should be more precise when being critical. The comment further asks for clarification on the term \"brittle convergence properties\" and suggests considering the adoption of DeepRL methods and the landscape of research 10 years ago. While the comment provides several suggestions for improvement, it lacks explicit guidance on how to implement these suggestions or what specific actions the authors should take. The actions are implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should explore deeper aspects of evolutionary methods, such as leveraging state, reactiveness, and learning during an episode. It critiques the title as being too generic and suggests that the authors should be more precise when being critical. The comment also asks for clarification on the term \"brittle convergence properties\" and suggests considering the adoption of DeepRL methods and the landscape of research 10 years ago. However, the comment does not specify which part of the paper these suggestions relate to, making it weakly grounded. The specificity of the comment is moderate as it provides some guidance on what aspects to explore but lacks detailed instructions on how to do so. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the paper for being too generic and vague, particularly in its title. It suggests that the authors should be more precise when being critical and provides examples such as \"DeepRL methods are widely adopted\" and the concept of \"brittle convergence properties.\" However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is somewhat verifiable as it provides some reasoning but lacks detailed evidence or references. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the paper for being too generic and suggests that the authors should be more precise in their critical remarks. It provides specific examples, such as the adoption of DeepRL methods and the concept of 'brittle convergence properties,' which could help the authors refine their critique. However, the comment lacks detailed guidance on how to address these issues or what specific aspects of the paper need improvement. While it offers some direction, the feedback could be more comprehensive and actionable to fully assist the authors in enhancing their draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the methodology, specifically regarding the synthesis of the focal stack, the forward model used, and the handling of depth discontinuities at edges. While the questions are explicit and direct, they do not provide concrete guidance on how the authors should address these issues. The authors are left with a clear understanding of what needs to be clarified but lack specific steps or suggestions on how to improve the description. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer detailed guidance on implementation. This aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several questions about the methodology, specifically regarding the synthesis of the focal stack, the forward model used, and the handling of depth discontinuities at edges. However, it does not specify which part of the paper these questions pertain to, such as a specific section or figure. This makes it difficult for the authors to pinpoint the exact areas that need clarification. While the questions are specific about the methodology, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the methodology, specifically regarding the synthesis of the focal stack, the forward model used, and the handling of depth discontinuities at edges. These questions are based on factual observations about the methodology described in the paper. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. The authors are left to infer the validity of the questions based on their own understanding of the paper, which makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several important questions about the methodology described in the paper, specifically regarding the synthesis of the focal stack, the forward model used, and the handling of depth discontinuities at edges. These questions are clear and direct, providing the authors with specific areas to clarify and improve their methodology. However, the comment lacks detailed guidance or suggestions on how to address these issues, which limits its helpfulness. While it identifies key areas for improvement, it does not offer comprehensive advice or detailed steps for the authors to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the components of the approach are not novel, as they have been used in previous works. It mentions specific examples of weak predictors (MLP, Regression Tree, Random Forest) and sampling strategies (epsilon-greedy) that have been used before, citing references [2, 3, 7] and [5]. The comment also notes that the results of the proposed WeakNAS are almost the same as BRP-NAS, as shown in Table 2 in Appendix C. However, the comment does not provide explicit or implicit suggestions on how the authors might address these issues or improve their approach. The authors are left without guidance on how to make their work more novel or distinguishable from existing methods. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the approach by pointing out that the weak predictors used (MLP, Regression Tree, Random Forest) and the sampling strategy (epsilon-greedy) are similar to those used in previous works [2, 3, 7] and [5]. It also notes that the results of the proposed WeakNAS are almost the same as BRP-NAS, as shown in Table 2 in Appendix C. However, the comment does not specify which part of the paper discusses the approach or the results, making it weakly grounded. The comment is specific in detailing the issues with the novelty of the approach and the similarity of the methods used. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the components of the approach are not novel, as they have been used in previous works. It provides specific examples of weak predictors (MLP, Regression Tree, Random Forest) and sampling strategies (epsilon-greedy) that have been used before, citing references [2, 3, 7] and [5]. The comment also notes that the results of the proposed WeakNAS are almost the same as BRP-NAS, as shown in Table 2 in Appendix C. This provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by explicitly referencing the sections of the paper where these comparisons are made, enhancing its verifiability.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the novelty of the approach, pointing out that the weak predictors and sampling strategy used are similar to those in previous works. It provides specific examples of similar methods, such as MLP, Regression Tree, Random Forest, epsilon-greedy, and BRP-NAS, and references previous studies [2, 3, 7, 5]. The comment also notes that the results of the proposed WeakNAS are almost the same as BRP-NAS, as shown in Table 2 in Appendix C. This feedback is mostly helpful as it highlights the lack of novelty and suggests that the authors need to address these issues to differentiate their work. However, it could be more helpful if it provided specific suggestions on how to make the approach more novel or unique. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but lacks detailed guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the experimental evaluation of the proposed method, specifically noting that while the authors discuss how KG handles continuous tasks, there are no experiments with continuous tasks. It also questions the inclusion of entropy methods for conditional optimization, derived in Section 7, and asks why these are not included in the experiments. The comment requests a comparison of the empirical performance of these methods with ConBO. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to include experiments with continuous tasks and compare the performance of entropy methods. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the discussion of how KG handles continuous tasks, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of experiments with continuous tasks and the absence of a comparison of entropy methods for conditional optimization with ConBO. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the absence of experiments with continuous tasks and the lack of comparison of entropy methods for conditional optimization with ConBO. While the comment identifies a gap in the experimental evaluation, it does not provide specific examples or references to support the claim that these methods should be included. The reasoning is somewhat vague, as it lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap in the experimental evaluation of the proposed method, specifically noting the absence of experiments with continuous tasks. It also questions the inclusion of entropy methods for conditional optimization, derived in Section 7, and asks why these are not included in the experiments. The comment requests a comparison of the empirical performance of these methods with ConBO, which is a relevant and actionable suggestion for the authors to consider. However, the comment could be more helpful by providing specific guidance on how to conduct these experiments or by suggesting alternative approaches to address the issue. Overall, the feedback is somewhat helpful as it highlights an important area for improvement and encourages the authors to expand their experimental evaluation.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment questions the authors' claim about the novelty of unsupervised feature selection from a diffusion perspective and seeks clarification on the difference between similarity and exit times. While the comment highlights a potential area of confusion for the authors, it does not provide explicit guidance on how to address this issue or what specific aspects need clarification. The action is implicit, as the authors are expected to infer that they need to provide a more detailed explanation of the difference between similarity and exit times. However, the comment lacks concrete details on how to achieve this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the authors' claim about the novelty of unsupervised feature selection from a diffusion perspective and seeks clarification on the difference between similarity and exit times. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its request for clarification but lacks grounding as it does not mention the specific section or part of the paper being discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' claim about the novelty of unsupervised feature selection from a diffusion perspective and seeks clarification on the difference between similarity and exit times. However, it does not provide any specific evidence, reasoning, or references to support the claim or the need for clarification. The comment lacks depth and does not offer a clear path for the authors to address the issue, making it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the novelty of the authors' claim regarding unsupervised feature selection from a diffusion perspective and seeks clarification on the difference between similarity and exit times. While the comment identifies a potential area of confusion for the authors, it does not provide specific guidance or suggestions on how to address this issue. The feedback is somewhat helpful as it highlights a point that needs clarification, but it lacks depth and actionable advice, making it only somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the methodology used for calculating precision, recall, and F1-score for a 4-class classification of breast density. It also suggests that reporting AUC with sensitivity and specificity at different operating points would be more informative for comparing model performance. While the comment identifies specific areas for clarification and improvement, it does not provide explicit instructions on how to address these issues or what specific changes should be made to the draft. The actions are implicit and somewhat vague, as the authors need to infer how to calculate the metrics and incorporate AUC results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the methodology used for calculating precision, recall, and F1-score for a 4-class classification of breast density, and suggests that reporting AUC with sensitivity and specificity at different operating points would be more informative for comparing model performance. However, the comment does not specify which part of the paper discusses the classification of breast density or where the AUC results are reported. This lack of grounding makes it difficult for the authors to identify the specific sections or parts of the paper that need attention. While the comment is specific in its suggestions, the absence of explicit references to the paper makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the methodology used for calculating precision, recall, and F1-score for a 4-class classification of breast density and suggests that reporting AUC with sensitivity and specificity at different operating points would be more informative for comparing model performance. While the comment provides a suggestion for improvement, it lacks specific examples or references to support the claim that this approach would be more informative. The authors would need to infer the reasoning behind this suggestion, which could be challenging. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a specific question about the methodology used for calculating precision, recall, and F1-score for a 4-class classification of breast density. It also suggests that reporting AUC with sensitivity and specificity at different operating points would be more informative for comparing model performance. While the comment identifies an area for improvement, it lacks detailed guidance on how to address these issues or what specific changes should be made to the draft. The feedback is somewhat helpful as it points out a potential area for clarification and improvement, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the novelty of the Transformer in the context of NLP and vision tasks, suggesting that the authors' modification, particularly the cross-layer aspect, does not provide significant insight into machine learning. It also notes that the ablation study shows limited improvement from self-cross attention, questioning its significance. The comment implies that the main improvements might stem from using a na\u00efve Transformer rather than the proposed modification. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve their work. The action is implicit and vague, as the authors are left to infer what needs to be done. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the novelty of the Transformer in the context of NLP and vision tasks, suggesting that it is no longer novel. It also critiques the cross-layer modification, noting that it does not bring significant insight into machine learning. The comment further questions the significance of the self-cross attention ablation study, noting that it shows limited improvement. However, the comment does not specify which part of the paper discusses the Transformer or the ablation study, making it weakly grounded. The comment is specific in detailing the issues with the Transformer and the ablation study, but without explicit references to sections or figures, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the novelty of the Transformer in the context of NLP and vision tasks, suggesting that it is no longer novel. It also questions the significance of the cross-layer modification and the limited improvement observed in the ablation study. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The reasoning is somewhat vague, and the lack of detailed evidence or references makes it challenging to fully assess the validity of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the novelty of the Transformer in the context of NLP and vision tasks, suggesting that it is no longer a significant contribution. It also questions the significance of the cross-layer modification and the limited improvement observed in the ablation study. The comment provides a clear critique of the novelty and the impact of the proposed modification, which could help the authors understand the limitations of their work. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address these issues or improve the paper's contribution. Overall, the comment is somewhat helpful as it identifies areas for improvement but lacks depth and actionable advice.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the experiments conducted by the authors, noting that they only evaluate sentence similarity and open domain QA tasks. It suggests that the authors should consider conducting experiments on other sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. The comment provides a clear and explicit action for the authors to take, which is to expand their experiments to include more types of sentence pair tasks. This guidance is concrete and specific, allowing the authors to understand exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the limitation in the experiments conducted by the authors, specifically noting that they only evaluate sentence similarity and open domain QA tasks. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the need for additional experiments on other sentence pair tasks, such as MNLI and RTE, which are common in the NLP field. This provides a clear direction for the authors to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are limited, as the authors only conduct evaluations on sentence similarity and open domain QA tasks. It suggests that the authors should consider expanding their experiments to include other sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. The comment provides a logical reasoning by identifying the limitation in the scope of the experiments and suggesting specific tasks that could be included. However, it lacks specific examples or references to support the claim fully. Therefore, the comment is mostly verifiable, as it provides a clear rationale but could benefit from additional evidence or references to enhance its persuasiveness.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the experiments conducted by the authors, noting that they only evaluate sentence similarity and open domain QA tasks. It suggests that the authors should consider expanding their experiments to include other sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by conducting additional experiments. However, the comment could be more helpful if it included suggestions on how to implement these additional experiments or provided examples of relevant datasets. Overall, the comment is mostly helpful as it offers valuable guidance for enhancing the scope and depth of the experiments.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the prompt should be included in the appendix or supplement, noting that it might be in a supplement that the authors cannot access. However, it does not provide any explicit or implicit actions for the authors to take, such as where to include the prompt or how to access the supplement. The comment lacks concrete guidance on how to address this issue, making it unactionable. Therefore, the comment is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests including the prompt in the appendix or supplement, noting that it might be in a supplement that the authors cannot access. However, it does not specify which part of the paper the prompt is intended for or how it relates to the content of the paper. The authors cannot confidently determine which section or figure the comment addresses, making it weakly grounded. Additionally, the comment does not provide specific guidance on what needs to be addressed or how to include the prompt effectively. Therefore, the comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests including the prompt in the appendix or supplement, noting that it might be in a supplement that the authors cannot access. However, the comment lacks specific reasoning or examples to support why this suggestion is necessary or beneficial. It does not provide any evidence or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests including the prompt in the appendix or supplement, noting that it might be in a supplement that the authors cannot access. However, the comment lacks specific guidance or suggestions on how to include the prompt effectively or what additional information might be needed. It does not provide actionable advice or insights that would help the authors improve their draft. As a result, the comment is barely helpful, aligning with a score of 2.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the triviality of the convergence proof, suggesting that it lacks substantial novelty and rigor. It provides a specific example of how the proof could be adapted based on a previous modification. However, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should consider revising the proof to enhance its novelty and rigor. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Triviality of Convergence Proof\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proof, explaining that it lacks substantial novelty and rigor due to the assumption that $X$ is i.i.d., which contradicts the claim that $Z$ is non-i.i.d. The comment provides clear guidance on how the authors might address this issue by suggesting that previous theorems can be adapted with straightforward modifications. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical proof for convergence is trivial, as it follows from Assumption 4.1 that $X$ is i.i.d., leading to a clear covariance matrix for $Z$. The comment suggests that the proof lacks substantial novelty and rigor, and that previous theorems can be adapted with straightforward modifications. However, the claim lacks specific examples or detailed reasoning to fully substantiate the assertion of triviality. While the reasoning is logical, the absence of concrete evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the theoretical proof of convergence, noting that it appears trivial due to the assumption that $X$ is i.i.d., which contradicts the claim that $Z$ is non-i.i.d. The comment suggests that the proof lacks substantial novelty and rigor, and that previous theorems can be adapted with straightforward modifications. This feedback is clear and actionable, providing the authors with a specific direction to improve the depth and novelty of their theoretical analysis. However, it could be more helpful if it included suggestions for enhancing the proof's rigor or providing additional context. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a clear path for the authors to address it.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the experimental setup, noting that it is only semi-real because multi-node seed cascades are artificially created by merging single-node seed cascades. The comment suggests that this should be mentioned clearly. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the paper. The action is implicit, as the authors can infer that they need to clarify the experimental setup in the paper. The comment is somewhat actionable because it identifies a specific area that needs attention, but it lacks concrete details on how to implement the suggested change. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"The experimental setup borrowed from [2] is only semi-real,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely that the multi-node seed cascades are artificially created by merging single-node seed cascades. This provides clear guidance on how the authors should improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental setup is only semi-real because multi-node seed cascades are artificially created by merging single-node seed cascades. This claim is supported by the statement itself, which provides a clear explanation of the issue. However, the comment lacks specific examples or references to external works that could further substantiate the claim. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that it is only semi-real because multi-node seed cascades are artificially created by merging single-node seed cascades. This observation is clear and provides a specific point for the authors to address in their paper. By highlighting this detail, the comment offers a constructive suggestion for improving the transparency and rigor of the experimental setup description. However, the comment could be more helpful if it provided additional guidance on how to address this issue or suggested specific ways to improve the clarity of the experimental setup. Overall, the comment is mostly helpful as it points out a crucial aspect that needs attention, but it could be more comprehensive with additional suggestions or guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential conflict in the paper regarding the performance of the multi-environment model. It points out that the paper claims both an inevitable performance loss and outperformance due to knowledge sharing, which seems contradictory. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this conflict or clarify the statements. The action is implicit, as the authors need to infer that they should clarify the conflicting claims. The action is vague because it does not specify how to clarify the statements or what aspects of the claims need to be addressed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the conflicting claims made in the paper about the performance of the multi-environment model. It points out that the paper claims both an inevitable performance loss and outperformance due to knowledge sharing, which seems contradictory. However, the comment does not specify which part of the paper these claims are made, making it weakly grounded. The comment is specific in identifying the conflicting claims, but the lack of grounding makes it difficult for the authors to pinpoint the exact sections that need clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point identifies a potential conflict in the paper regarding the performance of the multi-environment model. It highlights that the paper claims both an inevitable performance loss and outperformance due to knowledge sharing, which seems contradictory. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this conflict or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential conflict in the paper regarding the performance of the multi-environment model. It points out that the paper claims both an inevitable performance loss and outperformance due to knowledge sharing, which seems contradictory. This feedback highlights a critical issue that needs clarification, as it could significantly impact the reader's understanding of the model's effectiveness. However, the comment does not provide specific guidance on how the authors should address this conflict or clarify the conflicting claims. While it points out a potential issue, it lacks actionable suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method is sensitive to hyperparameters and recommends performing a careful hyperparameter search to find a proper $\\alpha$ for a new problem. This provides a clear and explicit action for the authors to take, as they need to conduct a hyperparameter search and adjust the $\\alpha$ value accordingly. The comment is specific in its suggestion, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the method's sensitivity to hyperparameters, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for how to apply this sensitivity, namely by performing a careful hyperparameter search to find a proper $\\alpha$ for a new problem. This guidance is detailed and actionable, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method is sensitive to hyperparameters, suggesting that careful hyperparameter search is necessary to find a proper $\\alpha$ for a new problem. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the method's sensitivity to hyperparameters, suggesting that careful hyperparameter search is necessary to find a proper $\\alpha$ for a new problem. This feedback is clear and actionable, providing the authors with a specific direction to improve their method. However, the comment could be more helpful if it offered additional guidance on how to conduct the hyperparameter search or what specific strategies might be effective. Overall, the comment is mostly helpful as it highlights a critical aspect of the method that needs attention, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the description of the metrics used in the paper is limited and recommends providing an explanation of the metrics or citing the metrics. While the comment implies that the authors should include more details about the metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it leaves the authors to infer that they need to expand the description of the metrics. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the description of the metrics used in the paper is limited and recommends providing an explanation or citing the metrics. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact area that needs improvement. While the comment is specific about the need for more detail on the metrics, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the description of the metrics is limited and suggests that the authors should provide an explanation or cite the metrics. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting that the description of the metrics used is limited. It suggests that the authors should provide an explanation of the metrics or cite the metrics to enhance the clarity and comprehensiveness of the paper. While the comment highlights a potential weakness, it does not offer detailed guidance on how to address this issue or provide specific examples of where the metrics are discussed. This feedback is somewhat helpful as it points out an area for improvement, but it lacks depth and actionable suggestions, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"learned [MASK] embedding\" in the context of the proposed method\\'s SSL pre-training stage. While it identifies a lack of clarity, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the method need clarification. The action is implicit, as the authors would need to infer that they should clarify the meaning of \"learned [MASK] embedding\" in their paper. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the meaning of \"learned [MASK] embedding\" in the context of the proposed method\\'s SSL pre-training stage. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its request for clarification, the absence of explicit grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the meaning of \"learned [MASK] embedding\" in the context of the proposed method\\'s SSL pre-training stage. However, it does not provide any claim, assertion, or suggestion that requires verification or justification. The comment is purely descriptive, asking for clarification on a specific term within the paper. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the meaning of \"learned [MASK] embedding\" in the context of the proposed method\\'s SSL pre-training stage. This feedback is clear and actionable, as it points out a lack of clarity that could hinder the understanding of the proposed method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as providing additional explanations or examples. While it highlights a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the reported results are partially derivative, extending findings from standard networks to hyper-networks. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve their results or what specific changes are needed to make the extension more novel or impactful. Without concrete suggestions or actions, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the reported results are partially derivative, extending findings from standard networks to hyper-networks. However, it does not specify which part of the paper this issue is related to, such as a particular section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the results, the absence of grounding information limits its usefulness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the reported results are partially derivative, extending findings from standard networks to hyper-networks. However, the comment lacks specific evidence or references to support this claim. Without detailed examples or references to the specific literature the authors are building upon, it is difficult for the authors to verify the claim or understand the basis of the criticism. This lack of supporting evidence makes the claim somewhat verifiable, as it provides a general observation but lacks the necessary details to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reported results, suggesting that they are partially derivative, extending findings from standard networks to hyper-networks. While this observation is insightful, it lacks actionable guidance or suggestions for improvement. The authors are left without a clear understanding of how to address this issue or what steps they might take to enhance the novelty or impact of their results. The comment is somewhat helpful as it points out a potential area for improvement, but it does not provide detailed feedback or constructive advice, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the scope of the study is under-specified, suggesting that the work focuses on injecting a CoT-based approach into small-scale Language Models. It also points out that additional relevant CoT baselines for in-context learning of Large Language Models are missing in Table 2 and 3, referencing a question for clarification. While the comment identifies a potential issue with the scope and suggests the inclusion of additional baselines, it does not provide explicit guidance on how to address these issues or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer the need for additional baselines and potentially revise the scope of the study. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the scope of the study and the missing CoT baselines for in-context learning of Large Language Models. This provides the authors with clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the scope of the study is under-specified and suggests that the work focuses on injecting a CoT-based approach into small-scale Language Models. It also points out the absence of additional relevant CoT baselines for in-context learning of Large Language Models in Table 2 and 3, referencing a question for clarification. While the comment identifies a potential issue with the scope and suggests the inclusion of additional baselines, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the need for additional baselines and potentially revise the scope of the study. Therefore, the comment is somewhat verifiable, as it provides a basis for improvement but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the scope of the study, suggesting that it focuses on injecting a CoT-based approach into small-scale Language Models. It also points out the absence of additional relevant CoT baselines for in-context learning of Large Language Models in Table 2 and 3, referencing a question for clarification. This feedback is somewhat helpful as it highlights a potential area for improvement and suggests the inclusion of additional baselines. However, the comment could be more helpful if it provided specific guidance on how to address the issue or suggested additional relevant baselines. Overall, the comment offers some insight but lacks depth and actionable suggestions, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that Figure 3 is difficult to read, but it does not provide any specific guidance or suggestions on how to improve the figure's readability. The authors are left without any actionable steps to take to address this issue. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper Figure 3 is located in, making it difficult for the authors to identify the issue. Additionally, the comment is specific in that it identifies the problem as the difficulty in reading the figure, but without grounding, the authors cannot pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that Figure 3 is \"very hard to read anything on the figure.\" However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors cannot verify the claim or understand why it is an issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting that it is difficult to read anything on the figure. However, it lacks actionable suggestions or guidance on how to improve the figure's readability. Without specific advice on how to enhance the figure's clarity, the authors are left without a clear path to address the issue. This makes the comment barely helpful, as it points out a problem but does not provide sufficient assistance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the connection between the statement in the introduction regarding the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. However, it does not provide any explicit or implicit suggestions on how the authors might address this connection or incorporate it into their work. The comment lacks concrete guidance on how to improve the draft, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it questions the connection between the statement about the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. This provides clear guidance on what needs to be addressed in the introduction. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the connection between the statement in the introduction regarding the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. However, it does not provide any specific evidence, reasoning, or references to support the claim that this connection is relevant or important. Without additional context or justification, the authors may find it challenging to understand the basis of the comment and how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the connection between the statement in the introduction regarding the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. While the comment identifies a potential area for clarification or further discussion, it does not provide specific guidance or suggestions on how the authors might address this connection or incorporate it into their work. The feedback is somewhat helpful as it highlights a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides two specific suggestions for the authors to consider: replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda` and using a SGD learning rate of ~0.1 instead of the Adam default value. However, it does not explicitly instruct the authors on how to implement these changes or provide guidance on why these replacements or adjustments are necessary. The actions are implicit, as the authors need to infer that they should make these changes and understand the reasoning behind them. The lack of detailed guidance on how to apply these suggestions makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment provides specific suggestions for the authors to consider, such as replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda` and using a SGD learning rate of ~0.1. However, it does not specify which part of the paper these suggestions relate to, such as a particular section or table. This makes it difficult for the authors to pinpoint the exact areas where these changes should be made. While the suggestions are specific in terms of the proposed changes, the lack of grounding makes it challenging for the authors to understand the context and relevance of these suggestions. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two specific questions about the methodology used in the paper. The first question pertains to the replacement of `n^2/(2*s^2)` with an arbitrary parameter `lambda`, and the second question concerns the justification for using a SGD learning rate of ~0.1, which is different from the Adam default value. While the questions are clear and specific, they do not provide any supporting evidence or reasoning to justify why these choices were made or why they are important. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of these questions and how they might impact the paper. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides two specific suggestions for the authors to consider, such as replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda` and using a SGD learning rate of ~0.1 instead of the Adam default value. However, the comment lacks detailed reasoning or justification for why these changes might be necessary or beneficial. It does not explain the implications of these choices or how they might affect the results or conclusions of the paper. Without further elaboration or context, the authors may find it challenging to understand the rationale behind these suggestions and how to implement them effectively. Therefore, the comment is somewhat helpful, as it offers specific points for consideration but lacks depth and guidance, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to discuss a specific work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" from ICML2019, which is relevant to the topic of joint error in unsupervised domain adaptation (UDA). It also suggests that the authors should illustrate the relationship between this work and their proposed method and explain why their method is better. This provides a clear and concrete action for the authors to take, as they know exactly what needs to be addressed and how to do it. The comment is fully actionable, as it gives explicit guidance on what to include in the discussion and how to compare the proposed method with existing work. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific issue of joint error in unsupervised domain adaptation (UDA), which is a well-defined area of the paper. It also specifies the need to discuss a previous work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" from ICML2019, and to illustrate the relationship between this work and the proposed method. This provides clear guidance on what part of the paper needs attention and what specific issues need to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' assertion about the lack of research on joint error in unsupervised domain adaptation (UDA) is inaccurate, as previous work has already addressed this issue. The comment provides a specific reference to \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" from ICML2019, which supports the claim. However, the comment could be more robust by including a brief summary or explanation of the relevance of this work to the authors' proposed method. Despite this, the claim is mostly verifiable as it is supported by a specific reference, making it a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific gap in the authors' claim regarding the lack of research on joint error in unsupervised domain adaptation (UDA). It directs the authors to a relevant previous work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" from ICML2019, and suggests that they discuss this work in relation to their proposed method. By providing a specific reference and a clear direction for discussion, the comment offers actionable guidance that helps the authors improve the accuracy and depth of their paper. This feedback is detailed and constructive, making it highly valuable for enhancing the draft.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting that several curriculum learning methods have been discussed in Section 1, but it does not provide explicit guidance on how to address the need for designing a new curriculum learning method for text graphs. While the comment implies that the authors should justify the need for a new method, it lacks concrete suggestions or detailed instructions on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue: the lack of justification for designing a new curriculum learning method for text graphs and the absence of a discussion on why existing methods cannot be applied. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that several curriculum learning methods have been discussed in Section 1 but does not provide a detailed justification or explanation of why a new method is needed for text graphs. It mentions the research gap but lacks specific examples or references to support the claim. Without additional context or evidence, the claim is somewhat verifiable, as it is based on an observation but lacks depth and clarity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap in the paper by pointing out that while several curriculum learning methods have been discussed, the need for designing a new method for text graphs is not justified. It highlights the lack of discussion on why existing methods might not be applicable, which is a crucial aspect for the authors to address. This feedback is clear and actionable, as it directs the authors to provide a justification for the need for a new method and to discuss the limitations of existing approaches. However, the comment could be more helpful if it provided specific examples or suggestions for how to address this gap. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should use powerful pre-trained language models like BERT and XLNet as the base encoder for all methods and then compare the efficacy of the transfer parts instead of using the simplest n-gram features. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be done to improve their draft. The comment is specific in its suggestion, detailing which models to use and how to compare the transfer parts. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"domain adaptation in the NLP field\" and suggests using powerful pre-trained language models like BERT and XLNet as the base encoder. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides clear guidance on how the authors should improve their draft by comparing the efficacy of the transfer parts instead of using the simplest n-gram features. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that using powerful pre-trained language models like BERT and XLNet as the base encoder can overcome the domain-shift problem, and suggests comparing the efficacy of the transfer parts instead of using the simplest n-gram features. While the claim is based on the understanding of domain adaptation in the NLP field, it lacks specific references or detailed reasoning to fully substantiate the claim. The authors would need to provide more evidence or examples to fully understand the basis of this suggestion. Therefore, the comment is somewhat verifiable, as it provides a basis for improvement but requires additional support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending the use of powerful pre-trained language models like BERT and XLNet as the base encoder for domain adaptation in the NLP field. It suggests comparing the efficacy of the transfer parts instead of relying on simpler n-gram features. This feedback is actionable and offers a clear direction for the authors to enhance their draft by incorporating more advanced models and conducting a more thorough comparison. However, the comment could be more helpful if it included additional details or examples to guide the authors in implementing this suggestion effectively. Overall, the comment is mostly helpful as it provides a valuable insight into potential improvements, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a critical issue regarding the proposed method, which includes several complicated modules and more parameters than the baselines. It questions whether the main performance gain is due to a specific module or simply the increased number of parameters. The comment suggests that the current ablation study does not provide definitive answers to these questions. However, it does not offer any explicit or implicit guidance on how the authors should address this issue or what specific actions they should take to clarify the source of the performance gain. The lack of actionable steps or suggestions leaves the authors without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed method, which comprises several complicated modules and has more parameters than the baselines. It questions whether the main performance gain originates from a particular module or if the improvement is merely due to having more parameters. The comment also notes that the current version of the ablation study does not provide definitive answers to these questions. However, the comment does not specify which part of the paper discusses the proposed method or the ablation study, making it weakly grounded. It is specific in identifying the issue with the performance gain and the lack of clarity in the ablation study. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the source of performance gains in the proposed method, specifically questioning whether the gains are due to a particular module or simply the increased number of parameters. The comment suggests that the current ablation study does not provide definitive answers to these questions. However, the comment lacks specific examples or references to support the claim that the ablation study is insufficient. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it highlights a potential issue but does not provide a clear path for addressing it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the proposed method, which involves several complicated modules and a higher number of parameters compared to the baselines. It questions whether the main performance gain is due to a specific module or simply the increased number of parameters. The comment highlights that the current ablation study does not provide definitive answers to these questions, which is a crucial point for the authors to address. However, the comment lacks specific suggestions or guidance on how the authors might conduct a more thorough ablation study or what additional experiments could be conducted to clarify the source of the performance gain. While it points out a critical issue, the feedback could be more helpful if it provided actionable steps or suggestions for improvement. Therefore, the comment is somewhat helpful, as it identifies a meaningful weakness but does not offer detailed guidance for resolution.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for more explanation regarding why two quantities are different and how this captures the difference in learning settings. It also expresses a leaning toward acceptance, suggesting that the authors should consider the possibility of including \"pure theory\" papers. However, the comment does not provide specific guidance on how to address the request for more explanation or how to incorporate the suggestion about \"pure theory\" papers. The action is implicit and somewhat vague, as the authors need to infer what needs to be done. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific section of the paper (lines 196-7), allowing the authors to accurately identify the part being addressed. It also specifies what needs to be addressed, namely, the requirement for more explanation regarding why two quantities are different and how this captures the difference in learning settings. The comment is specific in its request for clarification and suggests a leaning toward acceptance, which provides a clear direction for the authors. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the explanation of why two quantities are different and how this captures the difference in learning settings. It also expresses a leaning toward acceptance, suggesting that the authors should consider the possibility of including \"pure theory\" papers. However, the comment lacks specific examples or detailed reasoning to support the claim that the explanation is insufficient or unclear. Without additional context or evidence, the authors may find it challenging to fully understand and address the feedback. Therefore, the comment is considered borderline verifiable, as it provides some basis for understanding but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area in the paper that requires more explanation, specifically regarding why two quantities are different and how this captures the difference in learning settings. It also expresses a leaning toward acceptance, suggesting that the authors should consider the possibility of including \"pure theory\" papers. While the comment highlights a potential area for improvement, it does not provide detailed guidance or suggestions on how to address the issue of insufficient explanation or how to incorporate the suggestion about \"pure theory\" papers. The feedback is somewhat helpful as it points out a specific area for improvement but lacks depth and actionable advice. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This is a clear and explicit action that the authors can take to address the comment. However, the comment does not provide specific guidance on how to conduct this discussion or what aspects of sensitivity to consider. While the action is explicit, it lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment asks the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for a discussion on sensitivity, but without grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point asks the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This is a request for clarification and does not contain a subjective claim or suggestion that requires verification. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment requests a discussion on the sensitivity of fixed tuning parameters in the model, specifically asking for both strengths and weaknesses. This feedback is clear and actionable, as it directs the authors to address a specific aspect of their model that could impact its performance and reliability. However, the comment lacks depth and does not provide guidance on how to conduct this discussion or what specific parameters to consider. While it offers a starting point for improvement, it could be more helpful if it included suggestions on how to approach the discussion or what aspects of sensitivity to focus on. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests exploring the performance of the proposed framework with different policy gradient approaches, specifically mentioning DDPO and IPPG. It also raises a question about the number of random seeds used for learning the policies. While the comment implies that the authors should conduct additional experiments to address these points, it does not provide explicit instructions on how to implement this exploration or how to determine the number of random seeds. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring the performance of the proposed framework with different policy gradient approaches, specifically mentioning DDPO and IPPG. It also raises a question about the number of random seeds used for learning the policies. However, the comment does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to explore different policy gradient approaches and to clarify the number of random seeds used, but without explicit references to sections or figures, the authors may need to infer the relevant parts. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the performance of the proposed framework with different policy gradient approaches, specifically mentioning DDPO and IPPG, and asks for clarification on the number of random seeds used in the experiments. However, the comment does not provide any evidence, reasoning, or references to support these claims or questions. The authors are left to interpret the questions and potentially conduct additional experiments or clarify their methodology, which makes the comment unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an interesting question about the performance of the proposed framework with different policy gradient approaches, specifically mentioning DDPO and IPPG. It also asks for clarification on the number of random seeds used in the experiments, which is a crucial detail for reproducibility and understanding the robustness of the results. However, the comment lacks specific guidance on how to address these points or what experiments should be conducted to explore the framework's performance with different approaches. While it identifies an area for further investigation, it does not provide actionable steps or suggestions for improvement, making it somewhat helpful. The feedback is valuable but could be more comprehensive if it included detailed guidance on how to conduct the additional experiments or clarify the experimental setup.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper's evaluation would be stronger if it were applied to more datasets and more tasks. This provides a clear and explicit action for the authors to take, as they can directly apply this feedback by expanding their evaluation to include additional datasets and tasks. The comment is specific in its suggestion, detailing exactly what needs to be done to strengthen the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper's evaluation would be stronger if it were applied to more datasets and more tasks. However, it does not specify which parts of the paper are being addressed or how the evaluation is conducted. The authors cannot confidently determine which sections or figures are being referred to, making the comment weakly grounded. Additionally, while the comment is specific in suggesting the need for more datasets and tasks, it lacks detailed guidance on how to achieve this. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper's evaluation would be stronger if it were applied to more datasets and more tasks. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. Without detailed justification or examples, the claim is somewhat verifiable, as it provides a general direction for improvement but lacks the necessary depth to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper's evaluation, noting that it is based on only one dataset and one task. This feedback is clear and actionable, as it suggests that expanding the evaluation to include more datasets and tasks would strengthen the results and conclusions. By providing a specific direction for improvement, the comment empowers the authors to enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it offered additional guidance on how to select or expand the datasets and tasks, or suggested specific types of tasks that would be beneficial to include. Overall, the comment is mostly helpful, as it provides a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the writing could be improved in certain areas, specifically pointing out a difficulty in interpreting definition 2.1. It provides an example by asking for clarification on the \"relevant\" auxiliary model weights. However, the comment does not explicitly instruct the authors to revise the writing or provide specific guidance on how to improve the clarity of the definition. While the authors can infer that they need to address the issue of clarity, the action is not concrete and lacks detailed instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"definition 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the definition, namely the difficulty in interpreting the \"relevant\" auxiliary model weights. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the writing could be improved in certain areas, specifically pointing out a difficulty in interpreting definition 2.1. It provides an example by asking for clarification on the \"relevant\" auxiliary model weights. However, the comment lacks specific guidance or examples to support the claim that the writing is difficult to interpret. Without additional context or examples, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is considered borderline verifiable, as it provides some indication of an issue but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area where the writing could be improved, particularly in the context of definition 2.1. It points out a lack of clarity regarding the \"relevant\" auxiliary model weights, which could hinder the reader's understanding. While the comment highlights a potential issue, it does not provide detailed suggestions or guidance on how to improve the clarity of the definition. This feedback is somewhat helpful as it directs the authors to a specific area for improvement, but it lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the robustness of MIA testing for privacy guarantees and recommends using U-LiRA. However, it does not provide explicit instructions or suggestions on how the authors should address this issue or incorporate U-LiRA into their work. The comment lacks concrete guidance on how to improve the robustness of MIA testing or how to implement the recommendation. As a result, the authors are left without a clear understanding of what steps to take to address the concern. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of MIA (Membership Inference Attack) testing in the paper, specifically mentioning the robustness of MIA testing for privacy guarantees and recommending the use of U-LiRA. However, it does not specify which part of the paper discusses MIA testing or how it is used. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. The comment is specific in that it identifies a potential issue with the robustness of MIA testing and suggests a specific tool for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the effectiveness of MIA testing is not sufficiently robust for privacy guarantees and recommends using U-LiRA. However, the comment lacks specific evidence or references to support this claim. It does not provide detailed reasoning or examples to substantiate the assertion about the robustness of MIA testing. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the robustness of Membership Inference Attack (MIA) testing for privacy guarantees, which is a critical aspect of evaluating unlearning effectiveness. It suggests that the current approach might not be sufficiently robust and recommends using U-LiRA, a specific tool for MIA testing. However, the comment lacks detailed guidance on how the authors should address this issue or incorporate U-LiRA into their work. While it points out a potential area for improvement, it does not provide actionable steps or suggestions for enhancing the robustness of the MIA testing or how to effectively use U-LiRA. As a result, the comment is somewhat helpful, as it highlights a concern but does not offer comprehensive guidance for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests that this could be presented in the context of kernel interpolation/smoothing. While the comment implies that the authors should consider this extension, it does not provide explicit instructions or detailed guidance on how to incorporate it into the paper. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to address the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests that this could be presented in the context of kernel interpolation/smoothing. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is specific in its suggestion but lacks grounding as it does not provide clear references or sections to focus on. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests that this could be presented in the context of kernel interpolation/smoothing. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests that this could be presented in the context of kernel interpolation/smoothing. While the comment identifies a potential area for expansion or clarification, it does not provide specific guidance or suggestions on how to address this issue. The feedback is somewhat helpful as it points out a potential avenue for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the paper, including the qualitative nature of explanations, minimal or missing descriptions of procedures in simulation or experiment-based evidence, confusing figures (e.g., \"sample count\" in Figure 2), and the lack of error bars or p-values in statistical inferences. While the comment identifies these areas for improvement, it does not provide explicit instructions on how to address them. The authors are left to infer that they need to add more details, figures, and statistical measures, but the lack of concrete guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses issues with the qualitative nature of explanations and the lack of detail in simulation or experiment-based evidence, specifically mentioning figures and statistical inferences. However, it does not specify which parts of the paper these issues are present in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as adding more details to the figures and including error bars or p-values. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the explanations are qualitative and that the procedures for simulation or experiment-based evidence are minimally described. It also notes that some figures are confusing, specifically mentioning \"sample count\" in Figure 2, and suggests adding more details to the paper or supplementary information. The comment also criticizes the lack of error bars or p-values in statistical inferences. While the comment identifies specific issues, it lacks detailed reasoning or references to support these claims, making it somewhat verifiable. The authors would need to infer the basis for these claims, which could be challenging. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several areas for improvement in the paper, including the qualitative nature of explanations, minimal or missing descriptions of procedures in simulation or experiment-based evidence, confusing figures, and the lack of error bars or p-values in statistical inferences. While the comment provides a clear overview of these issues, it lacks specific guidance on how to address them. The authors are left to infer that they need to add more details, clarify figures, and include statistical measures, but the feedback is somewhat vague and could be more actionable. Therefore, the comment is somewhat helpful, as it offers insights but requires further elaboration to be fully beneficial.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some claims in the paper might be inspired from existing studies and recommends adding supportive references. It provides an example of a section (Lines 55-64) where this issue is mentioned. However, the comment does not explicitly instruct the authors to add these references or provide specific guidance on which references to include. The action is implicit and somewhat vague, as the authors are left to infer that they need to add references to support the claims made in the specified section. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions Lines 55-64, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear example of claims that have been discussed in existing studies, suggesting that the authors should add supportive references. This feedback is detailed and provides a clear direction for improvement, making it fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some claims in the paper are inspired from existing studies and suggests adding supportive references. It provides an example of a section (Lines 55-64) where this issue is mentioned. However, the comment lacks specific references or detailed reasoning to support the claim that the claims are inspired from existing studies. Without concrete examples or references, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks key elements for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a critical issue in the paper, noting that some claims might be inspired from existing studies. It suggests adding supportive references to strengthen the claims, which is a valuable piece of feedback. However, the comment could be more helpful if it provided specific examples of where these references should be added or suggested which studies might be relevant. Additionally, it could offer guidance on how to effectively integrate these references into the paper. While the feedback is somewhat helpful, it could be more comprehensive and actionable to fully assist the authors in improving their draft.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. It also recommends providing a single review of the various advances in this area to benefit the community. While the comment provides a clear direction for improvement, it does not specify which settings need to be shown or how to mimic the prior work. The action is explicit but somewhat vague, as it lacks detailed guidance on how to implement the suggested changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact area that needs improvement. The comment is specific in its suggestion to provide a single review of the various advances in the area, but it lacks grounding as it does not mention specific sections or parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. However, the comment lacks specific details or examples of how this could be achieved, making it difficult for the authors to understand and implement the suggested improvement. Without additional context or guidance, the claim remains somewhat verifiable, as it lacks the necessary depth and specificity to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. It also recommends providing a single review of the various advances in this area to benefit the community. While the comment identifies a potential area for improvement, it lacks specific guidance on how to implement these suggestions. The feedback is somewhat helpful as it points out a direction for enhancing the paper's clarity and impact, but it does not provide detailed instructions or examples, which could make it more actionable for the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors would have appreciated more datasets, particularly for the cross-task transferability aspect. However, it does not provide explicit guidance on which datasets to include or how to incorporate them into the paper. The action is implicit, as the authors need to infer that they should add more datasets to address the cross-task transferability. While the comment is somewhat actionable, it lacks concrete details on how to implement the suggested improvement. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors would have appreciated more datasets, especially concerning the cross-task transferability aspect. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure. The authors cannot confidently determine which part of the paper needs to be addressed, making the comment weakly grounded. Additionally, the comment is specific in suggesting the inclusion of more datasets for cross-task transferability, providing a clear direction for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors would have appreciated more datasets, particularly concerning the cross-task transferability aspect. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors would have appreciated more datasets, especially concerning the cross-task transferability aspect. While this feedback provides a clear direction for improvement, it lacks specific guidance on which datasets to include or how to incorporate them into the paper. The comment is somewhat helpful as it identifies a potential area for enhancement, but it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the tasks performed on the dataset are somewhat standard and proposes the inclusion of unique tasks, such as interleaved image-text tasks like Question Answering from images, to showcase the diversity of the dataset. However, the comment does not provide explicit guidance on how to implement these unique tasks or what specific aspects of the dataset should be emphasized. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the tasks performed on the dataset are somewhat standard, specifically mentioning figure captioning and matching figures/sub-figures to appropriate captions. It proposes the inclusion of unique tasks, such as interleaved image-text tasks like Question Answering from images, to showcase the diversity of the dataset. However, the comment does not specify which part of the paper these tasks are discussed or proposed for, making it weakly grounded. The comment is specific in detailing the suggestion for unique tasks, but the lack of grounding makes it difficult for the authors to understand which part of the paper needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the tasks performed on the dataset are somewhat standard and proposes the inclusion of unique tasks, such as interleaved image-text tasks like Question Answering from images, to showcase the diversity of the dataset. However, the comment lacks specific examples or references to support the claim that the current tasks are standard or that the suggested tasks would effectively demonstrate the dataset's diversity. Without detailed reasoning or examples, the claim is somewhat verifiable, as it provides a general suggestion but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential area for improvement by suggesting the inclusion of unique tasks, such as interleaved image-text tasks like Question Answering from images, to showcase the diversity of the dataset. This feedback is somewhat helpful as it provides a direction for enhancing the tasks performed on the dataset, but it lacks specific guidance on how to implement these unique tasks or what aspects of the dataset should be emphasized. The comment could be more helpful if it offered detailed examples or suggestions for how to integrate these tasks into the draft. Overall, the feedback is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the tractability of MMD DRO and the limitations of the upper bound in Theorem 3.1. It highlights that MMD DRO does not have a tractable exact equivalent reformulation, which is a significant drawback. The comment also points out that the upper bound is crude due to the omission of the nonnegative constraint on the distribution and that further approximation is needed even for simple kernel ridge regression problems. Additionally, it notes that assuming the loss function belongs to the RKHS is restrictive, as the authors themselves pointed out. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks concrete guidance on how to improve the tractability of MMD DRO or how to refine the upper bound. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the tractability of MMD DRO and the limitations of the upper bound in Theorem 3.1, specifically mentioning that MMD DRO does not have a tractable exact equivalent reformulation. It also highlights the crude nature of the upper bound due to the omission of the nonnegative constraint on the distribution and the need for further approximation. Additionally, the comment points out the restrictive assumption of the loss function belonging to the RKHS. However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The lack of explicit references to specific sections or parts of the paper makes the comment weakly grounded. While it provides some specificity by detailing the issues with the tractability and the upper bound, the absence of grounding limits the authors' ability to effectively address the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several concerns about the tractability of MMD DRO and the limitations of the upper bound in Theorem 3.1. It claims that MMD DRO does not have a tractable exact equivalent reformulation, which is a significant drawback. The comment also points out that the upper bound is crude due to the omission of the nonnegative constraint on the distribution and that further approximation is needed even for simple kernel ridge regression problems. Additionally, it notes that assuming the loss function belongs to the RKHS is restrictive, as the authors themselves pointed out. However, the comment lacks specific examples or detailed reasoning to fully substantiate these claims. While it provides a general overview of the issues, it does not offer detailed explanations or references to support the claims, making it somewhat verifiable. Therefore, the comment aligns with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several valid concerns about the tractability of MMD DRO and the limitations of the upper bound presented in Theorem 3.1. It highlights that MMD DRO does not have a tractable exact equivalent reformulation, which is a significant drawback. The comment also points out that the upper bound is crude due to the omission of the nonnegative constraint on the distribution and that further approximation is needed even for simple kernel ridge regression problems. Additionally, it notes that assuming the loss function belongs to the RKHS is restrictive, as the authors themselves pointed out. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the tractability of MMD DRO or the upper bound. While it identifies important areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the relevance of the framework in the context of non-convex losses and non-norm type defenses, as well as its applicability to binary classification scenarios where the true mean is known. It questions whether the framework remains relevant given the challenges of non-vanishing duality gaps and the difficulty of maximization over non-norm type constraints. Additionally, it asks whether the framework can provide intuitions on the risk upper bound and suggests exploring the use of covariance or other statistics to design a better defense. However, the comment does not provide explicit guidance on how the authors should address these questions or incorporate them into their draft. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the relevance of the framework in the context of non-convex losses and non-norm type defenses, specifically questioning its applicability given the challenges of non-vanishing duality gaps and the difficulty of maximization over non-norm type constraints. It also asks about the relevance of the framework in binary classification scenarios where the true mean is known through an oracle, suggesting the use of covariance or other statistics to design a better defense. However, the comment does not specify which part of the paper these questions relate to, making it weakly grounded. The questions are specific in nature, as they delve into the applicability and relevance of the framework in different contexts. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the relevance of the framework in the context of non-convex losses and non-norm type defenses, specifically questioning whether the non-vanishing duality gap and the difficulty of maximization over non-norm type constraints make the algorithm irrelevant. It also asks about the applicability of the framework in binary classification scenarios where the true mean is known through an oracle, suggesting the use of covariance or other statistics to design a better defense. However, the comment does not provide any evidence, reasoning, or references to support these claims, making it difficult for the authors to understand the basis of the questions or how to address them. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several questions about the relevance and applicability of the framework in specific contexts, such as non-convex losses and non-norm type defenses, as well as in binary classification scenarios where the true mean is known. It questions whether the non-vanishing duality gap and the difficulty of maximization over non-norm type constraints make the algorithm irrelevant or if it can still provide some intuition on the risk upper bound. Additionally, it asks whether the framework can be used to design a better defense by utilizing covariance or other statistics. However, the comment lacks detailed guidance or suggestions on how the authors might address these questions or incorporate them into their work. While it identifies areas for improvement, it does not provide actionable steps or insights that would help the authors enhance their draft. Therefore, the comment is barely helpful, as it offers some direction but lacks depth and specificity to fully assist the authors.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about an action that could be taken with the baselines in Figure 3. It suggests sparsifying the trained models to reduce the number of selected features and comparing the accuracy to the proposed model. However, the comment does not provide explicit guidance on how to implement this action or what specific steps the authors should take. While the suggestion is clear, the lack of detailed instructions or examples makes it somewhat vague. Therefore, the comment is somewhat actionable, as it provides a direction but lacks concrete details on how to execute it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests an action to be taken with the baselines on the left-hand side of the figure, specifically to sparsify the trained models and compare accuracy to the proposed model. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about an action that could be taken with the baselines in Figure 3, specifically suggesting sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. However, the comment does not provide any justification, reasoning, or references to support why this action is relevant or beneficial. Without additional context or explanation, the claim is unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about an action that could be taken with the baselines in Figure 3, suggesting that the authors could sparsify the trained models to reduce the number of selected features and compare accuracy to the proposed model. This feedback is somewhat helpful as it identifies a potential area for improvement and provides a clear direction for the authors to consider. However, it lacks depth and does not offer detailed guidance or suggestions on how to implement this action effectively. The comment could be more helpful if it provided additional context or examples of how sparsification might impact the results. Overall, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the Appendix H section should be reorganized to improve its readability. However, it does not provide specific guidance on how to reorganize the section or what aspects of the organization are problematic. The comment lacks concrete details, leaving the authors uncertain about the exact steps to take. As a result, the action is implicit and vague, making it difficult for the authors to apply the feedback effectively. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the Appendix H section should be reorganized to improve its readability. However, it does not specify which part of the paper Appendix H corresponds to, making it difficult for the authors to identify the exact section that needs reorganization. Additionally, the comment lacks specificity in detailing what aspects of the section are difficult to follow, such as the structure, flow, or clarity of the content. Without these details, the authors are left without a clear understanding of how to address the issue. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the Appendix H section should be reorganized to improve its readability. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this reorganization is necessary or how it would benefit the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the organization of Appendix H, suggesting that it is difficult to follow. However, it lacks specific details or suggestions on how the authors might reorganize the section to improve its readability. Without actionable guidance or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is barely helpful, as it provides a general observation but no concrete steps for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with the paper's clarity and reproducibility. It notes that while the paper provides an intuitive understanding, it lacks the necessary details for reproduction, such as specific implementation details of the RNN, including the number of units. However, the comment does not explicitly instruct the authors to include these details or provide guidance on how to do so. While the action is implied, it is vague and lacks concrete steps, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paper and the issue of reproducibility, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the lack of necessary details for reproduction, such as RNN implementation specifics like the number of units, and other technical details. This provides clear guidance on what needs to be addressed to improve the paper\\'s reproducibility. Therefore, this comment is classified as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is written to provide an intuitive understanding but lacks details for reproduction, such as RNN implementation specifics. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand and address the issue. The lack of detailed justification or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper's reproducibility, noting that while it provides an intuitive understanding, it lacks the necessary technical details for others to reproduce the work. This includes specific implementation details, such as the number of units in the RNN, which are crucial for reproducibility. The comment is clear and actionable, providing a specific example of what is missing and how it impacts the paper's reproducibility. However, it could be more helpful if it suggested specific ways to include these details or provided guidance on how to enhance the paper for reproducibility. Overall, the comment is mostly helpful as it highlights a significant area for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the novelty and testability of the model in generating knowledge or hypotheses about neuron data. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific aspects of the model need to be clarified. The comment lacks concrete guidance on how the authors can improve the draft to address this concern. As a result, the authors are left without a clear understanding of what actions to take to enhance the paper. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the novelty and testability of the model in generating knowledge or hypotheses about neuron data. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. Without explicit mention or context, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment does not provide specific guidance or suggestions on how to address the question or improve the paper. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the novelty and testability of the model in generating knowledge or hypotheses about neuron data. However, it does not provide any specific evidence, reasoning, or references to support the claim that the model could generate novel knowledge or testable hypotheses. Without additional context or justification, the authors are left to interpret the question, making it difficult to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the novelty and testability of the model in generating knowledge or hypotheses about neuron data. This is a valid concern that could impact the paper's contribution and impact. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what aspects of the model need clarification. Without actionable feedback or detailed suggestions, the authors may find it challenging to improve their draft based on this comment alone. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not provide comprehensive guidance for improvement.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the approach used in the KeyQN section, specifically regarding the calculation of the averaged feature vector. It suggests that the current method might be incorrect and proposes an alternative approach. However, the comment does not provide explicit guidance on how the authors should revise their method or what specific changes to make. The action is implicit, as the authors need to infer that they should reconsider their approach and potentially implement the suggested alternative. While the action is somewhat concrete, it lacks detailed instructions on how to apply it, making the comment borderline actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"KeyQN section\" and the specific part of the section, \"What is the keypoint mask averaged feature vector?\". This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the approach used in calculating the averaged feature vector and suggests an alternative method. This provides clear guidance on what needs to be addressed in the section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the approach used in the KeyQN section, specifically regarding the calculation of the averaged feature vector. It suggests that the current method might be incorrect and proposes an alternative approach. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the current method might be incorrect or why the alternative approach is better. Without additional context or explanation, the claim lacks sufficient support, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the approach used in the KeyQN section, specifically regarding the calculation of the averaged feature vector. It suggests that the current method might be incorrect and proposes an alternative approach. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors should revise their method or what changes to implement. While it identifies a potential issue, it does not offer actionable feedback or detailed reasoning to help the authors address the concern effectively. Therefore, the comment is somewhat helpful, as it highlights a potential area for improvement but does not fully support the authors in making necessary revisions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the central contribution of the paper, specifically the modeling of weight evolution using ODEs, and raises concerns about the novelty of the problem it addresses. It suggests that the paper does not provide a convincing analytical argument or empirical evidence to support the claim that neural ODEs exhibit inaccuracy while recomputing activations. However, the comment does not offer any specific guidance or suggestions on how the authors might address this issue or strengthen their argument. The authors are left without a clear path to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the central contribution of the paper, specifically the modeling of weight evolution using ODEs, and raises concerns about the novelty of the problem it addresses. However, it does not specify which part of the paper discusses this contribution or the issue of neural ODEs exhibiting inaccuracy while recomputing activations. The authors are left to infer that the comment pertains to the introduction or methodology sections, but without explicit references, the grounding is weak. The comment is specific in its critique of the analytical argument and empirical evidence provided, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas that need improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the central contribution of the paper, specifically the modeling of weight evolution using ODEs, and raises concerns about the novelty of the problem it addresses. It claims that the paper does not provide a convincing analytical argument or empirical evidence to support the claim that neural ODEs exhibit inaccuracy while recomputing activations. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence weakens the verifiability of the claim, aligning with a score of 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the central contribution of the paper, specifically the modeling of weight evolution using ODEs. It questions the novelty of the problem addressed, suggesting that the paper does not provide a convincing analytical argument or empirical evidence to support the claim that neural ODEs exhibit inaccuracy while recomputing activations. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or strengthen their argument. Without actionable feedback or detailed examples, the authors are left without a clear path to improve their draft, making the comment somewhat helpful but not fully comprehensive. Therefore, it aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the paper by suggesting that the lower bound results for round complexity in batched ranking problems are not novel, as they follow easily from existing collaborative ranking results. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to make the results more impactful. The action is implicit, as the authors are left to infer that they should consider expanding the discussion or providing a more detailed analysis to differentiate their work from existing results. The comment is somewhat actionable because it identifies a potential area for improvement, but it lacks concrete steps or suggestions on how to achieve this. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"proving lower bounds for round complexity\" and \"batched ranking problems,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper exploits an easy reduction from collaborative ranking, making the lower bound results follow as a corollary. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that proving lower bounds for round complexity is a major part of work in batched ranking problems, but the paper exploits an easy reduction from collaborative ranking, making the lower bound results a corollary. This claim is somewhat verifiable as it provides a logical reasoning for why the results might not be novel. However, it lacks specific examples or references to support the claim fully, which could make it difficult for the authors to understand the exact nature of the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper by suggesting that the lower bound results for round complexity in batched ranking problems are not novel, as they follow easily from existing collaborative ranking results. This observation highlights a gap in the paper's contribution and provides a clear direction for the authors to consider expanding their discussion or providing a more detailed analysis to differentiate their work from existing results. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might address this issue, such as suggesting additional experiments or analyses to strengthen the novelty of their findings. Overall, the comment is somewhat helpful as it points out a potential area for improvement but lacks detailed actionable feedback. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the prompting technique used in the study is basic and does not fully leverage the potential of LLMs. It recommends that carefully curated prompts could yield better results in generating systematic reviews. However, the comment does not provide explicit guidance on how the authors should implement this suggestion or what specific aspects of the prompting technique need improvement. The action is implicit and vague, as it does not specify which prompts are basic or how they can be improved. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the prompting technique used in the study is basic and does not fully leverage the potential of LLMs. It recommends that carefully curated prompts could yield better results in generating systematic reviews. However, the comment does not specify which part of the paper discusses the prompting technique or where the authors should focus their attention. This lack of grounding makes it difficult for the authors to understand which section or aspect of the paper needs improvement. Additionally, the comment is specific in its suggestion to use carefully curated prompts, but without clear guidance on how to implement this suggestion, it remains somewhat specific. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the prompting technique used in the study is basic and fails to leverage the full potential of LLMs. It suggests that carefully curated prompts could yield better results in generating systematic reviews. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. Without detailed reasoning or evidence, the claim is considered borderline verifiable, as it provides some basis but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the study by pointing out that the prompting technique used is basic and does not fully leverage the capabilities of LLMs. It suggests that carefully curated prompts could yield better results in generating systematic reviews. However, the comment lacks specific guidance on how the authors might improve their prompting techniques or what aspects of their current approach could be enhanced. While it highlights an area for improvement, the feedback is somewhat limited in its actionable and detailed nature, making it somewhat helpful. The authors would need to infer how to address the issue, which limits the comment's effectiveness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific examples of how the performance of the models in Table 4 is behind more recent models, citing GLaMM and UNINEXT. However, it does not offer any explicit or implicit suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable guidance, leaving the authors without a clear path to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed examples of how the performance of the models in Table 4 is behind more recent models, citing specific models and their performance metrics. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance on REC and RES in Table 4 is behind more recent models, providing specific examples of how these models perform compared to the current models. The claim is supported by the inclusion of references to GLaMM and UNINEXT, which provide specific performance metrics. This level of detail and evidence makes the claim fully verifiable, as it provides a clear basis for comparison and highlights areas for improvement. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of the models in Table 4, noting that they are behind more recent models. It provides concrete examples of how these models perform, referencing GLaMM and UNINEXT, which achieve higher performance metrics. This feedback is valuable as it highlights a clear area for improvement and provides specific examples for the authors to consider. However, the comment could be more helpful if it offered suggestions on how the authors might address this performance gap or what steps they could take to improve their models. Despite this, the comment is mostly helpful as it directs the authors to areas that need attention and provides a basis for further discussion. Therefore, the comment is rated as 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should revise their claim about the evidence supporting the idea that some information is learned before the model can use the concepts. The comment implies that the current phrasing, \"evidence,\" is too strong and suggests a more specific term like \"Fig.\" However, it does not provide explicit guidance on how to revise the claim or what specific changes are needed. The action is implicit and somewhat vague, as the authors need to infer that they should replace \"evidence\" with a more precise term and potentially reference a figure. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should revise their claim about the evidence supporting the idea that some information is learned before the model can use the concepts, recommending a more specific term like \"Fig.\" This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should revise their claim about the evidence supporting the idea that some information is learned before the model can use the concepts. The comment implies that the current phrasing, \"evidence,\" is too strong and suggests a more specific term like \"Fig.\" However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or examples makes the claim somewhat verifiable, as it lacks sufficient evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the phrasing of a claim in the paper, suggesting that the term 'evidence' might be too strong and recommending a more specific term like 'Fig.' This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, it could be more helpful if it offered additional guidance on how to revise the claim or what specific changes to make. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the novelty of the proposed video storyboarding approach, noting that it primarily relies on frame-wise SDSA, similar to ConsiStory, with the main difference being the mask source. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this limitation or enhance the novelty of their approach. Without actionable guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the proposed video storyboarding approach, specifically mentioning that it relies on frame-wise SDSA, similar to ConsiStory, with the main difference being the mask source. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or figure being addressed. The comment is specific in detailing the issue of limited novelty but lacks grounding as it does not provide explicit references to the paper sections. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the innovation of the proposed video storyboarding approach is limited, as it primarily relies on frame-wise SDSA, similar to ConsiStory, with the main difference being the mask source. The comment provides a specific example of a similar approach, suggesting that the novelty is limited. However, it lacks detailed reasoning or references to support the claim fully. The authors could benefit from additional evidence or examples to strengthen the argument. Therefore, the comment is somewhat verifiable, as it provides some justification but lacks depth and detail.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the novelty of the proposed video storyboarding approach, noting that it primarily relies on frame-wise SDSA, similar to ConsiStory, with the main difference being the mask source. While the comment highlights this limitation, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. Without actionable feedback or suggestions for improvement, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it points out a weakness but lacks depth and direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the weakness of the method being addressed might be more prominent in images with multiple objects or cluttered scenes. It proposes an interesting comparison to previous approaches on few-shot classification using such a dataset. However, the comment does not provide explicit guidance on how the authors should address this weakness or what specific steps they should take to improve their draft. The action is implicit and vague, as it does not specify how the authors should analyze the method's performance in cluttered scenes or how they should compare it to previous approaches. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the weakness of the method being addressed might be more prominent in images with multiple objects or cluttered scenes. It proposes an interesting comparison to previous approaches on few-shot classification using such a dataset. However, the comment does not specify which part of the paper discusses the method or where the comparison to previous approaches should be made. This makes it difficult for the authors to identify the specific section or part of the paper that needs attention. The comment is specific in its suggestion but weakly grounded as it does not provide clear guidance on which part of the paper to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the weakness of the method being addressed might be more prominent in images with multiple objects or cluttered scenes. It proposes an interesting comparison to previous approaches on few-shot classification using such a dataset. However, the comment lacks specific details or examples to substantiate this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. Without further elaboration or evidence, the claim remains somewhat verifiable, as it lacks the necessary depth and support to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the method, suggesting that it might be more prominent in images with multiple objects or cluttered scenes. It proposes an interesting comparison to previous approaches on few-shot classification using such a dataset. However, the comment lacks specific guidance on how the authors should address this weakness or what steps they should take to improve their draft. While it provides a direction for further exploration, it does not offer detailed suggestions or actionable advice, making it somewhat helpful. The feedback is valuable but could be more comprehensive and actionable to fully assist the authors in enhancing their work.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the relative gains of the proposed method, suggesting that it might be easy to improve a relatively small backbone due to its smaller receptive field. It also raises a question about whether the proposed method still works well on larger backbone models like Swin-B or Swin-L. While the comment identifies a potential issue with the method's effectiveness on larger backbones, it does not provide explicit guidance on how to address this concern or what specific experiments or analyses should be conducted. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate the performance of the proposed method on larger backbones. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the relative gains of the proposed method across different frameworks and tasks, noting that the gains are not very strong. It specifically mentions that the proposed methods achieve only about 1% gain on a relatively small backbone ResNet-50. The comment also raises a question about whether the proposed method works well on larger backbone models like Swin-B or Swin-L. However, the comment does not explicitly mention which part of the paper this issue is related to, making it weakly grounded. The specificity of the comment is moderate as it clearly specifies the issue with the relative gains and the question about larger backbones, but it does not provide detailed guidance on how to address these concerns. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the relative gains of the proposed method are not very strong, particularly when compared to the baselines. It suggests that the proposed method might be easy to improve on a relatively small backbone due to its smaller receptive field, and questions whether it still works well on larger backbone models like Swin-B or Swin-L. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide references or evidence to substantiate the assertion about the relative gains or the ease of improvement on smaller backbones. As a result, the claim is not fully verifiable, aligning with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding the relative gains of the proposed method, noting that it is not very strong compared to the baselines. It also raises a question about whether the proposed method would still perform well on larger backbone models like Swin-B or Swin-L, given that it introduces global pooling. While the comment highlights an area for further investigation, it does not provide detailed guidance or suggestions on how to address this issue or what specific experiments or analyses should be conducted to explore the performance on larger backbones. The feedback is somewhat helpful as it points out a potential limitation and encourages further exploration, but it lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the analysis of neural networks, suggesting that it contributes less due to the triviality of extending from linear models to wide fully-connected neural networks, given the existing NTK theorem. It mentions specific sections of the paper (3.2 and 3.3) where this issue is discussed. However, the comment does not provide explicit guidance on how the authors might address this issue or improve their analysis. While the authors can infer that they need to strengthen their analysis or provide a more detailed discussion of the limitations of the current approach, the lack of concrete suggestions makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2, 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the contribution of the analysis of neural networks and the triviality of extending from linear models to wide fully-connected neural networks. This provides clear guidance on how the authors can improve their work. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis of neural networks contributes less due to the triviality of extending from linear models to wide fully-connected neural networks, given the existing NTK theorem. The comment provides a specific example of how the extension is considered trivial, referencing sections 3.2 and 3.3. However, it lacks detailed reasoning or examples to fully substantiate the claim. While the authors can infer that the analysis might be insufficient, the comment does not offer a comprehensive explanation or evidence to support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area of the paper where the analysis of neural networks contributes less, suggesting that the extension from linear models to wide fully-connected neural networks is trivial due to the existing NTK theorem. This feedback is somewhat helpful as it highlights a potential weakness in the analysis and provides a clear direction for improvement. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or expand their analysis to include more complex scenarios. Without specific guidance or suggestions, the authors may struggle to fully understand how to improve their work. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the clarity of the abstract and introduction regarding the cost of the multi-fidelity framework. It points out a discrepancy in the terminology used (\"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction). However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to improve the clarity. The action is implicit, as the authors would need to infer that they should clarify the terminology to avoid confusion. The comment is somewhat actionable because it identifies a specific area for improvement but lacks concrete instructions on how to implement it. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the multi-fidelity framework and sequential design for learning quantities of interest, referencing a specific paper (Stroh et al. 2017). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights a potential issue with the clarity of the abstract and introduction regarding the cost of the multi-fidelity framework, pointing out a discrepancy in terminology. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract and introduction use inconsistent terminology regarding the cost of the multi-fidelity framework, specifically mentioning \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. This claim is somewhat verifiable as it highlights a potential issue with clarity and consistency in the paper. However, it lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the clarity of the abstract and introduction regarding the cost of the multi-fidelity framework. It points out a discrepancy in terminology, specifically mentioning 'relatively inexpensive' in the abstract and 'expensive to evaluate' in the introduction. This feedback is somewhat helpful as it highlights a potential area for improvement in the paper's clarity and consistency. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue, such as clarifying the terminology or providing examples to illustrate the concepts. Without concrete advice, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of the curated AH36M dataset for training and suggests that it is not clearly indicated. It also asks whether other methods, such as HMR and SPIN, have access to this dataset during training for a fair comparison. While the comment identifies a potential issue and suggests a clarification, it does not provide explicit guidance on how the authors should address this concern or what specific actions they should take. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the dataset usage and compare training conditions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the use of the curated AH36M dataset for training and suggests that it is not clearly indicated. It also asks whether other methods, such as HMR and SPIN, have access to this dataset during training for a fair comparison. However, the comment does not specify which part of the paper discusses the dataset or the training process, making it difficult for the authors to pinpoint the exact section that needs clarification. While the comment is specific about the issue of dataset usage and comparison, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the use of the curated AH36M dataset for training and suggests that it is not clearly indicated. It also asks whether other methods, such as HMR and SPIN, have access to this dataset during training for a fair comparison. However, the comment does not provide any evidence, reasoning, or references to support the claim that the dataset usage is unclear or that the comparison is unfair. Without additional context or justification, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the clarity of the use of the curated AH36M dataset for training. It questions whether the dataset is used for training and whether other methods, such as HMR and SPIN, have access to the same data during training, which could affect the fairness of the comparison. While the comment identifies a potential issue, it does not provide specific guidance or suggestions on how the authors might address this concern or what changes could be made to ensure a fair comparison. The feedback is somewhat helpful as it highlights an important aspect of the methodology that needs clarification, but it lacks actionable advice for the authors to improve their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific suggestions for improving the comparison of the captioning experiment. It recommends comparing the results on the official COOC leader board on the blind test set, referencing specific examples and related work that have achieved high scores on this challenge. The comment also suggests comparing to other approaches that have been proposed since the initial work, which have significantly improved the results. By providing these detailed suggestions, the comment gives the authors a clear understanding of what needs to be done to enhance the paper. The action is explicit and concrete, as it specifies exactly what comparisons should be made and where to find relevant information. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the captioning experiment,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed suggestions for comparison, including references to the official COOC leader board on the blind test set and specific examples of related work that have won the challenge. The comment also suggests comparing to other approaches that have been proposed since then, which are significant improvements. This level of detail and specificity makes the comment highly informative and actionable for the authors. Therefore, this comment is rated as fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper should compare its results on the captioning experiment with official test sets or development sets, but it suggests comparing them on the official COOC leader board on the blind test set, referencing specific examples and related work that have won this challenge. The comment provides specific references and examples, such as [5, 17], which support the claim. Additionally, it suggests comparing to other approaches that have been proposed since then and have significantly improved the results, referencing the leaderboard. This level of detail and specificity makes the claim fully verifiable, as it provides clear evidence and reasoning to support the authors in improving their comparison. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the captioning experiment, suggesting that the paper should compare its results on the official COOC leader board on the blind test set, referencing specific examples and related work that have won this challenge. It also recommends comparing to other approaches that have been proposed since then and have significantly improved the results, referencing the leaderboard. This detailed feedback offers clear guidance on how the authors can enhance their comparison and ensure that their results are benchmarked against relevant and high-performing methods. The comment is mostly helpful as it provides a comprehensive and constructive suggestion for improvement, though it could be further expanded to include additional comparisons or specific methodologies. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the reliability of the experimental results, specifically noting that the MSE is significantly smaller than the MAE in Table 1, which raises concerns about their validity. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to verify the results, what steps to take to improve the reliability of the findings, or how to address the discrepancy between MSE and MAE. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue with the experimental results, noting that the MSE is significantly smaller than the MAE, which raises concerns about their validity. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results are unreliable, particularly in Table 1, where the MSE is significantly smaller than the MAE, raising concerns about their validity. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand why the results are considered unreliable or how to address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that the MSE is significantly smaller than the MAE in Table 1, which raises concerns about their validity. This feedback is clear and actionable, as it highlights a potential problem with the experimental findings that the authors should investigate and address. However, the comment could be more helpful if it provided suggestions on how to verify the results or what steps to take to improve the reliability of the findings. Despite this, the comment offers valuable insight into an area that needs attention, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of novelty in the methodology, suggesting that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might enhance the novelty of their methodology or what specific aspects need to be improved. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section or aspect being discussed. It is also not specific because it does not detail what aspects of the methodology lack novelty or how the proposed meta-algorithm is a direct extension of existing methods. Without specific references or detailed feedback, the authors cannot effectively address the comment. Therefore, this comment is rated as Not Grounded and Not Specific, corresponding to a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that there is not much novelty in the methodology, suggesting that the proposed meta-algorithm is a direct extension of existing methods. However, the comment lacks specific examples or references to support this claim. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by pointing out the lack of novelty in the methodology, specifically noting that the proposed meta-algorithm is a direct extension of existing methods. While this feedback highlights an area for improvement, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. The comment is somewhat helpful as it directs the authors to consider the novelty of their methodology, but it lacks depth and actionable advice, making it only marginally helpful.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the meaning of \"wrong\" in the context of the paper, suggesting that the authors should clarify what constitutes a good, bad, or wrong explanation. While the comment implies that the authors need to provide more context or examples to clarify the use of these terms, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the terminology. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the meaning of \"wrong\" in the context of the paper, suggesting that the authors should clarify what constitutes a good, bad, or wrong explanation. This provides a clear direction for the authors to improve the clarity of their writing. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the meaning of \"wrong\" in the context of the paper, specifically at line 248. It suggests that the authors should clarify what constitutes a good, bad, or wrong explanation before using these terms. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the use of \"wrong\" is unclear or problematic. Without additional context or justification, the reviewer's suggestion remains somewhat vague and lacks sufficient evidence to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific point of confusion in the paper, namely the use of the term \"wrong\" at line 248. It suggests that the authors should clarify what constitutes a good, bad, or wrong explanation before using these terms. This feedback is clear and actionable, as it provides a specific area for improvement and directs the authors to address a potential ambiguity in their writing. By clarifying the meaning of \"wrong,\" the authors can enhance the clarity and precision of their paper, making it easier for readers to understand their arguments. Therefore, the comment is mostly helpful, as it offers a clear and constructive suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the clarity of the concept of \"state\" in the paper, suggesting that it is represented by the \"grid status\" and obtained after applying an action. It also asks whether the term \"elements\" is equivalent to \"states\" or \"actions,\" implying that more elaboration is needed. While the comment explicitly states the need for clarification, it does not provide specific guidance on how the authors should elaborate on the concept or the relationship between \"elements,\" \"states,\" and \"actions.\" The action is clear but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the concept of \"state\" in the paper, specifically questioning its clarity and providing examples of how it is represented. It references specific lines (186-187) to pinpoint the part of the paper being discussed. However, it does not specify what needs to be addressed in terms of elaborating on the concept or providing more context. The comment is fully grounded as it mentions specific lines, but it is under-specific because it does not detail what needs to be addressed. Therefore, this comment is categorized as fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point questions the clarity of the concept of \"state\" in the paper, specifically asking whether \"elements\" are equivalent to \"states\" or \"actions.\" This is a subjective question that requires the authors to clarify their terminology. While the comment is clear and specific in its request for clarification, it does not provide any evidence or reasoning to support the claim that the concept of \"state\" is unclear. Therefore, the comment is considered \"3: Somewhat Verifiable,\" as it is clear but lacks detailed justification or references to support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the clarity of the concept of 'state' in the paper, specifically questioning whether 'elements' are equivalent to 'states' or 'actions.' This feedback is clear and actionable, as it prompts the authors to clarify their terminology and provide more context for the concept. However, the comment could be more helpful if it suggested specific ways to elaborate on the concept or provide examples to enhance understanding. Overall, the comment is somewhat helpful, as it provides a clear direction for improvement but lacks depth in its suggestions.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue in Section 5.3, noting that a generator with a standard R-GCN discriminator tends to collapse, while the proposed module does not. The reviewer suggests that the reason behind this difference is essential to demonstrate how the proposed method differs from previous ones. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the paper. The action is implicit, as the authors need to infer that they should provide a detailed explanation of the mechanism behind the proposed module's stability. While the action is somewhat concrete, it lacks explicit instructions on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular issue in this section, noting that a generator with a standard R-GCN discriminator tends to collapse, while the proposed module does not. The reviewer suggests that the reason behind this difference is essential to demonstrate how the proposed method differs from previous ones, implying that the authors should provide a detailed explanation of this mechanism. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a generator equipped with a standard R-GCN discriminator tends to collapse after several iterations, while the proposed module does not. The reviewer suggests that the reason behind this difference is essential to demonstrate how the proposed method differs from previous ones. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue in Section 5.3, noting that a generator with a standard R-GCN discriminator tends to collapse after several iterations, while the proposed module does not. The reviewer suggests that the reason behind this difference is crucial for demonstrating how the proposed method differs from previous ones. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or what specific improvements could be made to the paper. While it highlights an important area for clarification, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as barely helpful, as it points out a potential area for improvement but does not offer concrete advice or suggestions for the authors to follow.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit instructions or concrete examples of what needs to be clarified or improved. As a result, the authors are left without a clear understanding of how to respond to this feedback, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not specify which part of the paper discusses these comparisons, making it difficult for the authors to pinpoint the exact issue. The comment is specific in its critique but lacks grounding as it does not provide clear references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it identifies a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the sufficiency of measuring object hallucination through only yes/no responses, suggesting that this approach may not accurately reflect the model's comprehension of object presence. However, it does not provide explicit guidance on how the authors should address this issue or what alternative methods could be used. The comment implies that the authors should consider expanding their evaluation to include more nuanced measures, but it lacks concrete suggestions or detailed instructions on how to implement this. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the sufficiency of measuring object hallucination through only yes/no responses, suggesting that this approach may not accurately reflect the model\\'s comprehension of object presence. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its critique of the measurement method, the absence of explicit grounding limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the sufficiency of measuring object hallucination through only yes/no responses, suggesting that this approach may not accurately reflect the model\\'s comprehension of object presence. The comment implies that a yes response does not necessarily indicate that the model comprehends the presence of the object in the image, as it may still produce incorrect objects when undertaking other tasks. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to provide more detailed reasoning or evidence to fully understand the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the sufficiency of measuring object hallucination through only yes/no responses. It points out that a positive response does not necessarily indicate that the model comprehends the presence of the object in the image, as it may still produce incorrect objects in other tasks. This feedback is somewhat helpful as it highlights a potential limitation in the evaluation method, suggesting that the authors should consider expanding their evaluation to include more nuanced measures. However, the comment could be more helpful if it provided specific suggestions or examples of alternative evaluation methods that could address this issue. Overall, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific area of the paper that needs improvement, namely the lack of experiments and explanation regarding the different queries used in spatio-temporal representation. It explicitly mentions the key difference between the paper's approach and VideoChatGPT, suggesting that the authors should include experiments and explanations for spatial, temporal, and summary queries. However, the comment does not provide any guidance on how to conduct these experiments or what specific aspects of the queries should be explored. The action is explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Experiments - Ablation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of experiments and explanation regarding the different queries used in spatio-temporal representation, including spatial, temporal, and summary queries. The comment also poses a question about what would happen if only spatial, temporal, or summary queries were used, which provides a clear direction for the authors to address the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks experiments and explanation regarding the different queries used in spatio-temporal representation, specifically mentioning spatial, temporal, and summary queries. It suggests that the authors should include experiments and explanations for these queries, particularly in comparison to VideoChatGPT. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of supporting evidence makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that needs improvement, namely the lack of experiments and explanation regarding the different queries used in spatio-temporal representation. It highlights the key difference between the paper's approach and VideoChatGPT, suggesting that the authors should include experiments and explanations for spatial, temporal, and summary queries. However, the comment does not provide any guidance on how to conduct these experiments or what specific aspects of the queries should be explored. While it points out a crucial area for improvement, the lack of detailed suggestions or examples limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear direction for the authors to address the issue but lacks depth and actionable guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 3 and Section 4 are slightly redundant and proposes specific actions to address this redundancy by moving the first paragraph of Section 4 into Section 3 and placing the remainder of Section 4 before Section 3. This provides clear and explicit guidance on how the authors should reorganize their paper to improve its structure and flow. The actions are concrete, as they specify exactly what needs to be done to achieve the desired outcome. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that Section 3 and Section 4 are slightly redundant and proposes specific actions to address this redundancy by moving the first paragraph of Section 4 into Section 3 and placing the remainder of Section 4 before Section 3. However, the comment does not specify which parts of the sections are redundant or why they are redundant, making it difficult for the authors to identify the exact issues that need to be addressed. While the comment provides a general direction for improvement, it lacks specific details about what needs to be done to make the sections less redundant. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that Section 3 and Section 4 are slightly redundant and proposes specific actions to address this redundancy. However, it does not provide any evidence or reasoning to support why these sections are redundant or how the suggested actions would effectively reduce the redundancy. Without specific examples or justifications, the claim lacks sufficient support, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential redundancy between Section 3 and Section 4, suggesting that the first paragraph of Section 4 could be moved to Section 3 and the remainder of Section 4 could be placed before Section 3. This feedback is specific and actionable, providing clear guidance on how the authors might reorganize their paper to improve its structure and flow. By addressing this redundancy, the authors can enhance the clarity and coherence of their work. However, the comment could be more helpful if it included additional suggestions or considerations for the reorganization, such as the specific content that should be moved or the rationale behind the proposed changes. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clear connection between two concepts: \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zero-shot learning effectiveness.\" It suggests that the authors should clarify this connection, but it does not provide specific guidance on how to do so. The comment is explicit in identifying the issue but lacks detail on how to address it, making it somewhat actionable. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of clarity in the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zero-shot learning effectiveness.\" However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or figure that needs clarification. The comment is specific in identifying the need for clarification but lacks grounding as it does not provide explicit references to the paper sections. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of clarity in the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zero-shot learning effectiveness.\" However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the connection between two concepts discussed in the paper: \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zero-shot learning effectiveness.\" While the comment points out a lack of clarity, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it highlights an area that needs improvement, but it lacks actionable advice, making it difficult for the authors to fully understand and address the concern. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks the authors to provide a citation for the k-max problem, implying that it has been discussed elsewhere in the paper. However, it does not explicitly instruct the authors to include a citation or specify where the discussion can be found. The action is implicit and somewhat vague, as the authors need to infer that they should add a citation and then determine where to place it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment asks the authors to provide a citation for the k-max problem, implying that it has been discussed elsewhere in the paper. However, it does not specify which part of the paper the k-max problem is discussed in, making it weakly grounded. The comment is specific in its request for a citation, but the lack of grounding makes it difficult for the authors to know where to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification or additional information regarding the k-max problem. It does not contain a claim that requires verification or justification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is a question that prompts the authors to provide a citation for the k-max problem, suggesting that it has been discussed elsewhere in the paper. While it identifies a potential area for improvement by requesting a citation, it lacks specificity and does not offer actionable guidance on how to address the issue. The comment is vague and does not provide detailed feedback or suggestions, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. While it points out a missing detail, it does not provide explicit guidance on how to address this issue or what steps the authors should take to clarify or improve the explanation. The action is implicit and vague, as the authors are left to infer that they need to provide more information on the estimation process and the model's reliability. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what information is missing: the estimation of the function for the optimal sequence length and the reliability of the model. This provides the authors with a clear understanding of what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. However, it does not provide any specific reasoning, examples, or references to support why this information is important or how it impacts the paper. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper by pointing out the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. This feedback is clear and actionable, as it directs the authors to provide additional details or clarification regarding the estimation process and the model's reliability. By addressing this issue, the authors can enhance the transparency and robustness of their methodology, making the paper more comprehensive and understandable. The comment is mostly helpful as it provides a clear direction for improvement, though it could be further enhanced by suggesting specific ways to address the issue. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the use of \"thousands\" in the context of the main text, suggesting that it is not accurate and recommending the addition of \"on the subword level\" for clarity. The comment is explicit in identifying a specific issue with the text and provides a clear action for improvement by suggesting a more precise term. This allows the authors to directly address the inaccuracy and enhance the clarity of their writing. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L006\" in the main text, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding \"on the subword level\" to clarify the use of \"thousands,\" providing a clear direction for improvement. This feedback is detailed and actionable, making it fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the use of \"thousands\" in the context of the main text, suggesting that it is not accurate and recommending the addition of \"on the subword level\" for clarity. While the comment identifies a potential issue with the accuracy of the term used, it does not provide specific examples or references to support the claim that \"thousands\" is inaccurate. The suggestion to add \"on the subword level\" is clear and actionable, but the lack of detailed reasoning or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of the term \"thousands\" in the main text, suggesting that it is not accurate and recommending the addition of \"on the subword level\" for clarity. This feedback is clear and actionable, providing the authors with a direct suggestion for improvement. However, the comment could be more helpful if it offered additional context or examples to support the claim, or if it suggested alternative ways to convey the same information. Overall, the comment is mostly helpful as it directs the authors to a specific area for revision and improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggestions for improvement. It points out that certain hyperparameters, such as regularization, are not specified, which could hinder the reproducibility of the results. It also questions the y-value at x=0 in the latent path figures, asking if it is normalized and seeking clarification. Additionally, the reviewer suggests further analysis using interpolations. While the comment provides explicit questions and suggestions, it lacks concrete guidance on how to address these issues or what specific actions the authors should take. The actions are implicit and require the authors to infer the necessary steps, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific issues related to hyperparameters, such as the lack of specification for certain parameters like regularization, and questions the y-value at x=0 in latent path figures, asking if it is normalized. It also suggests further analysis using interpolations. However, the comment does not explicitly mention specific sections, figures, or tables, making it weakly grounded. The specificity of the feedback is good, as it clearly identifies areas needing clarification and suggests additional analysis. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the lack of specification for certain hyperparameters, such as regularization, and the y-value at x=0 in latent path figures. It also suggests further analysis using interpolations. While the questions are clear and specific, the comment lacks detailed reasoning or references to support the claims. The authors would need to infer the need for clarification and additional analysis, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies specific areas where the authors could improve their draft. It points out that certain hyperparameters, such as regularization, are not specified, which could hinder the reproducibility of the results. The comment also questions the y-value at x=0 in the latent path figures, asking if it is normalized, and suggests further analysis using interpolations. While the feedback is clear and identifies areas for improvement, it lacks detailed guidance on how to address these issues or what specific actions the authors should take. The comment provides a good starting point for the authors to enhance their draft, but it could be more helpful with additional suggestions or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies two main issues with the paper: the lack of explanation for forward referencing and the unclear explanation of contributions in the introduction. It also points out that the material supporting the main contributions, such as the deep-rag algorithm and discussion on high concurrency, is in the appendix rather than the main sections. While the comment explicitly mentions these issues, it does not provide specific guidance on how the authors should address them. The authors are left to infer that they need to clarify the forward referencing, provide more detailed explanations of the contributions in the introduction, and ensure that the supporting material is moved to the main sections. This lack of explicit guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"the Introduction,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the lack of explanation for forward referencing and the unclear explanation of contributions in the introduction. Additionally, it points out that the material supporting the main contributions, including the deep-rag algorithm and discussion on high concurrency, is in the appendix rather than the main sections. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is forward referencing in the paper, which is not properly explained, and that the contributions are unclear in the introduction. It also notes that the material supporting the main contributions, such as the deep-rag algorithm and discussion on high concurrency, is in the appendix rather than the main sections. The comment provides specific examples of issues, such as Figure 1 and the introduction, and suggests that the authors should clarify the forward referencing and provide more detailed explanations of the contributions. However, it lacks detailed reasoning or references to support these claims, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper: the lack of explanation for forward referencing and the unclear explanation of contributions in the introduction. It also points out that the material supporting the main contributions, such as the deep-rag algorithm and discussion on high concurrency, is located in the appendix rather than the main sections. While the comment highlights these areas for improvement, it does not provide specific guidance on how the authors should address these issues or suggest alternative approaches. The feedback is somewhat helpful as it directs the authors to areas that need clarification and improvement, but it lacks depth and actionable suggestions, making it a 3 out of 5.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the two test settings in visual dialog and the results presented in Table 1, which only shows the result for the discriminative setting. The reviewer questions the applicability of the discriminative setting to real-world applications and asks for the result on the generative setting. This comment implies that the authors should provide results for the generative setting to address the gap in the evaluation. However, it does not explicitly instruct the authors to include the generative setting results or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include the generative setting results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the evaluation of visual dialog, noting that Table 1 only presents results for the discriminative setting, while there are two test settings in visual dialog. It questions the applicability of the discriminative setting to real-world applications and asks for the results on the generative setting. This feedback is fully grounded as it explicitly mentions the part of the paper being addressed, allowing the authors to accurately identify the section. The comment is also specific, as it clearly specifies what is missing in the evaluation and what additional results are needed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the applicability of the discriminative setting in real-world applications and requests results for the generative setting. While the comment identifies a potential gap in the evaluation, it does not provide specific reasoning or evidence to support why the discriminative setting is not suitable for real-world applications or why the generative setting is important. The lack of detailed justification or references makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient support for a clear claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue in the evaluation of visual dialog, noting that Table 1 only presents results for the discriminative setting, while there are two test settings in visual dialog. It questions the applicability of the discriminative setting to real-world applications and asks for the results on the generative setting. This feedback is clear and actionable, as it directs the authors to provide additional results for the generative setting to address the gap in the evaluation. However, the comment could be more helpful if it provided some guidance on how to interpret or present the results for the generative setting. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed approach, noting that its effectiveness is not known for other language families. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might investigate or demonstrate the effectiveness of their approach across different language families. Without specific suggestions or guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation of the proposed approach, noting that its effectiveness is unknown for other language families. However, it does not specify which part of the paper this issue is related to, such as a particular section or methodology. This lack of grounding makes it difficult for the authors to pinpoint where the issue lies and how to address it. Additionally, the comment is specific in identifying the problem but lacks detail on how to address it. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the effectiveness of the proposed approach is unknown for other language families. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand or address this issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the paper, noting that the effectiveness of the proposed approach is unknown for other language families. This observation highlights a critical gap in the research, as it suggests that the findings may not be generalizable to a broader range of language families. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or explore the effectiveness of their approach across different language families. While it points out an important area for improvement, the feedback is somewhat limited in its actionable value, as it does not provide detailed steps or insights for the authors to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the related work section could be improved by providing more detailed descriptions of the differences between the related works. However, it does not specify which parts of the related work section need improvement or how the authors should address this issue. The comment lacks explicit guidance on what specific aspects of the related work need to be clarified or expanded upon. As a result, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the related works. However, it does not specify which part of the paper this comment refers to, making it weakly grounded. The comment is specific in its suggestion to improve the description of differences in related works, but without a clear reference to the section, the authors may struggle to identify the exact area that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the related work section could be improved by providing more detailed descriptions of the differences between the related works. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed examples or references, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the related work section, noting that while some related works are named, their differences are not adequately described. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the related work section by offering more detailed comparisons between the cited works. However, the comment could be more helpful if it suggested specific ways to improve the descriptions or provided examples of how to differentiate the related works. Overall, the comment is mostly helpful as it guides the authors towards a meaningful improvement in their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether the authors explicitly explain the understanding one reaches by looking at the PPP maps. It suggests that the authors should provide a clearer explanation of the significance of these maps in understanding PPP effects. However, the comment does not offer specific guidance on how to improve the explanation or what aspects of the understanding should be emphasized. The action is implicit, as the authors need to infer that they should provide a more detailed explanation of the PPP maps. The action is vague because it lacks concrete details on how to achieve this clarification. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions whether the authors explicitly explain the understanding one reaches by looking at the PPP maps. It does not specify which part of the paper this explanation should be included in, making it weakly grounded. However, the comment is specific in its request for clarification regarding the significance of PPP maps in understanding PPP effects. This provides clear guidance on what needs to be addressed, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions whether the authors explicitly explain the understanding one reaches by looking at the PPP maps. It suggests that the explanation is intriguing but not explicitly given in the article. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the explanation is missing or important. This lack of evidence makes the claim somewhat verifiable, as the authors would need to infer the need for a more detailed explanation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap in the paper by pointing out that while the authors mention the importance of reliable PPP metrics for understanding PPP effects, they do not explicitly explain what kind of understanding one reaches by examining the PPP maps. This feedback is somewhat helpful as it highlights a specific area where the authors could enhance their explanation and provide more context for their findings. However, the comment could be more helpful if it offered suggestions on how to clarify this understanding or provide additional context. Overall, the comment provides a clear direction for improvement, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of comparison with state-of-the-art methods, such as SpanBERT, which the authors do not mention. This feedback suggests that the authors should include such comparisons to enhance the credibility of their work. However, the comment does not provide explicit guidance on how to conduct these comparisons or what specific aspects of the methods should be compared. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of comparison with state-of-the-art methods, such as SpanBERT, which is a specific aspect of the paper. It clearly specifies what needs to be addressed, namely the absence of such comparisons, which is crucial for enhancing the credibility of the work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not compare their methods with other state-of-the-art methods, such as SpanBERT, which is a specific and well-known method in the field. This claim is supported by the mention of SpanBERT as an example of a state-of-the-art method that is not included in the comparison. The reasoning is clear and logical, providing a specific example to support the claim. Therefore, the comment is fully verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The comment identifies a significant weakness in the paper by pointing out the lack of comparison with state-of-the-art methods, specifically mentioning SpanBERT. This feedback is valuable as it highlights an area where the authors could strengthen their work by including such comparisons. However, the comment could be more helpful if it provided suggestions on how to conduct these comparisons or what specific aspects of the methods should be compared. Despite this, the feedback is mostly helpful as it directs the authors towards an important improvement that could enhance the credibility and impact of their research. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the lack of detailed explanation of the forward-prediction model and the poor schematic representation in Figure 2(b). It suggests that the figure should be redrawn and that the connection between the text, figure, and equations is unclear. While the comment provides explicit actions\u2014implying that the authors should redraw the figure and clarify the connection between the text, figure, and equations\u2014it lacks concrete guidance on how to achieve these actions. The authors are left with a general idea of what needs to be done but without specific steps or examples, making the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of detailed explanation of the forward-prediction model and points out issues with Figure 2(b), specifically that it does not accurately represent the model and is difficult to connect with the text and equations. However, the comment does not specify which part of the paper contains the detailed explanation of the forward-prediction model, making it weakly grounded. The comment is specific in detailing the issues with the figure and the lack of connection between the text, figure, and equations. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the details of the forward-prediction model are not well explained and that Figure 2(b) does not accurately represent the model, making it difficult to connect the text, figure, and equations. However, the comment lacks specific examples or references to support these claims. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific area of the paper that needs improvement, namely the explanation of the forward-prediction model. It points out that the details are not well explained and that Figure 2(b) does not accurately represent the model, making it difficult to connect the text, figure, and equations. This feedback is clear and actionable, as it directs the authors to improve the clarity and accuracy of their presentation. However, the comment could be more helpful if it provided specific suggestions for how to improve the explanation or the figure. Overall, the comment is mostly helpful, as it highlights important areas for improvement but could be more comprehensive.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the training data for the RBI model, suggesting that it only trains on rewarded actions and may ignore useful supervision from rewardless actions. The reviewer proposes that this could be a significant factor in the effectiveness of FP + RBI compared to RBI alone. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The suggestion to provide a stronger baseline is vague and lacks concrete details on how to implement it. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the training data for the RBI model, specifically noting that it only trains on rewarded actions and may ignore useful supervision from rewardless actions. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section being addressed. While the comment is specific in its critique of the training data, the lack of grounding makes it challenging for the authors to understand where to focus their attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the training data for the RBI model, suggesting that it only trains on rewarded actions and may ignore useful supervision from rewardless actions. The reviewer proposes that this could be a significant factor in the effectiveness of FP + RBI compared to RBI alone. However, the comment lacks specific examples or references to support the claim that rewardless actions are ignored. It does not provide a detailed explanation of how this oversight might impact the results or why it is a significant factor. Without additional context or evidence, the claim is difficult to verify, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the training data for the RBI model, specifically noting that it only trains on rewarded actions and may ignore useful supervision from rewardless actions. The reviewer suggests that this could be a significant factor in the effectiveness of FP + RBI compared to RBI alone. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what additional experiments could be conducted to strengthen their baseline. While it identifies a potential weakness, it lacks actionable advice or detailed recommendations, making it somewhat helpful. The authors would need to infer how to improve their draft based on this feedback, which limits its overall impact.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a weakness in the baseline methods used in the paper, stating that they are weak and not representative of state-of-the-art approaches. It also notes the absence of a discussion on limitations. The comment suggests that the authors should consider discussing the similarity and difference between their work and reinforcement learning (RL) and the extent to which the results are generalizable to RL settings. However, the comment does not provide explicit guidance on how to address these issues or what specific actions the authors should take to improve their draft. The actions are implicit and vague, leaving the authors uncertain about how to implement the suggestions. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the weakness of baseline methods being weak and not representing state-of-the-art approaches, and it notes the absence of a discussion on limitations. However, it does not specify which part of the paper discusses the baseline methods or where the authors should include a discussion on limitations. The comment is fully grounded in terms of identifying the area of concern, but it is not specific in detailing what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the baseline methods are weak and not representative of state-of-the-art approaches, and it notes the absence of a discussion on limitations. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism. Without detailed reasoning or evidence, the claim is not fully verifiable, aligning with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper by pointing out that the baseline methods are weak and not representative of state-of-the-art approaches. It also notes the absence of a discussion on limitations, which is a critical aspect of any research paper. The comment suggests that the authors should consider discussing the similarity and difference between their work and reinforcement learning (RL) and the extent to which the results are generalizable to RL settings. However, the comment lacks specific guidance on how to address these issues or what actions the authors should take to improve their draft. While it provides a clear direction for improvement, the feedback could be more helpful if it included detailed suggestions or examples of how to enhance the baseline methods or discuss the limitations. Therefore, the comment is mostly helpful, as it offers valuable insights but could be more comprehensive and actionable.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should clarify the distinction between expected performance under observation noise and the objective function of interest, which is a stochastic noisy function. It implies that the authors should make this distinction clearer upfront. However, the comment does not provide explicit guidance on how to implement this suggestion, such as specific sections or examples where this clarification should be added. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluation of expected performance under observation noise, suggesting that it is typically used because the decision-maker is interested in the true objective function and assumes noise. However, it points out that in the paper's formulation, the decision-maker does care about the noise, and the objective function of interest is a stochastic noisy function. This feedback is fully grounded as it explicitly mentions the part of the paper being addressed, and it is specific in detailing what needs to be clarified. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper should clarify the distinction between expected performance under observation noise and the objective function of interest, which is a stochastic noisy function. This claim is somewhat verifiable as it provides a logical reasoning for why the distinction is important and suggests that it should be made clearer upfront. However, it lacks specific examples or references to support the claim, which could make it less robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the evaluation methodology used in the paper, specifically regarding the use of expected performance under observation noise. It suggests that the decision-maker's interest in the true objective function and the assumption of noise might be misleading or not representative. The comment proposes that the paper should clarify the distinction between expected performance under observation noise and the objective function of interest, which is a stochastic noisy function. This feedback is mostly helpful as it provides a clear and actionable suggestion for improving the clarity and accuracy of the paper. However, it could be more helpful if it included specific examples or sections where this clarification should be made. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the good performance of the method, particularly in Table 2, but questions the novelty and contribution of the method, suggesting it is somewhat incremental. It also mentions that the main contribution is a new network design inspired by prior work for sound source localization. However, the comment does not provide explicit or implicit actions for the authors to take to address this concern. It lacks guidance on how to improve the novelty or contribution of the method or how to better articulate the inspiration from prior work. As a result, the authors are left without a clear path to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the novelty and contribution of the method, particularly in the context of sound source localization. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the novelty and contribution of the method are somewhat incremental, particularly in the context of sound source localization. However, the comment lacks specific evidence or references to support this claim. It does not provide examples or detailed reasoning to substantiate the assertion that the method's contribution is incremental. Without such evidence, the claim remains unsubstantiated, making the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty and contribution of the method, noting that it is somewhat incremental, especially in the context of sound source localization. It suggests that the main contribution is a new network design inspired by prior work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their method. While it points out a concern, it does not provide actionable feedback or detailed advice on how to improve the paper. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not offer comprehensive guidance for the authors to follow.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the model collapsing less than other methods is a common phenomenon and whether the authors have observed it in their experiments. While it prompts the authors to consider this aspect, it does not provide explicit instructions on what actions to take, such as conducting additional experiments or providing more detailed analysis. The comment is somewhat vague, as it leaves the authors to infer the need for further investigation and analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the model collapsing less than other methods, specifically referencing line 159 where gradients become 0 and collapse. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in questioning the commonality of this phenomenon and whether the authors have observed it in their experiments, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the commonality of model collapse and whether the authors have observed it in their experiments. While it prompts the authors to consider this aspect, it does not provide specific evidence or references to support the claim that this phenomenon is commonly encountered. The comment lacks detailed reasoning or examples, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the commonality of model collapse and whether the authors have observed it in their experiments. It specifically references line 159, where gradients become 0 and collapse, prompting the authors to consider this phenomenon. While the comment identifies an area for further investigation, it lacks detailed guidance or suggestions on how to address this issue or what experiments might be necessary. The feedback is somewhat helpful as it highlights a potential area for improvement, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the problem formulation is somewhat unclear in the statement and introduction examples. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit instructions or concrete advice on what needs to be done to clarify the problem formulation. As a result, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper is unclear, making it difficult for the authors to identify the exact section that needs improvement. It is also not specific because it does not provide details on what aspects of the problem formulation are unclear. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the problem formulation is somewhat unclear in the statement and introduction examples. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the problem formulation is unclear or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the problem formulation in the introduction and statement examples. However, it lacks specific details or suggestions on how the authors might address this issue. Without actionable guidance or examples of how to improve the clarity, the authors may find it difficult to make meaningful changes to their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This provides a clear and explicit action for the authors to take, as they can directly implement the suggestion by adding experiments with these models. The comment is specific in its recommendation, detailing which models should be used and how this would enhance the paper\\'s applicability and generalizability. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide valuable insights into the method\\'s applicability and generalizability. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its recommendation, as it clearly identifies the need for additional experiments and specifies the models to be used. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This claim is somewhat verifiable as it provides a suggestion for improvement but lacks specific examples or references to support the claim. The authors could benefit from additional context or references to understand the significance of the suggested experiments. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by noting the absence of experiments on different LLM families. It suggests conducting trials with models like OPT, BLOOM, or other alternatives to provide valuable insights into the method\\'s applicability and generalizability across various LLM families. This feedback is clear and actionable, as it directly points out an area where the authors can enhance their work. By suggesting specific models to include in the experiments, the comment provides a concrete direction for improvement, making it highly helpful for the authors. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method described in the paper is limited to generative models that can be fine-tuned as in/outpainting models. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. The comment lacks guidance on how the authors might expand the method's applicability or how to overcome this constraint. Without specific suggestions or actions, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the method described in the paper is limited to generative models that can be fine-tuned as in/outpainting models. However, it does not specify which part of the paper this limitation is discussed or how it affects the overall methodology. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to address this limitation or improve the method's applicability. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the method described in the paper is limited to generative models that can be fine-tuned as in/outpainting models. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the claim, making it difficult to address or improve the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a limitation in the method described in the paper, specifically that it is only applicable to generative models that can be fine-tuned as in/outpainting models. While this observation highlights a constraint on the method's applicability, it does not provide any suggestions or guidance on how the authors might address this limitation or expand the method's scope. The comment lacks actionable advice, leaving the authors without a clear path to improve their work. Therefore, the comment is barely helpful, as it identifies a problem but does not offer any constructive feedback or suggestions for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the weak connection between the first part of the paper, which discusses curve finding, and the second part, which focuses on FGE. The reviewer suggests that the current presentation does not align with the initial understanding of the first part, which involves taking random weights, learning curves between weights, and finding nice weights to be mixed into the final ensemble. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to improve the connection between the two parts. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to understand how to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the connection between the first part of the paper, which discusses curve finding, and the second part, which focuses on FGE. However, it does not specify which sections or parts of the paper these connections are discussed, making it weakly grounded. The comment is specific in identifying the issue with the weak connection between the two parts, but it lacks detailed guidance on how to improve this connection. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a concern about the weak connection between the first part of the paper, which discusses curve finding, and the second part, which focuses on FGE. The reviewer provides a detailed explanation of the initial understanding of the first part and contrasts it with the actual content of the paper, suggesting that the current presentation does not align with the initial understanding. However, the comment lacks specific examples or references to support the claim that the connection is weak. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper by pointing out a lack of connection between the first part, which discusses curve finding, and the second part, which focuses on FGE. The reviewer provides a detailed explanation of the initial understanding of the first part and contrasts it with the actual content of the paper, suggesting that the current presentation does not align with the initial understanding. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the connection between the two parts. While it highlights an area for improvement, the feedback is somewhat vague and could be more helpful if it provided actionable advice or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the performance of learning-based and heuristic-based solvers, noting that heuristic-based solvers, specifically the SOTA heuristic-solver (e.g., Concorde), usually perform better for single-objective TSP. The comment suggests that the results for linear scalarization + Concorde should be included for a better comparison. This provides a clear and explicit action for the authors to take, which is to include the results for linear scalarization + Concorde in their analysis. The action is concrete, as it specifies exactly what needs to be done to improve the comparison. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"competitive baselines\" and \"heuristic-based solvers,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the performance of the SOTA heuristic-solver (e.g., Concorde) for single-objective TSP and suggests including results for linear scalarization + Concorde for a better comparison. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the learning-based solvers are much better than the heuristic-based solvers according to the experimental results. However, it highlights that for single-objective TSP, the SOTA heuristic-solver (e.g., Concorde) usually performs better. The comment suggests that the results for linear scalarization + Concorde should be included for a better comparison. This claim is somewhat verifiable as it provides a logical reasoning for why the inclusion of linear scalarization + Concorde is necessary for a comprehensive comparison. However, it lacks specific examples or references to support the claim fully, which could make it less robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that the learning-based solvers outperform heuristic-based solvers, but it highlights a potential gap in the comparison by suggesting the inclusion of results for linear scalarization with the SOTA heuristic-solver (e.g., Concorde). This feedback is actionable and provides a clear direction for the authors to improve their analysis by including additional comparisons. By addressing this suggestion, the authors can enhance the comprehensiveness and robustness of their experimental evaluation. Therefore, the comment is mostly helpful, as it offers a specific and actionable suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental setup, tasks, and other details, which are currently in the appendix, should be moved back into the main body of the paper. It also recommends moving some background information from Section 2 to the appendix. This provides explicit guidance on where to move specific content, making it clear and actionable for the authors. The suggestion is concrete, as it specifies which sections should be moved and where they should be placed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the experimental setup, tasks, and other details, which are currently in the appendix, should be moved back into the main body of the paper. It also recommends moving some background information from Section 2 to the appendix. This provides explicit guidance on where to move specific content, making it clear and actionable for the authors. The comment is fully grounded as it explicitly mentions the appendix and the main body of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it specifies which details should be moved back and which background information should be moved to the appendix. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the experimental setup, tasks, and other details, currently in the appendix, should be moved back into the main body of the paper. It also recommends moving some background information from Section 2 to the appendix. While the comment provides a clear rationale for why these changes might be beneficial, it lacks specific examples or detailed reasoning to fully support the claim. The authors would need to infer the reasoning behind these suggestions, which could be improved with more detailed explanations or references. Therefore, the comment is somewhat verifiable, as it provides a basis for improvement but lacks full support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the organization of the paper, suggesting that moving certain details from the appendix to the main body would improve the interpretability of the experimental setup and tasks. It also recommends moving some background information from Section 2 to the appendix. This feedback is actionable and provides clear guidance on how the authors can enhance the clarity and coherence of their paper. By addressing these suggestions, the authors can significantly improve the readability and understanding of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide glosses in Figure 2. This is a clear and explicit action that the authors can readily understand and implement. The comment is specific in its request, indicating exactly what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing glosses in Figure 2, which is a specific part of the paper. However, it does not explicitly mention the section or figure number, making it weakly grounded. The comment is specific in its suggestion, as it clearly indicates what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide glosses in Figure 2. This is a suggestion for improvement, but it does not contain a claim that requires verification or justification. The comment is factual and descriptive, aligning with a classification of \"No.\" Therefore, the comment is labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests that the authors should provide glosses in Figure 2. This is a specific and actionable suggestion that directly addresses a potential area for improvement in the paper. By providing glosses, the authors can enhance the clarity and understanding of the content presented in Figure 2. This feedback is clear and constructive, offering a concrete step for the authors to take in improving their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the claim that \"Memb is apparently the previous state-of-the-art,\" but it does not provide any explicit or implicit suggestions on how to address this issue. The comment lacks guidance on whether the authors should include a reference or provide more context to support the claim. Without specific instructions on what needs to be done, the authors are left without actionable steps to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is referring to, making it difficult for the authors to identify the exact issue. It mentions \"Memb is apparently the previous state-of-the-art\" but does not provide any context or reference to a specific section, table, or figure. The comment is also not specific because it does not detail what is missing or needs to be addressed regarding the claim. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"Memb is apparently the previous state-of-the-art,\" but it does not provide any supporting evidence or references to substantiate this claim. Without any justification or references, the authors are left without a basis to verify or address the claim. This makes the comment unverifiable, as it lacks the necessary evidence to support the assertion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the claim that 'Memb is apparently the previous state-of-the-art,' but it does not provide any specific guidance or suggestions on how to address this concern. The comment lacks actionable advice, such as recommending the inclusion of a reference or providing more context to support the claim. Without these details, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it highlights a potential issue but does not offer any constructive feedback or suggestions for improvement.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of quantization grouping, specifically questioning why finer grouping was not considered instead of per-tensor and per-channel approaches. However, it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this question or what steps they should consider to improve their draft. As a result, the authors are left without a clear understanding of what to do next, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the choice of quantization grouping, specifically questioning why finer grouping was not considered instead of per-tensor and per-channel approaches. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to identify the exact area where the comment is relevant. While the comment is specific in its question about quantization grouping, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of quantization grouping, specifically questioning why finer grouping was not considered instead of per-tensor and per-channel approaches. However, it does not provide any justification or reasoning for why this choice was made or why finer grouping might be beneficial. Without any supporting evidence or explanation, the claim is unverifiable. The authors are left without a clear understanding of why this question is important or how it relates to the paper\u2019s content, making the comment unhelpful in terms of providing actionable feedback.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of quantization grouping, specifically questioning why finer grouping was not considered instead of per-tensor and per-channel approaches. This question highlights a potential area for improvement in the paper, as it suggests that the authors might have overlooked a more detailed approach to quantization. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what steps they could take to improve their draft. Without actionable feedback or specific suggestions, the comment is barely helpful, as it leaves the authors without a clear path forward to enhance their work. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should study the impact of the ratio of unseen classes, specifically how performance varies with different ratios of unlabeled examples. This provides a clear and explicit action for the authors to take, as they can directly address this suggestion by conducting additional experiments or analyses. The comment is specific in its request for further investigation, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests studying the impact of the ratio of unseen classes, specifically mentioning how performance varies with different ratios of unlabeled examples. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or figure. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper needs revision. While the comment is specific in its request for additional analysis, the lack of grounding makes it difficult for the authors to understand where to focus their efforts. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests studying the impact of the ratio of unseen classes, specifically how performance varies with different ratios of unlabeled examples. This is a suggestion for further investigation and analysis, which is a subjective opinion or judgment. However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is important or how it would impact the paper. Without additional context or justification, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests studying the impact of the ratio of unseen classes, specifically how performance varies with different ratios of unlabeled examples. This feedback is actionable and provides a clear direction for the authors to enhance their work by conducting additional experiments or analyses. By focusing on this aspect, the authors can gain a deeper understanding of the model's behavior and potentially improve its performance. However, the comment could be more helpful if it provided specific guidance on how to conduct these experiments or what metrics to use. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the rationale behind using GRU for the Pyramid and LSTM for the sequential part. It asks whether the combination of these two architectures is a reason for the improvements observed. However, the comment does not provide any explicit or implicit suggestions or actions for the authors to take in response to this question. It lacks guidance on how the authors might address this concern or what changes they should consider. As a result, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the rationale behind using GRU for the Pyramid and LSTM for the sequential part, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance or suggestions on how to address the question or improve the combination of architectures. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the rationale behind using GRU for the Pyramid and LSTM for the sequential part, but it does not provide any specific reasoning, examples, or references to support the claim. The comment lacks detailed justification or evidence to substantiate the question, making it difficult for the authors to understand the basis of the concern. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind using GRU for the Pyramid and LSTM for the sequential part, which is a valid concern for the authors to address. However, the comment does not provide any specific suggestions or guidance on how the authors might improve their approach or justify their choice of architectures. It lacks depth and actionable advice, leaving the authors with limited insight into how to enhance their work. Therefore, the comment is barely helpful, as it identifies a potential issue but does not offer substantial guidance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the definition of \"active vertices\" in line 135, which is a specific part of the paper. It implies that the authors need to clarify this term to ensure the reader understands the context. However, the comment does not provide explicit guidance on how to define \"active vertices\" or suggest alternative definitions. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the term. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is unclear, namely the definition of \"active vertices.\" This provides the authors with a clear understanding of the issue and how to address it. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the definition of \"active vertices\" in line 135, which is a factual question about the paper's content. It does not contain a subjective claim, suggestion, or judgment that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific point of confusion in the paper, namely the definition of \"active vertices\" in line 135. By pointing out this ambiguity, the comment provides the authors with a clear area to clarify, which is essential for improving the readability and understanding of the paper. However, the comment lacks broader guidance or suggestions on how to address this issue effectively. While it highlights a specific issue, it does not offer a comprehensive or detailed response, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific issue with the paper, noting that the authors do not explicitly mention the inapplicability of their theory to the used model in the limitations section. It also points out the vagueness of the term \"structural assumptions,\" which are only detailed in the appendix, making it difficult for the authors to understand this limitation. The comment suggests that the authors might be underestimating the use of graph neural networks in industry and recommends elaborating on potential negative societal impacts. While the comment identifies a gap in the paper's discussion and suggests an area for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The feedback is somewhat actionable as it points out areas for improvement but lacks detailed instructions on how to implement them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"limitations\" section of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by pointing out the lack of mention of the theory's inapplicability to the used model and the vagueness of \"structural assumptions.\" This level of detail provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not explicitly mention the inapplicability of their theory to the used model in the limitations section, which is a valid observation. It also highlights the vagueness of \"structural assumptions,\" which are only detailed in the appendix, making this limitation difficult to understand. The comment suggests that the authors might be underestimating the use of graph neural networks in industry and recommends elaborating on potential negative societal impacts. However, the comment lacks specific examples or references to support these claims, making it somewhat verifiable. The authors would need to provide more detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides valuable feedback by pointing out a significant gap in the paper: the lack of explicit mention of the inapplicability of the theory to the used model in the limitations section. It also highlights the vagueness of \"structural assumptions,\" which are only detailed in the appendix, making this limitation difficult to understand. Additionally, the comment suggests that the authors might be underestimating the widespread use of graph neural networks in industry and recommends elaborating on potential negative societal impacts. This feedback is mostly helpful as it identifies specific areas for improvement and provides actionable suggestions, such as elaborating on the limitations and societal impacts. However, it could be more helpful if it included specific examples or guidance on how to address these issues. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"epsilon-greedy\" in the context of the training process described in Appendix D.2. It also suggests that the authors might be using epsilon-greedy exploration in addition to their proposed strategy. However, the comment does not provide explicit guidance on how the authors should clarify this point or address the potential use of epsilon-greedy exploration. The action is implicit, as the authors need to infer that they should clarify the meaning of \"epsilon-greedy\" and consider its implications for their strategy. The action is vague because it does not specify how to clarify the meaning or what aspects of the strategy need to be addressed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Just before Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"epsilon-greedy\" in the context of the training process and suggests that the authors might be using epsilon-greedy exploration in addition to their proposed strategy. This provides clear guidance on what needs to be clarified or addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the meaning of \"epsilon-greedy\" in the context of the training process described in Appendix D.2. It does not contain a subjective claim or suggestion but rather asks for clarification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"epsilon-greedy\" in the context of the training process described in Appendix D.2. It suggests that the authors might be using epsilon-greedy exploration in addition to their proposed strategy. However, the comment does not provide any guidance or suggestions on how the authors should clarify this point or address the potential use of epsilon-greedy exploration. While it identifies an area that needs clarification, it lacks actionable feedback, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the proposed method, suggesting it is a direct combination of existing techniques (GCN and normalizing flow) with a minor modification in the transformed distribution. The comment questions the novelty of the approach, stating that there is not enough new stuffs here. However, the comment does not provide explicit guidance on how the authors might address this issue or what specific aspects of the method need to be improved to enhance its novelty. The action is implicit and vague, as it does not offer concrete steps for the authors to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the proposed method, suggesting it is a direct combination of GCN and normalizing flow, with a minor modification in the transformed distribution. It questions the novelty of the approach, stating that there is not enough new stuffs here. However, the comment does not specify which part of the paper this critique refers to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its critique of the method's novelty but lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the proposed method, suggesting it is a direct combination of GCN and normalizing flow with a minor modification in the transformed distribution. The comment questions the novelty of the approach, stating that there is not enough new stuffs here. However, the comment lacks specific examples or detailed reasoning to support the claim that the method lacks novelty. It does not provide references or logical arguments to substantiate the assertion that the method is not sufficiently innovative. As a result, the claim is not fully verifiable, making the comment borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment critiques the proposed method, suggesting it is a direct combination of existing techniques (GCN and normalizing flow) with a minor modification in the transformed distribution. The reviewer questions the novelty of the approach, noting that there is not enough new stuffs here. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their method. While it identifies a potential weakness, it lacks actionable advice or detailed feedback, making it barely helpful. The authors would need to infer what improvements could be made, which limits the comment's usefulness.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific aspect of the paper, noting that only the projection head (CNN layers) are affected, while the classification head (FCN layer) is not. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this observation or what changes could be made to the paper. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"projection head (CNN layers)\" and \"classification head (FCN layer),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights a particular aspect of the paper, noting that only the projection head is affected, while the classification head is not. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is factual and descriptive, stating that only the projection head (CNN layers) are affected but not the classification head (FCN layer). It does not contain any subjective opinions, suggestions, or claims that require verification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is factual and descriptive, noting that only the projection head (CNN layers) are affected but not the classification head (FCN layer). While this observation is accurate, the comment does not provide any suggestions or insights on how this might impact the paper or what actions the authors could take to address this finding. Without actionable feedback or guidance, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it lacks depth and direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the analogy between HOI analysis and Harmonic analysis, suggesting that the link is weak. It highlights that the decomposition and integration steps in the paper do not have a close connection with Fourier analysis as claimed. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the analysis need to be revised. The action is implicit and vague, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the analogy between HOI analysis and Harmonic analysis, suggesting that the link is weak. It highlights that the decomposition and integration steps in the paper do not have a close connection with Fourier analysis as claimed. However, the comment does not specify which part of the paper discusses the HOI analysis or the Fourier analysis, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in its critique of the analogy, the lack of grounding makes it challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the analogy between HOI analysis and Harmonic analysis, suggesting that the link is weak. It claims that the decomposition and integration steps in the paper do not have a close connection with Fourier analysis as claimed. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. The reasoning is vague and lacks detailed evidence, which limits the verifiability of the claim. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment critiques the analogy between HOI analysis and Harmonic analysis, pointing out that the link is weak and that the decomposition and integration steps do not have a close connection with Fourier analysis as claimed. This feedback is somewhat helpful as it identifies a specific area of concern and suggests that the analogy might be overstated. However, the comment could be more helpful if it provided more detailed guidance on how the authors could address this issue or what specific aspects of the analysis need to be revised. Without concrete suggestions or examples, the authors may struggle to understand how to improve their draft. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the applicability of dynamic precision control during training, suggesting that it might only show meaningful performance gains on bit-serial accelerators. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their methodology. The comment implies that the authors should consider the limitations of their approach in the context of existing ML accelerators that use bit-parallel fixed-point numbers. While the authors can infer that they need to discuss the implications of their methodology in this context, the lack of concrete suggestions or guidance makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the applicability of dynamic precision control during training, specifically mentioning bit-serial accelerators and the limitations of existing ML accelerators that use bit-parallel fixed-point numbers. However, it does not explicitly mention specific sections, tables, or figures of the paper that discuss these aspects. The authors can infer that the comment relates to the methodology or experimental setup, but without explicit references, the grounding is weak. The comment is specific in detailing the issue with dynamic precision control and its implications for existing accelerators, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is categorized as weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the applicability of dynamic precision control during training, specifically questioning whether it might only show meaningful performance gains on bit-serial accelerators. It then suggests that most existing ML accelerators use bit-parallel fixed-point numbers, which might restrict the implications of the proposed methodology. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, and the lack of detailed evidence or examples weakens the verifiability of the claim. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the applicability of dynamic precision control during training, specifically questioning whether it might only show meaningful performance gains on bit-serial accelerators. It suggests that most existing ML accelerators use bit-parallel fixed-point numbers, which could restrict the implications of the proposed methodology. This feedback highlights a potential limitation or area for further exploration, providing the authors with a clear direction to consider in their work. However, the comment could be more helpful if it offered suggestions or guidance on how to address this issue or expand the scope of their methodology. Overall, the comment is somewhat helpful as it identifies a relevant concern but lacks depth in providing actionable advice. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the generalization of the model's performance across different focusing distances, specifically those not present in the training data. It suggests that the authors should consider including images with other focusing distances to assess the model's generalization ability. However, the comment does not provide explicit guidance on how to implement this suggestion, such as which specific distances to include or how to analyze the results. The action is implicit and somewhat vague, as the authors need to infer the need for additional data and analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the generalization of the model across different focusing distances, particularly those not present in the training data. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the generalization of the model's performance across different focusing distances, specifically those not present in the training data. It does not contain a subjective claim or opinion but rather poses a question that requires the authors to consider additional data or analysis. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a valid concern about the generalization of the model's performance across different focusing distances, particularly those not included in the training data. It questions whether the model generalizes well beyond the distances present in the training set, which is a crucial aspect for evaluating the robustness of the model. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as proposing additional experiments or analyses. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a main weakness of the work regarding its technical novelty, specifically in comparison to spatial transformer networks (STN). It points out that the proposed X-transformation is similar to STN, applied locally, and notes that existing works have already explored applying STN in a local pixel neighborhood. The comment also mentions that there are no empirical or conceptual comparisons to STN in the work, which is a significant gap. While the comment identifies a key issue and suggests that the authors should address the lack of comparison, it does not provide explicit guidance on how to improve the draft or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should include comparisons to STN and other relevant works. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a main weakness of the work regarding its technical novelty, specifically in comparison to spatial transformer networks (STN). It highlights the similarity between the proposed X-transformation and STN, noting that existing works have already explored applying STN in a local pixel neighborhood. The comment also points out the absence of empirical or conceptual comparisons to STN in the work, which is a significant gap. However, the comment does not specify which part of the paper discusses the technical novelty or the comparison to STN, making it weakly grounded. The specificity is moderate as it clearly identifies the issue of limited technical novelty and the lack of comparison to STN, but it does not provide detailed guidance on how to address these issues. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work lacks technical novelty compared to spatial transformer networks (STN) and does not provide a comparison to STN. It highlights the similarity between the proposed X-transformation and STN, noting that existing works have already explored applying STN in a local pixel neighborhood. The comment also mentions the absence of empirical or conceptual comparisons to STN in the work, which is a significant gap. However, the comment lacks specific examples or references to support these claims, making it somewhat verifiable. The authors would need to infer the basis for the claim and seek additional evidence to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the lack of technical novelty compared to spatial transformer networks (STN). It highlights the similarity between the proposed X-transformation and STN, noting that existing works have already explored applying STN in a local pixel neighborhood. The comment also points out the absence of empirical or conceptual comparisons to STN, which is a critical gap in the work. While the comment effectively identifies a key area for improvement, it lacks specific guidance on how the authors might address this issue or what additional comparisons should be included. The feedback is somewhat helpful as it directs the authors to a specific area of concern, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific feedback on a potential error in the referencing of figures in the supplementary material, suggesting that \"Fig.7\" should be \"Fig.12\". It also offers a suggestion to attach proofs to theorems and corollaries in the main paper to improve readability. However, the comment does not explicitly instruct the authors to correct the figure reference or to implement the suggestion about proof links. While the actions are implied, they are vague and lack concrete details on how to execute them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the figure reference, suggesting that \"Fig.7\" should be \"Fig.12.\" Additionally, the comment provides a clear suggestion to attach proofs to theorems and corollaries in the main paper, enhancing the paper's readability. However, the comment lacks specificity in terms of what aspects of the methodology or experiments need to be improved to address the concerns about motivation, methodology soundness, and experiment persuasion. While the authors can infer that these concerns relate to the content of the paper, the comment does not provide detailed guidance on how to address them. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point contains a claim about the correctness of a figure reference (\"Fig.7\" should be \"Fig.12\") and suggests improving the paper's readability by attaching proofs to theorems and corollaries. However, the comment lacks specific examples or detailed reasoning to support the claim about the figure reference. While the suggestion to improve readability is logical, the overall comment is somewhat verifiable due to the lack of detailed justification for the figure reference claim. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on a potential error in the referencing of figures in the supplementary material, noting that \"Fig.7\" should be \"Fig.12\". It also suggests improving the paper's readability by attaching proofs to theorems and corollaries in the main paper. However, the comment lacks depth and does not address the primary concerns raised, such as motivation, methodology soundness, and experiment persuasion. While it offers some actionable suggestions, the feedback is incomplete and does not provide a comprehensive guide for the authors to improve their draft. Therefore, the comment is somewhat helpful, as it identifies some areas for improvement but lacks the depth needed for full guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and requests for clarification regarding specific sections of the paper. It asks for details about the determiner missing in the definition, the selection and tagging of action verbs, and the identification of action frames. While the comment provides explicit questions that the authors should address, it lacks concrete guidance on how to implement these actions or what specific changes are needed. The actions are implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific sections of the paper, such as \"Above definition\" and \"Section 3,\" which allows the authors to accurately identify the parts being discussed. It also asks for clarification on the selection of action verbs and the identification of action frames, providing specific guidance on what needs to be addressed. This makes the comment fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about specific sections of the paper, such as \"Above definition\" and \"Section 3,\" and asks for clarification on the selection of action verbs and the identification of action frames. While the questions are specific and require the authors to provide detailed information, they do not contain subjective opinions or claims that need verification. Therefore, the comment is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific areas in the paper that require clarification and detailed explanation. It asks for clarification on the missing determiner in a definition, the selection and tagging of action verbs, and the identification of action frames. These questions are specific and actionable, providing the authors with clear guidance on what needs to be addressed to improve the clarity and completeness of their work. However, the comment could be more helpful if it offered suggestions or examples to enhance the authors' understanding of these concepts. Overall, the feedback is mostly helpful as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that some details are missing, specifically mentioning the lack of understanding regarding the design of rewards. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on what specific details are missing or how the authors should clarify the design of rewards. Without concrete suggestions or examples, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is weakly grounded as it does not specify which part of the paper is missing details or lacks understanding regarding the design of rewards. However, it is specific in identifying the issue of missing details and the lack of understanding about the reward design. This allows the authors to infer that the feedback pertains to a specific section or part of the paper where these details are discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some details are missing and provides an example of a lack of understanding regarding the design of rewards. However, it does not offer any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the draft, noting that some details are missing and that the design of rewards is not fully understandable. This feedback is clear and actionable, as it points out a gap in the paper that needs to be addressed. However, the comment could be more helpful if it provided additional guidance on how the authors might clarify or expand on the reward design. Despite this, the comment offers a valuable insight that can guide the authors in improving their draft, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper, specifically the fixed number of entities and the lack of clarity on how to generalize the model to different numbers of entities. While it points out a potential issue, it does not provide explicit guidance on how to address this limitation or suggest specific actions for the authors to take. The comment implies that the authors should consider expanding their model to accommodate varying numbers of entities, but it does not offer concrete steps or examples on how to achieve this. Therefore, the comment is somewhat actionable, as it identifies a clear issue but lacks detailed guidance on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the fixed number of entities in the model and the lack of clarity on how to generalize it to different numbers of entities. It references figure 3 of INs, which suggests that the authors can accurately identify the part of the paper being addressed. However, the comment does not specify what needs to be addressed in this part, such as potential solutions or additional experiments. This makes the comment weakly grounded but specific, as it identifies a clear issue but lacks detailed guidance on how to address it. Therefore, it aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a limitation in the paper, specifically the fixed number of entities and the lack of clarity on how to generalize the model to different numbers of entities. While it points out a potential issue, it does not provide specific examples or references to support the claim that the model's generalization is unclear. The comment lacks detailed reasoning or evidence to substantiate the claim, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the paper, namely the fixed number of entities and the lack of clarity on how to generalize the model to different numbers of entities. This is a clear and actionable feedback that highlights a potential area for improvement in the paper. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this issue, such as proposing additional experiments or discussing potential solutions. Without specific recommendations, the feedback is somewhat helpful, as it points out a significant area for improvement but does not fully empower the authors to enhance their work. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the novelty of the incremental improvement to the K-NN based MT approach, suggesting that it lacks significant novelty but requires substantial engineering and execution effort. It acknowledges that the authors' execution is replicable and beats the idea in terms of novelty. However, the comment does not provide explicit guidance on how to address this issue or improve the novelty of the approach. The feedback is somewhat vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the novelty of the incremental improvement to the K-NN based MT approach, suggesting that it lacks significant novelty but requires substantial engineering and execution effort. It acknowledges that the authors' execution is replicable and beats the idea in terms of novelty. However, the comment does not specify which part of the paper this critique pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its critique of novelty but lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the novelty of the incremental improvement to the K-NN based MT approach, suggesting that it lacks significant novelty but requires substantial engineering and execution effort. It acknowledges that the authors' execution is replicable and beats the idea in terms of novelty. However, the comment does not provide specific examples or references to support the claim about the lack of novelty or the need for substantial engineering effort. This makes the claim somewhat verifiable, as it lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the novelty of the incremental improvement to the K-NN based MT approach, suggesting that it lacks significant novelty but requires substantial engineering and execution effort. It acknowledges that the authors' execution is replicable and beats the idea in terms of novelty. However, the comment does not provide specific suggestions or guidance on how to address this issue or enhance the novelty of the approach. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful. The feedback is valuable but could be more comprehensive and constructive if it offered detailed suggestions for improvement.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the computational efficiency of Prithvi WxC, suggesting that its runtime should be discussed as a limitation. However, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take to improve the draft. The comment implies that the authors should consider discussing the runtime, but it lacks concrete instructions or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it identifies a potential area for improvement but does not provide detailed guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the computational efficiency of Prithvi WxC, specifically mentioning its large parameter count and suggesting that its runtime should be discussed as a limitation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to discuss the runtime, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the computational efficiency of Prithvi WxC should be discussed due to its large parameter count. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or examples, the claim remains somewhat verifiable, as it lacks sufficient justification to fully understand the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the computational efficiency of Prithvi WxC, specifically mentioning its large parameter count. It suggests that the runtime of this model should be discussed as a limitation for applications involving climate model parametrizations. While the comment highlights a relevant aspect of the model's performance, it does not provide specific guidance on how to address this issue or what actions the authors should take to improve the draft. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable suggestions, making it only somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit instructions or concrete advice on what changes could be made to the framing or how the contribution could be clarified. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not specify which part of the paper is being referred to, leaving the authors uncertain about the exact section or aspect that needs attention. The comment is vague and does not provide specific guidance on how to address the overselling or clarify the contribution. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the framing of the paper oversells the method, making the contribution less clear. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or context, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the framing of the paper, suggesting that it oversells the method and makes the contribution less clear. However, the comment lacks specific details or actionable suggestions on how the authors might address this concern. Without further guidance or examples, the authors may find it difficult to understand the implications of the feedback or how to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model description could be improved by presenting the generative process in separate steps, which would enhance understanding. It also notes that the use of many symbols and a notation table could be better. However, the comment does not provide explicit guidance on how to implement these suggestions, such as specific examples of how to present the generative process in steps or how to create a more effective notation table. The action is implicit and somewhat vague, as the authors need to infer the exact actions to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the model description, specifically mentioning the need to present the generative process in separate steps for better understanding and the use of many symbols and a notation table. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific about the nature of the issue, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the model description could be improved by presenting the generative process in separate steps and by using a notation table. However, the comment does not provide specific examples, references, or detailed reasoning to support these suggestions. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies areas for improvement in the model description, specifically suggesting that presenting the generative process in separate steps could enhance understanding and that using a notation table could improve clarity. However, the comment lacks specific guidance on how to implement these suggestions, such as providing examples of how to structure the steps or what kind of notation table would be most effective. While it offers some direction, the feedback could be more helpful if it included actionable steps or detailed examples. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses the authors' difficulty in understanding the main idea and theoretical analysis of the paper, indicating that the writing could be improved. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might improve the writing or what aspects need clarification. As a result, the authors are left without a clear path to follow, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses the authors' difficulty in understanding the main idea and theoretical analysis of the paper, suggesting that the writing could be improved. However, it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need improvement. Additionally, the comment is somewhat specific in that it highlights the difficulty in understanding the main idea and theoretical analysis, but without further guidance on what aspects need clarification, it remains somewhat specific. Therefore, this comment is weakly grounded and somewhat specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses the authors' difficulty in understanding the main idea and theoretical analysis of the paper, suggesting that the writing could be improved. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the exact nature of the issue. Without additional context or suggestions, the claim is not fully verifiable, as it does not provide a clear basis for improvement. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment acknowledges the authors' difficulty in understanding the main idea and theoretical analysis of the paper, suggesting that the writing could be improved. However, it lacks specific suggestions or guidance on how the authors might address this issue. While it identifies a potential area for improvement, it does not provide actionable advice or examples of how to enhance the clarity or coherence of the paper. As a result, the comment is somewhat helpful, as it highlights a weakness but does not offer comprehensive feedback for improvement. Therefore, it aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the abstract sentence is cumbersome and could be made clearer. However, it does not provide specific guidance on how to make the sentence clearer or what aspects of the sentence need improvement. The authors are left with an implicit action to revise the sentence, but without concrete details on how to do so. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it provides a clear suggestion to make the sentence in lines 12-17 clearer. This feedback is actionable and provides a clear direction for improvement, making it a fully grounded and specific comment.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the abstract sentence is cumbersome and could be made clearer. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why the sentence is cumbersome or how to make it clearer. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the abstract, noting that the sentence describing the number of questions is cumbersome and could be clearer. This feedback is actionable as it provides a clear suggestion for improvement, guiding the authors to refine the sentence for better readability. However, the comment could be more helpful if it offered additional guidance on how to make the sentence clearer, such as suggesting specific ways to rephrase it or provide more context. Overall, the comment is mostly helpful as it highlights an area for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the fairness of comparisons made in the experiments, specifically noting that the domain-specific model and the experiments are both conducted on Pix3D. This observation suggests that the comparisons to zero-shot single-image 3D reconstruction models might be unfair. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the experiments or comparisons. The action is implicit, as the authors need to infer that they should consider alternative datasets or methods to ensure fair comparisons. While the action is somewhat vague, it is clear that the authors need to address the issue of fairness in their comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Pix3D\" and \"Pix3D,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparisons to zero-shot single-image 3D reconstruction models, highlighting the unfairness of the comparisons. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that comparisons to zero-shot single-image 3D reconstruction models are unfair because the domain-specific model and experiments are both conducted on Pix3D. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why the comparisons are unfair. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of comparisons made in the experiments, specifically noting that the domain-specific model and the experiments are both conducted on Pix3D. This observation suggests that the comparisons to zero-shot single-image 3D reconstruction models might be unfair. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what changes could be made to ensure fair comparisons. While it highlights a concern, it lacks actionable advice or detailed feedback, making it somewhat helpful. The authors would need to infer that they should consider alternative datasets or methods to ensure fair comparisons, but the comment does not provide explicit steps or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the intuition behind the specific choice of $\\lambda_t$ in the E2W algorithm, particularly regarding exploration. It also questions the necessity of the exploration parameter $\\epsilon$ and the use of $\\sum_a N(s, a)$ instead of $N(s, a)$ for $\\lambda_s$ in Equation (7). While the comment prompts the authors to consider these aspects, it does not provide explicit guidance on how to address these questions or what specific actions should be taken. The questions are clear and specific, but the lack of actionable suggestions leaves the authors without a clear path forward. Therefore, the comment is somewhat actionable, as it identifies areas for clarification but does not provide detailed guidance on how to implement the suggestions.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the intuition behind the specific choice of $\\lambda_t$ in the E2W algorithm, particularly regarding exploration. It also questions the necessity of the exploration parameter $\\epsilon$ and the use of $\\sum_a N(s, a)$ instead of $N(s, a)$ for $\\lambda_s$ in Equation (7). However, the comment does not specify which part of the paper these questions pertain to, such as a specific section or equation. This makes it difficult for the authors to pinpoint the exact areas that need clarification. While the questions are specific, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the intuition behind the specific choice of $\\lambda_t$ in the E2W algorithm, particularly regarding exploration. It also questions the necessity of the exploration parameter $\\epsilon$ and the use of $\\sum_a N(s, a)$ instead of $N(s, a)$ for $\\lambda_s$ in Equation (7). However, the comment does not provide any evidence, reasoning, or references to support these claims. The questions are based on logical reasoning but lack detailed explanations or references, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several questions about the intuition behind the specific choice of $\\lambda_t$ in the E2W algorithm, particularly regarding exploration. It also questions the necessity of the exploration parameter $\\epsilon$ and the use of $\\sum_a N(s, a)$ instead of $N(s, a)$ for $\\lambda_s$ in Equation (7). While the questions are clear and specific, they do not provide actionable guidance or suggestions for the authors to address these concerns. The feedback is somewhat helpful as it identifies areas where the authors might need to clarify or justify their choices, but it lacks depth and does not offer concrete steps for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation is limited, primarily relying on 4 OCR QA datasets. It acknowledges that this evaluation may be unreliable, as the authors themselves admit in Fig 4(5). The comment suggests that more scenarios, such as the LLaVA benchmark, would be expected, particularly in ablation studies. However, the comment does not provide explicit guidance on how the authors should incorporate these additional scenarios or how to conduct the ablation studies. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve their evaluation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 4(5)\" in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the evaluation, noting that it is limited to 4 OCR QA datasets and that the authors themselves acknowledge this limitation. The comment suggests that more scenarios, such as the LLaVA benchmark, would be expected, especially in ablation studies. This provides clear guidance on what additional scenarios the authors should consider to enhance their evaluation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation is limited, primarily relying on 4 OCR QA datasets, and that this evaluation may be unreliable, as acknowledged in Fig 4(5). The comment suggests that more scenarios, such as the LLaVA benchmark, would be expected, especially in ablation studies. However, the comment lacks specific examples or detailed reasoning to support the claim that the evaluation is unreliable or why the LLaVA benchmark would be more appropriate. Without concrete evidence or references, the claim is somewhat verifiable, as it provides a basis for improvement but lacks detailed justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the evaluation of the paper, noting that it primarily relies on 4 OCR QA datasets. The authors themselves acknowledge this limitation in Figure 4(5), suggesting that the evaluation may be unreliable. The comment proposes that more scenarios, such as the LLaVA benchmark, would be expected, particularly in ablation studies. This feedback is somewhat helpful as it highlights a specific area for improvement and suggests additional scenarios that could enhance the evaluation's comprehensiveness. However, the comment could be more helpful if it provided more detailed guidance on how to incorporate these additional scenarios or how to conduct the ablation studies. Overall, the comment offers valuable insights but lacks depth, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions whether the current formulation is necessary or if simpler tasks might suffice. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes they should make to the tasks. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions whether the current formulation is necessary or if simpler tasks might suffice. However, the comment does not specify which part of the paper discusses these tasks, making it difficult for the authors to pinpoint the exact issue. While the comment is specific about the nature of the tasks, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions whether the current formulation is necessary or if simpler tasks might suffice. However, the comment does not provide any specific evidence, examples, or references to support these claims. The feedback lacks detailed reasoning or justification, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions whether the current formulation is necessary or if simpler tasks might suffice, highlighting a potential issue with the complexity of the tasks. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve the clarity of the tasks. Without actionable feedback or detailed examples, the authors may find it challenging to understand how to make the necessary adjustments. Therefore, the comment is barely helpful, as it identifies a problem but does not provide sufficient guidance for improvement.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the evaluation of weak supervision could be improved by considering the realism of the evaluated tweets. It provides specific examples, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the issue with the generation of authors being unrealistic. However, the comment does not explicitly instruct the authors to address these issues or provide guidance on how to improve the realism of their evaluations. The action is implicit and somewhat vague, as the authors are left to infer what needs to be done. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the evaluation of weak supervision, specifically mentioning the realism of the evaluated tweets and the generation of authors. It provides specific examples, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the issue with the generation of authors being unrealistic. However, the comment does not explicitly mention which part of the paper this issue pertains to, making it weakly grounded. The specificity is high as it clearly specifies what needs to be addressed in the evaluation of weak supervision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation of weak supervision could be better evaluated by considering the realism of the evaluated tweets. It provides specific examples, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the issue with the generation of authors being unrealistic. However, the comment lacks detailed reasoning or references to support these claims, making it difficult for the authors to fully understand and address the issue. The feedback is somewhat verifiable as it provides some justification but lacks depth and specific examples to guide the authors in improving their evaluation process. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets and the generation of authors. It provides specific examples, such as the requirement for 'all of the structured elements for perspectives to be present in the generated tweets' and the unrealistic nature of the author embeddings. However, the comment does not offer actionable suggestions or guidance on how to address these issues or improve the realism of the evaluation. While it highlights a concern, it lacks depth and constructive feedback, making it somewhat helpful. The authors would need to infer what needs to be improved, which limits the comment's effectiveness. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the keypoint detection results should be included in the experiments section. This provides a clear and explicit action for the authors to take, as they need to add these results to the experiments section to improve the completeness of their paper. The comment is specific and concrete, giving the authors a precise idea of what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the keypoint detection results should be included in the experiments section. However, it does not specify which part of the experiments section this should be included in, nor does it provide any guidance on how to present or analyze these results. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity, as it does not provide any details on what aspects of the keypoint detection results need to be included or how they should be presented. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the keypoint detection results should be included in the experiments section. However, it does not provide any specific reasoning, examples, or references to support why this inclusion is necessary or beneficial. Without additional context or justification, the claim lacks sufficient evidence to be fully verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the keypoint detection results should be included in the experiments section. This is a specific and actionable piece of feedback that provides the authors with a clear direction for improving their draft. By including these results, the authors can enhance the completeness and depth of their experimental analysis, which is crucial for a thorough evaluation of their work. The comment is clear and directly addresses a specific aspect of the paper, making it highly helpful for the authors to improve their draft. Therefore, this comment aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the grid search of the learning rate is performed on the validation set. While it identifies a potential issue, it does not provide explicit instructions or suggestions on how to address this concern. The authors are left to infer that the comment implies a need to clarify the methodology used in the grid search. However, the action is implicit and somewhat vague, as it does not specify what needs to be done to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether the grid search of the learning rate is performed on the validation set. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or figure being referenced. The comment is not grounded as it lacks specific references or context. Additionally, it does not provide specific guidance on how to address the issue, making it under-specific. Therefore, this comment is weakly grounded and under-specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about whether the grid search of the learning rate is performed on the validation set. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific details or justification, making it difficult for the authors to understand the basis of the question or how it relates to the paper. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about whether the grid search of the learning rate is performed on the validation set. While it identifies a potential issue in the methodology, it does not provide any suggestions or guidance on how to address this concern. The comment lacks depth and specificity, as it does not offer any actionable advice or insights into how the authors might improve their approach. Without additional context or suggestions, the authors may find it challenging to understand the implications of the comment or how to respond effectively. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the presence of a large number of dobj relations in Table A2, suggesting that it might be an artifact of colloquial language or a specific choice in the UD dataset. However, it does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The comment implies that the authors should investigate the nature of these relations and consider whether they are appropriate for the dataset or if they should be categorized differently. While the action is implicit, it is somewhat vague, as the authors are left to infer the specific steps needed to address the concern. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the issue is by questioning the presence of a large number of dobj relations and asking whether this is an artifact of colloquial language or a specific choice in the UD dataset. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the presence of a large number of dobj relations in Table A2, suggesting that it might be an artifact of colloquial language or a specific choice in the UD dataset. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the observation. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the presence of a large number of dobj relations in Table A2, specifically questioning whether this might be an artifact of colloquial language or a specific choice in the UD dataset. While the comment identifies a potential issue with the data representation, it does not provide any suggestions or guidance on how the authors might address this concern. The feedback is somewhat helpful as it highlights a potential area for further investigation, but it lacks actionable advice or detailed insights that would guide the authors in improving their draft. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the diversity of the sample and its generalizability to other groups, particularly marginalized ones. It does not provide explicit instructions or suggestions on how to address this issue, such as adding data or discussing the implications of the sample's diversity. The action is implicit, as the authors would need to infer that they should consider the diversity of their sample and its impact on the generalizability of the results. However, the comment lacks concrete guidance on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific line number (L393), allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the diversity of the sample and its generalizability to other groups, especially marginalized ones. This provides clear guidance on how the authors should respond to the comment. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the diversity of the sample and its generalizability to other groups, particularly marginalized ones. It does not contain a subjective claim or suggestion but rather poses a question that requires the authors to consider the implications of their sample diversity. While it prompts a discussion, it lacks specific guidance or evidence to support the question, making it difficult for the authors to address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the diversity of the sample and its generalizability to other groups, especially marginalized ones. This is a critical aspect of research that can impact the broader applicability of the findings. By prompting the authors to consider the diversity of their sample, the comment encourages them to address potential biases or limitations in their data. However, the comment lacks specific guidance on how to address this issue or what data might be needed to strengthen the generalizability of the results. While it provides a valuable direction for improvement, it could be more helpful with additional suggestions or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the output quality of the paper is reasonable but still far from realistic, citing recent GAN works that achieve high-quality synthesized results. It implies that there is room for improvement in the result quality. However, the comment does not provide specific guidance on how to improve the output quality or what aspects of the paper need to be addressed to achieve higher quality results. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know exactly what steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue with output quality, referencing recent GAN works that have shown high-quality synthesized results. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with output quality and suggests that there is room for improvement. However, it does not provide detailed guidance on how to improve the output quality or what specific aspects of the paper need to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the output quality is reasonable but still far from realistic, citing recent GAN works that have shown high-quality synthesized results. This claim is somewhat verifiable as it provides a general reference to recent advancements in GANs, which could be expanded with specific examples or citations to support the claim. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the output quality of the paper, noting that it is reasonable but still far from realistic, especially considering recent advancements in GANs. It suggests that there is room for improvement in the result quality, which is a valuable feedback point for the authors. However, the comment lacks specific guidance on how to improve the output quality or what aspects of the paper need to be addressed to achieve higher quality results. While it provides a clear direction for improvement, the feedback could be more helpful if it included actionable suggestions or examples of how to enhance the output quality. Overall, the comment is somewhat helpful, as it highlights a critical area for improvement but does not provide detailed guidance for the authors to address it effectively.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the use of subpar hyperparameters, similar to those used in other works, and questions the clarity of the results presented in the leftmost plots. However, it does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The comment implies that the authors should consider using better hyperparameters or providing more clarity on the results, but it lacks concrete steps or detailed advice on how to implement these suggestions. As a result, the comment is somewhat actionable, as it identifies an area for improvement but does not offer specific guidance on how to achieve it. Therefore, it aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"soft labels\" and \"Cross entropy,\" which are specific technical terms related to the paper's content. It also refers to \"iNaturalist19\" and \"beta value,\" which are specific elements of the paper. The comment is specific because it details the concern about the use of subpar hyperparameters and questions the clarity of the results presented in the leftmost plots. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the use of subpar hyperparameters and questions the clarity of the results presented in the leftmost plots. However, it does not provide specific examples, references, or detailed reasoning to support these claims. The comment lacks sufficient evidence or justification to be considered fully verifiable. Therefore, it aligns with a score of 1, as it is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises concerns about the use of subpar hyperparameters and questions the clarity of the results presented in the leftmost plots. It suggests that the authors should consider using better hyperparameters or providing more clarity on the results. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve their draft. While it identifies potential areas for improvement, it does not provide actionable steps or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more evaluation on classifying unseen words, particularly by adding translations to Figure 6. This feedback is explicit, as it directly instructs the authors to include additional evaluations and specific elements in their draft. The action is also concrete, as it provides clear guidance on how to implement the suggestion by adding translations to Figure 6. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide more evaluation on classifying unseen words, particularly by adding translations to Figure 6. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to add translations to Figure 6, which would help clarify the evaluation process for unseen words. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide more evaluation on classifying unseen words, particularly by adding translations to Figure 6. This claim is somewhat verifiable as it implies the need for additional evaluation, but it lacks specific examples or references to support the suggestion. The authors would need to infer the need for more detailed evaluation and the rationale behind it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the presentation of the simple/traditional experiment for unseen characters, suggesting that it is presented as an afterthought. The reviewer recommends adding more evaluation, particularly on classifying unseen words, and suggests including translations in Figure 6 to aid understanding for those who do not speak Chinese. This feedback is actionable and provides clear guidance on how the authors can improve the presentation and clarity of their work. By addressing these suggestions, the authors can enhance the comprehensiveness and accessibility of their research, making the comment highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the sufficiency of the number of images in the VioT dataset to text the validity of the approach. While it identifies a potential issue with the dataset size, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take to improve the dataset or the approach. The comment lacks concrete suggestions or detailed instructions on how to enhance the dataset or the validity of the approach. As a result, the authors are left without a clear understanding of how to proceed, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the VioT dataset, specifically mentioning the number of images in each category. However, it does not specify which part of the paper this information is related to, making it weakly grounded. The comment is specific in questioning the sufficiency of the dataset size to validate the approach, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sufficiency of the number of images in the VioT dataset to validate the approach. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the reviewer's assertion remains speculative and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the dataset used in the study, specifically questioning the sufficiency of the number of images in each category to validate the approach. While the comment highlights a concern that could impact the reliability of the results, it does not provide specific suggestions or guidance on how to address this issue. The feedback is somewhat helpful as it points out a potential weakness in the dataset, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several issues with the paper, including its difficulty to follow, the need for more intuitive explanations of mathematical derivations, and the lack of detailed explanations for figure captions. It suggests that the authors should provide additional explanations and legends for figures, such as explaining the colors in Fig. 2. However, the comment does not explicitly instruct the authors on how to incorporate these suggestions or provide concrete guidance on what specific changes to make. The actions are implicit and somewhat vague, as the authors are left to infer how to improve the paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the paper's difficulty to follow and suggests the need for more intuitive explanations of mathematical derivations. It also points out the lack of detailed explanations for figure captions, specifically mentioning the need to explain the colors in Fig. 2. However, the comment does not specify which part of the paper these issues are present, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as providing intuitive explanations and detailed figure captions. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is hard to follow and suggests that more intuitive explanations of mathematical derivations are needed. It also points out the lack of detailed explanations for figure captions, specifically mentioning the need to explain the colors in Fig. 2. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the feedback. The lack of detailed reasoning or examples makes the claim somewhat verifiable, as the authors may need to infer the issues based on their own experience. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas where the paper could be improved, specifically noting that it is hard to follow and lacks intuitive explanations for mathematical derivations. It also points out the absence of detailed explanations for figure captions, such as the need to explain the colors in Fig. 2. The comment suggests that the authors should provide additional explanations and legends to enhance the clarity and understanding of the paper. While the feedback is clear and actionable, it could be more helpful if it provided specific examples or guidance on how to improve the explanations and figure captions. Overall, the comment is mostly helpful as it directs the authors to areas for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the paper: the readability of the text in Table 1 and the missing gradient symbol in Algorithm 1. However, it does not provide any explicit or implicit suggestions on how to address these issues. The comment lacks actionable guidance, leaving the authors without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses issues with the readability of text in Table 1 and the missing gradient symbol in Algorithm 1. However, it does not specify which part of the paper these issues are located in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment does not provide specific guidance on how to improve the readability of the text or how to correct the missing gradient symbol. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of two claims: that the text in Table 1 is too small and hard to read, and that the gradient symbol is missing in Algorithm 1. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without justification or examples, the authors may find it challenging to understand why these issues are significant or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the readability of the text in Table 1 and the missing gradient symbol in Algorithm 1. While it points out these areas for improvement, it does not provide any suggestions or guidance on how to address these issues. The feedback is somewhat helpful as it highlights areas that need attention, but it lacks depth and actionable advice, making it difficult for the authors to make meaningful improvements. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should render a citation more naturally using bracketed arguments in \\citep, referencing a specific figure. It also raises a question about the compatibility of this approach with hyperref. However, the comment does not provide explicit guidance on how to implement this suggestion or clarify the issue with hyperref. The action is implicit and vague, leaving the authors uncertain about the exact steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Wright et al., 1934\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with rendering the citation more naturally using bracketed arguments in \\citep, and raises a question about the compatibility with hyperref. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should render a citation more naturally using bracketed arguments in \\citep, referencing a specific figure. It also raises a question about the compatibility of this approach with hyperref. However, the comment lacks specific examples or detailed reasoning to support why this suggestion is necessary or beneficial. The authors are left to infer the importance of the suggestion, which makes it difficult to fully understand and address. Therefore, the comment is barely verifiable, aligning with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors should render a citation more naturally using bracketed arguments in \\citep, referencing a specific figure. It also raises a question about the compatibility of this approach with hyperref. While the comment identifies a potential improvement in the presentation of citations, it lacks detailed guidance or examples on how to implement this suggestion. The feedback is somewhat helpful as it points out an area for enhancement, but it does not provide comprehensive advice or actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific feedback on the equations in the paper, suggesting that the signs should be changed. It also mentions a minor comment about a specific line. However, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The actions are implicit and somewhat vague, as the authors need to infer that they should correct the signs in the equations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper (Line 502, 503, and 504), allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear feedback on the equations, detailing the necessary corrections to the signs. This level of detail helps the authors understand exactly what needs to be changed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a critique of specific equations in the paper, suggesting that the signs should be changed. While the comment provides a clear and specific claim about the need for correction, it lacks detailed reasoning or references to support why these changes are necessary. The feedback is somewhat verifiable as it points out specific errors but does not provide a comprehensive explanation or justification for the suggested changes. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific errors in the equations presented in the paper, providing clear feedback on the signs that should be corrected. It points out inconsistencies in the definitions and equations, which could potentially affect the accuracy and reliability of the results. However, the comment lacks broader context or suggestions for how the authors might address these issues beyond simply correcting the signs. While it offers some actionable feedback, it could be more helpful if it included additional guidance or suggestions for improving the clarity and robustness of the paper. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the ResNet in the experiments shares parameters between residual blocks. It suggests that comparing the current setup to a deeper ResNet with parameter sharing could be an interesting baseline, potentially equivalent to an ODE net with a fixed time-step Euler integrator. However, the comment does not provide explicit guidance on how the authors should address this question or incorporate the suggested comparison into their draft. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 7.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider, namely whether the ResNet shares parameters between residual blocks and suggests an interesting baseline for comparison. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about whether the ResNet in the experiments shares parameters between residual blocks and suggests an interesting baseline for comparison. However, it does not provide any specific reasoning, examples, or references to support the claim that this comparison would be interesting or relevant. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the ResNet implementation in the experiments, specifically whether the residual blocks share parameters. It suggests an interesting baseline for comparison by proposing a deeper ResNet with parameter sharing, which could be equivalent to an ODE net with a fixed time-step Euler integrator. This feedback is somewhat helpful as it identifies a potential area for further exploration and provides a suggestion for an interesting comparison. However, the comment lacks depth and does not offer detailed guidance on how to implement or evaluate this suggestion, leaving the authors with limited actionable insights. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the motivation of the paper, suggesting that the cross-encoder architecture is not as effective as claimed. It highlights that the architecture \"ignores cross-entity comparison\" and \"attends to all candidates at once,\" which may not be as fine-grained as suggested. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their draft. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to respond. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the motivation of the paper, specifically questioning the effectiveness of the cross-encoder architecture. It mentions that the architecture \"ignores cross-entity comparison\" and \"attends to all candidates at once,\" which may not be as fine-grained as suggested. However, the comment does not specify which part of the paper discusses the motivation or the cross-encoder architecture, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in its critique of the architecture, it lacks grounding as it does not provide clear references to the relevant sections. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the motivation of the paper, specifically questioning the effectiveness of the cross-encoder architecture. It claims that the architecture \"ignores cross-entity comparison\" and \"attends to all candidates at once,\" which may not be as fine-grained as suggested. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The reasoning is logical but lacks detailed evidence, which could be improved with additional references or examples. Therefore, the comment is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the motivation of the paper, specifically questioning the effectiveness of the cross-encoder architecture. It points out that the architecture 'ignores cross-entity comparison' and 'attends to all candidates at once,' which may not be as fine-grained as suggested. This critique provides a clear and actionable feedback, helping the authors understand a potential weakness in their approach. However, the comment could be more helpful if it offered suggestions on how to address these issues or improve the motivation of the paper. Overall, the feedback is somewhat helpful as it highlights a critical area for improvement, but it lacks depth and guidance, making it a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the use of an \"antiquated GNN model and method\" and suggests that this impacts the performance of the framework. It also mentions that the baseline algorithms/methods are \"antiquated.\" However, the comment does not provide any specific guidance or suggestions on how the authors should address this issue. The authors are left without a clear understanding of what changes or improvements are needed to enhance the performance of the framework or the baseline methods. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper discusses the use of an antiquated GNN model and method. The authors cannot confidently determine which section or aspect of the paper is being addressed. Additionally, the comment is not specific because it does not detail what aspects of the model or methods are considered \"antiquated\" or how this impacts the framework. Therefore, the comment is not grounded and not specific, aligning with category 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the work uses an \"antiquated GNN model and method,\" which seriously impacts the performance of the framework. It also states that the baseline algorithms/methods are \"antiquated.\" However, the comment lacks specific examples or references to support these claims. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks depth and clarity.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the use of an \"antiquated GNN model and method,\" which could impact the performance of the framework. It also points out that the baseline algorithms/methods are \"antiquated.\" However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their work. While it highlights a potential weakness, it does not provide actionable steps or insights to help the authors enhance their research or methodology. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but does not offer detailed guidance on how to achieve it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the clarity of how the proposed method produces the explanation in Figure 1, specifically regarding the presence of the NO2 group. It suggests that additional post-analysis might be needed to extract shared motifs, implying that the analysis is not as straightforward as it could be. However, the comment does not provide explicit guidance on how to address this issue or what specific steps should be taken to improve the clarity of the explanation. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the explanation in Figure 1, questioning how the proposed method produces the explanation and suggesting that additional post-analysis might be necessary. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of how the proposed method produces the explanation in Figure 1, specifically regarding the presence of the NO2 group. It suggests that additional post-analysis might be necessary to extract shared motifs, implying that the analysis is not as straightforward as it could be. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of detailed justification makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 1, noting that it is unclear how the proposed method produces the explanation regarding the presence of the NO2 group. The reviewer suggests that additional post-analysis might be necessary to extract shared motifs, implying that the analysis is not as straightforward as it could be. This feedback is somewhat helpful as it highlights a potential area for improvement in the clarity and comprehensiveness of the explanation. However, the comment could be more helpful if it provided specific guidance on how to address this issue or suggested alternative approaches to enhance the clarity of the explanation. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the paper, including the lack of comparison with models other than GPT2, confusion in certain sections, and missing citations and unreferenced notations. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment lacks guidance on how to compare models, how to clarify confusing sections, or how to add the missing references and references to the notation. As a result, the authors are left without a clear path to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper where issues need to be addressed, such as the lack of comparison with models other than GPT2, confusion in certain sections, and missing citations and unreferenced notations. It also specifies what needs to be addressed in these sections, including the need for comparisons, clarification, and references. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors did not compare any models other than GPT2, which is a specific observation that can be verified by examining the paper. It also mentions that several sections of the paper read confusingly, which can be assessed by reviewing the sections. Additionally, the comment points out a missing citation in Line 99, section 3.1, and an unreferenced notation \\hat{D}(c) in Line 165, section 3.4. These claims are supported by specific references to the paper, making the comment mostly verifiable. However, the comment could be more detailed by providing examples of the confusing sections or explaining why the comparison with other models is important. Overall, the comment is mostly verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, including the lack of comparison with models other than GPT2, confusion in certain sections, and missing citations and unreferenced notations. While the comment provides specific examples of issues, it does not offer detailed guidance on how to address these problems or suggest specific improvements. The feedback is somewhat helpful as it highlights areas that need attention, but it lacks depth and actionable suggestions, which could be expanded to provide more comprehensive feedback. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks for clarification on the meaning of a specific term in Equation (2). While it does not explicitly instruct the authors to provide this clarification, it implies that they should explain the term to ensure the reader understands the equation. However, the action is implicit and somewhat vague, as the authors are not given specific guidance on how to clarify the term. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is referring to, such as a particular section or equation. It is also not specific because it does not provide any guidance or explanation on how to clarify the meaning of the term. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the meaning of a specific term in Equation (2). It does not contain a claim or assertion that requires verification or justification. The comment is factual and descriptive, as it seeks clarification on a technical detail within the paper. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of a specific term in Equation (2), which could be helpful for the authors to clarify for better understanding. However, the comment does not provide any suggestions or guidance on how to address this issue, nor does it offer any additional context or explanation. As a result, the feedback is somewhat helpful, as it identifies a potential area for improvement but lacks depth and actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a more comprehensive and data-intensive analysis would improve the paper, but it does not provide specific guidance on how to achieve this. The comment lacks explicit instructions or concrete steps for the authors to take to enhance their analysis. As a result, the authors are left without a clear understanding of what actions to undertake to address the feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that a more comprehensive and data-intensive analysis would improve the paper, but it does not specify which part of the paper this analysis should be applied to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what kind of analysis would be more comprehensive or data-intensive. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that a more comprehensive and data-intensive analysis would improve the paper, but it does not provide specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that a more comprehensive and data-intensive analysis would improve the paper, but it does not provide specific guidance or examples on how to achieve this. While the feedback acknowledges the potential for improvement, it lacks actionable advice or suggestions for the authors to consider. This limits the comment's usefulness, as it does not offer a clear path for enhancing the paper. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should cite and discuss works related to meta-learning, particularly those that, while not directly targeting continual learning, are relevant. It also recommends strengthening the connection to works on RL for architecture search and optimization in the context of continual learning. However, the comment does not provide explicit guidance on how to implement these suggestions, such as specific sections or examples to include. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the feedback. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should cite and discuss works related to meta-learning, particularly those that, while not directly targeting continual learning, are relevant. It also recommends strengthening the connection to works on RL for architecture search and optimization in the context of continual learning. However, the comment does not specify which part of the paper these works are relevant to, making it weakly grounded. The comment is specific in its suggestions regarding the need to cite and discuss these works, but without clear references to specific sections or parts of the paper, the authors may find it challenging to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should cite and discuss works related to meta-learning, particularly those that are relevant to continual learning, even if they do not directly target it. The comment also recommends strengthening the connection to works on RL for architecture search and optimization in the context of continual learning. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand and address the feedback effectively. The reasoning is somewhat vague, and the lack of detailed examples or references makes it challenging to fully verify the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides valuable feedback by suggesting that the authors should cite and discuss works related to meta-learning, particularly those that are relevant to continual learning, even if they do not directly target it. It also recommends strengthening the connection to works on RL for architecture search and optimization in the context of continual learning. This feedback is clear and actionable, as it guides the authors to include additional relevant literature and enhance the discussion of their work. However, the comment could be more helpful if it provided specific examples or sections where these works could be cited. Overall, the comment is mostly helpful, as it offers clear directions for improvement but could be more comprehensive with additional details.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the diversity of teacher feedback, suggesting that the authors might consider turking or generating different feedback. However, it does not provide explicit instructions or guidance on how to implement this suggestion. The action is implicit, as the authors need to infer that they should explore methods to increase the diversity of feedback. While the suggestion is concrete in terms of exploring different feedback types, the lack of explicit guidance on how to do so makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the diversity of teacher feedback, suggesting that the authors might consider turking or generating different kinds of feedback. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its suggestion to explore different feedback types, but without a clear reference to the paper, it is difficult for the authors to understand where to apply this feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the diversity of teacher feedback, suggesting that the authors might consider turking or generating different kinds of feedback. However, it does not provide any specific reasoning, examples, or references to support why this is a concern or how it might impact the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the diversity of teacher feedback, suggesting that the authors might consider turking or generating different kinds of feedback. This is a relevant point, as it could enhance the comprehensiveness and depth of the feedback provided. However, the comment lacks specific guidance or suggestions on how to implement this idea, such as exploring different methods for generating diverse feedback or providing examples of how to do so. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point recommends comparing the performance of the proposed method with two specific papers, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer\". This recommendation provides a clear and explicit action for the authors to take, as they can compare their results with these specific works to better understand their performance relative to existing methods. The comment is concrete, as it specifies exactly which papers to compare with, and it provides a clear direction for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment recommends comparing the performance of the proposed method with two specific papers, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer\". This recommendation is fully grounded as it explicitly mentions the papers to be compared, allowing the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies which papers to compare with, providing a clear direction for the authors to follow. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point recommends comparing the performance of the proposed method with two specific papers, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer\". This recommendation is somewhat verifiable as it provides a clear suggestion for comparison, but it lacks specific details or examples of how the comparison should be conducted or what aspects of the performance should be evaluated. Without additional context or guidance, the authors may find it challenging to fully understand and implement the recommendation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to compare their method with two specific papers, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer\". This recommendation is valuable as it helps the authors understand how their work aligns with or differs from existing approaches in the field. By comparing their performance with these specific papers, the authors can better contextualize their contributions and identify potential areas for improvement. The comment is mostly helpful as it offers a clear direction for further evaluation and comparison, but it could be more comprehensive if it included additional guidance on how to conduct the comparison or what specific aspects to focus on. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the lack of standard deviations in the results, questioning the certainty of the best method's superiority. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting the inclusion of standard deviations or providing additional analysis to clarify the performance differences. The action is implicit and vague, as the authors are left to infer that they need to include standard deviations to address the concern. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of missing standard deviations in the results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the problem, questioning the certainty of the best method's superiority due to the absence of standard deviations. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the lack of standard deviations in the results makes it uncertain whether the best method is truly the best or if other RF configurations have performances close to it. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the lack of standard deviations in the results, which raises concerns about the certainty of the best method's superiority. This feedback is clear and actionable, as it directs the authors to include standard deviations to address the uncertainty in their findings. However, the comment could be more helpful if it provided additional guidance on how to present or interpret the results with standard deviations. Despite this, the feedback is mostly helpful as it highlights a critical aspect of the results that needs attention, empowering the authors to improve their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a specific concern about the limitations of the current setting, which requires knowledge of the model or access to a generative model, and suggests that the approach should be extended to more general settings. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how to extend the approach or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific setting of the paper, including the requirements for the model and the episodic nature of the problem. It also specifies the need to extend the approach to more general settings, providing clear guidance on what needs to be addressed. This allows the authors to accurately identify the part of the paper being discussed and understand the specific issue being raised. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a specific question about the limitations of the current setting, which requires knowledge of the model or access to a generative model, and suggests extending the approach to more general settings. While the comment highlights a potential area for improvement, it does not provide any evidence or reasoning to support why this extension is necessary or beneficial. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and how it relates to the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific concern about the limitations of the current setting, which requires knowledge of the model or access to a generative model, and suggests extending the approach to more general settings. This feedback is clear and actionable, as it identifies a potential area for improvement that could enhance the applicability and robustness of the proposed method. However, the comment could be more helpful if it provided additional guidance on how to extend the approach or what specific changes might be necessary. Despite this, the feedback is mostly helpful as it directs the authors towards a meaningful direction for enhancing their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not specify which parts of the paper these details should be included in or how they should be presented. The action is implicit, as the authors can infer that they need to add these details, but the lack of specificity makes it difficult to know exactly what to do. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not specify which part of the paper these details should be included in or how they should be presented. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what kind of computation, algorithm, or implementation details would be beneficial. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not offer any specific reasoning, examples, or references to support why this suggestion is beneficial. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it lacks specificity and does not offer any guidance on how these details should be presented or what aspects of the paper would benefit from such information. While the comment identifies a potential area for improvement, it does not provide actionable feedback or suggestions for the authors to address this issue. Therefore, the comment is barely helpful, as it offers a vague suggestion without detailed guidance or examples. The score aligns with a rating of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of p < 0.4 in Algorithm 1, but it does not provide any guidance or suggestions on how the authors might have made this choice. The comment lacks explicit instructions or concrete advice on how to address the question or improve the algorithm. As a result, the authors are left without any actionable steps to take, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper Algorithm 1 is located in, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment is specific in that it questions the choice of p < 0.4, but without the context of where Algorithm 1 is located, the authors cannot fully understand the scope of the question. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of p < 0.4 in Algorithm 1, but it does not provide any justification or reasoning for why this specific value was chosen. Without additional context or explanation, the authors are left without guidance on how to address this question or improve the algorithm. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of p < 0.4 in Algorithm 1, which could be a point of confusion for the authors. However, the comment does not provide any guidance or suggestions on how the authors might have made this choice or how to address it. Without additional context or explanation, the authors are left without actionable feedback to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential issue but lacks depth and guidance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to provide explanations or analysis for the figures presented in Section 5, specifically mentioning the need to clarify the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. This feedback is clear and direct, allowing the authors to understand exactly what needs to be addressed. The action is explicit and concrete, as it specifies the exact sections and elements that require clarification. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5\" and the figures \"Figure 1, Figure 2, and Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of explanations or analysis for the figures, particularly the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. This provides clear guidance on what the authors should do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors fail to provide explanations or analysis for the figures presented in Section 5, specifically mentioning the need to clarify the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the feedback and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of figures in Section 5, noting that the authors fail to provide explanations or analysis for Figures 1, 2, and 3. It highlights the need to clarify the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. This feedback is clear and actionable, as it directs the authors to specific areas where they need to improve their draft by adding explanations and analysis. However, the comment could be more helpful if it provided examples of how to explain or analyze the figures, or if it suggested specific types of analysis that would be beneficial. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of analysis regarding the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct the analysis or what specific aspects of the methods should be examined. The suggestion to compare with other methods is clear, but the lack of detailed instructions on how to perform the analysis makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a lack of analysis regarding the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing. However, it does not specify which part of the paper this analysis should be conducted or which sections of the paper discuss the methods being compared. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the need for analysis and comparison, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is insufficient analysis of the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing. The comment provides specific references to support the suggestion, which helps the authors understand the need for comparison. However, it lacks detailed reasoning or examples of how the analysis should be conducted or what specific aspects of the methods should be compared. This makes the claim somewhat verifiable, as it provides a basis for improvement but requires further elaboration from the authors. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper by pointing out the lack of analysis regarding the effectiveness of each data augmentation method. It also suggests comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing, to clarify the unique advantages of the proposed method. The inclusion of references to specific works further supports the suggestion, providing a clear direction for the authors to enhance their analysis. This feedback is mostly helpful as it offers actionable insights and guidance on how to strengthen the paper's evaluation and comparison of methods. However, it could be more comprehensive if it provided more detailed suggestions or examples of how to conduct the analysis. Overall, the comment is rated as 4: Mostly Helpful.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an ablation study is needed to understand the impact of each component in learning with MMD. It provides examples of alternative approaches, such as using typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, the comment does not explicitly instruct the authors to conduct an ablation study or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer the need for an ablation study and its implementation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the need for an ablation study in learning with MMD, suggesting alternative approaches to evaluate the impact of each component. However, it does not specify which part of the paper this issue is related to, such as a specific section or figure. The comment is fully grounded in terms of identifying the area of concern, but it is not specific in detailing what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an ablation study is needed to understand the net effect of each component in learning with MMD. It provides examples of alternative approaches, such as using typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, the comment lacks specific details or references to support the claim that an ablation study is necessary or how it would be conducted. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the learning with MMD approach, specifically noting the lack of an ablation study to understand the impact of each component. It provides examples of alternative approaches, such as using typical knowledge distillation loss or distilling a Hydra architecture with MMD loss, which could help the authors gain a better understanding of the proposed method. However, the comment does not offer detailed guidance on how to conduct the ablation study or what specific components should be analyzed. While it points out a potential area for improvement, it lacks depth and specificity, making it somewhat helpful. The feedback is clear but could be more comprehensive to fully assist the authors in enhancing their draft.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. While it raises a relevant question, it does not provide explicit guidance or suggestions on how the authors should address this issue or what actions they should take to improve their draft. The comment lacks concrete steps or detailed feedback, leaving the authors uncertain about how to respond or what changes are needed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is not grounded as it does not provide explicit references to specific sections, tables, or figures. Additionally, it lacks specificity because it does not detail what the authors should do to address this question or how it relates to the overall content of the paper. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not provide any context, explanation, or justification for why this question is important or how it relates to the paper's content. Without additional information or reasoning, the authors are left without guidance on how to address this question or what it implies for their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the performance of a model that assigns all negative samples to a distractor class. While this question is relevant to understanding the model's behavior, it does not provide specific guidance or suggestions on how the authors might address this issue or what improvements could be made to their draft. The comment lacks actionable feedback, leaving the authors with limited insight into how to enhance their work. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific observation about the performance of RLCD compared to RLAIF as the model size increases from 7B to 30B, as shown in Table 2. It suggests that the advantage of RLCD might diminish further with even larger models and questions whether RLCD or RLCD-Rescore can scale effectively. However, the comment does not provide explicit guidance on how the authors might address this issue or what specific actions they should take to improve their draft. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the performance of RLCD compared to RLAIF as the model size increases from 7B to 30B, as shown in Table 2. It questions whether RLCD or RLCD-Rescore can scale effectively to larger models, which are arguably better at differentiating responses near the decision boundary. However, the comment does not specify which part of the paper this observation is based on, making it difficult for the authors to pinpoint the exact section being discussed. While the authors can infer that it relates to the discussion of model performance, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing the observation about the performance trend, but the lack of grounding makes it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the advantage of RLCD over RLAIF shrinks as the model size increases from 7B to 30B, as shown in Table 2. It questions whether RLCD or RLCD-Rescore can scale effectively to larger models. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some basis for questioning the scalability of RLCD but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment highlights a specific observation about the performance of RLCD compared to RLAIF as the model size increases, as shown in Table 2. It questions whether RLCD or RLCD-Rescore can scale effectively to larger models, which are arguably better at differentiating responses near the decision boundary. This feedback provides a clear insight into a potential limitation of the current approach and suggests that the authors should consider the scalability of their model. However, the comment lacks detailed guidance on how the authors might address this issue or what specific actions they should take to improve their draft. While it identifies an important area for consideration, it does not provide actionable steps or suggestions for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of quantitative analysis regarding computational gains, specifically mentioning the absence of measurements like GPU hours, memory usage, or training time. It suggests that such analysis would provide stronger evidence of efficiency improvements. The comment is explicit in identifying the missing information and provides concrete details on what kind of data would substantiate the claim. This allows the authors to directly address the issue by including the suggested quantitative analysis in their revised draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"computational gains\" and \"DQ V2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of quantitative analysis on computational gains, such as GPU hours, memory usage, or training time, which would substantiate the claim of efficiency improvements. This provides the authors with a clear understanding of what needs to be addressed to strengthen the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks quantitative analysis on computational gains, specifically mentioning the absence of measurements like GPU hours, memory usage, or training time. The comment suggests that such analysis would provide stronger evidence of efficiency improvements. However, the comment does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the need for such analysis to improve their draft, which aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of quantitative analysis on computational gains. It highlights that while the paper claims efficiency improvements through the use of a CNN-based data augmentation strategy, it does not provide specific measurements or comparisons to substantiate these claims. The comment suggests that including quantitative data, such as GPU hours, memory usage, or training time, would strengthen the evidence of efficiency improvements. This feedback is clear, actionable, and provides a concrete direction for the authors to improve their draft by adding detailed quantitative analysis. Therefore, the comment is highly helpful, as it offers a clear and actionable suggestion to enhance the paper\\'s claims.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the time taken for COLMAP and scene-by-scene fine-tuning should be considered when comparing, which implies that the method might be less efficient for these scenes. However, the comment does not provide explicit guidance on how to incorporate this information into the comparison or how to address the efficiency issue. The action is implicit and vague, as it does not specify what needs to be done to make the comparison more accurate or how to demonstrate the efficiency of the method. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"COLMAP\" and \"scene-by-scene fine-tuning,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, noting that the time taken for these processes should be considered, making the method less efficient for these scenes. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the time taken for COLMAP and scene-by-scene fine-tuning should be considered when comparing, rendering the method less efficient for these scenes. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of COLMAP and scene-by-scene fine-tuning, suggesting that the time taken for these processes should be considered to accurately assess the method's efficiency. However, the comment lacks specific guidance or suggestions on how to address this issue or what data should be included in the comparison. While it points out a relevant concern, it does not provide actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is barely helpful, as it identifies a problem but does not offer substantial guidance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed model benefits from two factors: noise and keeping an exponential moving average. It recommends seeing how much each factor contributes individually and how much gain can be obtained by using a noise-free exponential moving average. While the comment provides a clear direction for the authors to explore, it does not explicitly instruct them on how to conduct this analysis or present the results. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed model and its two factors, noise and exponential moving average. It also specifies the need to see how much each factor contributes individually and how much gain can be obtained by using a noise-free exponential moving average. This provides clear guidance on what aspects of the model need further exploration or analysis. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the proposed model benefits from two factors: noise and keeping an exponential moving average. It recommends seeing how much each factor contributes individually and how much gain can be obtained by using a noise-free exponential moving average. However, the comment does not provide any specific reasoning, examples, or references to support why this analysis is important or how it would enhance the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper by suggesting that the authors explore the individual contributions of noise and exponential moving average in their proposed model. It provides a clear direction for the authors to consider, specifically asking how much gain can be obtained by using a noise-free exponential moving average. This feedback is actionable and constructive, as it guides the authors to conduct further analysis and potentially enhance their model. However, the comment could be more helpful if it provided additional context or examples to support the suggestion. Overall, the comment is mostly helpful, as it offers a clear and actionable direction for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the reporting of results, suggesting that the paper only shows results after a significant amount of training. It also speculates about the potential impact of early training on the CNN's performance. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve their draft. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the reporting of results, specifically noting that the results are only reported after a significant amount of training. It also speculates about the potential impact of early training on the CNN's performance. However, the comment does not specify which part of the paper discusses the results or the training process, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issues raised, it lacks grounding as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the reporting of results, specifically noting that the results are only reported after a significant amount of training. It also speculates about the potential impact of early training on the CNN's performance, suggesting that the model parameters might be \"essentially garbage\" and that the planning component might \"hurt\" more than it helps. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The authors are left to interpret the speculation, which makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a pertinent concern about the reporting of results, noting that the paper only shows results after a significant amount of training. This is particularly relevant in the context of reinforcement learning, where understanding the agent's behavior during the learning process is crucial. The comment also speculates on the potential impact of early training on the CNN's performance, suggesting that the model parameters might be 'essentially garbage' and that the planning component might 'hurt' more than it helps. While the comment identifies an important area for improvement, it lacks specific guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it highlights a gap in the reporting of results and encourages the authors to consider the behavior of the model during the learning process. However, it could be more helpful with additional suggestions or examples to guide the authors in improving their draft.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific questions about the handling of documents in DocRED and the treatment of multiple entity mentions. It suggests that the authors should consider these aspects and provide details on how they are addressed in the manuscript. While the comment implies that the authors should include this information, it does not explicitly instruct them to add it or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include details about these aspects in their manuscript. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"DocRED\" and \"multiple entity mentions,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with how the authors handle documents as an entire sentence and how they deal with multiple entity mentions, which are important aspects of the manuscript. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the handling of documents in DocRED and the treatment of multiple entity mentions, which are important aspects of the manuscript. However, it does not provide any specific reasoning, examples, or references to support why these issues are significant or how they should be addressed. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis for the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises specific questions about the handling of documents in DocRED and the treatment of multiple entity mentions, which are important aspects of the manuscript. It highlights a potential gap in the current draft, suggesting that the authors should consider these aspects and provide details on how they are addressed. However, the comment lacks actionable guidance or suggestions on how to improve the manuscript based on these observations. While it identifies areas for improvement, it does not provide detailed feedback or examples that would help the authors enhance their work. Therefore, the comment is somewhat helpful, as it points out specific areas that need attention but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the clarity of the main contribution, suggesting that the performance gain is primarily due to PBSD. It also asks for clarification on the motivation behind PBSD beyond its discriminative power on tail classes. While the comment implies that the authors should clarify the main contribution and provide additional motivation for PBSD, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the main contribution and provide more motivation for PBSD. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the clarity of the main contribution and asks for clarification on the motivation behind PBSD beyond its discriminative power on tail classes. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is specific in its request for clarification but lacks grounding as it does not mention specific sections, tables, or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the clarity of the main contribution and asks for clarification on the motivation behind PBSD beyond its discriminative power on tail classes. While the comment provides a logical reasoning by questioning the motivation, it lacks specific examples or references to support the claim that the performance gain is mostly from PBSD. The authors are left to infer the basis of the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the clarity of the main contribution, questioning whether it is well-defined. It points out that the performance gain appears to be primarily due to PBSD, as suggested by the ablation study. The comment also prompts the authors to clarify the motivation behind PBSD beyond its discriminative power on tail classes. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper's clarity and motivation. However, it could be more helpful if it provided specific suggestions or examples to address the lack of clarity. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implications of providing a tester for the spread parameter, specifically whether it also yields an (\u03f5, \u03b4)-identity tester. It also asks for clarification on how the tester handles pairs (\u03c0, \u03d5) where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. While the comment implies that the authors should clarify these aspects, it does not provide explicit instructions or concrete guidance on how to address these questions or improve the draft. The action is implicit and somewhat vague, as the authors need to infer what needs to be done. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment refers to \"2 gives a tester for the spread parameter,\" but it does not specify which part of the paper this refers to, making it weakly grounded. It also asks for clarification on whether the tester immediately yields an (\u03f5, \u03b4)-identity tester and how it handles specific pairs, which provides some specificity. However, the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section being addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the implications of providing a tester for the spread parameter, specifically whether it also yields an (\u03f5, \u03b4)-identity tester. It also asks for clarification on how the tester handles pairs (\u03c0, \u03d5) where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. While the comment highlights a potential gap in the explanation, it does not provide any evidence or reasoning to support the claim that the reviewer is questioning the implications of the provided tester. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the implications of providing a tester for the spread parameter, specifically whether it also yields an (\u03f5, \u03b4)-identity tester. It also asks for clarification on how the tester handles pairs (\u03c0, \u03d5) where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. While the comment identifies a potential area for clarification and deeper understanding, it does not provide specific guidance or suggestions on how the authors might address these questions or improve their draft. The feedback is somewhat helpful as it points out a specific area that needs further explanation, but it lacks actionable advice or detailed insights to guide the authors in enhancing their work. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the detailed distribution of the proposed dataset is unclear, but it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit instructions or concrete advice on what needs to be done to clarify the dataset distribution. As a result, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper discusses the detailed distribution of the proposed dataset. The authors cannot confidently determine which section or aspect of the paper is being addressed. Additionally, the comment is specific in that it points out a lack of clarity in the dataset distribution, but without grounding, the authors are left to guess which part needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the detailed distribution of the proposed dataset is unclear. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors are left without a basis to understand why the dataset distribution is unclear or how to address this issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the detailed distribution of the proposed dataset is unclear. However, it does not provide any suggestions or guidance on how the authors might address this lack of clarity. Without actionable feedback or suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it highlights a problem but does not offer any constructive advice or direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed method requires annotated labels for learning semantic tokens, which limits its application to supervised training. It proposes that a self-supervised pretraining approach without annotations could be more appealing. While the comment identifies a potential limitation and suggests an alternative approach, it does not provide explicit guidance on how the authors should address this issue or incorporate a self-supervised pretraining method. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the proposed method's reliance on annotated labels for learning semantic tokens, which limits its application to supervised training. It suggests that a self-supervised pretraining approach without annotations could be more appealing. However, the comment does not specify which part of the paper discusses the proposed method or the limitations of supervised training. The authors may need to infer the relevant sections, making the comment weakly grounded. The comment is specific in detailing the issue with annotated labels and suggesting an alternative approach, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method necessitates annotated labels for learning semantic tokens, limiting its application to supervised training. It suggests that a self-supervised pretraining approach without annotations could be more appealing. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim is considered borderline verifiable, as it provides a general observation but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation of the proposed method, specifically that it requires annotated labels for learning semantic tokens, which restricts its applicability to supervised training. It suggests that a self-supervised pretraining approach without annotations could be more appealing. This feedback is somewhat helpful as it highlights a potential weakness and offers an alternative approach that could broaden the method's applicability. However, the comment could be more helpful if it provided specific guidance on how to implement or adapt the method for self-supervised learning. Overall, the comment offers valuable insights but lacks detailed actionable suggestions, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should demonstrate the scalability of LFF by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This provides a clear and explicit action for the authors to take, as they need to expand their experiments to include these more complex tasks. The comment is specific in its suggestion and offers a concrete direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to demonstrate the scalability of LFF on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This provides clear guidance on which part of the paper the authors should focus on. The comment is also specific, as it specifies the type of tasks that would help demonstrate the scalability of LFF. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that most continuous control experiments are performed on simple and low-dimensional tasks, such as cartpole or mountain car, and suggests that demonstrating LFF's effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids, is important for fully demonstrating its scalability. This claim is somewhat verifiable as it provides a logical reasoning for why the suggestion is important, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out that most continuous control experiments are performed on simple and low-dimensional tasks, such as cartpole or mountain car. It suggests that to fully demonstrate the scalability of LFF, the authors should show its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is clear and actionable, providing a specific direction for the authors to enhance their experiments and better showcase the capabilities of LFF. By addressing this suggestion, the authors can significantly improve the comprehensiveness and impact of their work, making the comment highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests specific changes to the abstract, recommending a more detailed description of expressivity and the inclusion of learning curves for all experiments, potentially in an appendix. While the comment provides explicit guidance on what should be included, it does not specify how the authors should implement these changes or what steps they should take to incorporate the suggested elements. The action is somewhat vague, as it lacks concrete instructions on how to add the learning curves or where to place them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, providing a clear reference point for the authors to understand where the feedback is being applied. It also specifies what the authors should include in the abstract, such as a more detailed description of expressivity and the inclusion of learning curves for all experiments. This level of detail allows the authors to accurately identify the part of the paper that needs revision. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the abstract should include a more detailed description of expressivity, specifically mentioning the change in linear regions in output space after a citation. It also recommends including learning curves for all experiments, potentially in an appendix. While the suggestion is logical and provides a specific example, it lacks detailed reasoning or references to support why these additions would be beneficial. The comment is somewhat verifiable as it offers a clear direction for improvement but could be more robust with additional justification or examples. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the abstract by adding more detail about expressivity and including learning curves for all experiments. While it does not specify where to place the learning curves or how to present the additional information, it offers clear guidance on what the authors should include to enhance the paper. This feedback is actionable and constructive, as it directs the authors towards specific improvements that could strengthen the paper. However, the comment could be more helpful if it provided additional details or examples to guide the authors in implementing these suggestions. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the paper for considering only one deep learning-based baseline, MULT, which was proposed in 2019 and is no longer considered state-of-the-art. However, the comment does not provide any explicit or implicit suggestions for what the authors should do to address this issue, such as including more recent baselines or justifying the choice of baselines. Without specific guidance on how to improve the draft, the action is vague and lacks detail, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a list of references related to multimodal sentiment analysis and emotion recognition, but it does not specify which part of the paper these references are relevant to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not specify what needs to be addressed in relation to these references, such as how they might improve the paper or what aspects of the paper are missing. Therefore, the comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper regards MULT as the only deep learning-based baseline that considers cross-sensory interaction but notes that MULT was proposed in 2019 and is no longer considered state-of-the-art. This claim is somewhat verifiable as it provides a specific example of a baseline and its publication year, allowing the authors to understand the context and potentially address the issue by including more recent baselines or justifying the choice of baselines. However, it lacks detailed reasoning or references to support the claim fully, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper by pointing out that the baseline used, MULT, was proposed in 2019 and is no longer considered state-of-the-art. This observation is important as it suggests that the paper might be missing comparisons with more recent or relevant baselines. However, the comment does not provide specific suggestions or guidance on how the authors could address this issue, such as including more recent baselines or justifying the choice of baselines. Without actionable feedback or detailed suggestions, the comment is somewhat helpful, as it highlights a potential area for improvement but lacks depth and guidance for the authors to fully address the issue.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should compare the tensor completion results for all models, including TW, TT, and TR, but with the same number of model parameters. It also mentions that the number of model parameters can be computed by adding the number of entries of all core tensors for each model. This provides a clear and concrete action for the authors to take, as they know exactly what needs to be done to ensure a fair comparison. The comment is fully actionable because it specifies the exact steps required to address the issue of unclear comparisons and unfair evaluation of the models.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for a comparison against other models in the experiments, which allows the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the omission of the value of used ranks for all models, making the comment specific. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison against other models in the experiments is unclear and that the omission of the value of used ranks for all models makes it impossible to perform a fair comparison. The comment suggests that to demonstrate the superiority of TW over TT and TR, the authors should compare the tensor completion results for all models but with the same number of model parameters. While the comment provides a logical reasoning for the need for a fair comparison, it lacks specific examples or references to support the claim. However, it does offer a clear direction for the authors to take, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a significant issue with the experimental comparison, specifically the lack of clarity and the omission of model rank values. It provides a clear and actionable suggestion to address this by comparing tensor completion results across all models while ensuring they have the same number of model parameters. This guidance is detailed and constructive, enabling the authors to improve the fairness and comprehensiveness of their experiments. The comment is comprehensive and provides a clear path for the authors to enhance their work, making it highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential inconsistency in the normalization module between two versions of the paper, suggesting that the text might be misleading. It also points out the need for standardization in the pictograms used in the figures, specifically mentioning Figure 4, which is confusing due to overlapping symbols in the 0/5.0 to 2.5/4.0 MAE range. Additionally, the reviewer notes minor issues with the text, such as a specific point on page 4 after equation 2. However, the comment does not provide explicit guidance on how to address these issues or what specific actions the authors should take to resolve them. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the normalization module, suggesting that it appears different in two versions despite the text implying consistency. It also recommends standardizing pictograms in figures, specifically mentioning Figure 4, which is confusing due to overlapping symbols in the 0/5.0 to 2.5/4.0 MAE range. Additionally, the comment points out minor issues with the text, such as a specific point on page 4 after equation 2. However, the comment does not explicitly mention which part of the paper these issues are related to, making it weakly grounded. The comment is specific in detailing the issues with the normalization module and the need for standardization in the pictograms, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact areas that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the consistency of the normalization module between two versions of the paper, suggesting that the text might be misleading. It also recommends standardizing the pictograms in the figures, particularly noting the confusion in Figure 4 due to overlapping symbols in the 0/5.0 to 2.5/4.0 MAE range. Additionally, the comment points out minor issues with the text, such as a specific point on page 4 after equation 2. However, the comment lacks detailed reasoning or specific examples to fully substantiate these claims, making it somewhat verifiable. The authors would need to infer the basis for the concerns, which limits the clarity and support provided. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential inconsistency in the normalization module between two versions of the paper, which could lead to confusion for readers. It also suggests the need for standardization in the pictograms used in the figures, particularly noting the confusion in Figure 4 due to overlapping symbols in the 0/5.0 to 2.5/4.0 MAE range. Additionally, the comment points out minor issues with the text, such as a specific point on page 4 after equation 2. However, the feedback lacks detailed guidance or specific suggestions on how to address these issues, making it somewhat helpful. The authors would need to infer the implications and take steps to resolve the inconsistencies and improve the clarity of the figures and text. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors' claim about the utility of subdivision splines and the computational cost of the proposed algorithm. It highlights a gap in the theoretical part of the paper, as the authors did not provide details on how the algorithm removes subdivision splines. The comment implies that the authors should clarify the algorithm's details and address the computational cost. However, it does not explicitly instruct the authors to provide these details or address the cost, making the action implicit and somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the authors' claim about the utility of subdivision splines and the computational cost of the proposed algorithm. It does not specify which part of the paper this claim is based on, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its critique of the claim but lacks grounding as it does not mention the specific section or part of the paper where the claim is made. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' claim about the utility of subdivision splines and the computational cost of the proposed algorithm. It highlights a gap in the theoretical part of the paper, as the authors did not provide details on how the algorithm removes subdivision splines. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the critique. The reasoning is vague and does not provide sufficient evidence to verify the claim. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific claim made by the authors regarding the utility of subdivision splines and the computational cost of their proposed algorithm. It questions the lack of detail in the theoretical part of the paper regarding how the algorithm removes subdivision splines. This feedback is somewhat helpful as it points out a gap in the paper's explanation and encourages the authors to provide more details on the algorithm's mechanics and computational cost. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address these issues. Overall, the comment provides a clear direction for improvement, but it lacks depth and specificity, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies that the terms W and V are not defined in the paper, specifically in equations 3 and 4. While it suggests that these terms likely denote the Encoder and Decoder networks, the comment does not provide explicit guidance on how the authors should define these terms or where they should be defined. The action is implicit, as the authors need to infer that they should define W and V, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable, as it provides a clear indication of what needs to be addressed but does not offer specific guidance on how to implement the action.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper (p.3, A4, eq.3 and eq.4) where the terms W and V are not defined. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies that the terms W and V are not defined in these sections, and it suggests that these terms likely denote the Encoder and Decoder networks. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the terms W and V are not defined in the paper, specifically in equations 3 and 4. While the comment identifies a potential issue with the clarity of the paper, it does not provide any specific examples or references to support this claim. The lack of detailed explanation or evidence makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the terms W and V are not defined, particularly in equations 3 and 4. This feedback is clear and actionable, as it points out a lack of clarity in the paper's presentation. However, the comment could be more helpful if it provided guidance on how the authors might define these terms or where they should be defined for clarity. While it identifies a significant area for improvement, the lack of detailed suggestions limits its impact. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fixed nature of negative chips after being generated from the lightweight RPN and whether they will be updated during the training process. It also asks if alternating between generating negative chips and training the network could potentially improve performance. While the comment poses a question that could guide the authors to consider certain aspects of their methodology, it does not provide explicit instructions or suggestions on how to address this question or what changes might be necessary. The action is implicit and somewhat vague, as the authors are left to infer the need for further investigation or experimentation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the fixed nature of negative chips after being generated from the lightweight RPN and whether they will be updated during the training process. It also asks if alternating between generating negative chips and training the network could potentially improve performance. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or methodology description. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification or further discussion. While the comment is specific in its inquiry about the methodology, the absence of explicit references to the paper makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the fixed nature of negative chips after being generated from the lightweight RPN and whether they will be updated during the training process. It also asks if alternating between generating negative chips and training the network could potentially improve performance. However, the comment does not provide any evidence, reasoning, or references to support the claim that this is a critical issue or a necessary consideration for the authors to address. Without specific justification or examples, the claim remains unverifiable, as the authors are left to determine the relevance and importance of the question themselves. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the fixed nature of negative chips after being generated from the lightweight RPN and whether they will be updated during the training process. It also inquires whether alternating between generating negative chips and training the network could potentially improve performance. While the comment identifies a potential area for further exploration or clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or what experiments could be conducted to investigate it. The feedback is somewhat helpful as it prompts the authors to consider an important aspect of their methodology, but it lacks depth and actionable advice, making it only marginally helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the applicability of the proposed approach to new and old patients, suggesting that the authors should evaluate the approach on both groups. However, it does not provide explicit guidance on how to conduct this evaluation or what specific aspects of the approach should be considered. The action is implicit, as the authors need to infer that they should perform this evaluation, but it lacks concrete details on how to implement it. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the proposed approach to new and old patients, suggesting that the authors should evaluate the approach on both groups. However, it does not specify which part of the paper this question pertains to, such as a specific section or methodology. This lack of grounding makes it difficult for the authors to identify the exact area where the comment is relevant. While the comment is specific in its suggestion to evaluate the approach on new and old patients, the absence of explicit grounding makes it challenging for the authors to understand which part of the paper needs attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the applicability of the proposed approach to new and old patients, suggesting that the authors should evaluate the approach on both groups. However, it does not provide any specific reasoning, examples, or references to support why this evaluation is necessary or how it would impact the results. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the proposed approach to new and old patients, suggesting that the authors should evaluate the approach on both groups. This feedback highlights a potential area for improvement in the paper, specifically regarding the generalizability of the proposed method. However, the comment lacks specific guidance on how to conduct this evaluation or what aspects of the approach should be considered. While it identifies a relevant area for improvement, the lack of detailed suggestions or examples limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear direction for the authors to consider but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks in-depth analysis, specifically regarding the inverse scaling observed over compute. It suggests that the authors should provide an analysis explaining the training dynamics to make the paper more solid. While the comment implies that the authors should conduct a more detailed analysis, it does not explicitly instruct them to do so or provide specific guidance on how to analyze the training dynamics. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct a more thorough analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks in-depth analysis, specifically regarding the inverse scaling observed over compute. It implies that the authors should provide an analysis explaining the training dynamics to make the paper more solid. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. It is specific in suggesting that the authors should provide an analysis explaining the training dynamics, but without a clear reference to a specific section or figure, the authors may find it challenging to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks in-depth analysis, specifically regarding the inverse scaling observed over compute, and suggests that the authors should provide an analysis explaining the training dynamics to make the paper more solid. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper: the lack of in-depth analysis regarding the inverse scaling observed over compute. It suggests that the authors should provide an analysis explaining the training dynamics to strengthen the paper. This feedback is clear and actionable, as it directs the authors to a specific area where they can improve their work. However, the comment could be more helpful if it provided some guidance on how to conduct this analysis or suggested specific areas of investigation. Despite this, the comment is mostly helpful as it highlights a critical aspect of the paper that needs attention, providing the authors with a clear direction for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the lack of mathematical definition for architectural details, specifically mentioning multi-head attention. It also questions the clarity of a split arrow in Figure 2, asking for clarification on whether the same vectors are used for keys and values or if different sections are used. While the comment explicitly suggests that a formal definition would help readers understand the architecture, it does not provide specific guidance on how to implement this definition. The action is clear and explicit, but it lacks concrete details on how to define the mathematical aspects or how to clarify the split arrow in the figure. Therefore, the comment is mostly actionable, as it provides a clear direction but requires further elaboration to be fully actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2 right, bottom right,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the lack of mathematical definition for architectural details, such as multi-head attention, and questions the clarity of a split arrow in the figure. The comment provides clear guidance on what needs to be addressed, including the need for a formal definition of the architectural details. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises specific questions about the lack of mathematical definition for architectural details, such as multi-head attention, and the clarity of a split arrow in Figure 2. It suggests that a formal definition would help readers understand the architecture. However, the comment does not provide any evidence or reasoning to support why these issues are significant or how they impact the paper. Without specific examples or references, the claim is difficult to verify, making it borderline verifiable. The comment is somewhat verifiable as it identifies areas for improvement but lacks detailed justification or examples to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper could be improved, particularly in the lack of mathematical definitions for architectural details like multi-head attention. It also raises questions about the clarity of a split arrow in Figure 2, specifically asking whether the same vectors are used for keys and values or different sections. This feedback is actionable as it provides clear suggestions for enhancing the clarity and completeness of the paper. However, the comment could be more helpful if it offered additional guidance on how to provide these definitions or clarify the figure. Overall, the comment is mostly helpful, as it directs the authors to specific areas for improvement but could be more comprehensive with detailed suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the assumption that each individual's data is independently and identically distributed (iid) from the same distribution. It questions the validity of this assumption, particularly in the context of the \\sqrt{m} argument in the beginning of Section 5.1 and the application of Theorem 6 to prove Theorem 7. The reviewer finds this assumption unjustifiable, as it does not align with practical scenarios where users may have different preferences. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit, as the authors need to infer that they should consider the implications of this assumption and potentially revise their approach. The lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the assumption that each individual's data is independently and identically distributed (iid) from the same distribution. It questions the validity of this assumption, particularly in the context of the \\sqrt{m} argument in the beginning of Section 5.1 and the application of Theorem 6 to prove Theorem 7. The reviewer finds this assumption unjustifiable, as it does not align with practical scenarios where users may have different preferences. However, the comment does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or figure being addressed. The comment is specific in its critique of the assumption but lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the assumption that each individual's data is independently and identically distributed (iid) from the same distribution. It questions the validity of this assumption, particularly in the context of the \\(\\sqrt{m}\\) argument in the beginning of Section 5.1 and the application of Theorem 6 to prove Theorem 7. The reviewer finds this assumption unjustifiable, as it does not align with practical scenarios where users may have different preferences. However, the comment lacks specific examples or references to support the claim that this assumption is problematic or unjustifiable. While the reasoning is logical, the absence of detailed evidence or examples makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical concern about the assumption that each individual's data is independently and identically distributed (iid) from the same distribution. It questions the validity of this assumption, particularly in the context of the \\(\\sqrt{m}\\) argument in the beginning of Section 5.1 and the application of Theorem 6 to prove Theorem 7. The reviewer finds this assumption unjustifiable, as it does not align with practical scenarios where users may have different preferences. This feedback highlights a significant gap in the paper's assumptions and suggests that the authors need to reconsider the applicability of their theoretical results. However, the comment could be more helpful if it provided specific guidance on how the authors might address this issue or what alternative assumptions could be considered. Overall, the comment is somewhat helpful as it identifies a critical flaw in the paper's assumptions, but it lacks detailed suggestions for improvement, making it only partially beneficial.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider making the policy non-fixed to increase the complexity of the tasks and compare their approach with a reinforcement learning algorithm baseline. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement this change or what specific aspects of the policy to modify. The suggestion is somewhat vague, as it lacks concrete details on how to make the policy non-fixed or how to compare with a reinforcement learning baseline. Therefore, the comment is somewhat actionable, as it provides a general idea but lacks specific guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider making the policy non-fixed to increase the complexity of the tasks and compare their approach with a reinforcement learning algorithm baseline. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or table. This lack of grounding makes it difficult for the authors to identify the exact area where the comment applies. While the comment is specific in its suggestion, the absence of explicit grounding makes it challenging for the authors to understand which part of the paper needs attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that with a fixed policy, the setting is a subset of reinforcement learning and proposes that tasks could be made more complex to allow for a non-fixed policy. It also recommends comparing the approach with a reinforcement learning algorithm baseline. However, the comment lacks specific examples or references to support the claim that making the policy non-fixed would increase complexity or how the comparison with a reinforcement learning baseline would be implemented. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as borderline verifiable, as it provides some direction but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the authors consider making the policy non-fixed to increase the complexity of the tasks. It also recommends comparing their approach with a reinforcement learning algorithm baseline, which could provide valuable insights. However, the comment lacks specific guidance on how to implement these suggestions or what aspects of the policy should be modified to achieve non-fixed behavior. While it offers a direction for improvement, the feedback could be more helpful if it provided more detailed suggestions or examples. Therefore, the comment is somewhat helpful, as it provides a general idea but lacks depth and actionable guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper's focus on explaining multi-task models limits its applicability. However, it does not provide any specific guidance or suggestions on how the authors might address this limitation or enhance the applicability of their work. The comment lacks explicit actions or concrete steps that the authors could take to improve their draft. As a result, the authors are left without a clear understanding of what changes are needed to make the paper more applicable. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper mainly focuses on explaining multi-task models, which limits its applicability. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue of limited applicability but lacks grounding as it does not provide guidance on how to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper mainly focuses on explaining multi-task models, which limits its applicability. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper's focus on explaining multi-task models, suggesting that this limits the applicability of the work. However, the comment lacks specific details or suggestions on how the authors might address this issue or enhance the applicability of their research. Without actionable guidance or examples, the authors may find it challenging to understand the implications of this feedback or how to improve their draft. Therefore, the comment is barely helpful, as it provides a general observation but lacks depth and specificity to be fully beneficial.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the literature review should include several papers that seem relevant, specifically mentioning [1] and [2]. It also notes that VR-MARINA and DASHA-MVR satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not provide explicit guidance on how to incorporate these papers into the literature review or how to address the comparison with QSGD. The action is implicit and vague, as the authors are left to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the literature review should include several papers that seem relevant, specifically mentioning [1] and [2]. It also notes that VR-MARINA and DASHA-MVR satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not specify which section of the paper the literature review is located, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the inclusion of relevant papers and the comparison with QSGD. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the literature review ignores several relevant papers, specifically mentioning [1] and [2]. It suggests that VR-MARINA and DASHA-MVR satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issue. The absence of references or detailed explanations weakens the verifiability of the claim. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the literature review, noting that it may be overlooking several relevant papers. It provides specific examples, such as [1] and [2], which seem to satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment lacks detailed guidance on how to incorporate these papers into the literature review or how to address the comparison with QSGD. While it points out a potential gap in the literature review, it does not offer actionable steps or suggestions for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the performance of the algorithm on the Clothing1M dataset and suggests exploring its performance on other real-world datasets like WebVision, evaluated by DivideMix. However, it does not provide explicit instructions or guidance on how the authors should address these questions or what specific actions they should take to improve their draft. The feedback is somewhat vague and lacks concrete details, leaving the authors uncertain about how to respond or incorporate the suggestions. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the performance of the algorithm on the Clothing1M dataset and suggests exploring its performance on other real-world datasets like WebVision, evaluated by DivideMix. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its request for additional insights and performance evaluations but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the performance of the algorithm on the Clothing1M dataset and suggests exploring its performance on other real-world datasets like WebVision, evaluated by DivideMix. However, it does not provide any specific evidence, reasoning, or references to support these claims or questions. The comment lacks detailed justification or context, making it difficult for the authors to understand the basis of the inquiry or how it relates to the paper. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises questions about the performance of the algorithm on the Clothing1M dataset and suggests exploring its performance on other real-world datasets like WebVision, evaluated by DivideMix. This feedback is somewhat helpful as it identifies an area where the authors could provide additional insights or evidence to strengthen their claims. However, the comment lacks specificity and does not offer detailed guidance on how the authors might address these questions or what additional experiments or analyses could be conducted. Without concrete suggestions or a clear direction, the feedback is limited in its ability to guide the authors effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct more experiments on different famous LLMs like LLaMA and Falcon to serve as benchmark baselines. While the comment implies that additional experiments are needed, it does not explicitly instruct the authors to perform these experiments or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should expand their experiments to include these models. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should conduct more experiments on different famous LLMs like LLaMA and Falcon to serve as benchmark baselines. However, it does not specify which part of the paper these experiments are intended to address, making it weakly grounded. The comment is specific in its suggestion to include more experiments, but without clear references to specific sections or figures, the authors may find it challenging to identify the exact areas where these experiments should be added. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should conduct more experiments on different famous LLMs like LLaMA and Falcon to serve as benchmark baselines. However, the comment lacks specific reasoning or examples to support why these additional experiments are necessary or how they would enhance the paper. Without detailed justification or references, the claim remains somewhat verifiable, as the authors may find it challenging to understand the basis for the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should conduct more experiments on different famous LLMs, such as LLaMA and Falcon, to serve as benchmark baselines. This feedback is somewhat helpful as it identifies a potential area for improvement in the experimental setup. However, the comment lacks specific guidance on how to implement these additional experiments or what specific aspects of the models should be explored. Without detailed suggestions or examples, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting that it does not describe the hyperparameters used by each defense or how those hyperparameters are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate the amount of clean data required to remove the attack. This feedback provides a clear and explicit action for the authors to take, as they need to include details about the hyperparameters used and their derivation. The suggestion to optimize hyperparameters against the attack and demonstrate the impact of clean data adds further clarity and direction to the action. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the lack of description regarding hyperparameters used by each defense and how they are derived, suggesting a maximally charitable evaluation of defenses. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not describe the hyperparameters used by each defense or how they are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and show how much clean data is required to remove the attack. However, the comment lacks specific examples or references to support the claim that the paper does not address these aspects. Without detailed evidence or examples, the authors may find it challenging to understand the exact nature of the omission. Therefore, the comment is considered borderline verifiable, as it provides a general idea but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of information regarding the hyperparameters used by each defense and how they are derived. It suggests that a more comprehensive evaluation would involve optimizing these hyperparameters against the attack and demonstrating the amount of clean data required to remove the attack. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by including detailed descriptions of the hyperparameters and their derivation. However, the comment could be more helpful if it included examples or suggested specific sections where this information should be added. Overall, the comment is mostly helpful as it offers a clear path for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of mean pooling for token aggregation, suggesting that other pooling strategies might be considered. However, it does not provide explicit guidance on which alternative strategies to explore or how to implement them. The action is implicit, as the authors need to infer that they should consider other pooling methods and potentially explore them. While the comment is somewhat actionable, it lacks concrete details on how to apply the suggested exploration. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific line in the paper (L235), allowing the authors to accurately identify the part being addressed. It is also specific because it questions the choice of mean pooling and suggests exploring alternative strategies, providing clear guidance on what needs to be considered. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the choice of mean pooling for token aggregation, suggesting that other pooling strategies might be considered. However, it does not provide any specific reasoning, examples, or references to support why mean pooling is chosen or why other strategies might be better. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of mean pooling for token aggregation, suggesting that other pooling strategies might be considered. This feedback is somewhat helpful as it prompts the authors to consider alternative approaches, which could potentially improve the robustness or effectiveness of their method. However, the comment lacks depth and does not provide specific guidance or suggestions on which alternative pooling strategies to explore or how to implement them. As a result, while it offers a direction for improvement, it does not fully empower the authors to enhance their draft. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare the real search cost in terms of GPU days in addition to the number of queries in Table 3. This provides a clear and explicit action for the authors to take, as they know exactly what additional information to include in their table. The comment is specific and concrete, giving the authors a precise direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a concrete improvement by comparing the real search cost in terms of GPU days, which provides clear guidance on what needs to be added to the table. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should compare the real search cost in terms of GPU days in addition to the number of queries in Table 3. This is a specific and actionable suggestion that provides a clear direction for improvement. However, the comment does not offer any reasoning or justification for why this comparison is important or how it would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is somewhat verifiable, as it provides a specific action but lacks detailed reasoning or references to support its importance.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending that the authors compare the real search cost in terms of GPU days in addition to the number of queries in Table 3. This feedback is actionable and directly addresses a potential area for enhancing the clarity and comprehensiveness of the paper. By offering a concrete suggestion, the comment empowers the authors to make a meaningful improvement to their draft, making it mostly helpful. However, it could be more helpful if it included additional context or reasoning for why this comparison is important. Overall, the comment is mostly helpful as it provides a clear direction for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the training details of the VQGAN, specifically whether it is pre-trained or trained solely on the 88,635 images from the Computer Vision Figures dataset. While the comment implies that the authors should provide these details, it does not explicitly instruct them to include them in the draft. The action is implicit, as the authors can infer that they need to add this information, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific instructions on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the training details of the VQGAN, specifically whether it is pre-trained or trained solely on the 88,635 images from the Computer Vision Figures dataset. However, it does not specify which part of the paper this information is relevant to, making it weakly grounded. The comment is specific in that it identifies a missing detail that needs clarification, but without explicit references to sections or figures, the authors may struggle to locate the relevant part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the training details of the VQGAN, specifically whether it is pre-trained or trained solely on the 88,635 images from the Computer Vision Figures dataset. This is a factual question that requires the authors to provide specific details about their methodology. However, the comment does not offer any additional context, reasoning, or references to support the need for this information. As a result, the claim is somewhat verifiable, as it lacks sufficient justification or evidence to fully substantiate the need for clarification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the training details of the VQGAN, asking whether it is pre-trained or trained solely on the 88,635 images from the Computer Vision Figures dataset. This is a pertinent concern that could help the authors clarify their methodology and ensure the reproducibility of their results. However, the comment does not provide any suggestions or guidance on how to address this issue, nor does it offer any additional context or reasoning to support the need for this clarification. While the feedback is somewhat helpful in identifying a potential area of concern, it lacks depth and actionable advice, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the proposed methods, DualIS and DualDIS, noting that they are not generic on some cross-model retrieval tasks, particularly in the MSVD task, where performance shows minor improvements. However, the comment does not provide any explicit or implicit suggestions on how to address this issue or improve the methods. The authors are left without guidance on what steps to take to enhance the generality of the methods or to address the observed performance limitations. Therefore, the comment is unactionable as it lacks any actionable feedback or suggestions for improvement.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed methods, DualIS and DualDIS, and refers to specific results in Table 3, particularly the performance on the MSVD task. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the methods, noting that they are not generic on some cross-model retrieval tasks and that the performance in MSVD shows minor improvements. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed methods, DualIS and DualDIS, are not generic on some cross-model retrieval tasks, specifically noting that the performance in MSVD (Table 3) shows minor improvements. However, the comment lacks specific evidence or references to support this claim. Without additional context or data, the authors may find it challenging to fully understand or address the issue raised. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed methods, DualIS and DualDIS, noting that they are not generic on some cross-model retrieval tasks, particularly in the MSVD task, where performance shows minor improvements. While the comment highlights a limitation in the methods' applicability, it does not provide any suggestions or guidance on how to address this issue or improve the methods. The feedback is somewhat helpful as it points out a specific area for improvement, but it lacks actionable advice or detailed suggestions, leaving the authors with limited direction for enhancing their work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with the study, noting that the relationship between the top selected patches and the disease is not yet established. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what steps they should take to establish this relationship. The comment lacks concrete guidance on how to improve the study or what specific actions the authors should consider. As a result, the authors are left without a clear understanding of how to proceed, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is referring to, such as a particular section or figure. It is also not specific because it does not detail what aspects of the study are incomplete or how the relationship between the top selected patches and the disease should be established. Without specific references or details, the authors cannot confidently understand the scope of the feedback. Therefore, this comment is rated as Not Grounded and Not Specific, corresponding to a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the study is incomplete because the relationship between the top selected patches and the disease is not yet established. However, the comment lacks specific details or references to support this claim. It does not provide any examples or evidence to substantiate the assertion that the relationship is not yet established. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the study, noting that the relationship between the top selected patches and the disease is not yet established. This is a critical point that needs to be addressed for the study to be considered complete and robust. However, the comment lacks specific guidance or suggestions on how the authors might establish this relationship or what additional data or analysis could be included to address this gap. While it highlights an important area for improvement, the feedback is somewhat helpful as it points out a crucial weakness that needs attention. The authors would benefit from additional guidance on how to address this issue, making the comment mostly helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue regarding the performance of FedSP in Table 1 and Table 2 on some datasets, suggesting that the theme is mainly about FedSP. However, it does not provide explicit guidance on what needs to be improved or how the authors should address this issue. The comment implies that the authors should consider revising their draft to better reflect the performance of FedSP, but it lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it identifies a potential area for improvement but does not provide detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1 and Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the performance of FedSP on some datasets, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of FedSP is not the best in Table 1 and Table 2 on some datasets. However, it does not provide any specific evidence, examples, or references to support this claim. Without additional context or data, the authors may find it challenging to understand or address the issue raised in the comment. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue regarding the performance of FedSP in Table 1 and Table 2 on some datasets, suggesting that the theme of the paper is primarily focused on FedSP. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve their draft. It does not provide specific advice on revising the paper or enhancing the discussion of FedSP's performance. As a result, the comment is somewhat helpful, as it highlights a potential area for improvement but does not offer detailed guidance or constructive feedback to help the authors enhance their work.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggestions regarding the clarity and specificity of certain aspects of the paper. It asks the authors to clarify the meaning of \"Omega\" in line 178, to be more explicit about the OMD family of algorithms, and to specify the link function and theorem in reference to the regret guarantee. While the comment provides explicit questions and suggestions, it lacks concrete guidance on how the authors should address these points. The authors are left to infer the necessary actions, which makes the comment somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line 178, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as clarifying the meaning of \"Omega,\" being more explicit about the OMD family of algorithms, and specifying the link function and theorem. This provides clear guidance on what aspects of the paper require attention. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the clarity and specificity of certain aspects of the paper, such as the meaning of \"Omega\" in line 178, the OMD family of algorithms, the link function, and the specific theorem referenced. While the questions are logical and seek clarification, they do not provide specific examples or references to support the claims. The comment lacks detailed reasoning or evidence to fully substantiate the concerns, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper could be clearer and more explicit. It questions the meaning of \"Omega\" in line 178, suggests that the OMD family of algorithms should be more explicitly discussed, and requests clarification on the link function and theorem referenced for the regret guarantee. These questions and suggestions provide actionable feedback that could help the authors improve the clarity and precision of their paper. However, the comment could be more helpful if it offered additional guidance or examples on how to address these issues. Overall, the feedback is somewhat helpful, as it provides a clear direction for improvement but lacks depth in terms of specific suggestions or detailed explanations. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific aspect of the models being learned directly from pixels without a Markovian state. While it points out a potential issue with the approach, it does not provide explicit guidance on how the authors should address this concern or what changes might be necessary. The comment lacks concrete suggestions or actionable steps for the authors to take, leaving them uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the models are learned directly from pixels without a Markovian state,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular aspect of the models that may need clarification or further discussion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the models are learned directly from pixels without a Markovian state. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific aspect of the models being learned directly from pixels without a Markovian state. While it points out a potential issue, it lacks actionable guidance or suggestions on how the authors might address this concern. The comment does not provide any insights into potential improvements or alternative approaches, leaving the authors with limited direction for enhancing their work. Therefore, the comment is barely helpful, as it identifies a problem but does not offer substantial assistance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment questions the use of the Hamming distance over entire parts of the sequence as a common practice in the context of CRF, noting that the authors have not seen this approach before and are only aware of works reporting node-wise Hamming loss. The comment suggests that the authors should point out some references to clarify this aspect. While the comment implies that the authors should provide references, it does not explicitly instruct them to do so or provide specific guidance on how to find or include these references. The action is implicit and somewhat vague, as the authors need to infer that they should add references to support their claim. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Example 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the Hamming distance over entire parts of the sequence, questioning its common practice and contrasting it with node-wise Hamming loss. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of the Hamming distance over entire parts of the sequence as a common practice in the context of CRF, noting that the authors have not seen this approach before and are only aware of works reporting node-wise Hamming loss. The comment suggests that the authors should point out some references to clarify this aspect. However, the comment lacks specific references or detailed reasoning to support the claim that this approach is uncommon or unusual. Without additional context or references, the authors may find it challenging to fully understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some basis for questioning the approach but lacks sufficient detail or evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding the use of the Hamming distance over entire parts of the sequence as a common practice in the context of CRF, which is not aligned with the authors' awareness of works reporting node-wise Hamming loss. The comment is clear and actionable, as it prompts the authors to point out some references that might clarify this aspect. By providing this feedback, the comment helps the authors address a potential gap in their understanding and ensures that their work is well-supported. However, the comment could be more helpful if it provided specific references or examples of works that use node-wise Hamming loss, making it easier for the authors to address the issue. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional references.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the name of the \"Evaluation\" element can be changed to \"Metrics\" to avoid ambiguity, as \"evaluation\" has a broader meaning. It also recommends removing the corresponding sections and briefly mentioning the metrics along with the datasets or in the captions of the tables, as most metrics are well-known and standard practice. This comment provides explicit guidance on how to improve the paper by changing the name and adjusting the presentation of the evaluation section. The actions are concrete and detailed, allowing the authors to understand exactly what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" to avoid ambiguity, as \"evaluation\" has a broader meaning. It also recommends removing the corresponding sections and briefly mentioning the metrics along with the datasets or in the captions of the tables, as most metrics are well-known and standard practice. This feedback is fully grounded as it explicitly mentions the part of the paper being addressed, allowing the authors to accurately identify the section. The comment is also specific, as it provides clear guidance on how to improve the presentation of the evaluation section by suggesting a more precise name and adjusting the content. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the name of the \"Evaluation\" element can be changed to \"Metrics\" to avoid ambiguity, as \"evaluation\" has a broader meaning. It also recommends removing the corresponding sections and briefly mentioning the metrics along with the datasets or in the captions of the tables, as most metrics are well-known and standard practice. This feedback is mostly verifiable as it provides a clear rationale for the suggestion, explaining why the change would improve clarity and consistency. However, it could be more robust if it included specific examples of how the metrics are currently presented or why they are well-known. Overall, the comment is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific feedback on the naming of the \"Evaluation\" element, suggesting that it could be changed to \"Metrics\" to avoid ambiguity. It also recommends removing the corresponding sections and briefly mentioning the metrics along with the datasets or in the captions of the tables, as most metrics are well-known and standard practice. This feedback is clear and actionable, offering concrete suggestions for improving the clarity and presentation of the paper. By addressing the potential ambiguity in the term \"evaluation\" and suggesting a more precise and consistent approach to presenting metrics, the comment empowers the authors to enhance the readability and understanding of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that it is not yet possible to realize efficiency gains on GPU, similar to other work on pruning. However, it does not provide any specific actions or suggestions for the authors to take to address this issue or improve their draft. The comment lacks explicit guidance on how the authors might address this limitation or what changes could be made to their work. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing. It makes a general statement about the difficulty of realizing efficiency gains on GPU, which is a common issue in pruning work. However, it does not provide specific guidance or suggestions on how to address this issue or improve the paper. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that it is not yet possible to realize efficiency gains on GPU, similar to other work on pruning. However, the comment lacks specific evidence or references to support this claim. It does not provide any logical reasoning or examples to substantiate the assertion, making it difficult for the authors to understand the basis of the claim or how to address it. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that it is not yet possible to realize efficiency gains on GPU, which is a common issue in pruning work. However, it does not provide any specific suggestions or guidance on how the authors might address this limitation or improve their draft. The comment lacks actionable insights and does not offer any constructive feedback that could help the authors enhance their work. Therefore, the comment is barely helpful, as it identifies a problem but does not provide any meaningful suggestions for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the numerical evaluation: the use of synthetic data and the fairness of the comparison with [5]. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The authors are left without guidance on how to improve their evaluation or ensure a fair comparison. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the numerical evaluation of the paper, specifically mentioning the use of synthetic data and the comparison with [5]. It highlights that the evaluation is not fully convincing due to the use of synthetic data and that the comparison with [5] is not fair because [5] is designed for a more complex problem. However, the comment does not specify which part of the paper discusses the numerical evaluation or the comparison with [5]. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific about the issues raised, it lacks grounding as it does not provide clear references to the relevant parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the numerical evaluation is not fully convincing because it is based on synthetic data, and the comparison with [5] is not fair due to the difference in problem complexity. However, the comment does not provide specific examples or detailed reasoning to support these claims. It lacks references or detailed explanations of why the use of synthetic data or the comparison with [5] are problematic. Without additional evidence or justification, the claim is difficult to verify, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies two key issues with the numerical evaluation of the paper. First, it points out that the evaluation is based on synthetic data, which may not accurately reflect real-world scenarios. Second, it notes that the comparison with [5] is not entirely fair because [5] is designed for a more complex problem, specifically lacking knowledge of camera pose parameters. While the comment highlights these weaknesses, it does not provide specific suggestions or guidance on how the authors might address these issues in their evaluation. The feedback is somewhat helpful as it identifies areas for improvement, but it lacks actionable advice, making it a 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the necessity of studying the impact of the number of bits in logits on robustness against a larger epsilon in a PGD attack. It suggests that this experiment might not be absolutely necessary but could strengthen the paper. While the comment implies that the authors should consider the relevance of this experiment, it does not provide explicit guidance on how to address this question or what specific actions the authors should take. The action is implicit and somewhat vague, as the authors are left to infer the need for further analysis or discussion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the necessity of studying the impact of the number of bits in logits on robustness against a larger epsilon in a PGD attack. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area where the comment is relevant. While the comment is specific in its suggestion about the experiment's relevance, the absence of explicit grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the necessity of studying the impact of the number of bits in logits on robustness against a larger epsilon in a PGD attack. It suggests that this experiment might not be absolutely necessary but could strengthen the paper. However, the comment lacks specific evidence or reasoning to support the claim that the experiment is unnecessary or how it might strengthen the paper. The authors are left to infer the relevance of the experiment, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the necessity of studying the impact of the number of bits in logits on robustness against a larger epsilon in a PGD attack. It suggests that this experiment might not be absolutely necessary but could strengthen the paper. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this concern or what additional experiments could be conducted to strengthen their claims. The feedback is somewhat helpful as it points out a potential area for further exploration, but it does not provide detailed actionable advice or examples, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should clarify the difference between the meta solvers and centralized RL, where agents share weights. It provides a specific example, citing Foester et al., to illustrate the concept. However, the comment does not explicitly instruct the authors on how to clarify this difference or what specific aspects of the paper need to be addressed. While the suggestion is clear, the lack of detailed guidance on implementation makes it somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should clarify the difference between meta solvers and centralized RL, where agents share weights. It provides a specific example, citing Foester et al., to illustrate the concept. However, the comment does not specify which part of the paper discusses the meta solvers or centralized RL, making it difficult for the authors to pinpoint the exact section that needs clarification. While the suggestion is specific about the content to be clarified, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should clarify the difference between meta solvers and centralized RL, where agents share weights, and provides a specific example by citing Foester et al. This claim is somewhat verifiable as it offers a clear suggestion and a reference to support the idea. However, it lacks detailed reasoning or examples beyond the cited work, which could make it less robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for clarification in the paper, namely the distinction between meta solvers and centralized RL where agents share weights. It provides a clear suggestion to include a discussion of this difference, which could enhance the paper's clarity and depth. However, the comment lacks specific guidance on how to implement this clarification or what aspects of the paper need to be addressed. While it offers a valuable suggestion, the lack of detailed instructions limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the definition of M_T on page 3 could be clearer by providing examples. While the comment implies that the authors should consider adding examples to improve the understanding of M_T, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add examples. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the definition of M_T, suggesting that it is defined over the probabilities of atomic events and that the notation is not clear. The authors are advised to consider providing examples to explain M_T, which is a clear and actionable suggestion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the definition of M_T on page 3 could be clearer by providing examples. While the comment implies that the authors should consider adding examples to improve the understanding of M_T, it does not provide specific examples or references to support this suggestion. The lack of detailed reasoning or examples makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some guidance but lacks sufficient detail to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the definition of M_T on page 3, suggesting that it is defined over the probabilities of atomic events. The comment implies that the notation used is not making it easy to understand the concept and recommends providing examples to clarify it. While the comment points out a specific area for improvement, it does not offer detailed guidance on how to provide these examples or what kind of examples would be most effective. This feedback is somewhat helpful as it directs the authors to a specific area for revision, but it lacks depth and actionable suggestions, making it only somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about why both entities are detected in Figure 2 and asks for a comparison with a scenario where only the long entity is known. However, it does not provide explicit guidance on how the authors should address this question or what changes might be necessary in their draft. The action is implicit, as the authors need to infer that they should consider the implications of detecting both entities and compare it to a simpler scenario. The comment lacks concrete details on how to implement this suggestion, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about why both entities are detected in Figure 2 and asks for a comparison with a scenario where only the long one is known. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is not grounded as it lacks specific references to sections, tables, or figures. Additionally, it does not provide specific guidance on what needs to be addressed or how the authors should respond to the question. Therefore, the comment is not grounded and not specific, aligning with a score of 1: Not Grounded.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about why both entities are detected in Figure 2 and asks for a comparison with a scenario where only the long one is known. This is a question that seeks clarification and understanding, rather than making a claim that requires verification. The comment does not contain any subjective opinions, suggestions, or judgments, aligning with the classification of \"No\". Therefore, the comment is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind detecting both entities in Figure 2 and asks for a comparison with a scenario where only the long entity is known. This question prompts the authors to consider the implications of their detection method and its potential differences from simpler scenarios. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this question or improve their draft. While it identifies an area for clarification, it does not offer actionable feedback that would significantly enhance the authors' understanding or the quality of their work. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about a specific aspect of Theorem 1, questioning the validity of an assumption regarding a node with 0 neighbors. While the reviewer identifies a potential issue with the theorem, the comment does not provide explicit guidance or suggestions on how to address this concern. The authors are left to infer that they need to clarify or correct the theorem, but the lack of concrete steps or detailed explanations makes the action implicit and vague. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about a specific aspect of Theorem 1, focusing on a potential issue with an assumption regarding a node with 0 neighbors. However, it does not specify which part of the paper this theorem is located in, making it difficult for the authors to pinpoint the exact section being addressed. The comment is specific in its critique of the theorem but lacks grounding as it does not provide clear guidance on how to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about a specific aspect of Theorem 1, questioning the validity of an assumption regarding a node with 0 neighbors. The reviewer claims that the upper bound in this case is 0, which is not true. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the reviewer's assertion remains unsubstantiated, making the comment unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about a potential issue with Theorem 1, particularly concerning the assumption of a node with 0 neighbors. The reviewer questions the validity of the upper bound in this scenario, suggesting that it might be 0, which contradicts the theorem. However, the comment does not provide any guidance or suggestions on how to address this issue or clarify the theorem. While it identifies a potential area for improvement, the lack of actionable feedback leaves the authors without clear steps to take. Therefore, the comment is barely helpful, as it highlights a concern but does not offer constructive advice or solutions. The score is consistent with a rating of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting that while it mentions the challenges of detecting rumors generated by GPT, it does not provide further analysis or solutions. The comment suggests that the paper should explore why GPT-generated rumors are as difficult to detect as natural rumors, despite the fact that artificial rumors are also written by humans and should be about the same difficulty. However, the comment does not offer specific guidance on how to address this issue or what kind of analysis or solutions could be proposed. The action is implicit, as the authors need to infer that they should provide a deeper analysis of the difficulty in detecting GPT-generated rumors. The action is vague because it lacks concrete details on how to conduct this analysis or what specific aspects to focus on. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the handling of rumors generated by GPT, specifically noting that the paper mentions the challenges of detecting such rumors but lacks further analysis or solutions. It questions why GPT-generated rumors are as difficult to detect as natural rumors, despite the fact that artificial rumors are also written by humans and should be about the same difficulty. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in that it identifies a gap in the analysis and suggests a need for further exploration. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the difficulty of detecting GPT-generated rumors compared to natural rumors, suggesting that the paper should provide a deeper analysis of this issue. However, the comment does not offer any specific evidence, reasoning, or references to support this claim. It lacks detailed explanations or examples to substantiate the assertion that GPT-generated rumors are as difficult to detect as natural rumors. Without additional context or justification, the claim remains unsubstantiated, making the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by pointing out that while it acknowledges the challenges of detecting rumors generated by GPT, it does not provide further analysis or solutions to address this issue. The comment questions why GPT-generated rumors are as difficult to detect as natural rumors, despite the fact that artificial rumors are also written by humans and should be about the same difficulty. This feedback highlights an area where the paper could be strengthened by offering more in-depth analysis or proposing potential solutions. However, the comment lacks specific suggestions or guidance on how to address this issue, making it somewhat helpful. The authors would benefit from additional insights and suggestions to enhance the paper, but the feedback could be more comprehensive with detailed guidance on potential improvements. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the technical contribution is limited, specifically noting that the contents of Section 4 are not about a formal and principled solution but rather focus on heuristics. While the comment identifies a potential issue with the technical contribution, it does not provide explicit guidance on how the authors should address this limitation or what specific aspects of the section need improvement. The action is implicit, as the authors would need to infer that they should consider a more formal and principled approach to enhance the technical contribution. However, the comment lacks concrete details on how to achieve this, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the technical contribution, noting that the contents of Section 4 are not about a formal and principled solution but rather focus on heuristics. This provides the authors with a clear understanding of what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical contribution is limited, specifically noting that the contents of Section 4 are not about a formal and principled solution but rather focus on heuristics. This claim is somewhat verifiable as it provides a specific example of a limitation in the technical contribution, but it lacks detailed reasoning or references to support the claim fully. The authors would need to infer the basis for this claim, which could be improved by providing more context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the technical contribution of the paper, specifically pointing out that the contents of Section 4 are not about a formal and principled solution but rather focus on heuristics. This feedback is clear and actionable, as it highlights a specific area where the authors could enhance the rigor and depth of their work. By emphasizing the need for a more formal and principled approach, the comment provides a clear direction for improvement. However, it could be more helpful if it suggested specific ways to address this limitation or provided examples of how to incorporate a more formal approach. Overall, the comment is mostly helpful, as it offers valuable insights into areas for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a regret about the limited exploration of the probability mass function in the paper. It suggests that considering various probability mass functions could add depth to the experimental setting, particularly in the context of Boosted Decision Trees (BDT) of different depths. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to incorporate different probability mass functions into their experiments. The suggestion is vague and lacks concrete details, making it difficult for the authors to understand how to implement the proposed improvement. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"MixBoost\" and \"probability mass function,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the probability mass function is practically unexploited and suggests considering various distributions to add depth to the experimental setting. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses a regret about the limited exploration of the probability mass function in the paper, specifically mentioning that it is practically unexploited. It suggests that considering various probability mass functions could add depth to the experimental setting, particularly in the context of Boosted Decision Trees (BDT) of different depths. However, the comment lacks specific examples or references to support the claim that the quasi-uniform distribution is well-suited or why exploring other distributions would be beneficial. Without detailed reasoning or evidence, the claim is difficult to verify, making it somewhat verifiable. Therefore, the comment is rated as 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by highlighting the limited exploration of the probability mass function in the paper. It suggests that considering various probability mass functions could add depth to the experimental setting, particularly in the context of Boosted Decision Trees (BDT) of different depths. However, the comment does not provide detailed guidance on how the authors might explore different probability mass functions or what specific experiments could be conducted to demonstrate their impact. While it offers a direction for improvement, the lack of concrete suggestions or examples makes it somewhat helpful. The authors would need to infer how to address the comment, which limits its full impact. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the fairness of comparing accuracies when ChatGPT shows a higher percentage of abstention than other models. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to the comparison. The comment lacks concrete guidance on how to improve the draft or what specific aspects need to be revised. As a result, the authors are left without a clear understanding of how to respond to this feedback, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the fairness of comparing accuracies when ChatGPT shows a higher percentage of abstention than other models. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to address the issue or what changes could be made to the comparison. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the fairness of comparing accuracies when ChatGPT shows a higher percentage of abstention than other models. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the concern. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the fairness of comparing accuracies when ChatGPT shows a higher percentage of abstention than other models. This is a pertinent issue that could affect the interpretation of the results and the overall conclusions of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what changes could be made to ensure a fair comparison. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful. The authors would need to infer how to improve their draft based on this feedback, which limits the comment's usefulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include missing references, specifically mentioning a relevant work [a] that discusses supervised learning in QBF solving. It also provides a brief explanation of the relevance of this work, stating that it generalizes SMT. The comment is clear and direct, providing the authors with a specific action to take: include the suggested reference and discuss its connections to their work. This level of detail makes the comment highly actionable, as it clearly outlines what needs to be done and how to implement it. Therefore, the comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"relevant references\" and provides a specific example of a relevant work [a] that discusses supervised learning in QBF solving. It also suggests discussing the connections between the authors' work and this specific reference. This provides clear guidance on which part of the paper needs attention and what specific issue needs to be addressed. The comment is fully grounded as it accurately identifies the part of the paper that requires attention, and it is specific because it specifies the nature of the missing references and the need to discuss connections. Therefore, this comment is rated as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is missing relevant references, specifically mentioning a work [a] that discusses supervised learning in QBF solving. The comment provides a brief explanation of the relevance of this work, suggesting that it generalizes SMT. However, the claim lacks detailed reasoning or examples to fully substantiate the assertion that this reference is indeed relevant and missing. While the comment provides a basis for understanding the relevance, it does not offer a comprehensive justification or additional evidence to support the claim. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks depth and clarity.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper by pointing out missing references that are relevant to the topic. It provides a clear example of a relevant work [a] that discusses supervised learning in QBF solving, which generalizes SMT. The comment suggests that the authors should discuss the connections between their work and this specific reference, which is a valuable piece of feedback. However, the comment could be more helpful if it provided additional guidance on how to integrate or discuss the suggested reference effectively. Overall, the comment is somewhat helpful as it highlights an important aspect of the paper that needs attention, but it could be more comprehensive with additional suggestions or examples. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the necessity of a monotonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss. It suggests that this relationship might be replaced by other relationships and implies that explaining this point would be beneficial. However, the comment does not provide explicit guidance on how the authors should explore or address this issue. The suggestion to explain the point is vague and lacks concrete steps for the authors to take. Therefore, the comment is barely actionable, as it does not offer specific actions or detailed guidance on how to improve the draft.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the training process of a model, specifically questioning the necessity of a monotonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss. It suggests that this relationship might be replaced by other relationships and implies that explaining this point would be beneficial. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to explore alternative relationships, but without clear references to the paper, it is difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of a monotonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss, suggesting that this relationship might be replaced by other relationships. The comment implies that explaining this point would be beneficial, but it does not provide specific examples or references to support the claim. While the suggestion to explore alternative relationships is logical, the lack of detailed reasoning or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the necessity of a monotonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss. It suggests that this relationship might be replaced by other relationships and implies that explaining this point would be beneficial. However, the comment lacks specific guidance on how the authors might explore or address this issue, making it somewhat helpful. While it identifies a potential area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3, as it offers some insight but requires further elaboration to be fully helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the privacy-preserving nature of the proposed approach compared to other federated learning methods and questions the relevance of privacy preservation in the context of traffic signal control. While it prompts the authors to consider the privacy implications of their approach, it does not provide explicit guidance on how to address these concerns or suggest specific actions to improve the draft. The comment is somewhat vague, as it leaves the authors to infer the need for further discussion and clarification. Therefore, the comment is somewhat actionable, aligning with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the privacy-preserving nature of the proposed approach compared to other federated learning methods and questions the relevance of privacy preservation in the context of traffic signal control. However, it does not specify which part of the paper these questions are related to, making it difficult for the authors to pinpoint the exact section or aspect being addressed. The comment is not grounded as it lacks specific references to sections, tables, or figures. It is also not specific because it does not detail what needs to be addressed or how the questions should be answered. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises questions about the privacy-preserving nature of the proposed approach compared to other federated learning methods and questions the relevance of privacy preservation in the context of traffic signal control. While it prompts the authors to consider the privacy implications of their approach, it does not provide specific evidence or references to support the claim that the approach is more privacy-preserving than others. The questions raised are logical and relevant, but without detailed justification or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises questions about the privacy-preserving nature of the proposed approach compared to other federated learning methods and questions the relevance of privacy preservation in the context of traffic signal control. It suggests that one might think this is a bad example of an application of federated learning, which could provide valuable insights for the authors to consider. However, the comment lacks specific guidance or suggestions on how to address these concerns or improve the draft. While it identifies an area for improvement, it does not provide actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the hyperlinks for footnote 3 and 4 are not working. This is a clear and explicit action that the authors can take to address the issue. The comment provides specific information about which parts of the paper need to be checked and corrected, making it highly actionable. The authors know exactly what needs to be done to resolve the issue, which is to ensure the hyperlinks are functional. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"footnote 3 and 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue with the hyperlink functionality, providing a clear direction for the authors to take action. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point states that the hyperlink for footnote 3 and 4 does not seem to work. This is a factual observation that requires no further verification or explanation. The comment is a normal statement, as it describes a factual issue without making any claims or suggestions. Therefore, it is classified as \"No\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment points out an issue with the hyperlink functionality for footnote 3 and 4. This is a specific and actionable feedback that the authors can easily address by ensuring the hyperlinks are functional. The comment is clear and provides a direct action for the authors to take, making it highly helpful. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests revising the discussion, particularly in the modeling section, as it is not clear enough. It provides specific examples, such as the need for a better formalization of the architecture in section 2 and a clarification regarding the Label Embeddings. The comment implies that the authors should revise the discussion to address these points, but it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific changes required. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests revising the discussion, especially in the modeling section, which is currently not clear enough. It provides specific examples, such as the need for a better formalization of the architecture in section 2 and a clarification regarding the Label Embeddings. The comment is fully grounded as it explicitly mentions the modeling section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear examples of what needs to be improved, such as the formalization of the architecture and the clarification of the Label Embeddings. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests revising the discussion, particularly in the modeling section, which is currently not clear enough. It provides specific examples, such as the need for a better formalization of the architecture in section 2 and a clarification regarding the Label Embeddings. The comment implies that the authors should revise the discussion to address these points, but it does not provide explicit reasoning or references to support the claim that the discussion is unclear or needs improvement. While the suggestions are logical and provide direction, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the clarity and formalization of the modeling section, particularly in section 2. It highlights the need for a better formalization of the architecture and suggests that the Label Embeddings should be clarified. The feedback is actionable, as it directs the authors to specific areas where improvements are needed, such as the formalization of the architecture and the clarification of the Label Embeddings. However, the comment could be more helpful if it provided additional guidance on how to achieve these improvements or included examples of how to formalize the architecture. Overall, the comment is mostly helpful, as it offers clear directions for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the description of the neural network is hard to understand, but it also indicates that the final paragraph of the section clarifies it. The comment implies that the authors should consider starting the section with this clearer explanation. However, the action is implicit, as the authors need to infer that they should start the section with the final paragraph. The action is also somewhat vague, as it does not provide specific guidance on how to integrate the clearer explanation into the beginning of the section. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section of the paper (line 528), allowing the authors to accurately identify the part being addressed. It is also specific because it provides clear guidance on how to improve the clarity of the description of the neural network by suggesting that the final paragraph of the section should be used as the starting point. This provides a clear direction for the authors to enhance the readability of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of the neural network is hard to understand, suggesting that the final paragraph of the section clarifies it. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or evidence to substantiate the assertion that the description is unclear. As a result, the claim is not fully verifiable, as the authors may need to infer the basis of the feedback. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the description of the neural network, noting that the final paragraph of the section clarifies it. It suggests that the authors consider starting the section with this clearer explanation. This feedback is actionable and provides a clear direction for improvement, as it guides the authors to enhance the readability and coherence of their paper. However, the comment could be more helpful if it offered additional suggestions or examples of how to improve the clarity of the description. Overall, the comment is mostly helpful, as it provides a clear and actionable piece of feedback that empowers the authors to improve their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the model's limitation to CTC loss and suggests exploring attention-based enc-dec training. While it implies that the authors should consider this possibility, it does not provide explicit guidance on how to implement or explore this suggestion. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the comment. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the model's limitation to CTC loss and suggests exploring attention-based enc-dec training. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the model's limitation to CTC loss and suggests exploring attention-based enc-dec training. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is relevant or beneficial. The comment lacks depth and does not offer a clear justification for the proposed change, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the model's limitation to CTC loss and suggests exploring attention-based enc-dec training. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to implement or explore this idea. The comment is somewhat helpful as it points out a potential limitation and encourages the authors to consider alternative approaches, but it does not provide detailed feedback or actionable steps to address the issue. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point criticizes the paper for using only two attack methods, which are considered naive, and suggests that other classical attack methods in NLP could be used. However, it does not provide explicit guidance on which other methods should be considered or how they might improve the paper. The comment implies that the authors should explore additional attack methods, but it lacks concrete suggestions or detailed instructions on how to implement this feedback. As a result, the authors are left without a clear understanding of what specific changes to make, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the paper for using only two attack methods, suggesting that other classical attack methods in NLP could be considered. However, it does not specify which other methods should be explored or why the current methods are insufficient. The comment lacks grounding as it does not mention specific sections or parts of the paper that need improvement. It is also not specific because it does not provide detailed guidance on which additional methods to consider or how they might enhance the paper. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point critiques the paper for using only two attack methods, suggesting that other classical attack methods in NLP could be considered. However, the comment does not provide specific examples or references to support the claim that these methods are insufficient or naive. It lacks detailed reasoning or evidence to substantiate the assertion that the current methods are inadequate. As a result, the claim is not fully verifiable, making it difficult for the authors to understand the basis for the critique. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment critiques the paper for using only two attack methods, suggesting that other classical attack methods in NLP could be considered. While it identifies a potential area for improvement, it does not provide specific examples of alternative methods or explain why the current methods are insufficient. The comment lacks actionable guidance, such as suggesting specific alternative attack methods or providing references to relevant literature. This limits the authors' ability to address the feedback effectively, making the comment somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the mitigation methods used in the paper, suggesting that they might affect the image generation capabilities of diffusion models, leading to lower image quality. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might investigate or mitigate this issue, leaving them without a clear path forward. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing. It makes a general observation about the mitigation methods affecting the image generation capabilities of diffusion models, but it does not provide specific details or examples of what needs to be addressed. This lack of grounding makes it difficult for the authors to understand where the issue lies and how to address it. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the mitigation methods affect the image generation capabilities of diffusion models, leading to lower image quality. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the mitigation methods used in the paper, suggesting that they might affect the image generation capabilities of diffusion models, which could lead to lower image quality. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their draft. It lacks actionable advice, making it difficult for the authors to take meaningful steps to enhance their work. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit suggestions for improvement or clarification. The authors are left without guidance on how to address this observation or what might be causing it. As a result, the comment lacks actionable feedback, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper the reviewer is referring to, such as a particular section or figure. It is also not specific because it does not provide details on what is surprising or how the dominance of function words over content words might be addressed. The comment lacks both grounding and specificity, making it unsuitable for guiding the authors effectively.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a subjective observation about the dominance of function words over content words in a Japanese sentence, followed by a question about the reviewer\\'s understanding. While the observation is based on a specific example, the comment lacks detailed reasoning or evidence to support the claim. The authors may find it challenging to understand the basis of the observation without further explanation or context. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment expresses a subjective observation about the dominance of function words over content words in a Japanese sentence, which the reviewer finds surprising. However, it does not provide any specific feedback or suggestions on how this observation might be addressed or what implications it has for the paper. The comment lacks actionable guidance and does not offer insights into potential improvements or areas for clarification. As a result, it is barely helpful, as it does not provide the authors with a clear path forward for enhancing their work.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the average of k-means objectives with multiple seeds should be used as a baseline, and it recommends using the minimal k-means objective over multiple seeds instead. While the suggestion is clear and provides a specific reason for the change, it does not offer detailed guidance on how to implement this change or what specific aspects of the current baseline should be modified. The action is explicit but somewhat vague, as it lacks concrete steps for the authors to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the average of k-means objectives with multiple seeds should be used as a baseline, and it recommends using the minimal k-means objective over multiple seeds instead. It also provides references to support the suggestion. However, the comment does not specify which part of the paper discusses the baselines or the k-means objectives, making it weakly grounded. The comment is specific in its suggestion and references, but the lack of grounding makes it difficult for the authors to identify the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the average of k-means objectives with multiple seeds should be used as a baseline, and it recommends using the minimal k-means objective over multiple seeds instead. The comment provides references to support this suggestion, specifically citing two papers that discuss the use of minimal k-means objectives. This provides a clear rationale for the recommendation, making the claim fully verifiable. Therefore, the comment is labeled as 5.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides a minor suggestion to improve the baseline used in the paper by recommending the use of the minimal k-means objective over multiple seeds instead of the average. It also provides references to support this suggestion, citing two relevant papers that discuss the use of minimal k-means objectives. While the comment is specific and offers a clear rationale for the change, it lacks depth and does not provide detailed guidance on how to implement the suggested change or what specific aspects of the current baseline should be modified. The feedback is somewhat helpful as it directs the authors towards a more robust baseline, but it could be more comprehensive with additional details or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific questions (2.a and 2.b) that require clarification and explanation from the authors. It highlights a potential confusion regarding the relationship between temperature calibration and uncertainty calibration, particularly concerning the regularization term H. The comment explicitly asks for clarification on how temperature calibration is applied after training and why reducing entropy is considered against the paper motivation. While the actions are clear and explicit, the comment lacks concrete guidance on how the authors should address these questions or provide additional context. Therefore, the comment is somewhat actionable, as it provides clear directions but does not offer detailed steps on how to implement the suggestions.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific issues related to uncertainty calibration and the regularization term H, referencing lines 155-160 and 133-136. It provides detailed questions and suggestions for clarification, making it fully grounded as the authors can accurately identify the sections being discussed. The comment is also specific, as it clearly specifies what needs to be clarified and why it is important. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the relationship between temperature calibration and uncertainty calibration, specifically regarding the regularization term H. It points out a potential confusion in the paper, suggesting that the training regularization term requires temperature calibration, yet temperature calibration is applied after training. The comment also questions the motivation behind reducing entropy, which is considered against the paper's goal of calibrating networks that are already overconfident. While the comment highlights a potential issue, it does not provide specific examples or references to support the claim that the current approach is problematic. Therefore, the claim is somewhat verifiable, as it is based on logical reasoning but lacks detailed evidence or references to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential confusion regarding the relationship between temperature calibration and uncertainty calibration, particularly concerning the regularization term H. It raises two specific questions (2.a and 2.b) that require clarification from the authors. The comment highlights a potential inconsistency in the paper's approach, where the training regularization term requires temperature calibration, yet temperature calibration is applied after training. Additionally, it questions the motivation behind reducing entropy, which is considered against the paper's goal of calibrating overconfident networks. While the comment provides clear feedback and identifies areas for clarification, it could be more helpful if it offered specific suggestions or guidance on how the authors might address these issues. Overall, the comment is somewhat helpful as it points out important areas for improvement but lacks depth in its suggestions.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missing reference related to the concept of unrolling, specifically mentioning \"Lista\" and providing a link to the paper. It suggests that the paper should discuss the similarities and differences between the proposed work and Lista, placing it in the appropriate context. However, the comment does not provide explicit guidance on how to incorporate this discussion or where to add it in the draft. The action is implicit, as the authors need to infer that they should include a discussion of the missing reference and its relevance to their work. While the action is somewhat vague, it is clear that the authors need to address the missing reference and its context. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"unrolling\" and provides a link to a specific paper, \"Lista,\" which is relevant to the topic. It also specifies that the paper should discuss the similarities and differences between the proposed work and Lista, indicating what needs to be addressed. This provides clear guidance on which part of the paper should be revised and what specific content is missing. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that an important reference is missing, specifically mentioning \"Lista\" and providing a link to the paper. It suggests that the paper should discuss the similarities and differences between the proposed work and Lista, placing it in the appropriate context. However, the comment lacks detailed reasoning or examples to support the claim that the omission is significant or how it impacts the paper's contribution. Without specific evidence or references, the claim is somewhat verifiable, as it provides a basis for improvement but lacks depth. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper by pointing out a missing reference related to the concept of unrolling, specifically mentioning 'Lista' and providing a link to the paper. It highlights the importance of discussing the similarities and differences between the proposed work and 'Lista,' which is crucial for placing the paper in the appropriate context. This feedback is clear and actionable, as it directs the authors to include a discussion of the missing reference and its relevance to their work. However, the comment could be more helpful if it provided specific guidance on where to add this discussion or how to integrate it into the draft. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should explain the linear program in Theorem 3 intuitively, specifically mentioning the need to clarify the objective and constraints in equation (3). This feedback is explicit and provides a clear action for the authors to take, which is to elaborate on the components of the linear program. The comment is concrete, as it specifies exactly what needs to be explained, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the intuitive explanation of the linear program, particularly the objective and constraints in equation (3). This provides the authors with a clear understanding of the issue and how to address it. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should explain the linear program in Theorem 3 intuitively, specifically mentioning the need to clarify the objective and constraints in equation (3). This is a suggestion for improvement, but it lacks specific examples or detailed reasoning to support why this explanation would be beneficial. Without additional context or examples, the claim is somewhat verifiable, as it provides a general direction for improvement but does not offer concrete evidence or references to support the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors should provide an intuitive explanation of the linear program in Theorem 3. It highlights the need to clarify the objective and constraints in equation (3), which would significantly benefit the reader's understanding. This feedback is clear and actionable, offering a direct suggestion for enhancing the clarity and accessibility of the paper. However, it could be more helpful if it provided additional guidance on how to explain the linear program intuitively or suggested specific examples of how to do so. Overall, the comment is mostly helpful as it directs the authors towards a concrete improvement, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and concerns about the clarity of Algorithm 2, specifically regarding the computation of 'avg' and the use of variables j' and i''. It suggests that the authors should clarify these aspects to improve the understanding of the algorithm. While the comment explicitly asks for clarification, it does not provide concrete guidance on how to address these issues or what specific changes should be made to the algorithm. The action is implicit, as the authors need to infer that they should clarify the algorithm and address the specific questions raised. However, the lack of detailed guidance on how to implement these changes makes the comment somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the clarity of Algorithm 2, specifically regarding the computation of \"avg\" and the use of variables j\\' and i\\'. However, it does not specify which part of the paper Algorithm 2 is located in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but without explicit grounding, the authors may find it challenging to pinpoint the exact section to focus on. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the clarity of Algorithm 2, specifically regarding the computation of \"avg\" and the use of variables j\\' and i\\'. While the comment suggests that the authors should clarify these aspects, it does not provide any specific examples, references, or detailed reasoning to support the claim that the algorithm is unclear or that these variables are not used. The feedback is somewhat verifiable as it points out potential issues but lacks depth and specificity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises concerns about the clarity of Algorithm 2, specifically questioning the computation of 'avg' and the use of variables j' and i'. It suggests that the authors should clarify these aspects to improve the understanding of the algorithm. While the comment identifies a potential area for improvement, it lacks detailed guidance on how to address these issues or what specific changes should be made to the algorithm. The feedback is somewhat helpful as it points out a need for clarification, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is not polished and lacks polish, noting missing details in related work, experiments, and writing. It also directs the authors to a specific section labeled \"Clarity, Quality, Novelty And Reproducibility,\" which implies that this section contains more detailed feedback. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve the polish or polish the paper. The action is implicit and somewhat vague, as the authors need to infer that they should focus on the missing details and improve the polish. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper is not polished and lacks polish, noting missing details in related work, experiments, and writing. It directs the authors to a specific section labeled \"Clarity, Quality, Novelty And Reproducibility,\" which provides more detailed feedback. However, the comment does not specify which parts of the paper are missing details or where these details should be addressed. This makes it difficult for the authors to pinpoint the exact areas that need improvement. The comment is fully grounded in terms of identifying the need for polish and detailed feedback, but it is not specific in terms of what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is not polished and lacks polish, noting missing details in related work, experiments, and writing. It directs the authors to a specific section labeled \"Clarity, Quality, Novelty And Reproducibility,\" which implies that this section contains more detailed feedback. However, the comment lacks specific examples or references to support the claim about missing details or areas needing improvement. Without detailed examples or references, the authors may find it challenging to understand the specific issues that need to be addressed. Therefore, the claim is somewhat verifiable, as it provides a general direction but lacks the necessary depth and specificity to fully guide the authors.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that it is not polished and lacks polish, with missing details in related work, experiments, and writing. It directs the authors to a specific section labeled \"Clarity, Quality, Novelty And Reproducibility,\" which suggests that this section contains more detailed feedback. However, the comment lacks specific examples or guidance on how to address these issues, making it somewhat helpful. The authors gain a general understanding of the need for improvement but may struggle to pinpoint the exact areas that require attention. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the accuracy drop observed in Figure 5 after a certain order of around 4-5, suggesting that it might be due to overfitting. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they should consider to improve the model or the analysis. Without specific suggestions or instructions, the authors are left without a clear path to follow, making the comment unactionable. Therefore, this comment is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the accuracy drop observed in the figure and suggests that it might be due to overfitting, providing a clear direction for the authors to consider. This feedback is detailed and actionable, guiding the authors to investigate the potential cause of the accuracy drop. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the accuracy drop observed in Figure 5 after a certain order, suggesting that it might be due to overfitting. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific details or logical reasoning to substantiate the suggestion, making it difficult for the authors to understand or address the issue. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the accuracy drop observed in Figure 5 after a certain order, suggesting that it might be due to overfitting. While the comment identifies a potential issue with the model's performance, it does not provide any specific guidance or suggestions on how the authors might address this problem. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of natural ablation studies, specifically mentioning the importance of including a baseline where scratchGAN is pretrained. It suggests that this baseline is crucial for supporting the central argument against pretraining. However, the comment does not provide explicit guidance on how to conduct these ablations or what specific results should be included. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"natural ablation studies,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for a baseline where scratchGAN is pretrained, providing clear guidance on what needs to be addressed. However, the comment does not provide specific details on which sections or parts of the paper should be revised to include these ablations. This makes the comment fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that some natural ablation studies are missing, specifically mentioning the importance of including a baseline where scratchGAN is pretrained. This claim is somewhat verifiable as it highlights a specific area where additional analysis could strengthen the paper. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would benefit from additional context or references to support the assertion about the importance of this baseline.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the absence of natural ablation studies, particularly the importance of including a baseline where scratchGAN is pretrained. This is a crucial aspect for supporting the central argument against pretraining. However, the comment lacks depth and does not provide detailed guidance on how to conduct these ablations or what specific results should be included. While it offers a clear direction for improvement, the feedback could be more comprehensive and actionable to fully enhance the authors' draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should mention a specific detail in Section SI 6.5 regarding the evaluation process, noting that it differs from the evaluation in Mnih et al. [7] due to the absence of human starts. This comment provides an explicit action for the authors to take, which is to include this detail in their manuscript. The action is concrete as it specifies exactly what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies what needs to be mentioned in that section, namely the difference in evaluation due to the absence of human starts. This provides the authors with clear guidance on what to include, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should mention a specific detail in Section SI 6.5 regarding the evaluation process, noting that it differs from the evaluation in Mnih et al. [7] due to the absence of human starts. This claim is somewhat verifiable as it provides a clear reason for the authors to include this detail, but it lacks specific examples or references to support the claim fully. The authors would benefit from additional context or examples to strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for the authors to include in Section SI 6.5. It highlights a detail that is important for the evaluation process, noting that the evaluation differs from that in Mnih et al. [7] due to the absence of human starts. This feedback is clear and directly addresses a potential area of confusion or omission in the manuscript. By suggesting this addition, the comment empowers the authors to improve the clarity and completeness of their work. Therefore, the comment is mostly helpful, as it offers a clear and actionable piece of feedback that would enhance the manuscript.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting that while the authors discuss the advantages of their proposed method in terms of efficiency, they do not provide any specific metrics to support this claim. The comment implies that the authors should include such metrics to substantiate their claims of efficiency. However, the action is implicit, as the authors need to infer that they should report metrics to demonstrate efficiency. The action is also somewhat vague, as it does not specify which metrics should be reported or how they should be presented. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the authors discuss the advantages of their proposed method over previous work in terms of efficiency. This allows the authors to accurately identify the section being addressed. The comment is also specific because it points out a lack of reporting of metrics that would demonstrate the efficiency of the proposed method. This provides clear guidance on what needs to be addressed to strengthen the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not report any metric that shows the proposed method is more efficient to train compared to previous work. However, the comment lacks specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this critique. Therefore, the claim is considered borderline verifiable, as it provides some indication of a gap but lacks detailed justification or examples.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out that while the authors discuss the advantages of their proposed method in terms of efficiency, they do not provide any specific metrics to support this claim. This feedback is valuable as it highlights a critical area where the paper lacks empirical evidence. By requesting the inclusion of metrics, the comment encourages the authors to substantiate their claims of efficiency, which is essential for a thorough and convincing evaluation of the proposed method. However, the comment could be more helpful if it suggested specific types of metrics or how to present them effectively. Overall, the feedback is mostly helpful as it directs the authors to an important aspect of their work that needs further attention.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point requests the authors to provide more details about the state-space, actions, and the space of theta. While the authors can infer that they need to clarify these aspects, the comment does not explicitly instruct them to do so. The request for more details is clear, but the action of providing these details is implicit and could be more explicit. Therefore, this comment is somewhat actionable, as it provides a clear direction but lacks explicit guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific part of the paper, L81, allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the details about the state-space, actions, and the space of theta. The request for more details is clear and specific, making this comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point requests more details about specific aspects of the paper, such as the state-space, actions, and the space of theta. While the request is clear and specific, it does not provide any evidence or reasoning to support why these details are important or how they impact the paper. The authors are left to infer the significance of these details, which makes the comment somewhat verifiable. However, without additional context or justification, the claim is not fully verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies specific areas where the authors could provide more details, such as the nature of the state-space, actions, and the space of theta. This feedback is clear and actionable, as it directs the authors to enhance the clarity and precision of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to improve the clarity of these aspects. Overall, the feedback is valuable but could be more comprehensive to fully assist the authors in improving their draft.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the method does not work very effectively on general reasoning tasks compared to mathematical reasoning. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might improve the method's performance on general reasoning tasks or what changes could be made to enhance its effectiveness. As a result, the authors are left without a clear understanding of what steps to undertake to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the method does not work very effectively on general reasoning tasks compared to mathematical reasoning. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to identify the exact section or aspect that needs improvement. The comment is specific in its critique of the method's performance but lacks grounding as it does not provide explicit references to the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method does not work very effectively on general reasoning tasks compared to mathematical reasoning. However, the comment lacks specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the method's performance on general reasoning tasks compared to mathematical reasoning. While it highlights an area for improvement, it lacks specific details or suggestions on how the authors might address this issue. The comment is somewhat helpful as it points out a limitation that could be addressed, but it does not provide actionable guidance or examples of how to enhance the method's effectiveness on general reasoning tasks. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider using LiDAR-based segmentation as the downstream task instead of object detection, particularly for benchmarks using IoU-based metrics like KITTI and Waymo. It also critiques colorization-based pre-training for learning semantics, arguing that object detection requires accurate locations and poses. However, the comment does not provide explicit guidance on how the authors should implement these suggestions or address the concerns about the choice of downstream tasks and pre-training methods. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider using LiDAR-based segmentation as the downstream task instead of object detection, particularly for benchmarks using IoU-based metrics like KITTI and Waymo. It also critiques colorization-based pre-training for learning semantics, arguing that object detection requires accurate locations and poses. However, the comment does not specify which part of the paper discusses the choice of downstream tasks or the use of colorization-based pre-training. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs attention. While the comment is specific in its critique of the choice of downstream tasks and pre-training methods, the absence of explicit references to the paper makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the choice of downstream tasks and pre-training methods, specifically suggesting that LiDAR-based segmentation might be a better choice than object detection for benchmarks using IoU-based metrics like KITTI and Waymo. It also argues that colorization-based pre-training might not be as effective for object detection, which requires accurate locations and poses. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the feedback. The reasoning is somewhat vague, and the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides feedback on the choice of downstream tasks and pre-training methods, suggesting that LiDAR-based segmentation might be a better choice than object detection for benchmarks using IoU-based metrics like KITTI and Waymo. It also critiques colorization-based pre-training for learning semantics, arguing that object detection requires accurate locations and poses. However, the comment lacks specific guidance on how the authors should address these concerns or implement the suggested changes. While it identifies areas for improvement, it does not provide detailed suggestions or actionable steps for the authors to take, making it somewhat helpful. The feedback is somewhat helpful as it highlights important aspects of the draft that need attention, but it could be more comprehensive with detailed guidance.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential contradiction between the objective of Eq (12) and the IPO (Iterative Proportional Fitting) method. However, it does not provide explicit guidance on how the authors should address this contradiction or what specific changes might be necessary. The comment lacks concrete suggestions or actionable steps, leaving the authors uncertain about how to proceed. As a result, the feedback is not actionable, making it difficult for the authors to improve their draft. Therefore, this comment is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"Eq (12)\" and \"IPO,\" which provides some grounding as the authors can infer that the reference is to a specific equation and method in the paper. However, it does not specify which part of the paper discusses Eq (12) or how it relates to IPO. The comment is specific in identifying a potential contradiction, but the lack of detailed grounding makes it challenging for the authors to pinpoint the exact section or aspect of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the objective of Eq (12) seems to be in contradiction with IPO. However, the comment lacks specific details or examples to substantiate this claim. Without further explanation or evidence, the authors may find it challenging to understand the nature of the contradiction or how to address it. The comment is therefore considered unverifiable due to the absence of supporting information or reasoning. This aligns with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential contradiction between the objective of Eq (12) and the IPO method, which is a specific concern for the authors. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue. Without actionable advice or examples, the authors may struggle to understand the implications of this contradiction and how to resolve it. Therefore, the comment is barely helpful, as it points out a problem but does not offer substantial assistance for improvement. This aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the adaptation capacity of the proposed visual memory to accommodate ever-growing concepts, particularly when class labels correlate more with semantics than geometry. It suggests that the image encoder may struggle to produce meaningful embeddings for new concepts in such cases. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft. The action is implicit, as the authors would need to infer that they should consider the limitations of the image encoder in handling semantic concepts and potentially explore alternative approaches or provide more detailed explanations. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the adaptation capacity of the proposed visual memory to accommodate ever-growing concepts, particularly when class labels correlate more with semantics than geometry. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or figure being discussed. While the comment is specific in its inquiry about the adaptation capacity and the challenges it might face, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the adaptation capacity of the proposed visual memory to accommodate ever-growing concepts, particularly when class labels correlate more with semantics than geometry. It suggests that the image encoder may struggle to produce meaningful embeddings for new concepts in such cases, especially for geometrically distinctive concepts where DINO representations are observed to contain rich geometric information. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the adaptation capacity still holds for concepts where class labels correlate more with semantics. This lack of evidence makes the claim somewhat verifiable, as the authors would need to provide additional context or evidence to substantiate the point. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the adaptation capacity of the proposed visual memory to accommodate ever-growing concepts, particularly when class labels correlate more with semantics than geometry. It highlights a potential limitation in the image encoder's ability to produce meaningful embeddings for new concepts in such cases. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as barely helpful, as it offers a question but lacks depth and constructive feedback.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential issue with the notation used in Algorithm 1, specifically the use of $p$ to denote both the phase mixing probability and a dummy variable in the inner loop of Phase 2. This could lead to confusion for readers, as the same symbol is used for two distinct concepts. However, the comment does not provide any explicit guidance or suggestions on how the authors might address this issue, such as suggesting alternative notations or clarifying the usage of $p$. The action is implicit and vague, as the authors are left to infer that they need to make the notation clearer. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a potential issue with the notation used in Algorithm 1, specifically the use of $p$ to denote both the phase mixing probability and a dummy variable in the inner loop of Phase 2. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that using $p$ to denote both the phase mixing probability and a dummy variable in Algorithm 1 could be confusing. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand why this confusion might arise or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the notation used in Algorithm 1, specifically the use of $p$ to denote both the phase mixing probability and a dummy variable in the inner loop of Phase 2. This could lead to confusion for readers, as the same symbol is used for two distinct concepts. While the comment highlights a specific area that needs clarification, it does not provide any suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks actionable advice, making it difficult for the authors to fully benefit from the comment. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a more detailed mathematical formulation, potentially in the appendix, would enhance the understanding of the approach. It also points out that the figure is too abstract and confusing, and that it does not align with the paper's main contribution, which is improvements on the WiC task. The comment implies that the authors should consider adding more text labels to the figure and potentially reworking it to depict the WiC task. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve the paper. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the high-level description and the figure, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed in these parts, such as adding a more detailed mathematical formulation and improving the clarity of the figure. The comment provides clear guidance on how to enhance the understanding of the approach and the figure, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the high-level description helps understand the approach intuitively but suggests a more detailed mathematical formulation, potentially in the appendix, would be beneficial. It also criticizes the figure for being too abstract and confusing, noting that it does not align with the paper's main contribution, which is improvements on the WiC task. The comment provides specific suggestions for improvement, such as adding more text labels to the figure and potentially reworking it to depict the WiC task. However, it lacks detailed reasoning or references to support these claims, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides specific feedback on areas where the paper could be improved. It suggests that while the high-level description helps understand the approach intuitively, a more detailed mathematical formulation, potentially in the appendix, would enhance the understanding. Additionally, the comment points out that the figure is too abstract and confusing, and that it does not align with the paper's main contribution, which is improvements on the WiC task. The reviewer offers suggestions for improvement, such as adding more text labels to the figure and potentially reworking it to depict the WiC task. This feedback is clear and actionable, providing the authors with specific directions for enhancing the clarity and relevance of their work. Therefore, the comment is mostly helpful, as it offers constructive guidance for improvement.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include additional benchmarking tasks outside of AitW. While the comment implies that this addition would be beneficial, it does not explicitly instruct the authors on how to implement this suggestion. The action is implicit, as the authors can infer that they need to add more benchmarking tasks, but the comment lacks concrete guidance on which tasks to include or how to integrate them into the draft. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific details on how to execute it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including additional benchmarking tasks outside of AitW, but it does not specify which tasks or how they should be integrated into the paper. This makes it difficult for the authors to identify the exact part of the paper that needs revision or improvement. The comment is not grounded as it does not provide specific guidance on which sections or parts of the paper should be addressed. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should include additional benchmarking tasks outside of AitW. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors should include additional benchmarking tasks outside of AitW, which could enhance the comprehensiveness and robustness of their work. However, the comment lacks specificity, as it does not specify which tasks should be included or how they would be integrated into the draft. This makes it somewhat helpful, as it provides a general direction for improvement but does not offer detailed guidance or actionable steps for the authors. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the abstract and the text regarding the requirement of the proposal distribution to upper bound the target everywhere. While the abstract implies this requirement, the authors clarify in the text that it is not true. This feedback suggests that the abstract should be revised to accurately reflect the content of the paper. However, the comment does not provide explicit guidance on how to revise the abstract or what specific changes are needed. The action is implicit and somewhat vague, as the authors are left to infer the necessary revisions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it points out a factual error in the abstract, where the authors themselves clarify that the proposal distribution does not need to upper bound the target everywhere. This provides clear guidance on what needs to be corrected. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract implies the proposal distribution must upper bound the target everywhere, which is not true as the authors clarify in the text. This claim is supported by the authors' own clarification, providing a clear basis for the reviewer's observation. However, the comment could be more verifiable by explicitly referencing the specific section of the text where the clarification is provided. Despite this, the claim is mostly verifiable, as it is supported by logical reasoning and a reference to the authors' own text. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue in the abstract, noting that it implies the proposal distribution must upper bound the target everywhere, which is not accurate as the authors clarify in the text. This feedback is clear and actionable, as it directs the authors to revise the abstract to accurately reflect the content of the paper. By highlighting this discrepancy, the comment provides a concrete suggestion for improvement, helping the authors ensure the accuracy and clarity of their work. However, the comment could be more helpful if it offered additional guidance on how to revise the abstract or what specific changes to make. Overall, the comment is mostly helpful, as it effectively points out a critical issue that needs attention.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the policy gradient in Eq. 6 and whether it solves the optimal problem, specifically questioning if the converged solution aligns with Eq. 5. It suggests that the authors should clarify this point. However, the comment does not provide explicit guidance on how to address this question or what specific aspects of the policy gradient need clarification. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the relationship between the policy gradient and the optimal problem. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the policy gradient in Eq. 6 and whether it solves the optimal problem, specifically questioning if the converged solution aligns with Eq. 5. It suggests that the authors should clarify this point. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification regarding the policy gradient and its convergence to the optimal solution. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the policy gradient in Eq. 6 and whether it solves the optimal problem, specifically questioning if the converged solution aligns with Eq. 5. It suggests that the authors should clarify this point. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the policy gradient in Eq. 6 and whether it solves the optimal problem, specifically questioning if the converged solution aligns with Eq. 5. It suggests that the authors should clarify this point, which is a valuable piece of feedback for improving the clarity and accuracy of the paper. However, the comment lacks specific guidance on how to address this issue or what aspects of the policy gradient need clarification. While it identifies a potential area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it highlights a specific area for clarification but does not offer comprehensive guidance. This aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. It implies that the authors should discuss the limitations of this approach. However, the comment does not provide explicit guidance on how to implement this discussion or what specific aspects of the partitioning strategy should be addressed. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by suggesting that the authors discuss the limitations of freezing the partitioning in the first iteration. This provides clear guidance on how to improve the paper, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. It implies that the authors should discuss the limitations of this approach. However, the comment does not provide specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the methodology, specifically the assumption of coverage in the first iteration of partitioning. It suggests that this choice might be risky and recommends a discussion of its limitations. This feedback is clear and actionable, as it provides a specific area for improvement and encourages the authors to address a potential weakness in their approach. However, the comment could be more helpful if it offered additional guidance on how to discuss the limitations or what aspects of the partitioning strategy should be considered. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that many aspects of the approach need clarification and that the paper quickly delves into technical details without clearly explaining the overall approach or its rationale. However, it does not provide explicit instructions or suggestions on how the authors should clarify these aspects or address the issue of understanding how the approach overcomes reporting bias. The action is implicit, as the authors need to infer that they should provide more clarity on the approach and its rationale. The comment is somewhat actionable because it identifies a specific area for improvement but lacks concrete guidance on how to achieve it. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that many aspects of the approach need clarification, but it does not specify which parts of the paper these aspects relate to. The reviewer expresses concern about understanding how the approach makes knowledge about objects interact with knowledge about verbs to overcome reporting bias. However, the comment does not provide specific guidance on which sections or figures might be causing confusion. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need clarification. The comment is specific in its critique of the approach's clarity but lacks grounding in terms of identifying the specific parts of the paper that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the clarity of the approach and the lack of explanation regarding how the approach overcomes reporting bias. However, it does not provide specific examples, references, or detailed reasoning to support these claims. The comment lacks sufficient evidence to substantiate the concerns, making it difficult for the authors to address the issues effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that many aspects of the approach need clarification. It specifically highlights the lack of understanding regarding how the approach makes knowledge about objects interact with knowledge about verbs to overcome reporting bias. The comment also points out that the paper quickly delves into highly technical details without clearly explaining the overall approach and its rationale. This feedback is somewhat helpful as it directs the authors to areas that require clarification and provides a specific concern about the paper's structure and explanation. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided examples of where the explanation is lacking. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind using early stopping based solely on link prediction accuracy, suggesting that averaging with type accuracy might be a more comprehensive approach. While the comment implies that the authors should provide a justification for their decision, it does not explicitly instruct them to do so or offer specific guidance on how to explain the choice. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a rationale for their decision. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"590,\" allowing the authors to accurately identify the section of the paper being addressed. It is also specific because it clearly specifies the issue: the decision to use early stopping only by link prediction accuracy and questions why it was not averaged with type accuracy. This provides a clear direction for the authors to address the concern. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the rationale behind using early stopping based solely on link prediction accuracy, suggesting that averaging with type accuracy might be a more comprehensive approach. However, the comment does not provide any specific reasoning, examples, or references to support why averaging with type accuracy would be a better approach. Without additional justification or evidence, the claim remains somewhat verifiable, as the authors are left to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific point of concern regarding the decision to use early stopping based solely on link prediction accuracy. It questions the rationale behind this choice, suggesting that averaging with type accuracy might be a more comprehensive approach. While the comment highlights a potential area for improvement, it does not provide detailed guidance or suggestions on how to address this issue. The feedback is somewhat helpful as it points out a potential weakness in the methodology, but it lacks depth and actionable advice, making it only somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how to set a reasonable class-imbalanced task in the context of few-shot learning. It does not provide explicit instructions or suggestions on how to address this issue, nor does it offer concrete details or examples to guide the authors. The comment implies that the authors should clarify this aspect, but it lacks specific guidance on how to do so. Therefore, the comment is not actionable, as it does not provide the authors with a clear path to improve their draft. The comment is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the paper\\'s writing of \"sampling class-imbalanced tasks\" in the context of few-shot learning. It does not specify which part of the paper this issue is discussed, making it difficult for the authors to pinpoint the exact section or figure that needs attention. However, the comment is specific in its request for clarification and explanation regarding how to set a reasonable class-imbalanced task. This suggests that the authors need to provide more details on this aspect. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the paper\\'s writing of \"sampling class-imbalanced tasks\" in the context of few-shot learning. It asks how to set a reasonable class-imbalanced task, which is a valid concern regarding the clarity and specificity of the paper\\'s description. However, the comment does not provide any evidence, reasoning, or references to support the claim that the paper lacks clarity or specificity in this regard. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the paper\\'s writing of \"sampling class-imbalanced tasks\" in the context of few-shot learning. It specifically asks how to set a reasonable class-imbalanced task, which is a valid concern regarding the clarity and specificity of the paper\\'s description. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their writing. While it identifies a potential area for improvement, it lacks actionable advice, making it somewhat helpful. The authors would need to infer how to address the issue themselves, which limits the comment\\'s usefulness. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the chat-GPT baseline is rudimentary and that few-shot approaches should be tested. It also recommends including discourse relation information in the prompts, possibly using a Chain-of-Thought style, to potentially improve the results. However, the comment does not provide explicit guidance on how to implement these suggestions or actions. The feedback is somewhat vague, as it lacks detailed instructions on how to test the few-shot approach or how to incorporate the discourse relation information into the prompts. Therefore, the comment is somewhat actionable, aligning with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the chat-GPT baseline, noting that it is rudimentary and that few-shot approaches are not tested. It also suggests that including discourse relation information in the prompts, possibly using a Chain-of-Thought style, could yield good results. However, the comment does not specify which part of the paper discusses the chat-GPT baseline or the few-shot approach, making it weakly grounded. The comment is specific in suggesting improvements, such as testing few-shot approaches and incorporating discourse relation information, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the chat-GPT baseline is rudimentary and that few-shot approaches are not tested. It suggests that including discourse relation information in the prompts, possibly using a Chain-of-Thought style, could yield good results. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is somewhat verifiable as it provides a general idea but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a weakness in the paper by pointing out that the chat-GPT baseline is rudimentary and that few-shot approaches are not tested. It also suggests that including discourse relation information in the prompts, possibly using a Chain-of-Thought style, could yield better results. While the comment provides some actionable feedback, it lacks depth and specificity, as it does not offer detailed guidance on how to implement these suggestions or how to evaluate the results. The feedback is somewhat helpful, as it directs the authors to areas for improvement but does not provide comprehensive advice. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of detail in the explanation of how the ground truth of sensitivity is achieved. It points out that the paper mentions estimating sensitivity by pruning but does not provide details on how the actual pruning was performed. This feedback is explicit, as it directly instructs the authors to include more information about the pruning process. However, the action is somewhat vague because it does not specify exactly what details need to be added or how the pruning process should be described. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 238-239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly points out the lack of detail in explaining how the ground truth of sensitivity is achieved, specifically mentioning the absence of information on the pruning process. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not explain how the ground truth of sensitivity is achieved, specifically noting that lines 238-239 mention estimating sensitivity by pruning but lack details on the actual pruning process. This claim is somewhat verifiable as it identifies a gap in the explanation but does not provide specific examples or references to support the assertion. The authors would need to infer the missing details, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors lack detail, namely the explanation of how the ground truth of sensitivity is achieved. It points out that the paper mentions estimating sensitivity by pruning but does not provide sufficient information on the actual pruning process. This feedback is clear and actionable, as it directs the authors to include more details about the methodology used to determine the ground truth of sensitivity. By addressing this feedback, the authors can improve the clarity and completeness of their paper, making the comment highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the results comparing standard- vs. evolutional dropout on shallow models should be presented as a mean over many runs (at least 10), ideally with error-bars. It also points out that the plotted curves are from single runs, which might be subject to significant fluctuations, and that the models are small, making it an excuse for not providing statistics. The comment provides clear guidance on how the authors should present their results, including specific actions such as calculating means over multiple runs and including error bars. This explicit and detailed feedback allows the authors to directly address the issue and improve their presentation of the results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the results comparing standard- vs. evolutional dropout on shallow models, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how the results should be presented, including the need to present them as a mean over many runs (at least 10) with error bars, and highlights the issue with the plotted curves being from single runs. This detailed feedback helps the authors understand what needs to be addressed and how to improve their presentation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results comparing standard- vs. evolutional dropout on shallow models should be presented as a mean over many runs (at least 10) with error bars. This claim is somewhat verifiable as it provides a specific suggestion for improving the presentation of results, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors are encouraged to consider the potential impact of single-run fluctuations on the interpretation of the results, which could be addressed by presenting the data more robustly. However, the comment could be more convincing with additional justification or examples to support the need for this change. Therefore, it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the presentation of results, suggesting that the comparison between standard and evolutional dropout on shallow models should be presented as a mean over many runs with error bars. This is a clear and actionable suggestion that addresses a potential issue with the current presentation of results, which could be subject to significant fluctuations due to single runs. By providing this guidance, the comment helps the authors improve the robustness and reliability of their findings. However, the comment could be more helpful if it included additional suggestions or considerations for the analysis of the results. Overall, the feedback is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment provides specific feedback on the clarity of a paragraph (L156-166) and suggests that the authors should clarify the use of bandit algorithms and the explanation of the Gittins strategy. It also points out that the figure is hard to understand and that the explanation of dashed lines is vague. While the comment identifies areas for improvement, it does not explicitly instruct the authors on how to clarify these sections or provide concrete guidance on what specific changes to make. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the issues. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific section of the paper (L156-166), allowing the authors to accurately identify the part being addressed. It also provides specific feedback on the clarity of the paragraph, the use of bandit algorithms, the explanation of the Gittins strategy, and the difficulty in understanding the figure. The comment is specific in detailing what needs to be clarified or improved, such as the explanation of bandit algorithms and the vagueness of the figure's explanation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paragraph is barely understandable, despite the reviewer's expectation that they understand what is being said. It also critiques the use of bandit algorithms, specifically mentioning the Gittins strategy and the Markov chain nature of posterior evolution. The comment highlights the difficulty in understanding the figure, noting that the explanation of dashed lines is vague. However, the comment lacks specific examples or detailed reasoning to support these claims, making it somewhat verifiable. The authors would need to infer the basis for the critique, which limits the verifiability of the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the clarity of a paragraph (L156-166) and suggests that the authors should clarify the use of bandit algorithms and the explanation of the Gittins strategy. It also points out that the figure is hard to understand and that the explanation of dashed lines is vague. While the comment identifies areas for improvement, it does not offer detailed guidance on how to clarify these sections or provide concrete suggestions for improvement. The feedback is somewhat helpful as it highlights specific issues that need attention, but it lacks depth and actionable advice, making it only somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should mention the evaluation metric used in the paper to improve clarity and understanding of the results. It provides a specific example of where this information is missing, namely lines 078-079 and line 08. However, the comment does not explicitly instruct the authors on how to incorporate this information or what specific metric should be mentioned. While the action is implied, it is vague and lacks concrete guidance on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines of the paper (078-079 and 08), allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the inclusion of the evaluation metric for clarity and comparability. This provides clear guidance on how to improve the paper, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation metric should be mentioned for clarity and comparability, providing a specific example of where this information is missing. However, the comment lacks detailed reasoning or examples to fully support the claim. It does not provide references or logical reasoning to justify why mentioning the evaluation metric is crucial for understanding the results. As a result, the claim is somewhat verifiable, as it is partially supported but lacks depth and clarity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the paper by suggesting that the evaluation metric should be mentioned for clarity and comparability. It provides a concrete example of where this information is missing, specifically in lines 078-079 and line 08. By highlighting the importance of including the evaluation metric, the comment offers a clear and actionable suggestion for the authors to enhance the understanding and comparability of their results. This feedback is mostly helpful as it directs the authors to a specific aspect of the paper that needs attention, but it could be more comprehensive if it suggested additional improvements or provided more detailed guidance. Therefore, the comment is rated as mostly helpful.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises an interesting question about the performance of DVP on video with varying lengths. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or what steps they should consider to improve their draft. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises an interesting question about the performance of DVP on video with different lengths, but it does not specify which part of the paper this question relates to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance or suggestions on how to address this question or what aspects of the paper need to be revised. Therefore, the comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises an interesting question about the performance of DVP on video with different lengths, but it does not provide any specific claims, opinions, or suggestions. It is a question that prompts further exploration or discussion but does not offer any guidance or evidence to support it. Therefore, it is classified as \"No\" because it lacks a claim or assertion that requires verification.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an interesting question about the performance of DVP on video with different lengths, which could be a valuable point for discussion or further exploration. However, it does not provide any specific feedback, suggestions, or guidance on how the authors might address this question or what aspects of their work could be improved. Without actionable insights or constructive feedback, the comment is barely helpful, as it offers minimal value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should evaluate the approximation error of the proposed training objective by calculating the actual KL-divergence and checking whether it approaches zero. This provides a clear and concrete action for the authors to take, as they know exactly what needs to be done to address the issue. The comment is fully actionable because it specifies the exact steps required to implement the suggested improvement. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Section 3.3,\" providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed training objective has ignored the KL-divergence term in equation (3) and suggests evaluating the approximation error by calculating the actual KL-divergence and checking whether it approaches zero. This level of detail makes the comment specific, as it clearly identifies what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a specific concern about the proposed training objective in Section 3.3, noting that it has ignored the KL-divergence term in equation (3). The comment suggests evaluating the approximation error by calculating the actual KL-divergence and checking whether it approaches zero. However, the comment does not provide any supporting evidence, examples, or references to substantiate the claim that the approximation error is significant. Without additional context or justification, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue in Section 3.3, where the proposed training objective has ignored the KL-divergence term in equation (3). It suggests that the authors evaluate the approximation error by calculating the actual KL-divergence and checking whether it approaches zero. This feedback is actionable and provides a clear direction for the authors to improve their draft by addressing the identified gap in their analysis. However, the comment could be more helpful if it included additional guidance on how to calculate the KL-divergence or suggested specific experiments to validate the approximation error. Despite this, the comment is mostly helpful as it offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should further discuss or explore which situations the losses help in particular, such as for specular areas. While the comment implies an action, it does not explicitly instruct the authors to provide a detailed discussion or analysis of these situations. The action is somewhat vague, as it leaves the authors to infer the exact nature of the discussion needed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests further discussion on the situations where losses help, specifically mentioning specular areas. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its focus on specular areas, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should further discuss or explore which situations the losses help in particular, such as for specular areas. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should further discuss or explore which situations the losses help in particular, such as for specular areas. This feedback is somewhat helpful as it points out a potential area for additional discussion that could enhance the paper's depth and clarity. However, the comment lacks specificity and does not provide detailed guidance on how to address this suggestion, leaving the authors with limited actionable advice. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the major contributions of the paper and criticizes the approach of analyzing previous work as a contribution. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment suggests that the authors should clarify their contributions and reconsider their approach to analyzing previous work, but it does not offer specific guidance on how to do so. Without concrete suggestions or actions, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper is unclear regarding its major contributions or critique the approach of analyzing previous work as a contribution. The authors cannot confidently determine which section or aspect of the paper is being addressed, making it difficult to understand the feedback and apply it effectively. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that it is unclear what the major contributions of the paper are and that analyzing previous work does not constitute a contribution. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. Without detailed reasoning or evidence, the claim is unverifiable, as it does not provide a clear path for the authors to improve their work. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of clarity regarding the major contributions. It also critiques the approach of analyzing previous work as a contribution, which is a valuable piece of feedback. However, the comment lacks specific suggestions or guidance on how the authors might address these issues. While it highlights a critical area for improvement, the absence of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out important weaknesses but does not provide detailed guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two specific issues with the paper: the lack of explanation on how to determine n_t in Algorithm 2 and the ambiguity of the term \"appropriate number\" in line 225. While the comment identifies these areas, it does not provide explicit instructions or concrete guidance on how the authors should address these issues. The authors are left to infer that they need to clarify the determination of n_t and provide a more precise definition of \"appropriate number.\" This lack of explicit and detailed guidance makes the comment somewhat actionable, as the authors can infer the necessary steps but do not have a clear roadmap for implementation. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses issues with Algorithm 2 and line 225, specifically regarding the determination of n_t and the ambiguity of \"appropriate number.\" However, it does not explicitly mention which part of the paper these issues are located in, such as a specific section or table. This makes it challenging for the authors to pinpoint the exact areas that need revision. While the comment is specific in detailing the problems, the lack of grounding makes it difficult for the authors to fully understand and address the issues. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the determination of n_t in Algorithm 2 and the meaning of \"appropriate number\" in line 225. It suggests that the authors should clarify these aspects, but it does not provide specific examples or references to support the claim that the current explanation is unclear or missing. The comment lacks detailed reasoning or evidence to substantiate the need for clarification, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies two specific issues in the paper: the lack of explanation on how to determine n_t in Algorithm 2 and the ambiguity of the term 'appropriate number' in line 225. While the comment points out these areas, it does not provide detailed guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it highlights areas that need clarification, but it lacks depth and actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point criticizes the claim that \"in practice the mixing time is even better\" and argues that this claim is not sufficiently supported by the experiments. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or strengthen their evidence. The comment lacks explicit instructions on what actions the authors should take to improve their draft, leaving them without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim \"in practice the mixing time is even better\" and questions its support by the experiments. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of sufficient support for the claim. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the claim \"in practice the mixing time is even better\" is not sufficiently supported by the experiments. However, the comment does not provide specific examples, references, or detailed reasoning to substantiate this claim. Without additional evidence or context, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the claim \"in practice the mixing time is even better\" is not sufficiently supported by the experiments. This feedback is clear and actionable, as it highlights a gap in the evidence provided to practitioners. However, the comment could be more helpful if it suggested specific ways the authors could strengthen their evidence or provide additional experimental results. Despite this, the comment offers valuable guidance for improving the paper, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests extending the protected feature A to a vector form, providing an example of how this could be done. It implies that the authors should consider this extension, but it does not explicitly instruct them to do so or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should extend the feature and understand the implications of such an extension. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests extending the protected feature A to a vector form, providing an example of how this could be done. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section or context. The comment is specific in its suggestion but lacks grounding as it does not provide clear references or context within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests extending the protected feature A to a vector form, providing an example of how this could be done. However, it does not offer any justification or reasoning for why this extension is necessary or beneficial. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests extending the protected feature A to a vector form, providing an example of how this could be done. This feedback is specific and actionable, as it offers a clear direction for the authors to consider in their work. However, it lacks depth and does not provide detailed reasoning or examples to fully justify the suggestion. While it offers a starting point for improvement, the comment could be more helpful if it included additional context or elaborated on the potential benefits of such an extension. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific suggestions for improving the clarity and detail of the paper. It suggests that the authors denote the vector representations of words in the equation, clarify whether the vectors are L2-normalized, and specify the method used for computing nearest neighbor examples (cosine or dot product). These suggestions are explicit and concrete, as they directly instruct the authors on what needs to be done to enhance the paper. The comment is fully actionable, as it provides clear guidance on how to address the identified issues. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed suggestions for improving the clarity of the notation, the normalization of vectors, and the method used for computing nearest neighbor examples. The authors are guided on what specific aspects need attention, making the comment both fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the notation, normalization, and computation of nearest neighbor examples in the paper. It suggests that the authors denote the vector representations of words, clarify whether the vectors are L2-normalized, and specify the method used for computing nearest neighbor examples (cosine or dot product). However, the comment does not provide any evidence or reasoning to support these suggestions or claims. The authors are left to interpret and address these points themselves, which limits the verifiability of the feedback. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the clarity and detail of the paper. It requests that the authors denote the vector representations of words in the equation, clarify whether the vectors are L2-normalized, and specify the method used for computing nearest neighbor examples (cosine or dot product). These suggestions are actionable and detailed, offering clear guidance on how to enhance the paper. By addressing these points, the authors can improve the clarity and completeness of their work. The comment is mostly helpful as it provides a comprehensive set of actionable feedback, though it could be further expanded to include additional areas for improvement. Therefore, it is rated as 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the novelty of the proposed transductive method, suggesting it is similar to a common approach in semi-supervised learning, specifically self-training methods. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might improve the novelty of their method or what specific aspects need to be clarified or differentiated from existing methods. As a result, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a concern about the novelty of the proposed transductive method, suggesting it is similar to a common approach in semi-supervised learning, specifically self-training methods. However, it does not specify which part of the paper this concern relates to, such as a particular section, table, or figure. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide details on what aspects of the method need to be clarified or differentiated from existing approaches. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point expresses a concern about the novelty of the proposed transductive method, suggesting it is similar to a common approach in semi-supervised learning, specifically self-training methods. However, the comment lacks specific evidence or references to support this claim. It does not provide detailed reasoning or examples to substantiate the assertion that the method is not novel. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the novelty of the proposed transductive method, suggesting it is similar to a common approach in semi-supervised learning, specifically self-training methods. This feedback highlights a potential gap in the paper's contribution and could guide the authors to clarify or differentiate their method from existing techniques. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. While it identifies an important issue, the feedback is somewhat limited in its actionable value, making it somewhat helpful. Therefore, the comment aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the feature comparison with prior work is shallow and lacks two relevant papers. However, it does not provide any explicit or implicit actions for the authors to take. The comment suggests that the authors should include these two relevant papers in their comparison, but it does not specify how to do so or what aspects of the comparison should be addressed. Without concrete guidance, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the feature comparison with prior work is shallow and lacks two relevant papers. However, it does not specify which part of the paper this comparison is located in, making it difficult for the authors to identify the exact section that needs improvement. While the comment is specific about the issue of a shallow comparison, it lacks grounding as it does not provide explicit references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the feature comparison with prior work is shallow and lacks two relevant papers. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the feature comparison section, noting that it is shallow and lacks two relevant papers. This feedback is clear and actionable, as it directs the authors to include these missing references in their comparison. However, the comment could be more helpful if it provided suggestions on how to integrate these references or what aspects of the comparison should be addressed. Despite this, the comment offers a clear direction for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should be more cautious in their usage of the word \"equivalent,\" especially if the equivalence is not verified. This comment provides an explicit action for the authors to take, which is to reconsider their usage of the word and ensure that it is appropriate and verifiable. The suggestion is clear and concrete, giving the authors a specific direction to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific line numbers (8, 56, 70, 93) where the usage of the word \"equivalent\" is discussed. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests a more cautious usage of the word, especially if the equivalence is not verified. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should be more cautious in their usage of the word \"equivalent,\" especially if the equivalence is not verified. This comment is somewhat verifiable as it provides a suggestion for improvement but lacks specific examples or references to support the claim. While it implies that the authors should reconsider their usage, it does not provide detailed guidance or evidence to help them understand why the word might be problematic or how to verify the equivalence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of the word \"equivalent\" in the paper, suggesting that the authors should be more cautious in their usage, especially if the equivalence is not verified. This feedback is clear and actionable, providing the authors with a specific area to address in their draft. By recommending a more cautious approach, the comment helps the authors improve the accuracy and clarity of their writing. However, the comment could be more helpful if it provided additional guidance on how to verify the equivalence or suggested alternative terms. Overall, the comment is mostly helpful as it highlights a specific issue and offers a clear direction for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the effectiveness of the multi-view clustering approach, specifically questioning why other views are useful if the paraphrase similarity view performs significantly better. It suggests that the authors should provide a more detailed analysis of the differences and similarities between the views to draw solid conclusions. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to perform a detailed analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the effectiveness of the multi-view clustering approach, specifically questioning the usefulness of other views given the superior performance of the paraphrase similarity view. It suggests that the authors should provide a more detailed analysis of the differences and similarities between the views to draw solid conclusions. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or figure. This makes it weakly grounded, as the authors cannot confidently determine where the issue lies. The comment is specific in its critique of the lack of detailed analysis regarding the differences between views, but without explicit grounding, it is difficult for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the effectiveness of the multi-view clustering approach, specifically questioning the usefulness of other views given the superior performance of the paraphrase similarity view. It suggests that the authors should provide a more detailed analysis of the differences and similarities between the views to draw solid conclusions. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the other views are not useful. The lack of evidence or justification makes the claim somewhat verifiable, as the authors are left to infer the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the effectiveness of the multi-view clustering approach, specifically questioning the usefulness of other views given the superior performance of the paraphrase similarity view. It points out that while the paraphrase similarity view performs significantly better, the authors do not provide a detailed analysis of how the different views differ or how they contribute to the clustering task. This feedback is somewhat helpful as it highlights a potential gap in the analysis and encourages the authors to provide a more comprehensive evaluation of the different views. However, the comment could be more helpful if it offered specific suggestions or guidance on how to conduct this analysis, such as suggesting additional empirical examples or analytical techniques. Overall, the comment provides a clear direction for improvement but lacks detailed guidance, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the explanation of the architecture used for the experiments, noting that the authors refer to Jiang et al. (2019) for details. This implies that the authors need to provide a more detailed explanation of the architecture within the paper to make it self-contained. However, the comment does not specify exactly what aspects of the architecture need clarification or how the authors should elaborate on it. While the action is implied, it is vague and lacks concrete guidance on what needs to be done. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"architecture used for the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue: the lack of clarity in the explanation of the architecture and the reliance on Jiang et al. (2019) for details, which makes the paper not self-contained. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the architecture used for the experiments is not clearly explained in the paper, as the authors refer to Jiang et al. (2019) for details. This makes the paper not self-contained. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or logical arguments to substantiate the assertion that the explanation is unclear or insufficient. As a result, the claim is not fully verifiable, aligning with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the architecture used for the experiments is not clearly explained, and the authors rely on Jiang et al. (2019) for details. This makes the paper not self-contained, as readers may not have access to the cited work. The comment is clear and actionable, as it directs the authors to provide a more detailed explanation of the architecture within the paper. However, it could be more helpful if it suggested specific areas where the explanation could be improved or provided examples of how to enhance clarity. Overall, the comment is mostly helpful, as it effectively highlights a critical issue and provides a clear direction for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights an inconsistency in the typesetting of BertScore and BLEURT throughout the paper, suggesting that maintaining consistency would be beneficial. While the comment identifies a specific issue, it does not provide explicit guidance on how to achieve consistency or what steps the authors should take to address this. The action is implicit, as the authors would need to infer that they should ensure consistent formatting of these terms. However, the lack of concrete instructions on how to implement this change makes the comment somewhat actionable. Therefore, this comment aligns with a score of 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"BertScore\" and \"BLEURT,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of inconsistent typesetting and suggests a solution: maintaining consistency. This provides the authors with clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that BertScore and BLEURT are inconsistently typeset throughout the paper, suggesting that maintaining consistency would be beneficial. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why this inconsistency exists or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the typesetting of BertScore and BLEURT throughout the paper, noting that they are inconsistently typeset as Bertscore or Bleurt. This observation is clear and actionable, as it points out a minor but noticeable inconsistency that could affect the readability and professionalism of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending a specific formatting style or providing examples of consistent usage. While the feedback is somewhat helpful, it lacks depth and could be more impactful with additional suggestions or recommendations. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies several specific issues with the presentation quality of the paper, such as the lack of informativeness in tables, the management of figures and tables, and the meaning of a \"*\" in Table 1. However, it does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve the presentation. The actions are implicit and vague, as the authors are left to infer how to make the necessary changes. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figs 1&2,\" \"tables with a \\\"-\\\" for the method,\" \"the \\\"Dataset\\\" columns in the tables,\" \"the management of Fig 3 and Table 2,\" and a \"*\" in Table 1. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it details several issues with the presentation quality, such as the lack of informativeness in tables, the management of figures and tables, and the meaning of a \"*\" in Table 1. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some aspects of the presentation quality in the paper are weaknesses for a high-quality publication, such as NeurIPS. It provides specific examples of issues, including the lack of informativeness in tables, the management of figures and tables, and the meaning of a \"*\" in Table 1. However, the claim lacks detailed reasoning or references to support why these issues are significant or how they impact the paper's quality. The comment is somewhat verifiable as it provides some justification but lacks depth and specific examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several specific weaknesses in the presentation quality of the paper, such as the lack of informativeness in tables, the management of figures and tables, and the meaning of a \"*\" in Table 1. While the comment provides a clear overview of these issues, it lacks detailed guidance on how the authors might address them or what specific improvements could be made. The feedback is somewhat helpful as it highlights areas for improvement, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper uses analysis to justify the use of the information axis as a tool. It also points out that the conclusion mentions the need for related experiments to demonstrate the tool's effectiveness. However, the comment does not provide explicit guidance on how the authors should conduct these experiments or what specific aspects of the information axis tool need to be explored. The action is implicit and somewhat vague, as the authors are left to infer that they need to add experiments to support their claims. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper uses analysis to justify the use of the information axis as a tool, noting that the conclusion mentions the need for related experiments. However, it does not specify which part of the paper this analysis is located in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific about the need for additional experiments, it lacks grounding as it does not provide clear guidance on which part of the paper should be revised. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper uses analysis to justify the use of the information axis as a tool, noting that the conclusion mentions the need for related experiments. However, the comment does not provide specific examples or references to support the claim that the analysis is insufficient or that the experiments would effectively demonstrate the tool's effectiveness. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as the authors are left to infer the need for additional experiments. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the paper could benefit from additional experiments to demonstrate the effectiveness of the information axis tool. While it points out the need for related experiments, it does not provide specific guidance on what these experiments should entail or how they might be conducted. This feedback is somewhat helpful as it highlights a potential weakness in the paper and suggests a direction for improvement, but it lacks depth and specificity, leaving the authors with limited actionable advice. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the text in lines 293-295 is unclear and difficult for readers to understand and evaluate. It suggests that the authors should clarify the statement by providing more context or explanation. However, the comment does not specify how the authors should clarify the statement or what additional information would make it clearer. The action is implicit and vague, as it requires the authors to infer the need for clarification and then decide how to implement it. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 293-295, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the text in these lines is unclear and difficult for readers to understand and evaluate, suggesting that the authors should clarify the statement by providing more context or explanation. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the text in lines 293-295 is unclear and difficult for readers to understand and evaluate. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the text is unclear or how to improve its clarity. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the text in lines 293-295, noting that it is unclear and difficult for readers to understand and evaluate. The comment suggests that the authors should clarify the statement by providing more context or explanation. While the comment highlights a potential area for improvement, it lacks specific guidance on how to clarify the text or what additional information would make it clearer. This feedback is somewhat helpful as it points out a need for improvement but does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant issue with the organization and clarity of the proofs in the paper, noting that many proofs lack clean logic and are difficult to follow. It provides a specific example, questioning whether the result in Lemma 3 holds for any polynomial function $P(\\gamma)$. While the comment identifies a clear area for improvement, it does not provide explicit guidance on how the authors should reorganize the proofs or address the specific issue with Lemma 3. The action is implicit, as the authors would need to infer that they should improve the organization and clarity of the proofs and address the specific question about Lemma 3. However, the lack of concrete instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the organization and clarity of the proofs, providing a clear example of what needs to be addressed. The comment specifies that the authors should reorganize the proofs to improve their logic and readability, and it raises a specific question about Lemma 3, which requires further clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof is \"extremely not well organized\" and that many proofs lack \"clean logic and are very hard to follow,\" making it difficult to rigorously check the correctness of the proof. The comment provides a specific example, questioning whether the result in Lemma 3 holds for any polynomial function $P(\\gamma)$. However, the claim lacks detailed reasoning or examples to fully substantiate the assertion about the organization and clarity of the proofs. While the comment provides a basis for improvement, it does not offer specific guidance or evidence to support the claim comprehensively. Therefore, the comment is somewhat verifiable, as it provides some justification but lacks depth and detail.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the organization and clarity of the proofs in the paper, noting that many proofs lack clean logic and are difficult to follow, making it challenging to rigorously check their correctness. The comment provides a specific example, questioning whether the result in Lemma 3 holds for any polynomial function $P(\\gamma)$. This feedback is valuable as it highlights a critical area for improvement, suggesting that the authors should reorganize the proofs to enhance their logic and readability. However, the comment could be more helpful if it provided additional guidance on how to reorganize the proofs or addressed the specific question about Lemma 3. Overall, the comment is mostly helpful, as it offers clear feedback on an important aspect of the paper that needs improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should conduct experiments on real-world datasets instead of synthetic ones, particularly for the out-of-distribution setting. This provides a clear and explicit action for the authors to take, as they can directly address this suggestion by incorporating experiments on real-world datasets. The comment is specific in its recommendation, detailing what kind of experiments would be beneficial. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting experiments on real-world datasets instead of synthetic ones, particularly for the out-of-distribution setting. However, it does not specify which part of the paper discusses the experiments or the out-of-distribution setting, making it difficult for the authors to identify the exact section or part that needs revision. While the comment is specific about the type of experiments, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should conduct experiments on real-world datasets instead of synthetic ones, particularly for the out-of-distribution setting. This claim is somewhat verifiable as it provides a logical reasoning for why real-world datasets might be more appropriate for evaluating the paper's claims. However, it lacks specific examples or references to support the suggestion, which could make it less robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper should conduct experiments on real-world datasets instead of synthetic ones, particularly for the out-of-distribution setting. This feedback is clear and actionable, as it provides a specific direction for improving the paper by aligning the experiments with real-world scenarios. By recommending the use of real-world datasets, the comment addresses a potential gap in the paper's evaluation and suggests a way to enhance its practical relevance. However, it could be more helpful if it provided additional guidance on how to select or implement these experiments. Overall, the comment is mostly helpful, as it offers a clear and actionable suggestion that would benefit the authors.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the proposed approach to pretraining has limited novelty because it more or less follows the strategies used in ELECTRA. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might enhance the novelty of their approach or what specific aspects need to be improved. Without concrete suggestions or actions, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the proposed approach to pretraining has limited novelty because it follows strategies similar to those used in ELECTRA. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to pinpoint the exact section or aspect being addressed. The comment is specific in its critique of novelty but lacks grounding as it does not provide clear references or sections to support the claim. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed approach to pretraining has limited novelty because it more or less follows the strategies used in ELECTRA. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without detailed reasoning or references, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the novelty of the proposed approach to pretraining, noting that it closely resembles strategies used in ELECTRA. While this observation highlights a specific area for improvement, it lacks depth and actionable suggestions for the authors to address the issue. The comment does not provide guidance on how the authors might enhance the novelty of their approach or what specific aspects need to be improved. As a result, the feedback is somewhat helpful, as it points out a potential weakness but does not offer comprehensive or detailed advice for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the motivation for the Newton algorithm in section 4 is lacking, as it is essentially a 1-dimensional line search on a convex function, which converges linearly. The reviewer questions the impact of this on the algorithm's runtime and suggests that experiments could help motivate the need for the analysis/algorithm. While the comment implies that the authors should consider adding experiments to address this concern, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct experiments to demonstrate the impact of the Newton algorithm. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the motivation for the Newton algorithm, suggesting that it is essentially a 1-dimensional line search on a convex function and questioning the impact of this on the algorithm\\'s runtime. The comment provides a clear and specific request for additional experiments to motivate the need for the analysis/algorithm. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation for the Newton algorithm in section 4 is lacking, suggesting that it is essentially a 1-dimensional line search on a convex function, which converges linearly. The reviewer questions the impact of this on the algorithm\\'s runtime and suggests that experiments could help motivate the need for the analysis/algorithm. However, the comment lacks specific examples or references to support the claim that the Newton algorithm is merely a linearly converging line search. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the motivation for the Newton algorithm in section 4, suggesting that it is essentially a 1-dimensional line search on a convex function that converges linearly. The reviewer questions the impact of this on the algorithm's runtime and recommends that experiments be conducted to demonstrate the need for the analysis/algorithm. This feedback is somewhat helpful as it points out a specific area that could be strengthened by additional experiments. However, the comment could be more helpful if it provided more detailed guidance on how to conduct these experiments or suggested specific experiments that could be performed. Overall, the comment offers a clear direction for improvement but lacks depth, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the proposed upweighing and KNN methods, suggesting that their impact on idiomatic vs. random data is similar, which implies that the results may not be specific to idiom-specific performance. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes might be necessary to make the results more idiom-specific. The action is implicit and vague, as it does not offer concrete steps for improvement. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the proposed upweighing and KNN methods, referencing Figure 3 to support its claims. However, it does not specify which part of the paper Figure 3 is located in, making it weakly grounded. The comment is specific in detailing the issue with the methods and the interpretation of the results, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the impact of the proposed MT modeling methods on idiomatic vs. random data is similar, suggesting that the results may not be specific to idiom-specific performance. The comment provides a logical reasoning based on the observation that the impact is similar across different language and score combinations, as shown in Figure 3. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the basis of the claim, which could be improved with more detailed reasoning or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the proposed upweighing and KNN methods, suggesting that their impact on idiomatic vs. random data is similar, which implies that the results may not be specific to idiom-specific performance. The comment implies that the results simply indicate that \"better NMT systems are also better at idiomatic translations,\" which is a critical observation. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their methods to better capture idiom-specific performance. While it identifies a significant weakness, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the consistency of the number of biases across different parts of the paper, specifically noting that the authors mention having C biases in section 3.4 but only find one hyper-parameter for the feed-forward models. This feedback is explicit and provides a clear action for the authors to take: they should clarify the discrepancy in the number of biases and ensure consistency throughout the paper. The comment is specific and actionable, as it directly points out a potential issue and suggests a concrete step for the authors to address it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 77,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the confusion regarding the number of biases, noting that the authors mention having C biases in section 3.4 but only find one hyper-parameter for feed-forward models. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the consistency of the number of biases across different parts of the paper. It highlights a potential confusion regarding the number of biases, noting that the authors mention having C biases in section 3.4 but only find one hyper-parameter for feed-forward models. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the number of biases is inconsistent. Without further elaboration or evidence, the authors may find it challenging to fully understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks detailed justification or examples.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue regarding the consistency of the number of biases across different parts of the paper. It points out that while the authors mention having C biases in section 3.4, they only find one hyper-parameter for the feed-forward models described in section 3.4. This inconsistency creates confusion and suggests that the authors need to clarify their approach to handling biases. The comment is clear and actionable, providing a direct suggestion for the authors to address the discrepancy. However, it could be more helpful if it offered additional guidance on how to resolve the issue or suggested specific steps to take. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests showing smoothed ground truth (GT) shapes in Figure 3 and Figure 5 to help readers better understand the quality of the reconstruction. However, it does not provide any explicit guidance on how to implement this suggestion, such as which specific elements of the figures should be highlighted or how the smoothing process should be visualized. The action is implicit and vague, as it leaves the authors without a clear understanding of how to apply the suggestion. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests showing smoothed ground truth shapes in Figure 3 and Figure 5, which provides some grounding as it mentions specific figures. However, it does not specify which parts of the figures should be highlighted or how the smoothing process should be visualized, making the comment specific but not fully grounded. The lack of detail on what needs to be addressed in these figures makes it somewhat specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests showing smoothed ground truth shapes in Figure 3 and Figure 5 to help readers better understand the quality of the reconstruction. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would enhance the understanding of the reconstruction quality. The comment lacks detailed justification, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests showing smoothed ground truth shapes in Figure 3 and Figure 5 to help readers better understand the quality of the reconstruction. While this feedback is relevant and provides a clear direction for improvement, it lacks depth and specificity. The comment does not explain why showing smoothed ground truth shapes is crucial or how it would enhance the understanding of the reconstruction quality. Additionally, it does not offer any guidance on how to effectively present these shapes or what aspects of the figures should be highlighted. As a result, the comment is somewhat helpful, as it identifies an area for improvement but does not provide detailed or actionable suggestions. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the generalizability of the method to other domains and questions the selection of event types from Freebase. It asks for clarification on how these event types were selected and what coverage they provide on the 33 event types in the ACE data. While the comment identifies specific areas that need clarification, it does not provide explicit instructions or suggestions on how to address these concerns. The action is implicit, as the authors would need to infer that they should clarify the selection process and coverage. However, the lack of concrete guidance on how to implement this clarification makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the generalizability of the method to other domains and questions the selection of event types from Freebase. It specifically mentions Section 2 line 262, which indicates that 21 event types are selected from Freebase. However, the comment does not specify which part of the paper discusses the selection process or the coverage on the 33 event types in the ACE data. This makes it difficult for the authors to pinpoint the exact sections that need clarification. While the comment is specific about the concerns raised, it lacks full grounding as it does not provide explicit references to the sections or parts of the paper being addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the generalizability of the method to other domains and questions the selection of event types from Freebase. It specifically mentions Section 2 line 262, which indicates that 21 event types are selected from Freebase. However, the comment does not provide any justification or reasoning for why this selection is problematic or how it might affect the generalizability of the method. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises concerns about the generalizability of the method to other domains and questions the selection of event types from Freebase. It specifically mentions that 21 event types are selected from Freebase and asks for clarification on how these event types were chosen and what coverage they provide on the 33 event types in the ACE data. This feedback is somewhat helpful as it identifies a potential area of concern and prompts the authors to provide more details about their methodology. However, the comment lacks depth and does not offer specific suggestions or guidance on how to address the concerns, making it somewhat helpful but not fully comprehensive. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks important references for domain adaptation. It suggests that the authors should cite and discuss these references in the revised manuscript. This feedback is explicit and provides a clear action for the authors to take, which is to include and discuss the missing references. The comment is specific in its suggestion, guiding the authors on what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"domain adaptation,\" allowing the authors to accurately identify the part of the paper that needs improvement. It is also specific because it clearly specifies that the authors should cite and discuss important references for domain adaptation. This provides the authors with a clear understanding of what needs to be addressed in the revised manuscript. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks important references for domain adaptation. However, it does not provide any specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the paper is lacking in this regard. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of important references for domain adaptation. It provides a clear and actionable suggestion for improvement by recommending that the authors cite and discuss these references in the revised manuscript. This feedback is valuable as it directly addresses a critical gap in the paper's literature review, guiding the authors on what needs to be added to enhance the paper's comprehensiveness and credibility. Therefore, the comment is mostly helpful, as it offers clear and constructive guidance for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether EMA-weighting is used for other baseline models in Table 3, specifically \"Supervised\" and \\Pi. It suggests that knowing this would ensure a fair comparison, as all models should benefit from EMA. However, the comment does not provide explicit instructions or suggestions on how the authors should address this issue, such as adding a clarification or explanation in the paper. The action is implicit, as the authors need to infer that they should check the usage of EMA-weighting for other models and provide a justification for a fair comparison. While the action is somewhat concrete, it lacks explicit guidance on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of information regarding the use of EMA-weighting for baseline models like \"Supervised\" and \\Pi, which is crucial for ensuring a fair comparison. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the use of EMA-weighting in Table 3, specifically for baseline models like \"Supervised\" and \\Pi. It suggests that knowing whether these models also utilize EMA would ensure a fair comparison. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific concern about the use of EMA-weighting in Table 3, particularly for baseline models like \"Supervised\" and \\Pi. It questions whether these models also utilize EMA, which is important for ensuring a fair comparison. While the comment identifies a potential issue, it does not provide any suggestions or guidance on how the authors might address this concern or improve their draft. The feedback is somewhat helpful as it highlights a specific area that needs attention, but it lacks actionable advice or detailed suggestions, making it incomplete in its assistance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the SCNN model's performance on domain pricing, suggesting that it might be \"lucky\" due to hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and notes the suspiciously large distance to the next best model. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to improve their model or presentation. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to respond. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the SCNN model's performance on domain pricing, suggesting that it might be \"lucky\" due to hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and notes the suspiciously large distance to the next best model. However, the comment does not specify which part of the paper discusses the SCNN model or the domain pricing results, making it difficult for the authors to pinpoint the exact issue. While the comment is specific about the concerns raised, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the SCNN model's performance on domain pricing, questioning whether the chosen hyperparameters are at the end of the searched range and noting the suspiciously large distance to the next best model. However, the comment lacks specific evidence, examples, or references to support these claims. Without detailed reasoning or supporting data, the authors may find it challenging to fully understand and address the concerns raised. Therefore, the comment is considered borderline verifiable, as it provides some basis for questioning the results but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises concerns about the SCNN model's performance on domain pricing, specifically questioning whether the chosen hyperparameters are at the end of the searched range and noting the suspiciously large distance to the next best model. This feedback highlights potential issues with the model's generalization capabilities and suggests that the results might be due to chance rather than a robust model. However, the comment does not provide specific guidance on how the authors might address these concerns or what steps they should take to improve their model or presentation. While it identifies a potential weakness, it lacks actionable suggestions, making it somewhat helpful. The authors would need to infer how to respond, which limits the comment's overall impact.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that some aspects of the experimental setup were unclear or poorly motivated, specifically mentioning corpora and datasets. However, it does not provide explicit guidance on what needs to be clarified or how the authors should address these issues. The comment lacks concrete actions or suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that some aspects of the experimental setup were unclear or poorly motivated, specifically mentioning corpora and datasets. However, it does not specify which parts of the paper these issues relate to, such as specific sections or figures. This makes it difficult for the authors to pinpoint the exact areas that need clarification. While the comment is specific about the nature of the issues, it lacks grounding as it does not provide clear references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some aspects of the experimental setup were unclear or poorly motivated, specifically mentioning corpora and datasets. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors are left without a clear understanding of what specific issues need to be addressed. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity and motivation of the experimental setup, specifically mentioning corpora and datasets. However, it lacks detailed guidance or suggestions on how to address these issues. The comment is vague and does not provide actionable feedback, leaving the authors uncertain about how to improve their draft. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the size of the model in terms of depth or number of parameters compared to competing approaches. It also notes that while the authors mention the model consists of 4 hourglass modules, they do not specify the size of each module. This feedback is explicit and provides a clear action for the authors to take: they should provide more detailed information about the size of each hourglass module. However, the comment lacks specific guidance on how to determine or measure the size of each module, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the size of the model in terms of depth or number of parameters, specifically mentioning that the model consists of 4 hourglass modules but does not specify the size of each module. This provides a clear reference to a specific part of the paper, allowing the authors to identify the relevant section. However, the comment does not specify what needs to be addressed in this part, such as how the size of the model compares to competing approaches or why the size is important. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the size of the model in terms of depth or number of parameters, specifically mentioning that the model consists of 4 hourglass modules but does not specify the size of each module. This feedback is clear and provides a specific question that the authors should address to improve the clarity and completeness of their paper. However, it does not offer any additional context or justification for why this information is important or how it relates to the overall work. Therefore, the comment is somewhat verifiable, as it provides a clear question but lacks depth in terms of supporting evidence or reasoning.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by questioning the size of the model in terms of depth or number of parameters compared to competing approaches. It points out that while the authors mention the model consists of 4 hourglass modules, they do not specify the size of each module. This feedback is clear and actionable, as it directs the authors to provide more detailed information about the model's architecture. However, the comment could be more helpful if it suggested specific ways to compare the model's size to other approaches or why this information is important. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a specific concern about the dimensions of the projection matrices in Section 1.2, suggesting that the current notation might be incorrect. It provides a potential correction, indicating that the dimensions should be $A_i \\in \\mathbb{R}^{d_i \\times m_i}$ to allow projection of a tensor $T \\in \\mathbb{R}^{d_1 \\times d_2 \\times \\ldots d_p}$. However, the comment does not explicitly instruct the authors to make this change or provide detailed guidance on how to verify the correctness of the dimensions. The action is implicit and somewhat vague, as the authors need to infer that they should correct the notation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the dimensions of the projection matrices, suggesting a potential correction. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a specific concern about the dimensions of the projection matrices in Section 1.2, suggesting that the current notation might be incorrect. The reviewer provides a potential correction, indicating that the dimensions should be $A_i \\in \\mathbb{R}^{d_i \\times m_i}$ to allow projection of a tensor $T \\in \\mathbb{R}^{d_1 \\times d_2 \\times \\ldots d_p}$. However, the comment lacks detailed reasoning or examples to fully support the claim, making it somewhat verifiable. The authors would need to infer the reasoning and potentially seek additional justification to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the dimensions of the projection matrices in Section 1.2, suggesting a potential correction. It provides a clear and actionable suggestion for the authors to consider, indicating that the dimensions should be $A_i \\in \\mathbb{R}^{d_i \\times m_i}$ to allow projection of a tensor $T \\in \\mathbb{R}^{d_1 \\times d_2 \\times \\ldots d_p}$. This feedback is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive if it included additional details or examples to fully guide the authors in addressing the issue. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the claim that the proposed method, PACE, addresses a gap by treating climate emulation as a diagnostic-type prediction. It points out that prior work, such as ClimateBench or ClimateSet, has already explored similar concepts. However, the comment does not provide explicit guidance on how the authors should revise their draft to clarify the distinction between their work and these prior studies. The action is implicit, as the authors need to infer that they should address the overlap with existing work. Additionally, the comment lacks concrete details on how to make the distinction clear, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim being made in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what is misleading about the claim, noting that prior work, such as ClimateBench or ClimateSet, has already addressed similar concepts. This provides clear guidance on how the authors should revise their draft to clarify the distinction. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper's claim about addressing a gap by proposing PACE as a diagnostic-type prediction is misleading because prior work, such as ClimateBench or ClimateSet, has already done this. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references or detailed explanations of how these prior works relate to the proposed method, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the claim made in the paper regarding the novelty of the proposed method, PACE. It points out that prior work, such as ClimateBench or ClimateSet, has already explored similar concepts, which could make the claim misleading. However, the comment does not provide specific guidance on how the authors should revise their draft to clarify the distinction between their work and these prior studies. While it highlights a potential area for improvement, it lacks actionable advice on how to address the issue, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests moving visual results from the supplementary material to the main paper, specifically noting the lack of visual results on crowd density estimation, which is a central experiment. It also recommends condensing the current figures to make space for these visual results. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on which figures to move or how to condense them. The action is somewhat vague, as the authors need to infer which figures to move and how to condense them to effectively utilize the space. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests moving visual results from the supplementary material to the main paper, specifically noting the lack of visual results on crowd density estimation, which is a central experiment. It also recommends condensing the current figures to make space for these visual results. However, the comment does not specify which figures are being referred to or how they should be condensed, making it weakly grounded. The comment is specific in its suggestion to include visual results on crowd density estimation, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact parts of the paper that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests moving visual results from the supplementary material to the main paper, specifically noting the lack of visual results on crowd density estimation, which is a central experiment. It recommends condensing the current figures to make space for these visual results. While the comment provides a clear rationale for the suggestion, it lacks specific examples or references to support the claim that the main paper lacks visual results on crowd density estimation. The suggestion is somewhat verifiable as it offers a logical reasoning but could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the organization of the paper, suggesting that visual results from the supplementary material should be moved to the main paper. It highlights the lack of visual results on crowd density estimation, a central experiment, and recommends condensing the current figures to make space for these visual results. This feedback is actionable and constructive, as it guides the authors on how to improve the presentation of their results and enhance the clarity of their main paper. However, the comment could be more helpful if it provided more detailed guidance on which figures to move or how to condense them effectively. Overall, the comment is mostly helpful, as it offers clear suggestions for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the importance of test examples and suggests exploring whether differences in the corpus (e.g., British vs. American) could affect the results. However, it does not provide explicit guidance on how to address this issue or what actions the authors should take to investigate it. The comment is vague and lacks concrete suggestions, making it difficult for the authors to understand how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the importance of test examples and suggests exploring whether differences in the corpus (e.g., British vs. American) could affect the results. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. The authors may infer that it relates to the discussion of test examples or the analysis of corpus residual value, but the lack of explicit mention makes it weakly grounded. The comment is specific in its question about the impact of corpus differences, but without clear grounding, it is difficult for the authors to pinpoint the exact area of concern. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the importance of test examples and suggests exploring whether differences in the corpus (e.g., British vs. American) could affect the results. However, it does not provide any specific reasoning, examples, or references to support the claim that this could be detected with corpus residual value. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a pertinent question about the importance of test examples and suggests exploring whether differences in the corpus could affect the results. It specifically asks if the 'British' patient in Figure 8 could be detected using the American corpus, which is a valuable point for consideration. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or what experiments could be conducted to investigate it. While it identifies a potential area for improvement, it does not provide detailed feedback or concrete steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of the testbed dataset, WebQuestionsSP, and suggests using the more popular WebQuestions benchmark set instead. It provides a rationale for this suggestion, explaining that WebQuestions is more intuitive and straightforward for weak supervision tasks and would facilitate direct comparison with mainstream QA research. However, the comment does not explicitly instruct the authors to change the dataset or provide specific guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider using the suggested dataset and understand the reasoning behind it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the choice of the testbed dataset, WebQuestionsSP, and suggests using the more popular WebQuestions benchmark set instead. It provides a rationale for this suggestion, explaining that WebQuestions is more intuitive and straightforward for weak supervision tasks and would facilitate direct comparison with mainstream QA research. However, the comment does not specify which part of the paper discusses the choice of the testbed dataset, making it difficult for the authors to identify the exact section being addressed. While the suggestion is specific, the lack of grounding makes it challenging for the authors to understand the context and apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of the testbed dataset, WebQuestionsSP, and suggests using the more popular WebQuestions benchmark set instead. The reasoning provided is that WebQuestions is more intuitive and straightforward for weak supervision tasks and would facilitate direct comparison with mainstream QA research. However, the comment lacks specific examples or references to support the claim that WebQuestions is more intuitive or straightforward for weak supervision tasks. Without detailed justification or evidence, the claim is somewhat verifiable, as it provides a rationale but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the choice of the testbed dataset, suggesting that the authors consider using the more popular WebQuestions benchmark set instead of WebQuestionsSP. The rationale provided explains why this change would be more intuitive and straightforward for weak supervision tasks, as it aligns with the requirements of the NSM method and facilitates direct comparison with mainstream QA research. This feedback is clear and actionable, as it provides a specific suggestion for improvement that the authors can easily implement. However, the comment could be more helpful if it included additional guidance on how to conduct the comparison or what specific aspects of the results would be relevant to consider. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be further enhanced with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should include an analysis or results on other datasets, specifically mentioning ImageNet derivatives, ImageNet-1k, and ImageNet-100. It implies that these results are important for verifying the effectiveness of the framework. However, the comment does not provide explicit guidance on how to present these results or what specific aspects of the framework should be analyzed on these datasets. The action is implicit and somewhat vague, as the authors are left to infer that they need to include these results in the main paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include an analysis or results on other datasets, specifically mentioning ImageNet derivatives, ImageNet-1k, and ImageNet-100. It implies that these results are important for verifying the effectiveness of the framework. However, the comment does not specify which part of the paper should be addressed or provide detailed guidance on how to present these results. The authors cannot confidently determine which section or figure this comment refers to, making it weakly grounded. The comment is specific in suggesting the inclusion of results on these datasets, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include an analysis or results on other datasets, specifically mentioning ImageNet derivatives, ImageNet-1k, and ImageNet-100, to verify the effectiveness of the framework. This claim is somewhat verifiable as it provides a clear direction for the authors to enhance their analysis. However, it lacks specific examples or references to support the suggestion, which could make it less robust. The authors would need to infer the need for additional results, which could be challenging. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap in the paper by noting that while improvements are shown on CIFAR derivatives, the analysis lacks results on other datasets, such as ImageNet derivatives, ImageNet-1k, and ImageNet-100. This feedback is valuable as it highlights an area where the authors could strengthen their evaluation of the framework's effectiveness. By suggesting the inclusion of these results, the comment provides a clear direction for improvement, though it could be more helpful if it offered specific guidance on how to present or analyze these results. Overall, the comment is somewhat helpful, as it points out a specific area for enhancement but lacks detailed suggestions.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the initial mention of BigFive and MBTI as models in the Abstract and Introduction sections and their subsequent use as datasets in the Experiments section. It suggests that the authors should either extend their explanation for using these as models or consider stating them as datasets throughout the paper. While the comment identifies a specific issue and provides a clear direction for addressing it, it does not explicitly instruct the authors on how to extend their explanation or provide detailed guidance on how to revise the paper. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the use of BigFive and MBTI as models in the Abstract and Introduction sections but inconsistently uses them as datasets in the Experiments section. It suggests that the authors should either extend their explanation for using these as models or consider stating them as datasets throughout the paper. However, the comment does not explicitly mention which part of the paper it is addressing, making it weakly grounded. It is specific in detailing the inconsistency and suggesting a possible solution, but without clear guidance on how to implement the suggestion, it is somewhat grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that BigFive and MBTI are used inconsistently as models and datasets throughout the paper. The comment suggests that the authors should either extend their explanation for using these as models or consider stating them as datasets throughout the paper. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the inconsistency and how to address it. Without detailed reasoning or evidence, the claim is somewhat verifiable, as it provides a general observation but lacks the necessary depth to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant inconsistency in the paper by pointing out that BigFive and MBTI are initially presented as models in the Abstract and Introduction but are later used as datasets in the Experiments section. This inconsistency raises concerns about the clarity and coherence of the paper. The comment suggests that the authors should either provide an extended explanation for using these as models or consider stating them as datasets throughout the paper. While the comment highlights a critical issue, it does not offer specific guidance on how to address the inconsistency or improve the clarity of the paper. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable suggestions, making it only somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should clarify the generalization to specific TSP instances, particularly the fine-tuning step in DIMES. It also recommends comparing DIMES with other methods on TSP100, both with and without meta-learning. While the comment provides a clear direction for improvement, it does not specify which parts of the paper need to be addressed or how the authors should implement these suggestions. The action is explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the generalization to specific TSP instances, particularly the fine-tuning step in DIMES, and suggests that the authors should clarify this aspect. It also recommends comparing DIMES with other methods on TSP100, both with and without meta-learning. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestions for improvement, such as clarifying the generalization and providing comparisons. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the generalization of the proposed method to specific TSP instances, particularly the fine-tuning step in DIMES. It suggests that the authors should clarify this aspect and provide comparisons with other methods on TSP100, both with and without meta-learning. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The feedback is somewhat verifiable as it provides a general direction but lacks the necessary depth and specificity to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the need for clarification regarding the generalization of the proposed method to specific TSP instances, particularly the fine-tuning step in DIMES. It suggests that the authors should clarify this aspect and provide comparisons with other methods on TSP100, both with and without meta-learning. While the comment highlights an important area for improvement, it lacks detailed guidance on how to address these issues or what specific aspects of the paper need to be clarified. The feedback is somewhat helpful as it provides a clear direction for the authors to focus on, but it could be more comprehensive with additional suggestions or examples to enhance its usefulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks for clarification on the final thresholds used in the results and suggests that sharing the full set of hyperparameters would enhance reproducibility. While the comment explicitly requests information about the thresholds and hyperparameters, it does not provide specific guidance on how to obtain or present this information. The authors are left to infer that they need to provide these details, but the action is not concrete. Therefore, the comment is somewhat actionable, as it provides an implicit action but lacks detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment asks for clarification on the final thresholds used in the results and suggests that sharing the full set of hyperparameters would enhance reproducibility. However, it does not specify which part of the paper contains this information or which sections are relevant. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, while it requests specific details, it does not provide clear guidance on how to present or share these thresholds and hyperparameters. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point asks for clarification on the final thresholds used in the results and suggests that sharing the full set of hyperparameters would enhance reproducibility. This comment is factual and descriptive, as it requests specific information without making subjective claims or judgments. It does not provide any reasoning, common knowledge, or external references to support the request. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment requests clarification on the final thresholds used in the results and suggests that sharing the full set of hyperparameters would enhance reproducibility. While it identifies an area for improvement, it lacks specific guidance on how to obtain or present these thresholds and hyperparameters. The comment is somewhat helpful as it points out a potential issue with reproducibility, but it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the claim that the readability of RC datasets does not directly affect question difficulty, suggesting that this conclusion might be influenced by the method or features used for answer detection, such as POS/dependency parse features. While the comment identifies a potential nuance in the original claim, it does not provide explicit guidance on how the authors should address this issue or what specific features they should consider. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore the impact of different features on question difficulty. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the claim that the readability of RC datasets does not directly affect question difficulty, suggesting that this conclusion might be influenced by the method or features used for answer detection, such as POS/dependency parse features. However, the comment does not specify which part of the paper this critique refers to, making it weakly grounded. It is specific in detailing what the authors should consider regarding the impact of different features on question difficulty, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the claim that the readability of RC datasets does not directly affect question difficulty, suggesting that this conclusion might be influenced by the method or features used for answer detection, such as POS/dependency parse features. While the comment provides a specific example of a potential factor that could influence the conclusion, it lacks detailed reasoning or references to support the claim. The authors are left to infer the basis of the critique, which makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques a specific claim made in the paper, pointing out that the conclusion about the relationship between RC dataset readability and question difficulty might be influenced by the method or features used for answer detection. This critique is valuable as it highlights a potential nuance or oversight in the original claim, suggesting that the authors should consider the impact of different features on question difficulty. However, the comment could be more helpful if it provided specific guidance on how the authors might explore or address this issue, such as suggesting alternative methods or features to consider. Overall, the comment is somewhat helpful as it identifies an important aspect that needs further consideration, but it lacks detailed actionable advice, making it rated as 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing quality of the paper should be improved, specifically pointing out that the authors spend the same space on explaining basic memory networks and the forward model. It also notes that the related work section has missing pieces on more reinforcement learning tasks. While the comment identifies areas for improvement, it does not provide explicit guidance on how to improve the writing quality or address the issue of missing related work. The authors are left to infer that they need to revise the paper to enhance its clarity and comprehensiveness, but the lack of concrete suggestions makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the writing quality of the paper should be improved, specifically pointing out that the authors spend the same space on explaining basic memory networks and the forward model. It also notes that the related work section has missing pieces on more reinforcement learning tasks. However, the comment does not specify which part of the paper discusses these topics, making it difficult for the authors to pinpoint the exact areas that need improvement. The lack of specific guidance on what aspects of the writing quality need improvement or how to address the missing related work tasks makes the comment weakly grounded. Therefore, this comment is rated as 1: Not Grounded and Not Specific.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing quality of the paper should be improved, specifically noting that the authors spend the same space on explaining basic memory networks and the forward model. It also mentions that the related work section has missing pieces on more reinforcement learning tasks. However, the comment lacks specific examples or detailed reasoning to support these claims. Without concrete evidence or examples, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two main areas for improvement: the writing quality of the paper and the comprehensiveness of the related work section. It points out that the authors spend the same space on explaining basic memory networks and the forward model, which could be streamlined for better clarity. Additionally, it notes that the related work section lacks coverage of more reinforcement learning tasks, suggesting that it could be expanded to provide a more comprehensive overview of the literature. While the comment highlights these areas, it does not provide specific suggestions or guidance on how to improve the writing quality or address the missing related work tasks. This feedback is somewhat helpful as it directs the authors to areas for improvement, but it lacks depth and actionable advice, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implications of replacing the first column of Qo with vo, which affects the reachability of the first state. It suggests that this change might impact the validity of Assumption 1, which concerns the finite length of an option. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes might be necessary. The action is implicit, as the authors need to infer that they should consider the impact of this change on their assumptions and potentially revise their approach. The lack of concrete instructions makes the action somewhat vague, aligning with a score of 2: Borderline Actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 140,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the implications of replacing the first column of Qo with vo and its impact on the reachability of the first state and Assumption 1. This provides clear guidance on how the authors should respond to the comment. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the implications of a specific change in the paper, namely the replacement of the first column of Qo with vo, and its impact on the reachability of the first state and Assumption 1. While the comment highlights a potential issue, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, pointing out that replacing the first column of Qo with vo affects the reachability of the first state and potentially impacts Assumption 1. This feedback is clear and actionable, as it highlights a potential problem that the authors should address. However, the comment could be more helpful if it provided guidance on how the authors might approach this issue or what specific changes they should consider. While the comment is somewhat helpful, it lacks depth and detailed suggestions, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether the assumption that d_e are good replacements for entity embeddings has been tested. While it implies that the authors should have tested this assumption, the comment does not explicitly instruct or suggest how to conduct the test. The action is implicit, as the authors need to infer that they should test the assumption. However, the comment lacks concrete guidance on how to perform the test or what specific aspects to consider. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions whether an important assumption made in the paper, that d_e are good replacements for entity embeddings, has been tested. However, it does not specify which part of the paper this assumption is made or where the testing should be conducted. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs attention. While the comment is specific in questioning the assumption, the absence of grounding information makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions whether the assumption that d_e are good replacements for entity embeddings has been tested. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the assumption made in the paper regarding the use of d_e as replacements for entity embeddings. It questions whether this assumption has been tested, which is a crucial aspect of ensuring the validity and robustness of the research. However, the comment does not provide any specific guidance or suggestions on how the authors might address this issue or what kind of testing could be conducted. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it highlights a potential weakness but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that making the factors in a table does not help convey more messages than pure text, implying that the table does not add any additional information. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to revise the table or what specific changes could be made to improve its effectiveness in conveying messages. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that making factors in a table does not help convey more messages than pure text, implying that the table does not add any additional information. However, it does not specify which part of the paper this issue is related to, such as a particular table or section. This lack of specificity makes it difficult for the authors to pinpoint the exact area that needs improvement. Additionally, the comment does not provide any suggestions or guidance on how to address this issue, leaving the authors without a clear path forward. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that making factors in a table does not help convey more messages than pure text, suggesting that the table does not add any additional information. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind it. Without detailed justification or examples, the claim remains somewhat unverifiable, as it does not provide a clear basis for the authors to address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the presentation of information in a table, suggesting that it does not effectively convey more messages than pure text. This feedback is somewhat helpful as it highlights a specific area for improvement, but it lacks depth and actionable suggestions. The authors are left without clear guidance on how to revise the table or what specific changes could be made to enhance its effectiveness. While the comment points out a valid concern, it does not provide detailed feedback or examples to help the authors address the issue effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the number of different kinds of physical interactions that can be included in a simulation. However, it does not provide any guidance or suggestions on how to address this question or what aspects of the simulation might benefit from such an analysis. The comment lacks explicit instructions or concrete advice, leaving the authors without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the number of different kinds of physical interactions that can be included in a simulation. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. Without this context, the authors cannot accurately identify the area that needs clarification or discussion. The comment is not grounded, as it lacks specific references to the paper, making it difficult for the authors to understand which part of the paper is being addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the number of different kinds of physical interactions that can be included in a simulation. It does not contain any claims, opinions, or suggestions that require verification or justification. The comment is purely factual and descriptive, aligning with the classification of \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the number of different kinds of physical interactions that can be included in a simulation. While it identifies an area that might need clarification or further discussion, it does not provide any specific guidance or suggestions on how to address this question or what aspects of the simulation might benefit from such an analysis. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the pruning strategy, suggesting that it might not be effective for large networks due to the lack of mention of global top Q values of the metric over the average of gradients. It implies that this omission could lead to the breaking of acceleration techniques like quantization and sparsification. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to incorporate this information into their work. The action is implicit and vague, as it leaves the authors to infer the necessary changes. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to pruning strategies, particularly in the context of large networks and distributed training. It highlights a potential problem with the lack of mention of global top Q values of the metric over the average of gradients, which could impact the effectiveness of acceleration techniques like quantization and sparsification. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The specificity of the comment is good as it clearly identifies the problem and its potential consequences. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that pruning majorly works with large networks, which are usually trained in distributed settings, but does not mention anything about potential necessity to find global top Q values of the metric over the average of gradients. This omission could potentially break big portion of acceleration techniques, such as quantization and sparsification. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand and address the issue. The reasoning is somewhat vague, and the claim is not fully verifiable without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the pruning strategy, specifically noting that it might not work effectively for large networks due to the lack of mention of global top Q values of the metric over the average of gradients. This observation is relevant as it could impact the effectiveness of acceleration techniques like quantization and sparsification. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or incorporate this information into their work. While it highlights a potential problem, it lacks actionable advice, making it somewhat helpful. The authors would need to infer the necessary steps to improve their draft, which limits the comment's overall impact. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether some subfigures in Figs 1 and 2 have been swapped by mistake. While it identifies a potential issue, it does not provide any explicit or implicit actions for the authors to take. The authors are left without guidance on how to address this concern, making the comment unactionable. Therefore, this comment aligns with the lowest score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions whether some subfigures in Figs 1 and 2 have been swapped by mistake. However, it does not specify which subfigures are in question or provide any details about the figures themselves. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not specify what needs to be addressed or how the issue should be resolved, making it not specific. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions whether some subfigures in Figs 1 and 2 have been swapped by mistake. However, it does not provide any evidence, reasoning, or references to support this claim. Without specific details or examples, the authors are left without guidance on how to address the issue or verify its existence. Therefore, the comment is considered unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about potential errors in the subfigures of Figs 1 and 2, questioning whether they have been swapped by mistake. However, it does not provide any specific details or suggestions on how to address this issue. The comment lacks actionable guidance or insight into what might have caused the error or how the authors could verify the accuracy of the figures. Without further elaboration or suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the dropout probe improves sensitivity and identifies a potential concern about the increased risk of false positives. It suggests that this issue should be a substantial part of the discussion. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific aspects of the discussion need to be expanded. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the dropout probe improving sensitivity and highlights a concern about the increased risk of false positives. It suggests that this issue should be a substantial part of the discussion. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or figure. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs attention. The comment is specific in identifying the concern about false positives, but without grounding, it is difficult for the authors to apply the feedback effectively. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the dropout probe improves sensitivity but also raises a concern about the increased risk of false positives. While the comment acknowledges the improvement in sensitivity, it does not provide specific evidence or references to support the claim about the increased risk of false positives. The reasoning is somewhat vague, as it lacks detailed examples or references to substantiate the concern. Therefore, the claim is somewhat verifiable, as it is partially supported but lacks sufficient evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential concern regarding the increased risk of false positives associated with the dropout probe, which improves sensitivity. It suggests that this issue should be a substantial part of the discussion. While the comment highlights a critical aspect that needs attention, it does not provide specific guidance on how to address this concern or what aspects of the discussion should be expanded. The feedback is somewhat helpful as it points out an important consideration, but it lacks depth and actionable suggestions, making it only partially beneficial for the authors. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper is not sound because it does not discuss or compare exploration methods in RL literature, such as count-based methods and intrinsic motivations (RND, ICM). However, it does not provide explicit guidance on how the authors should address this issue or what specific methods they should include in their discussion. The action is implicit and vague, as it leaves the authors without a clear understanding of how to improve their draft. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the paper,\" allowing the authors to accurately identify the part being addressed. It is also specific because it highlights the lack of discussion and comparison of exploration methods in RL literature, such as count-based methods and intrinsic motivations (RND, ICM). This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not sound because it does not discuss or compare exploration methods in RL literature, such as count-based methods and intrinsic motivations (RND, ICM). However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed examples or references, the claim is somewhat verifiable, as it provides a general idea but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper by pointing out the absence of discussion and comparison of exploration methods in RL literature, such as count-based methods and intrinsic motivations (RND, ICM). This feedback is valuable as it highlights an area where the paper could be strengthened by providing a more comprehensive overview of the existing literature. However, the comment could be more helpful if it suggested specific methods or approaches that the authors should consider discussing or comparing. While it provides a clear direction for improvement, the lack of detailed guidance limits its impact on the authors. Therefore, the comment is mostly helpful, as it offers actionable feedback but could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the annotations in Figure 4 can be further enlarged for better visibility. This is a clear and explicit action that the authors can easily understand and implement. The comment provides a specific detail on how to improve the figure, making it actionable. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the annotations in Figure 4 can be further enlarged for visibility. However, it does not specify which part of the paper this figure is located in, nor does it provide any specific details about the annotations themselves. This makes it difficult for the authors to pinpoint the exact section that needs attention. As a result, the comment is not grounded, as the authors cannot confidently determine which part of the paper is being addressed. It is also not specific because it lacks details about the annotations or the reasons for their current size. Therefore, this comment is rated as Not Grounded and Not Specific, corresponding to a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the annotations in Figure 4 can be further enlarged for visibility. This is a subjective opinion or critique, as it expresses an opinion about the clarity of the figure. However, the comment does not provide any specific reasoning or evidence to support why the annotations are difficult to see or why enlarging them would be beneficial. Without additional context or justification, the claim lacks sufficient support, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the annotations in Figure 4 can be further enlarged for visibility. This is a specific and actionable piece of feedback that directly addresses a potential issue with the figure's clarity. By recommending the enlargement of annotations, the comment provides a clear direction for improvement, allowing the authors to enhance the readability and understanding of the figure. This feedback is concise and directly actionable, making it highly helpful for the authors to refine their draft. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the claim that \"Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only document-level RE or joint entity and relation extraction.\" However, it does not provide any explicit or implicit actions for the authors to take. The comment highlights a potential issue with the paper's framing but does not offer guidance on how to address it or improve the draft. As a result, the authors are left without any actionable feedback, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific part of the paper by referencing \"Lines 26-27,\" which provides a clear indication of the section being discussed. It critiques the claim that \"Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only document-level RE or joint entity and relation extraction.\" This allows the authors to accurately identify the part of the paper being addressed. However, the comment does not specify what needs to be addressed or how the critique should be addressed, making it specific but lacking in detail. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the claim that \"Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only document-level RE or joint entity and relation extraction.\" However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors are left to question the validity of the critique, making it difficult to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the claim that \"Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only document-level RE or joint entity and relation extraction.\" However, it does not provide any specific suggestions or actionable feedback on how the authors might address this issue or improve their draft. The comment lacks depth and does not offer guidance on what changes could be made to the paper. As a result, it is barely helpful, as it does not provide the authors with any meaningful insights or direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and concerns about the paper, including the impact of inference on speed, the possibility of only doing inference, the coefficient of the p(L, E | X) term in line 307, and the lack of hyperparameter details. It also notes that the writing is not careful and hinders understanding. While the comment identifies several areas that need clarification or improvement, it does not provide explicit instructions on how to address these issues. The actions are implicit, as the authors would need to infer how to provide the requested information or improve the writing. Therefore, the comment is somewhat actionable, as it provides some guidance but lacks concrete details on how to implement the suggestions.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several questions and concerns about specific aspects of the paper, such as the impact of inference on speed, the possibility of only doing inference, and the coefficient of the p(L, E | X) term in line 307. It also notes the lack of hyperparameter details and the writing quality. However, the comment does not explicitly mention specific sections or parts of the paper that need attention, making it weakly grounded. The specificity of the feedback is moderate, as it addresses several issues but lacks detailed guidance on how to address them. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several questions and concerns about the paper, including the impact of inference on speed, the possibility of only doing inference, the coefficient of the p(L, E | X) term in line 307, and the lack of hyperparameter details. It also notes that the writing is not careful and hinders understanding. However, the comment lacks specific examples, detailed reasoning, or references to support the claims made. The feedback is somewhat verifiable as it identifies areas that need clarification or improvement, but it does not provide sufficient evidence or guidance for the authors to address these issues effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises several important questions and concerns about the paper, such as the impact of inference on speed, the possibility of only doing inference, the coefficient of the p(L, E | X) term in line 307, and the lack of hyperparameter details. It also notes that the writing is not careful and hinders understanding. While the comment identifies areas that need clarification or improvement, it lacks specific guidance on how to address these issues or provide additional details. The feedback is somewhat helpful as it points out areas that could be improved, but it does not offer a comprehensive or actionable response. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests replacing the model by Dozat and Manning (2016) with a \"very high performing model\" or something similar. This provides a clear and explicit action for the authors to take, as they can directly implement this suggestion by updating their model reference. The comment is specific in its recommendation, guiding the authors on what to do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 152,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to replace the model by Dozat and Manning (2016) with a \"very high performing model\" or something similar. This guidance is concrete and actionable, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests replacing the model by Dozat and Manning (2016) with a \"very high performing model\" or something similar. While the suggestion is based on the reviewer's opinion that the model is no longer state-of-the-art, it lacks specific evidence or references to support this claim. The comment does not provide detailed reasoning or examples to justify the suggestion, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion to replace the model by Dozat and Manning (2016) with a \"very high performing model\" or something similar. This feedback is actionable and directly addresses a potential issue with the model used in the paper. By offering a concrete alternative, the comment empowers the authors to improve the accuracy and relevance of their work. However, the comment could be more helpful if it provided additional context or justification for why this replacement is necessary or beneficial. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion, but it could be further enhanced with additional reasoning or examples. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies several areas where the paper could be improved, such as the inclusion of subjective statements, the need for proofs and references to support claims, and the lack of detailed explanation for certain statements. It also suggests that the paper should provide a detailed explanation to verify these claims. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to do so. The actions are implicit and somewhat vague, as the authors are left to infer what needs to be done. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses issues with subjective statements and the need for proofs and references to support claims. It also mentions specific areas, such as the labor-intensive nature of seeking an effective architecture and the sensitivity of image recovery performance to neural architecture choices. However, it does not specify which part of the paper these issues are present in, making it weakly grounded. The comment is specific in detailing the need for additional evidence and detailed explanations, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas that require attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about subjective statements and the need for proofs and references to support claims. It also mentions the labor-intensive nature of seeking an effective architecture and the sensitivity of image recovery performance to neural architecture choices. However, the comment lacks specific examples or references to substantiate these claims, making it difficult for the authors to understand and address the issues. The feedback is somewhat verifiable as it provides a general direction but lacks detailed support. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several areas where the paper could be improved, such as the inclusion of subjective statements and the need for proofs and references to support claims. It also highlights the labor-intensive nature of seeking an effective architecture and the sensitivity of image recovery performance to neural architecture choices. The comment suggests that the paper should provide a detailed explanation to verify these statements, which is a valuable piece of feedback. However, the comment could be more helpful if it provided specific examples or guidance on how to address these issues. Overall, the feedback is somewhat helpful as it points out areas for improvement but lacks depth and detail, making it slightly beneficial for the authors to consider.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks a question about how the proposed method compares with prior art. While it prompts the authors to consider this comparison, it does not provide explicit instructions or suggestions on how to address this comparison. The authors are left to infer that they should include a comparison with prior work, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment asks a question about how the proposed method compares with prior art. However, it does not specify which part of the paper this comparison should be made or what aspects of the comparison are relevant. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its request for a comparison, but without grounding, the authors are left to make an educated guess about where to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about how the proposed method compares with prior art. However, it does not provide any specific details, reasoning, or references to support this claim. Without additional context or evidence, the authors are left to make their own judgments about the relevance and importance of this comparison. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about how the proposed method compares with prior art, which is a relevant and important aspect for evaluating the novelty and contribution of the work. However, the comment lacks specific guidance or suggestions on how to address this comparison. It does not provide any insights into what kind of comparison would be beneficial or how the authors might approach it. Without actionable advice or examples, the comment is somewhat helpful as it identifies an important area for improvement but does not provide sufficient direction for the authors to enhance their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that some analyses could be more detailed, specifically mentioning the inclusion of data from various languages and nationalities. It provides an example of the data included and raises a question about potential interesting observations comparing different languages/nationalities. However, the comment does not explicitly instruct the authors to add more detailed analyses or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the need for more detailed analysis and the specific areas where it should be expanded. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that some analyses could be more detailed, specifically mentioning the inclusion of data from various languages and nationalities. It provides an example of the data included and raises a question about potential interesting observations comparing different languages/nationalities. However, the comment does not specify which part of the paper this suggestion relates to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific about the type of analysis that could be more detailed, it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that some analyses could be more detailed, specifically mentioning the inclusion of data from various languages and nationalities. It provides an example of the data included and raises a question about potential interesting observations comparing different languages/nationalities. However, the comment lacks specific examples or references to support the claim that the current analysis is lacking in detail. While the suggestion is logical, it does not provide sufficient evidence or guidance for the authors to understand how to improve their analysis. Therefore, the comment is considered borderline verifiable, as it offers a suggestion but lacks detailed justification or examples.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that some analyses could be more detailed, specifically mentioning the inclusion of data from various languages and nationalities. It provides an example of the data included and raises a question about potential interesting observations comparing different languages/nationalities. However, the comment lacks specific guidance on how to enhance the analysis or what additional insights could be derived from the data. While it identifies a potential area for improvement, it does not offer actionable advice or detailed suggestions for the authors to follow. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether there are other properties of features that could be used in the approach design. While it suggests that exploring additional properties might be beneficial, it does not provide explicit guidance on how to identify or utilize these properties. The comment is somewhat vague, as it lacks specific examples or actionable steps for the authors to take. Therefore, the comment is somewhat actionable, as it provides a direction but not a detailed path for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether there are other properties of features that could be used in the approach design, suggesting that exploring additional properties might be beneficial. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is specific in its suggestion but lacks grounding as it does not provide context or references to specific sections or parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about whether there are other properties of features that could be used in the approach design, suggesting that exploring additional properties might be beneficial. However, the comment does not provide any specific reasoning, examples, or references to support this claim. It lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about whether there are other properties of features that could be used in the approach design, suggesting that exploring additional properties might be beneficial. This feedback is somewhat helpful as it prompts the authors to consider expanding their approach and potentially enhancing its effectiveness. However, the comment lacks specificity and does not provide detailed guidance or suggestions on how to identify or utilize these additional properties. Without concrete examples or actionable advice, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggestions regarding the conservation of mathematical properties in the context of learning F^\\\\dagger, particularly in relation to symplectic integrators and Hamiltonian systems. It asks whether the learning process can preserve these properties and provides examples of how to illustrate this numerically. However, the comment does not explicitly instruct the authors to address these questions or provide guidance on how to do so. The action is implicit, as the authors need to infer that they should investigate and potentially illustrate the conservation of properties in their work. While the action is somewhat concrete, it lacks explicit instructions on how to implement it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"many solvers' algorithms\" and provides examples of how they guarantee mathematical properties, such as conservation of mass or charge in physics-related continuous PDEs. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it asks about the behavior of learning F^\\\\dagger in this regard, suggesting that the authors investigate whether it can preserve these properties and how to illustrate this numerically. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the conservation of mathematical properties in the context of learning F^\\\\dagger, particularly in relation to symplectic integrators and Hamiltonian systems. It asks whether the learning process can preserve these properties and provides examples of how to illustrate this numerically. However, the comment does not offer any specific reasoning, references, or examples to support the claims made, leaving the authors to interpret and potentially address the questions independently. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the basis for the questions and their relevance to the paper.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several insightful questions and suggestions regarding the conservation of mathematical properties in the context of learning F^\\\\dagger, particularly in relation to symplectic integrators and Hamiltonian systems. It asks whether the learning process can preserve these properties and provides examples of how to illustrate this numerically. However, the comment lacks detailed guidance or suggestions on how to address these questions or what specific aspects of the work might need to be explored further. While it identifies an area for improvement, it does not provide actionable steps or detailed feedback that would help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it offers some direction but could be more comprehensive and detailed to fully assist the authors.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a weakness in the method, noting that it is mostly constructed on top of previous methods without significant network changes or losses. It also questions the use of two SIRENs for f and d, suggesting that d might be a simpler network. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes to make. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies weaknesses in the method, specifically noting that it is mostly constructed on top of previous methods without significant network changes or losses. It also questions the use of two SIRENs for f and d, suggesting that d might be a simpler network. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in detailing the issue with the network architecture but lacks grounding as it does not mention specific sections or parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the necessity of using two SIRENs for f and d, suggesting that d might be a simpler network. However, it does not provide any specific reasoning or evidence to support this claim, such as logical arguments or references to existing literature. Without detailed justification or examples, the claim remains somewhat verifiable, as the authors may need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the method, noting that it is mostly constructed on top of previous methods without significant network changes or losses. It questions the use of two SIRENs for f and d, suggesting that d might be a simpler network. This feedback provides a clear area for improvement, prompting the authors to consider simplifying the network architecture. However, the comment lacks detailed guidance on how to address this issue or what specific changes might be beneficial. While it highlights a potential area for enhancement, the feedback could be more helpful with additional suggestions or examples. Therefore, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the RQ1 mentioned in the paper is redundant and adds no extra information for the audience. It also proposes an interesting point for analysis, such as how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and vice versa, and its corresponding effect on RQ2 & RQ3 t-sne plots. However, the comment does not provide explicit guidance on how the authors should address this issue or incorporate the suggested analysis. The action is implicit and somewhat vague, as the authors are left to infer how to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the redundancy of RQ1 and suggests an interesting point for analysis related to the percentage of explicit hate information in the dataset and its effect on implicit hate speech detection performance. However, it does not specify which part of the paper discusses RQ1 or where the dataset analysis is mentioned. The comment is weakly grounded as it does not provide explicit references to sections or figures, but it is specific in detailing what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the RQ1 mentioned in the paper is redundant and adds no extra information for the audience. It also suggests an interesting point for analysis regarding the percentage of explicit hate information in the dataset and its effect on implicit hate speech detection performance. However, the comment lacks specific examples or references to support the claim about the redundancy of RQ1. While it provides a suggestion for improvement, the lack of detailed reasoning or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential redundancy in the RQ1 mentioned in the paper, suggesting that it adds no extra information for the audience. It also proposes an interesting point for analysis, such as how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and vice versa, and its corresponding effect on RQ2 & RQ3 t-sne plots. However, the comment lacks specific guidance on how the authors should address this issue or incorporate the suggested analysis into their draft. While it provides a clear direction for improvement, the feedback could be more helpful if it included actionable steps or examples of how to implement the suggested analysis. Therefore, the comment is mostly helpful, as it offers valuable insights but could be more comprehensive in its guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the differences between the authors' work and other works focusing on semantic face editing, particularly those that achieve continuous control over attributes. While it prompts the authors to elaborate on these differences, it does not provide explicit guidance on how to address this question or what specific aspects need to be clarified. The action is implicit, as the authors need to infer that they should compare their work with the mentioned papers and explain the differences. However, the lack of concrete instructions on how to elaborate on these differences makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"other works focusing on the semantic face editing,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking the authors to elaborate on the differences between their work and these papers, particularly regarding continuous control over attributes. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the differences between the authors' work and other works focusing on semantic face editing, particularly those that achieve continuous control over attributes. While it does not contain a direct claim, it prompts the authors to elaborate on these differences, which could be considered a suggestion for improvement. However, the comment lacks specific examples or detailed reasoning to support the need for this elaboration, making it somewhat verifiable. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the authors elaborate on the differences between their work and other works focusing on semantic face editing, particularly those that achieve continuous control over attributes. This feedback is clear and actionable, as it prompts the authors to provide a detailed comparison and explanation of their work in relation to existing research. However, the comment could be more helpful if it provided specific examples or guidance on how to elaborate on these differences. Overall, the comment is mostly helpful as it directs the authors to a relevant area for improvement, but it could be more comprehensive with additional details. Therefore, the comment is rated as 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that footnotes are used excessively, making the paper distracting, and recommends moving important content into the main body and details about parameter settings into the appendix. While the comment provides explicit guidance on how to improve the paper by suggesting specific actions, such as moving content to the main body and appendix, it does not offer detailed instructions on how to execute these actions. The authors are left with a general idea of what needs to be done but lack specific steps to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"footnotes\" and \"parameter settings,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on how to improve the paper by suggesting that excessive footnotes are distracting and that important content should be moved into the main body, with details about parameter settings moved to the appendix. This provides a clear direction for the authors to make necessary changes. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that footnotes are used too extensively, making the paper distracting, and suggests moving important content to the main body and details about parameter settings to the appendix. While the comment provides a general rationale for the suggestion, it lacks specific examples or references to support the claim about the excessive use of footnotes. The authors are left with a general understanding of the issue but without detailed evidence or guidance on how to address it. Therefore, the comment is barely verifiable, as it provides some reasoning but lacks the necessary depth and specificity to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the excessive use of footnotes, which can make the paper distracting. It provides actionable suggestions for improvement, such as moving important content to the main body and details about parameter settings to the appendix. This feedback is clear and constructive, offering the authors specific guidance on how to enhance the readability and flow of their paper. However, the comment could be more helpful if it included additional suggestions or considerations, such as specific examples of what content should be moved or how the appendix should be structured. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the effective receptive field is improved after applying the GS module and suggests that this can be computed from a reference [2]. While the comment implies that the authors should investigate this aspect, it does not provide explicit instructions or detailed guidance on how to conduct the analysis or what specific changes to expect. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the question. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the effective receptive field of the GS module, suggesting it can be computed from a reference [2]. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The authors may infer that it relates to the methodology or experimental results, but the lack of explicit mention makes it weakly grounded. The comment is specific in questioning the improvement of the effective receptive field, but the lack of grounding makes it difficult for the authors to pinpoint the exact area to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about whether the effective receptive field is improved after applying the GS module and suggests that this can be computed from a reference [2]. However, it does not provide any specific reasoning or evidence to support the claim that the effective receptive field is indeed improved. The comment lacks detailed explanation or examples to substantiate the assertion, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the effectiveness of the GS module in improving the effective receptive field, suggesting that this can be computed from a reference [2]. While it identifies a potential area for further investigation, it does not provide detailed guidance or suggestions on how to conduct this analysis or what specific results to expect. The comment is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their work. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the objective for the LSTM part is the same for pre-training and fine-tuning, specifically mentioning the probabilities of actions. It also proposes that the authors may add another head to the network to compute value functions for states during the fine-tuning stage. This comment provides explicit guidance on what the authors should consider and how they might improve their approach. The action is clear and concrete, as it specifies exactly what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment provides a specific suggestion regarding the objective of the LSTM part in the context of pre-training and fine-tuning, aligning with the probabilities of actions. It also suggests an additional head for computing value functions during fine-tuning. However, the comment does not explicitly mention which part of the paper this suggestion relates to, such as a specific section or figure. This makes it weakly grounded, as the authors may need to infer the relevant section. The comment is specific in detailing what needs to be addressed, but the lack of explicit grounding makes it weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the objective for the LSTM part is the same for pre-training and fine-tuning, specifically mentioning the probabilities of actions. It also proposes that the authors may add another head to the network to compute value functions for states during the fine-tuning stage. This comment is mostly verifiable as it provides a clear and logical suggestion based on the understanding of LSTM networks and their application in pre-training and fine-tuning. However, it lacks specific examples or references to support the claim fully, which could make it slightly less verifiable. Therefore, it aligns with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the objective of the LSTM part in the context of pre-training and fine-tuning. It suggests that the probabilities of actions should be the same for both stages and proposes adding another head to the network to compute value functions for states during fine-tuning. This feedback is clear and actionable, offering a concrete improvement that the authors can implement. However, it could be more helpful if it included additional context or examples to further guide the authors in making these changes. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded for greater depth and guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the rationale behind combining G4RL with HRAC (i.e., HRAC-G4RL) and whether G4RL requires HRAC's regularization in the latent space. While it prompts the authors to provide a justification for this combination, it does not explicitly instruct them to do so or offer guidance on how to address this question. The action is implicit, as the authors need to infer that they should provide a rationale for the combination. However, the comment lacks concrete details on how to implement this action, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the rationale behind combining G4RL with HRAC (i.e., HRAC-G4RL) and whether G4RL requires HRAC's regularization in the latent space. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. Without explicit mention or context, the authors may find it challenging to identify the exact part of the paper being addressed. While the comment is specific in its inquiry, the lack of grounding makes it difficult for the authors to fully understand and address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the rationale behind combining G4RL with HRAC (i.e., HRAC-G4RL) and whether G4RL requires HRAC's regularization in the latent space. This is a question that seeks clarification and understanding, rather than making a claim that requires verification. The comment does not provide any evidence, reasoning, or references to support a claim. Therefore, it is classified as \"No\" because it is a question for clarification, not a claim that needs verification.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind combining G4RL with HRAC (i.e., HRAC-G4RL) and whether G4RL requires HRAC's regularization in the latent space. This question prompts the authors to provide a justification for their approach, which could help them clarify their methodology and improve the clarity of their work. However, the comment lacks depth and does not offer specific guidance or suggestions on how to address this question or what aspects of the combination might need further explanation. While it identifies an area for improvement, it does not provide actionable feedback that would significantly enhance the authors' draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should acknowledge some of the older works in the related works section. While the comment implies that the authors should include these older works, it does not provide specific guidance on which works to acknowledge or how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer the exact action and its implementation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should acknowledge some of the older works in the related works section, specifically mentioning \"a long line of work that use supervised, multilingual systems.\" However, it does not specify which part of the paper this comment refers to, making it weakly grounded. The comment is specific in its suggestion to acknowledge older works, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should acknowledge some of the older works in the related works section, specifically mentioning \"a long line of work that use supervised, multilingual systems.\" However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to implement it. Without detailed examples or references, the claim is somewhat verifiable, as it provides a general direction but lacks the necessary depth to be fully actionable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should acknowledge some of the older works in the related works section, specifically mentioning \"a long line of work that use supervised, multilingual systems.\" This feedback is somewhat helpful as it points out a potential area for improvement by suggesting that the authors should include a broader range of related works. However, the comment lacks specificity and does not provide detailed guidance on which older works should be acknowledged or how they might be integrated into the paper. Without more detailed suggestions, the authors may struggle to effectively address the feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the results presented in Table 2, specifically regarding the underperformance of linear-/exponential-decay sampling compared to uniform sampling. It suggests that if the predictor is accurate on the good subregion, increasing the sampling probability for top-performing predicted architectures could lead to better performance. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results presented in the table, questioning the underperformance of linear-/exponential-decay sampling compared to uniform sampling and suggesting an alternative approach based on the authors' argument about the predictor's accuracy on the good subregion. This provides a clear direction for the authors to address the issue. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the results presented in Table 2, specifically regarding the underperformance of linear-/exponential-decay sampling compared to uniform sampling. It suggests that if the predictor is accurate on the good subregion, increasing the sampling probability for top-performing predicted architectures could lead to better performance. However, the comment does not provide any specific examples, reasoning, or references to support the claim that the results are confusing or that the suggested alternative approach is valid. The lack of detailed explanation or evidence makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the results presented in Table 2, specifically regarding the underperformance of linear-/exponential-decay sampling compared to uniform sampling. It suggests that if the predictor is accurate on the good subregion, increasing the sampling probability for top-performing predicted architectures could lead to better performance. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their draft. While it identifies a potential area for clarification, it lacks actionable advice or detailed reasoning, making it somewhat helpful. The authors would need to infer the necessary steps to address the concern, which limits the comment's effectiveness. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights potential issues with the time complexity of the proposed method, specifically mentioning the use of an item-oriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorization methods. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks guidance on how to optimize the method or what specific changes might be necessary to reduce the time complexity. Without concrete suggestions or actionable steps, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the time complexity of the proposed method, specifically mentioning the use of an item-oriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorization-based methods. However, it does not specify which part of the paper these issues are discussed in, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific in detailing the issues, it lacks grounding as it does not provide clear references to the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the time complexity of the proposed method is high, citing the use of an item-oriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorization methods. However, the comment lacks specific examples or detailed reasoning to substantiate these claims. Without clear evidence or references, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered borderline verifiable, as it provides some basis for concern but lacks sufficient detail to fully support the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies potential issues with the time complexity of the proposed method, specifically mentioning the use of an item-oriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorization-based methods. While the comment highlights these concerns, it does not provide specific suggestions or guidance on how the authors might address these issues or optimize their method. Without actionable advice or detailed feedback, the authors may struggle to understand how to improve their draft. Therefore, the comment is somewhat helpful, as it points out areas for improvement but lacks depth and specificity in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the figures would be clearer if they specified \"pre-trained solution encoders & solution decoders,\" given that there are multiple types of autoencoders. This comment provides a clear and explicit action for the authors to take, which is to label the figures more precisely. The suggestion is concrete, as it specifies exactly what needs to be done to improve the clarity of the figures. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the figures would be clearer if they specified \"pre-trained solution encoders & solution decoders,\" given that there are multiple types of autoencoders. However, it does not explicitly mention which figures are being referred to, making it weakly grounded. The comment is specific in its suggestion to improve the clarity of the figures by providing more detailed labels. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the figures would be clearer if they specified \"pre-trained solution encoders & solution decoders,\" given that there are multiple types of autoencoders. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. Without additional context or evidence, the claim remains somewhat verifiable, as it lacks sufficient justification or examples to fully substantiate the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the figures, suggesting that labeling them as \"pre-trained solution encoders & solution decoders\" would improve their readability. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing the presentation of their figures. By addressing this suggestion, the authors can make their figures more understandable and effectively communicate their findings. Therefore, the comment is mostly helpful, as it offers a clear and actionable improvement that could significantly enhance the draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks for information about the computational requirements of the experiments, specifically the time taken and the hardware used. While it prompts the authors to provide this information, it does not explicitly instruct them to include it in the paper or suggest where to add it. The action is implicit, as the authors can infer that they need to provide this information, but it lacks concrete guidance on how to present or discuss it. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for information about the computational requirements of the experiments, including the time taken and the hardware used. This allows the authors to accurately identify the part of the paper where this information should be addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the computation required for the experiments. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the computational requirements of the experiments, specifically the time taken and the hardware used. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it prompts the authors to provide information about the computational requirements of their experiments, specifically the time taken and the hardware used. This feedback is valuable as it highlights an important aspect of the experimental setup that could enhance the reproducibility and transparency of the work. However, the comment lacks depth and does not provide specific guidance on how to present or discuss this information, making it somewhat helpful rather than fully helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the application of the meta sampler, specifically whether it is used in a decoupled way and when it is applied. While it prompts the authors to provide more discussion, it does not explicitly instruct them to do so or offer concrete guidance on how to address this concern. The action is implicit, as the authors need to infer that they should discuss the application of the meta sampler and the specific epoch it is applied. However, the lack of detailed guidance on how to implement this discussion makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the application of the meta sampler, specifically whether it is used in a decoupled way and when it is applied. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This makes it difficult for the authors to identify the exact area that needs clarification. While the comment is specific in its inquiry about the application of the meta sampler, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the application of the meta sampler, specifically whether it is used in a decoupled way and when it is applied. However, it does not provide any evidence, reasoning, or references to support the claim that the authors only apply the meta sampler in a decoupled way or when specific epochs are used. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the application of the meta sampler, asking whether it is used in a decoupled way and when it is applied. This question prompts the authors to provide more discussion on this aspect, which could enhance the clarity and depth of their work. However, the comment lacks detailed guidance or suggestions on how to address this concern, leaving the authors with a general direction but without specific steps to take. While the feedback is somewhat helpful, it could be more impactful with additional details or suggestions. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use fairness-aware metrics like Equality odds (EO) and conduct more experiments on datasets like COMPAS and Drug Comsumption. It also encourages the authors to follow a cited AAAI paper. However, the comment does not explicitly instruct the authors on how to implement these changes or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer the necessary actions and may require additional guidance to execute them effectively. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests using fairness-aware metrics like Equality odds (EO) and conducting more experiments on datasets like COMPAS and Drug Comsumption. It also encourages the authors to follow a cited AAAI paper. However, the comment does not specify which part of the paper discusses the use of metrics or the experimental setup, making it difficult for the authors to identify the exact sections that need revision. While the suggestion to use specific metrics and datasets is clear, the lack of explicit grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should use fairness-aware metrics like Equality odds (EO) and conduct more experiments on datasets like COMPAS and Drug Comsumption, referencing a cited AAAI paper. This claim is somewhat verifiable as it provides a clear direction for improvement by suggesting specific metrics and datasets to enhance the fairness of the experiments. However, it lacks detailed reasoning or examples to fully support the claim, which could make it challenging for the authors to fully understand and implement the suggestions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides specific suggestions for improvement, such as using fairness-aware metrics like Equality odds (EO) and conducting additional experiments on datasets like COMPAS and Drug Comsumption. It also encourages the authors to follow a cited AAAI paper, which could provide further guidance. However, the comment lacks detailed explanations or examples of how to implement these suggestions, making it somewhat helpful. The authors gain a general idea of what needs to be improved but may require additional guidance to fully address the feedback. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests considering additional baselines, such as Rope and Alibi relative positional embeddings, to verify the performance improvement achieved by the changes suggested in the paper. While the comment implies that these baselines should be included, it does not explicitly instruct the authors to add them or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to include these baselines in their experiments. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests considering additional baselines, such as Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes suggested in the paper. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to include these baselines, but without a clear reference to the section or part of the paper, the authors may find it challenging to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests considering additional baselines, such as Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes suggested in the paper. However, the comment lacks specific examples or references to support the claim that these baselines would provide additional insights or verification. Without detailed reasoning or examples, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered borderline verifiable, as it provides some guidance but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests considering additional baselines, such as Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes suggested in the paper. This feedback is somewhat helpful as it provides a specific suggestion for improvement, indicating that the authors should include these baselines to strengthen their experimental validation. However, the comment lacks depth and does not offer detailed guidance on how to implement this suggestion or why these baselines are particularly relevant. As a result, the feedback is somewhat helpful, as it provides a clear direction for improvement but could be more comprehensive with additional details or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two key issues that need addressing: the lack of analysis regarding the value of the neighborhood size h and its influence on the model's performance, and the inconsistent use of hyperparameter sets across different datasets. The comment suggests that the authors should provide insights into how performance varies with a constant set of parameters. However, it does not explicitly instruct the authors on how to conduct this analysis or what specific steps to take. While the action is implied, it is vague and lacks concrete guidance on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the missing element of the value of neighborhood size h and its influence on the model\\'s performance, which is a key parameter of the proposed strategy. It also mentions the inconsistent use of hyperparameter sets across different datasets. However, the comment does not specify which part of the paper discusses the model or the experiments, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as providing insights into the value of h and the robustness of the method with respect to different neighborhood sizes. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two key issues: the lack of analysis regarding the value of neighborhood size h and its influence on the model\\'s performance, and the inconsistent use of hyperparameter sets across different datasets. The comment suggests that the authors should provide insights into how performance varies with a constant set of parameters. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of detailed justification makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claims but lacks sufficient evidence or explanation.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies two significant areas for improvement in the paper: the lack of analysis regarding the value of the neighborhood size h and its influence on the model\\'s performance, and the inconsistent use of hyperparameter sets across different datasets. It highlights that the neighborhood size h is a key parameter of the proposed strategy, and providing readers with intuitive knowledge of its value and the robustness of the method with respect to different neighborhood sizes is essential. The comment also points out that different hyperparameter sets are used per dataset, which is not ideal and suggests that the authors should provide insights into how performance varies with a constant set of parameters. This feedback is clear and actionable, offering specific areas for the authors to address and improve their work. However, it could be more helpful if it provided more detailed guidance on how to conduct the analysis or what specific steps to take. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the model's performance when multimodal data is imperfect, specifically when certain modalities are missing. It asks about the impact on the model and whether it can leverage additional modalities to infer missing ones. While the comment prompts the authors to consider these aspects, it does not provide explicit instructions or suggestions on how to address these questions or incorporate them into the paper. The action is implicit, as the authors need to infer that they should analyze the model's behavior under imperfect data conditions and consider the impact of missing modalities. However, the comment lacks concrete guidance on how to conduct this analysis or what specific experiments or analyses would be necessary. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the model's performance when multimodal data is imperfect, specifically when certain modalities are missing. It asks about the impact on the model and whether it can leverage additional modalities to infer missing ones. However, the comment does not specify which part of the paper addresses this issue, making it weakly grounded. The comment is specific in its inquiry about the model's behavior under imperfect data conditions and the potential for leveraging additional modalities. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the model's performance when multimodal data is imperfect, specifically when certain modalities are missing. It asks about the impact on the model and whether it can leverage additional modalities to infer missing ones. However, the comment does not provide any specific evidence, reasoning, or references to support these claims. The questions posed are speculative and lack detailed justification or examples, making the comment unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises important questions about the model's performance when multimodal data is imperfect, specifically when certain modalities are missing. It prompts the authors to consider the impact of this issue on the model and whether it can leverage additional modalities to infer missing ones. While the comment identifies a potential area for improvement and encourages the authors to explore this aspect, it lacks specific guidance or suggestions on how to address these questions or incorporate them into the paper. The feedback is somewhat helpful as it highlights a critical area for consideration but does not provide detailed actionable advice. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the effectiveness of negation or intensity words in the SST dataset, specifically asking for statistics on how often these words change the polarity of the context. While the comment suggests an analysis, it does not provide explicit guidance on how to conduct this analysis or what specific actions the authors should take. The action is implicit and somewhat vague, as the authors are left to infer that they need to analyze the dataset and provide statistics. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"General Discussion,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear question and suggestion for analysis, asking the authors to show the statistics of how negation or intensity words affect the dataset. This guidance is detailed and specific, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the effectiveness of negation or intensity words in the SST dataset, specifically asking for statistics on how often these words change the polarity of the context. While the comment does not contain a subjective claim, it suggests an analysis that could be beneficial for the paper. However, it lacks specific examples or references to support the suggestion, making it somewhat verifiable. The authors would need to infer the need for this analysis, which limits the verifiability of the comment.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the effectiveness of negation or intensity words in the SST dataset, specifically asking for statistics on how often these words change the polarity of the context. This feedback is somewhat helpful as it identifies a potential area for further analysis that could enhance the understanding of the dataset's characteristics. However, the comment lacks detailed guidance or suggestions on how to conduct this analysis, which limits its impact on the authors. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the authors\\' draft, noting that they do not verify the stability of the OGE-Aug model on OOD benchmarks like DrugOOD, where SPE [2] is validated. This feedback is explicit and provides a clear action for the authors to take, which is to verify the stability of their model on these benchmarks. The comment is specific in its suggestion, guiding the authors to address a particular aspect of their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the stability of the OGE-Aug on OOD benchmarks such as DrugOOD,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of verification of the model\\'s stability on these benchmarks. The comment provides a clear direction for the authors to take, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not verify the stability of the OGE-Aug model on OOD benchmarks such as DrugOOD, where SPE [2] is validated. This claim is somewhat verifiable as it points out a specific issue with the authors\\' draft, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors could provide more context or evidence to support this assertion, making the comment more robust. Therefore, it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the authors\\' draft, noting that they do not verify the stability of the OGE-Aug model on OOD benchmarks such as DrugOOD, where SPE [2] is validated. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work that needs verification. By highlighting this omission, the comment provides a concrete suggestion for improvement, empowering the authors to enhance the robustness and reliability of their model. Therefore, the comment is mostly helpful, as it offers a clear and actionable direction for the authors to follow.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests expanding the related work section by comparing the current work to strong baselines that use coordinates. However, it does not provide explicit guidance on which baselines to compare or how to structure this comparison. The action is implicit, as the authors need to infer that they should expand the related work section and compare their work to specific baselines. While the comment is somewhat actionable, it lacks concrete details on how to implement the suggested action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests expanding the related work section by comparing the current work to strong baselines that use coordinates. However, it does not specify which baselines are being referred to or provide any context for why this comparison is necessary. The authors cannot confidently determine which part of the paper this comment addresses, as it lacks specific references or examples. Therefore, the comment is not grounded and does not provide specific guidance on what needs to be addressed. This aligns with a score of 1: Not Grounded and Not Specific.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests expanding the related work section by comparing the current work to strong baselines that use coordinates. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis for this suggestion or how to implement it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests expanding the related work section by comparing the current work to strong baselines that use coordinates. However, it lacks specific details or examples of which baselines should be included or how this comparison would be beneficial. The comment provides a general direction for improvement but does not offer actionable guidance or suggestions for specific comparisons. As a result, the feedback is somewhat helpful, as it identifies an area for enhancement but does not fully address the authors' needs for detailed guidance. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments are limited to training on a single seed, which makes it difficult to assess the significance of performance differences and the true impact of the proposed cycle consistency loss on convergence. The comment implies that multiple seed experiments would provide a more robust evaluation. However, it does not explicitly instruct the authors to conduct multiple seed experiments or provide detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should perform additional experiments. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limitation of the experiments being conducted on a single seed, which makes it difficult to assess the significance of performance differences and the true impact of the proposed cycle consistency loss on convergence. However, the comment does not specify which part of the paper this issue is discussed in, such as a particular section or figure. This lack of grounding makes it challenging for the authors to identify the exact area that needs improvement. While the comment is specific in its critique of the experimental setup, the absence of explicit grounding makes it difficult for the authors to understand where to focus their attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are limited to training on a single seed, making it difficult to assess the significance of performance differences and the true impact of the proposed cycle consistency loss on convergence. The comment suggests that multiple seed experiments would provide a more robust evaluation. However, the claim lacks specific examples or references to support the assertion that single seed experiments are insufficient for assessing the significance of performance differences. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the experimental setup, specifically the use of single seed experiments, which can make it difficult to assess the significance of performance differences and the true impact of the proposed cycle consistency loss on convergence. The comment suggests that conducting multiple seed experiments would provide a more robust evaluation. This feedback is clear and actionable, as it provides a specific suggestion for improvement that the authors can easily implement. However, the comment could be more helpful if it included additional guidance on how to conduct these experiments or what specific metrics to consider. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the accessibility of the proposed method due to the requirement of a multi-GPU setup for optimizations. It suggests that this requirement might limit the potential users who can access or implement the method. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks specific guidance on how to make the method more accessible or how to justify the need for a multi-GPU setup. Without actionable steps or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"optimizations in the proposed method\" and the \"requirement of a multi-GPU setup,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly explains the issue of accessibility due to the need for a multi-GPU setup, which could limit potential users. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the requirement of a multi-GPU setup for the proposed method makes it inaccessible to many potential users. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the accessibility of the proposed method due to the requirement of a multi-GPU setup for optimizations. This is a valid concern that could limit the potential users who can access or implement the method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or make the method more accessible. Without actionable feedback or detailed suggestions, the authors may find it challenging to improve their draft based on this comment alone. Therefore, the comment is somewhat helpful, as it highlights a potential weakness but does not provide comprehensive guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the current system captures semantics through RNN-based models and recommends comparing it with another system that also captures semantics. It also suggests using Ref-[2] as a strong baseline for comparison. However, the comment does not provide explicit guidance on how to implement these suggestions, such as which specific aspects of the comparison should be highlighted or how the performance of the current system should be evaluated against the baseline. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the current system with another system that captures semantics, implying a need for comparison. However, it does not specify which part of the paper this comparison should be made or which sections are relevant. The comment is weakly grounded as the authors cannot confidently determine which part of the paper it addresses. It is also specific in suggesting a comparison with Ref-[2] as a strong baseline, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the current system with another system that captures semantics, recommending Ref-[2] as a strong baseline. However, it lacks specific details or references to support the claim that Ref-[2] is a strong baseline. The comment does not provide a clear rationale or evidence for why this comparison is necessary or beneficial. As a result, the claim is not verifiable, making the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests comparing the current system with another system that captures semantics, recommending Ref-[2] as a strong baseline for comparison. While it identifies a potential area for improvement by highlighting the need for a comparative analysis, the comment lacks specific guidance on how to conduct this comparison or what aspects of the performance should be evaluated. The suggestion to use Ref-[2] as a baseline is a good starting point, but the comment does not provide detailed instructions or examples to help the authors implement this suggestion effectively. Therefore, the comment is somewhat helpful, as it offers a direction for improvement but lacks depth and actionable guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the rationale behind using only the information up to time step t in the user decoder, instead of using information from all time steps. However, it does not provide any explicit or implicit suggestions or actions for the authors to take in response to this question. The comment lacks guidance on how the authors might address this issue or what changes they should consider making to their draft. As a result, the authors are left without a clear understanding of what to do next, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the rationale behind using only the information up to time step t in the user decoder, instead of using information from all time steps. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. While the comment is specific in its question about the rationale, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the rationale behind using only the information up to time step t in the user decoder, instead of using information from all time steps. However, it does not provide any claim, suggestion, or reasoning to support the question. The comment lacks any evidence or justification, making it unverifiable. Therefore, it is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind using only the information up to time step t in the user decoder, instead of using information from all time steps. This question highlights a potential area for clarification or further explanation in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what changes they should consider making to their draft. Without actionable feedback or suggestions, the authors are left without a clear understanding of how to improve their work. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but lacks depth and guidance.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential confounding factor related to the different locations of induction heads and FV heads within the model, which could affect the performance difference when ablating these heads. It suggests that a controlled baseline, where heads are ablated at different locations, should be considered. However, the comment does not provide explicit guidance on how to implement this controlled baseline or what specific experiments should be conducted to address this issue. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the different locations of induction heads and FV heads within the model, which could be a confounding factor affecting ICL performance. It suggests that a controlled baseline should be considered to ablate heads at different locations. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential confounding factor and suggesting a controlled baseline, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the different locations of induction heads and FV heads within the model, suggesting that this could be a confounding factor affecting the performance difference when ablating these heads. The comment implies that a controlled baseline, where heads are ablated at different locations, should be considered. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, and the lack of detailed justification or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential confounding factor related to the different locations of induction heads and FV heads within the model, which could affect the performance difference when ablating these heads. It suggests that a controlled baseline, where heads are ablated at different locations, should be considered. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by addressing the potential confounding factor. However, the comment could be more helpful if it included suggestions on how to implement the controlled baseline or what specific experiments should be conducted. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that a section on synonym identification is missing under the similarity measurement section, which describes how the multiple-choice task is approached. This provides a clear and direct action for the authors to take, namely to include this section in their draft. The comment is explicit and concrete, as it specifies exactly what is missing and where it should be added. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"similarity measurement\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the missing section, \"a section on synonym identification,\" which describes how the multiple-choice task is approached. This provides the authors with a clear understanding of what needs to be added to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a section on synonym identification is missing under the similarity measurement section, which describes how the multiple-choice task is approached. However, the comment does not provide any reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand why this section is missing or how it impacts the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper by pointing out the absence of a section on synonym identification under the similarity measurement section. This is a clear and actionable piece of feedback that would help the authors improve their draft by ensuring all relevant aspects are addressed. The comment is specific and provides a clear direction for improvement, making it highly helpful for the authors. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an overview of the workflow and the model would make it easier for readers to understand the work. However, it does not provide any specific guidance on how to create this overview or what aspects should be included. The comment is vague and lacks concrete instructions, leaving the authors uncertain about how to implement the suggested improvement. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that an overview of the workflow and the model would make it easier for readers to understand the work. However, it does not specify which part of the paper this overview should be included in or how it should be structured. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in suggesting the inclusion of an overview, but it lacks details on what aspects of the workflow and model should be covered. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an overview of the workflow and the model would make it easier for readers to understand the work. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this suggestion is beneficial or how to implement it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that an overview of the workflow and the model would make it easier for readers to understand the work. While this feedback is relevant and could help improve the clarity and accessibility of the paper, it lacks specific guidance on how to create such an overview or what aspects should be included. The comment is somewhat helpful as it identifies a potential area for improvement, but it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A. It suggests that this cannot be computed accurately without a significant runtime, potentially leading to bias that defeats the purpose of the approach. The comment implies that this issue should be discussed in the paper, but it does not provide explicit guidance on how to address it or what specific aspects of the paper need revision. The action is implicit and somewhat vague, as the authors are left to infer that they need to discuss this issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A. It suggests that this cannot be computed accurately without a significant runtime, potentially leading to bias that defeats the purpose of the approach. However, the comment does not specify which part of the paper this issue is discussed or addressed, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the issue, it lacks grounding as it does not provide clear guidance on which part of the paper to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A. It suggests that this cannot be computed accurately without a significant runtime, potentially leading to bias that defeats the purpose of the approach. The comment implies that this issue should be discussed in the paper, but it does not provide specific examples or references to support this claim. The lack of detailed reasoning or evidence makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for concern but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a critical concern about the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A. It points out that this cannot be computed accurately without a significant runtime, potentially leading to bias that defeats the purpose of the approach. The comment suggests that this issue should be discussed in the paper, but it does not provide specific guidance on how to address it or what aspects of the paper need revision. While the feedback highlights a significant concern, it lacks detailed suggestions or actionable steps for the authors to take, making it somewhat helpful. The authors are left to infer that they need to address this issue, but without clear guidance, the feedback is limited in its usefulness. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should redefine Figure 3 to show expected quantities as scalars instead of vectors. This is a clear and explicit action that the authors can readily follow. The comment provides specific guidance on how to implement the change, making it highly actionable. Therefore, this comment is rated as 5: Highly Actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure-3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be done: redefine the figure to show expected quantities as scalars instead of vectors. This provides the authors with a clear understanding of the issue and how to address it. Therefore, this comment is rated as 5: Fully Grounded and Specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should redefine Figure 3 to show expected quantities as scalars instead of vectors. This is a specific and actionable suggestion that directly addresses a potential issue in the presentation of the figure. However, the comment does not provide any reasoning or justification for why this change is necessary or how it would improve the clarity or accuracy of the figure. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting that the expected quantities are scalars but are shown as vectors. This feedback is clear and actionable, providing the authors with a direct instruction on how to improve the accuracy and clarity of their figure. By redefining the figure to accurately represent the expected quantities as scalars, the authors can enhance the precision and effectiveness of their presentation. This level of detail and specificity makes the comment highly helpful, as it guides the authors in addressing a concrete issue that could impact the clarity and accuracy of their work. Therefore, the comment is rated as 5: Highly Helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the lack of empirical evidence to support the claim that the proposed models are particularly useful for learning representations for low-frequency words. It suggests that the authors should explore this aspect further, implying that additional empirical testing could strengthen the argument. However, the comment does not provide specific guidance on how to conduct this testing or what data or experiments would be most effective. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, focusing on the utility of the proposed models for learning representations of low-frequency words. It mentions that the argument is reasonable but lacks empirical evidence, suggesting that the authors should explore this aspect further. However, the comment does not specify which part of the paper discusses this aspect, making it weakly grounded. The comment is specific in detailing the issue of the lack of empirical evidence and the suggestion to explore the aspect further. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks empirical evidence to support the argument about the usefulness of the proposed models for learning representations of low-frequency words. It suggests that the authors should explore this aspect further. However, the comment does not provide specific examples, references, or detailed reasoning to substantiate this claim. The lack of supporting evidence or detailed explanation makes the claim somewhat verifiable, as the authors would need to infer the basis for the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area of the paper that lacks empirical evidence to support a claim about the usefulness of the proposed models for learning representations of low-frequency words. It suggests that the authors should explore this aspect further, which is a valuable piece of feedback. However, the comment could be more helpful if it provided specific guidance on how to conduct this exploration or what kind of empirical evidence would be most relevant. The feedback is somewhat helpful as it points out a gap in the paper but lacks detailed suggestions for improvement. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the resolution of the 3D voxel and its impact on computational cost. It suggests that the importance of global features could be better studied by comparing different resolutions of voxel features, specifically mentioning the case of a 1x1x1 resolution, which is equivalent to using a single global feature. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to conduct this comparison or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the study of global features and specifically mentions methods like PiFu that avoid voxel-like features due to computational and memory costs. It questions the resolution of the 3D voxel and whether it introduces unnecessary overhead. The comment suggests studying the importance of global features in Section 4.2 by comparing different resolutions of voxel features, noting that a 1x1x1 resolution is equivalent to using a single global feature. This provides a clear and specific direction for the authors to address the issue, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the resolution of the 3D voxel and its impact on computational cost, particularly in the context of methods like PiFu that avoid voxel-like features due to high computational and memory costs. It suggests that the importance of global features could be better studied by comparing different resolutions of voxel features, specifically mentioning the case of a 1x1x1 resolution, which is equivalent to using a single global feature. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that different resolutions of voxel features could offer more insights into the importance of global features. The authors would need to infer the basis for this claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the resolution of the 3D voxel and its impact on computational cost, particularly in the context of methods like PiFu that avoid voxel-like features due to high computational and memory costs. It suggests that the importance of global features could be better studied by comparing different resolutions of voxel features, specifically mentioning the case of a 1x1x1 resolution, which is equivalent to using a single global feature. This feedback is clear and actionable, providing a specific direction for the authors to improve their study by exploring the impact of different voxel resolutions on the importance of global features. However, the comment could be more helpful if it included additional guidance on how to conduct this comparison or what specific analyses would be most informative. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement, but it could be further enhanced with more detailed guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it is difficult to discern trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. It recommends exploring development set trends with respect to hyper-parameters. However, the comment does not provide explicit guidance on how the authors should analyze the table or what specific actions they should take to identify these trends. The suggestion is somewhat vague and lacks concrete details on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the table, namely the difficulty in discerning trends and suggests exploring development set trends with respect to hyper-parameters. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a suggestion for improvement, specifically regarding the analysis of Table 3. It does not contain a subjective claim or opinion, but rather a request for clarification or further analysis. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 3, noting that it is difficult to discern trends, particularly the behavior of PM+CL compared to PM or CL alone. It suggests exploring development set trends with respect to hyper-parameters, which provides a clear direction for improvement. However, the comment could be more helpful if it offered additional guidance on how to analyze the table or what specific metrics to consider. Overall, the feedback is somewhat helpful as it highlights an area for improvement and suggests a potential approach, but it lacks depth and detail to fully assist the authors in enhancing their draft.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a difficulty in understanding Figure 5 due to overlapping lines, suggesting that the authors could report additional metrics such as FLOPs or model size to make the figure more concrete. While the comment provides a clear action\u2014improving the clarity of Figure 5 by adding more metrics\u2014it does not specify how to implement this action, such as which metrics to include or how to present them. The action is explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies the issue with the figure, namely the difficulty in understanding due to overlapping lines, and suggests a concrete improvement by reporting additional metrics like FLOPs or model size. This provides clear guidance on what needs to be addressed to enhance the clarity and comprehensiveness of the figure.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that it is difficult to understand Figure 5 due to overlapping lines, and suggests that reporting additional metrics like FLOPs or model size would make the figure more concrete. While the comment identifies a specific issue with the figure, it does not provide any reasoning or examples to support why these additional metrics would improve understanding. The suggestion is logical but lacks detailed justification or references, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 5, noting that the overlapping lines make it difficult to understand. It suggests that the authors could enhance the figure's clarity by reporting additional metrics such as FLOPs or model size. This feedback is actionable and provides a clear direction for improvement, as it suggests a concrete way to make the figure more informative and easier to interpret. However, the comment could be more helpful if it included specific examples of how these metrics would be reported or presented. Overall, the comment is mostly helpful, as it offers valuable guidance for enhancing the clarity and comprehensiveness of the figure.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that some details of the proposed method are missing, referencing a \"questions section below.\" However, it does not specify which details are missing or provide any guidance on how the authors should address these omissions. The action is implicit, as the authors need to infer that they should provide more details in the questions section. The lack of specific guidance on what details are missing makes the action vague and difficult to execute. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment indicates that some details of the proposed method are missing, referencing a \"questions section below.\" However, it does not specify which part of the paper this section is located in, making it difficult for the authors to identify the exact area that needs attention. Additionally, the comment does not provide specific guidance on what details are missing or how they should be addressed. This lack of grounding and specificity makes the comment challenging for the authors to understand and act upon. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that some details of the proposed method are missing, referencing a \"questions section below.\" However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the nature of the missing details or how to address them. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that some details of the proposed method are missing, referencing a \"questions section below.\" However, it does not specify which details are missing or provide any guidance on how the authors might address these omissions. This feedback is vague and lacks actionable suggestions, making it difficult for the authors to improve their draft. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should evaluate the performance of EIGNN with respect to over-smoothing on real-world datasets, particularly in comparison to variants like GCNII. However, it does not provide explicit instructions or detailed guidance on how to conduct this evaluation or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests evaluating the performance of EIGNN with respect to over-smoothing on real-world datasets, specifically comparing it to variants like GCNII. However, it does not specify which part of the paper this evaluation should be conducted in, making it weakly grounded. The comment is specific in its suggestion to compare against certain variants, but the lack of grounding makes it difficult for the authors to pinpoint the exact area of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests evaluating the performance of EIGNN with respect to over-smoothing on real-world datasets, particularly in comparison to variants like GCNII. However, it does not provide any specific reasoning, examples, or references to support why this evaluation is important or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests evaluating the performance of EIGNN with respect to over-smoothing on real-world datasets, particularly in comparison to variants like GCNII. This feedback is somewhat helpful as it identifies a specific area for improvement and provides a direction for further evaluation. However, it lacks detailed guidance on how to conduct this evaluation or what specific aspects to focus on, which limits its impact on the authors. The comment is clear and actionable but could be more comprehensive with additional suggestions or examples. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that Figure 4 is confusing and that the columns are not explained in the text or caption. While the comment highlights a specific issue with the figure, it does not provide explicit guidance on how the authors should address this confusion. The authors are left to infer that they need to clarify the meaning of the columns in the figure, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with Figure 4, namely that the columns are not explained in the text or caption. This provides the authors with a clear understanding of what needs to be addressed to improve the clarity of the figure. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 4 is confusing because it is not clear what the columns mean, as this is not explained in the text or caption. This claim is somewhat verifiable as it provides a specific issue with the figure but lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer that the lack of explanation in the text or caption contributes to the confusion, but the comment does not offer additional context or evidence to support this assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 4, noting that the columns are not explained in the text or caption, making the figure confusing. This feedback is clear and actionable, as it directs the authors to clarify the meaning of the columns in the figure. However, the comment could be more helpful if it provided suggestions on how to improve the clarity of the figure, such as suggesting specific ways to label the columns or provide additional context. Despite this, the comment offers valuable guidance for the authors to enhance the understanding of their work. Therefore, it is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the paper, noting that the lack of ablation analysis makes it difficult to determine the source of a small performance gain. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what steps they should take to include an ablation study. The comment identifies a gap in the analysis but does not offer guidance on how to fill that gap, leaving the authors without a clear path forward. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the lack of ablation analysis in the main paper, which makes it difficult to determine the source of a small performance gain. However, it does not specify which part of the paper lacks this analysis or provide any guidance on how to address the issue. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in identifying the need for ablation analysis but lacks detailed suggestions on how to implement it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lack of ablation analysis in the main paper makes it difficult to determine the source of a small performance gain. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the lack of ablation analysis makes it difficult to determine the source of a small performance gain. This feedback is clear and actionable, as it highlights a critical gap in the analysis that could impact the paper's conclusions. However, the comment could be more helpful if it provided suggestions on how the authors might conduct an ablation study or discuss the implications of the lack of such analysis. Despite this, the comment offers valuable guidance for the authors to improve their draft, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific observation about the noise rate of similarity labels compared to class labels when the number of classes is large (>8). It also mentions that the authors use a threshold (Th.) in their experiments. However, the comment does not provide explicit or implicit actions for the authors to take. It lacks guidance on how to address this observation or incorporate the threshold into their work. Without specific instructions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"2,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should do, namely, to show that when the number of classes is large (>8), the noise rate of similarity labels is less than class labels. This provides clear guidance on how to address the issue. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that when the number of classes is large (>8), the noise rate of similarity labels is less than class labels, and the authors use a threshold (Th.) in their experiments. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left without a basis to understand or verify the claim. Therefore, the comment is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific observation about the noise rate of similarity labels compared to class labels when the number of classes is large (>8). It also mentions that the authors use a threshold (Th.) in their experiments. However, the comment lacks actionable guidance or suggestions on how the authors might address this observation or incorporate the threshold into their work. Without specific advice or steps to improve the draft, the feedback is limited in its usefulness to the authors. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the verification of the hypothesis through the designed experiment. It points out that the base model is trained on the adversarial set only, while conventional methods are trained on the original training set in addition to the generated adversarial examples. The comment suggests that it would be better to compare the model trained on the original dataset with that trained on the mixture to highlight the impact of the augmented adversarial examples. This feedback provides a clear and explicit action for the authors to take, which is to conduct an additional experiment to strengthen the motivation of the work. The action is concrete, as it specifies exactly what needs to be done to improve the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the comparison between models trained on the original dataset and the mixture of original and adversarial examples to better verify the hypothesis. This provides clear guidance on how to improve the paper, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the hypothesis is not well verified by the designed experiment, specifically noting a discrepancy in how models are trained in conventional methods versus the base model. The comment suggests an additional experiment to compare models trained on the original dataset versus the mixture of original and adversarial examples. This claim is somewhat verifiable as it provides a logical reasoning for why the experiment might not be sufficient, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the experimental design, specifically the lack of verification for the hypothesis. It points out that the base model is trained on the adversarial set only, while conventional methods are trained on the original training set in addition to the generated adversarial examples. The comment suggests that comparing the model trained on the original dataset with that trained on the mixture would help highlight the impact of the augmented adversarial examples, making the motivation more convincing. This feedback is clear, actionable, and provides a specific direction for improvement, making it highly helpful for the authors to enhance their draft. Therefore, the comment aligns with a score of 5.\", 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the CNN experiments are not fully convincing but does not provide any specific details or suggestions on how to improve them. The comment lacks explicit guidance on what aspects of the experiments need to be addressed or how the authors should enhance the results. Without concrete actions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper the CNN experiments are discussed in, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment is not specific because it does not provide details on what aspects of the experiments are not convincing or what improvements could be made. Without specific guidance or examples, the authors cannot effectively address the issue. Therefore, this comment is rated as Not Grounded and Not Specific, corresponding to a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the CNN experiments are not fully convincing, but it does not provide any specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors are left without a clear understanding of why the experiments are not convincing or how they might be improved. This lack of support makes the claim difficult to verify, and the comment is therefore considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses concern about the CNN experiments, stating they are not fully convincing. However, it lacks specific details or suggestions on how the authors might address this issue or improve the experiments. Without actionable feedback or guidance, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not provide sufficient depth or direction for the authors to act upon.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests comparing the authors' results with SoTA approaches, specifically mentioning HateXplain models as an example. This provides a clear and explicit action for the authors to take, as they can directly compare their results with these models. The comment is specific in its suggestion, guiding the authors on how to enhance their work by including such comparisons. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests comparing the authors' results with SoTA approaches, specifically mentioning HateXexplain models as an example. However, it does not specify which part of the paper this comparison should be made or where the results are discussed. This makes it difficult for the authors to identify the exact section or part of the paper that needs to be addressed. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the authors' results with SoTA approaches, specifically mentioning HateXplain models as an example. However, it does not provide any specific reasoning, examples, or references to support why this comparison is necessary or beneficial. The comment lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests comparing the authors' results with SoTA approaches, specifically mentioning HateXplain models as an example. This provides a clear and actionable direction for the authors to enhance their work by including such comparisons. By comparing their results with state-of-the-art models, the authors can better contextualize their findings and demonstrate the significance of their contributions. This feedback is specific and constructive, offering a concrete way for the authors to improve their draft. Therefore, the comment is mostly helpful, as it provides clear guidance but could be expanded to include more detailed suggestions or examples.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind using freezing in MLS selection, suggesting that if adaptive methods are effective, they should be used instead. While the comment implies that the use of freezing is not well-justified, it does not explicitly instruct the authors to remove or modify the use of freezing. The action is implicit, as the authors would need to infer that they should provide a clearer explanation for why freezing is used. However, the comment lacks concrete guidance on how to address this issue, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the rationale behind using freezing in MLS selection, suggesting that if adaptive methods are effective, they should be used instead. However, it does not specify which part of the paper discusses the use of freezing or the MLS selection process, making it difficult for the authors to pinpoint the exact section or part that needs clarification. The comment is specific in its suggestion to use adaptive methods, but it lacks grounding as it does not provide clear references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind using freezing in MLS selection, suggesting that if adaptive methods are effective, they should be used instead. However, the comment does not provide any specific reasoning, examples, or references to support why freezing is used or why adaptive methods might be preferable. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the rationale behind using freezing in MLS selection, suggesting that if adaptive methods are effective, they should be used instead. This feedback is somewhat helpful as it prompts the authors to clarify their choice of method and provide a justification for their decision. However, the comment lacks depth and does not offer specific suggestions or guidance on how to address the issue. The authors would need to infer that they should provide a clearer explanation for their choice of method, which limits the helpfulness of the comment. Therefore, it aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about whether the proposed knowledge-CLIP model addresses a specific issue and suggests that existing work has performed similar analyses. It also proposes an interesting idea for the authors to perform a similar analysis on their proposed model. However, the comment does not provide explicit guidance on how to conduct this analysis or what specific aspects of the model should be examined. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether the proposed knowledge-CLIP model addresses a specific issue and suggests that existing work has performed similar analyses. It provides a link to an external resource, which is helpful for context. However, the comment does not explicitly mention which part of the paper it is addressing, making it weakly grounded. It is specific in suggesting an analysis that could be performed on the proposed model, but without clear guidance on how to implement it. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about whether the proposed knowledge-CLIP model addresses a specific issue and suggests that existing work has performed similar analyses. It provides a link to an external resource, which is helpful for context. However, the comment lacks specific examples or detailed reasoning to fully support the claim that the proposed model could benefit from such analysis. While the suggestion is logical, the absence of concrete evidence or examples makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about whether the proposed knowledge-CLIP model addresses a specific issue and suggests that existing work has performed similar analyses. It provides a link to an external resource, which is helpful for context. The comment also proposes an interesting idea for the authors to perform a similar analysis on their proposed model, which could enhance its robustness. However, the comment lacks specific guidance on how to conduct this analysis or what aspects of the model should be examined. While it offers a valuable suggestion, the feedback could be more helpful if it included detailed instructions or examples. Therefore, the comment is somewhat helpful, as it provides some insight but requires further elaboration to fully assist the authors.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific questions about the use of p m and p c in Eq. 3 and the consideration of adding variance in Alg. 2. It also suggests using \u03bc g instead of \u03bc f for consistency with Eq. 3. While the comment identifies areas for clarification and potential improvement, it does not provide explicit instructions on how to address these issues or suggest specific actions to take. The actions are implicit and somewhat vague, as the authors are left to infer what needs to be done. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses issues in Eq. 3 and Alg. 2, specifically regarding the use of p m and p c in the numerator and p c in the denominator, as well as the consideration of adding variance in Alg. 2. It also suggests using \u03bc g instead of \u03bc f for consistency with Eq. 3. However, the comment does not explicitly mention which part of the paper these issues are located in, such as specific sections or equations. This makes it challenging for the authors to pinpoint the exact areas that need attention. While the comment is specific about the issues raised, the lack of explicit grounding makes it difficult for the authors to fully understand and address the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the use of p m and p c in Eq. 3 and the consideration of adding variance in Alg. 2. It also suggests using \u03bc g instead of \u03bc f for consistency. However, the comment does not provide any specific reasoning, examples, or references to support these claims or questions. The lack of detailed explanation or justification makes it difficult for the authors to understand the basis of the feedback or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several points for improvement, including questions about the use of p m and p c in Eq. 3, the consideration of adding variance in Alg. 2, and a suggestion to use \u03bc g instead of \u03bc f for consistency with Eq. 3. While the comment identifies areas where the authors could enhance their work, it lacks detailed guidance or specific suggestions on how to address these issues. The feedback is somewhat helpful as it points out potential areas for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the computational cost of the proposed approach, suggesting that the paper does not adequately explain why the additional cost did not result in significant delays. It also questions whether the approach might become prohibitive in certain settings. While the comment implies that the authors should provide a more comprehensive discussion of computational complexity, it does not explicitly instruct them to do so or offer specific guidance on how to address these issues. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the discussion of computational complexity. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the computational cost of the proposed approach, suggesting that the paper does not adequately explain why the additional cost did not result in significant delays. It also questions whether the approach might become prohibitive in some settings. However, the comment does not specify which part of the paper discusses the computational cost or where the authors should provide a more comprehensive discussion. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs attention. While the comment is specific in its critique of the computational cost, the absence of explicit references to the paper's sections or content makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the computational cost of the proposed approach, suggesting that the paper does not adequately explain why the additional cost did not result in significant delays. It also questions whether the approach might become prohibitive in some settings. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to fully understand and address the concerns raised. Therefore, the comment is considered borderline verifiable, as it provides some basis for concern but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's discussion of computational cost, specifically questioning why the additional cost did not lead to significant delays and whether the proposed approach might become prohibitive in certain settings. While the comment highlights a concern that could impact the paper's credibility and practical applicability, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it points out an area that needs further discussion, but it does not provide detailed advice or examples to enhance the authors' understanding or improve the paper's content. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider explaining how novel values in the test set are handled for clarity. This is an explicit action that the authors can directly implement by adding a brief explanation in the relevant section of the paper. The comment is specific and provides a clear direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific line number (l.97) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: explaining how novel values in the test set are handled for clarity. This provides the authors with a clear and precise direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should consider explaining how novel values in the test set are handled for clarity. This is a suggestion for improvement, but it does not contain a claim that requires verification or justification. The comment is factual and descriptive, aligning with the classification of \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is specific and actionable, as it suggests that the authors should clarify how novel values in the test set are handled for better understanding. This feedback is clear and provides a direct direction for improvement, allowing the authors to enhance the clarity of their paper. However, the comment could be more helpful if it offered additional suggestions or examples of how to improve the explanation. Overall, the comment is mostly helpful, as it provides a clear and actionable piece of feedback that the authors can readily address.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting the absence of in-depth analysis of the experimental results. It provides a specific example, asking for clarification on why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. This feedback is explicit and concrete, as it directly points out the need for a more detailed analysis and provides a clear direction for the authors to address this issue. The authors can infer that they should include a more thorough discussion of the experimental results, explaining the observed differences in model performance across different datasets. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for in-depth analysis of the experimental results, specifically questioning why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. This allows the authors to accurately identify the part of the paper that requires attention. The comment is also specific because it provides a clear example of what needs to be addressed, prompting the authors to delve deeper into the analysis of their experimental results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks in-depth analysis of the experimental results, specifically questioning why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of in-depth analysis of the experimental results. It specifically questions why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. This feedback is valuable as it highlights an area where the authors could enhance the depth and clarity of their analysis. However, the comment could be more helpful if it provided suggestions or guidance on how to conduct this additional analysis or what aspects of the results might warrant further exploration. Overall, the comment is somewhat helpful as it directs the authors to an important area for improvement, but it lacks detailed guidance on how to address the issue.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides several suggestions for improving the paper, such as using modern backbone baselines like ResNet50 or DenseNet121 for feature extraction, which is a concrete action. It also suggests that the current approach of training on labeled data with a few input mask explanation annotations might be too simplistic, and the reviewer expresses skepticism about its effectiveness. However, the comment does not offer specific guidance on how to implement these suggestions or address the skepticism. The action is somewhat explicit but lacks detailed guidance, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment provides specific suggestions for improving the paper, such as using modern backbone baselines like ResNet50 or DenseNet121 for feature extraction, which is a concrete action. It also expresses skepticism about the current approach of training on labeled data with a few input mask explanation annotations, suggesting that it might be too simplistic. However, the comment does not specify which part of the paper these suggestions relate to, making it weakly grounded. The specificity of the comment is moderate as it provides some guidance but lacks detailed examples or references. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the effectiveness of the proposed method, suggesting that the current approach might be too simplistic and that robustness/domain invariance interventions have failed in the past. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the skepticism. The reasoning is somewhat vague, and the claim is not fully verifiable without additional evidence or context. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment provides several suggestions for improving the paper, such as using modern backbone baselines like ResNet50 or DenseNet121 for feature extraction, which is a concrete action. It also expresses skepticism about the current approach of training on labeled data with a few input mask explanation annotations, suggesting that it might be too simplistic. However, the comment lacks specific guidance on how to implement these suggestions or address the skepticism, making it somewhat helpful. The feedback is valuable but could be more actionable with detailed guidance or examples. Therefore, the comment aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper introduces multiple hyperparameters and that a more extensive hyperparameter search could be beneficial for a fair comparison with the baseline. However, it does not provide explicit guidance on which hyperparameters to focus on or how to conduct the search. The action is implicit, as the authors need to infer that they should perform a more thorough hyperparameter search to ensure a fair comparison. While the comment is somewhat actionable, it lacks concrete details on how to implement the suggested action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper introduces multiple hyperparameters and that a more extensive hyperparameter search could be beneficial for a fair comparison with the baseline. However, it does not specify which hyperparameters are being referred to or provide any guidance on how to conduct the search. The comment lacks grounding as it does not identify a specific part of the paper that needs attention. It is also not specific because it does not detail what needs to be addressed in the hyperparameter search. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper introduces multiple hyperparameters and that a more extensive hyperparameter search could be beneficial for a fair comparison with the baseline. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. Without additional context or justification, the claim remains somewhat verifiable, as it is based on a logical inference but lacks concrete evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper by pointing out the extensive hyperparameter search conducted, which could lead to a fairer comparison with the baseline. However, the comment lacks specific guidance on which hyperparameters are critical or how to ensure a fair comparison. While it highlights an important aspect of the methodology, it does not provide actionable advice or suggestions for improvement, making it somewhat helpful. The authors would need to infer that they should focus on tuning the most critical hyperparameters to ensure a fair comparison, which limits the comment's helpfulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the definition of perplexity provided in the paper, stating that it is not accurate and that Equation 1 does not represent perplexity but rather cross-entropy. While the comment identifies a specific issue with the definition and provides a clear explanation of the discrepancy, it does not explicitly instruct the authors to revise the definition or Equation 1. The action is implicit, as the authors can infer that they need to correct the definition and potentially the equation. However, the comment lacks concrete guidance on how to implement these changes, such as suggesting specific revisions or providing examples. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions for action.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L259\" and \"Equation 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the definition of perplexity and Equation 1, explaining that they do not represent perplexity but rather cross-entropy. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the definition of perplexity on line 259 is incorrect and that Equation 1 does not represent perplexity but rather cross-entropy. This claim is supported by logical reasoning, as the authors provide a clear explanation of the discrepancy between the stated definition and the actual mathematical representation. However, the comment lacks specific examples or references to external sources that could further substantiate the claim. While the reasoning is sound, the absence of detailed examples or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the definition of perplexity in the paper, pointing out that it is not accurate and that Equation 1 does not represent perplexity but rather cross-entropy. This feedback is clear and actionable, as it directs the authors to correct the definition and potentially revise Equation 1. However, the comment could be more helpful if it provided additional guidance on how to accurately define perplexity or suggested alternative ways to represent it. Despite this, the comment offers valuable insights that can guide the authors in improving the accuracy and clarity of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include more baselines for graph contrastive learning, specifically mentioning MVGRL and gpt-gnn, and test them on common datasets. This provides a clear and explicit action for the authors to take, as they know exactly which baselines to add and where to test them. The comment is concrete, as it specifies the exact baselines and datasets to consider, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"graph classification task\" and suggests adding more baselines for graph contrastive learning, such as MVGRL and gpt-gnn. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies which baselines are missing and suggests testing them on common datasets. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the compared baseline in the graph classification task is not sufficient, suggesting the inclusion of MVGRL and gpt-gnn. However, the comment does not provide any reasoning or justification for why these specific baselines are missing or why they should be included. It lacks references or examples to support the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the baselines used in the graph classification task, noting that MVGRL and gpt-gnn are missing. It provides a clear suggestion to include these additional baselines and test them on common datasets. This feedback is actionable and constructive, as it guides the authors to enhance the comprehensiveness of their experimental evaluation. By addressing this feedback, the authors can strengthen the robustness and validity of their results, making the comment highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a major concern about the evaluation of the proposed strategies, specifically the method of purifying the input image before passing it to the model. It suggests that an adaptive attack against the edge map-based defense strategies could result in structural damage to the edge map. However, the reviewer emphasizes the need to evaluate the proposed defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map but mislead the model predictions. This feedback provides a clear and explicit action for the authors to take, which is to conduct a more comprehensive evaluation of their defense strategies. The comment is specific in its suggestion, detailing the type of adversarial attack that should be considered. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises a major concern about the evaluation of the proposed strategies, specifically the method of purifying the input image before passing it to the model. It suggests that an adaptive attack against the edge map-based defense strategies could result in structural damage to the edge map. However, the reviewer emphasizes the need to evaluate the proposed defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map but mislead the model predictions. This feedback provides a clear and explicit action for the authors to take, which is to conduct a more comprehensive evaluation of their defense strategies. The comment is specific in its suggestion, detailing the type of adversarial attack that should be considered. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the evaluation of the proposed strategies, specifically the method of purifying the input image before passing it to the model. It suggests that an adaptive attack against the edge map-based defense strategies could result in structural damage to the edge map. However, the reviewer emphasizes the need to evaluate the proposed defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map but mislead the model predictions. This feedback provides a clear and explicit action for the authors to take, which is to conduct a more comprehensive evaluation of their defense strategies. The comment is specific in its suggestion, detailing the type of adversarial attack that should be considered. Therefore, the claim is fully verifiable as it provides a clear and actionable direction for improvement.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment raises a significant concern about the evaluation of the proposed strategies, specifically the method of purifying the input image before passing it to the model. It highlights that an adaptive attack against the edge map-based defense strategies could result in structural damage to the edge map. However, the reviewer emphasizes the need to evaluate the proposed defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map but mislead the model predictions. This feedback provides a clear and actionable suggestion for the authors to enhance their evaluation process, ensuring that their defense strategies are robust against more sophisticated attacks. By addressing this concern, the authors can significantly improve the reliability and effectiveness of their proposed methods. Therefore, the comment is highly helpful, as it offers a specific and actionable direction for improvement.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the experimental results, noting that they lack standard deviations, making it difficult to assess the significance of the results. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue, such as including standard deviations in future experiments or analyses. Without concrete guidance on how to improve the results, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue as the lack of standard deviations, which makes it difficult to judge the significance of the results. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results do not contain standard deviations, making it difficult to judge the significance of the results. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the results lack standard deviations or how this affects their interpretation. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that they lack standard deviations, which makes it difficult to judge the significance of the results. This feedback is clear and actionable, as it highlights a critical aspect of the experimental analysis that needs to be addressed. However, the comment could be more helpful if it provided suggestions on how the authors might include standard deviations or discuss their implications. Despite this, the comment offers valuable guidance for improving the clarity and rigor of the experimental results, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the quality of generated images by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might improve the realism of their generated images, leaving them without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the quality of generated images by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. However, it does not specify which part of the paper this issue is discussed in, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs improvement. The comment is specific in identifying the issue with the realism of generated results, but it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the quality of generated images by the proposed method is limited, specifically noting that while continuous control is achieved, the realism of the results is limited. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the quality of generated images produced by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. This feedback is clear and actionable, as it highlights a key area for improvement in the paper. However, it could be more helpful if it provided suggestions on how to enhance the realism of the generated images or discussed potential methods for achieving this. Despite this, the comment offers valuable insight into an area that needs attention, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques a specific claim made in the paper regarding the Cycle Consistency loss, suggesting that it is not entirely accurate. It provides a counter-argument, stating that the loss can be iterated between two phases of reconstructions with two separate standard backpropagation processes. However, the comment does not offer any explicit or implicit suggestions on how the authors should revise or improve their draft to address this critique. The authors are left without guidance on what specific changes to make or how to clarify the issue. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (559-560) in the paper, allowing the authors to accurately identify the part being addressed. It also specifies what is incorrect, suggesting that the claim made in the paper is not entirely true and providing a counter-argument about the Cycle Consistency loss. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement on lines 559-560 is not entirely true, specifically regarding the Cycle Consistency loss. It provides a counter-argument, suggesting that the loss can be iterated between two phases of reconstructions with two separate standard backpropagation processes. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to verify the accuracy of the statement or understand the basis of the critique. Without detailed evidence or examples, the claim remains somewhat verifiable, as it lacks sufficient justification to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific claim made in the paper regarding the Cycle Consistency loss, suggesting that it is not entirely accurate. It provides a counter-argument, stating that the loss can be iterated between two phases of reconstructions with two separate standard backpropagation processes. However, the comment does not offer any suggestions or guidance on how the authors might address this critique or improve their draft. While it points out a potential issue, it lacks actionable advice, making it somewhat helpful. The authors are left without a clear path to address the feedback, which limits the comment's usefulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the term \"hyper-spectral\" is confusing and provides a definition of hyperspectral imaging. However, it does not offer any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or improve the clarity of their terminology. As a result, the authors are left without a clear path to follow, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the term \"hyper-spectral,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear definition of hyperspectral imaging, which helps the authors understand the confusion and how to clarify their terminology. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that calling \"hyper-spectral\" is confusing and provides a definition of hyperspectral imaging. However, it does not offer any evidence or reasoning to support why this term is confusing or how it impacts the paper. The comment lacks specific examples or references to clarify the issue, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the terminology used in the paper, specifically the term \"hyper-spectral.\" It suggests that this term might be confusing and provides a definition of hyperspectral imaging. However, the comment does not offer any actionable advice or suggestions on how the authors might address this confusion or improve the clarity of their terminology. While it points out a potential area for improvement, it lacks depth and does not provide guidance on how to implement the suggested changes. Therefore, the comment is barely helpful, as it identifies a problem but does not offer substantial assistance to the authors.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more detailed explanations of how each component contributes to the final performance improvements. It mentions specific examples, such as the combination of Linformer and window attention in Big Bird using contrition, to illustrate the need for such details. However, the comment does not explicitly instruct the authors to include these explanations or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more detailed explanations. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"1), 2) and 3) mentioned above,\" which allows the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, the contribution of each component to the final performance improvements, with an example provided. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should provide more detailed explanations of how each component contributes to the final performance improvements, with an example given. However, the comment lacks specific reasoning or references to support why this is necessary or how it would enhance the paper. Without additional context or justification, the claim remains somewhat verifiable, as it is based on an assumption rather than a well-supported argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors provide more detailed explanations of how each component contributes to the final performance improvements. It offers a concrete example, such as the combination of Linformer and window attention in Big Bird using contrition, to illustrate the need for such detailed explanations. This feedback is actionable and provides a clear direction for the authors to enhance their draft by adding more context and depth to their analysis. However, the comment could be more helpful if it included additional suggestions or guidance on how to present these explanations effectively. Overall, the comment is mostly helpful, as it offers valuable insights and actionable feedback that can guide the authors in improving their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the paper, including the lack of clarity regarding the role of visual information, the absence of explicit verification in the ablation study, and questions about the significance of the experimental results. However, it does not provide specific guidance or suggestions on how the authors should address these issues. The comment lacks actionable steps or concrete advice on how to improve the paper, leaving the authors without a clear path forward. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the role of visual information in the paper, noting that it is not explicitly discussed or verified. It mentions an ablation study in Table 10, where the performance of the model with and without the perception module is similar, and the implementation details of the \"w/o perception\" module are unknown. The comment also questions the significance of the experimental results given the sample size, suggesting that the improvements may not be significant. However, the comment does not specify which part of the paper discusses the role of visual information or the ablation study, making it weakly grounded. It is specific in detailing the issues with the ablation study and the experimental results, but without explicit references to sections or tables, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several concerns about the paper, including the lack of clarity regarding the role of visual information, the absence of explicit verification in the ablation study, and questions about the significance of the experimental results. The comment provides specific examples, such as the similar performance of the model with and without the perception module, and questions the statistical significance of the improvements given the sample size. However, it lacks detailed reasoning or references to support these claims, making it somewhat verifiable. The authors would need to infer the basis for these claims, which could be improved with more explicit justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several areas where the paper could be improved, specifically regarding the role of visual information, the lack of explicit verification in the ablation study, and questions about the statistical significance of the experimental results. It points out that the ablation study does not clearly demonstrate the effectiveness of the perception module, and the similar performance of the model with and without the perception module raises questions about the significance of the improvements. However, the comment lacks detailed suggestions or guidance on how the authors might address these issues, such as providing more explicit verification or conducting additional experiments to strengthen the claims. While it highlights important areas for improvement, the feedback could be more helpful if it included specific recommendations or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the notation used for results, specifically questioning the meaning of the percentage improvement claim for CIFAR-10. While the comment identifies a specific issue with the clarity of the notation, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the notation, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the notation used for results, particularly the unclear meaning of the percentage improvement claim for CIFAR-10. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the lack of clarity in the notation, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the notation for results is unclear and that the paper does not specify what the percentage improvement claim for CIFAR-10 means. However, the comment lacks any supporting evidence or reasoning to substantiate this claim. Without additional context or explanation, the authors are left to question the validity of the claim, making it difficult to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of notation used in the results section, noting that the paper claims a 3% improvement for CIFAR-10 but does not specify what the \"%p\" stands for. This feedback is clear and actionable, as it directs the authors to clarify the notation and provide a clear explanation of the percentage improvement. By addressing this issue, the authors can improve the readability and understanding of their results, making the comment highly helpful. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific claim made in the paper on line 238, which is that the Central Limit Theorem (CLT) implies that a normally distributed random variable can be produced through a finite linear combination of any random variables. The reviewer points out that this statement is incorrect, as the CLT does not guarantee Gaussianity in a non-asymptotic regime and does not hold for a finite linear combination of arbitrary random variables. The comment provides a clear and explicit action for the authors to take, which is to correct this specific claim. It also offers detailed reasoning about why the claim is incorrect, making it highly actionable. The authors know exactly what part of the paper needs revision and what specific issue needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly identifies the incorrect claim made about the Central Limit Theorem (CLT) and provides detailed reasoning about why the statement is incorrect. This allows the authors to understand exactly what needs to be corrected. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' statement on line 238, \"According to the Central Limit Theorem (CLT), a normally distributed random variable can be produced through a finite linear combination of any random variables,\" is incorrect. The reviewer provides specific reasoning, explaining that the CLT does not guarantee Gaussianity in a non-asymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This detailed explanation supports the claim, making it fully verifiable. The comment is clear, logical, and provides sufficient evidence for the authors to understand and address the issue. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific and incorrect claim made in the paper regarding the Central Limit Theorem (CLT). It provides a clear and detailed explanation of why the claim is incorrect, highlighting that the CLT does not guarantee Gaussianity in a non-asymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is actionable and constructive, as it guides the authors to correct the inaccurate statement and improve the accuracy of their claims. The comment is specific and provides a clear direction for improvement, making it highly beneficial for the authors. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to analyze the time complexity of the proposed policies mentioned in Section 4. This provides a clear and direct action for the authors to take, as they know exactly what needs to be addressed. The comment is specific and concrete, giving the authors a precise direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly instructs the authors to analyze the time complexity of the proposed policies mentioned in that section. This provides a clear and actionable direction for the authors to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual statement, as it instructs the authors to analyze the time complexity of the proposed policies mentioned in Section 4. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and specific, instructing the authors to analyze the time complexity of the proposed policies mentioned in Section 4. This provides a clear and actionable direction for the authors to improve their draft by addressing a specific aspect of their work. The feedback is concise and directly helpful, making it a valuable piece of guidance. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the use of an automatic metric TSS for human evaluation, suggesting that a human metric would be more convincing. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit, as the authors need to infer that they should consider using a human metric for evaluation. While the comment is somewhat actionable, it lacks concrete details on how to implement the suggested change. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the use of an automatic metric TSS for human evaluation, suggesting that a human metric would be more convincing. However, it does not specify which part of the paper discusses the human evaluation or the use of TSS. This makes it difficult for the authors to identify the exact section or aspect of the paper that needs attention. While the comment is specific about the issue of using an automatic metric, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of an automatic metric TSS for human evaluation, suggesting that a human metric would be more convincing. However, the comment does not provide any specific reasoning, examples, or references to support why an automatic metric is less convincing or why a human metric is preferable. Without additional justification or evidence, the claim lacks sufficient support, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the use of an automatic metric TSS for human evaluation, questioning its effectiveness compared to a human metric. This feedback is somewhat helpful as it identifies a potential weakness in the evaluation methodology, which could impact the convincingness of the human evaluation. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what changes they could make to their draft. Without actionable advice or detailed recommendations, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiments should be expanded to include more diverse domains, specifically mentioning TD-MPC 2. While the comment implies that the current experiments are sufficient to prove the point, it does not explicitly instruct the authors to include experiments across more diverse domains. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct additional experiments. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments should be expanded to include more diverse domains, specifically mentioning TD-MPC 2. However, it does not specify which part of the paper the experiments are currently located in, making it difficult for the authors to identify the exact section that needs improvement. The comment is specific in its suggestion to include experiments across more diverse domains, but it lacks grounding as it does not provide clear guidance on which part of the paper to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments should be expanded to include more diverse domains, specifically mentioning TD-MPC 2. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would strengthen the paper. The comment lacks detailed justification, making it difficult for the authors to understand the basis for the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the experiments should be expanded to include more diverse domains, specifically mentioning TD-MPC 2. This feedback is somewhat helpful as it identifies a potential area for improvement in the experimental design, which could strengthen the paper's claims. However, the comment lacks specificity and does not provide detailed guidance on how to implement this suggestion or what specific domains should be included. Without additional details, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the main contribution of the paper is demonstrating the effectiveness of combining existing techniques, rather than proposing novel ones. However, it does not provide explicit guidance on how the authors should address this point or what specific actions they should take to improve their draft. The comment lacks concrete suggestions or detailed instructions on how to enhance the paper, leaving the authors with a general idea but no clear path forward. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider, namely that the approaches in Sec. 5 are straightforward and standard, and that the main contribution is demonstrating the effectiveness of combining existing techniques. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main contribution of the paper is showing the effectiveness of combining existing techniques, rather than proposing novel ones. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or evidence to substantiate the assertion that the approaches in Section 5 are standard or have been explored in previous literature. Without such evidence, the claim remains somewhat speculative and difficult for the authors to address effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a critique of the paper's main contribution, suggesting that it primarily demonstrates the effectiveness of combining existing techniques rather than proposing novel ones. While this feedback offers a clear direction for the authors to consider, it lacks specific suggestions or actionable advice on how to address this critique or enhance the paper's contribution. The comment is somewhat helpful as it identifies a potential area for improvement, but it does not provide detailed guidance or examples to help the authors make meaningful changes. Therefore, it aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the training of RegMixup, suggesting that it sees 2x samples per iteration, which could lead to a slower running speed compared to other methods. The authors are questioned about the fairness of this comparison. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the training process. While it identifies a potential problem, it lacks concrete suggestions or actions for the authors to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the training of RegMixup, specifically mentioning that it sees 2x samples per iteration, which could lead to a slower running speed compared to other methods. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the potential issue with the training process, but without clear references to the relevant sections, it is difficult for the authors to pinpoint the exact area needing attention. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the training of RegMixup sees 2x samples per iteration, leading to a slower running speed compared to other methods. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without detailed justification or examples, the claim remains unverifiable, as the authors cannot independently verify the accuracy or significance of the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the training of RegMixup, specifically noting that it sees 2x samples per iteration, which could lead to a slower running speed compared to other methods. The authors are questioned about the fairness of this comparison, which is a valid concern. However, the comment lacks actionable suggestions or detailed guidance on how to address this issue or improve the comparison. While it highlights a potential problem, it does not provide specific steps or recommendations for the authors to take, making it somewhat helpful. The feedback is clear but could be more comprehensive to fully assist the authors in improving their draft.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about potential modifications to the method, specifically regarding the need to visit all ball-action pairs in each iteration. It suggests exploring the possibility of relaxing this requirement by partially covering the pairs. However, the comment does not provide explicit guidance on how to implement these suggestions or what specific actions the authors should take. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"continuation to the above remark,\" indicating a specific part of the paper being addressed. It also specifies what needs to be addressed, namely, the need to relax the requirement of visiting all ball-action pairs with each iteration and explores the possibility of partially covering them. This provides clear guidance on what the authors should consider and how they might approach the issue. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about potential modifications to the method, specifically regarding the need to visit all ball-action pairs in each iteration. It suggests exploring the possibility of relaxing this requirement by partially covering the pairs. However, the comment does not provide any specific reasoning, examples, or references to support why this modification might be beneficial or how it could be implemented. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors may need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about potential modifications to the method, specifically regarding the need to visit all ball-action pairs in each iteration. It suggests exploring the possibility of relaxing this requirement by partially covering the pairs, which could potentially improve efficiency. However, the comment does not provide specific guidance on how to implement these suggestions or what minimal assumptions might be needed. While it identifies an area for improvement, the lack of detailed feedback or actionable steps limits its helpfulness. The comment is somewhat helpful as it points out a potential area for enhancement but does not fully address the authors' needs for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique across tasks with varying levels of reasoning requirements. However, the comment does not provide explicit guidance on how to implement this suggestion, such as which specific datasets to include or how to analyze the results. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps to address the comment. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique across tasks with varying levels of reasoning requirements. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to include more datasets, but without clear grounding, the authors may struggle to identify the exact section or part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique across tasks with varying levels of reasoning requirements. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion or how to implement it effectively. Without detailed justification or examples, the claim is somewhat verifiable, as it provides a general direction but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique across tasks with varying levels of reasoning requirements. This feedback is somewhat helpful as it identifies a potential area for improvement in terms of the breadth of the evaluation. However, the comment lacks specific guidance on which datasets to include or how to analyze the results, making it somewhat vague and incomplete. The authors would benefit from additional details on how to implement this suggestion effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the choice of baseline methods could be improved, particularly for the appearance decomposition part, by comparing to other existing methods like Ref-NeRF. It also recommends using MipNerf as a baseline for larger outdoor scenes. While the comment provides specific examples of potential baselines, it does not explicitly instruct the authors to implement these suggestions or provide detailed guidance on how to compare the methods. The action is implicit and somewhat vague, as the authors need to infer that they should include these baselines in their evaluation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the choice of baseline methods, specifically mentioning Ref-NeRF and MipNerf for comparison, particularly in the appearance decomposition part and for larger outdoor scenes. However, it does not specify which part of the paper discusses these methods or where the comparison should be made. This makes it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in its suggestions but weakly grounded as it lacks explicit references to the paper sections. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the choice of baseline methods could be improved, particularly for the appearance decomposition part, by comparing to other existing methods like Ref-NeRF. It also recommends using MipNerf as a baseline for larger outdoor scenes. However, the comment does not provide specific reasoning or evidence to support why these methods are suitable or how they would improve the evaluation. The suggestions are somewhat vague and lack detailed justification, making it difficult for the authors to understand the basis for these recommendations. Therefore, the comment is rated as 2: Borderline Verifiable, as it offers some direction but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the choice of baseline methods, particularly in the context of appearance decomposition and larger outdoor scenes. It recommends comparing against existing methods like Ref-NeRF and MipNerf, which could enhance the evaluation of the paper. However, the comment lacks detailed guidance on how to implement these suggestions or what specific aspects of the comparison should be emphasized. While it offers a clear direction for improvement, the feedback could be more helpful if it included additional details or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant concern regarding the lack of implementation details for the proposed methods, which could hinder the reader's understanding. It suggests that these details should be included in Section 4.1. However, the comment does not provide specific guidance on what aspects of the implementation details are missing or how they should be described. The authors are left with a general idea of what needs to be addressed but lack concrete instructions on how to implement the suggested changes. Therefore, the comment is somewhat actionable, as it identifies an action but lacks detailed guidance on its execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific concern regarding the lack of implementation details for the proposed methods, which is a clear issue that needs to be addressed. It explicitly mentions that these details should be described in Section 4.1, providing a clear reference point for the authors. However, the comment does not specify what aspects of the implementation details are missing or how they should be described, leaving some room for interpretation. This makes the comment weakly grounded but specific, as it clearly identifies the issue and the section where it should be addressed. Therefore, the comment aligns with category 3: Weakly Grounded and Specific.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a concern regarding the lack of implementation details for the proposed methods, which could hinder the reader\\'s understanding. It suggests that these details should be included in Section 4.1. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the lack of implementation details is a significant issue. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the lack of implementation details for the proposed methods, which could hinder the reader\\'s understanding of the paper. It suggests that these details should be included in Section 4.1, providing a clear direction for the authors to improve their draft. However, the comment lacks specific guidance on what aspects of the implementation details are missing or how they should be described. While it points out a crucial area for improvement, it does not offer detailed suggestions or examples, which could make it somewhat helpful. Therefore, the comment aligns with a score of 3, as it provides a clear direction but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with the paper, noting the absence of empirical evaluation and comparison with other methods. It also points out the lack of clarity regarding the practical value of the contribution, suggesting that even a theoretical paper should address this. The comment implies that the authors should provide empirical evidence and comparisons to demonstrate the practical value of their contribution. However, it does not specify which parts of the paper need to be revised or how to conduct the empirical evaluation. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of empirical evaluation and comparison with other methods, which are specific areas of the paper that need improvement. It also highlights the absence of clarity regarding the practical value of the contribution, which is a critical aspect of the paper. The comment is specific in detailing what needs to be addressed, such as providing empirical evidence and comparisons. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks empirical evaluation and comparison with other methods, making it unclear about the practical value of the contribution. It suggests that even theoretical papers should address this. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed explanation makes it difficult for the authors to understand and address the issue effectively. Therefore, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of empirical evaluation and comparison with other methods. It highlights the absence of clarity regarding the practical value of the contribution, which is a significant concern for a theoretical paper. The comment suggests that even theoretical papers should address the practical value of their contributions, implying that the paper is not suitable for publication at NeurIPS. While the comment points out a major weakness, it does not provide specific suggestions or guidance on how to address the issue. The feedback is somewhat helpful as it directs the authors to consider the practical value of their work, but it lacks actionable advice on how to improve the paper. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method discussed in the paper can be applied in general MDP but is limited in navigation problems. It also mentions that combining RL and planning has been discussed in PRM-RL and asks if the algorithms can be applied in more general tasks. While the comment identifies a potential area for expansion, it does not provide explicit guidance on how to address the limitations or explore the application of the algorithms in more general tasks. The action is implicit and somewhat vague, as the authors are left to infer how to implement the suggested improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the applicability of the method discussed in the paper to general MDPs, specifically noting that it is limited in navigation problems. It also mentions that combining RL and planning has been discussed in PRM-RL, suggesting that the authors might explore applying such algorithms in more general tasks. However, the comment does not explicitly mention which part of the paper discusses the method or navigation problems, making it weakly grounded. The comment is specific in detailing the limitations and suggesting potential areas for expansion, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method discussed in the paper can be applied in general MDP but is limited in navigation problems. It also mentions that combining RL and planning has been discussed in PRM-RL and suggests exploring the application of such algorithms in more general tasks. However, the comment lacks specific examples or detailed reasoning to support the claim that the method is limited to navigation problems or that the combination of RL and planning has already been discussed in PRM-RL. Without additional context or references, the claim is difficult to verify, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, noting that the method discussed can be applied in general MDPs but is limited in navigation problems. It also points out that combining RL and planning has been discussed in PRM-RL, suggesting that the authors might explore applying such algorithms in more general tasks. While the comment highlights an area for potential expansion and suggests a direction for future work, it does not provide specific guidance or detailed feedback on how to address the identified limitations or how to apply the algorithms in more general tasks. The feedback is somewhat helpful as it directs the authors to consider broader applications, but it lacks depth and actionable suggestions, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the suitability of feature spaces for 1-NN and suggests that if a feature space is not close to a spherical Gaussian, it may perform poorly. It also provides a suggestion that individual standardization of feature dimensions could avoid this issue. However, the comment does not explicitly instruct the authors to address this concern or provide specific guidance on how to improve the feature space or the 1-NN performance. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the suitability of their feature space and potentially standardize it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by questioning the suitability of feature spaces for 1-NN and suggesting that standardizing feature dimensions could improve performance. This provides clear guidance on how to address the issue. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the suitability of feature spaces for 1-NN and suggests that standardizing feature dimensions could improve performance. While it provides a logical reasoning for the concern, it lacks specific examples or references to support the claim that feature spaces not close to a spherical Gaussian may perform poorly. The suggestion to standardize feature dimensions is clear, but the overall claim is somewhat verifiable as it lacks detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the suitability of feature spaces for 1-NN and provides a suggestion that standardizing feature dimensions could improve performance. While it identifies a potential issue with the feature space, it does not offer detailed guidance or specific advice on how to address this concern. The comment is somewhat helpful as it highlights an area for improvement, but it lacks depth and actionable suggestions, leaving the authors with limited insight into how to enhance their work. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific feedback on two aspects of the paper: the description of state changes and environment giving a reward in section 3.1, line 143, and the clarity of the action description in line 154. It explicitly points out that the statement is not true of standard MDP formulations, suggesting that the authors may be misrepresenting the reward structure. Additionally, it notes that the description of each action being a single feature or the power set is unclear, recommending that the authors make the description more precise. While the comment is explicit in identifying the issues, it lacks detailed guidance on how to address these concerns, such as providing examples or specific suggestions for clarification. Therefore, the comment is somewhat actionable, as it identifies the areas needing improvement but does not provide concrete steps for the authors to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.1, line 143\" and \"line 154,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on the content of these sections, pointing out that the statement about state changes and environment giving a reward is not true of standard MDP formulations and that the description of each action being a single feature or the power set is unclear. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement in section 3.1, line 143, \"Then the state changes and environment gives a reward,\" is not true of standard MDP formulations. This claim is supported by the reasoning that in standard MDPs, rewards are typically associated with transitions between states, not directly with state changes or environment interactions. The comment also points out that the description of each action being a single feature or the power set is unclear, suggesting that the authors should make the description more precise. While the reasoning is logical and provides a basis for the claim, it could be strengthened by including specific examples or references to standard MDP formulations. Therefore, the comment is mostly verifiable, as it is well-supported but lacks some depth in explanation or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific feedback on two key areas of the paper. It points out that the statement in section 3.1, line 143, \"Then the state changes and environment gives a reward,\" is not accurate for standard MDP formulations, suggesting that the authors may be misrepresenting the reward structure. This feedback is valuable as it highlights a potential misunderstanding or error in the paper's description. Additionally, the comment notes that the description of each action being a single feature or the power set is unclear, recommending that the authors make the description more precise. This feedback is actionable and constructive, as it provides clear guidance on how the authors can improve the clarity and accuracy of their work. However, the comment could be more helpful if it included specific suggestions or examples for how to clarify these points. Overall, the comment is mostly helpful, as it identifies important areas for improvement and provides a basis for the authors to enhance their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that other baselines should be included, referencing specific works in the related work section. It also indicates that the authors have addressed their concerns in a response, leading to an increase in the score. However, the comment does not provide explicit guidance on how to incorporate these additional baselines or how to test beforehand whether they are suitable. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"related work [29, 5, 6]\" and \"other works discussed in related work,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies that the authors should include other baselines, such as those discussed in the related work section, and suggests that this would be beneficial. The comment is specific in detailing what needs to be addressed, including the inclusion of additional baselines and the testing of the chosen baseline. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that other baselines should be included, referencing specific works in the related work section. It suggests that the authors should consider adding these baselines to the final version of the paper. However, the comment lacks specific examples or detailed reasoning to support why these additional baselines are necessary or how they would enhance the paper. The claim is somewhat verifiable as it provides a general direction but lacks detailed justification or references. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper by suggesting the inclusion of additional baselines, referencing specific works in the related work section. It also acknowledges that the authors have addressed their concerns in a response, which led to an increase in the score. However, the comment lacks detailed guidance on how to incorporate these additional baselines or how to test them beforehand. While it provides a direction for improvement, the feedback could be more helpful if it included specific suggestions or examples of how to enhance the paper with additional baselines. Therefore, the comment is somewhat helpful, as it offers some insight but could be more comprehensive and actionable.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the use of the phrase \"to meet\" in the paper, noting that it is difficult to understand. While the comment identifies a problem with the language, it does not provide any explicit guidance or suggestions on how the authors might address this issue. The authors are left without a clear understanding of what changes are needed to improve the clarity of the text. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the use of the phrase \"to meet\" in the paper, specifically on line 280. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is problematic, namely the difficulty in understanding the use of \"to meet\". Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of \"to meet\" in the paper is pervasive and difficult to understand. However, the comment does not provide any specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of the phrase \"to meet\" in the paper, noting that it is difficult to understand. While the comment highlights a potential area for improvement in clarity, it does not provide any suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a specific area that needs attention, but it lacks depth and actionable advice, leaving the authors with limited insight into how to improve the draft. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the limitations of the method, specifically in the context of a graph case where the network was described as \"pretty shallow.\" However, it does not provide explicit guidance on what actions the authors should take to address these limitations or how to improve the network architecture. The comment lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable because it does not offer clear or actionable steps for the authors to follow. Therefore, it aligns with a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises questions about the limitations of the method, specifically in the context of a graph case where the network was described as \"pretty shallow.\" However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is not grounded as it lacks specific references to sections, tables, or figures. Additionally, it does not provide specific guidance on what needs to be addressed or how to improve the network architecture. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises questions about the limitations of the method, specifically in the context of a graph case where the network was described as \"pretty shallow.\" However, it does not provide any specific evidence, reasoning, or references to support these claims. The comment lacks detailed justification or examples to substantiate the assertion about the network architecture. Without additional context or evidence, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises questions about the limitations of the method, specifically in the context of a graph case where the network was described as 'pretty shallow.' This feedback highlights a potential area for improvement in the paper, suggesting that the authors should consider addressing the limitations of their method or providing more detailed information about the network architecture. However, the comment lacks specific guidance or suggestions on how to address these limitations or what changes might be necessary. While it identifies an area for improvement, the lack of actionable advice makes it somewhat helpful, as it provides a starting point for the authors to consider but does not fully support their needs for improvement. Therefore, the comment aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed method should be evaluated in machine translation to provide a more convincing evaluation. It implies that the current evaluation, which only includes answer generation and summarization, is limited because these tasks are close to \"open domain\" generation rather than \"close domain\" generation like machine translation. The comment provides a clear action for the authors to take, which is to expand the evaluation to include machine translation. This action is explicit and concrete, as it specifies exactly what needs to be done to improve the evaluation. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the proposed method should be evaluated in machine translation to provide a more convincing evaluation. It highlights that the current evaluation, which only includes answer generation and summarization, is close to \"open domain\" generation rather than \"close domain\" generation like machine translation. The comment implies that expanding the evaluation to include machine translation would strengthen the paper. However, it does not specify which part of the paper discusses the evaluation methodology or where the suggestion to include machine translation evaluation should be addressed. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper it addresses. The comment is specific in suggesting an additional evaluation method, but without explicit grounding, it is difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is evaluated using only answer generation and summarization, which are close to \"open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that evaluating the method in machine translation would provide a more convincing evaluation due to the lower uncertainties per word. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is logical but lacks detailed evidence, which could be improved with additional references or examples. Therefore, the comment is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation methodology of the proposed method, noting that it only uses answer generation and summarization, which are close to \"open domain\" generation rather than \"close domain\" generation like machine translation. The comment suggests that including machine translation evaluation would provide a more convincing assessment of the method's effectiveness, as it would exhibit lower uncertainties per word. This feedback is clear and actionable, as it provides a specific suggestion for improvement that could enhance the paper's credibility. However, the comment could be more helpful if it offered additional guidance on how to conduct the machine translation evaluation or why this additional evaluation would be beneficial. Overall, the comment is mostly helpful, as it effectively highlights a gap in the evaluation and provides a clear direction for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implementation details of the dropout mechanism, specifically asking for clarification on the dropping rate and the number of masks generated. While the comment is explicit in its request for clarification, it does not provide any guidance or suggestions on how the authors might address these questions or improve their draft. The action is implicit, as the authors need to infer that they should clarify these details in their paper. However, the lack of concrete guidance on how to implement or address these questions makes the comment somewhat actionable. Therefore, it aligns with a score of 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"dropout\" and refers to the \"response letter,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the \"dropping rate\" and the \"number of masks generated,\" providing clear guidance on what needs to be addressed. Therefore, this comment is classified as fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the implementation details of the dropout mechanism, specifically asking for clarification on the dropping rate and the number of masks generated. While the comment is factual and seeks clarification, it does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the implementation details of the dropout mechanism, asking for clarification on the dropping rate and the number of masks generated. This feedback is clear and actionable, as it directs the authors to provide more detailed information about their implementation. However, the comment could be more helpful if it suggested ways to address these questions or provided guidance on how to improve the clarity of the explanation. Overall, the comment is somewhat helpful as it identifies a specific area for improvement but lacks depth in terms of actionable suggestions. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need for further justification of the effectiveness of the proposed two-stage optimization approach. It suggests that the authors should include comparisons with other single-stage attacks and provide proper benchmarks and comparisons with state-of-the-art algorithms to substantiate the effectiveness of the technical contributions. While the comment explicitly suggests what needs to be done, it lacks specific guidance on how to conduct these comparisons or what benchmarks to use. The action is clear but somewhat vague, as it does not provide detailed instructions on implementation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the effectiveness of the proposed two-stage optimization approach, suggesting that it needs further justification. It mentions the need for comparisons with other single-stage attacks and proper benchmarks and comparisons with state-of-the-art algorithms. However, the comment does not specify which part of the paper discusses the proposed approach or where these comparisons should be made. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific about the need for additional comparisons, it lacks grounding as it does not provide clear references or sections to address. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the effectiveness of the proposed two-stage optimization approach needs further justification. It suggests that the authors should include comparisons with other single-stage attacks and provide benchmarks and comparisons with state-of-the-art algorithms to substantiate the effectiveness. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to fully understand and address the feedback. Therefore, the claim is considered borderline verifiable, as it provides some basis for the suggestion but lacks sufficient detail or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper by highlighting the need for further justification of the effectiveness of the proposed two-stage optimization approach. It suggests that the authors should include comparisons with other single-stage attacks and provide benchmarks and comparisons with state-of-the-art algorithms to substantiate the effectiveness of their technical contributions. This feedback is clear and actionable, as it provides specific areas for improvement and guidance on how to strengthen the paper. However, the comment could be more helpful if it included suggestions on which specific benchmarks or comparisons to include. Overall, the comment is mostly helpful, as it effectively guides the authors in addressing a significant aspect of their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific sentence in the paper that is confusing and requires clarification. It suggests that the authors should re-read the sentence and the subsequent sentences to understand it better. However, the comment does not provide explicit guidance on how to clarify the sentence or what specific changes should be made. The action is implicit, as the authors need to infer that they should clarify the confusing sentence. The action is vague because it does not specify what kind of clarification is needed or how to achieve it. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, which is the sentence in lines 93-95. This allows the authors to accurately identify the section being discussed. The comment is also specific because it clearly identifies a problem with the sentence, stating that it is confusing and requires clarification. The authors are informed about the exact location of the issue, making it easy for them to address it. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a specific sentence in the paper is confusing and requires clarification. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or explanation, the authors cannot verify the claim or understand why it is problematic. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with a sentence in the paper, noting that it is confusing and requires clarification. While the comment highlights a potential area for improvement, it does not provide detailed guidance or suggestions on how to clarify the sentence or what specific changes might be necessary. The feedback is somewhat helpful as it points out a need for clarification, but it lacks depth and actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between Figure 1 and Figure 2, noting that Figure 1 shows a single shared encoder-decoder for multiple tasks, while Figure 2 shows one encoder-decoder per auxiliary task. This observation points out a potential inconsistency in the figures. However, the comment does not provide explicit guidance on how the authors should address this inconsistency or what changes need to be made to the figures. The action is implicit and vague, as the authors are left to infer that they need to clarify or correct the figures. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the inconsistency in the number of encoder-decoders shown in the two figures. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between Figure 1 and Figure 2, noting that Figure 1 shows a single shared encoder-decoder for multiple tasks, while Figure 2 shows one encoder-decoder per auxiliary task. This observation is a factual claim that is supported by the visual representation of the figures. However, the comment does not provide additional context, reasoning, or references to substantiate the claim further. While the claim is verifiable based on the figures, the lack of detailed explanation or examples makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific inconsistency between Figure 1 and Figure 2, noting that Figure 1 shows a single shared encoder-decoder for multiple tasks, while Figure 2 shows one encoder-decoder per auxiliary task. This observation is clear and highlights a potential issue with the figures. However, the comment does not provide any suggestions or guidance on how the authors might address this inconsistency or improve the figures. While it points out a problem, it lacks actionable advice, making it somewhat helpful. The authors are left to infer that they need to clarify or correct the figures, but without further guidance, the feedback is limited in its usefulness. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether each node attends to its own lower-level representation, suggesting that only neighboring nodes are attended to based on the description of equation 2. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the representation of each node. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions whether each node attends to its own lower-level representation, suggesting that only neighboring nodes are attended to based on the description of equation 2. However, the comment does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. While the authors can infer that it relates to the description of equation 2, the lack of explicit mention or clear grounding makes the comment weakly grounded. The comment is specific in questioning the representation of each node, but the lack of grounding limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions whether each node attends to its own lower-level representation, suggesting that only neighboring nodes are attended to based on the description of equation 2. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to interpret the question, making it difficult to verify the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the representation of each node in the context of the described attention mechanism. It points out a potential inconsistency between the description of equation 2 and the claim that only neighboring nodes are attended to. This feedback is somewhat helpful as it highlights a potential area of confusion or ambiguity in the paper, prompting the authors to clarify their representation of node attention. However, the comment could be more helpful if it provided suggestions or guidance on how to address this issue, such as suggesting a more detailed explanation or revising the description of equation 2. Overall, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions how the inequality after line 433 follows from Lemma 7, suggesting that it might be a combination of previous inequalities. The comment implies that the authors should clarify the connection between Lemma 7 and the inequality, but it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should elaborate on the derivation of the inequality from Lemma 7. However, the comment lacks concrete details on how to implement this action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l433,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the derivation of the inequality after line 433 from Lemma 7. The comment provides a clear and detailed request for clarification, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the derivation of an inequality from Lemma 7, specifically asking for clarification on how the inequality after line 433 follows from the previous inequalities. While the comment does not contain a subjective claim, it does suggest that the authors should provide more context or explanation to improve the clarity of their work. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would benefit from additional details or examples to address the reviewer's concern, which would enhance the verifiability of the feedback.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific point of confusion regarding the derivation of an inequality from Lemma 7, which is a crucial aspect of the paper. It requests clarification on how the inequality after line 433 follows from the previous inequalities, suggesting that the authors should provide more context or explanation to improve the clarity of their work. While the comment is clear and identifies a specific area for improvement, it lacks detailed guidance on how to address the issue or what specific changes might be necessary. This makes the feedback somewhat helpful, as it provides a clear direction for the authors to improve their draft, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the paper, including the unclear main contribution, the overstated novelty claims, and the lack of clarity in how the proposed method copes with dynamic large-scale multitasking and how automation is achieved. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The actions are implicit and vague, as the authors are left to infer what needs to be done to clarify these aspects. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the main contribution of the paper, noting that it is unclear and that the novelty claims are overstated or not well-supported. It also points out the lack of clarity in how the proposed method copes with dynamic large-scale multitasking and how automation is achieved. However, the comment does not specify which part of the paper discusses the main contribution, making it weakly grounded. The specificity of the comment is moderate as it identifies areas that need clarification, but it does not provide detailed guidance on how to address these issues. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the main contribution of the paper is unclear and that the novelty claims are overstated or not well-supported. It also notes the lack of clarity in how the proposed method copes with dynamic large-scale multitasking and how automation is achieved. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique, rendering the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several areas where the paper could be improved, specifically focusing on the clarity of the main contribution and the novelty claims. It points out that the paper claims the proposed method possesses 8 novel properties, but these claims are either overstated or not well-supported. Additionally, the comment highlights the lack of clarity in how the proposed method copes with dynamic large-scale multitasking and how automation is achieved. While the comment provides some insight into areas needing improvement, it lacks detailed guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it directs the authors to specific areas that require clarification, but it could be more comprehensive with additional guidance on how to improve the paper's presentation and argumentation. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the claim of using \"annotation guideline\" in the paper, suggesting that it may be an overstatement. It provides specific examples from the TACRED slot filling guidelines, such as the rule for city of birth, to illustrate the complexity of annotation guidelines in the Information Extraction (IE) domain. However, the comment does not offer any explicit or implicit suggestions on how the authors might address this issue or improve their approach. It lacks concrete guidance on what changes could be made to align the paper with the depth of true guideline understanding. As a result, the authors are left without actionable steps to take, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"annotation guideline\" claim, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider, namely that the paper only considers label names, descriptions, and few-shot examples, while annotation guidelines in the IE domain are complex and curated by linguists. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper may be overstating its use of \"annotation guideline\" by only considering label names, descriptions, and few-shot examples. It provides specific examples from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the Information Extraction (IE) domain. The comment is mostly verifiable as it offers a clear rationale and examples to support the claim, but it could be strengthened by including more detailed references or a broader range of examples. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a potential overstatement in the paper's claim regarding the use of \"annotation guideline.\" It provides specific examples from the TACRED slot filling guidelines, such as the rule for city of birth, to illustrate the complexity of annotation guidelines in the Information Extraction (IE) domain. This critique highlights a gap in the paper's consideration of the depth of true guideline understanding, suggesting that the prompts proposed might not fully capture this complexity. However, the comment could be more helpful if it offered suggestions on how the authors could address this issue or improve their approach to align with the depth of true guideline understanding. Overall, the feedback is valuable and provides a clear direction for improvement, making it a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiment comparison is weak because the authors only compare their method to the BERT-baseline. It recommends comparing the method to token pruning and token combination baselines. While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to conduct these additional comparisons. The authors are left to infer that they need to add these comparisons to their experimental setup. This lack of explicit guidance makes the action somewhat vague and leaves the authors with limited direction on how to implement the suggested improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiment comparison is weak, specifically mentioning that the authors only compare their method to the BERT-baseline. It recommends comparing the method to token pruning and token combination baselines. However, the comment does not specify which part of the paper this comparison is intended for, such as a specific section or table. This makes it difficult for the authors to accurately identify the section being addressed, resulting in weak grounding. The comment is specific in suggesting additional comparisons, but the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiment comparison is weak, as the authors only compare their method to the BERT-baseline. It suggests that the authors should compare their method to token pruning and token combination baselines. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed reasoning or evidence, the claim is considered borderline verifiable, as it provides a general suggestion but lacks the necessary depth to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the experimental comparison, noting that the authors only compare their method to the BERT-baseline. It suggests that the authors should include comparisons to token pruning and token combination baselines to provide a more comprehensive evaluation of their method. This feedback is clear and actionable, as it directs the authors to specific areas where they can enhance their experimental setup. However, the comment could be more helpful if it provided additional guidance on how to conduct these comparisons or why these baselines are particularly relevant. Overall, the comment is mostly helpful, as it offers valuable suggestions for improvement but could be more detailed in its guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential weakness in the paper by stating that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might identify or discuss these weaknesses, leaving the authors without a clear path forward. As a result, the comment is unactionable, as it does not offer any actionable steps or suggestions for improvement.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper the authors did not show the possible weaknesses of the proposed model. It lacks any reference to a specific section, table, or figure, making it difficult for the authors to identify the exact area that needs improvement. Additionally, the comment is not specific because it does not provide any details on what aspects of the model's weaknesses are not addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors did not show the possible weaknesses of the proposed model. However, the comment lacks any supporting evidence or reasoning to substantiate this claim. Without specific examples or references, the authors are left without guidance on how to address this issue or what aspects of the model's weaknesses need to be explored. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by pointing out that the authors did not show the possible weaknesses of the proposed model. However, it lacks specific guidance or suggestions on how the authors might address this issue. Without actionable feedback or examples of how to demonstrate the weaknesses, the authors are left without a clear path forward to improve their draft. The comment is somewhat helpful as it highlights an area for improvement, but it does not provide sufficient detail or direction for the authors to effectively address the concern. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises questions about the novelty and contribution of the proposed method compared to existing extract-then-generate methodologies. It suggests that the paper lacks a related work section and does not experiment with other extract-then-generate methods. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve their draft. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to respond or enhance their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the novelty and contribution of the proposed method compared to existing extract-then-generate methodologies, specifically questioning what the system offers over previous approaches. However, it does not specify which part of the paper these questions relate to, such as the introduction, methodology, or related work section. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need clarification or improvement. While the comment is specific in its questioning of the novelty and contribution, the absence of explicit references to specific sections or parts of the paper limits its effectiveness. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the novelty and contribution of the proposed method compared to existing extract-then-generate methodologies. It suggests that the paper lacks a related work section and does not experiment with other extract-then-generate methods. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises important questions about the novelty and contribution of the proposed method compared to existing extract-then-generate methodologies. It highlights the lack of a related work section and the absence of experiments with other extract-then-generate methods, which are crucial for understanding the paper's context and contribution. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve their draft. While it identifies a significant gap in the paper, the feedback lacks actionable advice, making it somewhat helpful. The authors would need to infer how to respond to the comment, which limits its overall impact. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the computational cost of training 30-40 models for burn-in, which is not particularly appealing. It suggests an alternative approach involving unlabeled data or constraints to improve model stability. However, the comment does not provide explicit guidance on how to address the computational cost or how to implement the suggested alternative approach. The action is implicit and vague, leaving the authors uncertain about the specific steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the computational cost of training 30-40 models for burn-in, which is not particularly appealing. It suggests an alternative approach involving unlabeled data or constraints to improve model stability. However, the comment does not specify which part of the paper this issue relates to, making it difficult for the authors to identify the exact section being addressed. While the suggestion for an alternative approach is specific, the lack of grounding makes it challenging for the authors to understand the context. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the computational cost of training 30-40 models for burn-in, which is not particularly appealing. It suggests an alternative approach involving unlabeled data or constraints to improve model stability. However, the comment does not provide any specific reasoning, examples, or references to support the claim that this approach is appealing or beneficial. The lack of detailed justification makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the computational cost of training 30-40 models for burn-in, which is not particularly appealing. It suggests an alternative approach involving unlabeled data or constraints to improve model stability. While the comment identifies a potential issue with the current methodology, it does not provide specific guidance or suggestions on how to address the computational cost or implement the alternative approach. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice, making it only marginally helpful to the authors.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the introduction of related work is insufficient and recommends providing more work on GLN to reflect the advantages or differences of the proposed method, specifically mentioning the difference from B-GLN. While the comment implies that the authors should include more related work, it does not explicitly instruct them on how to do so. The action is implicit and somewhat vague, as the authors are not given specific guidance on which additional works to include or how to compare their method with B-GLN. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the introduction of related work is insufficient and recommends providing more work on GLN to reflect the advantages or differences of the proposed method, specifically mentioning the difference from B-GLN. However, the comment does not specify which part of the paper the introduction of related work is located, making it weakly grounded. It is specific in suggesting the need for more work on GLN and the comparison with B-GLN, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the introduction of related work is insufficient and suggests providing more work on GLN to reflect the advantages or differences of the proposed method, specifically mentioning the difference from B-GLN. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or evidence, the claim is not fully verifiable, aligning with a score of 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the introduction of related work, noting that it is insufficient and recommending the inclusion of more work on GLN to reflect the advantages or differences of the proposed method, particularly in comparison to B-GLN. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their draft. However, it could be more helpful if it included suggestions on which specific works to include or how to effectively compare the proposed method with B-GLN. Overall, the comment is mostly helpful as it offers a clear and constructive suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind using only one dropout rate for Moon\\'s approach, while suggesting that Variational dropout might benefit from additional parameters such as input-output and recurrent dropout. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit, as the authors need to infer that they should consider adding more parameters to their model or providing a rationale for their current choice. The comment is somewhat actionable because it identifies a potential issue but lacks concrete details on how to implement the suggested changes. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the rationale behind using only one dropout rate for Moon\\'s approach, while suggesting that Variational dropout might benefit from additional parameters such as input-output and recurrent dropout. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or figure being addressed. The comment is specific in its suggestion regarding the need for additional parameters, but the lack of grounding makes it challenging for the authors to understand the context. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind using only one dropout rate for Moon\\'s approach, suggesting that Variational dropout might benefit from additional parameters such as input-output and recurrent dropout. However, the comment does not provide any specific reasoning, examples, or references to support this claim. It lacks detailed justification or evidence to explain why the authors chose to use only one dropout rate or why additional parameters would be beneficial. Without this additional context, the claim remains unverifiable, as the authors cannot confidently understand the basis of the critique. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind using only one dropout rate for Moon\\'s approach, while suggesting that Variational dropout might benefit from additional parameters such as input-output and recurrent dropout. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper, specifically regarding the choice of dropout parameters. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or what changes could be made to their model. Without actionable advice or detailed reasoning, the authors may find it challenging to fully understand and incorporate the feedback into their draft. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the absence of larger-scale experiments, specifically mentioning the lack of experiments with larger state-action spaces and non-trivial dynamics, such as grid-worlds with walls or other non-trivial tiles. It suggests that the absence of these experiments might be due to a lack of time or scalability issues. The comment also provides examples of alternative experimental domains, such as simple video-game domains, which could have been used to better assess the method. However, the comment does not explicitly instruct the authors to include these types of experiments or provide detailed guidance on how to conduct them. The action is implicit and somewhat vague, as the authors need to infer that they should include larger-scale experiments and consider specific examples. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for larger-scale experiments, which allows the authors to accurately identify the part of the paper being addressed. It specifies the type of experiments that would be beneficial, such as those with larger state-action spaces and non-trivial dynamics, including examples like grid-worlds with walls and other non-trivial tiles. The comment also suggests alternative experimental domains, such as simple video-game domains, which further clarifies the need for additional experiments. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the absence of larger-scale experiments, specifically mentioning the lack of experiments with larger state-action spaces and non-trivial dynamics. It suggests that the absence of these experiments might be due to a lack of time or scalability issues. The comment provides examples of alternative experimental domains, such as simple video-game domains, which could have been used to better assess the method. However, the comment does not offer specific evidence or references to support the claim that the absence of these experiments is due to scalability issues. While the reasoning is logical, the lack of detailed justification or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of larger-scale experiments, particularly those with larger state-action spaces and non-trivial dynamics. It questions the reason for this omission, suggesting that it might be due to a lack of time or scalability issues. The comment provides specific examples of alternative experimental domains, such as simple video-game domains, which could have been used to better assess the method. This feedback is valuable as it directs the authors to consider expanding their experimental evaluation to include more complex scenarios, thereby enhancing the comprehensiveness and robustness of their work. However, the comment could be more helpful if it provided more detailed guidance on how to conduct these additional experiments or suggested specific methods for addressing scalability issues. Overall, the comment is mostly helpful, as it offers clear suggestions for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the authors\\' draft, noting that they did not propose any quantitative measurement to address the extent of occupation bias relative to real distributions in society. While the comment identifies a gap in the authors\\' work, it does not provide explicit guidance on how the authors should address this issue or what specific quantitative methods they could use. The action is implicit, as the authors need to infer that they should include a quantitative measurement to address the identified gap. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of quantitative measurement regarding occupation bias relative to real distributions in society, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the missing aspect, which is the lack of quantitative measurement for occupation bias. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors did not propose any quantitative measurement to address the extent of occupation bias relative to real distributions in society. This is a specific claim that highlights a gap in the authors\\' work. However, the comment does not provide any evidence or reasoning to support this claim, such as examples of missing measurements or references to similar studies. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the authors\\' work, noting that they did not propose any quantitative measurement to address the extent of occupation bias relative to real distributions in society. This feedback is clear and actionable, as it highlights a critical area for improvement that could enhance the rigor and impact of the study. By pointing out the absence of quantitative measurement, the comment provides a direct suggestion for the authors to address this gap, which is essential for a comprehensive analysis. However, the comment could be more helpful if it offered specific examples of quantitative methods that could be used or suggested ways to incorporate such measurements. Overall, the comment is mostly helpful as it directs the authors towards an important improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the lack of information from 2-hop neighbors and questions the effectiveness of the method. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment lacks guidance on how the authors might incorporate information from 2-hop neighbors or clarify the effectiveness of their method. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the lack of information from 2-hop neighbors and questions the effectiveness of the method. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact area that needs improvement. The comment is vague and does not provide specific guidance on how to address these issues. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises concerns about the lack of information from 2-hop neighbors and questions the effectiveness of the method. However, it does not provide any specific evidence, reasoning, or references to support these claims. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically the lack of information from 2-hop neighbors and questions the effectiveness of the method. However, it does not provide detailed feedback or suggestions on how the authors might address these concerns or improve the clarity of their method. The comment lacks actionable guidance, making it somewhat helpful as it highlights areas for improvement but does not offer specific steps for the authors to take. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests using DICOM images instead of PNG images for experiments and recommends the FastMRI challenge dataset. It also mentions the need to compare inference speeds between different methods. However, it does not provide explicit instructions or detailed guidance on how to implement these suggestions, such as which specific parts of the paper need to be revised or what specific analyses should be conducted. The actions are implicit and somewhat vague, leaving the authors with a general idea of what needs to be done but without clear steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests using DICOM images instead of PNG images for experiments and recommends the FastMRI challenge dataset. It also mentions the need to compare inference speeds between different methods. However, the comment does not specify which part of the paper this suggestion relates to, such as a specific section or figure. This makes it difficult for the authors to identify the exact area that needs revision. While the comment provides some specificity by mentioning the type of image and dataset, it lacks full grounding as it does not explicitly mention sections or figures. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests using DICOM images instead of PNG images for experiments and recommends the FastMRI challenge dataset. It also mentions the need to compare inference speeds between different methods. However, the comment lacks specific reasoning or evidence to support why these changes are necessary or beneficial. It does not provide detailed explanations or references to justify the recommendation, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the experimental setup by recommending the use of DICOM images instead of PNG images and suggesting the FastMRI challenge dataset. It also mentions the importance of comparing inference speeds between different methods. However, the comment lacks detailed guidance on how to implement these suggestions, such as which specific sections of the paper need to be revised or what specific analyses should be conducted. While it offers valuable insights, the lack of actionable steps limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about a specific scenario involving the association of a CAD model with spatially-varying BRDF maps. While it raises an interesting point, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this scenario or what changes could be made to their draft to account for it. Without specific instructions or suggestions, the authors are left without a clear path forward, making the comment unactionable. Therefore, this comment aligns with a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about a specific scenario involving the association of a CAD model with spatially-varying BRDF maps. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment is specific in its inquiry about a particular aspect of the paper, but it lacks grounding as it does not provide explicit references or sections. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about a specific scenario involving the association of a CAD model with spatially-varying BRDF maps. However, it does not provide any claim, assertion, or suggestion that requires verification or justification. The comment is purely descriptive and does not offer any insight or guidance that would help the authors understand or address the issue. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about a specific scenario involving the association of a CAD model with spatially-varying BRDF maps. While it prompts the authors to consider this scenario, it does not provide any guidance or suggestions on how to address it or what changes might be necessary in their draft. The comment lacks depth and actionable feedback, leaving the authors without a clear understanding of how to improve their work. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that more evaluation would be beneficial, particularly for CIFAR-10 in full label and lower label scenarios. However, it does not provide explicit guidance on what specific evaluations should be conducted or how the authors should approach this additional evaluation. The action is implicit, as the authors need to infer that they should add more evaluations, but it lacks concrete details on what to evaluate or how to implement this suggestion. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more evaluation would be beneficial, especially for CIFAR-10 in full label and lower label scenarios. However, it does not specify which part of the paper this evaluation should be conducted in or how it should be integrated. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, while it suggests the need for more evaluation, it does not provide specific details on what kind of evaluation is required or how it should be conducted, making it specific but not fully specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more evaluation would be beneficial, particularly for CIFAR-10 in full label and lower label scenarios. However, it does not provide any specific reasoning, examples, or references to support why this additional evaluation is necessary or how it would enhance the paper. The comment lacks detailed justification, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that more evaluation would be beneficial, especially for CIFAR-10 in full label and lower label scenarios. However, it lacks specificity and does not provide detailed guidance on what kind of additional evaluation is needed or how it should be conducted. While it points out a potential area for improvement, the comment does not offer actionable advice or suggestions for enhancing the paper's evaluation, leaving the authors with limited insight into how to address the feedback. Therefore, the comment is somewhat helpful, as it identifies a need for more evaluation but does not provide sufficient detail to guide the authors in making improvements.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the comparability of results in Table 2, specifically regarding the use of different amounts of data in the comparisons. It provides examples of how certain comparisons use less data than others, such as H->N and H->B using less data than H->N+B, and H->N->H and H->N->H using less data than H->N+B->H. While the comment identifies a potential issue with the comparability of the results, it does not explicitly instruct the authors to address this concern or provide guidance on how to ensure fair comparisons. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the data usage in their comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparisons in Table 2, particularly regarding the use of different amounts of data in the comparisons. The authors are informed about the specific comparisons that use less data, such as H->N and H->B compared to H->N+B, and H->N->H compared to H->N+B->H. This level of detail provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the comparability of results in Table 2, specifically regarding the use of different amounts of data in the comparisons. It provides examples of how certain comparisons use less data than others, such as H->N and H->B compared to H->N+B, and H->N->H compared to H->N+B->H. However, the comment does not offer any justification or reasoning for why this comparability issue is a concern or how it might affect the results. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparability of results in Table 2, specifically regarding the use of different amounts of data in the comparisons. It provides examples of how certain comparisons use less data than others, such as H->N and H->B compared to H->N+B, and H->N->H compared to H->N+B->H. This feedback is clear and actionable, as it highlights a specific area where the authors need to ensure fair comparisons. However, the comment could be more helpful if it provided guidance on how to address this issue, such as suggesting alternative methods for comparison or explaining the rationale behind the data usage. Overall, the comment is mostly helpful as it points out a critical issue that needs attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the placement of an addition, the clarity of the iterative algorithm application, and the lack of references to Laplacian eigenmaps. It questions the counterintuitive placement of the addition, suggesting that it might be more logical to be placed elsewhere. The comment also points out a lack of clarity regarding the iterative algorithm's application, specifically whether it is applied with one or two iterations, and what happens for larger iterations. Additionally, it notes the absence of a reference to Laplacian eigenmaps in the introduction and mentions a figure that is not referenced. While the comment identifies several issues, it does not provide explicit guidance on how to address them or what specific actions the authors should take. The actions are implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several concerns about the placement of an addition, the clarity of the iterative algorithm application, and the lack of references to Laplacian eigenmaps. It questions the counterintuitive placement of the addition, suggesting it might be more logical to be placed elsewhere. The comment also points out a lack of clarity regarding the iterative algorithm's application, specifically whether it is applied with one or two iterations, and what happens for larger iterations. Additionally, it notes the absence of a reference to Laplacian eigenmaps in the introduction and mentions a figure that is not referenced. However, the comment does not specify which part of the paper these issues are related to, making it difficult for the authors to pinpoint the exact sections that need attention. The lack of specific guidance on how to address these issues further reduces the comment's effectiveness. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises several concerns about the placement of an addition, the clarity of the iterative algorithm application, and the lack of references to Laplacian eigenmaps. It questions the counterintuitive placement of the addition, suggesting it might be more logical to be placed elsewhere. The comment also points out a lack of clarity regarding the iterative algorithm's application, specifically whether it is applied with one or two iterations, and what happens for larger iterations. Additionally, it notes the absence of a reference to Laplacian eigenmaps in the introduction and mentions a figure that is not referenced. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the issues and how to address them. The lack of detailed justification or references makes the claim somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several concerns about the placement of an addition, the clarity of the iterative algorithm application, and the lack of references to Laplacian eigenmaps. It questions the counterintuitive placement of the addition, suggesting it might be more logical to be placed elsewhere. The comment also points out a lack of clarity regarding the iterative algorithm's application, specifically whether it is applied with one or two iterations, and what happens for larger iterations. Additionally, it notes the absence of a reference to Laplacian eigenmaps in the introduction and mentions a figure that is not referenced. While the comment identifies several areas for improvement, it lacks specific guidance on how to address these issues or what actions the authors should take. The feedback is somewhat helpful as it highlights areas that need attention, but it does not provide detailed suggestions or actionable steps for the authors to take, which limits its overall impact. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the inclusion of Section 2.1, specifically Batch Normalization, and suggests that the description of the proposed methodology is independent of the model choice. It also implies that the time spent describing the ResNet architecture could be better used to provide motivation and intuition for the Conditional Batch Normalization (CBN) approach. However, the comment does not explicitly instruct the authors to remove or reorganize the section, nor does it provide specific guidance on how to better integrate the description of the proposed methodology with the model choice or how to use the time spent on ResNet architecture more effectively. The action is implicit and somewhat vague, as the authors need to infer the necessary changes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the inclusion of Section 2.1, specifically Batch Normalization, and suggests that the description of the proposed methodology is independent of the model choice. It also implies that the time spent describing the ResNet architecture could be better used to provide motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. However, the comment does not specify which part of the paper is being addressed, making it weakly grounded. It is specific in its critique of the inclusion and relevance of Section 2.1 and the description of the methodology, but without explicit references to the section or parts of the paper, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the inclusion of Section 2.1, specifically Batch Normalization, and suggests that the description of the proposed methodology is independent of the model choice. It also implies that the time spent describing the ResNet architecture could be better used to provide motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is somewhat verifiable as it provides a general critique but lacks detailed justification or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the inclusion of Section 2.1, specifically questioning the relevance of Batch Normalization in the context of the proposed Conditional Batch Normalization (CBN). It suggests that the description of the methodology is independent of the model choice and that the time spent on describing the ResNet architecture could be better utilized to provide motivation and intuition for the CBN approach. While the comment highlights areas for potential improvement, it lacks specific guidance on how to address these issues or what changes might be necessary. The feedback is somewhat helpful as it points out areas for clarification and improvement, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the assumption made in the paper regarding the sparsity of the resulting matrix after multiplication by a dense projection matrix. It highlights a potential inconsistency in the reasoning, suggesting that multiplying by a nicely-conditioned matrix might not result in a sparse matrix. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit and vague, as it leaves the authors to infer the need for clarification or correction. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue raised in the paper at line 122, where the authors assume a dense projection matrix multiplication leads to a sparse matrix. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific, as it clearly explains the inconsistency in the reasoning and questions the assumption of sparsity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the assumption made in the paper regarding the sparsity of the resulting matrix after multiplication by a dense projection matrix. It points out a potential inconsistency in the reasoning, suggesting that multiplying by a nicely-conditioned matrix might not result in a sparse matrix. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of evidence or justification makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific point of confusion in the paper, questioning the assumption that multiplying by a dense projection matrix results in a sparse matrix. It highlights a potential inconsistency in the reasoning, suggesting that a nicely-conditioned matrix might not lead to a sparse matrix. This feedback is somewhat helpful as it points out a potential issue that needs clarification or further explanation. However, it does not provide detailed guidance on how the authors might address this concern or what changes could be made to the paper. The comment is clear and identifies an area for improvement, but it lacks depth and actionable suggestions, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the statement about initialization playing a role in NGD being a discretization of NGF should be more carefully stated. It also provides a reference to support the claim. However, the comment does not explicitly instruct the authors to revise the statement or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to rephrase the statement. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the role of initialization in the context of Natural Gradient Descent (NGD) and Natural Gradient Flow (NGF), suggesting that initialization should play a role similar to pre-training. It references a specific paper to support the claim about NGD being a discretization of NGF. However, the comment does not specify which part of the paper discusses initialization or where the reference is located, making it weakly grounded. The comment is specific in detailing the issue with the statement about initialization, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the statement about initialization playing a role in NGD being a discretization of NGF should be more carefully stated, referencing a specific paper. This claim is somewhat verifiable as it provides a reference to support the claim, allowing the authors to understand the basis of the argument. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper, noting that the statement about initialization playing a role in NGD being a discretization of NGF should be more carefully stated. It also provides a reference to support the claim, which is helpful for the authors to understand the context and reasoning behind the critique. However, the comment could be more helpful if it offered specific guidance on how to rephrase the statement or what aspects of the statement need to be clarified. Without detailed suggestions or examples, the feedback is somewhat helpful, as it directs the authors to improve the clarity of their writing but lacks actionable depth. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the lack of clarity in the extraction of named entities from the datasets and the need for English proofreading to improve readability. While the comment explicitly mentions the need for clarification regarding the extraction process, it does not provide specific guidance on how to achieve this. The suggestion to improve readability through proofreading is also vague and lacks detail. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide concrete steps for the authors to take. The comment is rated as 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for clarification regarding the extraction of named entities from the datasets, allowing the authors to accurately identify the part of the paper being addressed. It also suggests that English proofreading would improve readability, which is a specific and actionable suggestion. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that it is not clear how named entities were extracted from the datasets and suggests that English proofreading would improve readability. While the suggestion to improve readability is logical and common practice, the claim about the lack of clarity in named entity extraction is not substantiated with specific examples or references. This makes the claim somewhat verifiable, as it lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two key areas for improvement: the lack of clarity in the extraction of named entities from the datasets and the need for English proofreading to enhance readability. While the comment highlights these issues, it does not provide specific guidance or suggestions on how to address them. The feedback is somewhat helpful as it points out areas that need attention, but it lacks depth and actionable advice, making it only slightly beneficial for the authors. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific instances where the authors' draft could be improved. It highlights a potential issue with the phrasing at line 200, suggesting that the term \"for every arm a\" might imply a single optimistic parameter, which is not necessarily the case. The comment also suggests an alternative choice for T_0, namely T_0 = m Sqrt(T), and provides a mathematical condition that would improve the result. However, the comment does not explicitly instruct the authors to revise the phrasing at line 200 or to consider the alternative choice for T_0. While the suggestions are concrete, the lack of explicit instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment provides specific instances for improvement, such as the phrasing at line 200 and the choice of T_0. It references specific parts of the paper, making it fully grounded. The comment also specifies what needs to be addressed, such as the potential issue with the phrasing and the suggestion for an alternative choice of T_0. This level of detail and specificity allows the authors to understand exactly where and what to improve, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts, each making a claim about the draft. The first part, \"for every arm a\" implies there is a single optimistic parameter, but of course it depends on a,' is a critique that requires the authors to clarify their reasoning or provide additional context. The second part, \"Why not choose T_0 = m Sqrt(T)? Then the condition becomes B > Sqrt(m) T^(3/4), which improves slightly on what you give,\" suggests an alternative choice for T_0 and provides a mathematical condition that would improve the result. However, the comment lacks detailed reasoning or references to support these claims, making it difficult for the authors to fully understand and address the issues. Therefore, the comment is rated as borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment provides specific instances where the authors' draft could be improved, offering suggestions for clarification and potential enhancements. It highlights a potential issue with the phrasing at line 200, suggesting that the term 'for every arm a' might imply a single optimistic parameter, which is not necessarily the case. The comment also suggests an alternative choice for T_0, namely T_0 = m Sqrt(T), and provides a mathematical condition that would improve the result. However, the comment lacks detailed reasoning or references to support these suggestions, making it somewhat helpful. The feedback is clear and actionable, but it could be more comprehensive if it included additional context or examples. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue regarding the definition of variables L and E in the paper. It points out that these variables are not defined in the immediate vicinity, which could hinder the reader's understanding. Additionally, the comment notes inconsistencies in the italicization of L and E, further indicating a need for clarification. While the comment identifies a clear action\u2014defining L and E and ensuring consistent formatting\u2014it does not provide explicit guidance on how to implement these changes. The authors are left to infer that they need to define the variables and check for consistent formatting, which makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 296,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the variables L and E are not defined in the immediate vicinity and that there are inconsistencies in their italicization. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a specific issue regarding the definition of variables L and E in the paper, noting that they are not defined in the immediate vicinity and that there are inconsistencies in their italicization. While the comment identifies a factual observation about the paper's formatting and clarity, it does not provide any logical reasoning, common knowledge, or external references to support the claim. The authors are left to infer that these issues need to be addressed, but without further guidance, the claim is considered unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that the variables L and E are not defined in the immediate vicinity and that there are inconsistencies in their italicization. This feedback is clear and actionable, as it provides the authors with specific areas to address in their draft. By defining L and E and ensuring consistent formatting, the authors can improve the clarity and readability of their paper. However, the comment could be more helpful if it suggested specific ways to define the variables or how to ensure consistent formatting. Despite this, the feedback is mostly helpful as it directs the authors to concrete improvements they can make to their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental section is weak and that more experiments are needed. However, it does not specify which aspects of the experimental section are weak or what additional experiments would be beneficial. The comment lacks concrete guidance on how to improve the experimental section, leaving the authors with a general idea but no specific direction to follow. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the experimental section is weak and that more experiments are needed. However, it does not specify which part of the paper the experimental section is located in, nor does it provide any details on what aspects of the experiments are weak or what additional experiments could be beneficial. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity, as it does not provide any guidance on how to improve the experimental section or what kind of additional experiments would be helpful. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the experimental section is weak and suggests that more experiments are required. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left to infer the nature of the weakness and the need for more experiments, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the experimental section, suggesting that more experiments are needed. However, it lacks specificity and does not provide any guidance on what additional experiments might be beneficial or how they could address the identified weakness. This feedback is vague and does not offer actionable advice, leaving the authors with limited insight into how to improve their draft. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameter-efficient fine-tuning techniques beyond LoRA and SPP. While the comment implies that the authors should include additional comparisons, it does not explicitly instruct them to do so or provide specific guidance on which models or techniques to include. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their comparisons. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameter-efficient fine-tuning techniques beyond LoRA and SPP. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs improvement. The comment is specific in its suggestion to include more comparisons, but it lacks grounding as it does not mention specific sections or figures. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameter-efficient fine-tuning techniques beyond LoRA and SPP. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameter-efficient fine-tuning techniques beyond LoRA and SPP. This feedback is somewhat helpful as it identifies a potential area for improvement by highlighting the need for more comprehensive comparisons. However, the comment lacks specific guidance on which models or techniques should be included, making it somewhat vague and incomplete. The authors would need to infer that they should expand their comparisons, which could be challenging without further direction. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific suggestions for improving the writing style and clarity of certain sentences in the paper. It explicitly instructs the authors to revise the sentences on lines 2, 56, and 158 to remove the word \"of\" and use \"to\" instead. Additionally, it points out an issue with the sentence on line 265, which is grammatically incorrect and unclear. The feedback is explicit and concrete, as it clearly directs the authors on what changes to make. However, it does not provide detailed guidance on how to revise the sentences or suggest specific ways to improve the clarity. Therefore, the comment is mostly actionable, as it provides clear instructions but lacks detailed guidance on implementation.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper (lines 2, 56, 158, and 265), allowing the authors to accurately identify the parts being addressed. It also provides specific suggestions for improving the writing style and clarity of the sentences on these lines, such as removing \"of\" and using \"to\" instead, and pointing out grammatical errors. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of specific suggestions for improving the writing style and clarity of certain sentences in the paper. It provides clear guidance on how to revise the sentences on lines 2, 56, and 158, and it identifies a grammatical error on line 265. The feedback is detailed and actionable, as it instructs the authors on what changes to make to improve the paper. However, it does not provide any additional context or reasoning beyond the specific suggestions, which makes it mostly verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the writing style and clarity of certain sentences in the paper. It explicitly instructs the authors to revise the sentences on lines 2, 56, and 158 to remove the word \"of\" and use \"to\" instead, which improves the grammatical correctness and clarity of the text. Additionally, it points out an issue with the sentence on line 265, which is grammatically incorrect and unclear, and suggests that the authors clarify the meaning of the sentence. While the feedback is clear and actionable, it could be more helpful if it provided additional guidance on how to revise the sentences or suggested specific ways to improve the clarity. Overall, the comment is mostly helpful, as it offers valuable feedback that can guide the authors in improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the inversion of matrix determination or the number of samples, specifically in relation to equations labeled W4. While it points out a potential error in the equations, it does not provide explicit guidance on how to address this issue or what specific changes should be made. The authors are left to infer that they need to correct the equations, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the inversion of matrix determination or the number of samples, specifically in relation to equations labeled W4. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or figure being addressed. The comment is weakly grounded as it does not provide explicit references or context. It is also specific in that it identifies a potential error in the equations, but without further guidance, the authors may struggle to understand the exact issue. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the inversion of matrix determination or the number of samples, specifically in relation to equations labeled W4. However, it does not provide any context, explanation, or references to support the claim that there are mistakes in the equations. Without additional information or justification, the authors are left to question the validity of the claim, making it difficult to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the inversion of matrix determination or the number of samples, specifically in relation to equations labeled W4. This feedback highlights a potential error in the equations, which could impact the accuracy and reliability of the results presented in the paper. However, the comment lacks specificity and does not provide any guidance or suggestions on how to address the issue. The authors are left without actionable steps to take, as they do not know what changes are needed or how to correct the equations. Therefore, the comment is barely helpful, as it identifies a problem but does not offer any constructive feedback or direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve the novelty or significance of their work. Without specific suggestions or actions, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to pinpoint the exact area that needs improvement. The comment lacks specificity in detailing what aspects of the model or its extension are considered straightforward or incremental. As a result, the authors are left without a clear understanding of how to address the feedback. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. However, the comment lacks specific evidence or reasoning to support this claim. It does not provide examples, references, or detailed explanations to substantiate the assertion that the model is a straightforward extension. Without such support, the claim remains unsubstantiated, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. While this feedback provides a general critique of the paper's novelty, it lacks specific details or actionable suggestions for improvement. The authors are left without a clear understanding of how to address the perceived lack of innovation or depth in their work. The comment is vague and does not offer any guidance on how the authors might enhance the novelty or significance of their research. As a result, it is barely helpful, as it does not provide sufficient direction for the authors to improve their draft.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While it suggests that the authors should provide this information, it does not explicitly instruct them to include it in the draft or specify how to calculate or present the results. The action is implicit, as the authors need to infer that they should add this information to the experiment section. However, the lack of detailed guidance on how to implement this suggestion makes the comment somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiment section where the authors have designed a baseline combining LDA and LSTM. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it requests the performance of this baseline in terms of the topic switch percent metric, providing a clear direction for improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. However, it does not provide any evidence, reasoning, or references to support why this metric is important or how it should be evaluated. The comment lacks specific details or justification, making it difficult for the authors to understand the basis for the request. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While it identifies a potential area for improvement, it does not provide any specific guidance or suggestions on how to address this issue or what data might be relevant. The comment lacks actionable advice, such as suggesting alternative metrics or providing examples of how to calculate the topic switch percent. As a result, the feedback is somewhat helpful, as it highlights a potential area for improvement but does not offer detailed guidance for the authors to enhance their draft. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the motivation of the task, specifically regarding the difficulty of predicting the state of occluded objects and the lack of guarantee in annotation quality. It also asks about potential downstream applications or benefits of amodal tracking and how uncertainty in predictions might be handled. While the comment identifies areas where the authors could provide more clarity, it does not explicitly instruct the authors on what specific aspects to address or how to improve their draft. The action is implicit and somewhat vague, as the authors need to infer the need for more detailed explanations and examples. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the motivation of the task, specifically regarding the difficulty of predicting the state of occluded objects and the lack of guarantee in annotation quality. It also asks about potential downstream applications or benefits of amodal tracking and how uncertainty in predictions might be handled. However, the comment does not specify which part of the paper addresses these issues, making it difficult for the authors to pinpoint the exact sections that need revision. While the questions are specific, the lack of grounding makes it challenging for the authors to understand which parts of the paper are being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the motivation of the task, specifically regarding the difficulty of predicting the state of occluded objects and the lack of guarantee in annotation quality. It also asks about potential downstream applications or benefits of amodal tracking and how uncertainty in predictions might be handled. However, the comment does not provide any specific examples, reasoning, or references to support these claims. The questions are logical and inferable, but without detailed justification or evidence, they are somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the motivation of the task, particularly concerning the difficulty of predicting the state of occluded objects and the lack of guarantee in annotation quality. It also inquires about potential downstream applications or benefits of amodal tracking and how uncertainty in predictions might be handled. While the comment identifies a key area for clarification, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it prompts the authors to elaborate on the motivation and potential applications of their work, but it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the claim about the synergies between DQD and PPO, noting that the main paper does not mention the TD3GA algorithm. It suggests that the comparison to TD3GA should be central to the study, as it is crucial for understanding these synergies. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to include the TD3GA algorithm and its comparison. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the main paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the study of combining DQD with TD3 is crucial for understanding the synergies between DQD and PPO. However, the comment does not provide specific guidance on what needs to be addressed or how to improve the comparison to TD3GA. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the claim about the synergies between DQD and PPO is insufficiently backed-up, specifically noting the absence of the TD3GA algorithm in the main paper. The comment suggests that the comparison to TD3GA is crucial for understanding these synergies. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the need for a more detailed comparison to TD3GA, which could be challenging. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper, namely the insufficient backing of the claim about the synergies between DQD and PPO. It points out that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. The comment suggests that the comparison to TD3GA should be central to the study, implying that this comparison is essential for supporting the central claim. However, the comment does not provide detailed guidance on how the authors should address this issue or what specific changes are needed to include the TD3GA algorithm and its comparison. While it highlights a critical area for improvement, the feedback lacks depth and actionable suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the surprising performance of the tree-sliced Wasserstein distance compared to the original optimal transport distance. It prompts the authors to explain why this occurs, suggesting that they should provide a detailed explanation of the results. However, the comment does not explicitly instruct the authors to include this explanation in their draft or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explain the results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions Sections 6.1 and 6.2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the surprising performance of the tree-sliced Wasserstein distance compared to the original optimal transport distance and asks for an explanation. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the surprising performance of the tree-sliced Wasserstein distance compared to the original optimal transport distance. It prompts the authors to explain why this occurs, but it does not provide any specific evidence, reasoning, or references to support the claim. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the observation. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the results presented in Sections 6.1 and 6.2, specifically questioning why the tree-sliced Wasserstein distance outperforms the original optimal transport distance. This observation is surprising and requires explanation. The comment prompts the authors to provide a detailed explanation of this phenomenon, which is crucial for understanding the results and potentially improving the paper. However, the comment does not offer specific suggestions or guidance on how to address this issue, making it somewhat helpful. The authors are left with a clear area for improvement but lack detailed feedback on how to proceed. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about the term \"confident\" in the context of ceterus paribus convexity, suggesting that it might be about human interpretability rather than model confidence. While the comment identifies a potential issue with clarity, it does not provide explicit guidance on how the authors should rephrase the sentence or address the confusion. The action is implicit, as the authors need to infer that they should rephrase the sentence to clarify the meaning of \"confident.\" However, the comment lacks concrete details on how to rephrase the sentence or what specific issues need to be addressed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the confusion arises, allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies the issue with the term \"confident,\" suggesting that it might be about human interpretability rather than model confidence. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses confusion about the term \"confident\" in the context of ceterus paribus convexity, suggesting that it might be about human interpretability rather than model confidence. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential point of confusion regarding the term \"confident\" in the context of ceterus paribus convexity. It suggests that the authors might be misinterpreting the term as related to model confidence rather than human interpretability. While the comment highlights a potential issue with clarity, it does not provide specific guidance or suggestions on how the authors might address this confusion. The feedback is somewhat helpful as it points out a potential area for clarification, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the figures and empirical results, such as the lack of polishing, missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small scale datasets and a single architecture type. However, it does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve the figures and empirical results. The feedback is somewhat vague and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of polishing of figures and empirical results, which impedes clarity and confidence in the findings. It also specifies the issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small scale datasets and a single architecture type. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a lack of polishing of figures and empirical results, which impedes clarity and confidence in the findings. It provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small scale datasets and a single architecture type. However, the comment does not offer any logical reasoning, references, or examples to support these claims. The lack of detailed justification makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, specifically focusing on the figures and empirical results. It highlights issues such as the lack of polishing, missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small scale datasets and a single architecture type. These observations provide the authors with specific feedback on what needs to be addressed to enhance the clarity and confidence in their empirical findings. However, the comment could be more helpful if it offered suggestions on how to improve the figures or empirical results, such as providing guidance on polishing techniques or suggesting alternative experimental designs. Overall, the comment is somewhat helpful as it points out areas for improvement but lacks detailed guidance on how to implement these suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would be stronger if it reported the numbers observed in a label noise experiment on ImageNet with 1000 classes, particularly focusing on non-tail classes. This provides a clear and explicit action for the authors to take, as they can directly incorporate these additional results into their draft. The comment is specific in its suggestion and provides a concrete direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper would be stronger if it reported numbers from a label noise experiment on ImageNet with 1000 classes, specifically focusing on non-tail classes. This provides a clear and specific direction for the authors to enhance their analysis. However, the comment does not explicitly mention which part of the paper this suggestion relates to, making it weakly grounded. The suggestion is specific in its request for additional data, which would help stress-test the conjecture. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would be stronger if it reported additional numbers from a label noise experiment on ImageNet with 1000 classes, particularly focusing on non-tail classes. This claim is somewhat verifiable as it provides a specific suggestion for improvement, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the importance of this additional data to understand the full context of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper would be strengthened by reporting additional numbers from a label noise experiment on ImageNet with 1000 classes, specifically focusing on non-tail classes. This feedback is actionable and provides a clear direction for the authors to enhance their analysis and potentially stress-test their conjecture. However, the comment could be more helpful if it included specific guidance on how to present or interpret these additional results. Overall, the comment is mostly helpful as it offers a valuable suggestion for improvement, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of metrics, specifically questioning why the number of weight updates is a better metric than the number of network updates. It suggests that the authors should provide additional feedback to improve the paper. However, the comment does not explicitly instruct the authors on how to address this question or what specific feedback to provide. The action is implicit, as the authors need to infer that they should explain their reasoning for choosing the metric and provide additional feedback. The action is somewhat vague, as it lacks concrete guidance on how to improve the paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of metrics, specifically questioning why the number of weight updates is a better metric than the number of network updates. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in questioning the choice of metrics, the absence of explicit grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of metrics, specifically questioning why the number of weight updates is a better metric than the number of network updates. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks a clear justification or explanation for why the authors chose one metric over another. Without additional context or reasoning, the claim is not verifiable, making the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of metrics, specifically questioning why the number of weight updates is a better metric than the number of network updates. It suggests that the authors should provide additional feedback to improve the paper. However, the comment lacks specificity and does not offer detailed guidance on how the authors might address this issue or what kind of feedback would be beneficial. The feedback is somewhat vague and does not provide actionable steps for the authors to take. As a result, the comment is somewhat helpful, as it identifies a potential area for improvement but does not fully support the authors in addressing it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the real-world scenarios where the proposed adversarial prediction accuracy is relevant compared to classical prediction accuracy. However, it does not provide any explicit or implicit suggestions on how the authors might address this question or incorporate it into their work. The comment lacks concrete guidance on what needs to be done to improve the draft, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the real-world scenarios where the proposed adversarial prediction accuracy is relevant compared to classical prediction accuracy. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. Additionally, the comment does not provide specific guidance or examples on how to address this question or incorporate it into the paper. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the real-world scenarios where the proposed adversarial prediction accuracy is relevant compared to classical prediction accuracy. However, it does not provide any claim, assertion, or suggestion that requires verification or justification. The comment is purely descriptive and does not offer any insight or guidance for the authors. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the real-world scenarios where the proposed adversarial prediction accuracy is relevant compared to classical prediction accuracy. However, it does not provide any specific guidance or suggestions on how the authors might address this question or incorporate it into their work. The comment lacks depth and actionable feedback, leaving the authors without a clear understanding of how to improve their draft. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the evaluation section, including the lack of transparency regarding the experiment setup, the absence of mention of the number of different sets of in-content examples used, and the lack of exploration of the effects of varying the number of in-context examples. It also points out that the evaluation relies solely on one dataset, which may limit the generalizability of the results. While the comment identifies several areas for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The actions are implicit and somewhat vague, as the authors are left to infer how to improve the evaluation section. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluation section of the paper, specifically noting that it is not sufficiently comprehensive and lacks transparency regarding the experiment setup. It highlights the absence of mention of the number of different sets of in-content examples used in the experiments and the lack of exploration of the effects of varying the number of in-context examples. Additionally, the comment points out that the evaluation relies solely on one dataset, which may limit the generalizability of the results. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the lack of transparency and the need for more comprehensive evaluation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation in the paper is not sufficiently comprehensive and lacks transparency regarding the experiment setup. It specifically mentions the absence of information on the number of different sets of in-content examples used in the experiments and the lack of exploration of the effects of varying the number of in-context examples. Additionally, it notes that the evaluation relies solely on one dataset, which may limit the generalizability of the results. However, the comment does not provide specific examples or references to support these claims, making it somewhat verifiable. The authors would need to infer the basis for these claims, which could be challenging. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas where the paper could be improved, specifically focusing on the comprehensiveness and transparency of the evaluation section. It highlights the lack of detail regarding the experiment setup, such as the number of different sets of in-content examples used, and the absence of exploration of the effects of varying the number of in-context examples. Additionally, the comment points out that the evaluation relies solely on one dataset, which may limit the generalizability of the results. While the comment provides specific areas for improvement, it lacks detailed guidance on how to address these issues or what specific actions the authors should take. The feedback is somewhat helpful as it directs the authors to areas that need attention, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the contrastive learning framework used in the paper, suggesting that it is the same as SimCLR. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what changes they should consider making to their framework. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to understand where to address the issue. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not provide any evidence, reasoning, or references to support this claim. Without any supporting information, the authors are left without a basis to verify or address the issue. This lack of substantiation makes the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the contrastive learning framework used in the paper is the same as SimCLR. While this observation is accurate, it does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this issue or what changes might be necessary to their framework. Without specific advice or suggestions, the comment is not particularly helpful in guiding the authors to enhance their draft. Therefore, it aligns with a score of 1, indicating that it is barely helpful.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning examples such as [1], [2], and [3]. However, it does not provide explicit guidance on how the authors should address this suggestion, such as by including a more comprehensive related work section or discussing the relevance of these works in more detail. The action is implicit, as the authors need to infer that they should expand their related work section. While the comment is somewhat actionable, it lacks concrete details on how to implement the suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning examples such as [1], [2], and [3]. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section or aspect that needs attention. The comment is not grounded as it does not provide clear guidance on which part of the paper should be revised. Additionally, the comment lacks specificity in detailing what aspects of the related work are missing or need attention. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning examples such as [1], [2], and [3]. However, the comment lacks specific details or reasoning to support why these works are relevant or how they could enhance the paper. Without further elaboration or examples, the claim is difficult to verify, making it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning examples such as [1], [2], and [3]. However, the comment lacks specificity and does not provide detailed guidance on how the authors should address this suggestion. It does not specify which aspects of the related work are missing or how the authors could incorporate these references effectively. Without actionable advice or examples, the comment is somewhat helpful as it identifies a potential area for improvement but does not provide sufficient direction for the authors to enhance their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting the absence of comparisons against existing text GANs, particularly those with open-source implementations. It mentions that SeqGAN is mentioned but not tested with a pretrained version. However, the comment does not provide explicit guidance on how the authors should address this gap or what specific comparisons would be beneficial. The action is implicit, as the authors would need to infer that they should include comparisons with existing text GANs and test SeqGAN with a pretrained version. While the action is somewhat vague, it is clear that the authors need to make these comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"text GANs\" and \"SeqGAN,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by highlighting the absence of comparisons against existing text GANs, including those with open-source implementations, and notes that SeqGAN is mentioned but not tested with a pretrained version. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a lack of comparison against existing text GANs, particularly those with open-source implementations, and that SeqGAN is mentioned but not tested with a pretrained version. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim is unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of comparisons against existing text GANs, especially those with open-source implementations. It also notes that SeqGAN is mentioned but not tested with a pretrained version, which is a crucial aspect for evaluating the effectiveness of the proposed method. However, the comment lacks specific guidance on how the authors should address this gap or what comparisons would be most beneficial. While it highlights an important area for improvement, the feedback is somewhat limited in its actionable value, as it does not provide detailed suggestions or examples for the authors to consider. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should have focused on the algorithmic aspects of the solution, given the proposal of the Blackwell winner concept. However, it does not provide explicit guidance on how the authors should address this suggestion or what specific aspects of the algorithmic focus they should consider. The comment implies that the authors should expand on the algorithmic aspects, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable, as it provides a general direction but lacks specific guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should have focused on the algorithmic aspects of the solution, given the proposal of the Blackwell winner concept. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to pinpoint the exact area that needs attention. The comment is specific in its suggestion regarding the focus on algorithmic aspects, but it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper should have focused on the algorithmic aspects of the solution, given the proposal of the Blackwell winner concept. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. Without detailed justification or evidence, the claim remains somewhat verifiable, as it lacks the necessary depth and clarity to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the paper should have focused more on the algorithmic aspects of the solution, given the proposal of the Blackwell winner concept. This feedback is somewhat helpful as it highlights a specific area that could enhance the paper's contribution and novelty. However, the comment lacks depth and does not provide detailed guidance on how the authors might address this suggestion or what specific aspects of the algorithmic focus they should consider. While it points out a potential weakness, it does not offer actionable steps for improvement, making it somewhat helpful rather than fully helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to loss-based sampling. However, it does not provide explicit guidance on which methods to compare or how to adapt them for language tasks. The action is implicit, as the authors need to infer that they should consider comparing to specific methods and adapt them for language tasks. While the comment is somewhat actionable, it lacks concrete details on how to implement the suggested comparison, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including a comparison to methods mentioned in the computer vision setting, implying that the authors should consider comparing their approach to these methods. However, it does not specify which methods are being referred to or provide details on how this comparison would be beneficial. The comment is weakly grounded as it does not explicitly mention specific sections or parts of the paper, and it is not specific because it lacks details on the methods or the benefits of the comparison. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that comparing the methods to those mentioned in the computer vision setting would be more useful than comparing to loss-based sampling. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind it. Without detailed justification or examples, the claim is considered borderline verifiable, as it provides a general suggestion but lacks the necessary evidence to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that including a comparison to methods mentioned in the computer vision setting would be more useful than comparing to loss-based sampling. While the comment provides a rationale for this suggestion, it lacks specific examples or detailed guidance on which methods to compare or how to adapt them for language tasks. This feedback is somewhat helpful as it offers a direction for improvement, but it could be more actionable with additional details. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove the scalability properties. This provides a clear and explicit action for the authors to take, as they need to estimate the time complexity to support the claim about scalability. The comment is specific in its suggestion, detailing what needs to be done to substantiate the claim. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the time complexity of the learning algorithm should be explicitly estimated to prove the scalability properties. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to understand which part of the paper to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove the scalability properties. This claim is somewhat verifiable as it provides a logical reasoning for why the estimation of time complexity is important for demonstrating scalability. However, it lacks specific examples or references to support the claim, which could make it less robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the time complexity of the learning algorithm should be explicitly estimated to prove the scalability properties. This feedback is clear and actionable, as it provides a specific and concrete suggestion for the authors to improve their draft. By estimating the time complexity, the authors can better substantiate their claims about the scalability of their learning algorithm. This feedback is detailed and constructive, offering a clear direction for improvement. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the connection between the third point of definition one and the properties of universal kernels, specifically referencing Chapter 4 of Steinwart and Christmann. While it prompts the authors to explore this connection, it does not provide explicit guidance on how to address it or what specific aspects of the connection should be investigated. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore the connection further. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests exploring the connection between the third point and the properties of universal kernels, referencing a specific chapter in a relevant work. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the connection between the third point of definition one and the properties of universal kernels, referencing Chapter 4 of Steinwart and Christmann. While the comment provides a specific reference to a relevant work, it does not offer detailed reasoning or examples to support the claim that exploring this connection would be beneficial. The authors are left to infer the relevance and importance of the suggestion, which could be improved with additional context or justification. Therefore, the comment is somewhat verifiable, as it provides a basis for further exploration but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the connection between the third point of definition one and the properties of universal kernels, referencing a relevant work by Steinwart and Christmann. This feedback is somewhat helpful as it prompts the authors to consider a potential link that could enhance their understanding or the paper's contribution. However, it lacks detailed guidance on how to explore this connection or what specific aspects of the connection should be investigated. The comment provides a starting point for further discussion but does not offer comprehensive suggestions for improvement. Therefore, it aligns with a score of 3, as it offers some insight but could be more comprehensive and actionable.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the discussion around equation (10) is terse and not clearly explained. While it suggests that the authors should improve the clarity of this discussion, it does not provide specific guidance on how to achieve this. The action is implicit, as the authors need to infer that they should enhance the explanation of the discussion around equation (10). However, the comment lacks concrete details on what aspects of the discussion need to be clarified or expanded. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly points out that the discussion around this equation is terse and not well-explained, providing a clear indication of what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion around equation (10) is terse and not clearly explained. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the discussion around equation (10), noting that it is terse and not clearly explained. This feedback is actionable as it provides a clear area for improvement, suggesting that the authors should enhance the clarity and depth of their discussion. However, the comment lacks specific guidance on how to improve the explanation or what aspects of the discussion need clarification. While it offers a valuable suggestion, it could be more helpful if it provided more detailed guidance or examples of how to improve the explanation. Therefore, the comment is mostly helpful, as it directs the authors to an area of improvement but does not fully address the need for actionable feedback.', 'helpfulness_label': '4'} "}
