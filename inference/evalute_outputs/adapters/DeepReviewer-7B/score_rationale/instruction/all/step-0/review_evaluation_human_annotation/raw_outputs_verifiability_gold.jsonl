{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the baseline models used in the paper. First, it points out that the authors do not compare their models to Campos et al. (2020), which also uses feedback in QA tasks. This suggests that the authors should include this comparison to provide a more comprehensive evaluation of their models. Second, the comment notes that the authors do not compare their models to other domain adaptation methods, such as those mentioned in Section 8. This implies that the authors should include these comparisons to strengthen their analysis. The review point also suggests a minor correction in the text, changing \"The may be attributed\u2026\" to \"This may be attributed\u2026\". While the comment provides explicit actions and concrete details on how to improve the draft, it could be more actionable if it included specific guidance on how to conduct the comparisons or what aspects of the models to focus on. Overall, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the baseline models used in the paper and refers to specific sections, such as Section 8, to highlight the lack of comparison with other domain adaptation methods. It also points out a specific issue with a sentence in the text. This provides clear guidance for the authors to address the concerns. However, the comment is somewhat specific as it does not provide detailed guidance on what aspects of the models or comparisons need to be addressed. The authors are expected to infer the need for comparison with specific models and methods, but the comment lacks detailed suggestions. Therefore, this comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the adopted baseline models are weak and suggests that the authors should compare their models to Campos et al. (2020) and other domain adaptation methods. The comment provides specific references, such as Section 8, to support the claim, indicating that the authors should include these comparisons. However, the reasoning could be more detailed, and the claim is mostly verifiable as it is supported by references but lacks some depth in explanation. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant weakness in the paper by pointing out that the baseline models used are weak and that the authors have not compared their models to relevant works, such as Campos et al. (2020) and other domain adaptation methods. This feedback is valuable as it directs the authors to include additional comparisons to strengthen their evaluation and provide a more comprehensive understanding of their models' performance. The comment also suggests a minor correction in the text, which is a helpful but minor point. Overall, the comment is mostly helpful as it provides clear guidance on areas for improvement, though it could be more detailed to fully assist the authors in enhancing their draft.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider adding information about the use of word embeddings in the Bi-LSTM-CRF model, similar to Lample et al. It also questions whether the mentions in Figure 3 are in the source language or in English, given that the mentions have been translated to English. The comment implies that this clarification is necessary for the authors to improve their draft. However, the action is implicit, as the authors need to infer that they should add this information and clarify the figure. The lack of explicit guidance on how to implement these changes makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, including the addition of information about word embeddings and the clarification of the KNs in Figure 3. This provides clear guidance on what changes are necessary, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should consider adding information about the use of word embeddings in the Bi-LSTM-CRF model, similar to Lample et al., and that the figure should clarify whether the mentions are in the source language or in English. However, the comment lacks specific reasoning or references to support why these additions are beneficial or necessary. It does not provide examples or detailed explanations of how these changes would improve the paper. As a result, the claim is not verifiable, and the comment does not offer actionable guidance for the authors. Therefore, it is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific suggestions for improvement, such as adding information about the use of word embeddings in the Bi-LSTM-CRF model, similar to Lample et al., and clarifying the source language of mentions in Figure 3. These suggestions are actionable and could help the authors enhance the clarity and completeness of their paper. However, the comment could be more helpful if it included additional guidance on how to implement these suggestions or provided examples of how the additions might look. Overall, the feedback is mostly helpful as it offers clear directions for improvement, but it could be more comprehensive with additional details. Therefore, the comment is rated as 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that some claims in the paper would benefit from more in-depth analysis. However, it does not specify which claims need more analysis or provide any guidance on how to conduct this analysis. The action is implicit and vague, as the authors are left to infer that they should delve deeper into the analysis of certain claims. Without explicit instructions or concrete examples, the authors are unable to understand what specific aspects require more detailed analysis. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that some claims in the paper would benefit from more in-depth analysis. However, it does not specify which claims or sections of the paper are being referred to, nor does it provide any guidance on how to conduct this analysis. The lack of specific information makes it difficult for the authors to identify the exact parts of the paper that need improvement. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that some claims in the paper would benefit from more in-depth analysis. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors are left to infer the nature of the claims that require more analysis, making the comment somewhat verifiable. The lack of detailed explanation or examples makes it challenging for the authors to understand the specific areas that need improvement.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that some claims in the paper would benefit from more in-depth analysis. However, it lacks specificity and does not provide any guidance on which claims need more analysis or how to conduct this analysis. The comment is vague and does not offer actionable feedback, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific issues regarding the presentation of the model. It asks for clarification on the pooling method used for embedding features, referencing line 397, and questions the clarity of Equation (7) in line 472, specifically regarding whether E_i represents the type or identity of an AC. The comment also suggests that the left-hand side of the equation might be a conditional probability. While the comment identifies two areas for clarification, it does not provide explicit instructions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should clarify the pooling method and the definition of E_i, as well as the nature of the left-hand side of Equation (7). Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (397 and 472) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be addressed: the pooling method used for embedding features and the clarity of Equation (7), including the definition of E_i and the nature of the left-hand side of the equation. This provides clear guidance on how the authors should improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two specific questions about the presentation of the model, focusing on the pooling method used for embedding features and the clarity of Equation (7). The first question asks for clarification on the pooling method referenced in line 397, which is a factual request for information. The second question questions the clarity of Equation (7) in line 472, specifically regarding whether E_i represents the type or identity of an AC, and suggests that the left-hand side of the equation might be a conditional probability. While the comment provides some context and asks for clarification, it lacks detailed reasoning or references to support the claims. Therefore, the comment is somewhat verifiable, as it provides some basis for understanding but could be more robust with additional justification or examples. The label aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement in the presentation of the model: the pooling method used for embedding features and the clarity of Equation (7). It requests clarification on the pooling method referenced in line 397 and questions the definition of E_i in Equation (7), specifying whether it represents the type or identity of an AC. Additionally, it suggests that the left-hand side of Equation (7) might be a conditional probability. This feedback is clear and actionable, providing the authors with specific questions and areas to address in their draft. By highlighting these issues, the comment guides the authors to improve the clarity and precision of their presentation, making it mostly helpful. However, it could be more helpful if it provided more detailed guidance on how to address these issues or suggested specific ways to clarify the equations. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. This feedback is explicit and provides a clear action for the authors to take, which is to include empirical evidence to substantiate the claim. The comment is specific in its suggestion and offers a concrete direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. However, the comment does not specify which part of the paper discusses the third contribution or the Column Subset Selection problem, making it weakly grounded. It is specific in its suggestion to include empirical evidence, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. However, the comment does not provide any specific examples, references, or detailed reasoning to substantiate this claim. Without additional context or evidence, the authors may find it challenging to understand and address the suggestion effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. This feedback is clear and actionable, as it directs the authors to include empirical evidence to substantiate their claim. By doing so, the authors can strengthen the validity of their contribution and provide a more comprehensive evaluation of their algorithm. However, the comment could be more helpful if it offered specific guidance on how to conduct the empirical evaluation or what kind of evidence would be most effective. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more detailed in its suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that more analysis and comments are needed regarding the performance trends of increasing the number of parameters for ViT (DeiT) in Figure 3. It disagrees with the authors' viewpoint that both CNNs and ViTs benefit similarly from increased model capacity. The comment provides specific observations about the performance of DeiT models on different datasets, noting that DeiT-B does not outperform DeiT-T and DeiT-S in APTOS2019, ISIC2019, and CheXpert, while CNNs show more consistent improvements. However, the comment does not explicitly instruct the authors on how to conduct this additional analysis or what specific aspects to focus on. While the authors can infer that they need to provide more analysis, the lack of explicit guidance on the methodology or specific areas to explore makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed observations about the performance trends of DeiT models compared to CNNs, highlighting discrepancies in their performance across different datasets. The authors are informed about what specific aspects need further analysis, making the comment both fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' viewpoint regarding the performance trends of increasing model capacity for ViT (DeiT) is incorrect. It provides specific observations about the performance of DeiT models on different datasets, noting that DeiT-B does not outperform DeiT-T and DeiT-S in APTOS2019, ISIC2019, and CheXpert, while CNNs show more consistent improvements. However, the comment lacks detailed reasoning or references to support these claims, making it somewhat verifiable. The authors would need to independently verify the claims by examining the data presented in Figure 3 and comparing the performance of different models. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a detailed analysis of the performance trends of increasing model capacity for ViT (DeiT) in Figure 3, offering specific observations and comparisons with CNNs. It challenges the authors' viewpoint that both CNNs and ViTs benefit similarly from increased model capacity, noting that DeiT models do not consistently outperform CNNs across all datasets. This feedback is valuable as it highlights a potential inconsistency in the authors' claims and suggests that the performance trends may need further analysis. However, the comment could be more helpful if it provided specific suggestions or guidance on how to conduct this additional analysis or what aspects of the performance trends should be explored further. Overall, the comment is mostly helpful as it identifies a significant area for improvement and encourages the authors to revisit their claims.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the novelty of the proposed method, noting its similarity to existing attentional modules and ResNeSt. It suggests that the paper should discuss the differences between the proposed method and these existing modules. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the method need to be clarified. The action is implicit and vague, as it does not specify how the authors should compare their method to the mentioned works or what specific details need to be discussed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the novelty of the proposed method, noting its similarity to existing attentional modules and ResNeSt. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the similarity to other modules and ResNeSt, but it lacks detailed guidance on how to address this issue or what specific aspects of the method need to be clarified. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the proposed method is limited due to its similarity to existing attentional modules and ResNeSt. The comment provides specific references to previous works [1, 2, 3] and ResNeSt [4], suggesting that the paper should discuss these similarities. However, the comment lacks detailed reasoning or examples to fully support the claim, making it somewhat verifiable. The authors would need to provide more context or evidence to fully understand the basis of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the novelty of the proposed method, noting its similarity to existing attentional modules and ResNeSt. It provides specific references to previous works [1, 2, 3] and ResNeSt [4], which helps the authors understand the context and the potential overlap in their approach. However, the comment could be more helpful by offering suggestions on how the authors might differentiate their method or address the similarities more explicitly. While it highlights an important issue, the feedback lacks depth and actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential confusion regarding the implicit call to the Witness oracle, but it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks specific details or suggestions on what changes might be necessary to clarify the concept. Without actionable steps or concrete advice, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a potential confusion regarding the implicit call to the Witness oracle, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine where the confusion arises, making the comment weakly grounded. However, the comment is specific in identifying the need for clarification regarding the implicit call to the Witness oracle. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the required implicit call to the Witness oracle is confusing. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the call is confusing or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the implicit call to the Witness oracle, which could be confusing for readers. However, the comment lacks specific details or suggestions on how the authors might address this confusion. Without actionable guidance or examples, the authors may struggle to understand or resolve the issue, making the feedback somewhat helpful. The comment provides a starting point for improvement but does not fully support the authors in enhancing their draft.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the necessity of reproducing a well-known result using a \"coarse\" methodology, suggesting that the observation has been made at each step of the evolution of language models. However, it does not provide explicit or implicit actions for the authors to take, such as suggesting alternative methodologies or providing more detailed analysis. The comment lacks concrete guidance on how the authors might address this concern or improve their draft. As a result, the comment is unactionable, aligning with a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"coarse\" methodology used in reproducing a well-known result in the literature, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of novelty in the observation and the need for a more detailed analysis. The comment suggests that the authors should consider alternative methodologies or provide more detailed analysis to address this concern. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have reproduced a well-known result using a \"coarse\" methodology, which is not novel. The comment suggests that the observation has been made at each step of the evolution of language models, making the authors' approach unclear. However, the comment lacks specific examples or references to support the claim that the observation is indeed well-known or that the authors' methodology is \"coarse.\" Without detailed evidence or examples, the claim is difficult to verify, making it borderline verifiable. Therefore, the comment is rated as 2.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment questions the novelty of the authors' approach by pointing out that the observation of political bias in language models has been made at each step of their evolution. This critique suggests that the authors' methodology, which involves passing a binary stance classifier over ChatGPT's output, is not particularly novel and lacks depth. While the comment identifies a potential issue with the authors' approach, it does not provide specific suggestions or guidance on how the authors might address this concern or enhance their work. The feedback is somewhat helpful as it highlights a need for more detailed analysis or a different approach, but it lacks actionable advice, making it a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to clarify the distinction between weak and semi-supervised training of the proposed method. It provides specific examples, such as renaming a column in Table 1 to \u201cFully supervised\u201d and suggests a more detailed categorization of training data into \u201cMixture training data\u201d and \u201cSingle source data.\u201d These instructions are clear and provide concrete guidance on how the authors should address the issue. The comment is fully actionable, as it directly instructs the authors on what changes to make to improve the clarity of their paper. Therefore, this comment is rated as 5: Highly Actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to clarify the distinction between weak and semi-supervised training, suggesting renaming a column and categorizing training data. This detailed feedback helps the authors understand exactly what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point provides specific suggestions for improving the clarity of the paper, such as renaming a column in Table 1 and categorizing training data. These suggestions are logical and actionable, as they offer clear guidance on how the authors can enhance the presentation of their work. However, the comment lacks references or detailed reasoning to fully substantiate the claims. While the suggestions are well-supported, the absence of additional evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback on the clarity of the distinction between weak and semi-supervised training in the proposed method. It suggests renaming a column in Table 1 to \u201cFully supervised\u201d and proposes a more detailed categorization of training data into \u201cMixture training data\u201d and \u201cSingle source data.\u201d These suggestions are specific and provide a clear path for the authors to improve the clarity and organization of their paper. The feedback is mostly helpful as it offers concrete guidance but could be further expanded to include additional details or examples. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a significant weakness in the paper, specifically the limited scope of the experiments section. It highlights that the results are only presented on the CIFAR-10 dataset and suggests considering other datasets from federated learning benchmarks, such as those available on the LEAF benchmark. The comment also recommends exploring relevant works like FedProx and FedMAX for details on different datasets and model types. However, the comment does not provide explicit guidance on how the authors should expand their experiments or what specific datasets or model types they should consider. While the action is implied, it lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experiments, namely that they are limited to the CIFAR-10 dataset and do not consider other datasets from federated learning benchmarks. The comment provides specific examples of relevant datasets and suggests considering additional works for details on different datasets and model types. This level of detail helps the authors understand what needs to be addressed to improve the comprehensiveness of the experiments. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments section is a main weakness of the paper, as the results are presented only on the CIFAR-10 dataset and do not consider other datasets from federated learning benchmarks. The comment suggests considering datasets from the LEAF benchmark and recommends exploring relevant works like FedProx and FedMAX for details on different datasets and model types. However, the comment lacks specific examples or detailed reasoning to fully support the claim. While it provides a general direction for improvement, it does not offer detailed guidance or references to specific datasets or models that would enhance the comprehensiveness of the experiments. Therefore, the claim is somewhat verifiable, as it provides some basis for improvement but lacks sufficient detail to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the limited scope of the experiments section. It points out that the results are only presented on the CIFAR-10 dataset and suggests considering other datasets from federated learning benchmarks, such as those available on the LEAF benchmark. The comment also recommends exploring relevant works like FedProx and FedMAX for details on different datasets and model types. This feedback is mostly helpful as it provides clear guidance on how the authors can enhance the comprehensiveness of their experiments, which is crucial for a robust evaluation of the proposed method. However, the comment could be more helpful if it included specific examples of datasets or model types that the authors should consider, or if it provided more detailed reasoning for why these additional datasets are important. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the use of unlabeled data, noting that the data is perfectly balanced and may not be practical in real-world applications. It suggests that the authors should consider using a more convincing setting, such as sampling unlabeled data from millions of reviews, as done in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018. This comment provides a clear and explicit action for the authors to take, which is to consider using a more realistic setting for their experiments. The suggestion is concrete and offers a specific example of how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"preprocessed Amazon review dataset (Blitzer version)\" and the \"2000 unlabeled data,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear rationale for the issue, suggesting that the authors should consider using a more convincing setting as done in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018. This provides a specific example of how the authors could address the issue, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of perfectly balanced unlabeled data is impractical in real-world applications and suggests using a more convincing setting as done in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018. The claim is supported by the reasoning that controlling label distribution during training is difficult in real-world scenarios, and the suggestion provides a specific example of a more realistic setting. However, the comment could be more robust if it included a detailed explanation of why the suggested approach is more convincing or how it addresses the limitations of the current method. Overall, the claim is mostly verifiable, as it is supported by logical reasoning and a reference to a relevant work, but it could be strengthened with additional details.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of unlabeled data, specifically noting that the data is perfectly balanced and may not be practical in real-world applications. It suggests that the authors should consider using a more convincing setting, such as sampling unlabeled data from millions of reviews, as done in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018. This feedback is clear and actionable, providing the authors with a specific direction to improve their experimental setup. By suggesting a more realistic setting, the comment helps the authors enhance the practical relevance and applicability of their work. Therefore, the comment is highly helpful, as it offers a clear and constructive suggestion for improvement.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a confusion regarding the description of the MFDA setting in the first paragraph of the Method Section. It points out that the notation for the target domain \\\\tau is unlabeled, which is inconsistent with the original MFDA paper (Yue et al., 2021a). The comment questions whether unlabeled data from source domains is used during training, as in the original paper. This feedback is explicit and provides a clear action for the authors to take: they should clarify the notation and explain the use of unlabeled data from source domains in their method. The comment is specific and actionable, as it directly addresses a potential issue in the paper and suggests a concrete step for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the first paragraph of the Method Section, providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies the issue with the description of the MFDA setting, particularly the confusion regarding the notation for the target domain \\\\tau and the use of unlabeled data from source domains. This level of detail makes the comment specific, as it clearly identifies what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the consistency of the description of the MFDA setting in the paper with the original MFDA paper (Yue et al., 2021a). It points out that the notation for the target domain \\\\tau is unlabeled, which is inconsistent with the original paper. The comment questions whether unlabeled data from source domains is used during training, as in the original paper. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to provide more context or evidence to fully understand the issue. Therefore, the comment is somewhat verifiable, as it provides a basis for further clarification but requires additional support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the description of the MFDA setting within the Method Section, particularly concerning the notation for the target domain \\\\tau and the use of unlabeled data from source domains. It highlights a potential inconsistency with the original MFDA paper (Yue et al., 2021a), which could confuse readers. The comment is clear and actionable, as it directs the authors to clarify the notation and explain the use of unlabeled data from source domains in their method. This feedback is valuable as it provides a concrete step for the authors to improve the clarity and consistency of their paper. However, the comment could be more helpful if it offered additional guidance on how to address the issue or suggested specific ways to clarify the description. Overall, the comment is mostly helpful, as it effectively points out a potential area for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the authors' claim about the immense workload but disagrees with the assessment of the paper's contribution as incremental. It suggests that the paper is essentially a combination of GraphRAG and GraphCare [1] and points out that many key baselines were not cited. The comment also notes that essential RAG algorithms for EHR, such as MedRetriever [2], and commonly used GraphRAG algorithms like KGRAG [3], should have been introduced. However, the comment does not provide explicit guidance on how the authors should address these issues, such as suggesting specific sections to revise or how to incorporate the missing information. While the action is somewhat implied, it lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the authors' claim about the immense workload and the incremental contribution of the article, referencing specific works [1], [2], and [3]. It also provides specific suggestions for improvement, such as introducing essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG. This level of detail allows the authors to understand exactly what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' contribution is incremental and suggests that the paper is essentially a combination of GraphRAG and GraphCare [1]. It also points out that many key baselines were not cited and recommends introducing essential RAG algorithms like MedRetriever [2] and commonly used GraphRAG algorithms like KGRAG [3]. The claim about the incremental contribution is somewhat verifiable as it provides a basis for comparison with existing work, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to include essential RAG algorithms is more verifiable as it provides concrete examples of what should be included. Overall, the comment is somewhat verifiable, as it offers some justification but could be strengthened with more detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a detailed critique of the authors' work, highlighting the incremental nature of their contribution and suggesting that the paper is essentially a combination of GraphRAG and GraphCare [1]. It also points out the absence of key baselines and recommends the inclusion of essential RAG algorithms like MedRetriever [2] and commonly used GraphRAG algorithms like KGRAG [3]. This feedback is mostly helpful as it offers specific suggestions for improvement, guiding the authors on what aspects of their work need attention. However, it could be more comprehensive if it included additional details or examples to fully support the claims. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights specific missing state-of-the-art references in the face recognition experiment, providing examples such as \"Baidu' work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\", http://vis-www.cs.umass.edu/lfw/results.html#baidu.\" It also mentions that the VRF can achieve 98.65% on LFW, which is better than the result in Table 3 of the paper. This feedback is explicit and provides concrete details on what is missing and how it relates to the paper's results. The authors can directly infer that they need to include these references and compare their results with the reported findings. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiment of face recognition,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the missing state-of-the-art references, such as \"Baidu' work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding,\" and provides a specific comparison with the results reported in Table 3 of the paper. This allows the authors to understand exactly what needs to be addressed and how it relates to their work. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some state-of-the-art references are missing in the face recognition experiment, specifically mentioning \"Baidu' work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding,\" and provides a comparison of the VRF's performance on LFW with the results in Table 3 of the paper. The claim is supported by specific examples and a detailed comparison, making it mostly verifiable. The authors can verify the claim by examining the mentioned reference and comparing the results. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue in the face recognition experiment by pointing out the absence of certain state-of-the-art references. It provides a concrete example, \"Baidu' work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding,\" and highlights that this work uses a similar approach and achieves a better result on the LFW dataset compared to the results presented in Table 3 of the paper. This feedback is actionable as it directs the authors to include these references and compare their results with the reported findings, which can help improve the comprehensiveness and accuracy of their work. However, the comment could be more helpful if it suggested specific ways to incorporate or discuss these references. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but lacks some depth in terms of actionable suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the rock-paper-scissors example is inspired by previous work and requests that the authors cite the source appropriately. While the comment implies that the authors should cite the source, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should cite the source. However, the comment provides a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"rock-paper-scissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests that the authors cite the source appropriately, providing clear guidance on what needs to be done. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the rock-paper-scissors example is inspired by an example from previous work and requests that the authors cite the source appropriately. While the comment suggests a necessary action, it does not provide any specific reasoning or evidence to support the claim that the example is indeed inspired by previous work. The authors are left to infer the basis of the inspiration, which makes the claim somewhat verifiable. However, without additional context or references, the claim lacks sufficient support, aligning with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the rock-paper-scissors example, noting that it is inspired by examples from previous work. It requests that the authors cite the source appropriately. This feedback is clear and actionable, as it directs the authors to address a potential oversight in their citation practices. However, the comment could be more helpful if it provided specific examples of previous work that inspired the rock-paper-scissors example or suggested where the authors might find these sources. Despite this, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should consider averaging over subword representations, a common practice in certain cases, and provides a specific reference to support this suggestion. This action is clear and concrete, as it directly instructs the authors on how to modify their approach. The authors know exactly what needs to be done to incorporate this suggestion into their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific line in the paper (L.490), allowing the authors to accurately identify the part being addressed. It is also specific because it provides a clear suggestion to consider averaging over subword representations, a common practice, and references a specific paper to support this suggestion. This provides the authors with a clear understanding of what needs to be addressed and how to do it. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that it is common to average over subword representations in certain cases, providing a reference to support this claim. However, the comment does not elaborate on why this is a common practice or how it relates to the specific context of the paper. While the reference is provided, the reasoning behind the claim is not fully explained, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by pointing out a common practice in natural language processing, namely averaging over subword representations, and referencing a relevant paper. It suggests that the authors should consider this approach, which could enhance the robustness of their method. However, the comment lacks detailed guidance on how to implement this suggestion or why it is beneficial in the context of the paper. While it offers a valuable insight, the feedback could be more helpful if it included specific examples or a deeper explanation of the implications of this suggestion. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the comprehensiveness of the experiments conducted to validate the efficacy of CATER in different settings, such as architectural mismatch and cross-domain imitation. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might improve their draft or address any specific issues related to the comprehensiveness of their experiments. As a result, the authors are left without any actionable feedback, making this comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments conducted to validate the efficacy of CATER in various settings, including an architectural mismatch between the victim and the imitation model and cross-domain imitation. This provides clear guidance on which part of the paper the authors should focus on. The comment is also specific because it highlights the comprehensiveness of the experiments and the settings considered, offering detailed feedback on the scope of the validation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point describes the experiments conducted to validate the efficacy of CATER in various settings, including an architectural mismatch between the victim and the imitation model and cross-domain imitation. However, it does not provide any specific claims, opinions, or suggestions that require verification or justification. The comment is purely factual and descriptive, lacking any critical analysis or guidance that would help the authors improve their work. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment acknowledges the comprehensiveness of the experiments conducted to validate the efficacy of CATER in various settings, including an architectural mismatch between the victim and the imitation model and cross-domain imitation. However, it does not provide any specific feedback or suggestions on how the authors might improve their draft or address any potential weaknesses in their experimental design. The comment lacks actionable guidance, making it unhelpful for the authors to enhance their work. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the restrictive nature of the bounded noise assumption in stochastic optimization literature and mentions several efforts to extend these noise conditions, citing specific works. However, it does not provide explicit or implicit actions for the authors to take, such as suggesting alternative assumptions or exploring the cited works. The comment lacks concrete guidance on how the authors might address the issue or incorporate the suggested references. As a result, the authors are left without clear direction on how to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the bounded noise assumption in stochastic optimization literature, referencing specific works that extend these noise conditions. However, it does not specify which part of the paper discusses the bounded noise assumption or how it relates to the authors' work. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, while the comment mentions specific works, it does not provide detailed guidance on how these works could be integrated or discussed in the paper. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the bounded noise assumption, while common, is somewhat restrictive in stochastic optimization literature. It provides references to specific works that have extended these noise conditions, such as [A. Khaled and P. Richt\u00b4arik] and [R. Gower, O. Sebbouh, and N. Loizou]. However, the comment lacks detailed reasoning or explanation of why the bounded noise assumption is restrictive or how the cited works address this limitation. The references are provided, but without a clear connection to the specific issue being discussed in the paper, the claim is somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the bounded noise assumption, which is a common assumption in stochastic optimization literature. It acknowledges that this assumption is somewhat restrictive and points out several efforts to extend these noise conditions, citing specific works. However, the comment does not provide actionable guidance or suggestions on how the authors might address this limitation or incorporate the suggested works into their research. Without specific advice or recommendations, the authors are left without a clear path forward, making the comment somewhat helpful. It could be more helpful if it offered suggestions or guidance on how to extend the noise conditions or integrate the cited works into the paper.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"100 steps\" in the context of search models comparison. It does not provide an explicit action or suggestion for the authors to take, such as clarifying the definition of \"100 steps\" or providing additional context. The comment is vague and lacks concrete guidance on how the authors should address this issue. Therefore, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the meaning of \"100 steps\" in the context of search models comparison, specifically questioning whether it refers to 100 sampled strategies. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or figure being referenced. The comment is specific in its request for clarification but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the meaning of \"100 steps\" in the context of search models comparison, specifically questioning whether it refers to 100 sampled strategies. This is a factual question seeking clarification, and it does not contain any subjective opinions or claims that require verification. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"100 steps\" in the context of search models comparison, specifically asking whether it refers to 100 sampled strategies. This question highlights a potential ambiguity in the description, which could hinder the clarity and understanding of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify the meaning of \"100 steps.\" Without actionable feedback or suggestions, the comment is barely helpful, as it only points out a potential area of confusion without offering a solution.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the convergence rate of the proposed algorithm DMLCBO compared to previous works that utilize the double momentum technique. It suggests that the authors should discuss the reasons for this difference and the theoretical technique differences between DMLCBO and the mentioned works. While the comment provides a clear direction for the authors to address the issue, it does not specify how to analyze the convergence rate or the theoretical differences. The action is explicit but somewhat vague, as it lacks detailed guidance on how to implement the suggested discussion. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed algorithm DMLCBO and its basis in the double momentum technique, referencing specific previous works, SUSTAIN[1] and MRBO[2]. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue of the convergence rate discrepancy and encourages the authors to discuss the reasons and theoretical differences between DMLCBO and the mentioned works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed algorithm DMLCBO, based on the double momentum technique, does not achieve the same convergence rate as previous works, such as SUSTAIN and MRBO, which achieve $\\mathcal{\\widetilde O}(\\epsilon^{-3})$. The comment suggests that the authors should discuss the reasons for this discrepancy and the theoretical differences between DMLCBO and the mentioned works. However, the comment lacks specific examples or detailed reasoning to support the claim, making it somewhat verifiable. The authors would need to provide more context or evidence to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed algorithm DMLCBO, noting that it does not achieve the same convergence rate as previous works that utilize the double momentum technique. It encourages the authors to discuss the reasons for this discrepancy and the theoretical differences between DMLCBO and the mentioned works. This feedback is clear and actionable, providing the authors with a specific direction to improve their understanding and potentially enhance the paper. However, the comment could be more helpful if it offered additional guidance on how to analyze the convergence rate or the theoretical differences. Overall, the comment is mostly helpful, as it effectively highlights an area for improvement and encourages detailed discussion.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the heuristic design of the modulator and suggests that it might be hard to justify due to potential scalability issues and the need for tedious hyperparameter tuning for diverse training data. However, the comment does not provide explicit guidance on how the authors might address these issues or what specific actions they should take to improve the modulator. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the heuristic design of the modulator and suggests that it might be hard to justify due to potential scalability issues and the need for tedious hyperparameter tuning for diverse training data. However, the comment does not specify which part of the paper discusses the modulator or where the issue of scalability is addressed. This lack of grounding makes it difficult for the authors to pinpoint the exact section or aspect of the paper that needs attention. While the comment is specific in its critique of the modulator's design, the absence of explicit references or grounding weakens the overall impact. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the heuristic design of the modulator, suggesting that it might be hard to justify due to potential scalability issues and the need for tedious hyperparameter tuning for diverse training data. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the heuristic design of the modulator, suggesting that it might be hard to justify due to potential scalability issues and the need for tedious hyperparameter tuning for diverse training data. While the comment identifies a potential weakness in the modulator's design, it lacks specific guidance or suggestions on how the authors might address these issues or improve the modulator. The feedback is somewhat helpful as it points out a potential area for improvement, but it does not provide actionable steps or detailed insights to help the authors enhance their work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should mention and compare its method with untrained neural networks used for solving inverse problems in imaging, referencing specific work by Ulyanov et al. (CVPR 2018). The comment implies that this comparison would provide context and strengthen the paper. However, it does not explicitly instruct the authors to add this comparison or mention it in the paper. The action is implicit and somewhat vague, as the authors need to infer that they should include this comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"OOD experiments\" and \"imaging in the recent few years,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the suggestion to mention and compare the current method with untrained neural networks used for solving inverse problems in imaging, referencing specific work by Ulyanov et al. (CVPR 2018). This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper should mention and compare its method with untrained neural networks used for solving inverse problems in imaging, referencing specific work by Ulyanov et al. (CVPR 2018). This claim is somewhat verifiable as it provides a specific suggestion for improvement and references a relevant piece of work. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would benefit from additional explanation or examples to strengthen the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific area for improvement by suggesting that the paper should mention and compare its method with untrained neural networks used for solving inverse problems in imaging. It provides a clear reference to a relevant work by Ulyanov et al. (CVPR 2018), which helps the authors understand the context and potential comparison points. However, the comment could be more helpful if it included specific guidance on how to integrate this comparison into the paper or suggested additional relevant literature. Overall, the feedback is actionable and provides a clear direction for improvement, making it a mostly helpful comment.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies two specific sections of the paper that are hard to read and points out a lack of clarity in the explanation of previous approaches. It provides detailed examples of where the authors fail to explain certain concepts, such as the conversion of a stacked LSTM to a sequential LSTM and the meaning of specific variables in a figure. However, the comment does not offer any explicit or implicit suggestions on how to improve the clarity of these sections. The authors are left without guidance on how to address these issues, making the comment unactionable. Therefore, the comment is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed examples of where the authors fail to explain certain concepts, such as the conversion of a stacked LSTM to a sequential LSTM and the meaning of specific variables in a figure. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises specific questions about the clarity of explanations in the paper, particularly regarding the conversion of a stacked LSTM to a sequential LSTM and the meaning of certain variables in a figure. However, it does not provide any evidence or reasoning to support why these explanations are unclear or how they could be improved. The comment lacks detailed examples or references that would help the authors understand the issues or how to address them. As a result, the claim is unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies specific sections of the paper that are difficult to read, particularly the first two sections, due to the lack of clear explanations of previous approaches. It provides detailed examples of where the authors fail to explain certain concepts, such as the conversion of a stacked LSTM to a sequential LSTM and the meaning of specific variables in a figure. However, the comment does not offer any suggestions or guidance on how to improve the clarity of these sections or address the specific issues raised. While it highlights areas for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the goal of the paper, suggesting that the authors should clarify whether the work aims to develop a foundation model or to demonstrate a proof of concept. It also points out the absence of a comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and questions the justification for the method's benefit over these existing approaches. The comment implies that the authors should provide a clearer explanation of their goal and demonstrate the utility of their method through additional experiments or justifications. However, the comment does not explicitly instruct the authors to address these issues, leaving the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the goal of the paper, specifically mentioning the existence of DAS earthquake detectors and the lack of comparison or justification against them. It also suggests clarifying whether the work aims to develop a foundation model or demonstrate a proof of concept and recommends showing or justifying future useful applications. However, the comment does not specify which part of the paper discusses the goal or the comparison with existing methods, making it weakly grounded. The specificity of the comment is good as it clearly identifies the issues that need to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the lack of comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and questions the justification for the method's benefit over these existing approaches. The comment suggests that if the claim is to present a foundation model, it should be clearer and demonstrate future applications. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. The authors would need to provide more evidence or justification to address this concern effectively.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the paper\\'s goal and the lack of comparison with existing DAS earthquake detectors, such as PhaseNet-Das. It suggests that the authors should clarify whether the work aims to develop a foundation model or demonstrate a proof of concept and provide a justification for the benefit of their method over existing approaches. Additionally, the comment recommends showing or justifying future useful applications, which could enhance the paper\\'s impact. While the comment is clear and provides actionable feedback, it could be more helpful if it included specific examples or suggestions for how to address the identified issues. Overall, the comment is mostly helpful, as it offers valuable insights for improving the paper.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that similar analyses have been conducted in prior works, noting that the results are not particularly surprising. It provides specific examples, such as the study of CIFAR-10 models on distribution shifts in RobustBench and the evaluation of adversarially trained models in [A, B]. However, the comment does not offer explicit or implicit suggestions on how the authors might address these points or improve their work. The authors are left without guidance on how to incorporate or discuss these findings, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific prior works and examples, such as RobustBench and [A, B], allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what the authors should consider by noting that similar analyses have been conducted on smaller scales and that the results are not particularly surprising. This provides clear guidance on how the authors might improve their work by referencing these prior studies. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that similar analyses have been conducted in prior works, specifically mentioning RobustBench and references [A, B]. It provides examples, such as the study of CIFAR-10 models on distribution shifts and the evaluation of adversarially trained models. However, the comment lacks detailed reasoning or specific examples to fully support the claim, making it somewhat verifiable. The authors would benefit from a more comprehensive explanation of how these prior works relate to their own research, enhancing the verifiability of the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies that similar analyses have been conducted in prior works, specifically mentioning RobustBench and references [A, B]. It highlights that the results are not particularly surprising, which suggests that the authors should consider expanding their work to include a more comprehensive discussion of these prior studies. However, the comment lacks specific guidance on how the authors might address these points or incorporate them into their work. While it provides a starting point for improvement, it does not offer detailed suggestions or actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific feedback on two aspects of the paper. First, it critiques the accuracy of a statement regarding the related work, suggesting that the Walkman algorithm is solved by ADMM with two versions, not just SGD. This implies that the authors should revise their statement to accurately reflect the capabilities of the Walkman algorithm. Second, the comment points out a lack of clarity in the reference \"it\" in Section 3, first paragraph, which could hinder the reader's understanding. While the comment identifies areas for improvement, it does not provide explicit instructions on how to revise the statements or clarify the references. The actions are somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, namely the Related Work section (Page 2, second paragraph) and Section 3, first paragraph. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides detailed feedback on the accuracy of a statement regarding the Walkman algorithm and the clarity of a reference, offering concrete suggestions for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point contains two claims. The first claim critiques the accuracy of a statement regarding the related work, specifically mentioning the Walkman algorithm and its solutions using ADMM. This claim is somewhat verifiable as it provides a specific example of a discrepancy in the paper's description, allowing the authors to verify the claim. The second claim points out a lack of clarity in a reference within Section 3, first paragraph, which could hinder the reader's understanding. This claim is also somewhat verifiable as it highlights a potential issue with the clarity of the reference. Overall, the comment is somewhat verifiable, as it provides some justification but lacks detailed reasoning or references to fully support the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on two aspects of the paper. First, it critiques the accuracy of a statement regarding the related work, pointing out that the Walkman algorithm is solved by ADMM with two versions, not just SGD. This feedback is valuable as it helps the authors refine their claims and ensure accuracy. Second, the comment highlights a lack of clarity in a reference within Section 3, first paragraph, which could hinder the reader's understanding. While the comment identifies areas for improvement, it could be more helpful if it provided specific suggestions for how to revise the statements or clarify the references. Overall, the comment is somewhat helpful, as it offers actionable feedback but could be more comprehensive and detailed.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their proposed method with more baselines, as there are several works that focus on the same questions. It provides specific examples of these works, such as [1, 2, 3], which implies that the authors should include these in their experimental comparisons to better demonstrate the effectiveness of their method. The comment is explicit in suggesting the addition of more baselines and provides concrete examples, making it clear how the authors should apply the feedback. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should compare their proposed method with more baselines, specifically mentioning several works that focus on the same questions, such as [1, 2, 3]. This provides a clear indication of what additional comparisons are needed. However, the comment does not specify which part of the paper discusses the experimental section or where these comparisons are currently addressed. While the authors can infer that the experimental section is the relevant part, the lack of explicit mention makes the comment weakly grounded. The comment is specific in suggesting the need for additional comparisons, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas that require improvement. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors should compare their proposed method with more baselines, as there are several works that focus on the same questions. The comment provides specific examples of these works, such as [1, 2, 3], which suggests that the authors should include these in their experimental comparisons. However, the comment lacks detailed reasoning or references to support the claim that these additional comparisons are necessary or would significantly enhance the paper's effectiveness. While the examples are provided, the reasoning behind why these additional comparisons are crucial is not elaborated upon, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the experimental section, noting that the authors only compared their proposed method with two baselines. It suggests that there are other works focusing on similar questions and provides examples of these works, such as [1, 2, 3]. This feedback is clear and actionable, as it directs the authors to include additional comparisons to better demonstrate the effectiveness of their method. By recommending the inclusion of more relevant baselines, the comment provides a concrete and constructive suggestion that can help the authors strengthen their experimental evaluation. Therefore, the comment is highly helpful, as it offers specific guidance on how to improve the draft.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of detail regarding the filtering process used to create the Arabic climate change QA dataset. It suggests that more information on the translation and filtering methodology is needed to assess the dataset quality. However, the comment does not provide explicit guidance on what specific aspects of the methodology should be included or how the authors should address this issue. The action is implicit, as the authors can infer that they need to provide more details on the filtering process, but the lack of concrete instructions makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"details around the filtering process used to create the Arabic climate change QA dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what information is lacking, namely \"more information on the translation and filtering methodology,\" which is crucial for assessing the dataset quality. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a lack of detail regarding the filtering process used to create the Arabic climate change QA dataset, suggesting that more information on the translation and filtering methodology is needed to assess the dataset quality. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the dataset quality is lacking. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some indication of a problem but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors could improve their paper by providing more details about the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that requires further elaboration. However, the comment could be more helpful if it suggested specific ways to improve the dataset or provided examples of how to enhance the methodology. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the Related Work section lacks details and should provide a more comprehensive overview of existing methods and their limitations, particularly in the context of long-context language models. It mentions specific areas, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods, and provides references to support these suggestions. The comment is clear and specific, offering concrete guidance on what needs to be included in the Related Work section. This allows the authors to directly address the feedback and improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Related Work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed suggestions for improving the section by discussing specific methods and their limitations, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This level of detail helps the authors understand exactly what needs to be added or improved in the Related Work section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Related Work section lacks details and should provide a more comprehensive overview of existing methods and their limitations, particularly in the context of long-context language models. It suggests including specific methods such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods, and provides references to support these suggestions. The claim is well-supported by specific examples and references, making it fully verifiable. Therefore, the comment is rated as 5.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback on the Related Work section. It identifies a significant gap in the current draft by noting the lack of detail and comprehensiveness in the section. The comment suggests including specific methods and their limitations, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods, which are crucial for positioning the study effectively. By offering concrete suggestions and references, the comment guides the authors in enhancing the Related Work section, making it more informative and impactful. This level of detail and guidance is highly beneficial for improving the draft, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing needs improvement and that some points in the paper are unclear. However, it does not provide specific guidance on what aspects of the writing are unclear or how the authors should improve them. The comment lacks explicit actions or concrete suggestions, making it difficult for the authors to know what to address. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the writing needs improvement and that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or provide any guidance on how to address these issues. The authors cannot confidently determine which sections or aspects require revision, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what aspects of the writing are unclear or how the authors should improve them. Therefore, this comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the writing should be improved and that some points in the paper are unclear. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or justification, the authors may find it challenging to understand the basis of the feedback and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the writing needs improvement and that some points in the paper are unclear. However, it lacks specific details or actionable feedback on what aspects of the writing are unclear or how the authors can improve them. The comment is vague and does not provide guidance on addressing the identified issues, making it barely helpful. The authors are left without a clear understanding of how to enhance the clarity and coherence of their paper.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the synthetic experiment in a non-separable case, suggesting that the data distribution in Figure 1 might be inseparable from the network model. However, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take to clarify or improve the experiment. The comment implies that the authors should consider the nonlinear expression ability of neural networks and how it relates to the data distribution, but it lacks concrete steps or suggestions for implementation. Therefore, the comment is not actionable, as it does not provide clear guidance on how the authors can address the issue or improve their draft.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the synthetic experiment in a non-separable case, specifically questioning the inseparability of the data distribution illustrated in Figure 1 from the network model. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or figure being addressed. While the comment is specific about the issue, the lack of grounding makes it challenging for the authors to understand where to focus their attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the synthetic experiment in a non-separable case, specifically questioning the inseparability of the data distribution illustrated in Figure 1 from the network model. The comment does not provide any evidence, reasoning, or references to support the claim that the data distribution is inseparable from the network model. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the synthetic experiment in a non-separable case, specifically questioning the inseparability of the data distribution illustrated in Figure 1 from the network model. However, the comment lacks depth and actionable suggestions, as it does not provide guidance on how to address this concern or what specific improvements could be made to the experiment. Without further elaboration or suggestions, the authors may find it challenging to understand the implications of the comment or how to respond effectively. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the efficiency of pairwise matching, noting that it is very low and difficult to be used in practical application systems. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might improve the efficiency of their method or what changes could be made to enhance its practical applicability. As a result, the authors are left without a clear understanding of how to respond to this feedback, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the efficiency of pairwise matching, noting that it is very low and difficult to be used in practical application systems. However, it does not specify which part of the paper this issue is discussed or how it relates to the overall content. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in identifying the problem with the efficiency of pairwise matching, but it lacks guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the efficiency of pairwise matching is very low, making it difficult to be used in practical application systems. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this critique and how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the efficiency of pairwise matching, noting that it is very low and may limit its practical application. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the efficiency of their method. Without actionable advice or examples, the authors may find it challenging to understand how to respond to this feedback effectively. Therefore, the comment is barely helpful, as it points out a problem but does not provide sufficient direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. While the comment acknowledges the potential benefit of the approach, it does not provide explicit guidance on how to implement this idea or what specific aspects of the method should be emphasized to make it a significant contribution. The action is implicit, as the authors need to infer that they should consider adding such a method and how to make it impactful. However, the comment lacks concrete details on how to achieve this, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its critique of the approach, but without clear references to the paper, the authors may find it challenging to understand which sections need attention. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or evidence to substantiate the assertion that this approach is not a significant contribution. As a result, the claim is considered unverifiable due to the absence of supporting evidence or justification. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a critique of a potential method for improving transferability, suggesting that adding a method on top of other methods is a good idea but not a significant contribution. While the comment offers a specific observation about the potential impact of the method, it lacks detailed guidance or suggestions on how to make the approach more impactful or significant. The feedback is somewhat helpful as it highlights a potential area for improvement, but it does not provide actionable advice or detailed insights to help the authors enhance their work. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests toning down the statement about the neural network memorizing \"critical points\" and provides feedback on the method section being wordy and containing grammatical errors. While the comment offers specific suggestions for improvement, it does not explicitly instruct the authors on how to tone down the statement or compress the method section. The feedback on grammatical errors is vague and lacks concrete guidance on how to address them. Therefore, the comment is somewhat actionable, as it provides some direction but lacks detailed instructions for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific part of the paper by referencing \"34\" and \"TopoNet [24]\", indicating that the authors can accurately identify the section being discussed. It also provides feedback on the method section being wordy and suggests compressing it, which is specific to the method section. Additionally, the comment points out the presence of grammatical errors, particularly concerning plurals and articles, which is a specific issue within the method section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point contains a claim that the authors should tone down the statement about the neural network memorizing \"critical points,\" suggesting that this is not accurate in the context of TopoNet [24]. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The feedback on the method section being wordy and containing grammatical errors is somewhat verifiable, as it points out areas for improvement but does not provide detailed reasoning or examples. Therefore, the comment is rated as 2: Borderline Verifiable, as it provides some basis for improvement but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment provides specific feedback on a particular statement in the paper, suggesting that it should be toned down. It also offers feedback on the method section, noting that it is wordy and contains grammatical errors. While the comment identifies areas for improvement, it lacks detailed guidance on how to tone down the statement or address the grammatical errors. The feedback is somewhat helpful as it directs the authors to specific areas that need attention, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the comparison with Megatron, suggesting it is overrated and that the performance of Megatron and COCO-LM is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. The comment also questions the authors' claim about COCO-LM being parameter-efficient, noting that the conclusion would be applicable to the related works. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve their draft. The feedback is somewhat vague and lacks detailed instructions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the comparison with Megatron, suggesting it is overrated and that the performance of Megatron and COCO-LM is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the authors' claim about COCO-LM being parameter-efficient, noting that the conclusion would be applicable to related works. However, the comment does not specify which part of the paper this critique is related to, such as the experimental setup or results section. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its critique of the comparison, the absence of explicit grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the comparison with Megatron, suggesting it is overrated and that the performance of Megatron and COCO-LM is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. The comment questions the authors' claim about COCO-LM being parameter-efficient, noting that the conclusion would be applicable to related works. However, the comment lacks specific examples or detailed reasoning to support its claims, making it difficult for the authors to understand and address the critique effectively. The feedback is somewhat verifiable as it provides a general critique but lacks detailed evidence or references to support the claims. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the comparison with Megatron, suggesting it is overrated and that the performance of Megatron and COCO-LM is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the authors' claim about COCO-LM being parameter-efficient, noting that the conclusion would be applicable to related works. However, the comment does not provide specific suggestions or actionable feedback on how the authors might address these issues or improve their draft. While it identifies areas for improvement, it lacks depth and detail, making it somewhat helpful. The authors would need to infer what changes to make based on the critique, which limits the comment's usefulness. Therefore, it aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the analysis presented in lines 128 to 149, noting that it is not convincing enough. It highlights a specific observation from a histogram in Figure 3, where the GS-P-50 model is claimed to have smaller class selectivity scores, suggesting that it shares more features with ResNet-50, which learns more class-specific features. The authors hypothesize that additional context may allow the network to reduce its dependency. However, the comment does not provide explicit guidance on how to improve the analysis or address the concerns raised. While it identifies a potential issue with the analysis, it lacks actionable steps for the authors to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the analysis presented in lines 128 to 149, specifically referencing a histogram in Figure 3. It provides a detailed explanation of the observation, noting that the GS-P-50 model has smaller class selectivity scores, which implies it shares more features with ResNet-50, while ResNet-50 learns more class-specific features. The authors hypothesize that additional context may allow the network to reduce its dependency. The comment is fully grounded as it explicitly mentions the specific lines and figure where the analysis is discussed. It is also specific because it provides a detailed explanation of the observation and the reasoning behind the critique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the analysis presented in lines 128 to 149, specifically referencing a histogram in Figure 3. It claims that the GS-P-50 model has smaller class selectivity scores, suggesting it shares more features with ResNet-50, which learns more class-specific features. The authors hypothesize that additional context may allow the network to reduce its dependency. However, the comment does not provide any specific reasoning or evidence to support the claim that this observation indicates GS-P-50 learns better representations. It lacks detailed explanations or references to substantiate the critique, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the analysis presented in lines 128 to 149, specifically referencing a histogram in Figure 3. It highlights a potential issue with the analysis, noting that the GS-P-50 model has smaller class selectivity scores, which suggests it shares more features with ResNet-50, while ResNet-50 learns more class-specific features. The authors hypothesize that additional context may allow the network to reduce its dependency. However, the comment does not provide specific guidance or suggestions on how to address these concerns or improve the analysis. While it identifies a potential weakness in the analysis, it lacks actionable feedback that would help the authors enhance their work. Therefore, the comment is barely helpful, as it offers limited insight and guidance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the paper for some conclusions that are not convincing, specifically mentioning the claim that \"continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality.\" The authors are encouraged to explore the impact of different combination methods, particularly in rehearsal-free continual learning, where feature-replay methods have shown promise. The review suggests considering more recent works, such as [R3], which employ feature replay to continually adjust the feature space. However, the comment does not provide explicit guidance on how to address these issues or what specific actions the authors should take to improve their draft. The feedback is somewhat vague and lacks detailed instructions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the issue of conclusions not being convincing is discussed, allowing the authors to accurately identify the section being addressed. It also specifies what needs to be addressed by suggesting that the authors explore the impact of different combination methods, particularly in rehearsal-free continual learning, and consider more recent works like [R3]. This provides clear guidance on how to improve the paper, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the paper for some conclusions that are not convincing, specifically mentioning the claim that \"continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality.\" The authors are encouraged to explore the impact of different combination methods, particularly in rehearsal-free continual learning, where feature-replay methods have shown promise. The review suggests considering more recent works, such as [R3], which employ feature replay to continually adjust the feature space. However, the comment lacks specific examples or detailed reasoning to fully support the claim, making it somewhat verifiable. The authors would benefit from a more detailed explanation of how the suggested methods could address the issue of noise accumulation, enhancing the verifiability of the feedback.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern in the paper, noting that some conclusions are not convincing. It provides a detailed critique of the claim that \"continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality,\" suggesting that the results might stem from limited exploration of combination methods. The comment offers suggestions for improvement, such as considering rehearsal-free continual learning and feature-replay methods, particularly referencing recent works like [R3] that employ feature replay to continually adjust the feature space. This feedback is mostly helpful as it provides clear directions for the authors to enhance the depth and robustness of their analysis, but it could be more comprehensive with additional guidance on how to implement these suggestions. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific changes might be necessary. Without further clarification or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some observations and design decisions might be hardware and software dependent. However, it does not specify which part of the paper these observations and decisions are discussed in, nor does it provide any specific examples or guidance on how to address this issue. The lack of grounding makes it difficult for the authors to understand which sections need revision, and the comment lacks specificity in detailing what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this observation or how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that some observations and design decisions might be hardware and software dependent, which is a valid concern. However, the comment lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address this issue. Without further elaboration or examples, the authors may struggle to understand the implications of this observation or how to incorporate it into their work. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer detailed guidance or actionable advice.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the limited novelty of the paper, suggesting that it primarily applies existing literature, specifically DeCorr, to a specific application domain. It mentions that the contribution is mainly the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. However, the comment does not provide explicit or implicit actions for the authors to take to address this issue. It lacks concrete guidance on how to enhance the novelty or provide deeper insights into the unique challenges of overcorrelation in recommender systems. As a result, the authors are left without clear directions on how to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"DeCorr\" and \"graph collaborative filtering,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of limited novelty and the lack of unique insights into overcorrelation in recommender systems, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks novelty, as it primarily applies existing literature, specifically DeCorr, to a specific application domain. It suggests that the contribution is mainly the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence weakens the verifiability of the claim, aligning with a score of 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper's novelty, suggesting that it primarily applies existing literature, specifically DeCorr, to a specific application domain. The authors are informed that the contribution is mainly the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. However, the comment highlights that the paper lacks deeper insights into the unique challenges of overcorrelation in recommender systems. This feedback is somewhat helpful as it points out a critical area for improvement, but it could be more actionable with additional suggestions or guidance on how to enhance the novelty and provide unique insights. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific issues regarding the clarity of the description in Section 4.2 and the equation presented. It points out that the description does not align with the equation, particularly noting the absence of a term for r^q, which is the question representation. The reviewer also questions the meaning of \\sigma in the equation, suggesting it might be a sigmoid activation. The comment implies that these issues need to be clarified to improve the understanding of how the question is used to learn an attention on the image feature. While the action is implicit, the authors can infer that they need to clarify the description and the equation to address the concerns. However, the comment lacks concrete guidance on how to implement these clarifications, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the description and the equation in Section 4.2, particularly the absence of a term for r^q and the unclear meaning of \\sigma. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises specific questions about the clarity of the description in Section 4.2 and the equation presented. It points out that the description does not align with the equation, particularly noting the absence of a term for r^q, which is the question representation. The reviewer also questions the meaning of \\sigma in the equation, suggesting it might be a sigmoid activation. The comment implies that these issues need clarification to improve the understanding of how the question is used to learn an attention on the image feature. However, the comment lacks detailed reasoning or references to support these claims, making it somewhat verifiable. The authors would need to infer the need for clarification but would not have a clear path to address the issues without further guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies specific areas of confusion in the paper, particularly in Section 4.2. It points out that the description of how the question is used to learn an attention on image features does not align with the equation presented, specifically noting the absence of a term for r^q, which is the question representation. The reviewer also questions the meaning of \\sigma in the equation, suggesting it might be a sigmoid activation, and highlights potential issues with multiplying two sigmoid activations. This feedback is clear and actionable, providing the authors with specific areas to clarify and improve their draft. By addressing these points, the authors can enhance the clarity and accuracy of their work, making the comment highly valuable for their revision process. Therefore, the comment is rated as 5: Highly Helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the novelty of the paper is limited, noting that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into D and Phi_v. However, the comment does not provide explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to enhance the novelty of the paper or what specific aspects need to be improved. Without concrete suggestions or actionable steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the methodology aspect of the paper, specifically mentioning the ENCODE part and the decomposition part. It provides a detailed explanation of the novelty of the paper, noting that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. This provides clear grounding as the authors can accurately identify the section of the paper being discussed. Additionally, the comment specifies what needs to be addressed, highlighting the limited novelty and suggesting that the authors should enhance the novelty of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. While the comment provides a specific claim about the novelty of the paper, it lacks detailed reasoning or references to support the assertion that the ENCODE part is already proposed in [10]. Without further elaboration or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the novelty of the paper, specifically pointing out that the ENCODE part is already proposed in [10]. It also highlights that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. While the comment provides a clear observation about the novelty of the paper, it lacks actionable suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without specific advice or suggestions, the authors are left with limited insight on how to improve their draft. Therefore, the comment is somewhat helpful, as it identifies a weakness but does not provide sufficient guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the formatting of the paper, noting that equations are crammed together and captions are too close to the figures. It also mentions that this formatting issue effectively violates the 9-page paper limit, which is a significant concern. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to improve the formatting. While the authors can infer that they need to adjust the spacing to adhere to the paper limit, the lack of concrete instructions or examples makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W1,\" indicating a specific part of the paper being addressed. It also specifies the issue by detailing the formatting problems with equations and captions, which are common elements in academic papers. The comment clearly identifies the need for improvement in terms of formatting to adhere to the 9-page paper limit. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have reduced whitespace, causing equations and captions to be crammed together, which effectively violates the 9-page paper limit. This claim is somewhat verifiable as it highlights a specific formatting issue that could impact the paper's length. However, it lacks detailed examples or references to support the claim fully, making it somewhat verifiable. Therefore, the comment aligns with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the formatting of the paper, noting that equations and captions are crammed together, which effectively violates the 9-page paper limit. This is a clear and actionable feedback that highlights a significant concern regarding the paper's length. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as specific formatting adjustments or alternative layouts. While it points out a critical problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the technical details and formulations are limited, suggesting that the novelty of the scheme or procedure is not fully reflected. However, it does not provide explicit guidance on what specific aspects need to be expanded or how the authors should address this issue. The comment lacks concrete suggestions or actionable steps for the authors to take, making it difficult for them to understand how to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the exact section or aspect that needs improvement. It is also not specific because it does not detail what aspects of the technical details and formulations are limited or how the novelty of the scheme or procedure is reflected. Without specific guidance or examples, the authors cannot effectively address the feedback. Therefore, this comment is rated as Not Grounded and Not Specific, corresponding to a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical details and formulations are limited, suggesting that the novelty of the scheme or procedure is not fully reflected. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. Without detailed reasoning or evidence, the claim remains unverifiable, as the authors cannot confidently assess the validity of the feedback. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper, specifically noting that the technical details and formulations are limited and that the novelty of the scheme or procedure is not fully reflected. While the comment points out an area for improvement, it lacks specific guidance or suggestions on how the authors might address these issues. Without actionable advice or examples, the authors may struggle to understand how to enhance the depth and novelty of their work. Therefore, the comment is somewhat helpful, as it highlights a critical area for improvement but does not provide sufficient direction for the authors to make meaningful changes.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant risk of methods exploiting relationships between action units, noting that these relationships can vary across datasets. It provides a specific example, mentioning that AU6 can occur in both expressions of pain and happiness, and that this co-occurrence differs in datasets like SEMAINE and UNBC pain dataset. The comment suggests that cross-dataset experiments would be a good way to test the generalization of such work, noting that the paper lacks these experiments. The comment is explicit in identifying the issue and provides a clear action for the authors to take, which is to conduct cross-dataset experiments. This makes the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"action units\" and \"datasets,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by highlighting the differences in co-occurrences of action units across datasets, such as SEMAINE and UNBC pain dataset. The comment suggests a good way to test the generalization of the work by performing cross-dataset experiments, which is a clear and specific action for the authors to take. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that methods exploiting relationships between action units can lead to different co-occurrences across datasets, as illustrated by the example of AU6 occurring in both pain and happiness expressions. It suggests that cross-dataset experiments would be a good way to test the generalization of such work, noting that the paper lacks these experiments. The claim is supported by a logical reasoning that highlights the potential differences in co-occurrences across datasets, and the suggestion to perform cross-dataset experiments is clear and actionable. However, the comment could be more robust if it provided specific examples or references to support the claim about the differences in co-occurrences. Overall, the comment is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant risk associated with methods that exploit relationships between action units, specifically highlighting the variability of these relationships across different datasets. It provides a clear example, noting that AU6 can occur in both expressions of pain and happiness, and that this co-occurrence differs significantly between datasets like SEMAINE and UNBC pain dataset. The comment suggests that cross-dataset experiments would be a good way to test the generalization of such work, which is a valuable and actionable suggestion for the authors. By pointing out this issue and offering a specific direction for improvement, the comment is mostly helpful, as it provides clear guidance on how the authors can enhance their work. However, it could be more comprehensive if it included additional suggestions or considerations for addressing the identified risk.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the statement about over-parametrization leading to overfitting and worse performance, suggesting that over-parametrization can be beneficial in practice. It also mentions theoretical work supporting the benefits of over-parametrization. However, the comment does not provide explicit or implicit actions for the authors to take. It lacks guidance on how to address the critique or incorporate the suggested benefits into their work. As a result, the authors are left without clear directions on how to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines of the paper (line 47-48), allowing the authors to accurately identify the part being addressed. It also provides specific feedback by questioning the statement about over-parametrization and suggesting that it might be beneficial in practice, referencing theoretical work. This feedback is clear and specific, guiding the authors on how to address the critique and incorporate additional insights. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the statement about over-parametrization leading to overfitting and worse performance, suggesting that over-parametrization can be beneficial in practice. It references theoretical work supporting this benefit, providing a basis for the critique. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. The authors would benefit from a more detailed explanation or additional evidence to fully understand the critique and address it effectively.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques a statement about over-parametrization, suggesting that it is not always detrimental and can be beneficial in practice. It references theoretical work that supports the benefits of over-parametrization, providing a counterpoint to the initial statement. However, the comment lacks specific guidance on how the authors might address this critique or incorporate the benefits of over-parametrization into their work. While it offers a valuable perspective, the feedback could be more helpful if it included actionable suggestions or examples of how to improve the draft based on the critique. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the fairness of the experimental comparison, suggesting that the proposed method was pre-trained before fine-tuning, while the compared methods might not have been initialized with the same or similar pre-trained models. It also points out that the proposed method without SSL performs worse than most compared methods, as shown in Table 1. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the experimental setup. The action is implicit and somewhat vague, as the authors are left to infer that they need to ensure fair initialization of the compared methods or provide a more detailed explanation of the experimental setup. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental comparison with other methods, suggesting that the proposed method was pre-trained before fine-tuning, which may make the comparison unfair. It also mentions that the compared methods might not have been initialized with the same or similar pre-trained models, and that the proposed method without SSL performs worse than most compared methods, as shown in Table 1. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the experimental setup and the performance of the proposed method without SSL. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental comparison with other methods is unfair due to the proposed method being pre-trained before fine-tuning, while the compared methods might not have been initialized with the same or similar pre-trained models. The comment provides a logical reasoning by suggesting that this discrepancy could affect the fairness of the comparison. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the basis for the claim, which limits its verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the experimental comparison, noting that the proposed method was pre-trained before fine-tuning, while the compared methods might not have been initialized with the same or similar pre-trained models. This observation is supported by the mention of Table 1, which shows that the proposed method without SSL performs worse than most compared methods. However, the comment does not provide specific guidance on how the authors should address this issue or what steps they should take to ensure a fair comparison. While it highlights a critical aspect of the experimental setup, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should consider using better meta-data embeddings for their zero-shot learning results on the CUB dataset. It provides a specific reference to a related work, \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016,\" which suggests that better meta-data embeddings are available. The comment also indicates that the authors should update their paper with this suggestion. This feedback is explicit and provides a clear action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the results of zero-shot learning on CUB dataset\" and \"Table 3 page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests considering better meta-data embeddings and provides a reference to a related work, \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016,\" which helps the authors understand the suggestion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the meta-data used in the zero-shot learning results on the CUB dataset are \"attribute,\" which is good for fair comparison. However, it suggests that better meta-data embeddings options are available and recommends exploring their performance. The comment provides a reference to a related work, \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016,\" which supports the suggestion. This provides a logical reasoning and reference to back the claim, making it mostly verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific feedback on the results of zero-shot learning on the CUB dataset, noting that the meta-data used is \"attribute,\" which is good for fair comparison. However, it suggests that better meta-data embeddings options are available and recommends exploring their performance. The comment also references a related work, \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016,\" which provides context for the suggestion. This feedback is mostly helpful as it offers actionable insights and a reference for further exploration, guiding the authors to improve their work. However, it could be more comprehensive if it included a detailed discussion of the specific meta-data embeddings options or a more in-depth analysis of the potential performance improvements. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper lacks relevant literature on using moment matching for distributional reinforcement learning (DRL), specifically mentioning the work by Nguyen-Tang et al. (AAAI\u201921). It implies that this discussion should be included when talking about various approaches to DRL, even though the paper currently uses quantile regression. However, the comment does not provide explicit guidance on how the authors should incorporate this information into their draft or suggest specific sections to address. The action is implicit and somewhat vague, as the authors need to infer that they should discuss moment matching and its relevance to DRL. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific part of the paper, lines 22-30, where the discussion of distributional RL occurs. This allows the authors to accurately identify the section being addressed. The comment is also specific because it clearly specifies the issue: the paper lacks relevant literature on using moment matching for DRL, suggesting that this should be discussed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks relevant literature on using moment matching for distributional reinforcement learning (DRL), specifically mentioning the work by Nguyen-Tang et al. (AAAI\u201921). The comment suggests that this discussion should be included when talking about various approaches to DRL, even though the paper currently uses quantile regression. However, the comment does not provide specific examples or detailed reasoning to support why moment matching is relevant or how it should be discussed. It lacks references or detailed explanations, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area in the paper where additional literature could be discussed, particularly regarding the use of moment matching in distributional reinforcement learning. It provides a specific example of relevant work, referencing Nguyen-Tang et al. (AAAI\u201921), which could enhance the paper's discussion of various approaches to DRL. However, the comment could be more helpful by suggesting how this additional discussion might impact the paper's overall argument or findings. While it offers a clear direction for improvement, it lacks depth and could be expanded to provide more actionable guidance. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the novelty of the paper is limited because interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment does not provide any specific suggestions or actions for the authors to take to address this issue. It lacks concrete guidance on how to enhance the novelty of their work or what specific aspects of their approach could be improved to differentiate it from existing methods. As a result, the authors are left without a clear understanding of how to respond to this critique and improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the novelty of the paper is limited because interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, it does not specify which part of the paper this issue is related to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to understand where the comment is relevant and how to address it. Additionally, the comment is specific in its critique of the novelty, but without grounding, it is challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited because interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the novelty of the paper, suggesting that interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. This feedback highlights a specific area where the authors might need to strengthen their claims or provide additional context to differentiate their work from existing methods. However, the comment lacks specific suggestions or guidance on how the authors could address this issue or enhance the novelty of their approach. Without actionable advice or examples, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not provide detailed guidance for the authors.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the novelty of using PCA to reduce the interaction count and suggests that the significance of the paper's results is unclear. It also provides a rationale for why PCA is intuitive and requests clarification on whether the assumptions are met, referencing a specific paper. While the comment identifies a potential issue with the novelty and significance of the paper, it does not explicitly instruct the authors to address these concerns or provide specific guidance on how to improve the paper. The action is implicit, as the authors need to infer that they should discuss the novelty and significance of their approach and address the assumptions of PCA. However, the comment lacks concrete details on how to do so, making it somewhat actionable. Therefore, the comment is rated as 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of using PCA to reduce the interaction count and questions its significance, suggesting that it is incremental. It also requests clarification on whether the assumptions of PCA are met, referencing a specific paper. However, the comment does not specify which part of the paper discusses the use of PCA or the results that are unclear. This makes it weakly grounded, as the authors cannot confidently determine which section or part of the paper is being addressed. The comment is specific in its critique of the novelty and significance of the approach, but without explicit grounding, it is challenging for the authors to focus their responses. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the novelty of using PCA to reduce the interaction count and the clarity of the paper's results. It suggests that the approach is intuitive and requests clarification on whether the assumptions of PCA are met, referencing a specific paper. However, the comment does not provide detailed reasoning or examples to support the claim that the novelty is incremental or that the significance of the results is unclear. While the reference to the paper provides some context, the lack of detailed explanation or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the novelty of using PCA to reduce the interaction count and suggests that the significance of the paper's results is unclear. It provides a rationale for why PCA might be intuitive and requests clarification on whether the assumptions of PCA are met, referencing a specific paper. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper's novelty and significance. However, it lacks detailed guidance on how the authors might address these concerns or what specific aspects of their approach need to be clarified. The comment could be more helpful if it provided more detailed suggestions or examples of how to improve the paper's novelty and significance. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the evaluative framework is somewhat limited in scope, as it only considers three question-answering tasks and two language models. The comment expresses reservations about the method's broader applicability, particularly regarding its potential to generalize to other reasoning or generation tasks or more advanced models like vicunna or alpaca. However, the comment does not provide explicit guidance on how the authors might address these limitations or expand the framework. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps to improve the framework. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the evaluative framework's limited scope, specifically mentioning that it considers only three question-answering tasks and two language models. This provides some grounding as the authors can infer the specific part of the paper being discussed. However, the comment does not specify what aspects of the framework need to be expanded or how the authors might address the concerns about broader applicability. The lack of specificity regarding the tasks or models being considered makes it difficult for the authors to fully understand the implications of the comment. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the evaluative framework is somewhat limited in scope, as it only considers three question-answering tasks and two language models. This claim is somewhat verifiable because it provides a specific example of the limited scope, but it lacks detailed reasoning or references to support the claim fully. The authors could benefit from additional context or examples to better understand the limitations and how they might be addressed. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the scope of the evaluative framework, noting that it is restricted to only three question-answering tasks and two language models. This observation raises concerns about the method's broader applicability and suggests that it may not be generalizable to other reasoning or generation tasks or more advanced models like vicunna or alpaca. While the comment highlights a potential area for improvement, it does not provide specific guidance or suggestions on how the authors might address these limitations or expand the framework. The feedback is somewhat helpful as it points out a critical area for consideration, but it lacks actionable advice, making it only marginally helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Figure 6C is awkward and implies negative rates, which is not the case. It recommends using a second y-axis or another visualization that is more physically accurate. While the comment provides a clear suggestion for improvement, it does not explicitly instruct the authors to make these changes. The action is implicit, as the authors can infer that they need to revise the figure to address the issue. However, the comment lacks concrete details on how to implement this suggestion, such as specific examples of how to use a second y-axis or another visualization. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely that it implies negative rates, which is not physically accurate. The suggestion to use a second y-axis or another visualization is a concrete and actionable step for the authors to take. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 6C is awkward and implies negative rates, which is not physically accurate. The reviewer suggests using a second y-axis or another visualization for better clarity. However, the comment lacks specific examples or references to support the claim about the figure's accuracy. Without detailed evidence or examples, the claim is somewhat verifiable, as it provides a general suggestion but lacks the necessary depth to fully substantiate the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates, which is not physically accurate. The reviewer suggests using a second y-axis or another visualization to improve the clarity and accuracy of the figure. This feedback is actionable and provides a clear direction for the authors to improve the presentation of their data. However, the comment could be more helpful if it included specific examples of how to implement the suggested changes or if it offered additional guidance on selecting appropriate visualizations. Overall, the comment is mostly helpful as it highlights a critical issue and offers a constructive suggestion for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that there is room to improve the complexity of Algorithm 2, but it does not provide any specific guidance or suggestions on how to achieve this improvement. The comment lacks concrete details or actionable steps for the authors to take. As a result, the authors are left without a clear understanding of what aspects of the algorithm need to be addressed to enhance its complexity. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that there is room to improve the complexity of Algorithm 2, but it does not specify which part of the paper Algorithm 2 is located in or provide any details on what aspects of the algorithm could be improved. This makes it difficult for the authors to understand the exact area that needs attention. The comment is not grounded as it does not provide specific references or sections, and it is also not specific because it lacks details on how to improve the algorithm. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that there is room to improve the complexity of Algorithm 2. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that there is room to improve the complexity of Algorithm 2, but it does not provide specific suggestions or guidance on how to achieve this improvement. While it identifies a potential area for enhancement, the lack of actionable advice leaves the authors without a clear path forward. The comment is somewhat helpful as it highlights a specific area for improvement, but it lacks depth and detail, making it incomplete. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the claim made in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LMs) compared to GAN models to avoid overfitting. It provides a counter-argument based on the reviewer's experience with high-dimensional LSTMs and suggests that the baseline models might not be properly regularized. The comment implies that the authors should investigate the regularization techniques used in their models, specifically questioning whether dropout is applied to the hidden states as well. However, the comment does not explicitly instruct the authors to conduct this investigation or provide detailed guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should explore the regularization techniques and potentially adjust their models accordingly. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"supplemental section D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by questioning the claim about smaller architectures and suggesting that the baseline models might not be properly regularized. The comment provides a clear and specific request for clarification and further investigation, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement in supplemental section D.4 is questionable, suggesting that smaller architectures are not necessary for language models compared to GAN models to avoid overfitting. It provides a counter-argument based on the reviewer's experience with high-dimensional LSTMs, citing Zaremba et al. 2014 as evidence. The comment also questions whether dropout is applied to the hidden states, which is a specific and actionable suggestion for the authors to investigate. However, the reasoning could be more detailed, and the claim is somewhat verifiable as it relies on a specific counter-example and a request for clarification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue in the supplemental section D.4, questioning the claim that smaller architectures are necessary for language models (LMs) compared to GAN models to avoid overfitting. It provides a counter-argument based on the reviewer's experience with high-dimensional LSTMs, suggesting that the baseline models might not be properly regularized. The comment also raises a specific question about whether dropout is applied to the hidden states, which is a relevant point for the authors to consider. While the comment is clear and identifies a potential issue, it could be more helpful if it provided more detailed guidance on how to address the concern or suggested specific experiments to validate the claim. Overall, the feedback is somewhat helpful as it highlights an area for improvement and encourages further investigation, but it lacks depth and actionable suggestions for the authors to fully address the issue.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and that the inclusion of empirical results would be beneficial. However, it does not provide specific guidance on how to achieve this conciseness or what aspects of the introduction should be streamlined. The comment lacks concrete instructions on how to revise the introduction or what specific sections or phrases need to be removed or rephrased. While it identifies the need for conciseness and the inclusion of empirical results, it does not offer actionable steps for the authors to take. Therefore, the comment is somewhat actionable, as it provides a general direction but lacks detailed guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the main part of the paper, especially the introduction, could be more concise and that including empirical results would be beneficial. However, it does not specify which part of the paper is being addressed, making it difficult for the authors to pinpoint the exact sections that need revision. The comment lacks specificity in terms of what aspects of the introduction should be made more concise or what kind of empirical results would be most beneficial. Without this detailed information, the authors may struggle to understand how to improve their draft. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the main part of the paper, particularly the introduction, could be more concise and that including empirical results would be beneficial. However, the comment lacks specific details or examples to support these claims. It does not provide any reasoning or references to substantiate why the introduction should be more concise or why empirical results are necessary. Without this additional information, the authors may find it challenging to understand the basis of the feedback and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and that including empirical results would be beneficial. However, the comment lacks specific guidance on how to achieve these improvements or what aspects of the introduction should be streamlined. It does not provide detailed suggestions or examples of how to make the introduction more concise or how to incorporate empirical results effectively. While the feedback identifies areas for improvement, it does not offer actionable steps or detailed guidance, making it somewhat helpful. The authors may gain some insight but would need to infer additional details to fully address the comment. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the clarity of their technical contribution. The comment lacks explicit actions or concrete steps that the authors can take to enhance their draft. As a result, the authors are left without a clear understanding of what needs to be done to improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not specify which part of the paper is being addressed, making it difficult for the authors to pinpoint the exact issue. The comment lacks grounding as it does not provide specific references or sections of the paper that need attention. Additionally, it does not offer specific suggestions or guidance on how to improve the clarity of the technical contribution. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific evidence, examples, or references to support this claim. Without detailed reasoning or examples, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the technical contribution of the paper, suggesting that it is unclear and that most of the analysis is standard. However, the comment lacks specific details or actionable suggestions on how the authors might address this issue or improve the clarity of their technical contribution. Without concrete guidance or examples, the authors may find it challenging to understand the feedback and incorporate it into their work. Therefore, the comment is barely helpful, as it provides a general observation but lacks depth and actionable advice.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the regularization methods used for the LN model and the GLM, suggesting that the authors should try to reproduce the main features of previous models to ensure a fair comparison. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific steps the authors should take to reproduce the features of previous models. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the regularization methods used in the LN model and the GLM, specifically noting a discrepancy in the regularization techniques. It suggests that the authors should try to reproduce the main features of previous models to ensure a fair comparison. However, the comment does not specify which part of the paper discusses the regularization methods or the GLM, making it weakly grounded. The comment is specific in detailing the issue with the regularization methods, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a specific concern about the regularization methods used in the LN model and the GLM, suggesting that the authors should try to reproduce the main features of previous models to ensure a fair comparison. The comment provides a detailed explanation of the discrepancy in regularization techniques, referencing the work of Pillow et al. This level of detail and specific reference makes the claim fully verifiable, as it provides a clear rationale and evidence for the suggestion. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment identifies a specific issue with the regularization methods used in the LN model and the GLM, noting a discrepancy with the methods described in previous work. It suggests that the authors should try to reproduce the main features of previous models to ensure a fair comparison. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by aligning their methods with established practices. However, the comment could be more helpful if it offered additional guidance on how to reproduce the features of previous models or suggested specific steps to take. Overall, the comment is mostly helpful, as it provides a clear and actionable suggestion for improvement.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would be improved by including some failure cases and related discussion. While the comment implies that this addition would enhance the paper, it does not explicitly instruct the authors to include specific examples or details about these failure cases. The action is implicit, as the authors need to infer that they should add this information, but it lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper would be improved by including some failure cases and related discussion. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. The authors cannot confidently determine where to address this feedback, making the comment weakly grounded. Additionally, the comment is specific in its suggestion to include failure cases and related discussion, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would be improved by including some failure cases and related discussion. However, it does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why this suggestion is beneficial or how to incorporate it into their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper would be improved by including some failure cases and related discussion. While this feedback is relevant and could enhance the paper's comprehensiveness, it lacks specific guidance on how to identify or discuss these failure cases. The comment is somewhat helpful as it points out a potential area for improvement, but it does not provide detailed suggestions or examples, leaving the authors with limited actionable insights. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the variable \\\\(\\\\epsilon\\\\) should be introduced when discussing equation (11) instead of equation (10). This provides a clear and explicit action for the authors to take, as they can directly address the issue by introducing \\\\(\\\\epsilon\\\\) in the context of equation (11). The comment is specific and concrete, detailing exactly what needs to be done to improve the clarity of the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the variable \\\\(\\\\epsilon\\\\) is not used in equation (10) but is used in equation (11), and suggests that introducing \\\\(\\\\epsilon\\\\) when discussing equation (11) would improve clarity. This provides a clear and actionable direction for the authors to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the variable \\\\(\\\\epsilon\\\\) should be introduced when discussing equation (11) instead of equation (10). This claim is based on the observation that \\\\(\\\\epsilon\\\\) is not used in equation (10) but is used in equation (11). The suggestion is logical and provides a clear rationale for improving the clarity of the paper. However, the comment lacks specific examples or references to support the claim, which could make it slightly less verifiable. Therefore, the comment is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that the variable \\\\(\\\\epsilon\\\\) is not used in equation (10) but is used in equation (11). It suggests that introducing \\\\(\\\\(\\\\epsilon\\\\) when discussing equation (11) would improve the clarity of the paper. This feedback is clear and actionable, providing the authors with a specific direction to enhance the presentation of their work. By addressing this suggestion, the authors can improve the readability and coherence of their paper, making it more accessible to readers. Therefore, the comment is highly helpful, as it offers a clear and constructive improvement that the authors can easily implement.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses an opinion about the claim regarding evolutional dropout and internal covariate shift, suggesting that it is limited to increasing the variance of low-variance units. It also mentions that Batch Normalization standardizes variance and centers activation, implying that these limitations should be discussed explicitly. However, the comment does not provide explicit guidance on how to address these limitations or what specific aspects of the claim need to be discussed. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim regarding evolutional dropout and internal covariate shift, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the limitations of the claim, suggesting that Batch Normalization standardizes variance and centers activation, which should be discussed explicitly. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses an opinion about the claim regarding evolutional dropout and internal covariate shift, suggesting that it is limited to increasing the variance of low-variance units. It also mentions that Batch Normalization standardizes variance and centers activation, implying that these limitations should be discussed explicitly. However, the comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to fully understand and address the issue. The feedback is somewhat verifiable as it provides a general direction but lacks depth and specific guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding the claim about evolutional dropout and internal covariate shift, suggesting that it is limited to increasing the variance of low-variance units. It also points out that Batch Normalization standardizes variance and centers activation, implying that these limitations should be discussed explicitly. This feedback is clear and actionable, providing the authors with a specific area to address and improve their draft. However, it could be more helpful if it included suggestions on how to discuss these limitations or what specific aspects of the claim need to be elaborated upon. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should add more description about the contribution of the paper. However, it does not specify which part of the paper needs more description or what kind of description should be added. The action is implicit and vague, as it does not provide concrete guidance on how to enhance the description of the paper\\'s contribution. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the authors should add more description about the contribution of the paper. However, it does not specify which part of the paper this description should be added to or what aspects of the contribution need more detail. This lack of specificity makes it difficult for the authors to understand where and how to improve the paper. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should add more description about the contribution of the paper. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this suggestion is necessary or how to implement it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should add more description about the contribution of the paper. However, it lacks specificity and does not provide any guidance on what aspects of the contribution need more detail or how to enhance the description. Without additional context or suggestions, the authors may find it challenging to understand the need for more description or how to improve it. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the term \"X\" in section 4 should be a multiset instead of a set to accurately represent graphs with repeated vertex or edge labels. It provides a specific reason for this suggestion, indicating that the histogram should include the multiplicities of labels. However, the comment does not explicitly instruct the authors to make this change or provide guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should revise the definition of \"X\" and consider the implications for the histogram representation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear and detailed explanation of why the term \"X\" should be a multiset instead of a set, emphasizing the need to include multiplicities of labels for accurate histogram representation. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the term \"X\" in section 4 should be a multiset instead of a set to accurately represent graphs with repeated vertex or edge labels. The reviewer provides a specific reasoning, explaining that including the multiplicities of labels is necessary for the histogram to honestly represent such graphs. This reasoning is logical and well-supported, making the claim fully verifiable. The comment is clear and provides a detailed explanation of the issue, allowing the authors to understand and address it effectively. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue in section 4, suggesting that the term \"X\" should be a multiset instead of a set to accurately represent graphs with repeated vertex or edge labels. The reviewer provides a clear rationale for this suggestion, explaining that including the multiplicities of labels is necessary for the histogram to honestly represent such graphs. This feedback is actionable and provides a specific direction for improvement, helping the authors refine their work. However, the comment could be more helpful if it included additional guidance on how to implement this change or examples of how it would affect the results. Overall, the comment is mostly helpful, as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors\\' derivation, suggesting that it falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are included. However, the comment does not provide any explicit or implicit guidance on how the authors should address this issue or incorporate Bayesian considerations into their derivation. The authors are left without any actionable steps to take, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors\\' derivation, suggesting that it falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are included. However, the comment does not specify which part of the paper this critique refers to, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment does not provide specific guidance on how to address the issue or incorporate Bayesian considerations. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors\\' derivation falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are taken into account. The reviewer provides an example of Bayesian-PAC based bounds, suggesting that the authors should consider incorporating Bayesian considerations. However, the comment lacks detailed reasoning or specific references to support the claim that classical bounds are unrealistic without Bayesian considerations. The authors may find it challenging to fully understand and address the issue without additional context or evidence. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks depth and clarity.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors\\' derivation, suggesting that it falls into classical learning theory-based bounds, which may not yield realistic results without incorporating Bayesian considerations. This feedback is somewhat helpful as it points out a specific area that needs attention and suggests a potential improvement by considering Bayesian-PAC based bounds. However, the comment lacks detailed guidance on how the authors should address this issue or what specific steps they should take to incorporate Bayesian considerations into their derivation. While it provides a direction for improvement, the feedback could be more actionable with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of significance testing to support the claims made about the differences between various methods. It provides specific examples, such as the comparison between ChatGPT and GPT-4, and suggests that the authors should conduct significance testing to substantiate their claims. However, the comment does not provide explicit guidance on how to perform the significance testing or what specific statistical methods should be used. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines of the paper (line 486) and provides examples of claims made in the draft. It specifies what needs to be addressed by suggesting the inclusion of significance testing to support the claims about the differences between various methods. This provides clear guidance on how the authors can improve their draft, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should conduct significance testing to support their claims about the differences between various methods, such as ChatGPT and GPT-4. It provides specific examples, such as the scores mentioned in line 486, and suggests that the differences are minimal without proper testing. However, the comment lacks detailed reasoning or references to support the claim that the differences are indeed minimal or that significance testing is necessary. The authors are left to infer the need for such testing, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue in the paper by pointing out the lack of significance testing to support claims about the differences between various methods. It provides specific examples, such as the comparison between ChatGPT and GPT-4, and highlights the minimal differences in scores, suggesting that significance testing is necessary to substantiate these claims. This feedback is clear and actionable, as it directs the authors to conduct a more rigorous analysis to strengthen their claims. However, the comment could be more helpful if it provided guidance on the specific statistical methods or tests that should be used. Overall, the comment is mostly helpful, as it effectively guides the authors to improve the rigor of their analysis.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the claim that improvements are due to distillation rather than regularization effects. It suggests that the fine-tuning was performed for 10 epochs without early stopping, which could lead to high variances and the need for proper ablation studies. However, the comment does not explicitly instruct the authors to conduct these ablation studies or provide detailed guidance on how to address the issue. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim that improvements are due to distillation rather than regularization effects, specifically questioning the validity of this claim given the fine-tuning parameters. It mentions that all fine-tuning is performed for 10 epochs without early stopping, which is a specific detail that could lead to high variances. However, the comment does not explicitly mention which part of the paper this issue is discussed, making it weakly grounded. The comment is specific in detailing the concern about the regularization effects and the need for proper ablation studies, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvements in the paper could be due to regularization effects rather than distillation, as the fine-tuning was performed for 10 epochs without early stopping. The comment suggests that this is a potential issue and that proper ablation studies are needed to verify the findings. However, the claim lacks specific examples or references to support the assertion that regularization effects are a likely cause of the observed improvements. The reasoning is somewhat vague, as it does not provide detailed evidence or examples to substantiate the claim. Therefore, the comment is rated as 2: Borderline Verifiable, as it provides some basis for the claim but lacks sufficient detail or evidence to fully support it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the claim that improvements are due to distillation rather than regularization effects. It points out that the fine-tuning was performed for 10 epochs without early stopping, which could lead to high variances and the need for proper ablation studies. This feedback is somewhat helpful as it highlights a specific area that requires further investigation and provides a suggestion for improvement. However, the comment could be more helpful if it offered more detailed guidance on how to conduct these ablation studies or provided examples of how to address the issue. Overall, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses an opinion about the limited contribution and incremental nature of the proposed model. However, it does not provide any specific suggestions or actions for the authors to take to address this concern. The comment lacks explicit guidance on how the authors might enhance the contribution or make the model more significant. As a result, the authors are left without a clear path to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the limited contribution and incremental nature of the proposed model, but it does not specify which part of the paper this opinion pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide details on what aspects of the contribution or model are considered limited or incremental. Therefore, this comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses an opinion about the limited contribution and incremental nature of the proposed model. However, it lacks specific evidence or reasoning to support this claim. Without detailed examples or references to other works that might challenge the authors' assessment, the claim remains subjective and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses an opinion about the limited contribution and incremental nature of the proposed model. While it identifies a potential weakness in the paper, it does not provide specific suggestions or actionable feedback on how the authors might address this issue or enhance the contribution of their work. The comment lacks depth and guidance, making it somewhat helpful as it highlights an area for improvement but does not offer a comprehensive solution. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the supervised pretraining method based on the homo-lumo gap, suggesting that it might lead to negative transfer. It provides an example of this issue by mentioning the poor performance of Transformer-M on most tasks in the QM9 dataset, except for homo, lumo, and gap. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to mitigate it. While the authors can infer that they should consider alternative pretraining methods or discuss the implications of this finding, the action remains somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to supervised pretraining based on the homo-lumo gap, which is a particular aspect of the paper. It provides an example of how this pretraining method might lead to negative transfer, specifically mentioning the poor performance of Transformer-M on most tasks in the QM9 dataset, except for homo, lumo, and gap. This allows the authors to identify the specific part of the paper being addressed, making the comment fully grounded. The comment is also specific as it details the issue and provides an example, guiding the authors on how to address it. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that supervised pretraining based on the homo-lumo gap may lead to negative transfer, as evidenced by the poor performance of Transformer-M on most tasks in the QM9 dataset, except for homo, lumo, and gap. This claim is supported by specific examples and data, making it mostly verifiable. The reasoning is clear and logical, providing a basis for the authors to understand and address the issue. However, the comment could be strengthened by including more detailed references or explanations to further substantiate the claim. Overall, the comment is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the supervised pretraining method based on the homo-lumo gap, suggesting that it might lead to negative transfer. It provides an example of this issue by mentioning the poor performance of Transformer-M on most tasks in the QM9 dataset, except for homo, lumo, and gap. This feedback is somewhat helpful as it highlights a specific area that needs attention and provides a clear example of the problem. However, the comment could be more helpful if it offered suggestions or guidance on how the authors might address this issue or discuss the implications of this finding. Overall, the comment provides a valuable insight but lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific feedback on the experimental evaluation, particularly regarding the ablation study and the comparison on the CIFAR dataset. It highlights that the paper claims a distinction in the \"picking\" step but does not ablate it, which is a clear and explicit action for the authors to address. Additionally, it points out that the comparison on CIFAR is not convincing due to the limited number of approaches compared and the lack of clarity in the use of the DEN approach. The comment is fully actionable as it provides concrete guidance on what needs to be addressed, including the inclusion of an ablation study and a more comprehensive comparison with a similar setup as the DEN paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Experimental Evaluation\" and \"Experiments on CIFAR,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it details the issues with the ablation study, the limited comparison on CIFAR, and the lack of clarity in the use of the DEN approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks an ablation study for the \"picking\" step, which is a subjective observation. It also criticizes the comparison on the CIFAR dataset, stating that it is not convincing due to the limited number of approaches compared and the lack of clarity in the use of the DEN approach. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Therefore, the claim is somewhat verifiable, as it lacks sufficient evidence or justification to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the experimental evaluation section, particularly regarding the ablation study and the comparison on the CIFAR dataset. It highlights that the paper claims a distinction in the \"picking\" step but does not ablate it, which is a clear and actionable point for the authors to address. Additionally, it points out that the comparison on CIFAR is not convincing due to the limited number of approaches compared and the lack of clarity in the use of the DEN approach. The comment suggests that the authors should use the same setup as in the DEN paper to ensure a fair and correct comparison. This feedback is mostly helpful as it provides clear guidance on areas for improvement, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the trade-off between computational efficiency and information loss when using ancestral graphs compared to DAGs. It highlights that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in less information compared to the richer search space of DAGs. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft. The action is implicit, as the authors need to infer that they should consider the information loss and potentially discuss it further. The action is vague because it does not specify how to address the issue or what changes might be needed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the trade-off between computational efficiency and information loss when using ancestral graphs compared to DAGs, referencing a specific paper [10]. It highlights that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in less information compared to the richer search space of DAGs. However, the comment does not specify which part of the paper this issue is discussed or how it relates to the overall content. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. The comment is specific in detailing the trade-off and questioning the information loss, but without clear grounding, the authors may struggle to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method reduces computation time by reducing the search space to ancestral graphs, which results in less information compared to the richer search space of DAGs. The comment questions how much information of a DAG is encoded in its corresponding ancestral graph. However, the comment lacks specific examples or references to support the claim about the trade-off between computational efficiency and information loss. Without detailed reasoning or evidence, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail or support.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method, noting that while it achieves faster computation by reducing the search space to ancestral graphs, this comes at the cost of less information compared to the richer search space of DAGs. The comment questions how much information of a DAG is encoded in its corresponding ancestral graph, highlighting a trade-off that needs to be considered. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it raises a valid concern, the feedback lacks actionable advice, making it somewhat helpful. The authors would need to infer that they should consider the information loss and potentially discuss it further, but the comment does not offer concrete steps for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises doubts about the definitions in Table 1, specifically questioning the difference between \"anchor-based regression\" and \"regression in RepPoints\" in the context of RepPoints, RetinaNet, and ATSS. The reviewer suggests that the distinction between these methods is not clear and that the motivation for the work is weak. While the comment identifies a potential issue with the clarity of definitions, it does not provide explicit guidance on how the authors should address this concern or clarify the definitions. The action is implicit, as the authors need to infer that they should provide a clearer explanation of the definitions in the paper. However, the lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises doubts about the definitions in Table 1, specifically questioning the difference between \"anchor-based regression\" and \"regression in RepPoints\" in the context of RepPoints, RetinaNet, and ATSS. It suggests that the distinction between these methods is not clear and that the motivation for the work is weak. However, the comment does not specify which part of the paper contains these definitions or where the confusion arises. The authors cannot confidently determine which section or table is being addressed, making the comment weakly grounded. Additionally, while it highlights a potential issue with clarity, it does not provide specific guidance on how to address the lack of distinction or improve the motivation. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises doubts about the definitions in Table 1, specifically questioning the difference between \"anchor-based regression\" and \"regression in RepPoints\" in the context of RepPoints, RetinaNet, and ATSS. The reviewer suggests that the distinction between these methods is not clear and that the motivation for the work is weak. However, the comment lacks specific examples or detailed reasoning to support the claim that the definitions are unclear or that the motivation is weak. Without additional context or evidence, the authors may find it challenging to understand the basis of the reviewer's concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises concerns about the clarity of definitions in Table 1, specifically questioning the distinction between \"anchor-based regression\" and \"regression in RepPoints\" in the context of RepPoints, RetinaNet, and ATSS. The reviewer suggests that the distinction between these methods is not clear and that the motivation for the work is weak. While the comment identifies a potential issue with the clarity of the definitions, it does not provide specific suggestions or detailed guidance on how the authors might address this concern. The feedback is somewhat helpful as it highlights an area that needs clarification, but it lacks depth and actionable advice, making it difficult for the authors to fully address the issue. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should clarify whether the Fourier modes are represented as real or complex numbers. This is a specific and actionable suggestion that provides clear guidance on how the authors can improve their draft. By explicitly stating the need for clarification, the comment directs the authors to a specific area where they should make adjustments. The action is both explicit and concrete, as it clearly indicates what needs to be done and how to implement it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should clarify whether the Fourier modes are represented as real or complex numbers. However, it does not specify which part of the paper this clarification is needed, making it weakly grounded. The comment is specific in its suggestion, as it clearly indicates what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should clarify whether the Fourier modes are represented as real or complex numbers. This is a suggestion for improvement, but it does not provide any specific reasoning, examples, or references to support why this clarification is necessary or beneficial. The comment lacks depth and does not offer a clear justification for the suggestion, making it difficult for the authors to understand the rationale behind it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should clarify whether the Fourier modes are represented as real or complex numbers. This is a specific and actionable piece of feedback that directly addresses a potential ambiguity in the paper. By prompting the authors to clarify this aspect, the comment provides a clear direction for improvement, helping them to ensure the accuracy and consistency of their representation. However, the comment could be more helpful if it offered additional guidance on how to clarify this point or suggested specific ways to present the information. Overall, the comment is mostly helpful as it identifies a specific area for improvement and provides a clear action for the authors to take.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to correct a specific error in the text, stating that \"it should be Fig. 1 instead of Fig. 5.1.\" It also provides a concrete suggestion for improving the LaTeX formatting by placing the label after the caption. This direct and specific feedback allows the authors to easily identify the error and understand how to correct it. The comment is clear and actionable, providing both the correction and the method for implementation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 205,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error, stating that \"it should be Fig. 1 instead of Fig. 5.1\" and provides a concrete suggestion for improvement regarding LaTeX formatting by recommending placing the label after the caption. This level of detail and specificity makes the comment highly actionable and informative for the authors. Therefore, this comment is classified as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should correct a specific error in the text, stating that \"it should be Fig. 1 instead of Fig. 5.1.\" It also provides a suggestion for improving LaTeX formatting by placing the label after the caption. While the comment is factual and points out a specific error, it lacks detailed reasoning or references to support why this correction is necessary or how it impacts the paper. The suggestion for LaTeX formatting is clear and actionable, but the overall claim is somewhat verifiable due to the lack of comprehensive justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific error in the text, pointing out that \"it should be Fig. 1 instead of Fig. 5.1.\" It also provides a clear suggestion for improving LaTeX formatting by recommending placing the label after the caption. This feedback is actionable and constructive, as it directly addresses a factual error and offers a practical solution for improving the presentation of the paper. By correcting the figure reference and ensuring proper LaTeX formatting, the authors can enhance the clarity and professionalism of their work. Therefore, the comment is highly helpful, as it provides clear guidance on how to improve the draft.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that including case studies and error studies would enhance the paper by providing a more convincing demonstration of the effectiveness of the proposed components. It provides an example of a case study in the context of graph pre-training for AMR parsing and generation. However, the comment does not explicitly instruct the authors to include these elements or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors are left to infer that they should add case studies and error studies to their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including case studies and error studies to enhance the paper\\'s effectiveness, providing an example of a case study in the context of graph pre-training for AMR parsing and generation. However, the comment does not specify which part of the paper should be addressed or how these studies should be integrated. The authors may infer that these studies should be included in the experimental section or discussion, but the lack of explicit guidance makes the comment weakly grounded. The comment is specific in suggesting the inclusion of case studies and error studies, but the absence of detailed instructions or examples makes it somewhat specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including case studies and error studies would enhance the paper by providing a more convincing demonstration of the effectiveness of the proposed components. It provides an example of a case study in the context of graph pre-training for AMR parsing and generation, which helps to illustrate the point. However, the comment lacks detailed reasoning or references to support the claim that these studies would be convincing. While the example is helpful, the overall claim is somewhat verifiable as it provides a basis for improvement but lacks comprehensive justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that including case studies and error studies would enhance the paper by providing a more convincing demonstration of the effectiveness of the proposed components. It provides an example of a case study in the context of graph pre-training for AMR parsing and generation, which helps to illustrate the point. However, the comment lacks detailed guidance on how to implement these studies or what specific aspects should be covered. While it offers a valuable suggestion for improvement, the feedback could be more helpful if it included more detailed examples or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not provide comprehensive guidance.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights an issue with the notation {\\cal P} with a subscript being used multiple times in the same section without being defined. This feedback is explicit, as it directly points out a lack of definition for the notation, which the authors should address. The action is also concrete, as it clearly specifies what needs to be done: define the notation {\\cal P} with a subscript. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment points out an issue with the notation {\\cal P} with a subscript being used multiple times in the same section without being defined. This provides full grounding as the authors can accurately identify the section where the issue occurs. The comment is also specific, as it clearly specifies what needs to be addressed: the lack of definition for the notation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights an issue with the notation {\\cal P} with a subscript being used multiple times in the same section without being defined. This is a factual observation that requires no further explanation or justification to be understood. The comment is clear and specific, making it fully verifiable. Therefore, it aligns with a score of 5.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, namely the inconsistent use of notation {\\cal P} with a subscript in the same section without being defined. This feedback is clear and actionable, as it points out a lack of clarity in the notation, which could hinder the reader's understanding. By defining the notation, the authors can improve the clarity and consistency of their paper. The comment is specific and provides a clear direction for improvement, making it highly helpful for the authors. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific suggestions for improving the draft, such as correcting a spelling error (\"known\" instead of \"know\"), defining a symbol (\"\\\\gamma_0^{***}\"), and specifying the meaning of colors in a figure caption. These suggestions are explicit and concrete, allowing the authors to directly apply them to their draft. The feedback is detailed and actionable, providing clear guidance on how to address the identified issues. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment provides specific suggestions for improving the draft, such as correcting a spelling error (\"known\" instead of \"know\"), defining a symbol (\"\\\\gamma_0^{***}\"), and specifying the meaning of colors in a figure caption. However, it does not explicitly mention which part of the paper these suggestions relate to, such as a specific section or figure number. This makes it difficult for the authors to pinpoint the exact areas that need attention. While the suggestions are specific, the lack of grounding makes it challenging for the authors to fully understand the scope of the feedback. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of three separate suggestions for improving the draft. The first suggestion, correcting a spelling error (\"known\" instead of \"know\"), is a factual observation that does not require verification. The second suggestion, asking for a definition of the symbol \\\\gamma_0^{***}, is a request for clarification, which is a common request in peer reviews. The third suggestion, specifying the meaning of colors in a figure caption, is also a request for clarification. Overall, the comment is mostly factual and does not contain any subjective opinions or claims that require verification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the draft, such as correcting a spelling error (\"known\" instead of \"know\"), defining a symbol (\"\\\\gamma_0^{***}\"), and specifying the meaning of colors in a figure caption. These suggestions are actionable and detailed, offering clear guidance on how the authors can enhance their work. By addressing these specific issues, the authors can improve the clarity, accuracy, and overall quality of their paper. The feedback is comprehensive and provides a clear roadmap for improvement, making it highly helpful for the authors. Therefore, the comment is rated as 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind two specific design choices in Figure 1: the use of a separate timbre encoder module and the input of content encoder outputs into SADTW. However, it does not provide explicit or implicit suggestions on how the authors should address these questions or provide further justification for their design choices. The comment lacks concrete guidance on what needs to be done or how the authors can improve their draft. As a result, the comment is unactionable, aligning with a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by questioning the rationale behind two specific design choices: the use of a separate timbre encoder module and the input of content encoder outputs into SADTW. This provides clear guidance on what aspects of the paper require further explanation or justification. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the rationale behind specific design choices in Figure 1, specifically regarding the use of a separate timbre encoder module and the input of content encoder outputs into SADTW. However, it does not provide any claims, opinions, or suggestions that require verification or justification. The comment is purely descriptive and does not offer any guidance or insight that would help the authors improve their work. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the rationale behind specific design choices in Figure 1, specifically regarding the use of a separate timbre encoder module and the input of content encoder outputs into SADTW. While it identifies areas that could be clarified or better explained, it does not provide actionable feedback or suggestions on how the authors might address these questions or improve their draft. The comment lacks depth and specificity, making it somewhat helpful as it points out potential areas for improvement but does not offer concrete guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the writing and presentation of the paper, noting that it is \"jumbled at times.\" However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on what aspects of the writing are jumbled or how the authors can improve the clarity and organization of their presentation. Without concrete suggestions or actionable steps, the authors are left without a clear path to follow, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a concern about the writing and presentation of the paper, noting that it is \"jumbled at times.\" However, it does not specify which sections or parts of the paper are affected by this issue, nor does it provide any details on what might be contributing to the jumbledness. The authors cannot confidently determine which part of the paper needs attention, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not offer any suggestions or guidance on how to improve the clarity or organization of the writing. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point expresses a subjective opinion about the writing and presentation of the paper, noting that it is \"jumbled at times.\" This is a subjective assessment and lacks specific examples or references to support the claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a concern about the writing and presentation of the paper, noting that it is \"jumbled at times.\" However, the comment lacks specificity and does not provide any actionable feedback or suggestions on how the authors might improve the clarity or organization of their writing. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects of the writing need attention or how to address the issue. As a result, the comment is barely helpful, as it does not offer any meaningful insights or actionable advice to the authors.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the computational complexity of the proposed method compared to other methods, specifically mentioning \"emerging convolutions.\" It also suggests considering the power demand on a mobile device. However, the comment does not provide explicit guidance on how to address this concern or what specific actions the authors should take to improve their draft. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to respond. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the computational complexity of the proposed method compared to other methods, specifically mentioning \"emerging convolutions.\" However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. Additionally, the comment does not provide specific guidance or suggestions on how to address the computational complexity issue or the power demand on a mobile device. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the computational complexity of the proposed method compared to other methods, specifically mentioning \"emerging convolutions.\" It also suggests considering the power demand on a mobile device. However, the comment does not provide any evidence, reasoning, or references to support the claim that the computational complexity is a significant issue or that it could cause a power demand on a mobile device. Without specific examples or references, the claim remains unverifiable, as the authors cannot confidently understand or address the issue raised. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the computational complexity of the proposed method compared to other methods, specifically mentioning \"emerging convolutions.\" It also suggests considering the power demand on a mobile device, which is a relevant concern for practical applications. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their draft in this regard. While it identifies a potential area for improvement, it does not provide actionable advice or detailed insights that would help the authors enhance their work. Therefore, the comment is somewhat helpful, as it highlights a relevant concern but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the authors' claim about the primary attention of the Induction, Duplicate Token, and Previous Token heads to the S2 token is incorrect, referencing Section 3 of Wang et al., 2023. It provides a specific correction, indicating that these heads are active at the S2 token but do not primarily attend to it. This feedback is clear and actionable, as it directs the authors to correct their understanding and potentially revise their draft. The comment is fully actionable because it provides a direct and concrete instruction for the authors to address the issue. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the base IOI circuit\" and \"Section 3 of Wang et al., 2023,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the incorrect claim made by the authors regarding the primary attention of certain heads to the S2 token, providing a clear explanation of the error. This feedback is both grounded and specific, making it highly actionable for the authors to address the issue. Therefore, this comment is rated as 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors incorrectly state that the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token, referencing Section 3 of Wang et al., 2023. The comment provides a specific correction, explaining that these heads are active at the S2 token but do not primarily attend to it. This claim is supported by a reference to external work, making it mostly verifiable. However, the comment could be more robust by providing additional examples or detailed reasoning to fully substantiate the claim. Therefore, it is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific error in the authors' claim regarding the primary attention of certain heads in the base IOI circuit. It points out that the authors incorrectly state that these heads primarily attend to the S2 token, while the reference to Wang et al., 2023 suggests that they are active at the S2 token but do not primarily attend to it. This feedback is clear and actionable, as it directs the authors to correct their understanding and potentially revise their draft. By providing a specific correction and referencing external work, the comment offers valuable guidance for improving the accuracy and clarity of the paper. Therefore, the comment is highly helpful, as it addresses a concrete issue and provides actionable feedback.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment provides specific feedback on the vagueness of the statement at L15, suggesting that certain RNNs work well for specific natural language reasoning tasks and providing a reference to support this claim. It also critiques the reinforcement learning-agent analogy at L16-18, suggesting that it is out-of-place and that generalization capabilities are better illustrated by examples later in the paper. While the comment identifies areas for improvement, it does not offer explicit or concrete actions for the authors to take. The feedback is somewhat actionable as it directs the authors to clarify the vague statement and reconsider the reinforcement learning-agent analogy, but it lacks detailed guidance on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific parts of the paper, such as lines 15, 16-18, and later sections (229 to 253). It provides detailed feedback on the vagueness of a statement at line 15, suggesting that certain RNNs work well for specific natural language reasoning tasks and providing a reference to support this claim. It also critiques the reinforcement learning-agent analogy at lines 16-18, suggesting that it is out-of-place and that generalization capabilities are better illustrated by examples later in the paper. The comment is fully grounded as it explicitly mentions specific sections of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed feedback on the vagueness of a statement and the relevance of the reinforcement learning-agent analogy. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point contains claims that are partially verifiable. The first part of the comment suggests that certain RNNs work well for specific natural language reasoning tasks, referencing the literature on natural language inference and providing a link to a leaderboard. This provides some support for the claim, but it could be more detailed with specific examples or references. The second part critiques the reinforcement learning-agent analogy, suggesting that it is out-of-place and that generalization capabilities are better illustrated by examples later in the paper. This critique is somewhat verifiable as it provides a logical reasoning for why the analogy might be out-of-place, but it lacks specific examples or references to support the claim fully. Overall, the comment is mostly verifiable, as it provides some justification but could be strengthened with more detailed evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific feedback on the vagueness of a statement at line 15, suggesting that certain RNNs work well for specific natural language reasoning tasks and providing a reference to support this claim. It also critiques the reinforcement learning-agent analogy at lines 16-18, suggesting that it is out-of-place and that generalization capabilities are better illustrated by examples later in the paper. While the comment identifies areas for improvement, it lacks detailed guidance on how the authors might address these issues or what specific changes should be made. The feedback is somewhat helpful as it directs the authors to clarify the vague statement and reconsider the reinforcement learning-agent analogy, but it does not provide a comprehensive roadmap for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with the statement that every kernel can be described by a feature space parameterized by a neural network. It provides a counterexample using RBF kernels, explaining that neural networks can only represent finite-dimensional RKHSs in practice. However, the comment does not explicitly instruct the authors to revise or clarify this point. While the authors can infer that they need to address this limitation, the action is implicit and somewhat vague, as it does not provide specific guidance on how to make the statement clearer or more accurate. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific part of the paper (line 104) where a statement is made. It also provides a clear and specific critique of the statement, explaining why it is not entirely accurate and offering a counterexample with RBF kernels. This allows the authors to understand exactly what part of the paper needs revision and what specific issue needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement \"every kernel can be described by a feature space parameterized by a neural network\" is trivially not true, providing a counterexample with RBF kernels. The reviewer argues that neural networks can only represent finite-dimensional RKHSs in practice, contrasting this with the infinite-dimensional nature of RBF kernels. This claim is supported by logical reasoning and a specific example, making it mostly verifiable. However, it could be strengthened by including references to relevant literature on kernel methods and neural networks. Overall, the comment is mostly verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with a statement in the paper, noting that the claim that every kernel can be described by a feature space parameterized by a neural network is not entirely accurate. It provides a counterexample using RBF kernels, explaining that neural networks can only represent finite-dimensional RKHSs in practice, while RBF kernels have infinite-dimensional RKHSs. This feedback is clear and actionable, as it directs the authors to reconsider and clarify the statement. However, the comment could be more helpful if it suggested specific ways to revise the statement or provide additional context. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed method is not well-positioned in the literature and points out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known and used in other works, such as the original denoising score matching objective [1] and score-interpolation [2]. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the positioning of their method in the literature. The action is implicit and vague, as it does not specify how the authors should conduct a thorough literature review or what specific aspects of their method need to be highlighted. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and suggests a thorough literature review, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known and used in other works, such as the original denoising score matching objective [1] and score-interpolation [2]. This provides clear guidance on what the authors should consider in their literature review. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is not well-positioned in the literature and suggests that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known and used in other works, such as the original denoising score matching objective [1] and score-interpolation [2]. The claim is supported by providing specific examples of related work, which helps the authors understand the existing literature and how their method relates to it. However, the comment could be more robust if it included a broader range of references or a more detailed explanation of how the proposed method differs from or builds upon these existing works. Overall, the claim is mostly verifiable, as it is supported by logical reasoning and specific examples, but it could be strengthened with additional references or elaboration.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the literature positioning of the proposed method, noting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known and used in other works, such as the original denoising score matching objective [1] and score-interpolation [2]. This feedback is valuable as it directs the authors to conduct a thorough literature review and acknowledge the existing work that aligns with their method. However, the comment could be more helpful if it provided specific suggestions on how the authors could position their method within the existing literature or highlighted the unique contributions of their work. Despite this, the comment offers a clear direction for improvement, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the technical contribution of the paper is limited, as it does not offer significant technical contributions or extensions based on a typical model for the cross-domain recommendation setting. However, the comment does not provide any specific suggestions or guidance on how the authors might address this limitation or enhance their work. The authors are left without a clear understanding of what needs to be done to improve the technical contribution of their paper. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section or aspect being discussed. It is also not specific because it does not detail what aspects of the technical contribution are limited or how the authors might address this limitation. Without specific references or details, the authors cannot effectively respond to the comment. Therefore, this comment is rated as Not Grounded and Not Specific, corresponding to a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution of the paper is limited, as it does not offer significant technical contributions or extensions based on a typical model for the cross-domain recommendation setting. However, the comment lacks specific details or examples to support this claim. Without further elaboration or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the paper, specifically the lack of technical contribution and extension based on a typical model for the cross-domain recommendation setting. This feedback is clear and actionable, as it highlights a critical area where the authors could enhance their work. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this limitation or improve their technical contribution. Despite this, the comment is mostly helpful as it directs the authors to a specific area for improvement, allowing them to focus on enhancing the technical aspects of their paper. Therefore, the comment is rated as mostly helpful, corresponding to a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the components of the approach are not novel, as they have been used in previous works. It mentions specific examples of weak predictors (MLP, Regression Tree, Random Forest) and sampling strategies (epsilon-greedy) that have been used before, citing references [2, 3, 7] and [5]. The comment also notes that the results of the proposed WeakNAS are almost the same as BRP-NAS, as shown in Table 2 in Appendix C. While the comment identifies a lack of novelty and similarity to existing methods, it does not provide explicit or implicit actions for the authors to take to address this issue. The authors are left to infer that they need to consider the novelty of their approach and potentially differentiate it from existing methods. However, the comment lacks concrete guidance on how to achieve this differentiation or what specific aspects to focus on. Therefore, the comment is somewhat actionable, as it points out a critical issue but does not provide detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of the approach by pointing out that the weak predictor components (MLP, Regression Tree, Random Forest) and the sampling strategy are similar to existing methods, such as those used in previous works [2, 3, 7] and [5]. It also notes that the results of the proposed WeakNAS are almost the same as those of BRP-NAS, as shown in Table 2 in Appendix C. This comment is fully grounded as it explicitly mentions the specific components and methods being discussed, allowing the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides detailed examples of the methods and results being compared, making it clear what aspects of the approach need to be considered for novelty. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the components of the approach, such as weak predictors (MLP, Regression Tree, Random Forest) and sampling strategies, are not novel and have been used in previous works. It provides specific references [2, 3, 7] and [5] to support the claim about the similarity of the weak predictors and sampling strategy to existing methods. Additionally, it notes that the results of the proposed WeakNAS are almost the same as those of BRP-NAS, as shown in Table 2 in Appendix C. This level of detail and specific references makes the claim fully verifiable, as it provides clear evidence to support the authors\\' understanding of the issue. Therefore, the comment is rated as 5.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant issue with the novelty of the approach, specifically pointing out that the weak predictor components (MLP, Regression Tree, Random Forest) and the sampling strategy are similar to existing methods used in previous works. It provides specific references [2, 3, 7] and [5] to support this claim, which helps the authors understand the context and the limitations of their approach. Additionally, the comment notes that the results of the proposed WeakNAS are almost the same as those of BRP-NAS, as shown in Table 2 in Appendix C. This feedback is mostly helpful as it highlights a critical area for improvement and provides specific references and results for the authors to consider. However, it could be more helpful if it offered suggestions on how to differentiate the proposed approach from existing methods or how to enhance its novelty. Overall, the comment provides a clear direction for the authors to address the issue of novelty, making it a mostly helpful feedback.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the methodology used for calculating precision, recall, and F1-score for a 4-class classification of breast density. It also suggests that reporting AUC with sensitivity and specificity at different operating points would be more informative for comparing model performance. While the comment identifies specific areas for clarification and improvement, it does not provide explicit instructions on how to address these issues or what actions the authors should take. The actions are implicit and somewhat vague, as the authors are left to infer how to implement the suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the methodology used for calculating precision, recall, and F1-score for a 4-class classification of breast density, which is a specific aspect of the paper. It also suggests that reporting AUC with sensitivity and specificity at different operating points would be more informative for comparing model performance, which is a specific recommendation for improving the evaluation of the model. However, the comment does not explicitly mention which part of the paper discusses these calculations or evaluations, making it weakly grounded. The specificity is good as it clearly specifies what needs to be addressed and improved. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the methodology used for calculating precision, recall, and F1-score for a 4-class classification of breast density and suggests that reporting AUC with sensitivity and specificity at different operating points would be more informative for comparing model performance. While the comment identifies specific areas for clarification and improvement, it lacks detailed reasoning or references to support why these suggestions are important or how they would enhance the paper. The authors are left to infer the significance of these points, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises specific questions about the methodology used for calculating precision, recall, and F1-score for a 4-class classification of breast density. It also suggests that reporting AUC with sensitivity and specificity at different operating points would be more informative for comparing model performance. While the comment identifies areas for improvement, it lacks detailed guidance on how to address these issues or what specific actions the authors should take. The feedback is somewhat helpful as it points out potential areas for enhancement, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the dataset created by the authors is optional and recommends using the Kialo dataset, which is well-studied and cleaner. However, it does not provide explicit guidance on how the authors should implement this suggestion or what specific actions they should take to incorporate the Kialo dataset into their work. The comment implies that the authors should consider using the Kialo dataset as an additional resource, but it lacks concrete steps or details on how to do so. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the dataset creation process is optional and recommends using the Kialo dataset, which is well-studied and cleaner. However, it does not specify which part of the paper discusses the dataset creation or how the authors should address this suggestion. The comment lacks grounding as it does not provide clear references to specific sections or parts of the paper, making it difficult for the authors to identify the exact area that needs attention. Additionally, the comment is specific in its recommendation to use the Kialo dataset, but without grounding, it is challenging for the authors to understand how to apply this suggestion. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the dataset creation process is optional and recommends using the Kialo dataset, which is well-studied and cleaner. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the recommendation. Without detailed reasoning or evidence, the claim is not fully verifiable, as it does not provide a clear justification for why the Kialo dataset is a suitable alternative. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the dataset creation process, suggesting that the Kialo dataset, which is well-studied and cleaner, could be a more suitable alternative. While the comment provides a recommendation, it lacks specific guidance on how the authors should implement this suggestion or what steps they should take to incorporate the Kialo dataset into their work. The feedback is somewhat helpful as it points out a potential improvement but does not offer detailed instructions or examples, leaving the authors with limited actionable advice. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the novelty of the Transformer in the context of NLP and vision tasks, suggesting that the authors' modification, particularly the cross-layer aspect, does not provide significant insight into machine learning. It also notes that the ablation study shows limited improvement from self-cross attention, questioning its significance. The comment implies that the main improvements might stem from using a na\u00efve Transformer rather than the proposed modification. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve their work. The action is implicit and vague, as the authors are left to infer what needs to be done. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the novelty of the Transformer in the context of NLP and vision tasks, suggesting that it is no longer novel. It also critiques the cross-layer modification, noting that it does not bring significant insight into machine learning. The comment further questions the significance of the self-cross attention ablation study, noting that it shows limited improvement. However, the comment does not specify which part of the paper discusses the Transformer or the ablation study, making it weakly grounded. The comment is specific in detailing the issues with the Transformer and the ablation study, but without explicit references to sections or figures, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the novelty of the Transformer in the context of NLP and vision tasks, suggesting that it is no longer novel. It also questions the significance of the self-cross attention ablation study, noting that the improvement is limited (<1%). The comment implies that the main improvements might stem from using a na\u00efve Transformer rather than the proposed modification. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand and address the issues. The reasoning is somewhat vague, and the lack of detailed evidence or references makes it challenging to fully verify the claims. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the novelty of the Transformer in the context of NLP and vision tasks, suggesting that it is no longer a significant contribution. It also questions the significance of the self-cross attention ablation study, noting that the improvement is limited. The comment implies that the main improvements might stem from using a na\u00efve Transformer rather than the proposed modification. However, the comment lacks specific guidance or suggestions on how the authors can address these issues or improve their work. While it identifies areas for improvement, it does not provide actionable steps or detailed feedback, making it somewhat helpful. The authors would need to infer what changes to make, which limits the comment's usefulness. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to discuss a specific work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" from ICML2019, which is relevant to the topic of joint error in unsupervised domain adaptation (UDA). It also suggests that the authors should illustrate the relationship between this work and their proposed method and explain why their method is better. This provides a clear and concrete action for the authors to take, as they know exactly what needs to be addressed and how to do it. The comment is fully actionable, as it gives explicit guidance on what to include in the discussion and how to compare the proposed method with existing work. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific issue of joint error in unsupervised domain adaptation (UDA), which is a well-defined part of the paper. It also specifies the need to discuss a previous work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" from ICML2019, and to illustrate the relationship between this work and the proposed method. This provides clear guidance on what part of the paper needs attention and what specific issues need to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' assertion about the lack of research on joint error in unsupervised domain adaptation (UDA) is inaccurate, as previous work has already addressed this issue. The comment provides a specific reference to \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" from ICML2019, which supports the claim. However, the comment could be more robust by including a brief summary or explanation of the relevance of this work to the authors' proposed method, enhancing the verifiability. Overall, the claim is mostly verifiable, as it is supported by a specific reference but lacks some depth in explanation.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific gap in the authors' claim regarding the lack of research on joint error in unsupervised domain adaptation (UDA). It directs the authors to a relevant previous work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" from ICML2019, and suggests that they discuss this work and illustrate the relationship between it and their proposed method. This feedback is actionable and provides a clear path for the authors to improve their draft by acknowledging and building upon existing research. The comment is detailed and constructive, offering specific guidance on how to enhance the paper\\'s contribution and context. Therefore, it is rated as highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the comparison with state-of-the-art (SOTA) methods due to the use of a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method might be attributed to the larger dataset size, which significantly impacts accuracy. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to ensure a fair comparison. The action is implicit and vague, as it leaves the authors to infer the necessary steps, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the fairness of the comparison with state-of-the-art methods, specifically mentioning the use of a newly collected 209M dataset while existing methods use smaller datasets. This provides some grounding as the authors can infer that the comparison is being questioned due to the dataset size. However, the comment does not specify which part of the paper discusses the comparison with SOTA methods, making it weakly grounded. The comment is specific in detailing the issue with the dataset size and its potential impact on the accuracy of the results. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison with state-of-the-art methods may be unfair due to the use of a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer provides an example of a method, GEM, which uses only 20M unlabeled data, highlighting the potential impact of dataset size on accuracy. This reasoning is logical and provides a clear explanation of why the comparison might be unfair. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the fairness of the comparison with state-of-the-art methods due to the use of a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer points out that the superior performance of the proposed method might be attributed to the larger dataset size, which significantly impacts accuracy. This feedback is clear and actionable, as it highlights a potential issue with the experimental setup and suggests that the authors should consider the impact of dataset size on their results. However, the comment could be more helpful if it provided specific guidance on how to address this issue, such as suggesting alternative comparisons or methods to control for dataset size. Overall, the comment is mostly helpful, as it identifies a significant concern and provides a clear direction for improvement.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting that several curriculum learning methods have been discussed in Section 1, but it does not provide explicit guidance on how to address the need for designing a new curriculum learning method for text graphs. While the comment implies that the authors should justify the need for a new method, it lacks concrete suggestions or detailed instructions on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue: the lack of justification for designing a new curriculum learning method for text graphs and the absence of a discussion on why existing methods cannot be applied. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that several curriculum learning methods have been discussed in Section 1 but does not provide a clear justification for why a new method is needed for text graphs. It highlights a research gap by noting that the paper does not discuss why existing methods cannot be applied. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the reasoning behind the need for a new method. The lack of detailed explanation or evidence makes the claim somewhat verifiable, as it requires the authors to infer the missing information themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out that while several curriculum learning methods have been discussed, the need for designing a new method for text graphs is not adequately justified. It highlights a research gap by noting that the paper does not explain why existing methods cannot be applied to text graphs. This feedback is valuable as it directs the authors to address a critical aspect of their work that is currently missing. However, the comment could be more helpful if it provided specific examples or suggestions for how to justify the need for a new method. Overall, the comment is mostly helpful as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should use powerful pre-trained language models like BERT and XLNet as the base encoder for all methods and then compare the efficacy of the transfer parts instead of using the simplest n-gram features. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be done to improve their draft. The comment is specific in its suggestion, detailing which models to use and how to compare the transfer parts. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"domain adaptation in the NLP field\" and suggests using powerful pre-trained language models like BERT and XLNet as the base encoder. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides clear guidance on how the authors should improve their draft by comparing the efficacy of the transfer parts instead of using the simplest n-gram features. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that using powerful pre-trained language models like BERT and XLNet as the base encoder can overcome the domain-shift problem, and suggests comparing the efficacy of the transfer parts instead of using the simplest n-gram features. While the claim is based on the understanding of domain adaptation in the NLP field, it lacks specific references or detailed reasoning to fully substantiate the suggestion. The comment provides a logical argument but could be strengthened with more detailed explanations or examples. Therefore, the claim is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending the use of powerful pre-trained language models like BERT and XLNet as the base encoder for domain adaptation in the NLP field. It suggests comparing the efficacy of the transfer parts instead of relying on simpler n-gram features. This feedback is actionable and offers a clear direction for the authors to enhance their draft by incorporating more advanced models and conducting a more thorough comparison. However, the comment could be more helpful if it included additional guidance on how to implement this suggestion or why these models are particularly effective for domain adaptation. Overall, the comment is mostly helpful, as it provides a valuable insight into potential improvements but could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the quantitative evaluation results, noting that Figure 3 only reflects middle outputs and Figure 4 compares final results with a single data sample. The comment suggests that the current evaluations are not convincing enough to confirm ModelAngelo\u2019s superiority to competitors and asks if a quantitative comparison on the final outputs is possible. While the comment identifies a specific issue with the evaluation, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the evaluation process. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct a quantitative comparison on the final outputs. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the quantitative evaluation results, noting that they only reflect middle outputs and lack comparison with final outputs. This provides a clear direction for the authors to improve their evaluation process. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the quantitative evaluation results, specifically questioning whether they reflect only middle outputs and if a comparison with final outputs is possible. While the comment identifies a potential issue with the evaluation, it does not provide any supporting evidence or reasoning to substantiate the claim that the current evaluations are not convincing enough to confirm ModelAngelo\u2019s superiority. The lack of justification or examples makes it difficult for the authors to understand the basis of the claim, rendering it unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific issue with the quantitative evaluation results, noting that Figure 3 only reflects middle outputs and Figure 4 compares final results with a single data sample. This observation raises concerns about the conclusiveness of the current evaluations in confirming ModelAngelo's superiority over competitors. The comment suggests that a quantitative comparison on the final outputs would be necessary to strengthen the evaluation. While the comment highlights a potential weakness in the evaluation process, it does not provide detailed guidance or suggestions on how to conduct this additional comparison. The feedback is somewhat helpful as it points out a specific area for improvement, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several areas where the paper lacks detail, making it difficult for the authors to reproduce the results. It specifically mentions the sparsification process, the generation of landmarks on edges, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. However, the comment does not provide explicit instructions or suggestions on how the authors should address these issues. While it identifies the areas needing more detail, it does not offer concrete guidance on how to improve the paper. Therefore, the comment is somewhat actionable, as it points out specific areas for improvement but lacks detailed guidance on how to implement these suggestions.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of detail in the techniques, making it difficult to reproduce the results. It provides specific examples of areas where the paper lacks detail, such as the sparsification process, the generation of landmarks on edges, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. This allows the authors to accurately identify the parts of the paper that need improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights specific areas where the paper lacks detail, such as the sparsification process, the generation of landmarks on edges, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. However, the comment does not provide any specific examples, references, or logical reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of detail regarding the techniques used, which makes it difficult for the authors to reproduce the results. It provides specific examples of areas where the paper lacks detail, such as the sparsification process, the generation of landmarks on edges, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. However, the comment does not offer any suggestions or guidance on how the authors might address these issues or improve the paper. While it highlights the need for more detail, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the FIITED approach, which relies on utility-based eviction decisions. It suggests that this method might introduce biases, particularly by prematurely evicting valuable chunks due to their temporary high utility. However, the comment does not provide explicit guidance on how the authors might address this issue or what specific changes could be made to mitigate the bias. While the authors can infer that they need to consider alternative eviction strategies or incorporate additional factors beyond utility, the lack of concrete suggestions makes the comment somewhat actionable. Therefore, it aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the FIITED approach, which is described as utility-based for determining chunk significance. It highlights a potential issue with relying solely on utility scores for eviction decisions, suggesting that this could introduce biases. However, the comment does not specify which part of the paper discusses the FIITED approach or the utility-based method, making it difficult for the authors to pinpoint the exact section being addressed. While the issue is clearly stated, the lack of specific grounding makes the comment weakly grounded. Therefore, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that relying solely on utility scores for eviction decisions in the FIITED approach might introduce biases. It provides an example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to verify the assertion. The reasoning is logical but lacks detailed examples or references, which could strengthen the claim. Therefore, the comment is considered borderline verifiable, aligning with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the FIITED approach, which relies on utility-based eviction decisions. It highlights that this method might introduce biases, particularly by prematurely evicting valuable chunks due to their temporary high utility. While the comment points out a valid concern, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the approach. The feedback is somewhat helpful as it raises a critical point about the potential limitations of the current method, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the first paragraph of the Introduction is devoted to a general introduction of DNNs and lacks any mention of drift. It suggests that this paragraph is not central to the paper's focus on detecting drift types and magnitude, and that it provides little valuable information. This feedback is clear and specific, as it identifies a specific part of the paper that needs revision and provides a clear rationale for why it is not relevant to the paper's core focus. The authors can directly infer that they should either remove or reframe this paragraph to align with the paper's main contribution. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the first paragraph of the Introduction, providing full grounding as the authors can accurately identify the section being addressed. It also specifies the issue with this paragraph, noting that it is devoted to a general introduction of DNNs without mentioning drift, which is central to the paper\\'s focus. This level of detail allows the authors to understand exactly what part of the paper needs revision and what specific issue needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first paragraph of the Introduction is devoted to a general introduction of DNNs without mentioning drift, which is central to the paper\\'s focus. The comment suggests that this paragraph provides little valuable information to readers. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. Without detailed reasoning or examples, the claim is somewhat verifiable, as it provides a basis for improvement but lacks the depth needed for full validation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the introduction section, noting that it is devoted to a general introduction of DNNs without mentioning drift, which is central to the paper\\'s focus. This feedback is clear and actionable, as it directs the authors to reconsider the relevance of the DNN introduction to their core contribution. By highlighting the lack of focus on drift, the comment provides a clear direction for improving the draft. However, it could be more helpful if it suggested specific ways to reframe or remove the DNN introduction. Overall, the comment is mostly helpful, as it offers valuable insights but could be more comprehensive in its suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the performance and contribution of different parts of the framework, particularly from an experimental perspective. It points out that while the result section shows promising visual stimuli results, it lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the presented ones. The comment suggests that it is unclear what the exact performance of the whole framework and individual parts is compared to other solutions. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to clarify the performance and contribution of the framework. The action is implicit and somewhat vague, as the authors are left to infer how to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of clarity regarding the performance and contribution of different parts of the framework, particularly from an experimental perspective. It mentions that while the result section shows promising visual stimuli results, it lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the presented ones. The comment is fully grounded as it explicitly mentions the areas where the authors need to clarify their work, specifically regarding the experimental aspects of the framework. It is also specific because it clearly specifies what needs to be addressed, such as the lack of quantitative experiments, comparisons between algorithms, and detailed explanations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the clarity of the experimental aspects of the framework, specifically regarding the performance and contribution of different parts. It notes that while the result section shows promising visual stimuli results, it lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the presented ones. The comment suggests that it is unclear what the exact performance of the whole framework and individual parts is compared to other solutions. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims, making it somewhat verifiable. The authors are left to infer the need for additional experimental details and comparisons, which could be helpful but lacks full support. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by highlighting the lack of clarity regarding the performance and contribution of different parts of the framework, particularly from an experimental perspective. It points out that while the result section shows promising visual stimuli results, it lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the presented ones. The comment suggests that it is unclear what the exact performance of the whole framework and individual parts is compared to other solutions, which is a crucial point for the authors to address. However, the comment could be more helpful if it provided specific suggestions or guidance on how to conduct these experiments or comparisons, or if it offered more detailed explanations of the presented results. Overall, the comment is somewhat helpful as it identifies an important area for improvement but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific suggestions for improving the comparison of the captioning experiment. It recommends comparing the results on the official COOC leader board on the blind test set, referencing specific examples and related work that have achieved high scores on this challenge. The comment also suggests comparing the paper to other approaches that have been proposed since the initial work and have significantly improved the results. However, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the captioning experiment,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the comparison of results on the official COOC leader board on the blind test set, referencing specific examples and related work. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper should compare its results on the captioning experiment with official test sets or development sets, but it suggests comparing them on the official COOC leader board on the blind test set, referencing specific examples and related work that have achieved high scores on this challenge. The comment provides specific references and examples to support its claim, making it mostly verifiable. However, it could be more robust with additional details or examples to fully substantiate the suggestion. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the comparison of the captioning experiment. It recommends comparing the results on the official COOC leader board on the blind test set, referencing specific examples and related work that have achieved high scores on this challenge. Additionally, it suggests comparing the paper to other approaches that have been proposed since then and have significantly improved the results, providing a clear direction for improvement. However, the comment could be more helpful if it included more detailed guidance on how to implement these suggestions or provided specific examples of how to compare the results. Overall, the feedback is mostly helpful as it offers actionable insights for the authors to enhance their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the meaning of \"wrong\" in the context of the paper, suggesting that the authors should clarify what constitutes a good, bad, or wrong explanation before using these terms. While the comment implies that the authors need to provide more context, it does not explicitly instruct them to clarify the meaning of \"wrong\" or how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the terminology. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is unclear, namely the meaning of \"wrong\" in the context of the paper. The comment provides a clear and actionable suggestion for the authors to clarify the terminology, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the meaning of \"wrong\" in the context of the paper, specifically at line 248. It suggests that the authors should clarify what constitutes a good, bad, or wrong explanation before using these terms. However, the comment does not provide any specific examples, references, or logical reasoning to support the claim that the use of \"wrong\" is unclear or problematic. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific point of confusion in the paper, namely the use of the term \"wrong\" at line 248. It suggests that the authors should clarify what constitutes a good, bad, or wrong explanation before using these terms. This feedback is clear and actionable, as it provides a specific area for improvement and guidance on how to address the issue. By clarifying the meaning of \"wrong,\" the authors can enhance the clarity and precision of their paper, making it easier for readers to understand the nuances of their arguments. Therefore, the comment is mostly helpful, as it offers a clear and constructive suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of sufficient experimental demonstration of the contribution points, specifically noting that the paper only compares ELF (the author\\'s method) with a baseline without Mid Vision Feedback (MVF) but lacks a comparison with the image classification results of Mid Vision Feedback (MVF). This feedback suggests that the authors should include such a comparison to better demonstrate the contribution of their method. However, the comment does not provide explicit guidance on how to conduct this comparison or what specific aspects of the comparison should be included. The action is implicit and somewhat vague, as the authors need to infer the need for a comparison and deduce the specific steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of sufficient experimental demonstration of the contribution points, specifically highlighting the absence of a comparison with the image classification results of Mid Vision Feedback (MVF). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue: the lack of comparison with the image classification results of MVF, which is crucial for demonstrating the superiority of the schema searched by ELF. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks sufficient experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification results of Mid Vision Feedback (MVF). The comment suggests that this lack of comparison does not prove the superiority of the schema searched by ELF. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional evidence or justification, the claim remains somewhat verifiable, as it lacks the necessary depth and clarity to fully substantiate the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the experimental demonstration of the paper's contribution points. It highlights the lack of a comparison with the image classification results of Mid Vision Feedback (MVF), which is crucial for demonstrating the superiority of the schema searched by ELF. This feedback is valuable as it directs the authors to include a more comprehensive experimental comparison, thereby strengthening the paper's claims. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or what aspects of the comparison should be included. Overall, the comment is mostly helpful, as it points out a critical area for improvement but lacks detailed suggestions.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the originality of the article, suggesting that its reasoning and writing logic are similar to those in a previous study. It questions whether the work is merely an extension of that study or if it introduces novel contributions. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or enhance the originality of their work. The action is implicit and vague, as it does not specify what steps the authors should take to differentiate their work or provide evidence of novelty. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the originality of the article, suggesting that its reasoning and writing logic are similar to those found in a previous study. It questions whether the work is merely an extension of that study or if it introduces novel contributions. However, the comment does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact area that needs attention. The comment is not grounded as it does not provide specific references or sections of the paper that need to be addressed. It is also not specific because it does not detail what aspects of the reasoning or writing logic are similar to the previous study. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the originality of the article, suggesting that its reasoning and writing logic are similar to those found in a previous study. It questions whether the work is merely an extension of that study or if it introduces novel contributions. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the originality of the article, suggesting that its reasoning and writing logic are similar to those found in a previous study. It questions whether the work is merely an extension of that study or if it introduces novel contributions. While the comment identifies a potential issue with the originality of the work, it does not provide specific suggestions or guidance on how the authors might address this concern or enhance the originality of their contribution. The feedback is somewhat helpful as it highlights a critical aspect of the paper that needs attention, but it lacks actionable advice, making it difficult for the authors to improve their draft effectively. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors' discussion of regret, specifically regarding whether the prediction error over the entire horizon T can be sublinear. It points out a potential inconsistency in the authors' reasoning, as they discuss the impossibility of sublinear regret but then proceed to prove that their method achieves T^{1/2} regret. The comment implies that the authors need to clarify their discussion of regret and ensure consistency in their claims. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer that they should clarify their discussion of regret. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 32-37 of the paper, allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies the issue with the discussion of regret, questioning whether the prediction error over the entire horizon T can be sublinear. This provides a clear direction for the authors to address the inconsistency in their reasoning. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' discussion of regret, specifically regarding whether the prediction error over the entire horizon T can be sublinear. It points out a potential inconsistency in the authors\\' reasoning, as they discuss the impossibility of sublinear regret but then proceed to prove that their method achieves T^{1/2} regret. The comment implies that the authors need to clarify their discussion of regret and ensure consistency in their claims. However, it does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the need for clarification and potentially seek additional context to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific inconsistency in the authors' discussion of regret. It points out that the authors discuss the impossibility of sublinear regret but then proceed to prove that their method achieves T^{1/2} regret, creating a potential confusion. The comment suggests that the authors need to clarify their discussion of regret to ensure consistency in their claims. While it highlights an important issue, it does not provide detailed guidance on how to address the inconsistency or what specific changes should be made to the draft. The feedback is somewhat helpful as it directs the authors to a critical area that needs clarification, but it lacks depth and actionable suggestions for improvement. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the necessity of long-range dependencies for powerful predictors in the context of semantic segmentation. It suggests that the paper should discuss whether locality with respect to the 2D image space is encoded in the graph structure and how this might affect prediction. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the paper opens that learning long-range dependencies is important for powerful predictors,\" allowing the authors to identify the specific part of the paper being addressed. It also specifies what the authors should consider, namely the necessity of long-range dependencies and the potential impact of locality with respect to the 2D image space. This provides clear guidance on what needs to be discussed or addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the necessity of long-range dependencies for powerful predictors in the context of semantic segmentation, specifically questioning whether locality with respect to the 2D image space is encoded in the graph structure. While the comment provides a logical reasoning by suggesting that the truth might lie somewhere in between, it lacks specific examples or references to support the claim. The absence of detailed evidence or references makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a pertinent question about the necessity of long-range dependencies for powerful predictors in the context of semantic segmentation. It points out that while the paper claims learning long-range dependencies is important, the reviewer questions whether this is fully required and suggests that the truth might lie somewhere in between. The comment also implies that the absence of locality with respect to the 2D image space in the graph structure might affect prediction, depending on the image size. This feedback is somewhat helpful as it identifies a potential area for further discussion and exploration, but it lacks specific guidance on how the authors might address this issue or what additional experiments or analyses could be conducted. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the paper, including the lack of clarity regarding the term $e_l$ in Eq. (3), the exponential dependence of the results on the diameter $M$ of the data domain, and the potential weakness of the proposed approaches or theoretical results. However, the comment does not provide explicit or implicit actions for the authors to take. It lacks guidance on how to address these issues or what specific changes should be made to improve the paper. As a result, the authors are left without a clear understanding of how to respond to these points, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses specific issues related to the paper, such as the lack of clarity regarding the term $e_l$ in Eq. (3) and the exponential dependence of the results on the diameter $M$ of the data domain. It also mentions the potential weakness of the proposed approaches or theoretical results. However, the comment does not explicitly mention which part of the paper these issues are related to, making it weakly grounded. The specificity of the comment is moderate as it clearly specifies the issues that need to be addressed, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims about the paper, including the lack of clarity regarding the term $e_l$ in Eq. (3), the exponential dependence of the results on the diameter $M$ of the data domain, and the potential weakness of the proposed approaches or theoretical results. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of these claims and how they might impact their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific issues in the paper, such as the lack of clarity regarding the term $e_l$ in Eq. (3) and the exponential dependence of the results on the diameter $M$ of the data domain. It also points out a potential weakness in the proposed approaches or theoretical results, suggesting that the performance may be more quickly getting worse than standard random features. However, the comment lacks actionable guidance or suggestions on how the authors might address these issues or improve their work. Without specific recommendations or detailed feedback, the authors are left without a clear path forward, making the comment barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the authors' explanation of the poor long-range modelling ability of DGNs, suggesting that it might be due to oversmoothing in addition to oversquashing and vanishing/exploding gradients. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of their model or analysis need to be revised. The suggestion is implicit and lacks concrete details, making it difficult for the authors to understand how to implement the feedback. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the poor long-range modelling ability of DGNs, specifically mentioning oversquashing, vanishing/exploding gradients, and oversmoothing. It references a specific paper to support the claim about oversmoothing. However, the comment does not explicitly mention which part of the paper it is addressing, such as a specific section or figure. This makes it weakly grounded, as the authors may need to infer the part of the paper being discussed. The comment is specific in detailing the issue and suggesting an additional factor to consider, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact area of concern. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the poor long-range modelling ability of DGNs could be due to oversmoothing, in addition to oversquashing and vanishing/exploding gradients, referencing a specific paper. This claim is supported by logical reasoning and a reference to a relevant external source, making it mostly verifiable. The authors are provided with a clear explanation of the phenomenon and a reference to support their understanding, which helps them address the issue effectively. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential issue with the authors' explanation of the poor long-range modeling ability of DGNs, suggesting that it might be due to oversmoothing in addition to oversquashing and vanishing/exploding gradients. It references a specific paper to support the claim about oversmoothing, which provides a clear and actionable suggestion for the authors to consider. However, the comment could be more helpful if it offered additional guidance on how the authors might address this issue or what specific aspects of their model or analysis need to be revised. Overall, the feedback is somewhat helpful as it points out a potential area for improvement but lacks depth in terms of actionable advice. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the problem formulation is somewhat unclear in the statement and introduction examples. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit instructions or concrete advice on what needs to be done to clarify the problem formulation. As a result, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is weakly grounded as it does not specify which part of the paper the problem formulation is unclear in, making it difficult for the authors to identify the exact section that needs attention. However, it is specific in that it identifies the issue as the problem formulation being unclear in the statement and introduction examples. This provides a clear direction for the authors to focus on specific areas of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the problem formulation is somewhat unclear in the statement and introduction examples. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the problem formulation in the statement and introduction examples. However, it lacks specific details or suggestions on how the authors might address this issue. Without actionable guidance or examples, the authors may find it challenging to improve their draft. Therefore, the comment is barely helpful, as it points out a problem but does not provide sufficient assistance for the authors to make meaningful improvements.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of quantization grouping, specifically questioning why finer grouping was not considered instead of per-tensor and per-channel approaches. However, it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this question or what steps they should consider to improve their draft. Without specific advice or suggestions, the authors are left without a clear path to respond or improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the choice of quantization grouping, specifically questioning why finer grouping was not considered instead of per-tensor and per-channel approaches. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is vague and lacks specificity, as it does not provide any guidance or suggestions on how to address the question or what changes might be necessary. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the choice of quantization grouping, specifically questioning why finer grouping was not considered instead of per-tensor and per-channel approaches. However, it does not provide any claim, suggestion, or reasoning to support the question or offer any guidance on how to address it. The comment lacks any evidence or justification, making it unverifiable. Therefore, it is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of quantization grouping, specifically questioning why finer grouping was not considered instead of per-tensor and per-channel approaches. This question highlights a potential area for improvement in the paper, as it suggests that the authors might have overlooked a more detailed approach to quantization. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what changes could be made to enhance the paper. Without specific advice or recommendations, the authors are left without actionable feedback, making the comment somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"epsilon-greedy\" in the context of the training process described in Appendix D.2. It also suggests that the authors might be using epsilon-greedy exploration in addition to their proposed strategy. However, the comment does not provide explicit guidance on how the authors should clarify this point or address the potential use of epsilon-greedy exploration. The action is implicit, as the authors need to infer that they should clarify the meaning of \"epsilon-greedy\" and consider its implications for their strategy. The action is vague because it does not specify how to clarify the meaning or what aspects of the strategy need to be addressed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Just before Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"epsilon-greedy\" in the context of the training process and suggests that the authors might be using epsilon-greedy exploration in addition to their proposed strategy. This provides clear guidance on what needs to be clarified or addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the meaning of \"epsilon-greedy\" in the context of the training process described in Appendix D.2. It suggests that the authors might be using epsilon-greedy exploration in addition to their proposed strategy. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that epsilon-greedy exploration is being used. Without additional context or justification, the claim remains somewhat vague and lacks sufficient evidence for the authors to understand and address it effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the meaning of 'epsilon-greedy' in the context of the training process described in Appendix D.2. It also suggests that the authors might be using epsilon-greedy exploration in addition to their proposed strategy. However, the comment does not provide any guidance or clarification on how the authors should address this question or the implications of using epsilon-greedy exploration. While it identifies an area that needs clarification, it lacks actionable suggestions or detailed explanations, making it barely helpful. The authors are left without a clear path to improve their understanding or address the potential issue.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the applicability of dynamic precision control during training, suggesting that it might only show meaningful performance gains on bit-serial accelerators. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their methodology. The comment implies that the authors should consider the limitations of their approach in the context of existing ML accelerators that use bit-parallel fixed-point numbers. While the authors can infer that they need to discuss the implications of their methodology in this context, the lack of concrete suggestions or guidance makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the applicability of dynamic precision control during training, specifically mentioning bit-serial accelerators and the limitations of existing ML accelerators that use bit-parallel fixed-point numbers. However, it does not explicitly mention specific sections, tables, or figures of the paper that discuss these aspects. The authors can infer that the comment relates to the methodology or experimental setup, but without explicit references, the grounding is weak. The comment is specific in detailing the issue with dynamic precision control and its implications for existing accelerators. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the applicability of dynamic precision control during training, specifically questioning whether it might only show meaningful performance gains on bit-serial accelerators. It then suggests that most existing ML accelerators use bit-parallel fixed-point numbers, which might restrict the implications of the proposed methodology. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, and the lack of detailed evidence or examples weakens the verifiability of the claim. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a pertinent concern about the applicability of dynamic precision control during training, specifically questioning whether it might only show meaningful performance gains on bit-serial accelerators. It then suggests that most existing ML accelerators use bit-parallel fixed-point numbers, which could restrict the implications of the proposed methodology. This feedback highlights a potential limitation or area for further exploration, providing the authors with a clear direction for consideration. However, the comment could be more helpful if it offered suggestions on how to address this issue or how to expand the methodology to accommodate bit-parallel accelerators. Overall, the comment is somewhat helpful as it identifies a significant point that needs attention, but it lacks depth and actionable guidance, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the clarity of Eq. 12, specifically regarding the source of the reward at each trial and whether it is derived from Eq. 11. It suggests that explaining the network model in Sec. 4.2 with equations would enhance clarity. However, the comment does not provide explicit guidance on how to address these issues or what specific changes should be made to the paper. The action is implicit, as the authors would need to infer that they should clarify the source of the reward and provide more detailed explanations of the network model. While the comment is somewhat actionable, it lacks concrete details on how to implement the suggested improvements, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the clarity of Eq. 12, specifically regarding the source of the reward at each trial and whether it is derived from Eq. 11. It suggests that explaining the network model in Sec. 4.2 with equations would enhance clarity. However, the comment does not specify which part of the paper the authors should focus on, making it weakly grounded. The comment is specific in its request for clarification and suggestions, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the clarity of Eq. 12 and suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. However, the comment does not provide specific examples, detailed reasoning, or references to support these claims. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely Eq. 12, where the source of the reward at each trial is unclear. It also suggests that explaining the network model in Sec. 4.2 with equations would enhance clarity. However, the comment lacks detailed guidance on how to address these issues or what specific changes should be made to the paper. While it points out areas for improvement, it does not provide actionable steps or detailed suggestions, making it somewhat helpful. The feedback is somewhat helpful as it highlights areas that need clarification, but it could be more comprehensive with additional guidance on how to improve the clarity of the equations and the network model explanation.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the novelty of the idea is not enough and that both the new metric and method are straightforward. However, it does not provide any specific guidance or suggestions on how the authors might address these issues or improve the novelty of their work. The comment lacks actionable steps or concrete advice, leaving the authors without a clear path to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the novelty of the idea is not enough and that both the new metric and method are straightforward. However, it does not specify which part of the paper discusses the novelty or the new metric/method, making it difficult for the authors to identify the exact sections that need attention. The comment is not grounded as it does not provide specific references or sections, and it is also not specific because it does not detail what aspects of the novelty or methods are lacking. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the idea is not enough and that both the new metric and method are straightforward. However, the comment lacks specific details or examples to support this claim. It does not provide any references or evidence to substantiate the assertion that the novelty is insufficient or that the methods are straightforward. Without such evidence, the claim remains unsubstantiated and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the novelty of the idea and suggests that both the new metric and method are straightforward. While it points out a concern about the novelty, it does not provide specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their work. The comment lacks actionable advice and detailed feedback, making it somewhat helpful as it highlights an area for improvement but does not offer a comprehensive solution. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model description could be improved by presenting the generative process in separate steps, which would enhance understanding. It also notes that the use of many symbols and a notation table could be better. However, the comment does not provide explicit guidance on how to implement these suggestions, such as specific steps or examples. The action is implicit and somewhat vague, as the authors are left to infer how to improve the model description. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the model description, specifically mentioning the need to present the generative process in separate steps for better understanding and the use of many symbols and a notation table. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs attention. The comment is specific in its suggestions for improvement, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the model description could be improved by presenting the generative process in separate steps and by using a notation table. However, the comment does not provide specific examples, reasoning, or references to support these suggestions. Without detailed justification or evidence, the claim remains somewhat verifiable, as the authors may find it challenging to understand the basis for the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies areas for improvement in the model description, specifically suggesting that presenting the generative process in separate steps could enhance understanding and that using a notation table could improve clarity. While the feedback is somewhat specific, it lacks detailed guidance on how to implement these suggestions or examples of how the model description could be improved. The comment provides a clear direction for improvement but could be more helpful if it offered specific examples or detailed instructions. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could do better by first motivating the \"why\" behind the research. However, it does not provide explicit guidance on how to motivate the \"why\" or what specific aspects of the paper need to be addressed to improve the motivation. The action is implicit and vague, as it does not specify how to motivate the \"why\" or what elements of the paper should be revised. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper could do better by first motivating the \"why\" behind the research. However, it does not specify which part of the paper this motivation should be included in, making it weakly grounded. The comment is specific in its suggestion to motivate the \"why,\" but without clear guidance on where to apply this motivation, the authors may struggle to understand how to improve their draft. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could do better by first motivating the \"why\" behind the research. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper could be improved by first motivating the \"why\" behind the research, which is a valuable piece of feedback. However, the comment lacks specificity and does not provide detailed guidance on how to motivate the \"why\" or what aspects of the paper need to be addressed. While it identifies a potential area for improvement, it does not offer actionable steps or examples, making it somewhat helpful. The authors may gain some insight into the importance of motivation but would need additional guidance to implement the suggestion effectively. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with the proposed approach, noting that it does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also points out that the trade-off between head and tail categories has not been fully investigated for the baselines, suggesting that Decouple [Kang et al.] could potentially improve tail accuracy with hyperparameter adjustments. The comment encourages the authors to continue this line of work for future submission. However, the action is implicit, as the authors are not explicitly instructed to investigate the trade-off for baselines or to adjust hyperparameters. The comment lacks concrete guidance on how to address these issues, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"3)\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance, and that a similar trade-off has not been fully investigated for the baselines. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance, and that a similar trade-off between head and tail categories has not been fully investigated for the baselines. The comment suggests that by adjusting hyperparameters in Decouple [Kang et al.], the performance could be improved. However, the claim lacks specific examples or detailed reasoning to fully support the assertion, making it somewhat verifiable. The authors would need to provide more evidence or examples to fully understand and address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the proposed approach, noting that it does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also highlights a trade-off between head and tail categories that has not been fully investigated for the baselines, suggesting that Decouple [Kang et al.] could potentially improve tail accuracy with hyperparameter adjustments. This feedback is clear and actionable, providing the authors with specific areas for improvement and encouraging them to continue their work. However, the comment could be more helpful if it offered more detailed guidance on how to address the identified issues or suggested specific experiments to conduct. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the evaluation of weak supervision could be improved by considering the realism of the evaluated tweets. It provides specific examples, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the issue with the generation of authors being initialized by averaging artificial tweets. However, the comment does not explicitly instruct the authors to address these issues or provide guidance on how to improve the realism of their evaluations. The action is implicit and somewhat vague, as the authors are left to infer what needs to be done. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluation of weak supervision, specifically mentioning the realism of the evaluated tweets and the generation of authors. It provides specific examples, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the issue with \"author embeddings being initialized by averaging the corresponding artificial tweets.\" However, the comment does not explicitly mention which part of the paper this issue pertains to, making it weakly grounded. The specificity is good as it clearly specifies what needs to be addressed, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation of weak supervision could be better evaluated by considering the realism of the evaluated tweets. It provides specific examples, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the issue with \"author embeddings being initialized by averaging the corresponding artificial tweets.\" However, the comment lacks detailed reasoning or references to support these claims, making it difficult for the authors to fully understand and address the issue. The feedback is somewhat verifiable as it provides some justification but lacks depth and specific examples to guide the authors in improving their evaluation process. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets and the generation of authors. It provides specific examples, such as the requirement for 'all of the structured elements for perspectives to be present in the generated tweets' and the issue with 'author embeddings being initialized by averaging the corresponding artificial tweets.' However, the comment lacks detailed guidance or suggestions on how to address these concerns or improve the realism of the evaluation. While it highlights an important aspect of the evaluation process, the feedback could be more helpful if it provided actionable steps or examples for the authors to consider. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not offer comprehensive guidance.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their proposed model with existing models that use answers as inputs, such as the one mentioned in the paper \"Revisiting Visual Question Answering Baselines\" by Jabri et al. (ECCV16). However, the comment does not provide explicit guidance on how to conduct this comparison or what specific aspects of the comparison should be highlighted. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to implement the suggested comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed model with existing models that use answers as inputs, referencing a specific paper. This provides full grounding as the authors can accurately identify the section or paper being mentioned. The comment is also specific because it clearly specifies the comparison to be made, which is with existing models that use answers as inputs. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests comparing the proposed model with existing models that use answers as inputs, such as the one mentioned in the paper \"Revisiting Visual Question Answering Baselines\" by Jabri et al. (ECCV16). This claim is somewhat verifiable as it provides a specific reference to a relevant work that could be used for comparison. However, the comment lacks detailed reasoning or examples to fully support the suggestion, making it somewhat verifiable. The authors would need to infer the exact nature of the comparison to fully understand the implications of the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests comparing the proposed model with existing models that use answers as inputs, such as the one mentioned in the paper \"Revisiting Visual Question Answering Baselines\" by Jabri et al. (ECCV16). This feedback is somewhat helpful as it identifies a potential area for comparison that could enhance the paper's contribution. However, the comment lacks specific guidance on how to conduct this comparison or what aspects of the comparison should be highlighted. The authors are left to infer the exact steps needed to implement the suggested comparison, which limits the feedback's impact. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the design choice of trimming questions after the first 10, particularly in the context of a bag-of-words question model. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to the model or the question-answering process. The comment lacks concrete guidance on how to implement or improve the model, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies what the authors should consider regarding the design choice of trimming questions, particularly in the context of a bag-of-words question model. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the design choice of trimming questions after the first 10, particularly in the context of a bag-of-words question model. While the reviewer provides a rationale for why this choice might be odd, the comment lacks specific examples or references to support the claim. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it is based on logical reasoning but could benefit from more detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific design choice in the paper, namely the decision to trim questions after the first 10, and questions its oddness, particularly in the context of a bag-of-words question model. This feedback is somewhat helpful as it highlights a potential issue with the design choice and prompts the authors to consider the implications of this decision. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this issue or improve their model. Without actionable advice, the authors may struggle to fully understand the implications of the comment and how to respond effectively. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks for clarification on the meaning of a specific term in Equation (2). While it does not explicitly instruct the authors to provide this clarification, it implies that they should explain the term to ensure the reader understands the equation. However, the action is implicit and somewhat vague, as the authors are not given specific guidance on how to clarify the term. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper the authors should focus on. It raises a question about the meaning of a term in Equation (2), but without any context or reference to a specific section, the authors cannot determine which part of the paper is being addressed. The comment is also not specific, as it does not provide any guidance or suggestions on how to clarify the term. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the meaning of a specific term in Equation (2). It does not contain a claim or assertion that requires verification. The comment is factual and descriptive, as it seeks clarification on a technical detail within the paper. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of a specific term in Equation (2), which could be helpful for the authors to clarify and ensure that the equation is understandable to the readers. However, the comment does not provide any suggestions or guidance on how to address this issue, nor does it offer any additional context or explanation. As a result, while it identifies a potential area for improvement, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific instances where elements of the paper, such as lines and references, are incorrectly colored or labeled. It provides explicit instructions for correction, such as moving lines to green SuppMat and updating references to match the correct sections or tables. The actions are clear and concrete, allowing the authors to directly apply the feedback. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (L502, L507, L509) in the paper that need correction. It also specifies the actions to be taken, such as changing the color of lines and references to match the correct sections or tables. This provides clear guidance for the authors to address the issue. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is factual and descriptive, detailing specific instances where elements in the paper are incorrectly colored or labeled. It does not contain any subjective opinions or claims that require verification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific instances where elements in the paper, such as lines and references, are incorrectly colored or labeled. It provides clear instructions for correction, such as moving lines to green SuppMat and updating references to match the correct sections or tables. This feedback is actionable and constructive, as it directly points out areas that need attention and offers specific guidance for improvement. However, the comment could be more comprehensive by suggesting additional improvements or clarifications. Overall, it is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that important references are missing, specifically mentioning GFF[1] and EfficientFCN[2]. It encourages the authors to include a comprehensive comparison with these works. The comment provides a clear action for the authors to take, which is to add these references and conduct a comparison. However, it does not specify how to implement this action, such as which sections of the paper should be compared or what specific aspects of the comparison are needed. While the action is explicit, it lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific references, GFF[1] and EfficientFCN[2], which are relevant to the paper. It also specifies what needs to be addressed by encouraging a comprehensive comparison with these works. The comment is specific in detailing the need for a comparison and mentions the societal impact, providing clear guidance for the authors. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that important references are missing, specifically mentioning GFF[1] and EfficientFCN[2]. It encourages the authors to include a comprehensive comparison with these works. However, the comment lacks specific examples or detailed reasoning to support the claim that these references are indeed important or missing. Without additional context or justification, the authors may find it challenging to understand why these references are crucial. Therefore, the claim is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient evidence or detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper by pointing out the absence of important references, specifically mentioning GFF[1] and EfficientFCN[2]. It encourages the authors to include a comprehensive comparison with these works, which is a valuable suggestion for enhancing the paper's context and relevance. However, the comment could be more helpful if it provided more detailed guidance on how to conduct this comparison or what aspects of the comparison are essential. Despite this, the feedback is mostly helpful as it directs the authors towards a crucial improvement that could strengthen their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practical performance of the proposed algorithms, specifically Algorithm 1, which uses a Vandermonde matrix known to be ill-conditioned and numerically unstable, especially for large $n$ and small $\\alpha$. The reviewer expresses concern that the algorithm may fail in practice even for moderate sizes of $n$, $k$, and $L$. The comment suggests that the paper would be more convincing if the authors provided experimental results for the proposed algorithms. However, the comment does not explicitly instruct the authors to provide these results or offer any guidance on how to conduct the experiments. The action is implicit and somewhat vague, as the authors are left to infer that they need to include experimental results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and discusses the specific issue with the Vandermonde matrix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concern about the ill-conditioned and numerically unstable nature of the Vandermonde matrix, especially for large $n$ and small $\\alpha$, and suggests providing experimental results to address this concern. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the practical performance of the proposed algorithms, specifically Algorithm 1, which uses a Vandermonde matrix known to be ill-conditioned and numerically unstable, especially for large $n$ and small $\\alpha$. The reviewer expresses concern that the algorithm may fail in practice even for moderate sizes of $n$, $k$, and $L$. The comment suggests that the paper would be more convincing if the authors provided experimental results for the proposed algorithms. However, the comment lacks specific examples or references to support the claim about the ill-conditioned nature of the Vandermonde matrix and its impact on the algorithm's performance. While the reasoning is logical, the absence of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the practical performance of the proposed algorithms, specifically Algorithm 1, which uses a Vandermonde matrix known to be ill-conditioned and numerically unstable. The reviewer provides a detailed explanation of why this could be a problem, especially for large values of $n$ and small values of $\\alpha$. The comment suggests that the paper would be more convincing if the authors provided experimental results to address this concern. However, the feedback lacks specific guidance on how to conduct these experiments or what kind of results would be most convincing. While the comment identifies a significant issue, it does not offer detailed suggestions or actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions how this method can be learned and applied to large-scale datasets, such as ImageNet, and suggests that the practical contribution of the paper might be reduced without addressing this issue. While the comment identifies a potential problem and suggests a direction for improvement, it does not provide explicit guidance on how to address the scalability issue or what specific solutions might be effective. The action is implicit and somewhat vague, as the authors are left to infer the need for addressing scalability and the potential solutions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions how this method can be learned and applied to large-scale datasets, such as ImageNet, and suggests that the practical contribution of the paper might be reduced without addressing this issue. However, the comment does not specify which part of the paper discusses the proposed NC measure or the scalability issue, making it difficult for the authors to pinpoint the exact section to address. While the comment is specific about the issue of scalability, it lacks grounding as it does not provide clear references to the relevant sections or parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions how this method can be learned and applied to large-scale datasets, such as ImageNet, and suggests that the practical contribution of the paper might be reduced without addressing this issue. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim about the scalability issue. The lack of evidence or justification makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions how this method can be learned and applied to large-scale datasets, such as ImageNet, and suggests that the practical contribution of the paper might be significantly reduced without addressing this issue. While the comment identifies a potential limitation, it does not provide specific guidance or suggestions on how to address the scalability issue or what solutions might be effective. This feedback is somewhat helpful as it highlights a significant concern that needs to be addressed, but it lacks actionable advice or detailed suggestions, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It points out that the comparison of computational complexity is expected in the experiment part. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to improve the method. The action is implicit, as the authors need to infer that they should compare the computational complexity of their method with the baselines. While the action is somewhat vague, it is clear that the authors need to address the computational complexity issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the computational complexity of the proposed PSA method, specifically mentioning that it requires more computation than baselines. It also notes that the comparison of computational complexity is expected in the experiment part. However, the comment does not specify which part of the paper discusses the algorithm or the experimental setup, making it weakly grounded. The comment is specific in identifying the issue with the computational complexity of the PSA method, but without explicit references to sections or figures, the authors may need to infer which parts to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed PSA method requires more computation than baselines, specifically noting that it involves calculating all previous layer outputs in the current layer. The comment suggests that a comparison of computational complexity is expected in the experiment part. However, the comment lacks specific details or examples to substantiate this claim, making it difficult for the authors to verify the assertion. Without further elaboration or evidence, the claim remains somewhat verifiable, as it is based on a logical deduction but lacks sufficient support. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It highlights that the comparison of computational complexity is expected in the experiment part, which is a relevant point for the authors to consider. However, the comment lacks detailed guidance on how the authors might address this issue or what specific steps they should take to improve the method. While it points out a potential area for improvement, it does not provide actionable advice or suggestions for enhancing the draft. Therefore, the comment is somewhat helpful, as it identifies a weakness but does not offer comprehensive guidance for improvement.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment provides several specific suggestions for improving the figures, such as increasing the font size of labels and text in figures 1 and 2, and suggesting that the words in the grey box be larger. It also points out that the font sizes for V_mem, Th_i, and U_i^t are too small. Additionally, the comment suggests that the \"CTRL\" long form explanation be included. The reviewer also notes the lack of details comparison, such as epochs and number of parameters, with other state-of-the-art Transformer designs, and suggests that a \"table\" manner might better emphasize the data for readers to justify the improved accuracy. These suggestions are explicit and provide clear guidance on how the authors should improve their draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment provides specific suggestions for improving the figures, such as increasing the font size of labels and text in figures 1 and 2, and suggests that the words in the grey box be larger. It also points out that the font sizes for V_mem, Th_i, and U_i^t are too small. Additionally, the comment suggests that the \"CTRL\" long form explanation be included. The reviewer also notes the lack of details comparison, such as epochs and number of parameters, with other state-of-the-art Transformer designs, and suggests that a \"table\" manner might better emphasize the data for readers to justify the improved accuracy. These suggestions are explicit and provide clear guidance on how the authors should improve their draft, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point provides specific suggestions for improving the figures, such as increasing the font size of labels and text in figures 1 and 2, and suggests that the words in the grey box be larger. It also points out that the font sizes for V_mem, Th_i, and U_i^t are too small. Additionally, the comment suggests that the \"CTRL\" long form explanation be included. The reviewer also notes the lack of details comparison, such as epochs and number of parameters, with other state-of-the-art Transformer designs, and suggests that a \"table\" manner might better emphasize the data for readers to justify the improved accuracy. These suggestions are explicit and provide clear guidance on how the authors should improve their draft, making the comment fully verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the figures, such as increasing the font size of labels and text in figures 1 and 2, and suggests that the words in the grey box be larger. It also points out that the font sizes for V_mem, Th_i, and U_i^t are too small. Additionally, the comment suggests that the \"CTRL\" long form explanation be included. The reviewer also notes the lack of details comparison, such as epochs and number of parameters, with other state-of-the-art Transformer designs, and suggests that a \"table\" manner might better emphasize the data for readers to justify the improved accuracy. These suggestions are clear and actionable, providing the authors with specific guidance on how to enhance their draft. However, the comment could be more helpful if it included more detailed explanations or examples of how to implement these suggestions. Overall, the feedback is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed method should be compared to \"ATA\" in Table 2, as it was shown to be better than \"FP\" in Table 1. This provides a clear and explicit action for the authors to take, which is to include \"ATA\" in the comparison. The comment is specific and concrete, as it directly instructs the authors on what needs to be done to strengthen the comparison. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and the specific setting \"leave one out,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the comparison of the proposed method to \"ATA\" in the context of the \"leave one out\" setting. This provides a clear and actionable direction for the authors to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the proposed method should be compared to \"ATA\" in Table 2, as \"ATA\" was shown to be better than \"FP\" in Table 1. This claim is somewhat verifiable as it provides a logical reasoning based on the results in Table 1 to justify the suggestion. However, it lacks specific examples or references to support the claim fully, which could make it less convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper by suggesting that the proposed method should be compared to \"ATA\" in Table 2. This is based on the observation that \"ATA\" was shown to be better than \"FP\" in Table 1. The comment provides a clear and actionable suggestion for the authors to enhance the comparison and strengthen the results section. By including \"ATA\" in the comparison, the authors can provide a more comprehensive and convincing evaluation of their method. This feedback is mostly helpful as it offers a specific and constructive suggestion for improvement, though it could be further elaborated to provide additional context or rationale. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the lack of mathematical definition for architectural details, specifically mentioning multi-head attention. It also questions the clarity of Figure 2, particularly the split arrow in the bottom right, and asks for clarification on whether the same vectors are used for keys and values. While the comment explicitly suggests that a formal definition would help readers understand the architecture, it does not provide specific guidance on how to implement this suggestion, such as suggesting a particular notation or explanation. The action is clear and explicit, but it lacks concrete details on how to address the issue, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses architectural details and questions about multi-head attention, specifically mentioning the split arrow in Figure 2. It provides a clear reference to a specific part of the paper, making it fully grounded. The comment is also specific, as it details the issue with the lack of mathematical definition and asks for clarification on the use of keys and values in the attention layer. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the clarity of the architectural details, specifically regarding multi-head attention and the split arrow in Figure 2. It suggests that a formal definition would help readers understand the architecture. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the lack of mathematical definition is a significant issue. The feedback is somewhat verifiable as it points out a potential area for improvement but lacks detailed justification or evidence. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies specific areas where the paper could be improved, particularly in the lack of mathematical definitions for architectural details like multi-head attention. It also raises questions about the clarity of Figure 2, specifically the split arrow in the bottom right, and asks for clarification on whether the same vectors are used for keys and values. This feedback is mostly helpful as it provides clear suggestions for improvement, such as adding a formal definition of multi-head attention and clarifying the use of keys and values in the attention layer. However, it could be more helpful if it included additional guidance on how to implement these suggestions or provided examples of how to improve the clarity of the figures. Overall, the comment is mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses difficulty in following the presentation of the paper but does not provide any specific guidance or suggestions on how to improve the clarity or organization of the presentation. Without explicit instructions or concrete advice, the authors are left without a clear path to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses difficulty in following the presentation of the paper but does not specify which part of the paper is hard to follow. It lacks grounding as the authors cannot determine which section or aspect of the paper is causing the issue. Additionally, the comment does not provide specific details or suggestions for improvement, making it under-specific. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses difficulty in following the presentation of the paper, but it does not provide any specific claims, opinions, or suggestions for improvement. It lacks detailed reasoning, examples, or references to support the claim. As a result, the comment is classified as \"No\" because it does not contain a claim that requires verification.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment expresses difficulty in following the presentation of the paper, which is a valid concern for authors. However, it lacks specificity and actionable advice on how to improve the clarity or organization of the presentation. Without detailed suggestions or guidance, the authors may struggle to address the issue effectively. Therefore, the comment is barely helpful, as it identifies a problem but does not provide sufficient assistance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the work should include and compare to specific related works, such as Li et al. (2017) and He et al. (2015), at least conceptually. It also recommends a discussion on how the work differs from other chatbox research works. However, the comment does not provide explicit guidance on how to incorporate these comparisons or discussions into the paper. The action is implicit, as the authors would need to infer that they should add these comparisons and discussions, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including and comparing to specific related works, such as Li et al. (2017) and He et al. (2015), at least conceptually, and to discuss how the work differs from other chatbox research works. However, the comment does not specify which part of the paper these comparisons or discussions should be included in, making it weakly grounded. It is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to identify the exact sections to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the work should include and compare to specific related works, such as Li et al. (2017) and He et al. (2015), at least conceptually, and to discuss how the work differs from other chatbox research works. However, the comment lacks specific examples or detailed reasoning to support why these comparisons are necessary or how they would enhance the paper. Without clear justification or references, the claim is difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for improvement but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies the need to include and compare the work to specific related studies, such as Li et al. (2017) and He et al. (2015), at least conceptually. It also suggests a discussion on how the work differs from other chatbox research works. This feedback is clear and actionable, as it provides specific examples of works that should be included for comparison and discussion. By addressing these points, the authors can enhance the depth and relevance of their paper, making it more comprehensive and impactful. Therefore, the comment is mostly helpful, as it offers clear guidance on what needs to be added to improve the draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should clarify the difference between the meta solvers and centralized RL, where agents share weights. It provides a specific example, citing Foester et al., to illustrate the concept. However, the comment does not explicitly instruct the authors on how to clarify this difference or what specific aspects of the paper need to be addressed. While the suggestion is clear, the lack of explicit guidance on implementation makes it somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should clarify the difference between meta solvers and centralized RL, where agents share weights. It provides a specific example, citing Foester et al., to illustrate the concept. However, the comment does not specify which part of the paper discusses meta solvers or centralized RL, making it difficult for the authors to pinpoint the exact section that needs clarification. While the suggestion is specific about the content to be clarified, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should clarify the difference between meta solvers and centralized RL, where agents share weights, and provides a specific example by citing Foester et al. This claim is somewhat verifiable as it offers a clear suggestion and a reference to support the idea. However, it lacks detailed reasoning or examples beyond the cited work, which could enhance the clarity and persuasiveness of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for clarification in the paper, namely the distinction between meta solvers and centralized RL where agents share weights. It provides a clear suggestion to include a discussion of this difference, which could enhance the paper's clarity and depth. However, the comment lacks specific guidance on how to implement this clarification or what aspects of the paper need to be addressed. While it offers a valuable suggestion, the lack of detailed instructions limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the phrase \"non-sequential information such as chunks\" and asks for clarification on whether chunks are still sequential information. While the comment identifies a specific point of confusion, it does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit, as the authors need to infer that they should clarify the meaning of \"chunks\" in the context of the paper. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it directly questions the clarity of the phrase \"non-sequential information such as chunks\" and asks for clarification on whether chunks are still sequential information. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the phrase \"non-sequential information such as chunks\" and asks for clarification on whether chunks are still sequential information. This is a subjective question that seeks clarification rather than making a claim that requires verification. The comment does not provide any evidence, reasoning, or references to support the question, making it a normal statement. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the phrase \"non-sequential information such as chunks,\" asking for clarification on whether chunks are still considered sequential information. This feedback is clear and actionable, as it identifies a point of confusion in the paper and prompts the authors to clarify their terminology. By addressing this question, the authors can improve the clarity and precision of their writing, making the paper easier to understand. The comment is specific and provides a clear direction for improvement, making it mostly helpful. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or just masked versions. It suggests that if the output patches are indeed masked versions, Figure 1 is misleading. The comment also proposes that zooming on the region of interest using bilinear sampling could provide better results. However, the comment does not explicitly instruct the authors to address this discrepancy or provide specific guidance on how to revise the figure or equation to align with the proposed solution. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the discrepancy and potentially update the figure and equation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or just masked versions. It suggests that if the output patches are indeed masked versions, Figure 1 is misleading and proposes that zooming on the region of interest using bilinear sampling could provide better results. However, the comment does not specify which part of the paper contains the equation or figure, making it weakly grounded. It is specific in detailing the issue and suggesting a potential solution, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the discrepancy between equation 9 and Figure 1, specifically questioning whether the output patches are cropped parts of the input image or just masked versions. It suggests that if the output patches are indeed masked versions, Figure 1 is misleading and proposes that zooming on the region of interest using bilinear sampling could provide better results. However, the comment lacks specific examples or detailed reasoning to fully support the claim that the output patches are masked versions. While the suggestion for improvement is clear, the lack of detailed justification or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between equation 9 and Figure 1, specifically questioning whether the output patches are cropped parts of the input image or just masked versions. It suggests that if the output patches are indeed masked versions, Figure 1 is misleading and proposes that zooming on the region of interest using bilinear sampling could provide better results. This feedback is clear and actionable, as it points out a specific issue that needs clarification and suggests a potential improvement. However, the comment could be more helpful if it provided more detailed guidance on how to address the discrepancy or how to revise the figure and equation to align with the proposed solution. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the limited technical novelty of the paper, suggesting that it is similar to previous works that focus on graph-based approaches, co-attention mechanisms, and architectures. However, it does not provide explicit guidance on how the authors might address this issue or what specific aspects of the paper could be improved to enhance its novelty. The comment lacks concrete suggestions or actionable steps for the authors to take, making it difficult for them to understand how to respond or improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the two papers, Xing and Tsang, 2022a, b, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of limited technical novelty and suggests that the paper is similar to previous works in terms of idea, co-attention mechanism, and architecture. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper has limited technical novelty, as it is similar to previous works focusing on graph-based approaches, co-attention mechanisms, and architectures. However, the comment lacks specific examples or detailed comparisons to substantiate this claim. Without concrete evidence or references, the authors may find it challenging to understand the basis of the criticism and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the limited technical novelty compared to previous works. It highlights that the paper is similar to previous studies that focus on graph-based approaches, co-attention mechanisms, and architectures. This feedback is valuable as it points out a potential area for improvement, suggesting that the authors need to differentiate their work more effectively from existing literature. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue, such as by introducing novel techniques or applications. Overall, the comment is somewhat helpful as it identifies a critical weakness but lacks actionable advice, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of fair comparison between CPEF and PMEF in Figure 3, specifically noting that PMEF lacks a pre-training module. The comment suggests that a fair comparison would involve comparing CPEF with another pre-trained model, such as ExpertBert, to showcase the advantage of CPEF\\\\'s innovative pre-training module design. This feedback provides a clear and explicit action for the authors to take, which is to include a comparison with a pre-trained model like ExpertBert. The action is concrete, as it specifies exactly what needs to be done to ensure a fair comparison. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and the comparison between CPEF and PMEF, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of a lack of fair comparison and suggests a concrete solution by recommending a comparison with another pre-trained model, ExpertBert. This provides the authors with clear guidance on how to improve the fairness of their comparison. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison between CPEF and PMEF in Figure 3 is unfair because PMEF lacks a pre-training module, which is a valid concern. The comment suggests that a fair comparison would involve comparing CPEF with another pre-trained model, such as ExpertBert. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the reasoning and potentially seek additional evidence to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the fairness of the comparison between CPEF and PMEF in Figure 3. It points out that PMEF lacks a pre-training module, making the comparison unfair. The comment suggests that a fair comparison would involve comparing CPEF with another pre-trained model, such as ExpertBert, to showcase the advantage of CPEF\\\\'s innovative pre-training module design. This feedback is clear, actionable, and provides a specific suggestion for improvement, which would help the authors enhance the fairness and comprehensiveness of their comparison. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the paper for using only two attack methods, suggesting that other classical attack methods in NLP could be considered. However, it does not provide explicit guidance on which other methods should be included or how they might impact the results. The comment implies that the authors should consider expanding their evaluation to include a broader range of attack methods, but it lacks concrete suggestions or detailed instructions on how to do so. As a result, the authors are left with a vague idea of what to improve, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the paper for using only two attack methods, suggesting that other classical attack methods in NLP could be considered. However, it does not specify which other methods should be included or why they are relevant. The comment lacks grounding as it does not mention specific sections, tables, or figures of the paper that address the issue. It is also not specific because it does not provide detailed reasoning or examples of why other attack methods should be considered. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point critiques the paper for using only two attack methods, suggesting that other classical attack methods in NLP could be considered. However, it does not provide specific examples or references to support the claim that these other methods are not suitable or relevant. The comment lacks detailed reasoning or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered borderline verifiable, as it provides some basis but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment critiques the paper for using only two attack methods, suggesting that other classical attack methods in NLP could be considered. While it identifies a potential limitation in the evaluation, it does not provide specific guidance on which other methods should be included or how they might impact the results. The comment lacks depth and actionable suggestions, making it somewhat helpful. The authors are left with a general idea of what to improve but without concrete steps to follow. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific questions regarding the relationship between temperature calibration and uncertainty calibration, particularly concerning the regularization term H. It asks for clarification on why temperature calibration is applied after training, given that the regularization term H requires it, and questions the motivation for reducing entropy, which is already overconfident. While the comment explicitly asks for clarification, it does not provide concrete guidance on how the authors should address these questions or what specific actions they should take. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses specific issues related to uncertainty calibration and the regularization term H, referencing lines 155-160 and 133-136. It provides detailed questions and suggestions for clarification, making it fully grounded as it explicitly mentions the sections of the paper being discussed. The comment is also specific, as it clearly outlines the confusion regarding the application of temperature calibration after training and the motivation for reducing entropy, which are key aspects of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the relationship between temperature calibration and uncertainty calibration, specifically regarding the regularization term H. It asks for clarification on why temperature calibration is applied after training, despite the regularization term requiring it, and questions the motivation for reducing entropy, which is already overconfident. While the questions are logical and based on the paper's content, they do not provide specific examples or references to support the claims. The comment lacks detailed reasoning or evidence, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises two specific questions about the relationship between temperature calibration and uncertainty calibration, particularly concerning the regularization term H. It points out a potential confusion in the paper regarding the application of temperature calibration after training, given that the regularization term requires it. Additionally, it questions the motivation for reducing entropy, which is already overconfident, as stated in lines 133-136. The comment is clear and actionable, as it identifies specific areas of confusion and suggests that the authors clarify these points. By addressing these questions, the authors can improve the clarity and coherence of their paper. Therefore, the comment is mostly helpful, as it provides clear guidance on how to enhance the draft.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missing reference related to the concept of unrolling, specifically mentioning \"Lista\" and providing a link to the paper. It suggests that the paper should discuss the similarities and differences between the proposed work and Lista, placing it in the appropriate context. However, the comment does not provide explicit guidance on how to incorporate this discussion or where to add it in the draft. The action is implicit, as the authors need to infer that they should include a discussion of the missing reference and its relevance to their work. The lack of concrete instructions on how to implement this suggestion makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"unrolling\" and provides a link to a specific paper, \"Lista,\" which is relevant to the topic. It also specifies what needs to be addressed by discussing the similarities and differences between the proposed work and Lista, placing the paper in the appropriate context. This provides clear guidance on which part of the paper should be addressed and what specific issues need to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that an important reference is missing, specifically mentioning \"Lista\" and providing a link to the paper. It suggests that the paper should discuss the similarities and differences between the proposed work and Lista, placing it in the appropriate context. However, the comment lacks specific examples or detailed reasoning to support the claim that the paper is closely related to the idea of unrolling and that the omission of this reference is significant. Without additional context or evidence, the claim is difficult to verify, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out a missing reference that is closely related to the core idea of unrolling, specifically mentioning \"Lista.\" It provides a link to the relevant paper, which is helpful for the authors to understand the context and relevance of their work. However, the comment could be more helpful if it suggested how the authors should incorporate this discussion into their paper or provided guidance on the specific aspects of the paper that need to be addressed. While it offers a clear direction for improvement, the feedback is somewhat limited in its depth and actionable guidance, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and concerns about the clarity of Algorithm 2, specifically regarding the computation of 'avg' and the use of variables j' and i''. It suggests that the authors should clarify these aspects to improve the understanding of the algorithm. While the comment explicitly asks for clarification, it does not provide concrete guidance on how to address these issues or what specific changes should be made to the algorithm. The action is implicit, as the authors need to infer that they should clarify the algorithm and address the specific questions raised. However, the lack of detailed guidance on how to implement these changes makes the comment somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the clarity of Algorithm 2, specifically regarding the computation of \"avg\" and the use of variables j\\' and i\\'. However, it does not specify which part of the paper Algorithm 2 is located in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but without explicit grounding, the authors may find it challenging to pinpoint the exact section to focus on. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the clarity of Algorithm 2, specifically regarding the computation of \"avg\" and the use of variables j\\' and i\\'. While the comment suggests that the authors should clarify these aspects, it does not provide any specific examples, references, or detailed reasoning to support the claim that the algorithm is unclear or that the variables are not used. The feedback is somewhat verifiable as it points out potential issues but lacks depth and specificity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises concerns about the clarity of Algorithm 2, specifically questioning the computation of 'avg' and the use of variables j' and i'. It suggests that the authors should clarify these aspects to improve the understanding of the algorithm. While the comment identifies a potential area for improvement, it lacks detailed guidance on how to address these issues or what specific changes should be made to the algorithm. The feedback is somewhat helpful as it points out a need for clarification, but it does not provide actionable steps or suggestions for improvement, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to state how they handle comparisons between episodes with different lengths, providing a clear and concrete action to take. It also highlights a specific issue with the lack of a normalization factor in the distance calculation, which could bias the results towards longer trajectories. The comment is fully grounded as it directly references the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. The action is explicit and concrete, providing detailed guidance on how to implement the suggested changes. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with how comparisons between episodes with different lengths are handled, including the method used (padding) and the potential bias introduced by the lack of a normalization factor. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is classified as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should state how they handle comparisons between episodes with different lengths, specifically mentioning that the authors pad shorter sequences by replicating their last state. It also highlights a potential issue with the lack of a normalization factor of 1/T, which could bias the results towards longer trajectories. The comment provides specific details about the method used and the potential bias, making it mostly verifiable. However, it could be strengthened by including examples or references to support the claim about the bias. Overall, the comment is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback on a critical aspect of the paper. It identifies a potential issue with how comparisons between episodes with different lengths are handled, noting that the authors pad shorter sequences by replicating their last state. The comment also points out a potential bias introduced by the lack of a normalization factor of 1/T, which could favor longer trajectories. This feedback is valuable as it directs the authors to clarify their methodology and address a potential issue that could affect the validity of their results. The comment is clear, concise, and provides detailed guidance on how the authors can improve their draft, making it highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the figures, including their readability, the clarity of the text, the explanation of inputs and outputs, and the self-contained nature of the captions. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment lacks guidance on how the authors might improve the figures, such as suggesting specific changes or providing examples of how to enhance readability. Without concrete suggestions or actionable steps, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig.1 to Fig.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the figures, such as the difficulty in parsing them, the small text size, the lack of clear explanation of inputs and outputs, and the unself-contained nature of the captions. This provides clear guidance on what needs to be addressed in the figures. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figures 1 to 3 are difficult to parse due to small text, lack of clear explanation of inputs and outputs, and unself-contained captions. However, the comment does not provide specific examples or references to support these claims. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies specific issues with the figures, such as their readability, the clarity of the text, the explanation of inputs and outputs, and the self-contained nature of the captions. It highlights the difficulty in parsing the figures and the lack of clear explanations, which are crucial for understanding the content. However, the comment does not provide actionable suggestions or guidance on how the authors might improve the figures. While it points out areas for improvement, it lacks depth and specificity, making it somewhat helpful. The authors would need to infer how to address these issues, which limits the comment's overall impact. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the continuous diffusion model, which outperforms the discrete diffusion model in Table 2, should be compared as a baseline in Table 3 for the conditional generation task. It also mentions that the continuous diffusion model does not explicitly present a conditional framework but proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could be used as a baseline. However, the comment does not provide explicit guidance on how to implement this suggestion or compare the models in Table 3. The action is implicit and vague, as the authors are left to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the continuous diffusion model, which outperforms the discrete diffusion model in Table 2, should be compared as a baseline in Table 3 for the conditional generation task. The comment provides clear guidance on what needs to be addressed, making it specific. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the continuous diffusion model, as evidenced by its performance in Table 2, should be compared as a baseline in Table 3 for the conditional generation task. It also mentions that while the continuous diffusion model does not explicitly present a conditional framework, recent work [2] proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could be used as a baseline. The claim is supported by the performance data in Table 2 and the reference to recent work [2], providing a logical basis for the suggestion. However, the comment could be more robust if it included specific examples or detailed reasoning about why this comparison is necessary. Overall, the claim is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the continuous diffusion model, which outperforms the discrete diffusion model in Table 2, should be compared as a baseline in Table 3 for the conditional generation task. It also provides context by mentioning that while the continuous diffusion model does not explicitly present a conditional framework, recent work proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could serve as a relevant baseline. This feedback is clear and actionable, as it provides a specific suggestion for improvement and offers a rationale for why the comparison is necessary. However, it could be more helpful if it included more detailed guidance on how to implement the comparison or why this comparison is particularly important. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should include a comparison against state-of-the-art loss functions used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. This provides a clear and explicit action for the authors to take, as they need to add this comparison to their draft. The suggestion is concrete, as it specifies which loss functions to include and provides examples, making it easy for the authors to understand and implement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding a comparison against state-of-the-art loss functions used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. However, it does not specify which part of the paper this comparison should be made or which sections of the paper are relevant to this suggestion. The authors may infer that this comparison should be added to the related work or experimental sections, but the comment lacks explicit guidance. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include a comparison against state-of-the-art loss functions used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. This claim is somewhat verifiable as it provides specific examples of loss functions that could be included in the comparison. However, it lacks detailed reasoning or references to support why these specific loss functions are relevant or important for the paper's focus. The authors would need to provide more context or justification to fully understand the basis of this suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper should include a comparison against state-of-the-art loss functions used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. This feedback is specific and actionable, as it provides clear examples of loss functions that could enhance the paper's relevance and depth. By adding this comparison, the authors can better contextualize their work within the existing literature and demonstrate a more comprehensive understanding of the field. However, the comment could be more helpful if it provided additional guidance on how to conduct this comparison or why these specific loss functions are relevant. Overall, the comment is mostly helpful, as it offers valuable suggestions for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the use of the name \"PointNet\" for Figure 1, referencing a paper with the same name that is not mentioned in the current paper. It suggests that the authors should clarify the use of the name or provide a reference to the specific paper being discussed. The comment is explicit in identifying the issue and provides a clear action for the authors to take, which is to clarify the use of the name or provide a reference. However, it does not specify how the authors should go about clarifying or providing the reference, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the naming of \"PointNet\" and provides a reference to a paper with the same name, which helps the authors understand what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the use of the name \"PointNet\" for Figure 1, referencing a paper with the same name that is not mentioned in the current paper. The comment provides a specific reference to \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,\" which helps the authors understand the issue and potentially address it. However, the comment does not offer additional reasoning or examples to fully support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the naming of Figure 1, noting that the name 'PointNet' is confusing because it is used in another paper that is not referenced in the current work. The comment provides a clear reference to a paper with the same name, which helps the authors understand the confusion and potentially address it. However, the comment could be more helpful by suggesting specific ways the authors might clarify or rephrase the figure's description to avoid the confusion. Overall, the comment is somewhat helpful as it highlights a potential issue and provides a reference, but it lacks detailed guidance on how to resolve it.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the results comparing standard- vs. evolutional dropout on shallow models should be presented as a mean over many runs (at least 10), ideally with error-bars. It also points out that the plotted curves are from single runs, which might be subject to significant fluctuations, and that the models are small, making it an excuse for not providing statistics. The comment provides clear guidance on how the authors should present their results, including specific actions such as calculating means over multiple runs and including error bars. This explicit and detailed feedback allows the authors to directly address the issue and improve their presentation of the results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the results comparing standard- vs. evolutional dropout on shallow models, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how the results should be presented, including the need to present them as a mean over many runs (at least 10) with error bars, and highlights the issue of single-run plots and the small size of the models. This detailed feedback helps the authors understand exactly what needs to be addressed and how to improve their presentation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results comparing standard- vs. evolutional dropout on shallow models should be presented as a mean over many runs (at least 10) with error bars, as the current presentation based on single runs might be subject to significant fluctuations. This claim is somewhat verifiable as it provides a logical reasoning for why presenting results as a mean with error bars is beneficial, but it lacks specific examples or references to support the claim fully. The authors would benefit from additional evidence or references to strengthen the justification for this suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the presentation of results, particularly regarding the comparison of standard- vs. evolutional dropout on shallow models. It suggests that the results should be presented as a mean over many runs (at least 10) with error bars, as the current presentation based on single runs might be subject to significant fluctuations. This feedback is clear and constructive, guiding the authors on how to improve the rigor and reliability of their results. However, the comment could be more helpful if it included additional suggestions or considerations for the analysis of the results. Overall, the comment is mostly helpful, as it offers valuable insights for enhancing the quality of the paper.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more detail about the experimental environment, specifically mentioning the CUDA and PyTorch versions. It also notes that different versions of the environment can affect training and inference speeds. While the comment explicitly suggests what information should be included, it does not provide specific guidance on how to describe the environment or what aspects to focus on. The action is clear and explicit, but it lacks concrete details on how to implement the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors need to describe the experimental environment in more detail, specifically mentioning the CUDA and PyTorch versions. It also highlights that different versions of the environment can impact training and inference speeds. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. While it provides some specificity by mentioning the versions and their potential impact, it lacks detailed guidance on what aspects of the environment need to be described. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors need to describe the experimental environment in more detail, specifically mentioning the CUDA and PyTorch versions. It also notes that different versions of the environment can affect training and inference speeds. However, the comment does not provide any specific examples, references, or detailed reasoning to support why this information is necessary or how it impacts the results. The lack of detailed justification makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors should provide more detail about the experimental environment, including the CUDA and PyTorch versions. It also highlights the importance of this information in understanding the impact on training and inference speeds. While the comment is clear and identifies a potential gap in the paper, it lacks specific guidance on what aspects of the environment should be described or how the authors can address this issue. The feedback is somewhat helpful as it points out a relevant area for improvement, but it could be more actionable with additional details or suggestions. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses doubt about the paper's strength for ICLR but does not provide any specific suggestions or actions for the authors to take to improve their draft. It lacks concrete guidance on what aspects of the paper need to be addressed or how the authors can enhance its quality. Without explicit instructions or detailed feedback, the authors are left without a clear path to improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses doubt about the paper's strength for ICLR but does not specify which part of the paper is being questioned or what aspects need improvement. It lacks grounding as it does not point to a specific section, table, figure, or unique element of the paper. Additionally, it does not provide specific feedback or suggestions on how to address the concerns. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses doubt about the paper's strength for ICLR but does not provide any specific evidence, reasoning, or references to support this claim. It lacks detailed justification or examples to substantiate the authors' concerns. Without such evidence, the claim remains unsubstantiated and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses doubt about the paper's strength for ICLR but does not provide any specific feedback or suggestions on how the authors might improve their work to meet the standards of the conference. It lacks actionable guidance, making it difficult for the authors to address the concerns effectively. Without concrete advice or suggestions, the comment is not helpful in enhancing the draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a critical issue with deep reinforcement learning (RL) experiments, specifically their reproducibility and the significance of improvements. It suggests that experiments should be run multiple times and that reporting statistics is essential. The comment provides explicit guidance on what needs to be done, such as running multiple experiments and reporting statistics. This direct and concrete feedback allows the authors to understand exactly how to improve their draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"deep RL\" and provides a reference to a specific paper on reproducibility in deep RL. It also specifies the issue of reproducibility and the need for multiple experiments, which are critical for addressing the concerns raised. The comment is specific in detailing the problem and suggesting a solution, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that experiments should be run multiple times to address the reproducibility issue with deep RL, referencing a specific paper [a] that highlights this concern. The comment provides a clear justification for the need to run multiple experiments and report statistics, aligning with the reasoning and common knowledge about the importance of reproducibility in scientific research. However, it could be strengthened by explicitly mentioning the specific aspects of reproducibility that need to be addressed, such as random seeds or hyperparameter variations. Overall, the claim is mostly verifiable, as it is supported by logical reasoning and references, but it could benefit from additional details to enhance clarity and comprehensiveness.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical issue with deep reinforcement learning (RL) experiments, specifically their reproducibility and the significance of their improvements. It highlights a longstanding problem and suggests that a community effort should be undertaken to address reproducibility, referencing a relevant paper [a]. The comment emphasizes the importance of running multiple experiments and reporting statistics, which are essential for ensuring the reliability and significance of the results. By pointing out these issues, the comment provides clear and actionable feedback that can guide the authors in improving the reproducibility and robustness of their experiments. This feedback is mostly helpful as it offers specific suggestions and references, but it could be further enhanced by providing more detailed guidance on how to implement these suggestions. Overall, the comment is mostly helpful, as it effectively directs the authors towards addressing a significant concern in their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the proposed upweighing and KNN methods, suggesting that their impact on idiomatic vs. random data is similar, which implies that the results may not be specific to idiomatic translations. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes might be necessary to make the results more idiom-specific. The action is implicit and vague, as it does not offer concrete steps for improvement. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the proposed upweighing and KNN methods, specifically mentioning the results presented in Figure 3. It critiques the similarity of the impact of these methods on idiomatic vs. random data, suggesting that the results may not be specific to idiomatic translations. However, the comment does not explicitly mention which part of the paper Figure 3 is located in, making it weakly grounded. The comment is specific in detailing the issue with the methods and the interpretation of the results, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the proposed upweighing and KNN methods, suggesting that their impact on idiomatic vs. random data is similar, which implies that the results may not be specific to idiomatic translations. The comment provides a logical reasoning by pointing out the similarity in impact across different language and score combinations, as illustrated in Figure 3. However, it lacks specific examples or references to support the claim that the results are not idiom-specific. Without detailed evidence or examples, the claim is somewhat verifiable, as it provides a basis for further investigation but does not fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the proposed upweighing and KNN methods, suggesting that their impact on idiomatic vs. random data is similar, which implies that the results may not be specific to idiomatic translations. The comment provides a logical reasoning by pointing out the similarity in impact across different language and score combinations, as illustrated in Figure 3. However, the feedback lacks specific suggestions or actionable guidance on how the authors might address this issue or improve the results to be more idiom-specific. While the comment identifies a potential weakness in the methodology, it does not offer detailed insights or constructive advice for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3, as it provides some insight but lacks depth and actionable suggestions.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the evaluation of the proposed approach by noting the absence of direct comparisons with the prior approach PRANC in both language and vision tasks. While the comment mentions comparisons of training loss and the rank of possible solutions, it does not provide explicit guidance on how to conduct a direct comparison of test accuracy. The action is implicit, as the authors are expected to infer that they need to include a direct comparison of test accuracy to demonstrate the improvement of the proposed approach over the baseline. However, the lack of concrete instructions on how to perform this comparison makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.4\" and \"Section 3.5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the absence of direct comparisons with the prior approach PRANC in both language and vision tasks, and the lack of a direct comparison of test accuracy. This provides the authors with a clear understanding of what needs to be addressed to strengthen the evaluation of the proposed approach. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are no direct comparisons with the prior approach PRANC in either the language or vision tasks used to evaluate the proposed approach. It mentions comparisons of training loss and the rank of possible solutions but notes that without a direct comparison of test accuracy, it is unclear if the approach is an improvement over the baseline. The claim is somewhat verifiable as it provides some evidence of the lack of direct comparisons, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the evaluation of the proposed approach by pointing out the absence of direct comparisons with the prior approach PRANC in both language and vision tasks. While the comment acknowledges comparisons of training loss and the rank of possible solutions, it highlights the critical issue of test accuracy, which is essential for demonstrating the improvement of the proposed approach over the baseline. This feedback is clear and actionable, as it directs the authors to include a direct comparison of test accuracy to strengthen their evaluation. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or suggested additional metrics for evaluation. Overall, the comment is mostly helpful, as it effectively guides the authors to address a key weakness in their work.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the improvement of the proposed method over existing RL methods is not impressive. However, it does not provide any specific details or suggestions on how the authors might address this issue or what aspects of the method could be improved. The comment lacks explicit guidance on what needs to be done to enhance the method, making it difficult for the authors to take action. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is referring to. It makes a general statement about the improvement of the proposed method over existing RL methods, but without any specific reference to a section, table, or figure, the authors cannot confidently identify the part of the paper being addressed. Additionally, the comment is not specific because it does not provide details on what aspects of the improvement are lacking or how the authors might address this issue. Therefore, this comment is not grounded and not specific, aligning with category 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the improvement of the proposed method over existing RL methods is not impressive. However, the comment lacks specific details or evidence to support this claim. It does not provide any examples, references, or logical reasoning to substantiate the assertion that the improvement is not impressive. Without further context or justification, the authors are left without a clear understanding of why this claim is made or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses concern about the improvement of the proposed method over existing RL methods, suggesting that it is not impressive. However, the comment lacks specific details or suggestions on how the authors might address this issue or what aspects of the method could be improved. It does not provide actionable feedback or guidance on how to enhance the method's performance or presentation. As a result, the comment is barely helpful, as it identifies a potential area for improvement but does not offer concrete steps for the authors to take. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the model design and learning details, noting that they are fragmented or missing. It suggests that the authors could provide a model illustration plot, pseudo-code table, or code repository to address this issue. The comment is explicit in identifying the need for additional details and provides concrete suggestions on how to improve the clarity of the model design. By offering specific examples of what could be included, the authors are given clear guidance on how to enhance the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of unclear model design and learning details, suggesting that the authors could provide a model illustration plot, pseudo-code table, or code repository. However, it does not specify which part of the paper these details are missing from, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as providing visual aids or detailed descriptions. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the model architecture and learning details are fragmented or missing, suggesting that the authors could provide a model illustration plot, pseudo-code table, or code repository. While the comment provides some guidance on what could be included, it lacks specific examples or references to support the claim that these details are indeed missing or fragmented. The suggestion to provide additional details is logical and helpful, but the lack of concrete evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the model design and learning details, noting that they are fragmented or missing. It provides specific suggestions for improvement, such as including a model illustration plot, pseudo-code table, or code repository. This feedback is actionable and constructive, as it guides the authors on what additional information is needed to enhance the clarity and reproducibility of their work. By addressing the fragmentation of model details, the comment offers a clear path for the authors to improve their draft, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the pruning strategy, suggesting that it might not be effective for large networks due to the lack of consideration for global top Q values of the metric over the average of gradients. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes are needed. The comment implies that the authors should consider the necessity of finding global top Q values, but it lacks concrete steps or suggestions on how to implement this. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to pruning strategies, particularly in the context of large networks and distributed training. It highlights a potential problem with the current approach, suggesting that majorly works with large networks but does not mention the necessity of finding global top Q values of the metric over the average of gradients. This provides a clear indication of what needs to be addressed in the paper, making it fully grounded. The comment is also specific as it specifies the potential issue with pruning strategies and the impact on acceleration techniques like quantization and sparsification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that pruning majorly works with large networks, which are usually trained in distributed settings, but does not mention the necessity of finding global top Q values of the metric over the average of gradients. This claim is somewhat verifiable as it highlights a potential issue with the pruning strategy but lacks specific examples or references to support the claim. The authors are left to infer the potential impact on acceleration techniques like quantization and sparsification, which could be beneficial for the paper. However, the lack of detailed reasoning or examples makes the claim somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the pruning strategy, specifically noting that it might not work effectively for large networks due to the lack of consideration for global top Q values of the metric over the average of gradients. This observation is insightful and highlights a potential area for improvement in the paper. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what changes could be made to enhance the effectiveness of their pruning strategy. While it points out a critical aspect that needs attention, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear observation but lacks depth and guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether some subfigures in Figs 1 and 2 have been swapped by mistake. While it identifies a potential issue, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to verify the claim or what steps to follow to address the issue. As a result, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions whether some subfigures in Figs 1 and 2 have been swapped by mistake. However, it does not specify which subfigures are in question or provide any details about the potential issue. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not specify what needs to be addressed or how the issue should be resolved, making it not specific. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions whether some subfigures in Figs 1 and 2 have been swapped by mistake. However, it does not provide any evidence, reasoning, or references to support this claim. Without specific details or examples, the authors are left without a basis to address or verify the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about potential errors in the subfigures of Figs 1 and 2, questioning whether they have been swapped by mistake. While this feedback identifies a potential issue, it lacks specific details or suggestions on how to address the problem. The authors are left without actionable guidance on how to verify or correct the issue, making the comment somewhat helpful. It provides a starting point for the authors to investigate the figures but does not offer a comprehensive or detailed response. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly mentions that the paper formatting does not follow the NeurIPS style, specifically noting issues with the abstract font size and bottom page margins. It suggests that by fixing the formatting, the authors should gain space and potentially include the NLP experiments in the main body of the paper. This feedback is clear and provides specific actions for the authors to take, such as revising the formatting and restructuring the paper. The comment is explicit and concrete, allowing the authors to understand exactly what needs to be addressed and how to do it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions issues with the paper formatting, specifically noting that it does not follow the NeurIPS style, with the abstract font being too large and the bottom page margins altered. It suggests that by fixing the formatting, the authors should gain space and potentially include the NLP experiments in the main body of the paper. This feedback is fully grounded as it clearly identifies the specific parts of the paper being addressed, and it is specific because it details the issues with the formatting and suggests concrete actions for improvement. Therefore, this comment is rated as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper formatting does not follow the NeurIPS style, specifically mentioning issues with the abstract font size and bottom page margins. It suggests that by fixing the formatting, the authors should gain space and potentially include the NLP experiments in the main body of the paper. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to verify the issues or understand how to address them. The feedback is somewhat verifiable as it provides a general direction but lacks detailed evidence or guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper formatting, noting that it does not adhere to the NeurIPS style. It highlights particular problems, such as the abstract font being too large and the bottom page margins being altered. The comment suggests that by addressing these formatting issues, the authors could gain space and potentially include the NLP experiments in the main body of the paper. This feedback is clear and actionable, providing the authors with specific areas to improve their draft. However, it could be more helpful if it included additional suggestions or guidance on how to address the formatting issues. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper is not sound because it does not discuss or compare exploration methods in RL literature, such as count-based methods and intrinsic motivations (RND, ICM). However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the paper need to be revised. The action is implicit and vague, as it does not specify which parts of the paper should be expanded or how the authors should incorporate these methods. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paper is not sound and does not discuss or compare exploration methods in RL literature, such as count-based methods and intrinsic motivations (RND, ICM). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion and comparison of these exploration methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not sound because it does not discuss or compare exploration methods in RL literature, such as count-based methods and intrinsic motivations (RND, ICM). However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed examples or references, the claim is somewhat verifiable, as it provides a general idea but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper by pointing out that it does not discuss or compare exploration methods in RL literature, such as count-based methods and intrinsic motivations (RND, ICM). This feedback is valuable as it highlights an area where the paper could be strengthened by providing a more comprehensive discussion of related work. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might address this issue, such as recommending additional sections or comparisons. Overall, the comment is somewhat helpful as it identifies a critical gap in the paper but lacks detailed actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the definition of the quantile could be confusing and proposes two potential improvements: adding extra brackets around the term or defining the bracketed term separately. These suggestions are explicit and provide concrete guidance on how the authors might address the issue. The comment is clear and actionable, allowing the authors to directly implement the proposed changes. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the definition of the quantile, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides concrete suggestions for improving the clarity of the definition by adding extra brackets or defining the bracketed term separately. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the definition of the quantile could be confusing and proposes two potential improvements: adding extra brackets or defining the bracketed term separately. While the comment provides a suggestion for improvement, it does not offer any specific reasoning or examples to support why the current definition might be confusing. The lack of detailed explanation or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some suggestion but lacks sufficient justification or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the definition of the quantile, suggesting that adding extra brackets or defining the bracketed term separately could improve understanding. This feedback is specific and actionable, providing the authors with clear guidance on how to enhance the clarity of their paper. By addressing this suggestion, the authors can make their work more accessible and easier to follow. Therefore, the comment is mostly helpful, as it offers a clear and constructive suggestion for improvement, though it could be further expanded to provide additional context or examples. The comment aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the RQ1 mentioned in the paper is redundant and adds no extra information for the audience. It also proposes an interesting point for analysis, such as how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and vice versa, and its corresponding effect on RQ2 & RQ3 t-sne plots. However, the comment does not provide explicit guidance on how the authors should address this issue or incorporate the suggested analysis. While the authors can infer that they need to reconsider the redundancy of RQ1 and explore the suggested analysis, the lack of concrete steps or detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the redundancy of RQ1 in the paper, suggesting that it adds no extra information for the audience. It also proposes an interesting point for analysis, such as how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and vice versa, and its corresponding effect on RQ2 & RQ3 t-sne plots. However, the comment does not specify which part of the paper discusses RQ1 or where the dataset analysis is mentioned. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific about the suggestions for analysis, the lack of grounding makes it challenging for the authors to understand which parts of the paper are being referred to. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the RQ1 mentioned in the paper is redundant and adds no extra information for the audience. It also suggests an interesting point for analysis, such as how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and vice versa, and its corresponding effect on RQ2 & RQ3 t-sne plots. However, the comment lacks specific examples or references to support the claim about the redundancy of RQ1. While it provides a suggestion for analysis, the absence of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is somewhat verifiable, as it provides a basis for improvement but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential redundancy in the RQ1 mentioned in the paper, suggesting that it adds no extra information for the audience. It also proposes an interesting point for analysis, such as how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and vice versa, and its corresponding effect on RQ2 & RQ3 t-sne plots. However, the comment lacks specific guidance on how the authors should address this issue or incorporate the suggested analysis. While it provides a direction for improvement, the feedback is somewhat vague and could be more helpful if it included concrete steps or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to clarify the introduction by stating that the proposed solution is a \"fix\" of [12], rather than a new PIC approach. It provides a specific example of where this clarification should be made, in lines 29-30. The comment is clear and direct, providing a concrete action for the authors to take. It instructs them to mention the prior work [12] to avoid confusion. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction section where the clarification should be made, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the authors must clarify the proposed solution as a \"fix\" of [12] rather than a new PIC approach, and it provides a specific example of where this clarification should be made in lines 29-30. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors must be more clear in the introduction about the nature of the proposed solution, specifically that it is a \"fix\" of [12] rather than a new PIC approach. The comment provides a specific example of where this clarification should be made, in lines 29-30. However, it does not provide additional reasoning or references to support this claim, leaving the authors to infer the need for clarification. While the comment is somewhat verifiable due to the specific example provided, it lacks broader justification or evidence, making it a borderline score.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is highly helpful as it provides a clear and specific suggestion for improvement. It instructs the authors to clarify the introduction by explicitly stating that the proposed solution is a \"fix\" of [12] rather than a new PIC approach. This guidance is actionable and directly addresses a potential point of confusion or misinterpretation regarding the novelty of the proposed solution. By providing a specific example of where this clarification should be made, the comment offers valuable feedback that empowers the authors to enhance the clarity and accuracy of their paper. Therefore, this comment is rated as highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the rationale behind combining G4RL with HRAC (i.e., HRAC-G4RL) and whether G4RL requires HRAC's regularization in the latent space. While it prompts the authors to provide a justification for this combination, it does not explicitly instruct them to do so or offer guidance on how to address this question. The action is implicit, as the authors need to infer that they should provide a rationale for the combination. However, the comment lacks concrete details on how to implement this action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the rationale behind combining G4RL with HRAC (i.e., HRAC-G4RL) and whether G4RL requires HRAC's regularization in the latent space. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact area where the clarification is needed. While the comment is specific in its inquiry about the rationale and regularization, the absence of explicit grounding information makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the rationale behind combining G4RL with HRAC (i.e., HRAC-G4RL) and whether G4RL requires HRAC's regularization in the latent space. This is a question that seeks clarification and does not present a subjective opinion or claim that requires verification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind combining G4RL with HRAC (i.e., HRAC-G4RL) and whether G4RL requires HRAC's regularization in the latent space. This question prompts the authors to provide a justification for their approach, which could help clarify the reasoning behind their method. However, the comment lacks specificity and does not offer any guidance or suggestions on how to address this question or improve the draft. As a result, while it identifies an area for improvement, it does not provide actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of comparisons with NeRF-based methods, specifically mentioning \"Zero-1-to-3\" and \"point-e.\" It also suggests that the relevance of the occlusion experiment is unclear, as the method does not seem to propose anything specific to occlusion. However, the comment does not provide explicit guidance on how the authors should address these issues, such as suggesting specific comparisons or clarifying the relevance of the occlusion experiment. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific comparisons with NeRF-based methods, such as \"Zero-1-to-3\" and \"point-e,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the relevance of the occlusion experiment, questioning its significance in the context of the method. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the lack of comparison with NeRF-based methods, specifically mentioning \"Zero-1-to-3\" and \"point-e.\" It also questions the relevance of the occlusion experiment, suggesting that it does not align with the method's specific contributions. However, the comment lacks detailed reasoning or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of specific examples or justifications weakens the verifiability of the claim. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper by pointing out the absence of comparisons with NeRF-based methods, specifically mentioning 'Zero-1-to-3' and 'point-e.' This feedback is valuable as it highlights the need for the authors to contextualize their work within the existing literature. Additionally, the comment questions the relevance of the occlusion experiment, suggesting that it does not align with the method's specific contributions. However, the comment lacks detailed guidance on how the authors should address these issues, such as providing specific comparisons or clarifying the relevance of the occlusion experiment. While the feedback is somewhat helpful in identifying areas for improvement, it could be more actionable with additional suggestions or guidance. Therefore, the comment aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the discussion regarding the hyperparameter \u03b3, specifically mentioning the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. This feedback provides a clear and explicit action for the authors to take, which is to include a detailed discussion on how to set the hyperparameter in practice and to analyze its sensitivity. The comment is concrete, as it specifies exactly what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the discussion on arbitrary hyperparameter \u03b3, specifically mentioning the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. However, it does not specify which part of the paper this discussion is located in, such as a particular section or table. This makes the comment weakly grounded, as the authors may need to infer the specific part of the paper being addressed. The comment is specific in detailing what is missing, such as guidance on setting the hyperparameter and sensitivity analysis, but it lacks grounding as it does not explicitly mention the section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the discussion on the hyperparameter \u03b3 is missing, specifically mentioning the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. This claim is somewhat verifiable as it highlights a gap in the discussion but does not provide specific examples or references to support the claim. The authors would need to infer the missing information, which limits the verifiability of the comment. Therefore, it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the discussion regarding the hyperparameter \u03b3, specifically noting the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. This feedback is clear and actionable, as it provides the authors with specific areas to address in their draft. By highlighting the importance of this hyperparameter and its impact on the results, the comment encourages the authors to include a detailed discussion on how to set it in practice and to analyze its sensitivity. This feedback is mostly helpful as it offers a clear direction for improvement, but it could be further enhanced by suggesting specific methods or techniques for setting the hyperparameter. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights specific issues with the Methodology section, such as the difficulty in following the model architecture description and the use of inconsistent notation. It provides concrete examples, such as the introduction of $v^p_{t-1}$ in Section 2.2 without corresponding equations, and the confusion caused by the notation for labels ($l_0$, $l_{t-1}$). The comment suggests that these issues make the section hard to follow, but it does not provide explicit guidance on how the authors should address these problems. While the authors can infer that they need to clarify the model architecture and notation, the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the Methodology section, which is fully grounded as it explicitly mentions the section. It also specifies the issues with the model architecture description and inconsistent notation, providing clear guidance on what needs to be addressed. This makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Methodology section is hard to follow due to confusing model architecture descriptions and inconsistent notation. It provides specific examples, such as the introduction of $v^p_{t-1}$ in Section 2.2 without corresponding equations and the confusion caused by the notation for labels ($l_0$, $l_{t-1}$). However, the comment lacks detailed reasoning or references to support these claims, making it somewhat verifiable. The authors can infer the issues but may need additional context to fully understand the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the Methodology section, such as the difficulty in following the model architecture description and the use of inconsistent notation. It provides concrete examples, like the introduction of $v^p_{t-1}$ in Section 2.2 without corresponding equations, which helps the authors understand the confusion. However, the comment could be more helpful by offering suggestions on how to improve the clarity and consistency of the notation or by providing guidance on how to better explain the model architecture. While the feedback is somewhat detailed, it could be expanded to offer more actionable advice, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should place more emphasis on prompt design, noting that different prompts can lead to varying performance outcomes. It implies that the authors should discuss effective prompt design strategies. However, the comment does not provide specific guidance on how to implement this suggestion, such as which aspects of prompt design should be emphasized or what techniques should be discussed. The action is implicit and somewhat vague, as the authors need to infer the specific areas where more emphasis is needed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should place more emphasis on prompt design, particularly in the context of MenatQA. It highlights the importance of discussing how different prompts can lead to varying performance outcomes and emphasizes the need for effective prompt design strategies. However, the comment does not specify which part of the paper should be addressed or provide detailed guidance on how to improve the discussion on prompt design. The lack of specific examples or sections makes it difficult for the authors to pinpoint the exact areas that need attention. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper should place more emphasis on prompt design, particularly in the context of MenatQA. It highlights the importance of discussing how different prompts can lead to varying performance outcomes and emphasizes the need for effective prompt design strategies. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that more emphasis on prompt design is necessary. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should place more emphasis on prompt design, particularly in the context of MenatQA. It highlights the importance of discussing how different prompts can lead to varying performance outcomes and emphasizes the need for effective prompt design strategies. While the comment identifies a specific area for improvement, it lacks detailed guidance or suggestions on how to enhance the discussion on prompt design. The authors would benefit from additional insights or examples that could help them address this point effectively. Therefore, the comment is somewhat helpful, as it provides a clear direction but could be more comprehensive with actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the condition \\eta \\ge C_0 in Proposition 6.1 is strong and that it should be compared with the condition in Section 4. While the comment implies that the authors should clarify this condition, it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should provide more context or explanation for the condition. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Proposition 6.1\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed by suggesting that the authors clarify the condition \\eta \\ge C_0 and compare it with the condition in Section 4. This provides clear guidance on what needs to be done, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the condition \\eta \\ge C_0 in Proposition 6.1 is strong, suggesting that it should be compared with the condition in Section 4. While the comment provides a rationale for why the condition might be strong, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the basis for the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Proposition 6.1, noting that the condition \\eta \\ge C_0 is strong and typically small. It suggests that the authors should clarify this condition and compare it with the condition in Section 4. This feedback is actionable and provides a clear direction for the authors to improve their draft by offering a specific area for clarification and comparison. However, the comment could be more helpful if it included examples or suggestions on how to clarify the condition. Overall, the comment is mostly helpful as it guides the authors towards addressing a specific concern, but it could be more comprehensive with additional details. Therefore, it is rated as 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the legends of Table 1, 2, and 3 should be longer and clarify whether the numbers represent % errors or % correct, specifically mentioning MNIST and CIFAR. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be done to improve the clarity of the table legends. The action is concrete, as it specifies the exact changes required, such as expanding the legends and clarifying the meaning of the numbers. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the legends should be longer and clarify whether the numbers are % errors or % correct, particularly for MNIST and CIFAR. This provides the authors with clear guidance on how to improve the clarity of the table legends. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the legends of Table 1, 2, and 3 should be longer and clarify whether the numbers represent % errors or % correct, specifically mentioning MNIST and CIFAR. This is a clear and specific claim that provides guidance on how to improve the clarity and interpretability of the tables. The suggestion is logical and directly addresses the need for better labeling, making it fully verifiable. Therefore, the comment is rated as 5.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific feedback on the clarity and interpretability of the legends in Tables 1, 2, and 3. It suggests that the legends should be longer and clarify whether the numbers represent % errors or % correct, particularly for MNIST and CIFAR. This feedback is actionable and directly addresses a potential issue with the presentation of the data, guiding the authors on how to improve the clarity of their results. By providing concrete suggestions, the comment empowers the authors to enhance the readability and understanding of their paper, making it a valuable piece of feedback. Therefore, the comment is rated as 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the concept of energy, which is introduced in Section 3.1, could be better explained or refreshed in Section 5.2, where it is used more extensively. It also points out that the concept of peak in Figure 5 is not described. The comment provides specific suggestions for improvement, such as refreshing the concept of energy and providing hints for interpreting it, as well as clarifying the concept of peak. However, it does not explicitly instruct the authors to implement these suggestions, leaving the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions Section 5.2, where the concept of energy is used, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely refreshing the concept of energy and providing hints for interpretation, as well as clarifying the concept of peak in Figure 5. This level of detail provides clear guidance on what needs to be done, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the concept of energy, introduced in Section 3.1, could be better explained or refreshed in Section 5.2, where it is used more extensively. It also points out that the concept of peak in Figure 5 is not described. The comment provides specific suggestions for improvement, such as refreshing the concept of energy and providing hints for interpretation, as well as clarifying the concept of peak. However, it lacks detailed reasoning or references to support these suggestions, making the claim somewhat verifiable. The authors would need to infer the need for clarification and improvement, which limits the verifiability of the comment. Therefore, it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the clarity and completeness of the paper. It highlights that the concept of energy, introduced in Section 3.1, could be better explained or refreshed in Section 5.2, where it is used more extensively. Additionally, it points out that the concept of peak in Figure 5 is not described, which is a clear area for improvement. The feedback is actionable and constructive, offering concrete suggestions for enhancing the paper's clarity and completeness. However, it could be more helpful if it provided more detailed guidance on how to implement these suggestions. Overall, the comment is mostly helpful, as it identifies key areas for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the title is ambiguous and could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. This provides a clear and explicit action for the authors to take, as they can directly address the ambiguity in the title. The comment is specific in its suggestion, detailing exactly what needs to be done to improve the clarity of the title. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the title is ambiguous and could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. However, it does not provide specific guidance on which part of the paper this issue is related to, such as a particular section or figure. The authors may need to infer that the title is ambiguous based on the context of the paper, but the comment lacks full grounding. It is specific in its suggestion to clarify the title, but the lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the title is ambiguous and could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. This claim is somewhat verifiable as it provides a clear suggestion for improvement, but it lacks specific examples or references to support the claim fully. The authors can infer that the title needs clarification, but the comment does not provide detailed reasoning or evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential ambiguity in the title, suggesting that it could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. This is a valuable piece of feedback as it helps the authors ensure that their work is accurately represented and easily understood by the readers. By addressing this ambiguity, the authors can enhance the clarity and precision of their paper, making it more impactful. The comment is specific and actionable, providing a clear direction for improvement. Therefore, it is rated as highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific claim made in the paper on line 238, which is that the Central Limit Theorem (CLT) implies that a normally distributed random variable can be produced through a finite linear combination of any random variables. The reviewer points out that this statement is incorrect, as the CLT does not guarantee Gaussianity in a non-asymptotic regime and does not hold for a finite linear combination of arbitrary random variables. The comment provides a clear and explicit action for the authors to take, which is to correct this specific claim in their paper. It also offers detailed reasoning about why the claim is incorrect, making it highly actionable. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific line in the paper (line 238), allowing the authors to accurately identify the part being addressed. It is also specific because it clearly identifies the incorrect claim made about the Central Limit Theorem (CLT) and provides detailed reasoning about why the claim is incorrect. This allows the authors to understand exactly what needs to be corrected. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' statement on line 238, \"According to the Central Limit Theorem (CLT), a normally distributed random variable can be produced through a finite linear combination of any random variables,\" is incorrect. The reviewer provides specific reasoning, explaining that the CLT does not guarantee Gaussianity in a non-asymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This detailed explanation supports the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific and incorrect claim made in the paper regarding the Central Limit Theorem (CLT). The reviewer provides a clear and detailed explanation of why the claim is incorrect, highlighting that the CLT does not guarantee Gaussianity in a non-asymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is actionable and constructive, as it guides the authors to correct the inaccurate statement in their draft. By addressing this specific issue, the authors can improve the accuracy and reliability of their claims, enhancing the overall quality of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues with the authors' draft: the lack of confidence intervals for their results and the limited evaluation on only two datasets. While the comment identifies these areas as needing improvement, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to include confidence intervals and expand their evaluation to more datasets. This lack of explicit and detailed guidance makes the comment somewhat actionable, as the authors can infer the necessary actions but do not have a clear roadmap for implementation. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of confidence intervals for the results and the limited evaluation on only two datasets. However, it does not specify which part of the paper these issues are discussed or how they impact the results. The authors are left to infer that these issues need to be addressed, but the comment lacks specific guidance on which sections or aspects of the paper should be revised. Therefore, the comment is weakly grounded, as the authors cannot confidently determine which part of the paper it addresses, and it is not specific because it does not provide detailed guidance on how to address the issues. This aligns with a score of 2: Weakly Grounded and Not Specific.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the authors do not show confidence intervals for their results, making it unclear whether performance gains are statistically significant. It also notes that the evaluation is limited to two datasets, which are standard in the RNP community. The comment provides references to relevant works that have evaluated on similar datasets, suggesting that the authors should consider expanding their evaluation. However, the claim lacks detailed reasoning or specific examples to fully support the assertion that the evaluation is limited to only two datasets. The references provided are relevant but do not offer a comprehensive explanation of why the evaluation is limited. Therefore, the comment is somewhat verifiable, as it provides some justification but lacks depth and detail.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the authors' draft: the lack of confidence intervals for their results, which makes it difficult to assess the statistical significance of performance gains. It also points out that the evaluation is limited to only two datasets, which may not be sufficient to demonstrate the robustness of the findings. The comment provides references to relevant works in the RNP community, suggesting that the authors should consider expanding their evaluation to include more datasets. This feedback is clear and actionable, as it directs the authors to address the lack of statistical significance and broaden their evaluation. However, it could be more helpful if it provided specific guidance on how to include confidence intervals or suggest additional datasets for evaluation. Overall, the comment is mostly helpful, as it effectively highlights important areas for improvement.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scalability of the method as the corpus size or hidden dimension size is increased. However, it does not provide any explicit or implicit suggestions or actions for the authors to take to address this question. The comment lacks guidance on how the authors might investigate or address the scalability issue, leaving them without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the scalability of the method as the corpus size or hidden dimension size is increased. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This makes it difficult for the authors to identify the exact area that needs attention. Additionally, the comment does not provide specific guidance or suggestions on how to address the scalability issue. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the scalability of the method as the corpus size or hidden dimension size is increased. However, it does not provide any claim, assertion, or suggestion that requires verification or justification. The comment is purely factual and descriptive, lacking any critical or subjective elements. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the scalability of the method as the corpus size or hidden dimension size is increased. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is barely helpful, as it identifies a potential area for improvement but does not offer any concrete advice or direction.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method discussed in the paper, which can be applied in general MDP, is limited in its applicability to navigation problems. It also mentions that combining RL and planning has been discussed in PRM-RL~[1] and suggests exploring the application of such algorithms in more general tasks. While the comment provides a clear direction for the authors to consider, it does not explicitly instruct them on how to implement this suggestion or explore the application in more general tasks. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to address the limitation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the applicability of the method discussed in the paper, specifically mentioning that it can be applied in general MDP but is limited in navigation problems. It also references PRM-RL~[1] as prior work that combines RL and planning. However, the comment does not specify which part of the paper discusses the method or navigation problems, making it weakly grounded. The comment is specific in suggesting that the authors explore the application of such algorithms in more general tasks, but without explicit references to sections or figures, the authors may need to infer the relevant parts. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method discussed in the paper, which can be applied in general MDP, is limited in navigation problems. It also references PRM-RL~[1] as prior work that combines RL and planning. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the method's limitations in navigation problems. While the reference to PRM-RL~[1] provides some context, the absence of detailed explanations or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper by pointing out that the method discussed can be applied in general MDP but is limited in navigation problems. It also references PRM-RL~[1] as prior work that combines RL and planning, suggesting that the authors explore the application of such algorithms in more general tasks. This feedback is somewhat helpful as it highlights a specific area for improvement and provides a direction for further exploration. However, it could be more helpful if it offered more detailed guidance or suggestions on how to address the limitation or expand the applicability of the method. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the suitability of feature spaces for 1-NN and suggests that if a feature space is not close to a spherical Gaussian, it may perform poorly. It also provides a suggestion that individual standardization of feature dimensions could avoid this issue. However, the comment does not explicitly instruct the authors to address this concern or provide specific guidance on how to modify their feature spaces or experiments. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the impact of feature space suitability on 1-NN performance and explore the suggestion of standardization. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by questioning the suitability of feature spaces for 1-NN and suggesting that standardizing feature dimensions could improve performance. This provides clear guidance on how to revise the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the suitability of feature spaces for 1-NN and suggests that standardizing feature dimensions could improve performance. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim that feature spaces not close to a spherical Gaussian may perform poorly. The suggestion to standardize feature dimensions is clear, but the overall claim is somewhat verifiable as it lacks detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the suitability of feature spaces for 1-NN and provides a suggestion that standardizing feature dimensions could improve performance. While it identifies a potential issue with the feature space, it does not offer detailed guidance or specific advice on how to address this concern or what changes might be necessary. The comment is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable suggestions, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks a question about the meaning of \\delta in the statement of Lemma 5. While it prompts the authors to clarify the term, it does not provide explicit instructions or suggestions on how to address this issue. The authors are left to infer that they need to clarify the meaning of \\delta, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment asks a question about the meaning of \\delta in the statement of Lemma 5. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in that it identifies a particular aspect of the paper that needs clarification. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification about the meaning of \\delta in the statement of Lemma 5. It does not contain a claim or assertion that requires verification. The comment is factual and descriptive, as it seeks to understand a specific term within a mathematical context. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review point raises a question about the meaning of \\delta in the statement of Lemma 5. While it identifies a potential area of confusion or lack of clarity in the paper, it does not provide any suggestions or guidance on how the authors might address this issue. The comment is vague and lacks actionable advice, leaving the authors without a clear path to improvement. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests including the results of the bottom-up method [9] on the crowdpose dataset in Table 4 and evaluating the performance of the authors\\' method on the standard MS COCO dataset, particularly in easy (non-occluded) settings. While the comment provides explicit guidance on what data to include and how to evaluate performance, it lacks specific instructions on how to implement these suggestions, such as which columns or metrics to focus on. The action is somewhat vague, as it does not provide detailed steps or examples for inclusion and evaluation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the bottom-up method [9]\" and \"Table 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what data to include in the table and how to evaluate the performance of the authors\\' method on the MS COCO dataset, particularly in easy (non-occluded) settings. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the bottom-up method [9] has reported results on the crowdpose dataset outperforming all methods in Table 4 with a ResNet-50, including the paper one. It suggests including this information in the tables and evaluating the performance of the authors\\' method on the standard MS COCO dataset, particularly in easy (non-occluded) settings. While the claim is based on a specific observation about the performance of the bottom-up method, it lacks detailed reasoning or references to support the claim fully. The suggestion to include the results and evaluate performance on MS COCO is logical and provides a clear direction for improvement. However, the comment could be more verifiable with additional evidence or examples. Therefore, it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the draft by including the results of the bottom-up method [9] on the crowdpose dataset in Table 4 and evaluating the performance of the authors\\' method on the standard MS COCO dataset, particularly in easy (non-occluded) settings. This feedback is actionable and constructive, as it guides the authors on what additional data to include and how to assess the performance of their method. However, the comment could be more helpful if it provided more detailed guidance on how to evaluate the performance on MS COCO or suggested specific metrics to use. Overall, the comment is mostly helpful, as it offers clear directions for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the claim of using \"annotation guideline\" in the paper, suggesting that it may be an overstatement. It provides specific examples from the TACRED slot filling guidelines, such as the rule for city of birth, to illustrate the complexity of annotation guidelines in the Information Extraction (IE) domain. However, the comment does not offer any explicit or implicit suggestions on how the authors might address this issue or improve their approach. The authors are left without guidance on how to revise their draft to align with the complexity of annotation guidelines, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"annotation guideline\" claim, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the issue is by pointing out that the paper only considers label names, descriptions, and few-shot examples, while annotation guidelines in the Information Extraction (IE) domain are complex and curated by linguists. The comment provides specific examples, such as the TACRED slot filling guidelines, to illustrate the complexity of annotation guidelines. This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper may be overstating its use of \"annotation guideline\" by only considering label names, descriptions, and few-shot examples. It provides specific examples from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the Information Extraction (IE) domain. However, the comment lacks detailed reasoning or references to support the claim fully. While the examples are relevant, the absence of a comprehensive explanation or additional evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the claim of using 'annotation guideline' in the paper, suggesting that it may be an overstatement. It provides specific examples from the TACRED slot filling guidelines, such as the rule for city of birth, to illustrate the complexity of annotation guidelines in the Information Extraction (IE) domain. This critique highlights a potential gap in the paper's approach, as it suggests that the prompts proposed might not fully capture the depth of true guideline understanding. However, the comment does not offer any suggestions or guidance on how the authors could address this issue or improve their approach. Without actionable feedback or suggestions, the comment is barely helpful, as it only identifies a potential weakness without providing a clear path for improvement. Therefore, it aligns with a score of 2.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about a specific scenario involving the association of a CAD model with spatially-varying BRDF maps. While it raises an interesting point, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this scenario or what changes could be made to their draft to account for it. Without specific instructions or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about a specific scenario involving the association of a CAD model with spatially-varying BRDF maps. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment is not grounded as it lacks explicit references to specific sections, tables, or figures. Additionally, it does not provide specific guidance or suggestions on how to address the question or incorporate it into the paper. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about a specific scenario involving the association of a CAD model with spatially-varying BRDF maps. However, it does not provide any claim, judgment, or suggestion that requires verification or justification. The comment is purely descriptive and does not offer any insight or guidance that would help the authors improve their work. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about a specific scenario involving the association of a CAD model with spatially-varying BRDF maps. While it prompts the authors to consider this scenario, it does not provide any guidance or suggestions on how to address it or incorporate it into their draft. The comment lacks depth and specificity, leaving the authors without actionable feedback on how to improve their work. Therefore, it is barely helpful, as it identifies a potential area for consideration but does not offer constructive advice or suggestions. This aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors need to provide a figure demonstrating the decline in accuracy of a predictor over time in different settings to support their claim about the motivation. This action is clear and concrete, as it specifies exactly what the authors should do to address the issue. The comment is fully actionable, as it provides a direct and detailed instruction on how to improve the paper. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first question addressed in the paper, allowing the authors to accurately identify the part being discussed. It is also specific because it clearly specifies what needs to be addressed, namely, the lack of direct evidence for the motivation and suggests a way to support it by plotting a figure showing the decline in accuracy over time in different settings. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evidence of the motivation is not direct and suggests that the authors need to plot a figure to support their claim. While the suggestion is logical and provides a clear direction for improvement, it lacks specific examples or references to support the claim. The comment is somewhat verifiable as it offers a reasonable suggestion but could be strengthened with additional details or references to enhance its persuasiveness.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely that the evidence supporting the motivation is not direct. It suggests that the authors should plot a figure demonstrating the decline in accuracy of a predictor over time in different settings to provide a more compelling argument. This feedback is clear, actionable, and provides a concrete suggestion for improvement, making it mostly helpful. However, it could be more helpful if it included additional guidance on how to design the figure or what specific data to include. Overall, the comment is mostly helpful as it offers a clear direction for enhancing the paper.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and requests for clarification regarding the definition of excessive risk, its calculation, and its comparability across different groups. It asks the authors to explain how excessive risk is defined in line 103 and how it is calculated in practice, particularly concerning expectation. The comment also questions why excessive risk is a good representation for fairness, given that the optimal solution \u03b8* is not the optimal solution for the loss function with respect to data of group a, potentially leading to negative values. The reviewer points out that all excessive risk values in Figure 3 and Figure 7 are positive and asks if these values are comparable across different groups. These questions and requests for clarification provide explicit guidance on what the authors should address, making the comment actionable. However, the comment could be more specific by providing examples or detailed explanations of how to calculate excessive risk in practice. Overall, the comment is mostly actionable, as it clearly instructs the authors on what needs to be addressed but lacks some detail on how to implement the suggestions.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises several questions and requests for clarification regarding the definition of excessive risk, its calculation, and its comparability across different groups. It specifically references line 103, which suggests that the authors can accurately pinpoint the part of the paper being addressed. The comment also provides detailed questions about the calculation of excessive risk, its comparability, and its relevance to fairness, which are specific to the content of the paper. This allows the authors to understand exactly what aspects need clarification or further explanation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several questions and requests for clarification regarding the definition of excessive risk, its calculation, and its comparability across different groups. It does not contain any subjective opinions or claims that require verification. The questions are logical and seek to understand the methodology and reasoning behind the calculation of excessive risk. However, the comment lacks specific examples or references to external works that could provide further context or justification for the claims made. Therefore, the comment is mostly verifiable, as it provides logical reasoning but could benefit from additional evidence or references to fully substantiate the claims.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides detailed questions and requests for clarification regarding the definition of excessive risk, its calculation, and its comparability across different groups. It specifically asks the authors to explain how excessive risk is defined in line 103 and how it is calculated in practice, particularly concerning expectation. The comment also questions the comparability of excessive risk values across different groups and why it is a good representation for fairness. These questions are clear and actionable, guiding the authors to address specific aspects of their methodology that need further explanation or clarification. However, the comment could be more helpful if it provided additional context or examples to illustrate the concepts being questioned. Overall, the feedback is mostly helpful, as it directs the authors to areas where they need to improve their draft by providing specific questions and requests for clarification.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the motivation of the task, specifically regarding the difficulty of predicting the state of occluded objects and the lack of guarantee in annotation quality. It also asks about potential downstream applications or benefits of amodal tracking and how uncertainty in predictions might be handled. While the comment identifies areas where the authors could provide more clarity, it does not explicitly instruct the authors on what specific aspects to address or how to improve their draft. The action is implicit and somewhat vague, as the authors need to infer the need for more detailed explanations and examples. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the motivation of the task, specifically regarding the difficulty of predicting the state of occluded objects and the lack of guarantee in annotation quality. It also asks about potential downstream applications or benefits of amodal tracking and how uncertainty in predictions might be handled. However, the comment does not specify which part of the paper addresses these issues, making it difficult for the authors to pinpoint the exact sections that need revision. While the questions are specific, the lack of grounding makes it challenging for the authors to understand which parts of the paper are being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the motivation of the task, specifically regarding the difficulty of predicting the state of occluded objects and the lack of guarantee in annotation quality. It also asks about potential downstream applications or benefits of amodal tracking and how uncertainty in predictions might be handled. However, the comment does not provide any specific examples, reasoning, or references to support these claims. The questions are logical and inferable, but without detailed justification or evidence, they are somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the motivation of the task, particularly concerning the difficulty of predicting the state of occluded objects and the lack of guarantee in annotation quality. It also inquires about potential downstream applications or benefits of amodal tracking and how uncertainty in predictions might be handled. While the comment identifies a key area for clarification, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it prompts the authors to elaborate on the motivation and potential applications of their work, but it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks for examples of \"unreliable neighbors,\" which implies that the authors should provide specific instances to clarify the concept. However, it does not explicitly instruct the authors to include these examples in their draft or suggest where they should be added. The action is implicit and somewhat vague, as the authors need to infer that they should provide examples and understand the context of \"unreliable neighbors.\" Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 170 to 171, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests examples of \"unreliable neighbors,\" which directly points out what needs clarification or further explanation in that section. This provides clear guidance on what the authors should address to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point asks for examples of \"unreliable neighbors,\" which is a request for clarification and does not contain a subjective claim or suggestion that requires verification. It is a factual request for information, making it a \"No\" category.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment requests examples of \"unreliable neighbors,\" which is a specific and actionable suggestion for the authors to clarify a concept in their paper. By asking for examples, the reviewer provides a clear direction for improving the draft, making it somewhat helpful. However, the comment could be more helpful if it offered additional guidance on how to define or illustrate these neighbors effectively. Overall, the feedback is valuable but could be more comprehensive to fully assist the authors.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practicality of the paper, noting that the use of known causal relationships might not be feasible in practice due to the unavailability or inaccuracy of prior knowledge. However, the comment does not provide any specific guidance or suggestions on how the authors might address this issue or improve the practicality of their work. The action is implicit and vague, as it does not offer concrete steps or advice on how to make the paper more practical. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the practicality of the paper, specifically questioning the use of known causal relationships due to the unavailability or inaccuracy of prior knowledge. However, it does not specify which part of the paper this concern pertains to, such as a particular section or methodology. This makes it difficult for the authors to pinpoint the exact area that needs attention. The comment is specific in its critique but weakly grounded as it lacks explicit references to the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the practicality of the paper, specifically questioning the use of known causal relationships due to the unavailability or inaccuracy of prior knowledge. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the practicality of the paper, specifically questioning the use of known causal relationships due to the unavailability or inaccuracy of prior knowledge. This is a valid concern that could impact the applicability of the work in real-world scenarios. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the practicality of their work. While it identifies a potential limitation, it does not provide actionable advice or insights to help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it highlights an important consideration but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the contrastive learning framework used in the paper, suggesting that it is the same as SimCLR. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what changes they should consider making to their framework. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not specify which part of the paper this comparison is being made, nor does it provide any context or explanation for why this comparison is relevant. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what aspects of the framework or SimCLR are being compared or how this comparison might impact the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the contrastive learning framework used in the paper is the same as SimCLR. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the statement, making it difficult to address or improve their draft. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the contrastive learning framework used in the paper is the same as SimCLR, which is a specific and relevant observation. However, it lacks actionable guidance or suggestions for the authors to address this issue. Without further clarification or recommendations, the authors may not know how to proceed or what changes to make to their draft. Therefore, the comment is barely helpful, as it identifies a potential issue but does not provide sufficient guidance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that Tables 4 and 5 would be more readable if they were split into two tables each, with one table per measure. It provides a specific example of how the tables could be reorganized, suggesting that the 8 SFII columns and the 8 SPDI columns should be separated. This feedback is explicit and concrete, as it directly instructs the authors on how to improve the readability of the tables. The action is clear and actionable, providing a specific and detailed suggestion for the authors to implement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improving the readability of these tables by splitting them into two tables each, one for the 8 SFII columns and another for the 8 SPDI columns. This detailed feedback helps the authors understand exactly what needs to be done to enhance the clarity of the tables. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Tables 4 and 5 would be more readable if they were split into two tables each, with one table per measure. While the suggestion is logical and could improve readability, it lacks specific examples or references to support why this change would be beneficial. The comment does not provide detailed reasoning or evidence to justify the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the readability of Tables 4 and 5 by splitting them into two tables each, one for the 8 SFII columns and another for the 8 SPDI columns. This feedback is actionable and directly addresses a potential issue with the presentation of the data. By offering a clear and concise suggestion, the comment empowers the authors to enhance the clarity and organization of their tables, making it easier for readers to understand the information. However, the comment could be more helpful if it included additional suggestions or considerations for further improvements. Overall, the comment is mostly helpful as it provides a clear and actionable piece of feedback, but it could be expanded to offer a more comprehensive guide for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be improved by making comparisons more systematic with respect to the tuning of each method, specifically by comparing the best performance of each. However, it does not provide explicit guidance on how to achieve this, leaving the authors to infer the necessary steps. The action is implicit and somewhat vague, as it does not specify which parts of the paper need to be revised or how to conduct the systematic comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the most closely related work of Zemel et al. (2013)\" and suggests improvements by making comparisons more systematic with respect to the tuning of each method. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the systematic comparison of the best performance of each method. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper could be improved by making comparisons more systematic with respect to the tuning of each method, specifically by comparing the best performance of each. However, the comment does not provide any specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and implement the suggested improvements. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the paper by suggesting that the comparisons with the most closely related work of Zemel et al. (2013) could be more systematic, particularly by comparing the best performance of each method. This feedback is somewhat helpful as it points out a specific aspect that could enhance the paper's rigor and clarity. However, the comment lacks depth and does not provide detailed guidance on how to achieve this systematic comparison, leaving the authors with limited actionable advice. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove the scalability properties. This provides a clear and explicit action for the authors to take, as they need to estimate the time complexity to support the claim about scalability. The comment is specific in its suggestion, detailing what needs to be done to substantiate the claim. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the time complexity of the learning algorithm should be explicitly estimated to prove the scalability properties. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to understand which part of the paper to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove the scalability properties. This claim is somewhat verifiable as it provides a logical reasoning for why the estimation of time complexity is important for demonstrating scalability. However, it lacks specific examples or references to support the claim, which could make it less robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the time complexity of the learning algorithm should be explicitly estimated to prove the scalability properties. This feedback is clear and actionable, as it provides a specific and concrete suggestion for the authors to improve their draft. By estimating the time complexity, the authors can better substantiate their claims about the scalability of their learning algorithm. This feedback is detailed and directly addresses a potential weakness in the paper, making it highly helpful for the authors to enhance their work. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the discussion around equation (10) is terse and not clearly explained. While it suggests that the authors should improve the clarity of this discussion, it does not provide specific guidance on how to achieve this. The action is implicit, as the authors need to infer that they should enhance the explanation of the discussion around equation (10). However, the comment lacks concrete details on what aspects of the discussion need to be clarified or expanded. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly points out that the discussion around this equation is terse and not well-explained, providing a clear indication of what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion around equation (10) is terse and not clearly explained. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the discussion around equation (10), noting that it is terse and not clearly explained. This feedback is actionable as it provides a clear area for improvement, suggesting that the authors should enhance the clarity and depth of their discussion. However, the comment lacks specific guidance on how to improve the explanation or what aspects of the discussion need clarification. While it offers a valuable suggestion, it could be more helpful if it provided more detailed guidance or examples of how to improve the explanation. Therefore, the comment is mostly helpful, as it directs the authors to an area of improvement but does not fully address the need for actionable feedback.', 'helpfulness_label': '4'} "}
