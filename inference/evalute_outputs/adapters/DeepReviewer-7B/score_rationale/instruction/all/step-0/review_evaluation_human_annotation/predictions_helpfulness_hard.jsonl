{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the description of HIERENC, suggesting that the current explanation is unclear and that the method of averaging representations from all possible entity instantiations might introduce noise. However, the comment does not provide explicit guidance on how the authors should revise the description or address the issue of noise. While it identifies a problem, it lacks concrete steps or suggestions for improvement, making it 3.", "grounding_specificity_rationale": "The comment addresses the description of HIERENC, providing a specific explanation of how the input (h_i) is processed. It highlights a potential issue with the method of averaging representations from all possible entity instantiations, suggesting that this approach might introduce noise. The comment is fully grounded as it explicitly mentions the part of the paper being addressed, and it is specific because it clearly specifies the issue with the description of HIERENC. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that the description of HIERENC is unclear and suggests that averaging representations from all possible entity instantiations might introduce noise. While the reviewer provides a specific example of how the input is processed, the claim lacks detailed reasoning or references to support the assertion that this approach is problematic. The comment could be more verifiable with additional explanation or evidence, but it is still 3 as it provides a basis for understanding the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of HIERENC, noting that the method of averaging representations from all possible entity instantiations might introduce noise. This feedback is clear and actionable, as it points out a potential problem with the methodology and suggests that the authors should consider alternative approaches or provide a more detailed explanation of the process. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address the issue of noise. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional details. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the wording used in the paper, specifically the phrase \"on par or better,\" which might be misleading due to cognitive biases among NLP researchers. However, the comment does not provide explicit guidance on how the authors should correct the wording or what specific changes should be made. The action is implicit, as the authors need to infer that they should revise the wording to avoid ambiguity. While the comment is 3, it lacks concrete details on how to implement the suggested change, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"on par or better\" at line 791, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the wording, suggesting that it might be misleading due to cognitive biases among NLP researchers. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the phrase \"on par or better\" might be misleading due to cognitive biases among NLP researchers. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed reasoning or evidence, the claim is considered 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the wording used in the paper, specifically the phrase \"on par or better,\" which might be misleading due to cognitive biases among NLP researchers. The comment suggests that this wording could be corrected to avoid ambiguity, but it does not provide specific guidance on how to revise the wording or what changes should be made. While the feedback highlights a potential area for improvement, it lacks detailed suggestions or examples, making it 3. The authors would need to infer the need for revision and potentially seek further clarification to fully address the comment. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about the interpretation of results presented in Table 3, specifically regarding the comparison of Chinese MOSQ and Baseline with NVSB and GT Mel A, and the overlapping 95% confidence intervals for Chinese and English MOSV. However, it does not provide explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should interpret these results or what steps they should consider to address the overlapping confidence intervals. Without specific suggestions or guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing, such as a particular section or table. It raises questions about the interpretation of results in Table 3, but without referencing the table or section, the authors cannot confidently determine where the issue lies. Additionally, the comment is not specific because it does not provide detailed guidance on how to interpret the results or what actions should be taken. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises questions about the interpretation of results presented in Table 3, specifically regarding the comparison of Chinese MOSQ and Baseline with NVSB and GT Mel A, and the overlapping 95% confidence intervals for Chinese and English MOSV. However, it does not provide any claims, opinions, or suggestions that require verification. The comment is purely descriptive and does not offer any guidance or reasoning to support its points. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises questions about the interpretation of results presented in Table 3, specifically regarding the comparison of Chinese MOSQ and Baseline with NVSB and GT Mel A, and the overlapping 95% confidence intervals for Chinese and English MOSV. However, it does not provide any guidance or suggestions on how the authors might address these interpretations or improve their analysis. Without actionable feedback or insights, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential area for clarification but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should include an ablation study to demonstrate the importance of the postprocessing steps used to filter out \"falsepositive\" neurons. While the comment implies that an ablation study is needed, it does not explicitly instruct the authors to conduct one or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer that an ablation study is necessary to validate the significance of the postprocessing steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of integrated gradients and postprocessing steps, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights a gap in the paper by noting that the importance of these postprocessing steps is not shown, suggesting the need for an ablation study. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not show how important the postprocessing steps are, suggesting that an ablation study may be needed. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed reasoning or evidence, the claim is 3, as it provides a general suggestion but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should include an ablation study to demonstrate the importance of the postprocessing steps used to filter out \"falsepositive\" neurons. This feedback is actionable and provides a clear direction for the authors to enhance their work. However, the comment could be more helpful if it included suggestions on how to conduct the ablation study or what specific metrics to use. Despite this, the comment offers valuable guidance, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about how an antecedent can be identified when the prediction is a pronoun, specifically questioning the method proposed by the authors. It highlights a lack of clarity in handling situations where the head word is not a pronoun. However, the comment does not provide explicit guidance or suggestions on how to address this issue or improve the method. The action is implicit, as the authors would need to infer that they should clarify the method or provide more details on how to handle nonpronoun heads. The comment is vague and lacks concrete steps, making it 3.", "grounding_specificity_rationale": "The comment raises a question about how an antecedent can be identified when the prediction is a pronoun, specifically questioning the method proposed by the authors. It highlights a lack of clarity in handling situations where the head word is not a pronoun. However, the comment does not specify which part of the paper this issue is discussed or addressed, making it weakly grounded. The comment is specific in its critique of the method, but without clear references to specific sections or parts of the paper, it is difficult for the authors to pinpoint the exact areas that need improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about how an antecedent can be identified when the prediction is a pronoun, specifically questioning the method proposed by the authors. It highlights a lack of clarity in handling situations where the head word is not a pronoun. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a specific question about how an antecedent can be identified when the prediction is a pronoun, particularly questioning the method proposed by the authors. It highlights a lack of clarity in handling situations where the head word is not a pronoun. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the method. While it identifies a potential area for clarification, it lacks actionable advice or constructive feedback, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the comparison between the proposed models and models that consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model, but the paper does not adequately describe this comparison. The comment implies that the inclusion of more baselines based on related work would strengthen the paper. However, the action is implicit, as the authors need to infer that they should include more baselines. The action is also somewhat vague, as it does not provide specific guidance on which baselines to include or how to compare them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the comparison between the proposed models and models that consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model, but the paper does not adequately describe this comparison. The comment implies that the inclusion of more baselines based on related work would strengthen the paper. However, the authors cannot confidently determine which part of the paper this comment addresses, as it is not explicitly linked to a specific section or table. The comment is specific in its suggestion to include more baselines, but the lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the comparison between the proposed models and models that consider different senses but not sememes, suggesting that the MST baseline might be an example. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the comparison or how to address it. The absence of detailed reasoning or evidence makes the claim 3, as it is based on an assumption without clear justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by questioning the comparison between the proposed models and models that consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model, but the paper does not adequately describe this comparison. The comment implies that the inclusion of more baselines based on related work would strengthen the paper. However, the feedback lacks specific guidance on which baselines to include or how to compare them, making it 3. The authors gain some insight into the need for more comprehensive baselines, but the comment could be more actionable with detailed suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the selection process of frame similarity factors and attributes similarity factors, but it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks specific suggestions or actions that the authors can take to clarify or improve their methodology. As a result, the authors are left without a clear understanding of what steps to take to resolve this ambiguity. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the selection process of frame similarity factors and attributes similarity factors, but it does not specify which part of the paper this issue is discussed in. Without knowing the context or location of the discussion, the authors cannot confidently identify the section that needs attention. Additionally, the comment does not provide specific guidance or suggestions on how to address the ambiguity in the selection process. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the selection process of frame similarity factors and attributes similarity factors, but it does not provide any specific reasoning, examples, or references to support why this is unclear. The comment lacks detailed justification or context, making it difficult for the authors to understand the basis of the concern or how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential ambiguity in the selection process of frame similarity factors and attributes similarity factors, which could hinder the clarity and reproducibility of the research. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. While it highlights an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies the main weaknesses of the paper as the experiments, specifically noting that they are only conducted in an extremely lowresource regime and for a sentence classification task, which are not representative of realworld applications. It also suggests that the proposed augmentation method has potential for use in more NLP tasks, which are not shown. However, the comment does not provide explicit guidance on how the authors should address these weaknesses or improve their experiments. The actions are implicit and vague, as the authors are left to infer what needs to be done. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the main weaknesses of the paper, specifically focusing on the experiments. It mentions that the experiments are only conducted in an extremely lowresource regime and for a sentence classification task, which are not representative of realworld applications. It also suggests that the proposed augmentation method has potential for use in more NLP tasks, which are not shown. However, the comment does not specify which part of the paper discusses the experiments or the tasks, making it weakly grounded. The comment is specific in detailing the issues with the experiments and the potential for broader application of the augmentation method. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point identifies the main weaknesses of the paper as the experiments, specifically noting that they are only conducted in an extremely lowresource regime and for a sentence classification task, which are not representative of realworld applications. It also suggests that the proposed augmentation method has potential for use in more NLP tasks, which are not shown. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand and address the issues. The reasoning is somewhat vague, as it does not provide detailed explanations or evidence to substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies the main weaknesses of the paper, specifically focusing on the experiments. It points out that the experiments are limited to an extremely lowresource regime and a sentence classification task, which may not be representative of realworld applications. The comment also suggests that the proposed augmentation method has potential for use in more NLP tasks, which are not shown. However, the feedback lacks specific guidance on how the authors can address these weaknesses or improve their experiments. While it provides a general direction for improvement, it does not offer detailed suggestions or actionable steps, making it 3. Therefore, the comment aligns with a score of 3, as it provides some insight but could be more comprehensive and detailed."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether concept map extraction should be treated as a separate task, suggesting that it might be redundant given the capabilities of generic summarization systems. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or what changes could be made to their draft. The action is implicit, as the authors would need to infer that they should consider the redundancy of concept map extraction and potentially integrate it into the summarization process. The comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment addresses the necessity of treating concept map extraction as a separate task, suggesting that it might be redundant given the capabilities of generic summarization systems. It provides a rationale for this claim, explaining that many systems already build similar knowledge graphs and generate summaries accordingly. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its reasoning about the redundancy of concept map extraction, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the necessity of treating concept map extraction as a separate task, suggesting that it might be redundant given the capabilities of generic summarization systems. The comment provides a rationale for this claim, explaining that many systems already build similar knowledge graphs and generate summaries accordingly. However, it lacks specific examples or references to support the claim that concept map extraction becomes increasingly difficult to distinguish with a growing number of nodes. Without detailed evidence or examples, the claim is 3, as it provides a logical argument but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the necessity of treating concept map extraction as a separate task, suggesting that it might be redundant given the capabilities of generic summarization systems. It provides a rationale for this claim, explaining that many systems already build similar knowledge graphs and generate summaries accordingly. However, the comment does not offer specific suggestions or guidance on how the authors might address this concern or what changes could be made to their draft. While it identifies a potential area for improvement, it lacks actionable advice, making it 3. The authors would need to infer that they should consider the redundancy of concept map extraction and potentially integrate it into the summarization process, but the comment does not provide detailed guidance on how to do so. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with lines 102106, stating that the term \"such distribution\" is misleading because it does not align with the discussion in the preceding text. However, the comment does not provide any explicit guidance on how the authors should revise or clarify this section. The action is implicit, as the authors need to infer that they should address the misleading use of the term \"such distribution\" to ensure consistency and accuracy in their discussion. While the action is clear, the lack of concrete instructions on how to implement it makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 102106, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a misleading use of the term \"such distribution\" in the context of the discussion, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that lines 102106 are misleading because the term \"such distribution\" does not align with the preceding discussion. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed reasoning or evidence, the claim is considered 2, as it provides a general observation but lacks the necessary depth to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with lines 102106, noting that the term \"such distribution\" is misleading and does not align with the preceding discussion. This feedback is clear and actionable, as it directs the authors to revisit and clarify this section to ensure consistency and accuracy in their writing. However, the comment could be more helpful if it provided additional guidance on how to revise the text or suggested specific examples of how the term could be used more appropriately. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the sufficiency of a 4year period for studying style shifts and asks for clarification on the types of style shifts that occur within this timeframe. While it prompts the authors to consider the appropriateness of their dataset choice, it does not provide explicit guidance on how to address these concerns or what specific changes might be necessary. The action is implicit, as the authors need to infer that they should investigate the appropriateness of their dataset and the nature of style shifts over the chosen period. However, the comment lacks concrete details on how to implement this action, making it 3.", "grounding_specificity_rationale": "The comment questions the sufficiency of a 4year period for studying style shifts and asks for clarification on the types of style shifts that occur within this timeframe. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect of the paper being addressed. While the comment is specific in its questioning of the dataset choice and the nature of style shifts, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the sufficiency of a 4year period for studying style shifts and asks for clarification on the types of style shifts that occur within this timeframe. However, it does not provide any specific reasoning, examples, or references to support the claim that the dataset choice is insufficient. The comment lacks detailed justification or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the sufficiency of a 4year period for studying style shifts and questions the types of style shifts that might occur within this timeframe. It prompts the authors to consider whether the chosen dataset is appropriate for the research question and to provide more context on the nature of the style shifts being studied. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or what additional data or analysis might be necessary. While it identifies an important area for improvement, the feedback could be more helpful if it provided actionable advice or examples of how to strengthen the study. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point claims that there is no corresponding set of tools for the reinforcement learning setting, but it also states that this is false and provides references to support this claim. However, it does not explicitly instruct the authors to include these tools or to address the issue of missing tools in their draft. The action is implicit, as the authors would need to infer that they should consider adding or discussing these tools. The comment is 3 because it provides a clear direction for improvement, but it lacks explicit guidance on how to implement it. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the reinforcement learning setting, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it claims that there is no corresponding set of tools for this setting and provides references to support this claim, suggesting that the authors should consider including these tools. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is no corresponding set of tools for the reinforcement learning setting, but it also states that this is false and provides references to support this claim. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it offers references, it does not provide a comprehensive explanation of why the claim is valid or how the references support it. This makes the claim 3, as it provides some justification but lacks depth and detail. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the absence of corresponding tools for the reinforcement learning setting. It claims that this is false and provides references to support the claim. While the comment highlights a potential gap in the paper, it does not offer specific suggestions or guidance on how the authors might address this issue or incorporate the suggested tools. The feedback is 3 as it points out a potential area for improvement, but it lacks actionable advice, making it difficult for the authors to fully address the concern. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a missing link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, noting that these works have a similar structure to the CRF and ability to perform exact inference. However, the comment does not provide any explicit or implicit suggestions on how the authors should address this gap or incorporate these works into their draft. Without specific guidance on what needs to be done, the authors are left without a clear action to take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Continuous Conditional Random Fields\" and \"Continuous Conditional Neural Fields,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights a missing link to similar work that has a similar structure to the CRF and ability to perform exact inference, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is missing a link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, noting that these works have a similar structure to the CRF and ability to perform exact inference. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why this claim is valid or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the related work section by pointing out the absence of references to similar works on Continuous Conditional Random Fields and Continuous Conditional Neural Fields. These works have a similar structure to the CRF and can perform exact inference, which is relevant to the paper\"s topic. However, the comment does not provide any suggestions or guidance on how the authors might address this gap or incorporate these works into their draft. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as 3, as it provides a clear indication of a missing element but does not offer detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 4 is written in a very concise manner, which might be due to space limitations. It implies that the section could have been written more slowly to improve readability. However, the comment does not provide explicit guidance on how to achieve this, such as suggesting specific ways to expand the section or what content could be added to enhance readability. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand the section for better clarity. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the section is written in a very concise manner and suggests that it could have been written more slowly for easier readability. This provides clear guidance on what needs to be improved in the section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 4 is written in a very concise manner, which might be due to space limitations. It suggests that the section could have been written more slowly for easier readability. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the section is written in such a concise manner or how it could be improved. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the writing style of Section 4, noting that it is written in a very concise manner. This feedback is clear and actionable, as it suggests that the section could be improved for better readability by expanding it more slowly. However, the comment does not provide specific suggestions or examples of how to achieve this, which could limit its helpfulness. While it offers a direction for improvement, it lacks depth and specificity, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This provides clear and concrete guidance on what needs to be done, making the comment 5. The authors know exactly how to address the issue by adding a table and providing an explanation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to address the distribution of video lengths across the dataset, which is a specific part of the paper. It also specifies what needs to be addressed, including the inclusion of a table and an explanation of the balanced representation of video lengths across the 11 categories. This provides clear guidance for the authors to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not provide relevant explanations regarding the distribution of video lengths within the benchmark, which is crucial for assessing reasoning ability and robustness. The comment suggests that the authors should include a table showing the distribution of video lengths and explain how they ensured a balanced representation across the 11 categories. However, the comment lacks specific examples or references to support the claim that the current explanation is insufficient. While it provides a general direction for improvement, it does not offer detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is 3, as it identifies a potential issue but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of explanation regarding the distribution of video lengths across the benchmark. It provides clear guidance on what the authors should do to address this issue, including the need to include a table showing the distribution and explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback is actionable and constructive, as it directs the authors to specific steps they can take to enhance the clarity and comprehensiveness of their work. By addressing this feedback, the authors can significantly improve the presentation and robustness of their paper, making the comment 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should take a cautious approach regarding the contribution until the promised dataset is made publicly available. However, it does not provide any specific guidance or actions on how the authors should proceed with this cautious approach. The comment lacks explicit instructions or concrete steps that the authors can take to address this issue. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the promised dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, taking a cautious approach regarding the contribution until the dataset is publicly available. This provides clear guidance on how the authors should proceed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the promised dataset has not yet been made publicly available, suggesting a cautious approach should be taken. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to verify the accuracy of the statement. Without additional context or evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a critical issue regarding the availability of a promised dataset, which is essential for the contribution of the paper. It suggests a cautious approach until the dataset is publicly accessible, highlighting a potential limitation that could affect the reproducibility and impact of the work. However, the comment does not provide specific guidance on how the authors might address this issue or what steps they should take to ensure the dataset is made available in the future. While it points out a significant concern, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a critical issue regarding the related work section, specifically mentioning the importance of discussing modular networks for Visual Question Answering (VQA). It points out that the current introduction does not adequately address this aspect, suggesting that the authors should include it. However, the comment does not provide explicit guidance on how to incorporate this information or what specific examples or references should be included. The action is implicit, as the authors need to infer that they should add a discussion of modular networks for VQA, but it lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"related work\" and \"modular networks for VQA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need to mention related work on modular networks for VQA, such as [A], to provide context and relevance to the introduction. This provides the authors with clear guidance on what needs to be addressed in the related work section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction does not adequately address related work on modular networks for Visual Question Answering (VQA), specifically mentioning the omission of [A]. However, the comment lacks detailed reasoning or examples to support this claim. It does not provide specific evidence or references to substantiate the assertion that the introduction fails to mention this relevant work. Without additional context or justification, the claim remains 3, as the authors may need to infer the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical gap in the related work section by pointing out the absence of discussion on modular networks for Visual Question Answering (VQA). This is a significant oversight, as it suggests that the introduction does not adequately contextualize the work within the existing literature. By highlighting this omission, the comment provides the authors with a clear and actionable direction for improvement. It encourages them to include a discussion of relevant related work, which is essential for establishing the novelty and significance of their contribution. However, the comment could be more helpful if it provided specific examples or references to guide the authors in expanding the related work section. Overall, the feedback is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the ablation experiment results, noting that the performance without reinforcement learning dropped lower than without the dependency tree. It also points out that the two tables do not list the cases where either the dependency tree or RL is not used. This feedback is explicit and provides a clear action for the authors to take: they should include the missing cases in the tables to accurately represent the ablation study. The comment is specific and concrete, as it directly instructs the authors on what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the ablation experiment,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the performance drop and the missing cases in the tables, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance without reinforcement learning dropped lower than without the dependency tree, and that the two tables do not list the cases where either dependency tree or reinforcement learning is not used. This claim is 3 as it provides a specific observation about the ablation experiment results but lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to refer to the tables to verify the claim themselves, which limits the level of verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the ablation experiment, noting that the performance without reinforcement learning dropped lower than without the dependency tree. It also points out that the two tables do not list the cases where either dependency tree or reinforcement learning is not used. This feedback is clear and actionable, as it directs the authors to include the missing cases in the tables to accurately represent the ablation study. By addressing this issue, the authors can improve the completeness and clarity of their experimental results. The comment is 4 as it provides a specific and actionable suggestion for improvement, though it could be more comprehensive if it included additional guidance on how to present the results effectively. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the clarity of the notation used in the paper, specifically the confusion caused by the explicit split between \"static\" and temporal features into two variables, S and Xt. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the notation, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it identifies a specific area for improvement but does not provide detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the clarity of notation in the paper, particularly the confusion caused by the explicit split between \"static\" and temporal features into two variables, S and Xt. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for clarification regarding the variables S and Xt, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location of the problem. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of notation in the paper, specifically the confusion caused by the explicit split between \"static\" and temporal features into two variables, S and Xt. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that this confusion is significant or how it affects the paper. Without additional context or evidence, the authors may find it difficult to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of notation in the paper, specifically the confusion caused by the explicit split between \"static\" and temporal features into two variables, S and Xt. While the comment highlights a potential area for improvement, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a potential area for clarification, but it lacks actionable advice or detailed examples, which could leave the authors uncertain about how to proceed. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges that the paper deals with many graph notions and that the writing is generally good, but it also points out that more details could be provided, specifically mentioning the need for a definition of the resistance distance and more explanations for Algorithm 1. While the comment identifies areas where additional details are needed, it does not explicitly instruct the authors to provide these details or suggest specific ways to improve the explanations. The action is implicit and somewhat vague, as the authors are left to infer that they should add these details. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the need for more details in the definition of the resistance distance and the explanations for Algorithm 1, providing clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point acknowledges that the paper deals with many graph notions and that the writing is generally good, but it also suggests that more details could be provided, specifically mentioning the need for a definition of the resistance distance and more explanations for Algorithm 1. While the comment identifies areas where additional details are needed, it lacks specific examples or references to support the claim that more details are necessary. The feedback is 3 as it provides a general suggestion but does not offer detailed reasoning or evidence to justify the need for more details. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies areas where the paper could be improved, specifically mentioning the need for more details in the definition of the resistance distance and additional explanations for Algorithm 1. While it acknowledges that the writing is generally good, it provides specific suggestions for enhancing clarity and comprehensibility. This feedback is 4 as it offers actionable insights for the authors to improve their draft, but it could be more comprehensive if it included additional suggestions or examples of how to provide these details. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should consider introducing the specific aspects of the model that are relevant to the example model being discussed. It provides an example by mentioning that the authors should clarify that they are not operating in a setting with infinite subdivisions for \u03b3^1 and \u03b3^m, and that certain parameters are bounded on one side (acceleration and scaling parameters). This feedback is explicit and provides concrete guidance on what needs to be addressed in the paper. The authors know exactly what aspects to consider and how to implement the suggested clarification, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific section of the paper (line 132), allowing the authors to accurately identify the part being addressed. It also provides specific guidance on what needs to be clarified, such as the aspects of the specific model that are specific to this example model and the clarification regarding the bounds of certain parameters. This level of detail ensures that the authors understand exactly what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider introducing the specific aspects of the model that are relevant to the example model being discussed. It provides an example by mentioning that the authors should clarify that they are not operating in a setting with infinite subdivisions for \u03b3^1 and \u03b3^m and that certain parameters are bounded on one side (acceleration and scaling parameters). This feedback is 3 as it provides a clear example of what needs to be addressed, but it lacks detailed reasoning or references to support the claim fully. The authors can infer the need for clarification but may require additional context to fully understand the implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on a particular aspect of the paper, suggesting that the authors should consider introducing the specific aspects of the model that are relevant to the example model being discussed. It offers a concrete example by mentioning that the authors should clarify that they are not operating in a setting with infinite subdivisions for \u03b3^1 and \u03b3^m and that certain parameters are bounded on one side (acceleration and scaling parameters). This feedback is clear and actionable, as it guides the authors on what needs to be addressed to improve the clarity and precision of their work. However, the comment could be more helpful if it provided additional context or examples to further enhance the authors\" understanding of the issue. Overall, the comment is 4, as it offers valuable guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the required condition on the learning rate, specifically noting that it scales with the number of samples. The reviewer argues that this condition is not realistic because, in practice, the step size does not grow with the sample size, potentially leading to unreasonably large learning rates when dealing with largescale datasets. While the comment identifies a potential issue with the learning rate condition, it does not provide explicit guidance on how the authors might address this concern or what specific changes could be made to the draft. The action is implicit, as the authors would need to infer that they should consider alternative learning rate scaling strategies or provide a more realistic justification for the current condition. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the scalability of the required condition on the learning rate, which is a critical aspect of the paper. It highlights a concern that the learning rate scales with the number of samples, a point that is not realistic in practice. The comment is fully grounded as it explicitly mentions the learning rate condition, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the learning rate condition and its implications for scalability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the scalability of the required condition on the learning rate, specifically noting that it scales with the number of samples. The reviewer argues that this condition is not realistic because, in practice, the step size does not grow with the sample size, potentially leading to unreasonably large learning rates when dealing with largescale datasets. The comment provides a logical reasoning for why the condition might be unrealistic, but it lacks specific examples or references to support the claim. Without additional evidence or references, the claim is 3, as it offers a plausible argument but does not provide a comprehensive basis for the authors to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the scalability of the required condition on the learning rate, noting that it scales with the number of samples. The reviewer argues that this condition is not realistic in practice, as the step size does not typically grow with the sample size, potentially leading to unreasonably large learning rates for largescale datasets. While the comment highlights a potential issue with the learning rate condition, it does not provide specific suggestions or guidance on how the authors might address this concern or improve the draft. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a potential issue with the use of unlabeled data, noting that the data is perfectly balanced and may not be practical in realworld applications. It suggests that the authors should consider using a more convincing setting, such as sampling unlabeled data from millions of reviews, as done in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018. This comment provides a clear and explicit action for the authors to take, which is to explore and implement a more realistic setting for their experiments. The suggestion is concrete and offers a specific alternative approach, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"preprocessed Amazon review dataset (Blitzer version)\" and the \"2000 unlabeled data,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear rationale for the issue, suggesting that the balanced unlabeled data is impractical and recommending a more convincing setting as used in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018. This provides the authors with a clear understanding of what needs to be addressed and how to improve their approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of perfectly balanced unlabeled data from the preprocessed Amazon review dataset is impractical in realworld applications. It suggests that the authors should consider using a more convincing setting, such as sampling unlabeled data from millions of reviews, as done in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018. The comment provides a logical reasoning by highlighting the practical limitations of perfectly balanced data and suggests a more realistic approach. However, it lacks specific examples or references to support the claim fully, which could make it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of unlabeled data, specifically noting that the data is perfectly balanced and may not be practical in realworld applications. It suggests that the authors should consider using a more convincing setting, such as sampling unlabeled data from millions of reviews, as done in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018. This feedback is clear and actionable, providing the authors with a specific direction to improve their experimental setup. By recommending a more realistic approach, the comment offers valuable guidance on how to enhance the practical relevance and applicability of their work. Therefore, the comment is 5, as it addresses a significant aspect of the research and provides a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the clarity of sampling from the DPP when eigenfunctions are inaccessible, specifically referencing Equation (10) and line 130. It also suggests that this issue is similar to sampling from the leverage score, as discussed in [3]. However, the comment does not provide explicit guidance on how to address this issue or what steps the authors should take to clarify the sampling process. The action is implicit, as the authors would need to infer that they should seek clarification or provide more details on the sampling method. The lack of concrete instructions makes the comment 3.", "grounding_specificity_rationale": "The comment raises a question about the clarity of sampling from the DPP when eigenfunctions are inaccessible, specifically referencing Equation (10) and line 130. However, it does not provide a clear indication of which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in that it identifies a potential issue with the clarity of the sampling process, but it does not specify how this issue might be addressed or what changes are needed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of sampling from the DPP when eigenfunctions are inaccessible, referencing Equation (10) and line 130. It also suggests that this issue is similar to sampling from the leverage score, as discussed in [3]. However, the comment does not provide any specific reasoning or evidence to support the claim that the sampling process is unclear or that it is similar to sampling from the leverage score. Without detailed explanations or references, the claim is difficult to verify, making it 1.", "helpfulness_rationale": "The review comment raises a question about the clarity of sampling from the DPP when eigenfunctions are inaccessible, specifically referencing Equation (10) and line 130. It also suggests that this issue is similar to sampling from the leverage score, as discussed in [3]. However, the comment does not provide any actionable feedback or suggestions on how the authors might address this issue or clarify the sampling process. It lacks depth and specificity, leaving the authors without clear guidance on how to improve their draft. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer any concrete advice or direction for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper, noting that the extent to which the observations generalize to fewshot learners beyond Prototypical Networks is not evaluated. This observation suggests that the paper\"s contributions may be limited in terms of understanding the properties of episodic training. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to evaluate the generalizability of the observations or what steps could be taken to expand the scope of the paper. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the generalizability of observations to fewshot learners beyond Prototypical Networks, which is a particular aspect of the paper. However, it does not explicitly mention which part of the paper this issue pertains to, such as a specific section or figure. This makes it weakly grounded, as the authors may need to infer the relevant section. The comment is specific in that it identifies a limitation in the evaluation of the paper\"s contributions, suggesting that the authors should consider expanding their analysis to include fewshot learners beyond Prototypical Networks. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not evaluate the extent to which the observations generalize to fewshot learners beyond Prototypical Networks, which may limit the scope of the paper\u2019s contributions. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this claim and how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the paper, noting that the extent to which the observations generalize to fewshot learners beyond Prototypical Networks is not evaluated. This observation is important because it highlights a potential gap in the paper\"s contributions, particularly in understanding the properties of episodic training. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or expand their analysis. While it points out an area for improvement, it lacks actionable advice, making it 3. The authors would need to infer what steps to take to address the issue, which limits the comment\"s usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the contribution of different modalities and instances, suggesting that some instances with good performance in one modality might belong to a strong modality, while others might not. It also points out that Equation 3 removes the modal subset of all instances, which may not be appropriate. However, the comment does not provide explicit guidance or suggestions on how to address this issue or what actions the authors should take to improve their draft. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the contribution of different modalities and instances, suggesting that some instances with good performance in one modality might belong to a strong modality, while others might not. It also points out that Equation 3 removes the modal subset of all instances, which may not be appropriate. However, the comment does not specify which part of the paper this issue is discussed or addressed, making it difficult for the authors to pinpoint the exact section or figure that needs revision. While the comment is specific about the issue of different modalities, it lacks grounding as it does not provide explicit references to the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the contribution of different modalities and instances, suggesting that some instances with good performance in one modality might belong to a strong modality, while others might not. It also questions the appropriateness of Equation 3, which removes the modal subset of all instances. However, the comment lacks specific examples or references to support the claim that Equation 3 is problematic. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is barely verifiable.", "helpfulness_rationale": "The review comment raises a concern about the contribution of different modalities and instances, suggesting that some instances with good performance in one modality might belong to a strong modality, while others might not. It also questions the appropriateness of Equation 3, which removes the modal subset of all instances. However, the comment does not provide specific guidance or suggestions on how to address this issue or what actions the authors should take to improve their draft. While it identifies a potential problem, it lacks depth and actionable advice, making it 2. The authors would need to infer how to address the issue, which limits the comment\"s usefulness."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed objective equation, noting that it requires optimization over both the parameters of the transformation \u03c6 and the shared model \u03b8_S. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to the objective equation. The comment lacks concrete guidance on how to improve the draft, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 128,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed objective equation requires optimization over both the parameters of the transformation \u03c6 and the shared model \u03b8_S, and it highlights the lack of discussion regarding the effect on the number of parameters compared to prior work, such as AlignFlow. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed objective equation requires optimization over both the parameters of the transformation \u03c6 and the shared model \u03b8_S, and it notes that the effect on the number of parameters compared to prior work, such as AlignFlow, has not been discussed clearly. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim is considered 2, as it lacks sufficient justification to fully substantiate the authors\" concerns.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed objective equation, noting that it requires optimization over both the parameters of the transformation \u03c6 and the shared model \u03b8_S. It highlights a lack of discussion regarding the effect on the number of parameters compared to prior work, such as AlignFlow. This feedback is 3 as it points out a potential area for improvement in the paper, specifically regarding the clarity and depth of the discussion on the proposed objective. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue or expanded on the discussion of the objective equation. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the relationship between equations 4 and 3, specifically asking if the improvement of the designed solutions in Table 5 is significant on some datasets. It provides an example of marginal improvement on the OfficeHome dataset, where the CSAC achieves 64.35 and the proposed solution achieves 64.71. However, the comment does not offer explicit guidance on how the authors should address this issue or what specific actions they should take to improve the significance of their results. The action is implicit and vague, as it does not provide concrete steps for the authors to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the relationship between equations 4 and 3, specifically asking if the improvement of the designed solutions in Table 5 is significant on some datasets. It provides an example of marginal improvement on the OfficeHome dataset, where the CSAC achieves 64.35 and the proposed solution achieves 64.71. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in detailing the issue of marginal improvement on certain datasets, but without explicit references to sections or tables, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the relationship between equations 4 and 3 and provides an example of marginal improvement in the results presented in Table 5. It questions whether the improvement of the designed solutions is significant on some datasets, specifically mentioning the OfficeHome dataset where the CSAC achieves 64.35 and the proposed solution achieves 64.71. However, the comment lacks detailed reasoning or references to support the claim that the improvement is not significant. It does not provide a clear explanation of why this specific improvement is considered marginal or how it impacts the overall significance of the results. As a result, the claim is 3, as it is based on a specific observation but lacks comprehensive justification.", "helpfulness_rationale": "The review comment raises a question about the relationship between equations 4 and 3, specifically asking whether the improvement of the designed solutions in Table 5 is significant on some datasets. It provides an example of marginal improvement on the OfficeHome dataset, where the CSAC achieves 64.35 and the proposed solution achieves 64.71. This feedback highlights a potential issue with the significance of the results, prompting the authors to consider the impact of their improvements. However, the comment lacks detailed guidance on how the authors might address this issue or what specific actions they should take to enhance the significance of their results. While it identifies a potential area for improvement, it does not offer concrete suggestions or detailed reasoning, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point claims that using a volumetric representation in the deformation field is not a novel idea, citing VolumeDeform [1] as an example. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or incorporate the suggested approach. The comment lacks concrete guidance on how the authors could improve their work or what specific aspects of their research might benefit from the inclusion of volumetric grids. As a result, the authors are left without a clear understanding of how to proceed with the feedback, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"VolumeDeform [1]\" and the specific task of \"realtime dynamic reconstruction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by pointing out that using volumetric representation is not a novel idea and provides a reference to VolumeDeform [1]. This allows the authors to understand the context and the specific aspect of the paper that needs attention. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using a volumetric representation in the deformation field is not a novel idea, citing VolumeDeform [1]. This claim is 3 as it provides a reference to support the assertion that the idea is not novel. However, it lacks detailed reasoning or examples to fully substantiate the claim, which could leave the authors uncertain about the depth of the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the approach, specifically mentioning that using volumetric representation in the deformation field is not a novel idea and providing a reference to VolumeDeform [1]. While the comment highlights a concern, it does not offer any suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is 3 as it points out a potential area for improvement, but it lacks actionable advice or specific recommendations, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should consider averaging over subword representations, a common practice in certain cases, and provides a specific reference to support this suggestion. This action is clear and concrete, as it directly instructs the authors on how to modify their approach. The authors know exactly what needs to be done to incorporate this suggestion into their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line in the paper (L.490), allowing the authors to accurately identify the part being addressed. It is also specific because it provides a clear suggestion to consider averaging over subword representations, a common practice, and references a specific paper to support this suggestion. This provides the authors with a clear understanding of what needs to be addressed and how to do it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is common to average over subword representations in certain cases, providing a specific reference to support this claim. This allows the authors to understand the basis of the suggestion and potentially incorporate it into their work. However, the comment could be more robust if it included additional examples or a broader discussion of the implications of this approach. Overall, the claim is 3, as it is supported by a reference but lacks depth in explanation or examples.", "helpfulness_rationale": "The review comment identifies a specific detail in the paper, namely the use of the first subword token\"s embedding as the verb embedding, and suggests an alternative approach that is more common, involving averaging over subword representations. It provides a specific reference to support this suggestion, which is helpful for the authors to understand the context and potentially incorporate this approach into their work. However, the comment could be more helpful if it offered additional guidance on how to implement this suggestion or discussed the potential benefits and drawbacks of the alternative approach. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the model AUC can assess discriminant ability but may be difficult to demonstrate consistency with actual risk. It recommends conducting calibration curves to show agreement and encourages the authors to prove the feasibility of the generated scoring system. Additionally, it suggests discussing the differences between the traditional method and the proposed method. However, the comment does not provide explicit guidance on how to implement these suggestions or actions, such as specific steps or examples of how to conduct the calibration curves or discuss the differences. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the feedback. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the model AUC\"s ability to assess discriminant ability and suggests that it may be difficult to demonstrate consistency with actual risk. It recommends conducting calibration curves to show agreement and encourages the authors to prove the feasibility of the generated scoring system. Additionally, it suggests discussing the differences between the traditional method and the proposed method. However, the comment does not specify which part of the paper discusses the model AUC or where the calibration curves or discussions on differences would be most relevant. This makes it weakly grounded, as the authors cannot confidently determine which sections need attention. The comment is specific in its suggestions, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the model AUC can assess discriminant ability but may be difficult to demonstrate consistency with actual risk. It suggests conducting calibration curves to show agreement and encourages the authors to prove the feasibility of the generated scoring system. Additionally, it recommends discussing the differences between the traditional method and the proposed method. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The reasoning is somewhat vague, and the claim is not 5 without additional evidence or context. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the model AUC\"s ability to demonstrate consistency with actual risk, suggesting that calibration curves could be used to show agreement. It also encourages the authors to prove the feasibility of the generated scoring system and to discuss the differences between the traditional method and the proposed method. While the comment provides some guidance on areas for improvement, it lacks specific details or actionable steps for the authors to take. The feedback is 3 as it highlights important aspects that need attention but could be more comprehensive with detailed suggestions or examples. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several concerns about the strength and fairness of the experiments, including the use of position kernels for all baselines, the lack of comparison with baselines using default settings, and the absence of baselines related to BO with discrete and categorial variables. It also points out the lack of discussion regarding the limitations and societal impacts of the proposed approach. While the comment identifies several areas for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The actions are implicit and somewhat vague, as the authors need to infer how to strengthen the experiments, include additional baselines, and discuss limitations and societal impacts. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the strength and fairness of the experiments, specifically questioning why all baselines use position kernels and why default settings are not used. It also notes the absence of baselines related to BO with discrete and categorial variables and suggests a comparison with these baselines. However, the comment does not specify which part of the paper these issues are related to, such as the experimental setup or results section. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the issues raised, the absence of explicit references to sections or figures makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several concerns about the strength and fairness of the experiments, including the use of position kernels for all baselines, the lack of comparison with baselines using default settings, and the absence of baselines related to BO with discrete and categorial variables. The comment also suggests that the paper lacks discussion on the limitations and societal impacts of the proposed approach. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of detailed justification makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 2, as it provides some basis for concern but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises several concerns about the strength and fairness of the experiments, specifically questioning the use of position kernels for all baselines and the lack of comparison with baselines using default settings. It also points out the absence of baselines related to BO with discrete and categorial variables and suggests a comparison with these baselines. Additionally, the comment notes that the paper does not mention much about the limitations or societal impacts of the proposed approach. While the comment identifies areas for improvement, it lacks detailed guidance on how to address these issues or what specific actions the authors should take. The feedback is 3 as it provides a general direction for improvement but could be more comprehensive with specific suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the sparsity patterns and suggests that the authors should clarify whether the observed results are specific to the sparsity detection problem or generalize to GNNs in general. It also points out that the presentation of bits in Section 4.3 could be improved. However, the comment does not provide explicit instructions on how the authors should address these issues or what specific changes to make. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to clarify the results and improve the presentation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the question about the sparsity patterns and the suggestion to clarify the results and improve the presentation of bits in that section. This provides clear guidance on how the authors should respond. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the sparsity patterns and suggests that the authors should clarify whether the results are specific to the sparsity detection problem or generalize to GNNs in general. It also points out that the presentation of bits in Section 4.3 could be improved. However, the comment lacks specific examples or detailed reasoning to support the claim that the sparsity patterns do almost equally well and that there is no insight provided. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the sparsity patterns observed in the results, suggesting that the authors should clarify whether these patterns are specific to the sparsity detection problem or if they generalize to GNNs in general. It also points out that the presentation of bits in Section 4.3 could be improved. While the comment identifies an area for clarification and suggests a potential improvement in presentation, it lacks specific guidance on how the authors should address these issues or what changes might be necessary. The feedback is 3 as it directs the authors to areas that need attention, but it could be more comprehensive with detailed suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. While the comment implies that this comparison would be beneficial, it does not explicitly instruct the authors to make this comparison or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to include such a comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not specify which part of Section 6 this comparison should be made, leaving the authors to infer that it should be done in the context of the related work or discussion section. This lack of specific guidance makes the comment weakly grounded. The comment is specific in suggesting what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact part of the paper that requires attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. Without additional context or references, the claim remains 3, as it is based on an assumption rather than a wellsupported argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. This feedback is 3 as it identifies a potential area for improvement by highlighting the need for a comparative analysis. However, the comment lacks specific guidance on how to implement this comparison or what aspects of the prior work should be considered. Without detailed suggestions or examples, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the performance of the paper is closely related to the number of scenarios used for training. It proposes examining the performance with different numbers of scenarios, noting that the current paper uses a fixed number of 200. However, the comment does not provide explicit guidance on how to conduct this examination or what specific aspects of the performance should be analyzed. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests examining the performance with different numbers of scenarios, implying that the number of scenarios used for training might influence the results. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. The comment is weakly grounded because the authors cannot confidently determine which part of the paper it addresses. It is also specific in suggesting an area for further examination, but without clear guidance on how to implement this suggestion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the performance of the paper is closely related to the number of scenarios used for training. It proposes examining the performance with different numbers of scenarios, noting that the current paper uses a fixed number of 200. However, the comment does not provide any specific reasoning, examples, or references to support this claim. It lacks detailed justification or evidence to substantiate the assertion that the performance is closely related to the number of scenarios. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the performance of the paper might be closely related to the number of scenarios used for training. It proposes examining the performance with different numbers of scenarios, noting that the current paper uses a fixed number of 200. However, the comment does not provide specific guidance on how to conduct this examination or what aspects of the performance should be analyzed. While it identifies a potential area for further investigation, it lacks detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it offers a direction for improvement but does not fully support the authors in executing it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the relationship between generating a quality label and the model\"s ability to predict it. It also suggests considering the impact of disturbances in the training data on the model\"s performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what actions they should take to improve their draft. The feedback is vague and lacks concrete details, making it difficult for the authors to understand how to respond or incorporate the suggestions. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the relationship between generating a quality label and the model\"s ability to predict it, suggesting that disturbances in the training data might affect the model\"s performance. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to identify the exact area where the comment is relevant. While the comment is specific in its inquiry about the impact of disturbances, the absence of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the relationship between generating a quality label and the model\"s ability to predict it, specifically questioning whether disturbances in the training data might affect the model\"s performance. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or logical reasoning to substantiate the concern, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the relationship between generating a quality label and the model\"s ability to predict it. It suggests considering the impact of disturbances in the training data on the model\"s performance, which is a valuable point for the authors to explore. However, the comment lacks depth and specificity, as it does not provide detailed guidance or suggestions on how the authors might address this issue or what experiments could be conducted to investigate it. Without actionable advice or a clear framework for improvement, the comment is 3, as it identifies an important area for consideration but does not fully support the authors in enhancing their work. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the restrictive nature of the bounded noise assumption in stochastic optimization literature and mentions several efforts to extend these noise conditions, citing specific works. However, it does not provide explicit or implicit actions for the authors to take, such as suggesting alternative assumptions or exploring the cited works. The comment lacks concrete guidance on how the authors might address the issue or incorporate the suggested references. As a result, the authors are left without clear direction on how to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the bounded noise assumption in stochastic optimization literature, referencing specific works that extend these noise conditions. However, it does not specify which part of the paper discusses the bounded noise assumption or how it relates to the authors\" work. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, while the comment mentions specific works, it does not provide detailed guidance on how these works could be integrated or discussed in the paper. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the bounded noise assumption, while common, is somewhat restrictive in stochastic optimization literature. It provides references to specific works that have extended these noise conditions, such as [A. Khaled and P. Richt\u00b4arik]. Better theory for sgd in the nonconvex world. TMLR 2023. [R. Gower, O. Sebbouh, and N. Loizou] Sgd for structured nonconvex functions: Learning rates, minibatching and interpolation. AISTATS 2021. However, the comment does not offer a detailed explanation of why the bounded noise assumption is restrictive or how the cited works address this limitation. While the references are provided, the reasoning behind the claim is not fully elaborated, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the bounded noise assumption, which is a common assumption in stochastic optimization literature. It acknowledges that this assumption is somewhat restrictive and points out several efforts to extend these noise conditions, citing specific works. However, the comment does not provide actionable guidance or suggestions on how the authors might address this limitation or incorporate the suggested references into their work. While it highlights an important aspect of the literature, it lacks depth and does not offer concrete steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights several writing issues, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide any specific guidance or suggestions on how the authors should address these issues. The comment lacks explicit instructions or concrete steps for improvement, leaving the authors without a clear path to follow. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment identifies several writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which sections of the paper these issues are present in, making it difficult for the authors to pinpoint the exact areas that need improvement. The comment is 1 as it does not provide specific references or sections, and it is also not specific because it does not detail the nature of the writing issues. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper contains severe writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, the comment does not provide any specific examples or references to support these claims, making it difficult for the authors to understand the nature of the issues or how to address them. Without detailed examples or references, the claim is 1, as it lacks the necessary evidence to be substantiated. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies significant writing issues in the paper, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it lacks specific examples or detailed suggestions on how the authors might address these issues. While it highlights areas for improvement, the comment does not provide actionable guidance or constructive feedback that would help the authors enhance the clarity and accuracy of their writing. As a result, the comment is 2, as it offers a general overview of the problems but lacks depth and specificity to guide the authors effectively."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that exploring energy models for image generation is a promising direction, noting that it is less explored compared to GANs and VAEs. It also points out that the motivation and goals of the model are similar to a prior VAE paper, suggesting that the authors should consider this in their work. However, the comment does not provide explicit guidance on how the authors should explore energy models or how they should address the similarity to the prior VAE paper. The action is implicit and vague, as the authors are left to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of energy models for image generation and compares it to GANs and VAEs, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the motivation and goals of the model, noting that they are similar to a prior VAE paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that energy models for image generation are less explored compared to GANs and VAEs, suggesting that exploring them further is a promising direction. It also notes that the motivation and goals of the model are similar to a prior VAE paper, implying that the authors should consider this in their work. However, the comment lacks specific examples or references to support the claim about the relative unexploredness of energy models, making it 3. The suggestion to consider the prior VAE paper is clear, but the lack of detailed reasoning or examples weakens the overall verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to explore energy models for image generation, noting that it is less explored compared to GANs and VAEs. This offers a promising direction for future work. Additionally, the comment points out that the motivation and goals of the model are similar to a prior VAE paper, which could help the authors contextualize their work and avoid redundancy. However, the comment could be more helpful if it provided specific guidance on how to explore energy models or how to address the similarity to the prior VAE paper. Overall, the feedback is 4 as it offers valuable insights and directions for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the application of imitation learning, suggesting that obtaining labeled data through optimal problemsolving is necessary. However, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take to improve their draft. The comment lacks concrete suggestions or detailed instructions on how to conduct experiments or analyze the impact of labeled data size. As a result, the authors are left without a clear understanding of how to respond to this feedback, making the comment 1.", "grounding_specificity_rationale": "The comment raises a concern about the necessity of obtaining labeled data for imitation learning, suggesting that there are no experiments on the difficulties of obtaining this data or how performance changes with the size of the labeled data. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or methodology. This lack of grounding makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in its critique, the absence of explicit references to the paper makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the necessity of obtaining labeled data for imitation learning and suggests that there are no experiments on the difficulties of obtaining this data or how performance changes with the size of the labeled data. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue raised. Therefore, the comment is considered 2, as it lacks sufficient justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the application of imitation learning, specifically questioning the necessity of obtaining labeled data and the lack of experiments on the challenges and performance changes associated with different sizes of labeled data. While the comment highlights a gap in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is 3 as it points out a potential area for further exploration, but it lacks actionable advice, making it difficult for the authors to fully benefit from the comment. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the use of the term \"certificate\" in the paper, specifically at line 267. It suggests that the term might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue. The authors are left without a clear understanding of what changes or actions they should take to clarify the terminology. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the use of the term \"certificate\" in the paper, particularly at line 267. It highlights a potential misinterpretation due to the strong meaning of \"certificate\" in complexity theory. However, the comment does not provide specific guidance on how the authors should address this issue or what changes they should make to the paper. The authors may infer that they need to clarify the terminology, but the comment lacks explicit instructions or detailed suggestions. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the use of the term \"certificate\" in the paper might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any specific examples or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand why the term might be misinterpreted or how it could be clarified. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of the term \"certificate\" in the paper, specifically at line 267. It points out that the term might be misinterpreted due to its strong meaning in complexity theory. While the comment highlights a potential area for clarification, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it directs the authors to a specific area that needs attention, but it lacks depth and actionable advice. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that more experiments on deeper networks, such as ResNet50, and other network structures, such as MobileNet, are needed to strengthen the paper. It provides references to relevant works, which implies that the authors should conduct additional experiments to include these network structures. However, the comment does not explicitly instruct the authors to perform these experiments or provide detailed guidance on how to do so. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more experiments on deeper networks, such as ResNet50, and other network structures, such as MobileNet, are needed to strengthen the paper. It provides references to relevant works, which implies that the authors should consider including these experiments. However, the comment does not specify which part of the paper these additional experiments should be conducted in or how they would enhance the paper. The lack of specific guidance makes it difficult for the authors to understand exactly what needs to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that more experiments on deeper networks, such as ResNet50, and other network structures, such as MobileNet, are needed to strengthen the paper. It provides references to relevant works, which implies that the authors should consider conducting additional experiments to include these network structures. However, the comment lacks specific details on how these experiments would be conducted or what specific aspects of the paper would benefit from such experiments. The references provided are relevant but do not offer detailed guidance on how to implement the suggested changes. Therefore, the claim is 3, as it provides some support but lacks depth and detail.", "helpfulness_rationale": "The review comment suggests that more experiments on deeper networks, such as ResNet50, and other network structures, such as MobileNet, are needed to strengthen the paper. It provides references to relevant works, which implies that the authors should consider conducting additional experiments to include these network structures. However, the comment lacks specific guidance on how to conduct these experiments or what specific aspects of the paper would benefit from such additional experiments. While it identifies a need for more comprehensive experimentation, it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proxlinear subproblem in Eq.(1) can be reformulated using the conjugate function, making the motivation of Algorithm 1 unclear. However, it does not provide explicit guidance on how the authors should reformulate the subproblem or how this reformulation would clarify the motivation of Algorithm 1. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the proxlinear subproblem in Eq.(1) and suggests that it can be reformulated using the conjugate function, aligning with the subproblem in Algorithm 1. This provides a clear and specific reference to the part of the paper being discussed, allowing the authors to accurately identify the section being addressed. The comment is fully grounded as it explicitly mentions the equation and algorithm, and it is specific because it details the suggestion for reformulation and its implications for the motivation of Algorithm 1. Therefore, this comment is classified as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that the proxlinear subproblem in Eq.(1) can be reformulated using the conjugate function, aligning with the subproblem in Algorithm 1. This claim is 3 as it provides a specific suggestion for reformulation, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to understand the implications of this reformulation to fully grasp the point. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation of Algorithm 1, suggesting that the proxlinear subproblem in Eq.(1) could be reformulated using the conjugate function to align with the subproblem in Algorithm 1. This observation raises a concern about the clarity of the motivation, which could be a valuable point for the authors to address. However, the comment lacks specific guidance on how the authors might reformulate the subproblem or how this reformulation would enhance the motivation of Algorithm 1. While it points out a potential area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it highlights a potential issue but does not offer comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the use of multiple local prompts, suggesting that while it is intuitive, the features and their positions vary across different categories. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes are needed. The comment implies that the authors should consider the variability in features and positions, but it lacks concrete instructions on how to implement this consideration. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of using multiple local prompts, noting that while it is intuitive, the features and their positions vary across different categories. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the variability in features and positions, but the lack of grounding makes it challenging for the authors to understand where to address this concern. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that while it is intuitive that including multiple local prompts helps, the features and their positions are not the same for different categories. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of multiple local prompts, noting that while it is intuitive, the features and their positions vary across different categories. This observation is insightful and highlights a potential area for improvement in the paper. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what changes could be made to improve the consistency of feature representation across categories. While it points out a valid concern, the feedback could be more helpful if it provided actionable advice or examples of how to implement the suggested improvements. Therefore, the comment is 3, as it identifies a meaningful issue but does not fully guide the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: why the results of Table 6 are not aligned with Table 1 (MCTpair) and what the ablation studies of MCT without the adaptive metrics entail. While the questions prompt the authors to provide explanations and clarify certain aspects of their results, they do not offer explicit instructions or suggestions on how to address these issues. The authors are left to infer that they need to align the results and conduct ablation studies, but without concrete guidance on how to do so, the feedback remains somewhat vague. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment raises two questions regarding the results presented in Table 6 and Table 1, specifically questioning why the results are not aligned and what the ablation studies of MCT without adaptive metrics entail. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact sections being addressed. The comment is specific in its questions but lacks grounding as it does not provide clear references or context for the tables or metrics mentioned. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the alignment of results in Table 6 with Table 1 and the relevance of ablation studies for MCT without adaptive metrics. However, it does not provide any claims, opinions, or suggestions that require verification or justification. The comment is purely descriptive, asking for clarification or additional information, which does not contribute to the authors\" understanding or improvement of the paper. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises two questions regarding the alignment of results in Table 6 with Table 1 (MCTpair) and the relevance of ablation studies for MCT without adaptive metrics. While these questions highlight potential areas of concern or confusion, they do not provide specific guidance or suggestions on how the authors might address these issues. The feedback is 3 as it identifies areas that need clarification, but it lacks actionable advice or detailed explanations, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that similar analyses have been conducted in prior works, noting that the results are not particularly surprising. It provides specific examples, such as the study of CIFAR10 models on distribution shifts in RobustBench and the evaluation of adversarially trained models in [A, B]. However, the comment does not offer explicit or implicit suggestions for how the authors might address these points or improve their work. The authors are left without guidance on what specific aspects of their analysis could be enhanced or clarified to differentiate their work from existing studies. As a result, the comment lacks actionable feedback, making it 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific prior works and examples, such as RobustBench and [A, B], allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what the authors should consider by noting that similar analyses have been conducted on smaller scales and that the results are not particularly surprising. This provides clear guidance on how the authors might improve their work by addressing these points. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that similar analyses have been conducted in prior works, such as RobustBench and [A, B], and that the results are not particularly surprising. It provides specific examples, such as the study of CIFAR10 models on distribution shifts and the evaluation of adversarially trained models. However, the comment lacks detailed reasoning or references to support the claim that the results are not surprising or that the analyses are similar. The absence of a clear explanation or evidence makes it difficult for the authors to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies that similar analyses have been conducted in prior works, specifically mentioning RobustBench and other studies that have explored the robustness of CIFAR10 models on distribution shifts. It also notes that the results are not particularly surprising, which suggests that the authors should consider how their work differentiates itself from existing studies. However, the comment lacks specific guidance on how the authors might address these points or what aspects of their analysis could be improved to provide a more novel contribution. While it highlights an area for improvement, the feedback is 3 as it provides a starting point for the authors to consider, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the 10 subtasks in the paper are too simplistic for the bAbi task and that the final model could solve all of them. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what specific changes are needed to make the subtasks more challenging or relevant. The comment lacks concrete suggestions or actionable steps for the authors to take, leaving them without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the 10 subtasks are too simplistic for the bAbi task and that the final model could solve all of them. However, it does not specify which part of the paper these subtasks are discussed in, making it difficult for the authors to identify the exact section or context. While the comment implies that the authors should consider making the subtasks more challenging, it lacks specificity in terms of how to achieve this or what aspects of the tasks need to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the 10 subtasks are too simplistic for the bAbi task and that the final model could solve all of them. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the complexity of the 10 subtasks used in the paper, suggesting that they might be too simplistic for the bAbi task. The comment implies that the final model could solve all the subtasks, which raises concerns about the depth and challenge of the tasks. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or make the subtasks more challenging. While it points out a potential area for improvement, it does not provide actionable steps or detailed feedback, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the term \"sequence of episodes\" used in the paper, specifically asking for clarification on whether \"practice\" and \"evaluation\" are the two types of this sequence. It also mentions that the paper seems related but does not negate its novelty. While the comment explicitly asks for clarification, it does not provide concrete guidance on how the authors should address this question or what specific aspects of the term need clarification. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the term and its types. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L167,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by asking for clarification on the term \"sequence of episodes\" and whether \"practice\" and \"evaluation\" are the two types of this sequence. Additionally, it mentions that the paper seems related but does not negate its novelty, which provides context for the authors to understand the relevance of the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the term \"sequence of episodes\" and suggests that the paper might be related to existing work. However, it does not provide specific examples or references to support the claim that the paper is related. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific point of confusion regarding the term \"sequence of episodes\" in the paper, asking for clarification on whether \"practice\" and \"evaluation\" are the two types of this sequence. It also notes that the paper seems related to existing work, which could be relevant for the authors to consider. However, the comment lacks detailed guidance on how the authors might address this confusion or explore the related work further. While it points out an area that needs clarification, it does not provide actionable steps or suggestions for improvement, making it 3. The feedback is clear but could be more comprehensive to fully assist the authors in enhancing their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the classification of the study as an \"ablation\" study, arguing that it does not involve removing a component of the method. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue or what changes might be necessary. The comment lacks concrete guidance on how to revise the study or clarify its nature. As a result, the authors are left without a clear understanding of what action to take to address the concern. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the classification of the study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not specify which part of the paper this comment is addressing, making it difficult for the authors to pinpoint the exact section or aspect of the study being discussed. Additionally, the comment lacks specificity in explaining why the study is not considered an ablation study, as it does not provide examples or detailed reasoning. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the classification of the study as an \"ablation\" study, arguing that it does not involve removing a component of the method. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or evidence to substantiate the assertion that the study is not an ablation study. Without such evidence, the claim remains unsubstantiated and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the classification of the study as an \"ablation\" study, arguing that it does not involve removing a component of the method. This feedback is 3 as it highlights a potential misunderstanding or mischaracterization of the study\"s nature. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify the study\"s classification. Without actionable advice or examples, the authors may struggle to understand the implications of the comment and how to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation would be stronger if the base DA methods were similarly evaluated with and without the architectural competitors such as AutoDial and AdaBN, which are direct competitors to TransferNorm (TN). This provides a clear and explicit action for the authors to take, as they can now understand exactly what additional evaluations are needed to strengthen the comparison. The comment is specific in its suggestion, detailing which methods should be included in the evaluation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the evaluation would be stronger if the base DA methods were similarly evaluated with and without the architectural competitors such as AutoDial and AdaBN, which are direct competitors to TransferNorm (TN). However, the comment does not specify which part of the paper this evaluation is intended for, making it weakly grounded. It is specific in suggesting the inclusion of additional evaluations, but without clear references to sections or figures, the authors may find it challenging to identify the exact part of the paper that needs improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation would be stronger if the base DA methods were similarly evaluated with and without the architectural competitors such as AutoDial and AdaBN, which are direct competitors to TransferNorm (TN). However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would enhance the evaluation. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the evaluation would be stronger if the base DA methods were similarly evaluated with and without the architectural competitors such as AutoDial and AdaBN, which are direct competitors to TransferNorm (TN). This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their evaluation by including additional comparisons. By evaluating the base DA methods with and without these architectural competitors, the authors can provide a more comprehensive and robust assessment of the proposed TransferNorm architecture. This feedback is 4 as it offers a clear and constructive suggestion for improvement, though it could be further detailed to provide more specific guidance on how to conduct these additional evaluations. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the implementation details of the attention module\"s integration with the ResNet20 architecture. It asks for clarification on how the attention module is attached, how many modules are used, and where they are placed (e.g., after each block or stage). While the comment explicitly asks for clarification, it does not provide any guidance on how the authors should address these questions or what specific changes might be needed. The action is implicit and vague, as the authors are left to infer that they need to clarify these details in their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the implementation details of the attention module\"s integration with the ResNet20 architecture, specifically asking for clarification on how the attention module is attached, how many modules are used, and where they are placed. However, the comment does not specify which part of the paper these details are discussed or where the authors should provide this clarification. This makes it difficult for the authors to identify the exact section or part of the paper that needs attention. While the comment is specific about the content it addresses, the lack of grounding makes it challenging for the authors to act upon. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the implementation details of the attention module\"s integration with the ResNet20 architecture, specifically asking for clarification on how the attention module is attached, how many modules are used, and where they are placed. However, the comment does not provide any evidence or reasoning to support why these details are important or how they impact the paper. It lacks specific examples or references, making it difficult for the authors to understand the basis of the concern. As a result, the claim is not verifiable, and the comment does not provide actionable guidance. Therefore, it is rated as 1.", "helpfulness_rationale": "The review comment raises specific questions about the implementation details of the attention module\"s integration with the ResNet20 architecture. It asks for clarification on how the attention module is attached, how many modules are used, and where they are placed (e.g., after each block or stage). While the comment identifies a potential area of confusion for the authors, it does not provide any suggestions or guidance on how to address these questions or improve the clarity of the paper. The feedback is 3 as it points out a specific area that needs clarification, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that the linear convergence rates rely on Theorem 8, which is located at the end of the appendix and whose proof is not clear enough. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the proof of Theorem 8 or provide a clearer explanation of how the linear convergence rates are derived. This lack of explicit action makes the comment 3, as it points out a specific area that needs attention but does not provide detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 8,\" which is located at the end of the appendix. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights a particular issue with the linear convergence rates, noting that the proof of Theorem 8 is not clear enough. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the label is 5.", "verifiability_rationale": "The review point claims that all linear convergence rates rely on Theorem 8, which is located at the end of the appendix and whose proof is not clear enough. This claim is 3 as it points out a specific issue with the paper, but it lacks detailed reasoning or references to support the claim fully. The authors would need to infer the basis for this claim, which could be improved by providing more context or justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the linear convergence rates rely on Theorem 8, which is located at the end of the appendix and whose proof is not clear enough. This feedback is 3 as it highlights a potential area for improvement, specifically the clarity and presentation of the proof of Theorem 8. However, the comment could be more helpful if it provided suggestions on how the authors might improve the clarity or presentation of the proof. Without specific guidance or suggestions, the authors may struggle to address the issue effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the applicability of the proposed method to natural images, such as CIFAR10, given that it has been tested on digit or text images like MNIST and SVHN. While the comment raises a valid concern about the method\"s generalizability, it does not provide explicit guidance on how the authors might address this issue or what steps they should take to test the method on natural images. The action is implicit, as the authors need to infer that they should explore the method\"s performance on natural images and consider expanding their experiments to include such data. However, the lack of concrete suggestions or detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment questions the applicability of the proposed method to natural images, such as CIFAR10, given that it has been tested on digit or text images like MNIST and SVHN. However, it does not specify which part of the paper discusses the method\"s application or testing on these datasets. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, while the comment raises a valid point about the method\"s potential use on natural images, it does not provide specific guidance on how to address this issue or what experiments might be needed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the applicability of the proposed method to natural images, such as CIFAR10, given that it has been tested on digit or text images like MNIST and SVHN. This is a valid concern, as the method\"s performance on natural images is crucial for its realworld applicability. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the method is limited to digit or text images. Without additional context or evidence, the claim remains 3, as it lacks sufficient justification for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the applicability of the proposed method to natural images, such as CIFAR10, given that it has been tested on digit or text images like MNIST and SVHN. This is a pertinent point, as the method\"s performance on natural images is crucial for its realworld applicability. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or what additional experiments could be conducted to evaluate the method\"s performance on natural images. While it identifies a potential limitation, it lacks actionable advice, making it 3. The authors would need to infer that they should explore the method\"s applicability to natural images and consider expanding their experiments accordingly. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should explore existing work that offers a way to compute the contribution of FFNs, even if a linear decomposition is not possible. It also recommends adding a line or two to indicate that there is no solution for this, which would improve the readability and provide a clearer overall picture for the reader. The comment is explicit in suggesting what should be done and provides concrete details on how to implement the action, such as exploring existing work or adding a note about the difficulty of the problem. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FFNs\" and \"linear decomposition,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests exploring existing work to compute the contribution of FFNs, even if a linear decomposition is not possible, and recommends adding a note about the difficulty of the problem. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should explore existing work to compute the contribution of FFNs, even if a linear decomposition is not possible. It recommends adding a note about the difficulty of this problem to improve readability. However, the comment lacks specific references or examples to support the claim that such work exists or does not exist. Without detailed evidence or examples, the claim is 3, as it provides a general direction but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors explore existing work that could approximate the contribution of FFNs, even if a linear decomposition is not feasible. It also recommends adding a note to the paper to indicate that there is no solution for this, which would enhance the readability and provide a clearer overall picture for the reader. This feedback is actionable and provides specific guidance on how the authors might address the issue, making it 4. However, it could be more helpful if it included examples of existing work or a more detailed explanation of the challenges involved. Overall, the comment is 4 as it offers clear suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about questionable design choices, specifically questioning the use of perplexity as a measure of semantic information retention after finetuning. It also points out that while perplexity relates to the original task, there are other aspects of domain drift that are possible and separate from catastrophic forgetting. The comment asks how such factors are controlled, which provides a clear and explicit action for the authors to take. The authors are directed to consider and address these concerns, making the comment 5.", "grounding_specificity_rationale": "The comment raises concerns about questionable design choices, specifically questioning the use of perplexity as a measure of semantic information retention after finetuning. It highlights that while perplexity relates to the original task, there are other aspects of domain drift that are possible and separate from catastrophic forgetting. The comment asks how such factors are controlled, which provides a clear direction for the authors to address these concerns. However, the comment does not specify which part of the paper discusses these design choices or how they are controlled, making it weakly grounded. The specificity of the comment is good as it clearly identifies the issue and asks for clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the use of perplexity as a measure of semantic information retention after finetuning, questioning its relevance to domain drift. It suggests that perplexity might not capture aspects of domain drift separate from catastrophic forgetting. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the claim is difficult to verify, making it 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the methodology, specifically questioning the use of perplexity as a measure of semantic information retention after finetuning. It highlights that perplexity might not capture aspects of domain drift separate from catastrophic forgetting, which is a crucial consideration in the study. The comment also asks how such factors are controlled, providing a clear direction for the authors to address these concerns. This feedback is actionable and constructive, as it guides the authors to reconsider their methodology and ensure that their analysis is comprehensive. However, the comment could be more helpful if it provided specific examples or suggestions for alternative measures. Overall, the comment is 4, as it offers valuable insights and actionable feedback that can improve the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the applicability of the method to real and categorical features, given that the work uses only binary features. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to the method to accommodate these feature types. The comment lacks concrete guidance on how to extend the method or what specific steps could be taken to make it applicable to real and categorical features. As a result, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the applicability of the method to real and categorical features, given that the work uses only binary features. However, it does not specify which part of the paper discusses the use of binary features or how the method is applied. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in questioning the applicability of the method to real and categorical features, providing a clear direction for the authors to consider. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the applicability of the method to real and categorical features, given that the work uses only binary features. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The comment lacks sufficient evidence or justification to be considered verifiable. Therefore, it is rated as 1.", "helpfulness_rationale": "The review comment raises a valid concern about the applicability of the method to real and categorical features, which are common in realworld data. It highlights a potential limitation in the scope of the work, suggesting that the method might not be directly applicable to all types of data. However, the comment does not provide any specific guidance or suggestions on how the authors could address this issue or extend their method to handle real and categorical features. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the algorithm for constructing coresets is not novel, as existing coreset frameworks for classical kmeans and (k,z) clusterings have been extended to the kernelized setting. However, the comment does not provide any specific suggestions or actions for the authors to take to address this issue. It lacks concrete guidance on how the authors might improve the novelty of their work or what specific aspects of their algorithm could be made more novel. As a result, the authors are left without a clear understanding of how to proceed or what changes are needed to enhance the novelty of their approach. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the algorithm for constructing coresets, noting that it is not novel and that existing frameworks have been extended to the kernelized setting. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table. The comment is vague in terms of grounding, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment does not provide specific guidance on how to improve the novelty of the algorithm or what aspects of the existing frameworks could be extended. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the algorithm for construction of coresets is not novel, as existing coreset frameworks for classical kmeans and (k,z) clusterings have been extended to the kernelized setting. This claim is 3 as it provides a basis for the authors to understand the existing work and potentially address the novelty concern. However, it lacks specific examples or references to support the claim fully, which could make it difficult for the authors to fully grasp the context and implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the algorithm for constructing coresets, noting that existing frameworks have been extended to the kernelized setting. While this observation is accurate, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. It lacks actionable advice or constructive feedback that could help the authors improve their draft. As a result, the comment is 2, as it highlights a concern but does not offer a clear path forward for the authors to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale for considering only ECG segments with one label assigned, suggesting that including all reports might be easier. However, it does not provide explicit guidance on how the authors should address this concern or what changes might be necessary. The action is implicit, as the authors need to infer that they should consider the impact of including all reports. While the comment is somewhat specific in questioning the rationale, it lacks concrete suggestions on how to implement this change or what specific aspects of the reports might be easier to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the rationale for considering only ECG segments with one label assigned, suggesting that including all reports might be easier. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to identify the exact section being addressed. While the comment is specific in questioning the rationale, the absence of explicit grounding makes it challenging for the authors to understand the context and relevance of the question. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale for considering only ECG segments with one label assigned, suggesting that including all reports might be easier. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how it relates to the paper\"s content. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the rationale behind considering only ECG segments with one label assigned, suggesting that including all reports might be easier. This feedback is 3 as it highlights a potential area for clarification or improvement in the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern. Without actionable advice or examples, the authors may find it challenging to fully understand and incorporate the feedback into their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the number of variables in the instances used in the paper, suggesting that the authors may want to generate instances with more constraints and variables. It notes that the current instances have a maximum of 7 variables, which raises concerns about the ability of LLMs to model problems with large instance sizes. However, the comment does not provide explicit guidance on how the authors should generate these additional instances or what specific steps they should take to address this concern. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the number of variables in the instances used in the paper, suggesting that the authors may want to generate instances with more constraints and variables. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion to increase the number of variables, the absence of grounding information makes it challenging for the authors to address the concern effectively. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the number of variables in the instances used in the paper, suggesting that the authors may want to generate instances with more constraints and variables. However, the comment does not provide any specific reasoning, examples, or references to support why this is a concern or how it impacts the paper. Without additional context or evidence, the claim remains 1, as the authors cannot confidently understand the basis of the concern or how to address it. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a concern about the number of variables in the instances used in the paper, suggesting that the authors may want to generate instances with more constraints and variables. This is a valid point, as the current instances have a maximum of 7 variables, which may limit the ability of LLMs to model problems with large instance sizes. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as proposing additional experiments or providing more detailed analysis. While it identifies a potential area for improvement, the feedback is somewhat limited in its actionable value, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the interpretation of the statement \"NodeSort differentially sorts nodes depending on the base node.\" It asks for clarification on whether the base node affects the ordering, key nodes for attention, and model performance. While the comment prompts the authors to clarify their understanding, it does not provide explicit instructions or suggestions on how to address this clarification. The action is implicit, as the authors need to infer that they should clarify the statement. However, the comment lacks concrete guidance on what specific aspects to focus on or how to provide the clarification. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the interpretation of a specific statement in the paper, \"NodeSort differentially sorts nodes depending on the base node.\" However, it does not specify which part of the paper this statement is located in, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its request for clarification but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the interpretation of a specific statement in the paper, \"NodeSort differentially sorts nodes depending on the base node.\" It asks for clarification on whether the base node affects the ordering, key nodes for attention, and model performance. However, the comment does not provide any evidence, reasoning, or references to support the claim that this interpretation is incorrect or needs clarification. The authors are left to infer the meaning of the statement, which makes the comment 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the interpretation of a specific statement in the paper, \"NodeSort differentially sorts nodes depending on the base node.\" It asks whether the base node affects the ordering, key nodes for attention, and model performance. This question prompts the authors to clarify their understanding of the statement, which could help them better understand the implications of the method. However, the comment lacks detailed guidance or suggestions on how to address this clarification or what specific aspects of the statement need further explanation. While it provides a starting point for discussion, it does not offer comprehensive feedback or actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the direction of the arrow in Figure 2 and its purpose in influencing n^(i). While it prompts the authors to consider the rationale behind the arrow\"s direction, it does not provide explicit guidance on how to address this issue or what changes might be necessary. The action is implicit, as the authors need to infer that they should clarify the arrow\"s direction and its impact on n^(i). However, the comment lacks concrete details on how to implement this suggestion, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment questions the direction of the arrow in Figure 2 and its purpose in influencing n^(i). It does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. However, the comment is specific in its request for clarification regarding the arrow\"s direction and its impact on n^(i). This suggests that the authors should provide a detailed explanation of the arrow\"s direction and its relevance to the influence on n^(i). Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the direction of the arrow in Figure 2 and its purpose in influencing n^(i). It does not contain a subjective claim or suggestion, but rather a request for clarification or explanation. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a specific question about the direction of the arrow in Figure 2 and its purpose in influencing n^(i). It highlights a potential point of confusion or lack of clarity in the paper, which could hinder understanding. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the clarity of the figure. While it identifies a potential area for improvement, it lacks actionable advice, making it 3. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the use of abbreviations in Table 5, noting that they are not defined. While the comment identifies a problem, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to define the abbreviations, but the comment lacks concrete instructions on which abbreviations need to be defined and how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the abbreviations in Table 5 are not defined, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that many abbreviations lack definition and cause confusion, specifically mentioning that \u201cAR\u201d in Table 5 stands for domain adaptation tasks and algorithms. While the comment identifies a potential issue with clarity and consistency in the use of abbreviations, it does not provide specific examples or references to support the claim. The authors are left to infer that the lack of definition for abbreviations could hinder understanding, but without further elaboration or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of abbreviations in Table 5, noting that they are not defined. This is a clear and actionable piece of feedback that could help the authors improve the clarity and readability of their paper. By defining the abbreviations, the authors can ensure that their work is easily understood by readers. However, the comment could be more helpful if it provided guidance on which abbreviations need to be defined or suggested specific definitions. Overall, the comment is 3 as it highlights a clear area for improvement, but it lacks depth and detail to fully assist the authors."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the fairness of the performance comparison in Table 1 due to the use of different sample weights in the training process for VINS compared to the baselines. However, it does not provide explicit or implicit actions for the authors to take to address this concern. The comment suggests that the authors should consider the impact of different sample weights on the comparison, but it does not offer specific guidance on how to adjust the comparison or what steps to take to ensure fairness. As a result, the authors are left without clear instructions on how to address the issue, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the fairness of the performance comparison in Table 1, specifically pointing out that VINS uses different sample weights during training compared to most baselines. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the potential issue with the comparison, but without clear references to the table or section, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance comparison in Table 1 is unfair due to the use of different sample weights in the training process for VINS compared to most baselines. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand why the comparison is unfair or how to address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the performance comparison in Table 1, specifically noting that VINS uses different sample weights during training compared to most baselines. This observation raises concerns about the validity of the comparison, as the use of different sample weights could significantly impact the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or ensure a fair comparison. While it highlights a potential problem, it lacks actionable advice or constructive feedback, making it 3. The authors would need to infer how to improve their draft based on this feedback, which limits its overall impact."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the time complexity of the method might be too high if the reply buffer is too large, referencing a specific paper. While it identifies a potential issue, it does not provide explicit guidance on how to address this problem or what specific aspects of the method need to be improved. The action is implicit and vague, as the authors are left to infer that they need to consider the impact of the reply buffer size on the method\"s efficiency. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the time complexity issue related to a large reply buffer, referencing a specific paper. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue, suggesting that the time complexity might be too high if the reply buffer is too large, and provides a reference to support this claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the time complexity will be too high if the reply buffer is too large, referencing a specific paper. While the claim is supported by the reference, it lacks detailed reasoning or examples to fully substantiate the assertion. The authors would benefit from a more indepth explanation of why a large reply buffer could lead to high time complexity, potentially with additional references or examples. Therefore, the comment is 4, as it provides some support but could be more robust.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the method when the reply buffer is too large, referencing a specific paper. This feedback is clear and actionable, as it highlights a potential area for improvement in the method\"s efficiency. However, the comment could be more helpful if it provided additional guidance on how to address this issue or suggested specific techniques to optimize the method. Overall, the comment is 4, as it offers a clear direction for improvement but lacks depth in terms of actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that a brief conclusion and a summary of the paper\"s contributions should be included. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be added to their draft. The comment is specific in its request, detailing the exact elements that should be included, making it 5. Therefore, this comment aligns with a score of 5.", "grounding_specificity_rationale": "The comment suggests that a brief conclusion and a summary of the paper\"s contributions should be included. However, it does not specify which part of the paper this refers to, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in its request for inclusion, but the lack of grounding makes it challenging for the authors to understand where to make the changes. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that a brief conclusion and a summary of the paper\"s contributions should be included. This is a straightforward and logical request, as it aligns with standard academic writing practices. However, the comment lacks specific examples or references to support the need for these elements, making it 3. The authors can infer the importance of these elements but would benefit from additional justification or examples to fully understand the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that a brief conclusion and a summary of the paper\"s contributions should be included. This is a clear and actionable piece of feedback that directly addresses a common element missing in many academic papers. By providing specific suggestions for improvement, the comment empowers the authors to enhance the completeness and impact of their work. However, the comment could be more helpful if it offered additional guidance on how to craft these elements effectively or provided examples of what constitutes a good conclusion and summary. Despite this, the feedback is 4 as it directs the authors towards important areas for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should compare their proposed framework with a method designed to defend against multiple attacks, as this would provide a more meaningful comparison. However, the comment does not specify which method should be used for comparison or how this comparison should be presented in the paper. The action is implicit, as the authors need to infer that they should include this comparison, but it lacks concrete details on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the proposed framework with a method designed to defend against multiple attacks, implying that the authors should include this comparison in their paper. However, it does not specify which method should be used for comparison or how this comparison should be presented. The comment lacks specific guidance on which part of the paper should address this comparison, making it weakly grounded. It is also specific in suggesting the need for a comparison with a method defending against multiple attacks, but the lack of grounding makes it difficult for the authors to pinpoint the exact area to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should compare their proposed framework with a method designed to defend against multiple attacks, as this would provide a more meaningful comparison. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis for the suggestion. Without additional context or references, the claim is not 5, as it does not provide a clear rationale or evidence for why this comparison would be beneficial. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment suggests that the authors should compare their proposed framework with a method designed to defend against multiple attacks, as this would provide a more meaningful comparison. However, the comment lacks specific guidance on which method to use for comparison or how to present this comparison in the paper. While it identifies a potential area for improvement, it does not offer detailed suggestions or examples, making it 3. The feedback is clear but could be more comprehensive if it provided more actionable advice. Therefore, the comment aligns with a score of 3, as it offers some insight but requires further elaboration to be fully helpful."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the planbased method, noting that it requires manual design based on ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to methods with predefined plans, as evidenced by Table 2. The comment suggests that the proposed method may be difficult to generalize to a new dataset without ground truth summary. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their method. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the limitations of the planbased method, specifically noting that it requires manual design based on ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to methods with predefined plans, as suggested by Table 2. The comment further implies that the proposed method may be difficult to generalize to a new dataset without the ground truth summary. However, the comment does not explicitly mention specific sections, tables, or figures of the paper, making it weakly grounded. It is specific in detailing the issues with the planbased method, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact parts of the paper that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the planbased method requires manual design based on ground truth, which is unrealistic in realworld scenarios. It also suggests that the learned plan methods are not comparable to methods with predefined plans, as indicated by Table 2. The comment further implies that the proposed method may be difficult to generalize to a new dataset without the ground truth summary. However, the comment lacks specific examples or detailed reasoning to fully substantiate these claims, making it 3. The authors would need to infer the basis for these claims, which could be improved with more detailed explanations or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation of the planbased method, noting that it requires manual design based on ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to methods with predefined plans, as evidenced by Table 2. This observation raises concerns about the generalizability of the proposed method to new datasets without ground truth summaries. While the comment highlights a critical issue, it does not provide specific suggestions or guidance on how the authors might address this limitation or improve their method. The feedback is 3 as it points out a potential weakness, but it lacks actionable advice, leaving the authors with limited insight into how to enhance their work. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests adding a first sentence to introduce Section 3.2. This is an explicit action that the authors can directly implement by adding a sentence at the beginning of the section. The comment is specific and provides clear guidance on how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a first sentence to introduce the section, providing clear guidance on what needs to be done. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point suggests adding a first sentence to introduce Section 3.2. This is a suggestion for improvement, but it does not contain a claim that requires verification or justification. The comment is factual and descriptive, aligning with the classification of \"No.\" Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it suggests adding a first sentence to introduce Section 3.2. This is a clear and direct feedback that provides the authors with a concrete step to improve their draft. By adding this sentence, the authors can enhance the clarity and coherence of their paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the meaning of \"perfect\" in the context of the initial rationale selector and suggests that if it were perfect, no additional work would be needed. While the comment implies that the authors should clarify the term \"perfect,\" it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should clarify the term. However, the comment lacks concrete details on what specific clarification is needed, making it 3. Therefore, this comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"perfect\" in the context of the initial rationale selector and suggests that if it were perfect, no additional work would be needed. This provides clear guidance on what needs to be clarified or addressed. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point questions the meaning of \"perfect\" in the context of the initial rationale selector and suggests that if it were perfect, no additional work would be needed. While the comment raises a valid point about the ambiguity of the term \"perfect,\" it does not provide any specific examples or references to support the claim. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some context but lacks sufficient support to be 5.", "helpfulness_rationale": "The review comment identifies a specific point of confusion in the paper, namely the phrase \"perfect\" in the context of the initial rationale selector. It questions the meaning of \"perfect\" and suggests that if it were perfect, no additional work would be needed. This feedback is 3 as it highlights a potential ambiguity in the writing, which could be clarified to improve the paper\"s clarity. However, the comment could be more helpful if it provided additional context or suggestions for how to clarify the term. Overall, the comment offers a clear area for improvement but lacks depth and specificity, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the definition of uncertainty could be clarified by specifying that the epistemic model uncertainty is represented in the prior distribution, and that upon observing data, those beliefs can be updated in the form of a posterior distribution, which yields model uncertainty conditioned on observed data. This provides a clear and explicit action for the authors to take, as they can directly implement this suggestion to improve the clarity of their paper. The comment is specific and concrete, offering detailed guidance on how to enhance the explanation of uncertainty. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the uncertainty is defined, allowing the authors to accurately identify the section being addressed. It is also specific because it provides detailed feedback on how the definition could be clarified, suggesting that the authors should update the explanation to include the representation of epistemic model uncertainty in the prior distribution and the updating of beliefs in the posterior distribution. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the definition of uncertainty could be clarified by specifying that the epistemic model uncertainty is represented in the prior distribution and updated in the form of a posterior distribution. This claim is 3 as it provides a logical reasoning for why the current definition might be unclear, suggesting a more detailed explanation. However, it lacks specific examples or references to support the claim fully, which could make it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the clarity of the paper by specifying how uncertainty is defined. It suggests that the authors should update their explanation to clarify that the epistemic model uncertainty is represented in the prior distribution and can be updated in the form of a posterior distribution upon observing data. This feedback is specific and provides a concrete direction for the authors to enhance the clarity of their paper, making it 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions about the experimental setup and results, specifically regarding the use of domain ontologies and the accuracy of the zeroshot intent classifier. While the questions are explicit and direct, they do not provide any guidance on how the authors should address these issues or what actions they should take to improve their draft. The lack of actionable suggestions or guidance leaves the authors without a clear path forward, making the comment 1. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment raises two questions about the experimental setup and results, specifically regarding the use of domain ontologies and the accuracy of the zeroshot intent classifier. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact section being addressed. The questions are specific in nature, as they seek clarification on the methodology and results, but the lack of grounding makes it challenging for the authors to understand the context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two questions about the experimental setup and results, specifically regarding the use of domain ontologies and the accuracy of the zeroshot intent classifier. However, it does not provide any claims or opinions that require verification. The questions are factual and seek clarification, but they do not present any subjective opinions or suggestions that would need to be substantiated. Therefore, the comment is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises two specific questions about the experimental setup and results, particularly concerning the use of domain ontologies and the accuracy of the zeroshot intent classifier. These questions are clear and direct, providing the authors with specific areas to consider and clarify in their draft. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues or what improvements could be made. While it identifies areas for improvement, it does not provide detailed feedback or recommendations, making it 3. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of meaningful baselines in the authors\" comparisons, suggesting that they should include more sophisticated baselines such as a chainofthought prompting approach. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to implement this suggestion or what specific baselines to consider. The action is implicit and somewhat vague, as the authors are left to infer the need for more meaningful comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies a lack of meaningful baselines and suggests a specific alternative baseline, a chainofthought prompting approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors limit their comparisons to simple naive baselines, despite mentioning various model criticism techniques in Section 2. It suggests that the authors should compare with a chainofthought prompting approach. However, the comment lacks specific examples or references to support the claim that the current baselines are indeed \"simple naive.\" While it provides a suggestion for improvement, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out the lack of meaningful baselines used for comparison. It suggests that the authors should include more sophisticated baselines, such as a chainofthought prompting approach, to provide a more comprehensive evaluation of their model criticism techniques. This feedback is clear and actionable, as it directs the authors to enhance the depth and rigor of their comparisons. However, the comment could be more helpful if it provided specific examples of how to implement these baselines or suggested additional baselines that could be considered. Overall, the comment is 4, as it effectively guides the authors to improve their draft by addressing a critical gap in their evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights several issues with the paper, including the lack of experimental details in the main body and the minimal explanations in the Appendix. It specifically mentions the PCA experiments in Figures 3, 7, and 8, noting that they are not explained. However, the comment does not provide explicit guidance on what specific details are missing or how the authors should address these issues. While the authors can infer that they need to include more experimental details in the main body and provide explanations for the PCA experiments, the lack of concrete suggestions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the PCA experiments in Figures 3, 7, and 8, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights the missing experimental details and the lack of explanations in the Appendix, particularly for the PCA experiments. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that many important experimental details are missing or relegated to the Appendix, and the Appendix lacks explanations. It provides specific examples, such as the PCA experiments in Figures 3, 7, and 8, which are not explained. This level of detail and specificity makes the claim verifiable, as it provides clear evidence of what is missing and how it impacts the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that many important experimental details are missing or relegated to the Appendix, and the Appendix lacks explanations. It specifically mentions the PCA experiments in Figures 3, 7, and 8, which are not explained. This feedback is clear and actionable, as it directs the authors to include more detailed experimental information and provide explanations for the PCA experiments. By addressing these issues, the authors can improve the clarity and completeness of their paper, making the comment 5. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the notation used in the paper, noting that the symbol K is used to represent both a known kernel function and the number of layers. This is a clear and explicit action that the authors should take to avoid confusion and ensure clarity in their notation. The comment provides a direct and concrete instruction, making it 5. The authors know exactly what needs to be addressed and how to implement the suggested change. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment identifies a specific issue with the notation used in the paper, noting that the symbol K is used to represent both a known kernel function and the number of layers. This provides clear guidance on what needs to be addressed, making the comment fully grounded. It also specifies the exact issue, enhancing its specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a specific issue with the notation used in the paper, noting that the symbol K is used to represent both a known kernel function and the number of layers. This is a factual observation that requires no further explanation or justification to be understood. The comment is clear and specific, making it 5. Therefore, it is classified as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation used in the paper, noting that the symbol K is used to represent both a known kernel function and the number of layers. This is a clear and actionable feedback that highlights a potential source of confusion for the readers. By pointing out this inconsistency, the comment provides the authors with a concrete suggestion to improve the clarity and consistency of their notation. This feedback is valuable as it directly addresses a specific aspect of the paper that could hinder understanding. Therefore, the comment is 4, as it offers clear guidance on how to enhance the clarity of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the relevance of connections to human cognition in the context of the paper\"s focus on a reductionist problem. It suggests that the authors should clarify their claims and provide more context or citations to support their arguments. However, the comment does not explicitly instruct the authors on how to address this issue or what specific changes to make. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify their claims and provide more context or citations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the relevance of connections to human cognition in the context of the paper, suggesting that the authors should clarify their claims and provide more context or citations. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its critique of the authors\" claims and suggestions for improvement, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the relevance of connections to human cognition in the context of the paper, suggesting that the authors should clarify their claims and provide more context or citations. However, the comment does not offer specific examples, reasoning, or references to support the claim that the authors\" claims are unclear or require more context. Without detailed justification or examples, the claim is difficult for the authors to address effectively, making it 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the relevance of connections to human cognition in the context of the paper, suggesting that the authors should clarify their claims and provide more context or citations. This feedback is 3 as it identifies a potential area for improvement by prompting the authors to clarify their arguments and provide additional support for their claims. However, the comment lacks specific guidance on how to address the issue or what kind of evidence would be most beneficial, making it 3 rather than fully helpful. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the wording in the conclusion is overly exaggerated and suggests that the word choice is a bit flamboyant in multiple places. While the comment identifies a specific issue with the writing style, it does not provide explicit guidance on how to revise the conclusion or suggest specific changes to make the word choice less flamboyant. The action is implicit, as the authors would need to infer that they should revise the conclusion to be more concise and less exaggerated. However, the comment lacks concrete details on how to achieve this, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the conclusion section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies the issue of exaggerated wording and suggests that the word choice is a bit flamboyant in multiple places, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the wording in the conclusion is overly exaggerated and suggests that the word choice is a bit flamboyant in multiple places. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without concrete examples or evidence, the claim remains 3, as the authors may need to infer the basis of the criticism themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the writing style in the conclusion, noting that the wording is overly exaggerated and that the word choice is a bit flamboyant in multiple places. This feedback is clear and actionable, as it provides the authors with a specific area to improve the tone and conciseness of their conclusion. However, the comment could be more helpful if it suggested specific ways to revise the language or provided examples of more appropriate phrasing. Despite this, the feedback is 4 as it directs the authors towards enhancing the quality of their writing."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a significant weakness in the paper, stating that it does not compare the proposed approach to simple feature acquisition baselines like expected utility. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific baselines to consider. The comment lacks concrete guidance on how to improve the draft, leaving the authors without a clear path forward. As a result, the comment is 1, as it does not offer actionable feedback or suggestions for improvement.", "grounding_specificity_rationale": "The comment identifies a significant weakness in the paper, specifically the lack of comparison to simple feature acquisition baselines like expected utility. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact area that needs improvement. The comment is specific in identifying the need for comparison but lacks grounding as it does not provide clear guidance on where to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not compare to simple feature acquisition baselines like expected utility, which is a significant oversight. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing comparisons. Without detailed examples or references, the claim is 3, as it provides a general idea but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of comparison to simple feature acquisition baselines like expected utility. This is a crucial oversight that could impact the effectiveness of the proposed approach. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific baselines to consider. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it points out a critical weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the approach, suggesting that the introduction of multigranularity and multiscale techniques, while common in convolutional networks, does not represent a significant innovation in the context of MLMs. It also points out that some algorithms used in the article, which enhance information on the input side, are not unique to object detection and can be applied to MLMs. However, the comment does not provide explicit guidance on how the authors might address these issues or improve their contribution. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know what specific changes to make. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction of multigranularity and multiscale techniques in the article, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that this approach is common in convolutional networks and may not be innovative in the context of MLMs. The comment further highlights that some algorithms used in the article, which enhance information on the input side, are not unique to object detection and can be applied to MLMs. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the label is 5.", "verifiability_rationale": "The review point claims that the introduction of multigranularity and multiscale techniques to enhance model performance is a common approach in convolutional networks and may not be an innovative contribution in the context of MLMs. It also suggests that some algorithms used in the article, which enhance information on the input side, are not unique to object detection and can be applied to MLMs. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issue. The feedback is 3 as it provides a general observation but lacks detailed evidence or references to substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the novelty of the approach, suggesting that the introduction of multigranularity and multiscale techniques, while common in convolutional networks, does not represent a significant innovation in the context of MLMs. It also points out that some algorithms used in the article, which enhance information on the input side, are not unique to object detection and can be applied to MLMs. This feedback provides a clear critique of the novelty of the approach and highlights potential areas for improvement. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might address these issues or enhance the novelty of their contribution. Overall, the comment is 3 as it identifies a key area for improvement but lacks detailed actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the potential impact of similarityaware positive sample selection on the performance of GNNbased encoders, specifically regarding oversmoothing and generalization. It questions whether selecting positive samples within the same dataset without introducing perturbation noise might lead to lower generalization performance. The reviewer suggests that the authors should conduct more experiments on different downstream tasks and across different domains to address these concerns. However, the comment does not provide explicit guidance on how to conduct these additional experiments or what specific aspects of the model should be explored. The action is implicit and somewhat vague, as the authors are left to infer the need for more experiments and the specific areas to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the similarityaware positive sample selection and its potential impact on the performance of GNNbased encoders, specifically regarding oversmoothing and generalization. It questions whether selecting positive samples within the same dataset without introducing perturbation noise might lead to lower generalization performance. The reviewer suggests that the authors should conduct more experiments on different downstream tasks and across different domains to address these concerns. However, the comment does not specify which part of the paper discusses the similarityaware positive sample selection or the experiments conducted on the graph classification task. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs attention. While the comment is specific about the concerns raised, the absence of explicit references to the paper\"s sections or content makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the potential impact of similarityaware positive sample selection on the performance of GNNbased encoders, specifically regarding oversmoothing and generalization. It questions whether selecting positive samples within the same dataset without introducing perturbation noise might lead to lower generalization performance. The reviewer suggests that the authors should conduct more experiments on different downstream tasks and across different domains to address these concerns. However, the comment lacks specific examples, detailed reasoning, or references to support the claims about the potential impact of the sample selection method. Without concrete evidence or examples, the authors may find it challenging to fully understand and address the concerns raised. Therefore, the comment is considered 2, as it provides some basis for concern but lacks sufficient detail to fully substantiate the claims.", "helpfulness_rationale": "The review comment raises concerns about the potential impact of similarityaware positive sample selection on the performance of GNNbased encoders, specifically regarding oversmoothing and generalization. It questions whether selecting positive samples within the same dataset without introducing perturbation noise might lead to lower generalization performance. The reviewer suggests that the authors should conduct more experiments on different downstream tasks and across different domains to address these concerns. However, the comment lacks specific guidance on how to conduct these additional experiments or what aspects of the model should be explored. While it identifies a potential area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it highlights a concern but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that the authors should provide more discussion on the power of different architectures. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so or provide specific guidance on how to discuss the power of different architectures. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on this topic. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that the authors should provide more discussion on the power of different architectures. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment is specific in its request for more discussion but lacks grounding as it does not clearly indicate where this discussion should occur. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that the authors should provide more discussion on the power of different architectures. However, it does not contain any claims or opinions that require verification. The comment is purely descriptive and does not offer any guidance or suggestions for improvement. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that the authors should provide more discussion on the power of different architectures. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue. The comment is 3 as it points out a relevant aspect that could enhance the paper, but it does not provide detailed feedback or actionable advice. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the methods should be evaluated across different splits of trainvaltest to obtain robust results, rather than relying on different initialisation seeds. This provides a clear and explicit action for the authors to take, as they can directly apply this suggestion to improve the robustness of their results. The comment is specific in its recommendation, detailing exactly what needs to be done to enhance the evaluation process. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the methods should be evaluated across different splits of trainvaltest to obtain robust results, rather than relying on different initialisation seeds. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact area where the suggestion should be implemented. While the comment is specific in its recommendation, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the methods should be evaluated across different splits of trainvaltest to obtain robust results, rather than relying on different initialisation seeds. This claim is 3 as it provides a logical reasoning for why evaluating across different splits would lead to more robust results. However, it lacks specific examples or references to support the claim, which could make it less convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the robustness of the results by recommending that the methods be evaluated across different splits of trainvaltest, rather than relying solely on different initialisation seeds. This feedback is actionable and directly addresses a potential weakness in the evaluation process. By offering a clear and constructive suggestion, the comment empowers the authors to enhance the reliability and robustness of their findings. However, it could be more helpful if it included additional guidance on how to implement this suggestion or why this approach is beneficial. Overall, the comment is 4, as it provides a clear direction for improvement but could be further refined to be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with Figure 2: the ambiguity of some symbols and the curiosity about information redundancy and interference in the multisphere icosahedral discretization process. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should clarify the symbols and explain the redundancy and interference processes. This lack of explicit guidance makes the comment 3, as the authors can deduce the necessary steps but do not have concrete instructions on how to implement them. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the ambiguity of symbols in Figure 2, which is a specific part of the paper. However, it does not explicitly mention the figure or section, making it weakly grounded. The comment is specific in identifying the issue with the symbols and raises a question about information redundancy and interference in the multisphere icosahedral discretization process, which is also specific. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of symbols in Figure 2 and the presence of information redundancy and interference in the multisphere icosahedral discretization process. However, it does not provide any specific examples, references, or detailed reasoning to support these claims. The lack of evidence or justification makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that some symbols are ambiguous and raises a question about information redundancy and interference in the multisphere icosahedral discretization process. While the comment highlights a potential area for improvement in the clarity of the figure, it does not provide detailed guidance or suggestions on how to address these issues. The feedback is 3 as it points out a specific area that needs attention, but it lacks depth and actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a limitation in the results of the paper, specifically regarding the assumption that the spectrum of a kernel is subgaussian. It notes that while Gaussian kernels are in this class, other popular kernels like Matern kernels, which have polynomial decay spectra, are not included. The comment suggests that the results could be restrictive due to this limitation. However, the comment does not provide explicit guidance on how the authors might address this issue or what steps they should take to improve their results. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the limitation of the results by pointing out that the assumption of subgaussian spectra for kernels is valid for Gaussian kernels but restricts the results for other popular kernels like Matern kernels. It highlights that the results could be more comprehensive if other kernel types were considered. However, the comment does not specify which part of the paper discusses the results or the assumptions made, making it weakly grounded. It is specific in detailing the issue with the assumption of subgaussian spectra, but without explicit references to sections or figures, the authors may need to infer the relevant parts. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the results of the paper could be restrictive due to the assumption that the spectrum of a kernel is subgaussian. It argues that while Gaussian kernels are in this class, other popular kernels like Matern kernels, which have polynomial decay spectra, are not included. The comment suggests that this limitation could restrict the generality of the results. However, the claim lacks specific examples or references to support the assertion that the results are indeed restrictive. While the reasoning is logical, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the results of the paper, specifically regarding the assumption that the spectrum of a kernel is subgaussian. It points out that while Gaussian kernels are in this class, other popular kernels like Matern kernels, which have polynomial decay spectra, are not included. The comment suggests that this limitation could restrict the generality of the results. However, the feedback lacks specific guidance on how the authors might address this issue or what steps they should take to improve their results. While it highlights an important area for consideration, the comment does not provide actionable advice or suggestions for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should focus more on the unsupervised pretraining method in the main paper, as it is a key factor in performance gain, especially compared to other modules. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the pretraining method need to be discussed. While the suggestion is clear, the lack of detailed instructions or examples makes it somewhat vague and leaves the authors uncertain about how to implement the action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of detailed discussion on unsupervised pretraining in the main paper and suggests that it is more important than other modules. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the unsupervised pretraining is a key factor in performance gain, as indicated by data in Table 4, but lacks detailed discussion in the main paper. The comment suggests that the unsupervised pretraining is more important than other modules, as evidenced by the ablation study in Table 5. However, the claim lacks specific examples or detailed reasoning to fully substantiate the assertion that unsupervised pretraining is more important. While the reasoning is logical, the absence of concrete evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a key issue in the paper, specifically the lack of detailed discussion on unsupervised pretraining despite its importance in performance gain, as indicated by data in Table 4. It suggests that the authors should focus more on the pretraining method in the main paper, which is a valuable and actionable piece of feedback. However, the comment could be more helpful if it provided specific guidance on how the authors could address this issue, such as suggesting additional analysis or discussion points. Overall, the comment is 4 as it highlights an important area for improvement and encourages the authors to expand on a critical aspect of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether the method has been tested on more than two datasets, suggesting that the authors should try additional datasets to gain a better understanding of its performance. While the comment implies that the authors should conduct more experiments, it does not explicitly instruct them to do so or provide specific guidance on which datasets to use or how to analyze the results. The action is implicit and somewhat vague, as the authors need to infer that they should expand their testing to more datasets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions whether the method has been tested on more than two datasets, suggesting that the authors should try additional datasets to gain a better understanding of its performance. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. It is specific in questioning the limited testing of the method, but without clear references to specific sections or figures, the authors may find it challenging to address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether the method has been tested on more than two datasets, suggesting that the authors should try additional datasets to gain a better understanding of its performance. However, the comment does not provide any specific reasoning, examples, or references to support why testing on more datasets would be beneficial or how it would impact the results. The lack of detailed justification or evidence makes the claim 3, as the authors may need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the limited testing of the method on only two datasets, questioning whether the authors have explored more datasets to gain a better understanding of its performance. This feedback is 3 as it highlights a potential area for improvement, suggesting that the authors should consider expanding their testing to more datasets. However, the comment lacks specific guidance on which datasets to use or how to analyze the results, making it incomplete. The authors would need to infer the need for additional testing and may require more detailed suggestions to fully address the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the domain of the inputs, suggesting that they appear to be in the same sphere but are not explicitly mentioned in the paper. While the comment implies that the authors should clarify this aspect, it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should address the missing information about the input domain. However, the comment lacks concrete details on what specific information needs to be added or how to clarify the issue. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment raises a question about the domain of the inputs, suggesting that they appear to be in the same sphere but are not explicitly mentioned in the paper. However, it does not specify which part of the paper this issue relates to, making it difficult for the authors to pinpoint the exact section or figure where this information should be addressed. The comment is specific in its suggestion to clarify the input domain, but it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the domain of the inputs, suggesting that they appear to be in the same sphere but are not explicitly mentioned in the paper. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the domain of the inputs, suggesting that they appear to be in the same sphere but are not explicitly mentioned in the paper. This feedback highlights a potential gap in the clarity of the paper, as it leaves the authors uncertain about the scope and nature of the inputs being discussed. However, the comment does not provide specific guidance or suggestions on how to address this issue, such as clarifying the input domain or providing additional context. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential issue but does not offer detailed guidance for resolution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically mentioning equations (7) and the definition of minimal conditional dependence. It suggests that taking Z\u00e2\u0080\u0099 as the empty set should result in x and y being independent given W, but equation (7) contradicts this. While the comment highlights a specific issue, it does not provide explicit guidance on how the authors should address this conflict or what changes might be necessary. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to resolve the conflict. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lemma 2\" and \"Eq (7),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential conflict between the definition of minimal conditional dependence and the equations, suggesting that taking Z\u00e2\u0080\u0099 as the empty set should result in x and y being independent given W, but equation (7) contradicts this. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically mentioning equations (7) and the definition of minimal conditional dependence. It suggests that taking Z\u00e2\u0080\u0099 as the empty set should result in x and y being independent given W, but equation (7) contradicts this. The comment provides a clear logical reasoning by pointing out the inconsistency between the definition and the equation. However, it lacks specific examples or references to external works that could further substantiate the claim. While the reasoning is logical, the absence of detailed examples or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, namely a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence. It highlights a discrepancy between the theoretical expectation and the equation presented, suggesting that taking Z\u00e2\u0080\u0099 as the empty set should result in x and y being independent given W, but equation (7) contradicts this. This feedback is clear and actionable, as it points out a specific area where the authors need to address a potential inconsistency. However, the comment could be more helpful if it provided guidance on how to resolve the conflict or suggested alternative interpretations of the equations. Overall, the comment is 4, as it directs the authors to a critical issue that needs to be addressed for the paper to be accurate and consistent."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the difference between Batch Normalization and Online Normalization in terms of gradient bias, specifically questioning why one is biased and the other is unbiased. While the comment highlights a point of confusion for the reviewer, it does not provide explicit guidance or suggestions on how to address this confusion or clarify the issue. The authors are left to infer that the comment is intended to prompt them to explain the difference more clearly. The action is implicit and somewhat vague, as it does not specify how to clarify the issue or what aspects of the explanation need improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the explanation of gradient bias in Batch Normalization and Online Normalization. It highlights a point of confusion for the reviewer, questioning why one is biased and the other is unbiased. However, the comment does not explicitly mention which part of the paper this issue is discussed, making it weakly grounded. The comment is specific in identifying the need for clarification regarding the difference between the two normalization methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the difference between Batch Normalization and Online Normalization in terms of gradient bias. It highlights a point of confusion for the reviewer, questioning why one is biased and the other is unbiased. However, the comment does not provide any evidence, reasoning, or references to support the claim that the reviewer is confused or that the distinction between the two methods is unclear. The comment lacks specific examples or detailed explanations to substantiate the reviewer\"s confusion, making it difficult for the authors to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the difference between Batch Normalization and Online Normalization in terms of gradient bias, specifically questioning why one is biased and the other is unbiased. While the comment highlights a point of confusion for the reviewer, it does not provide any actionable feedback or suggestions on how to clarify this distinction or address the reviewer\"s confusion. The authors are left without guidance on how to improve the explanation or address the issue, making the comment 3. It could be more helpful if it offered specific suggestions or guidance on how to clarify the explanation of the two normalization methods."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the clarity of the concept of \"local interactions\" in the paper. It asks whether \"local\" refers to interactions within a time window or within the same modality. While the comment identifies a potential area of confusion, it does not provide explicit guidance on how the authors should clarify this concept. The authors are left to infer that they need to address the ambiguity in the definition of \"local interactions,\" but the comment lacks concrete suggestions on how to do so. Therefore, the comment is 3, as it identifies a specific issue but does not provide detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment raises a question about the clarity of the concept of \"local interactions\" in the paper, specifically asking whether it refers to interactions within a time window or within the same modality. However, it does not specify which part of the paper this concept is discussed in, making it difficult for the authors to pinpoint the exact section or figure that needs clarification. The comment is specific in its request for clarification but lacks grounding as it does not provide explicit references to the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of the concept of \"local interactions\" in the paper, specifically asking whether it refers to interactions within a time window or within the same modality. This is a subjective question that seeks clarification rather than making a claim that requires verification. The comment does not provide any evidence, reasoning, or references to support a claim, making it a factual statement. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the clarity of the concept of \"local interactions\" in the paper, specifically asking whether it refers to interactions within a time window or within the same modality. This question highlights a potential area of confusion for the authors, as it is not clear how the concept of \"local\" is defined in the context of the paper. While the comment identifies a specific issue that could improve the clarity of the paper, it does not provide any suggestions or guidance on how the authors might address this ambiguity. The feedback is 3 as it points out a potential area for improvement, but it lacks actionable advice, making it only marginally helpful."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the paper\"s claim of better results in the Molecule generation experiment (Table 3) and the observation that adding the proposed constrained method yields lower validity and diversity. However, it does not provide explicit or implicit actions for the authors to take. The comment suggests that the authors should reevaluate their results and consider the impact of the constrained method on validity and diversity. While the authors can infer that they need to address this issue, the comment lacks concrete guidance on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Molecule generation experiment (Table.3),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue: the paper claims better results, but the addition of the proposed constrained method yields lower validity and diversity. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s claim of better results in the Molecule generation experiment (Table 3) is contradicted by the observation that adding the proposed constrained method yields lower validity and diversity. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the claim, making it difficult to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claim regarding the Molecule generation experiment, specifically noting that adding the proposed constrained method results in lower validity and diversity compared to the paper\"s claim of better results. This feedback is clear and actionable, as it highlights a discrepancy that the authors should investigate and address. However, the comment could be more helpful if it provided suggestions on how to analyze or resolve this issue, such as suggesting specific analyses or comparisons to be made. Overall, the comment is 4 as it points out a critical issue that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors would have liked more description of the Starcraft environment, potentially in an appendix. While the comment implies that additional detail would be beneficial, it does not explicitly instruct the authors to provide this description or specify how it should be included. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the description of the Starcraft environment. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors would have liked more description of the Starcraft environment, potentially in an appendix. However, it does not specify which part of the paper this description should be included in or how it should be integrated. The comment is 1 as it does not provide clear guidance on which section or aspect of the paper needs improvement. It is also not specific because it does not detail what aspects of the Starcraft environment description are missing or how it should be expanded. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors would have liked more description of the Starcraft environment, potentially in an appendix. However, it does not provide any specific reasoning, examples, or references to support why this additional description would be beneficial. The comment lacks detailed justification or context, making it difficult for the authors to understand the basis for the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the authors would have liked more description of the Starcraft environment, potentially in an appendix. While this feedback provides a specific area for improvement, it lacks depth and actionable guidance. The authors are left to infer that additional detail would enhance the paper, but the comment does not offer specific suggestions on what aspects of the Starcraft environment should be described or how this additional information would benefit the paper. Therefore, the comment is 3, as it identifies a potential area for improvement but does not provide comprehensive guidance for the authors to address it effectively."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors combine two existing techniques without innovation and questions the use of an old and simple domain adaptation method. It implies that the authors should consider using more recent and effective domain adaptation methods to improve performance. However, the comment does not provide explicit guidance on which specific methods to use or how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer the need for improvement and the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the combination of two existing techniques and the use of an old and simple domain adaptation method. It provides specific guidance on why the authors should consider using more recent and effective domain adaptation methods to improve performance. This allows the authors to accurately identify the parts of the paper that need attention and understand the specific issues to address. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors combine two existing techniques without innovation and questions the use of an old and simple domain adaptation method. It suggests that more recent and effective methods could be used to improve performance. However, the comment lacks specific examples or references to support the claim about the novelty of the combination or the effectiveness of the proposed methods. Without detailed evidence or references, the claim is difficult to verify, making it 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential weakness in the authors\" approach by suggesting that they combine two existing techniques without introducing innovation. It questions the use of an old and simple domain adaptation method, implying that more recent and effective methods could be used to improve performance. This feedback is 3 as it points out a potential area for improvement and encourages the authors to consider more advanced techniques. However, the comment could be more helpful if it provided specific examples of recent domain adaptation methods or suggested alternative approaches. Overall, the comment offers a clear direction for enhancing the work, but it could be more comprehensive and actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments are only conducted on one game environment and that more experiments are necessary. While the comment implies that additional experiments should be performed, it does not specify which additional environments or types of experiments would be beneficial. The action is implicit, as the authors need to infer that they should conduct more experiments, but it lacks concrete guidance on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments are only conducted on one game environment and that more experiments are necessary. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. The authors cannot confidently determine which section is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide details on what additional experiments should be conducted or why the current single environment is insufficient. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the experiments are only conducted on one game environment and suggests that more experiments are necessary. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand why this is a significant issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the experiments are only conducted on one game environment, suggesting that more experiments are necessary. While this feedback highlights a potential limitation in the scope of the experiments, it does not provide specific guidance on what additional experiments should be conducted or how they might address the identified limitation. The comment is 3 as it identifies a potential area for improvement, but it lacks depth and actionable suggestions, leaving the authors with limited insight into how to enhance their work. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern regarding the implementation of ImageNet, noting that it is slow and has low accuracy. It provides specific details about the time taken to test an ImageNet picture using AlexNet and ResNet18, and mentions the accuracy is around 70%. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to improve the implementation. While the authors might infer that they need to optimize their implementation, the lack of explicit instructions or detailed suggestions makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ImageNet\" and provides specific details about the time taken to test an ImageNet picture using AlexNet and ResNet18, as well as the accuracy. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the performance issues with the implementation, including the time taken and the accuracy, which are clear indicators of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" implementation of ImageNet is slow and has low accuracy, providing specific details such as the time taken to test an ImageNet picture using AlexNet and ResNet18, and an accuracy of around 70%. This claim is supported by specific numerical data, making it 4. However, the comment could be strengthened by providing more context or comparison to other implementations, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the implementation of ImageNet, noting that it is slow and has low accuracy. It provides concrete data, such as the time taken to test an ImageNet picture using AlexNet and ResNet18, and mentions the accuracy is around 70%. This feedback is clear and actionable, as it highlights a significant performance issue that the authors need to address. However, the comment could be more helpful if it suggested specific steps or strategies for improving the implementation\"s speed and accuracy. Despite this, the comment provides valuable insights that can guide the authors in enhancing their work, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the authors\" claim that their proposed classification network is universally as good as the standard softmax network, particularly in terms of classification accuracy. It suggests that building a new model for better outofdistribution detection might come at the cost of losing classification accuracy. The comment implies that the authors should report the classification accuracy of their proposed classifier on ImageNet data and provide theoretical justifications for the issue. While the comment suggests specific actions, such as reporting accuracy and providing theoretical justifications, it does not provide detailed guidance on how to implement these actions or what specific aspects of the model should be analyzed. The actions are somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment questions the authors\" claim about the classification accuracy of their proposed network compared to the standard softmax network, specifically questioning whether the classification error is universally as good. It suggests that building a new model for better outofdistribution detection might lead to a loss of classification accuracy. The comment implies that the authors should report the classification accuracy of their proposed classifier on ImageNet data and provide theoretical justifications. However, the comment does not specify which part of the paper discusses the classification accuracy or the outofdistribution detection, making it weakly grounded. The comment is specific in suggesting what needs to be addressed, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point questions the authors\" claim that their proposed classification network is universally as good as the standard softmax network, particularly in terms of classification accuracy. It suggests that building a new model for better outofdistribution detection might come at the cost of losing classification accuracy. The comment implies that the authors should report the classification accuracy of their proposed classifier on ImageNet data and provide theoretical justifications for the issue. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to provide more detailed reasoning or evidence to substantiate their claim, which would enhance the verifiability of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the classification accuracy of the proposed network compared to the standard softmax network, particularly in the context of outofdistribution detection. It questions whether the new model might sacrifice classification accuracy, which is a crucial aspect for practical applications. The comment suggests that the authors should report the classification accuracy of their proposed classifier on ImageNet data and provide theoretical justifications for the issue. This feedback is 3 as it identifies a potential weakness and provides a direction for improvement, but it lacks depth and specificity in addressing the concern. The authors would benefit from a more detailed discussion of the tradeoffs between classification accuracy and outofdistribution detection, as well as a clear rationale for why their proposed model might be preferable despite the potential loss of accuracy. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern regarding the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar pretrained models as the proposed method. It suggests that the proposed method, which was pretrained before finetuning, might have an advantage over methods that were not pretrained in the same way. The comment implies that the authors should clarify the initialization conditions of the compared methods to ensure a fair comparison. However, it does not provide explicit guidance on how to address this issue, such as suggesting specific steps to ensure fair initialization or providing additional details on the experimental setup. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and potentially address it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental comparison with other methods, specifically questioning the fairness of the comparison due to the pretraining of the proposed method before the finetuning stage. It highlights that the compared methods might not have been initialized with the same or similar pretrained models, which could lead to an unfair comparison. The comment is fully grounded as it explicitly mentions the part of the paper being addressed, allowing the authors to accurately identify the section. It is also specific because it clearly specifies the issue with the experimental setup and suggests that the authors should clarify the initialization conditions of the compared methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental comparison with other methods is unfair due to the proposed method being pretrained before finetuning, while the compared methods might not have been initialized with the same or similar pretrained models. The comment provides a logical reasoning by suggesting that this could lead to an unfair comparison. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the need for clarification and potentially address it by providing more details on the experimental setup. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar pretrained models as the proposed method. It highlights that the proposed method, which was pretrained before finetuning, might have an advantage over methods that were not pretrained in the same way. The comment suggests that the authors should clarify the initialization conditions of the compared methods to ensure a fair comparison. This feedback is 3 as it points out a potential weakness in the experimental setup and provides a clear direction for the authors to address it. However, it could be more helpful if it offered specific suggestions or guidance on how to ensure fair initialization. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and asks for clarification on why entropy is not a good measure of the spreading of teacher predictions. It does not provide explicit instructions on how to address these points, such as suggesting specific sections or types of descriptions to include. The comment is somewhat vague, as it implies that the authors should consider these aspects but does not offer concrete guidance on how to do so. Therefore, the comment is 3, aligning with a score of 3.", "grounding_specificity_rationale": "The comment suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and asks for clarification on why entropy is not a good measure of the spreading of teacher predictions. However, it does not specify which part of the paper this issue is related to, such as a specific section or figure. The comment is vague in terms of grounding, as the authors cannot confidently determine which part of the paper it addresses. While it is specific in terms of the content it suggests, the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the clarity of the paper regarding the concept of Confidence Diversity (CD) and its relationship to Predictive Uncertainty. It asks for clarification on why entropy is not a good measure of the spreading of teacher predictions, specifically referencing line 115 and line 113. However, the comment does not provide any evidence, reasoning, or references to support these claims. The authors are left to interpret the questions and potentially seek clarification from the authors, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should describe possible alternate formulations for Confidence Diversity (CD). It also raises questions about the clarity of the paper regarding why entropy is not a good measure of the spreading of teacher predictions, particularly concerning the reference to line 115 and line 113. While the comment does not provide explicit guidance on how to address these issues, it does point out areas where the paper could be clearer and more comprehensive. This feedback is 3 as it highlights specific areas for improvement, but it could be more helpful with additional suggestions or guidance on how to address the concerns. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the human baseline\"s performance and the claim made in the abstract. It points out that the human baseline is based on a 1hour recording, which is less than the 15hour recording used for the model baseline. This discrepancy makes the human baseline weaker than the model baseline, apart from other factors mentioned in Section 4.1. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to the draft. The action is implicit, as the authors need to infer that they should clarify the discrepancy in the human baseline\"s performance and the abstract\"s claim. The action is somewhat vague, as it does not specify how to address the issue or what changes to make. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the human baseline, specifically mentioning that it is based on a 1hour recording compared to the 15hour recording used for the model baseline. This provides a clear reference point for the authors to understand which part of the paper is being discussed. However, the comment does not specify what needs to be addressed in this part, such as how to improve the human baseline or clarify the discrepancy in the abstract. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the human baseline is based on a 1hour recording, which is less than the 15hour recording used for the model baseline. This makes the human baseline weaker than the model baseline. The comment also notes that the abstract mentions a human baseline achieving a certain performance level, which is misleading given the discrepancy in recording lengths. However, the comment lacks specific examples or references to support the claim about the human baseline\"s performance. While the reasoning is logical, the lack of detailed evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the human baseline, noting that it is based on a 1hour recording compared to the 15hour recording used for the model baseline. This discrepancy makes the human baseline weaker than the model baseline, apart from other factors mentioned in Section 4.1. The comment also points out that the abstract claims the human baseline \"already beating the 34.2% CER and 4.51 BLEU achieved by a human who learned Kalamang from the same resources,\" which is misleading given the 1hour vs. 15hour recording difference. This feedback is 3 as it highlights a potential inconsistency in the presentation of the human baseline\"s performance. However, it could be more helpful if it provided suggestions on how to address this issue or clarify the discrepancy in the abstract. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the related work section, noting that while it discusses other methods for training NMT models beyond MLE, it does not include any of these methods as baselines. This feedback is explicit and provides a clear action for the authors to take: they should consider incorporating these methods as baselines in their experiments. The comment is specific in identifying the issue and offers a concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a gap in the related work by noting that while other methods for training NMT models beyond MLE are discussed, none of them are used as baselines. This provides a clear and specific direction for the authors to improve their draft by including these methods as baselines. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the related work section discusses other methods for training NMT models beyond MLE but does not include any of these methods as baselines. This claim is 3 as it highlights a gap in the related work section, but it lacks specific examples or references to support the claim. The authors would need to infer that the omission of these methods as baselines is a significant oversight. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the related work section by noting that while it discusses other methods for training NMT models beyond MLE, it does not include any of these methods as baselines. This feedback is clear and actionable, as it provides a specific suggestion for improvement: the authors should consider incorporating these methods as baselines in their experiments. By doing so, the authors can provide a more comprehensive comparison and better contextualize their work. This feedback is 4 as it offers a clear direction for improvement, but it could be more comprehensive if it suggested specific methods or baselines to include. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the variability of results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It also implies that the authors might have missed this in the appendix. However, the comment does not provide explicit guidance on how to address this issue or what specific actions the authors should take to improve their draft. The suggestion to explore the resilience of the metric to the choice of random projection is vague and lacks concrete details on how to implement it. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the variability of results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It also implies that the authors might have missed this in the appendix. However, the comment does not specify which part of the paper discusses the results or the appendix, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific in its suggestion to explore the resilience of the metric, the lack of grounding makes it challenging for the authors to understand where to focus their attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the variability of results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It implies that the authors might have missed this in the appendix. However, the comment lacks specific examples or references to support the claim that pathological projection matrices could skew the scores. Without detailed reasoning or evidence, the claim is difficult to verify, making the comment 2.", "helpfulness_rationale": "The review comment raises a question about the variability of results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It also implies that the authors might have missed this in the appendix. While the comment identifies a potential area for further exploration and suggests a specific aspect to consider, it lacks detailed guidance on how to address this issue or what specific actions the authors should take to improve their draft. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with additional suggestions or guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation of FGT should be used to assess the performance of the proposed method and comparative methods. However, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the performance should be evaluated. The action is implicit and vague, as it leaves the authors to infer the necessary steps to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the evaluation of FGT should be used to assess the performance of the proposed method and comparative methods, implying that the evaluation is currently only used for the ablation study. However, the comment does not specify which part of the paper discusses the evaluation of FGT or the ablation study, making it weakly grounded. It is specific in suggesting that the evaluation should be expanded, but without clear guidance on how to do so. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluation of FGT is only used to assess the method performance in the ablation study, suggesting that it should be used to evaluate the performance of the proposed method and comparative methods. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation of the proposed method, noting that the current evaluation of FGT is limited to the ablation study and suggests that it should be used to assess the performance of the proposed method and comparative methods. This feedback is clear and actionable, as it provides a specific direction for improvement. However, it could be more helpful if it included suggestions on how to conduct this additional evaluation or what specific aspects of performance should be considered. Overall, the comment is 4 as it highlights a clear area for improvement and provides a basis for further action."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the work\"s narrow focus on a specific task and language might limit its broader impact. However, it does not provide explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might broaden the scope or impact of their work. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing. It provides a general observation about the narrow focus of the work, but without referencing specific sections or elements, the authors cannot confidently identify where this issue is discussed. The comment is also not specific, as it does not detail what aspects of the work are limited or how they might be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work\"s narrow focus on a specific task and language might limit its broader impact. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand or address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the work, noting that its narrow focus on a specific task and language might limit its broader impact. While this observation is relevant, it lacks actionable guidance or suggestions on how the authors might address this issue. The comment does not provide specific advice on expanding the scope or impact of the work, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should provide more insight into the criteria used for this selection and consider whether other tasks or datasets might yield different insights. However, the comment does not explicitly instruct the authors to address these questions or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detail and consider additional tasks or datasets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should provide more insight into the criteria behind this selection and consider whether other tasks or datasets might yield different insights. However, the comment does not specify which part of the paper this issue is related to, making it weakly grounded. It is specific in its suggestion to provide more detail and consider additional tasks or datasets, but without clear references to specific sections or figures, the authors may find it challenging to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should provide more insight into the criteria behind this selection and consider whether other tasks or datasets might yield different insights. However, the comment does not provide any specific reasoning, examples, or references to support why this choice might limit generalizability or what alternative approaches could be considered. Without additional context or justification, the claim is difficult to verify, making it 1.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It questions whether the criteria for this selection are clear and whether other tasks or datasets might provide different insights. This feedback is 3 as it highlights an important aspect of the study that could impact the broader applicability of the findings. However, the comment could be more helpful if it provided specific guidance on how the authors might address this issue, such as suggesting additional tasks or datasets to consider or providing more detailed criteria for the selection process. Without such guidance, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of detail in the experimental description, which makes it difficult for readers to judge the results. It suggests that the authors should provide more clarity to allow readers to better understand the experimental setup. However, the comment does not explicitly instruct the authors on what specific aspects of the description need to be improved or how to enhance clarity. While the authors can infer that they need to add more detail, the action is not concrete and lacks specific guidance on what to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiment description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the lack of detail in the experimental description, which is crucial for readers to judge the results. The comment provides clear guidance on what needs to be improved, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the description of experimental details is lacking in clarity, making it difficult for readers to judge the results. However, the comment does not provide specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the lack of detail in the experimental description, which hinders the reader\"s ability to judge the results. It provides a clear and actionable suggestion to improve the clarity of the experimental details, making it a valuable piece of feedback. However, the comment could be more helpful if it offered specific examples or guidance on how to enhance the clarity of the description. Despite this, the feedback is 4 as it directs the authors towards a critical area for improvement, allowing them to enhance the manuscript. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the paper\"s selfcontained nature and suggests that the supplementary material is necessary for understanding large parts of the main paper and ensuring reproducibility. It also requests the authors to release the source code of their experiments. While the comment identifies specific issues and requests, it does not provide explicit guidance on how to address these concerns or what specific actions the authors should take to improve the paper. The actions are implicit and somewhat vague, as the authors are left to infer how to make the paper selfcontained and reproducible. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the paper\"s selfcontained nature and suggests that the supplementary material is necessary for understanding large parts of the main paper and ensuring reproducibility. It also requests the authors to release the source code of their experiments. However, the comment does not specify which part of the paper is being addressed, making it weakly grounded. It is specific in detailing the need for the supplementary material and the request for source code, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not selfcontained understandable given the NIPS format, but the supplementary material is necessary to understand large parts of the main paper and allow reproducibility. It also requests the authors to release the source code of their experiments to allow reproduction of their results. However, the comment lacks specific examples or detailed reasoning to support the claim about the paper\"s selfcontained nature or the necessity of the supplementary material. While it provides a general idea, it does not offer a thorough explanation or evidence to substantiate the claim. Therefore, the comment is considered 2, as it provides some basis for understanding but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper\"s selfcontained nature, noting that it is not understandable given the NIPS format and that the supplementary material is necessary for full comprehension and reproducibility. It also requests the authors to release the source code of their experiments, which is a valuable suggestion for enhancing the paper\"s reproducibility and transparency. However, the comment could be more helpful if it provided specific guidance on how to make the paper selfcontained or detailed the exact nature of the supplementary material needed. Despite this, the feedback is 4 as it highlights important areas for improvement and encourages the authors to enhance the paper\"s accessibility and reproducibility."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm for training, specifically in comparison to other algorithms like PPO. It implies that the authors should clarify why they chose REINFORCE, potentially referencing the attention model paper they are building upon. However, the comment does not explicitly instruct the authors to add this rationale or explanation to their draft. While the suggestion is clear, it lacks concrete guidance on how to implement it, making it 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm for training, specifically in comparison to other algorithms like PPO. However, it does not specify which part of the paper this choice is made or where the comparison is discussed. The comment is vague and does not provide detailed guidance on what needs to be addressed. Therefore, it is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm for training, specifically in comparison to other algorithms like PPO. However, the comment does not offer any specific reasoning or evidence to support why REINFORCE was chosen over PPO. It lacks detailed justification or examples, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm for training, specifically in comparison to other algorithms like PPO. It implies that the authors should clarify why they chose REINFORCE, potentially referencing the attention model paper they are building upon. However, the comment lacks specific guidance on how to provide this rationale or what aspects of the comparison should be included. While it identifies a potential area for improvement, it does not offer detailed suggestions or examples, making it 3. The feedback is clear but could be more actionable with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by pointing out the absence of a discussion about the Set Transformer and other related works that utilize summary tokens. While it identifies a specific area that needs attention, it does not provide explicit guidance on how the authors should address this gap. The authors are left to infer that they should include a discussion of these works, but the comment lacks concrete suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Set Transformer\" and provides a link, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the missing discussion about the Set Transformer and other related works that use summary tokens. This provides the authors with a clear understanding of what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is missing a discussion about the Set Transformer and other related works that use summary tokens. However, it does not provide any specific reasoning or evidence to support this claim. Without additional context or references, the authors are left to question the validity of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out the absence of a discussion about the Set Transformer and other related works that utilize summary tokens. This is a valuable piece of feedback as it highlights an area where the authors could enhance the comprehensiveness and depth of their work. However, the comment lacks specific guidance on how the authors might address this gap, such as suggesting particular aspects of the Set Transformer to discuss or how to compare their approach with other methods. While it provides a clear direction for improvement, the lack of detailed suggestions makes it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the methodology, specifically regarding how the network is trained to fit the residual instead of directly learning the inputoutput mapping. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to their draft. The comment lacks concrete guidance on how to improve the paper, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the methodology, specifically regarding how the network is trained to fit the residual instead of directly learning the inputoutput mapping. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its request for details, the absence of grounding information makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the methodology, specifically regarding how the network is trained to fit the residual instead of directly learning the inputoutput mapping. However, it does not provide any claim, suggestion, or critique that requires verification or justification. The comment is purely factual and descriptive, lacking any opinions or assertions that could be challenged or supported. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a specific question about the methodology, noting that the authors do not provide details on how the network is trained to fit the residual instead of directly learning the inputoutput mapping. This feedback is valuable as it highlights a potential gap in the clarity of the methodology section, which could hinder the reader\"s understanding of the approach. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue, such as providing additional details or clarifying the methodology. While it identifies an area for improvement, the feedback is somewhat limited in its scope and depth, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point asks for clarification on the experiment setup in Section 3.3, specifically mentioning details like data augmentation methods and learning rate. It also provides a reference to BadNets, which is relevant to the topic of backdooring attacks. However, the comment does not explicitly instruct the authors to provide this information or clarify it in their draft. While the authors can infer that they need to include this information, the action is implicit and somewhat vague. The lack of explicit guidance on how to incorporate or clarify the experiment setup makes the comment 3.", "grounding_specificity_rationale": "The comment asks for clarification on the experiment setup in Section 3.3, specifically mentioning details like data augmentation methods and learning rate. It also provides a reference to BadNets, which is relevant to the topic of backdooring attacks. However, the comment does not specify which part of Section 3.3 is being referred to, making it weakly grounded. The comment is specific in asking for details about the experiment setup, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point asks for clarification on the experiment setup in Section 3.3, specifically mentioning details like data augmentation methods and learning rate. It also provides a reference to BadNets, which is relevant to the topic of backdooring attacks. However, the comment does not contain a subjective claim or suggestion; it is a request for clarification and additional information. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment requests clarification on the experiment setup in Section 3.3, specifically mentioning details such as data augmentation methods and learning rate. It also provides a reference to BadNets, which is relevant to the topic of backdooring attacks. However, the comment lacks actionable guidance or suggestions on how the authors might address this request or incorporate the information into their draft. While it identifies an area for improvement, it does not provide specific steps or insights to help the authors enhance their work. Therefore, the comment is 2, as it highlights a need for clarification but does not offer detailed guidance or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the statistical significance of the numbers when comparing the proposed method with baselines. It does not provide explicit instructions or suggestions on how the authors should address this concern, such as conducting a statistical significance test or providing justification for the closeness of the numbers. While the comment implies that the authors should consider this aspect, it lacks concrete guidance on how to implement it. Therefore, the comment is 3, as it identifies a potential issue but does not provide detailed instructions on how to address it.", "grounding_specificity_rationale": "The comment raises a question about the statistical significance of the numbers when comparing the proposed method with baselines. However, it does not specify which part of the paper this comparison is made, nor does it provide any guidance on how to address this issue. The authors cannot confidently determine which section or part of the paper is being referenced, making the comment weakly grounded. Additionally, the comment is specific in questioning the statistical significance of the numbers, but it lacks detailed guidance on how to conduct the test or interpret the results. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the statistical significance of the numbers when comparing the proposed method with baselines. It does not contain a claim that requires verification or justification. The comment is factual and descriptive, as it simply questions the closeness of the numbers without providing any evidence or reasoning. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a valid concern about the statistical significance of the numbers when comparing the proposed method with baselines. It questions whether the closeness of the numbers is due to chance or if there is a significant difference. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as conducting a statistical significance test or providing a rationale for the closeness of the numbers. While it identifies a potential area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors might have incorrectly chosen a significance testing method and recommends using a paired test setting, specifically the Wilcoxon signedrank test, due to the comparison being made between two samples generated from the same input. While the comment implies that a paired test would be more appropriate, it does not explicitly instruct the authors to perform this test or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the need for a paired test and understand how to apply it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors might have incorrectly chosen a significance testing method and recommends using a paired test setting, specifically the Wilcoxon signedrank test, due to the comparison being made between two samples generated from the same input. However, the comment does not specify which part of the paper discusses the significance testing or where the comparison between the two samples is made. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs attention. While the comment is specific about the suggestion to use a paired test, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors might have incorrectly chosen a significance testing method and recommends using a paired test setting, specifically the Wilcoxon signedrank test, due to the comparison being made between two samples generated from the same input. However, the comment does not provide any specific reasoning, examples, or references to support why a paired test would be more appropriate in this context. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the choice of significance testing method, suggesting that a paired test like the Wilcoxon signedrank test might be more appropriate given the comparison between two samples generated from the same input. This feedback is 3 as it points out a potential area for improvement and provides a specific suggestion for an alternative test. However, the comment lacks detailed guidance on why the current test might be incorrect or how the authors could implement the suggested test. Without more comprehensive advice, the authors may struggle to fully address the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and bringing the description of related literature forward. While the comment implies that these actions would enhance the paper, it does not explicitly instruct the authors to do so. The actions are somewhat vague, as the authors are not given specific guidance on how to integrate the background knowledge or where to place the related literature description. Therefore, the comment is 3, as it provides a general direction but lacks concrete details on how to implement the suggested improvements.", "grounding_specificity_rationale": "The comment suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and bringing the description of related literature forward. However, it does not specify which part of the paper this organization issue pertains to, such as the introduction, methodology, or discussion sections. This lack of specificity makes it difficult for the authors to pinpoint exactly where the improvements should be made. The comment is fully grounded in terms of identifying the need for improvement but is not specific in detailing what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and bringing the description of related literature forward. However, the comment lacks specific details or examples to support this claim. It does not provide any references or logical reasoning to justify why these changes would be beneficial or how they would enhance the paper. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and bringing the description of related literature forward. While this feedback offers a general direction for improvement, it lacks specific details or actionable suggestions on how to implement these changes. The comment does not specify which sections of the paper need additional background or where the related literature should be integrated. This lack of specificity makes it challenging for the authors to fully understand and address the feedback effectively. Therefore, the comment is 3, as it identifies a potential area for improvement but does not provide detailed guidance on how to achieve it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not included in the comparison. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. The comment lacks guidance on whether the authors should include these models in their comparison or provide a rationale for their exclusion. As a result, the authors are left without a clear understanding of what action to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"some other representative panoptic segmentation models,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies which models are missing from the comparison, namely \"PanopticFPN\" and \"Mask2Former.\" This provides the authors with a clear understanding of what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed explanations or references to justify why these models are not included or why their absence is a significant omission. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the comparison of panoptic segmentation models, noting the absence of models like PanopticFPN and Mask2Former. This feedback is valuable as it highlights an area where the authors could enhance their work by including a broader range of models in their comparison. However, the comment lacks depth and does not provide specific guidance on how the authors might address this issue or what additional models they should consider. While it points out a potential improvement, it does not offer actionable steps or detailed suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include results in other modalities, such as languagerelated tasks, and questions the significance of expected test loss in these contexts. While the comment provides a direction for improvement, it does not explicitly instruct the authors on which modalities to include or how to present the results. The suggestion is somewhat vague, as it lacks specific guidance on which tasks or modalities to focus on. Therefore, the comment is 3, as it gives a general idea of what needs to be done but does not provide detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment suggests including results in other modalities, such as languagerelated tasks, and questions the significance of expected test loss in these contexts. However, it does not specify which modalities or tasks should be included, nor does it provide guidance on how to present the results or address the concerns about expected test loss. The comment is 1 as it does not explicitly mention specific sections or parts of the paper that need improvement. It is also not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests including results in other modalities, such as languagerelated tasks, and questions the significance of expected test loss in these contexts. However, the comment lacks specific examples or references to support the claim that expected test loss is not meaningful for languagerelated tasks. It does not provide detailed reasoning or evidence to justify the suggestion, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests including results in other modalities, such as languagerelated tasks, and questions the significance of expected test loss in these contexts. While it provides a direction for improvement by suggesting the inclusion of additional results, it lacks specific guidance on which modalities or tasks to focus on. The comment also raises a question about the relevance of expected test loss, which could prompt the authors to reconsider their evaluation metrics. However, the feedback is somewhat limited in its scope and does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it provides some insight but lacks depth and specificity to fully guide the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare their work with the recent related work CoCoOp [1] in the experiments. While the comment implies that this comparison is necessary, it does not explicitly instruct the authors to include it in their draft. The action is implicit, as the authors need to infer that they should add a comparison with CoCoOp to their experiments. However, the comment lacks specific guidance on how to implement this comparison, such as which aspects of the work should be compared or what data should be used. Therefore, the comment is 3, as it provides a clear direction but lacks concrete details on how to execute it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the recent related work CoCoOp [1]\" and suggests comparing it with the authors\" work in the experiments. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the need to compare with CoCoOp, which is a specific and relevant work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the recent related work CoCoOp [1] should be compared in the experiments. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide a detailed explanation of why CoCoOp is a relevant comparison or how its inclusion would enhance the paper. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should compare their work with the recent related work CoCoOp [1] in the experiments. This is a valuable piece of feedback as it highlights a relevant comparison that could strengthen the paper\"s context and contribution. However, the comment could be more helpful if it provided additional guidance on how to conduct this comparison, such as which aspects of the work should be compared or what data should be used. Despite this, the comment offers a clear direction for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the experimental setup, noting that the author only conducted experiments on two typical games. It suggests that the ReBeL\"s performance on more complex problems, especially those with larger depth, could be explored. However, the comment does not provide explicit guidance on how to address this limitation or what specific experiments should be conducted. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their experiments to more complex games. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ReBeL\"s performance on more complex problem\" and \"bigger depth,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a limitation in the experimental setup, noting that the experiments were only conducted on two typical games, and suggests exploring the performance on more complex problems with larger depth. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a limitation in the experimental setup, noting that the author only conducted experiments on two typical games. It suggests that the ReBeL\"s performance on more complex problems, especially those with larger depth, could be explored. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the experiments were limited to two typical games. This lack of evidence makes it difficult for the authors to understand the basis of the critique and how it might impact their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental setup, noting that the author only conducted experiments on two typical games. It highlights the ReBeL\"s performance on more complex problems, especially those with larger depth, which could lead to significant inputs for the value and policy functions. This feedback is 3 as it points out a potential area for improvement in the experimental design. However, it lacks specific guidance on how to address this limitation or what additional experiments could be conducted to strengthen the paper. The comment provides a clear direction for improvement but could be more helpful with additional suggestions or examples. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting the absence of a discussion on the theoretical guarantee of the hierarchical strategy compared to the global optimal of the original QUBO. However, it does not provide any explicit or implicit suggestions on how the authors might address this gap or what aspects of the discussion could be expanded. The comment identifies a specific area that needs attention but does not offer guidance on how to improve the draft. As a result, the authors are left without a clear direction for action, making the comment 1.", "grounding_specificity_rationale": "The comment highlights a specific gap in the paper by pointing out the lack of discussion on the theoretical guarantee of the hierarchical strategy compared to the global optimal of the original QUBO. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the missing discussion but lacks grounding as it does not provide clear guidance on where to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a discussion on the theoretical guarantee of the hierarchical strategy compared to the global optimal of the original QUBO. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors are left to infer the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of a discussion on the theoretical guarantee of the hierarchical strategy compared to the global optimal of the original QUBO. This is a crucial aspect that needs to be addressed to strengthen the paper\"s theoretical foundation. However, the comment lacks specific guidance or suggestions on how the authors might approach this discussion or what aspects of the analysis could be expanded. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for the authors to follow but does not offer detailed guidance on implementation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of quantitative measures for evaluating the generated VCEs, noting that the evaluation is primarily based on visual inspection. While it identifies a gap in the methodology, it does not provide explicit guidance on how to address this issue or suggest specific quantitative measures. The action is implicit, as the authors would need to infer that they should consider adding quantitative metrics to their evaluation process. However, the comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"generally lacking a quantitative measure to evaluate the generated VCEs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking quantitative measures and suggests that the evaluation is primarily based on visual inspection. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is generally lacking a quantitative measure to evaluate the generated VCEs, with evaluation primarily relying on visual inspection. This claim is 3 as it provides a general observation about the evaluation methodology but lacks specific examples or references to support the claim. The authors would need to infer that the lack of quantitative measures is a significant issue, but the comment does not offer detailed reasoning or evidence to fully substantiate the claim. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of quantitative measures for evaluating the generated VCEs. It notes that the evaluation is primarily based on visual inspection, which may not provide a comprehensive or objective assessment. This feedback is valuable as it highlights a potential gap in the methodology and suggests that the authors should consider incorporating quantitative measures to enhance the rigor and depth of their evaluation. However, the comment could be more helpful if it provided specific examples of quantitative measures that could be used or suggested alternative evaluation methods. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights issues with the generated videos, noting that only some are convincing and that the action recognition performance is below the stateoftheart on the UCF dataset. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment lacks guidance on how the authors might improve the video generation or action recognition performance. As a result, the authors are left without a clear path to follow, making the comment 1.", "grounding_specificity_rationale": "The comment mentions \"generated videos\" and \"action recognition performance,\" but it does not specify which part of the paper these issues relate to. The authors cannot confidently determine which sections or figures are being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific details about what needs to be addressed or how the issues can be resolved. Therefore, the comment is 2, aligning with category 2.", "verifiability_rationale": "The review point claims that the generated videos have significant artifacts and that the action recognition performance is below the stateoftheart on the UCF dataset. However, the comment lacks specific examples or references to support these claims. Without detailed evidence or examples, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some basis for concern but lacks sufficient detail to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies issues with the generated videos, specifically noting the presence of significant artifacts and the low action recognition performance compared to stateoftheart methods on the UCF dataset. It also questions the depth of the architectures used, suggesting that more complex models might be necessary. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues. While it highlights areas for improvement, it does not provide specific steps or recommendations for enhancing the video generation or action recognition processes. As a result, the feedback is 3, as it points out areas for improvement but does not fully empower the authors to make meaningful changes to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim (2017). While it raises a valid point about the need to clarify the connection between the term and the cited work, it does not provide explicit guidance on how the authors should address this concern. The comment lacks concrete suggestions or actions for the authors to take, such as suggesting specific ways to clarify the relevance or providing examples of how the term might be used in the context of the cited work. As a result, the comment is 3, as it identifies an area for improvement but does not provide detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider by questioning the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim (2017). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point raises a question about the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim (2017). While it prompts the authors to consider this connection, it does not provide any specific evidence, reasoning, or references to support the claim. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the question. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim (2017). This question prompts the authors to consider the connection between the term and the cited work, which could help them clarify their terminology and ensure consistency in their use of terms. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as suggesting specific ways to clarify the relevance or providing examples of how the term might be used in the context of the cited work. While it identifies an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. While this feedback identifies a potential area for improvement, it does not provide explicit guidance on how the authors should expand their experiments or what additional datasets they could consider. The action is implicit, as the authors need to infer that they should include more diverse datasets to enhance the comprehensiveness of their experiments. However, the lack of concrete suggestions or examples makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments being limited to MNIST and a single realworld dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the limitation in the experiments, indicating that the authors should consider expanding their experiments to include more diverse datasets. This provides clear guidance on what needs to be addressed to improve the comprehensiveness of the experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. This feedback is 3 as it points out a potential area for improvement in the experimental design. However, it lacks specific examples or references to support the claim that expanding the experiments would enhance the comprehensiveness of the study. The authors could benefit from additional context or suggestions on how to address this limitation, making the comment 3.", "helpfulness_rationale": "The comment identifies a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. This feedback is 3 as it highlights an area for improvement, suggesting that the authors should consider expanding their experiments to include more diverse datasets. However, the comment lacks specific guidance or suggestions on how to address this limitation, such as mentioning additional datasets or types of experiments that could be included. While it provides a clear direction for improvement, the lack of detailed advice limits its impact on the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors might be helpful in quantifying and clarifying the claim that ReLU does not work well in deep or convolutional networks. It also provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and convolutional. However, the comment does not explicitly instruct the authors on how to quantify or clarify the claim, nor does it provide detailed guidance on what specific aspects need to be addressed. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors might be helpful in quantifying and clarifying the claim about ReLU\"s performance in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and convolutional. However, the comment does not explicitly mention which part of the paper this claim is made, making it weakly grounded. The comment is specific in suggesting that the authors should quantify and clarify the claim, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors might be helpful in quantifying and clarifying the claim that ReLU does not work very well in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and convolutional. However, the comment lacks detailed reasoning or examples to fully support the claim, making it 3. The authors are left to infer the exact nature of the issue and how to address it, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors might be helpful in quantifying and clarifying the claim that ReLU does not work very well in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and convolutional. However, the comment lacks detailed guidance on how to quantify or clarify the claim, leaving the authors with limited actionable feedback. While it points out a potential area for improvement, it does not offer specific suggestions or detailed reasoning, making it 3. Therefore, the comment aligns with a score of 3, as it provides some insight but requires further elaboration to be fully beneficial."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper addresses the consistency between training and inference, noting that it can be easily satisfied due to the smoothness of neural models. However, it does not provide explicit guidance on what specific aspects of the paper need further explanation or elaboration. The suggestion to give more explanations is vague and lacks concrete details on how the authors should expand on this point. As a result, the authors are left without a clear understanding of what specific sections or arguments require additional clarification. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (9597 and 308310) where the issue of consistency between training and inference is discussed. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies that the authors should provide more explanations on this consistency, indicating what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper addresses the consistency between training and inference, noting that it can be easily satisfied due to the smoothness of neural models. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors are left to assume that the claim is valid, which makes it difficult to fully understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area in the paper where the consistency between training and inference is discussed, noting that it can be easily satisfied due to the smoothness of neural models. The reviewer suggests that the paper would benefit from providing more detailed explanations on this point. This feedback is clear and actionable, as it directs the authors to a specific area that requires further elaboration. By offering a suggestion for improvement, the comment helps the authors enhance the clarity and depth of their paper. However, the comment could be more helpful if it provided specific examples or guidance on how to expand on the explanation. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" claim of superior performance due to fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. It implies that the authors should explore whether the proposed model\"s performance improves with larger word embedding and LSTM parameters. However, the comment does not explicitly instruct the authors to conduct this exploration or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should test the model with larger parameters. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the authors\" claim of superior performance due to fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. It implies that the authors should explore whether the proposed model\"s performance improves with larger word embedding and LSTM parameters. However, the comment does not specify which part of the paper discusses the model\"s performance or parameters, making it weakly grounded. It is specific in questioning the claim and suggesting an additional experiment, but without clear references to the sections or figures, the authors may find it challenging to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" claim of superior performance due to fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. It implies that the authors should explore whether the proposed model\"s performance improves with larger word embedding and LSTM parameters. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to verify the claim or understand the reasoning behind it. The feedback is 3 as it provides a direction for further investigation but lacks detailed justification or evidence. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment questions the authors\" claim of superior performance due to fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. It implies that the authors should explore whether the proposed model\"s performance improves with larger word embedding and LSTM parameters. However, the comment lacks specific guidance or suggestions on how to conduct this exploration or what experiments to perform to substantiate the claim. While it points out a potential area for further investigation, it does not provide actionable steps or detailed feedback that would help the authors address the issue effectively. Therefore, the comment is 3, as it identifies a potential weakness but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the need for finetuning the extra hyperparameters k and \u03b7, which depend on the availability of the environment or a good Offline Policy Estimation (OPE) method. However, it does not provide explicit guidance on how to implement this finetuning or suggest specific methods or techniques to use. The action is implicit, as the authors need to infer that they should finetune the hyperparameters and consider the factors mentioned. While the comment is 3, it lacks concrete details on how to execute the finetuning process, making it 3.", "grounding_specificity_rationale": "The comment addresses the need for finetuning extra hyperparameters k and \u03b7, which depend on the availability of the environment or a good Offline Policy Estimation (OPE) method. However, it does not specify which part of the paper this issue is related to, such as a particular section or table. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific about the issue of hyperparameter finetuning, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the extra hyperparameters k and \u03b7 require finetuning, which depends on the availability of the environment or a good Offline Policy Estimation (OPE) method. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this claim and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the extra hyperparameters k and \u03b7, noting that they require finetuning, which depends on the availability of the environment or a good Offline Policy Estimation (OPE) method. This feedback is 3 as it highlights a potential area for improvement in the draft, specifically regarding the handling of these hyperparameters. However, the comment lacks depth and does not provide actionable guidance on how to address the issue or suggest specific methods for finetuning. The authors may need to infer the need for finetuning and consider the factors mentioned, but the comment does not offer comprehensive advice. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point provides specific feedback on a potential error in the text, noting that the first \"f\" should be \"g\" and that there is an extra \".\" in the middle of a sentence. It also raises a question about the convergence of networks in a baseline MCL with deep learning, suggesting that cutting learners early might affect ensemble performance. While the comment explicitly points out the error and raises a question, it does not provide explicit guidance on how to correct the error or address the question. The action is implicit, as the authors would need to infer that they should correct the error and consider the impact of early learner cutting. However, the feedback is somewhat vague, as it lacks detailed instructions on how to implement the correction or address the question. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (108 and 115) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be corrected, such as the typo in \"f\" and \"g\" and the extra period. Additionally, it raises a question about the convergence of networks in a baseline MCL with deep learning, which is a specific issue that needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the convergence of networks in a baseline MCL with deep learning, suggesting that cutting learners early might affect ensemble performance. However, it does not provide any specific evidence, reasoning, or references to support this claim. The comment lacks detailed justification or examples to substantiate the concern, making it difficult for the authors to understand the basis of the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues in the text, such as a potential typo (\"f\" should be \"g\") and an extra period in a sentence. It also raises a question about the convergence of networks in a baseline MCL with deep learning, suggesting that cutting learners early might affect ensemble performance. While the comment points out these areas for improvement, it lacks detailed guidance on how to address these issues or provide evidence to support the claim about convergence. The feedback is 3 as it highlights specific areas that need attention, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the dependence of FedPCL\"s performance on the selection of pretrained models, noting that this limits its applicability to a broader range of areas. It also mentions that the model accuracy is sensitive to the choice of pretrained models, as shown in Table 4. The comment suggests that the authors have adequately addressed the limitations and developed a lightweight federated learning framework to reduce computation and communication costs. However, the comment does not provide explicit guidance on how the authors should address these limitations or what specific actions they should take to improve their draft. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance of FedPCL and its reliance on pretrained models, noting that this limits its applications to a broader range of areas. It also mentions that the model accuracy is sensitive to the choice of pretrained models, as evidenced by the results in Table 4. The comment suggests that the authors have adequately addressed the limitations and developed a lightweight federated learning framework to reduce computation and communication costs. However, the comment does not specify which part of the paper discusses the limitations or the development of the framework, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issue of pretrained model selection, it lacks full grounding as it does not provide explicit references to sections or figures. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the performance of FedPCL heavily relies on the selection of different pretrained models, which limits its applications to a broader range of areas. It also notes that the model accuracy is sensitive to the choice of pretrained models, as shown in Table 4. The comment suggests that the authors have adequately addressed these limitations and developed a lightweight federated learning framework to reduce computation and communication costs. However, the claim lacks specific examples or detailed reasoning to fully substantiate the assertion about the limitations and the effectiveness of the proposed framework. The comment provides a general overview but does not offer a comprehensive explanation or evidence to support the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a limitation in the performance of FedPCL, which is heavily dependent on the selection of pretrained models. This limits its applicability to a broader range of areas. The comment also notes that the model accuracy is sensitive to the choice of pretrained models, as evidenced by the results in Table 4. While the comment acknowledges that the authors have adequately addressed these limitations, it does not provide specific suggestions or guidance on how the authors might improve their work to overcome these challenges. The feedback is 3 as it highlights an important issue that needs attention, but it lacks depth and actionable advice, making it difficult for the authors to fully address the concerns. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include not only the retrieved and final attention maps but also the tentative attention maps in the qualitative figures. This provides a clear and explicit action for the authors to take, as they know exactly what additional information they should include in their figures. The comment is specific in its request, detailing what is missing and why it would be beneficial. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including tentative attention maps in the qualitative figures, which implies that the authors should consider adding this information. However, it does not specify which part of the paper these figures are located in, making it weakly grounded. The comment is specific in its suggestion to include the missing information, but the lack of grounding makes it difficult for the authors to precisely identify where to make the addition. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including \"tentative attention maps\" in the qualitative figures, which implies that the authors should consider adding this information. However, the comment does not provide any specific reasoning, examples, or references to support why this addition would be beneficial or how it would enhance the paper. Without further elaboration or justification, the claim lacks sufficient evidence to be considered verifiable. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests including \"tentative attention maps\" in the qualitative figures, which implies that the authors should consider adding this information. While the comment identifies a potential improvement to the presentation of the results, it lacks specificity and does not provide detailed guidance on how to implement this suggestion. The feedback is 3 as it points out a potential area for enhancement, but it does not offer a comprehensive or actionable plan for the authors to follow. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses confusion about Figure 5 or the labels, but it does not provide any explicit or implicit actions for the authors to take. The authors are left without guidance on how to address this issue, making the comment 1. Therefore, the comment aligns with the lowest score of 1.", "grounding_specificity_rationale": "The comment expresses confusion about Figure 5 or the labels, but it does not specify which part of the paper this issue pertains to, nor does it provide any guidance on how to address it. The authors cannot confidently determine which section or element is being referred to, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what is unclear or incorrect about the figure or labels. Therefore, this comment is 2, aligning with a score of 1.", "verifiability_rationale": "The review point expresses confusion about Figure 5 or the labels, but it does not provide any specific reasoning, examples, or references to support the claim. The authors are left to interpret the issue, making the comment 1. Therefore, the comment aligns with a score of 1.", "helpfulness_rationale": "The review comment expresses confusion about Figure 5 or the labels, but it does not provide any specific guidance or suggestions on how to address this issue. The authors are left without actionable feedback, making the comment unhelpful. Therefore, the comment aligns with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the authors\" derivation, suggesting that it falls into classical learning theorybased bounds, which are not realistic unless Bayesian considerations are included. However, the comment does not provide any explicit or implicit guidance on how the authors might address this issue or incorporate Bayesian considerations into their derivation. The authors are left without any actionable steps to improve their work, making the comment 1.", "grounding_specificity_rationale": "The comment critiques the authors\" derivation, suggesting that it falls into classical learning theorybased bounds, which are not realistic unless Bayesian considerations are included. However, the comment does not specify which part of the paper this critique refers to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the derivation but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the authors\" derivation, suggesting that it falls into classical learning theorybased bounds, which are not realistic unless Bayesian considerations are included. The comment provides a specific example of BayesianPAC based bounds, which could be used to support the claim. However, it lacks detailed reasoning or references to substantiate the claim fully. The authors would benefit from a more comprehensive explanation of why classical bounds are insufficient and how Bayesian considerations could improve the derivation. Therefore, the comment is 3, as it provides some justification but lacks depth and detail.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" derivation, suggesting that it falls into classical learning theorybased bounds, which may not yield realistic results without incorporating Bayesian considerations. This feedback is 3 as it points out a specific area that needs attention and suggests a potential improvement by considering BayesianPAC based bounds. However, the comment lacks detailed guidance on how the authors might address this issue or what specific changes could be made to their derivation. While it provides a direction for improvement, it does not offer a comprehensive or actionable response, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the application of weight decay, suggesting that the authors should expect suboptimal cosine similarities for large weight decay parameters. It also notes that the plots do not extend to these large weight decay strengths, where cosine similarities are not reported. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to their draft. The action is implicit, as the authors need to infer that they should consider reporting cosine similarities for larger weight decay strengths or extend their plots to include these values. While the action is somewhat concrete, the lack of explicit guidance makes it 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the application of weight decay, noting that the plots do not extend to large weight decay strengths where cosine similarities are expected to be suboptimal. However, it does not explicitly mention which part of the paper this issue is discussed in, such as a specific section or figure. This makes it weakly grounded, as the authors may need to infer the relevant part of the paper. The comment is specific in that it identifies a clear issue with the reporting of cosine similarities for large weight decay parameters, which is a specific aspect of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the plots do not extend to large weight decay strengths where cosine similarities are expected to be suboptimal. However, it does not provide any specific reasoning or evidence to support this claim, such as examples or references to other studies. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the application of weight decay, noting that the plots do not extend to large weight decay strengths where cosine similarities are expected to be suboptimal. This observation is insightful and highlights a gap in the analysis. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their draft. While it points out a potential area for further exploration, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a significant issue with the paper, noting that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests. This omission is serious, as it could lead to misinterpretations and incorrect conclusions. The comment suggests that this issue must be addressed for publication and implies that it would be straightforward to fix. However, the comment does not provide specific guidance on how to revise the sections to include this information or what specific changes are needed. While the action is explicit in identifying the problem, it lacks concrete details on how to address it, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sections of the paper that do not explain the results for unsupervised random forests, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies the issue, which is the omission of this information in the title, abstract, introduction, and discussion. The comment provides a clear and detailed explanation of what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests, which is a serious omission. The comment suggests that this issue must be addressed for publication and implies that it would be straightforward to fix. However, the comment lacks specific examples or detailed reasoning to support the claim, making it 3. The authors would need to infer the need for clarification, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests. This omission is significant because it could lead to misinterpretations and incorrect conclusions, potentially affecting the credibility of the work. The comment suggests that this issue must be addressed for publication, implying that it would be straightforward to fix. However, the comment lacks detailed guidance on how to revise the sections to include this information or what specific changes are needed. While it highlights a crucial oversight, the feedback could be more helpful if it provided specific suggestions or examples of how to address the issue. Therefore, the comment is 3, as it points out a significant problem but does not offer comprehensive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and possible usecases of _LMGQS_ over other QFS datasets. This comment is explicit in its request for additional evidence and analysis, providing a clear action for the authors to take. It specifies what kind of evidence or analysis is needed, making it concrete. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and possible usecases of _LMGQS_ over other QFS datasets. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper needs to be addressed. Additionally, the comment is specific in its request for more evidence and analysis, but without a clear reference to the paper, it is difficult for the authors to understand exactly where to add this information. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and possible usecases of _LMGQS_ over other QFS datasets. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by suggesting that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and possible usecases of _LMGQS_ over other QFS datasets. This feedback is clear and actionable, as it directs the authors to enhance the depth and clarity of their analysis. However, the comment could be more helpful if it provided specific examples or guidance on what kind of evidence or analysis would be beneficial. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the claim that improvements are due to distillation rather than regularization effects. It suggests that the finetuning was performed for 10 epochs without early stopping, which could lead to high variances and the need for proper ablation studies. However, the comment does not explicitly instruct the authors to conduct these ablation studies or provide detailed guidance on how to address the issue. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the claim that improvements are due to distillation rather than regularization effects, specifically questioning the validity of this claim given the finetuning parameters. It mentions that all finetuning is performed for 10 epochs without early stopping, which is a specific detail that could lead to high variances. However, the comment does not explicitly mention which part of the paper this issue is discussed, making it weakly grounded. The comment is specific in detailing the concern about the regularization effects and the need for proper ablation studies, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim that the improvements in the paper could be due to regularization effects rather than distillation, as the finetuning was performed for 10 epochs without early stopping. The comment suggests that this is a potential issue and that proper ablation studies are needed to verify the claim. However, the comment lacks specific examples or references to support the claim that regularization effects are a significant factor in this context. While the reasoning is logical, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the claim that improvements are due to distillation rather than regularization effects. It points out that the finetuning was performed for 10 epochs without early stopping, which could lead to high variances and the need for proper ablation studies. This feedback is 3 as it highlights a specific area that requires further investigation and provides a suggestion for improvement. However, it could be more helpful if it included more detailed guidance on how to conduct these ablation studies or suggested alternative methods to address the issue. Overall, the comment provides a clear direction for the authors to consider, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the methodology and experimental setup, specifically regarding the use of node importance in a 1shot scenario and the absence of a 1shot setting in the experiments. While it prompts the authors to clarify how node importance is used in a 1shot setting, it does not provide explicit instructions or suggestions on how to address the issue of missing 1shot experiments. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and potentially additional experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the methodology and experimental setup, specifically regarding the use of node importance in a 1shot scenario and the absence of a 1shot setting in the experiments. However, it does not specify which part of the paper these questions pertain to, such as the methodology or experimental section. This lack of grounding makes it difficult for the authors to identify the exact areas that need clarification or improvement. While the comment is specific in its questions, the absence of explicit references to sections or parts of the paper makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the methodology and experimental setup, specifically regarding the use of node importance in a 1shot scenario and the absence of a 1shot setting in the experiments. However, it does not provide any claims or suggestions that require verification or justification. The comment is purely descriptive, asking for clarification and explanation rather than making assertions or recommendations. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises questions about the methodology and experimental setup, specifically regarding the use of node importance in a 1shot scenario and the absence of a 1shot setting in the experiments. It points out that related works, such as RALE, have a 1shot setting, which is not addressed in the paper. This feedback highlights a potential gap in the paper\"s discussion of the experimental setup and methodology, suggesting that the authors should clarify how node importance is used in a 1shot setting and why the experiments do not include a 1shot setting. However, the comment lacks specific guidance on how to address these issues or what changes might be necessary. While it identifies an area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should include more discussions about why Large Language Models (LLMs) struggle with finegrained hard constraints and how to address these issues. While the comment implies that the authors should expand on this topic, it does not provide specific guidance on what aspects of the discussion should be included or how to address the problems. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the discussion of LLM limitations and solutions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include more discussions about why LLMs struggle with finegrained hard constraints and how to address these problems. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs improvement. The comment is specific in its suggestion to address the issue of LLM limitations, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper should include more discussions about why LLMs struggle with finegrained hard constraints and how to address these problems. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to incorporate it into their work. Without additional context or references, the claim remains 3, as it is based on a general observation without detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the paper should include more discussions about why Large Language Models (LLMs) struggle with finegrained hard constraints and how to address these issues. This feedback is 3 as it highlights a specific area where the authors could enhance their work by providing a more comprehensive discussion. However, the comment lacks depth and does not offer specific guidance on what aspects of the discussion should be included or how to address the problems. While it points to a valuable area for improvement, it does not provide actionable steps for the authors to take, making it 3 rather than fully helpful. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting that while the experimental results suggest the value of the proposed approach for selfsupervised learning on 360 video data with spatial audio, the paper does not provide sufficient insights into why this specific type of data is important for selfsupervised learning. The comment implies that the authors should elaborate on the significance of this data type in the context of selfsupervised learning. However, the action is implicit, as the authors need to infer that they should provide more detailed insights or explanations regarding the importance of this data type. The action is vague because it does not specify exactly what kind of insights or explanations are needed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the experimental results and suggests that while the results indicate the value of the proposed approach for selfsupervised learning on 360 video data with spatial audio, the paper lacks insights into why this specific type of data is important for selfsupervised learning. However, the comment does not specify which part of the paper discusses the experimental results or the specific section where the authors should provide more insights. This makes it difficult for the authors to identify the exact area that needs improvement. The comment is specific in its critique but weakly grounded because it does not provide explicit references or sections for the authors to focus on. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks insights into why selfsupervised learning is necessary for 360 video data with spatial audio. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that while the experimental results suggest the value of the proposed approach for selfsupervised learning on 360 video data with spatial audio, the paper lacks insights into why this specific type of data is important for selfsupervised learning. This feedback highlights a need for the authors to elaborate on the significance and importance of this data type in the context of selfsupervised learning. However, the comment does not provide specific suggestions or guidance on how the authors might address this gap, such as suggesting additional experiments or analyses that could provide more insights. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the analysis of the SimCLR approach, specifically mentioning the absence of analysis on the projection head, which is a critical component of the method. While the comment identifies a specific area that needs further exploration, it does not provide explicit guidance on how the authors should address this gap or what specific analysis should be conducted. The action is implicit, as the authors are expected to infer that they need to include an analysis of the projection head. However, the lack of concrete instructions on how to perform this analysis makes the comment 3. Therefore, this comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SimCLR\" and \"projection head,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the absence of analysis on a critical component of the SimCLR approach, which is the projection head. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point claims that only the SimCLR case is covered and that there is no analysis on a seemingly important part of that approach, specifically the projection head. However, the comment does not provide any evidence or reasoning to support this claim, such as specific examples or references to other papers that might have addressed this aspect. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the analysis of the SimCLR approach, noting that only the SimCLR case is covered without any analysis of a critical component, the projection head. This feedback is clear and actionable, as it directs the authors to a specific area that needs further exploration. By highlighting this omission, the comment provides a clear direction for improving the depth and comprehensiveness of the analysis. However, it could be more helpful if it suggested specific ways to analyze the projection head or provided examples of how to do so. Overall, the comment is 4, as it effectively points out a significant area for improvement but could be more detailed in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the authors introduce several approximations, which could leave readers with questions about the robustness of the results. It suggests that the authors should expand on the possible vulnerability due to the assumption of attacks being in the feasible set only in lines 107110 to reassure readers that it is not a real concern. The comment implies that the authors should provide more detail or justification to address this concern, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand on the vulnerability. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of approximations introduced in the paper, specifically mentioning \"several approximations (i iii)\" and suggesting that the authors should expand on the possible vulnerability due to the assumption of attacks being in the feasible set only in lines 107110. However, the comment does not specify which part of the paper these approximations are discussed or where the vulnerability is addressed. This makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issue of approximations and vulnerability, it lacks grounding as it does not provide clear references to the relevant sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors introduce several approximations, which leaves loose ends, and suggests that the possible vulnerability due to the assumption of attacks being in the feasible set only in lines 107110 needs to be expanded to reassure readers. The comment provides a logical reasoning by pointing out the potential vulnerability and suggesting that it should be addressed. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper by pointing out that the authors introduce several approximations, which could leave readers with questions about the robustness of the results. It suggests that the authors should expand on the possible vulnerability due to the assumption of attacks being in the feasible set only in lines 107110 to reassure readers that it is not a real concern. This feedback is 3 as it highlights a specific area that needs clarification or expansion, but it lacks depth and does not provide detailed guidance on how to address the issue. The authors would benefit from a more comprehensive explanation of the approximations and the rationale behind the vulnerability, which would enhance the clarity and robustness of the paper. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the fairness of the comparison between the proposed method and the stateoftheart (SOTA). It points out that the proposed method lacks an advantage without prior information, similar to the benchmarks, and that the advantage only emerges when prior knowledge is used. The reviewer suggests that the proposed method essentially requires two representation models, VAE/GAN + CL, which adds complexity and cost. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the experimental results and highlights a concern regarding the fairness of the comparison between the proposed method and the stateoftheart (SOTA). It points out that without prior information, the proposed method does not show an advantage compared to the SOTA, similar to the benchmarks. However, the advantage is only evident when prior knowledge is used. The reviewer suggests that the proposed method essentially requires two representation models, VAE/GAN + CL, which adds complexity and cost. While the comment is specific about the issue of fairness and the need to consider the extra complexity of the proposed method, it does not explicitly mention which part of the paper this issue is discussed in. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method lacks an advantage without prior information, similar to the benchmarks, and that the advantage only emerges when prior knowledge is used. The reviewer suggests that the proposed method essentially requires two representation models, VAE/GAN + CL, which adds complexity and cost. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand and address the issue. The lack of detailed reasoning or evidence makes the claim 3, as it is based on logical reasoning but lacks sufficient support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the experimental comparison of the proposed method against the stateoftheart (SOTA). It highlights that the proposed method lacks an advantage without prior information, similar to the benchmarks, and that the advantage only emerges when prior knowledge is used. The reviewer points out that the proposed method essentially requires two representation models, VAE/GAN + CL, which adds complexity and cost. This feedback is valuable as it challenges the fairness of the comparison and raises concerns about the practicality and efficiency of the proposed method. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors could address these issues or improve their experimental setup. Overall, the comment is 3 as it identifies a significant concern but lacks detailed actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a limitation of the proposed model, noting that it can only be used with a small number of dimensions due to the curse of dimensionality. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. The comment lacks guidance on how the authors might overcome this issue or suggest alternative approaches. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific limitation of the proposed model, noting that it can only be used with a small number of dimensions due to the curse of dimensionality. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the model\"s applicability, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the new proposed model can only be used with a small number of dimensions due to the curse of dimensionality. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it difficult to understand or address the issue raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation of the proposed model, noting that it can only be used with a small number of dimensions due to the curse of dimensionality. While this observation is accurate, the comment lacks actionable suggestions or guidance on how the authors might address this limitation or improve the model\"s applicability. Without further insights or recommendations, the authors may struggle to understand the implications of this limitation or how to enhance their work. Therefore, the comment is 2, as it provides a clear observation but lacks depth and direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the supervised pretraining method based on the homolumo gap, suggesting that it might lead to negative transfer. It provides an example of this issue by mentioning the poor performance of TransformerM on most tasks in the QM9 dataset, except for homo, lumo, and gap. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to mitigate it. While the authors can infer that they should consider alternative pretraining methods or discuss the implications of this finding, the action remains somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to supervised pretraining based on the homolumo gap, which is a particular aspect of the paper. It provides an example of how this pretraining method might lead to negative transfer, specifically mentioning the poor performance of TransformerM on most tasks in the QM9 dataset, except for homo, lumo, and gap. This allows the authors to identify the specific part of the paper being addressed, making the comment fully grounded. The comment is also specific as it details the issue and provides an example, guiding the authors on how to address it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that supervised pretraining based on the homolumo gap may lead to negative transfer, as evidenced by the poor performance of TransformerM on most tasks in the QM9 dataset, except for homo, lumo, and gap. This claim is supported by specific examples and data, making it 4. The reasoning is clear and logical, providing a basis for the authors to understand and address the issue. However, the comment could be strengthened by including more detailed references or explanations to further substantiate the claim. Overall, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the supervised pretraining method based on the homolumo gap, suggesting that it might lead to negative transfer. It provides an example of this issue by mentioning the poor performance of TransformerM on most tasks in the QM9 dataset, except for homo, lumo, and gap. This feedback is 3 as it highlights a specific area that needs attention and provides a clear example of the problem. However, the comment could be more helpful if it offered suggestions or guidance on how the authors might address this issue or discuss the implications of this finding. Overall, the comment provides a valuable insight that could guide the authors in improving their draft, making it a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the theoretical contribution as \"ok\" but expresses concern about its strength, noting that it is \"weak, unpractical bound\" and that the proof does not provide \"particular mathematical novelty.\" However, the comment does not offer any explicit or implicit suggestions for improvement or actionable steps the authors should take to address these concerns. The authors are left without guidance on how to enhance the theoretical contribution or make it more practical. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"theoretical contribution,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors find lacking, namely, the strength of the theoretical contribution and the unpracticality of the bound. However, the comment does not provide specific guidance or suggestions on how to improve the theoretical contribution or address the identified issues. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the theoretical contribution is \"ok\" but not \"particularly strong,\" given existing results. It also critiques the bound as \"weak, unpractical,\" and notes that the proof does not provide \"particular mathematical novelty.\" However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The feedback is 3 as it provides a general assessment but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a concern regarding the strength of the theoretical contribution, noting that it is described as \"ok\" but not \"particularly strong.\" It also critiques the bound as \"weak, unpractical,\" and points out that the proof does not provide \"particular mathematical novelty.\" While the comment highlights specific issues with the theoretical contribution, it does not offer actionable suggestions or guidance on how the authors might address these concerns or improve the contribution. The feedback is 3 as it provides a clear critique of the theoretical aspects, but it lacks depth and direction for improvement, leaving the authors with limited insights on how to enhance their work. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the meaning of the phrase \"is sufficient\" in the context of the paper, specifically concerning the sum of \"optimistic\" hopedfor rewards and the expected actual rewards. While the comment implies that the authors should clarify this phrase, it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should clarify the phrase, but it lacks concrete details on what specific changes or additions are needed. Therefore, the comment is 3, as it identifies a potential area for improvement but does not provide detailed instructions on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific line numbers (L240 and L428), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what the authors should clarify, namely the meaning of the phrase \"is sufficient\" in the context of the sum of \"optimistic\" hopedfor rewards and the expected actual rewards. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the meaning of the phrase \"is sufficient\" in the context of the paper, specifically concerning the sum of \"optimistic\" hopedfor rewards and the expected actual rewards. While the comment implies that the authors should clarify this phrase, it does not provide any specific examples, reasoning, or references to support the claim that the phrase is unclear or requires clarification. The lack of detailed explanation or justification makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a specific ambiguity in the paper, particularly regarding the phrase \"is sufficient\" at lines 240 and 428. It suggests that the authors might be trying to convey that the sum of \"optimistic\" hopedfor rewards is close to the expected actual rewards. However, the comment does not provide any guidance or suggestions on how the authors could clarify this phrase or address the potential ambiguity. Without specific advice on what changes to make or how to rephrase the sentence, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is 2, as it identifies a potential issue but lacks actionable guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the tradeoff between computational efficiency and information loss when using ancestral graphs compared to DAGs. It highlights that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in less information compared to the richer search space of DAGs. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft. The action is implicit, as the authors need to infer that they should consider the implications of this tradeoff and potentially discuss it in their paper. The action is vague because it does not specify how to address the issue or what changes might be needed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the tradeoff between computational efficiency and information loss when using ancestral graphs compared to DAGs, referencing a specific paper [10]. It highlights that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in less information compared to the richer search space of DAGs. The comment is fully grounded as it explicitly mentions the paper [10] and the specific aspect of the method being discussed. It is also specific because it clearly specifies the issue of information loss and the tradeoff between computational efficiency and information richness. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method reduces computation time by reducing the search space to ancestral graphs, which results in less information compared to the richer search space of DAGs. The comment questions how much information of a DAG is encoded in its corresponding ancestral graph. However, the claim lacks specific examples or detailed reasoning to support the assertion about the information loss. While the logic is somewhat inferable, the absence of concrete evidence or references makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed method, noting that while it reduces computation time, it does so by reducing the search space to ancestral graphs, resulting in less information compared to the richer search space of DAGs. The comment questions the tradeoff between computational efficiency and information richness, which is a valuable point for the authors to consider. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights an important aspect of the method, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3, as it offers insight but could be more comprehensive with suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point questions the authors\" VAD (Visual Attention Descriptor) description, suggesting that it discards TF (TimeFrequency) bins with a magnitude less than epsilon. The reviewer argues that this approach is problematic because it discards TF bins with zero magnitude, which could lead to division by zero. They also critique the VAD\"s definition, noting that it should look for the presence of speech (not just energy) and is typically defined over time, not frequency. While the comment identifies a potential issue with the VAD description, it does not provide explicit guidance on how the authors should address this concern or what changes might be necessary. The action is implicit and somewhat vague, as the authors are left to infer the need for clarification or revision. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the VAD description, explaining that it discards TF bins with a magnitude less than epsilon, which could lead to division by zero. The reviewer critiques the approach, suggesting that it does not align with the typical definition of VADs, which are usually defined over time and look for the presence of speech, not just energy. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the VAD description is puzzling and suggests that it discards TF bins with a magnitude less than epsilon, which could lead to division by zero. The reviewer argues that this approach is problematic because it does not align with the typical definition of VADs, which are usually defined over time and look for the presence of speech, not just energy. The comment provides a logical reasoning for why the VAD description might be problematic, but it lacks specific examples or references to support the claim fully. While the reasoning is clear, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed critique of the VAD (Visual Attention Descriptor) description in the paper, highlighting a potential issue with how it handles TF (TimeFrequency) bins with a magnitude less than epsilon. The reviewer argues that this approach is problematic because it could lead to division by zero and does not align with the typical definition of VADs, which are usually defined over time and look for the presence of speech, not just energy. This feedback is clear and actionable, as it identifies a specific area of concern and suggests that the authors should reconsider their approach to defining and using the VAD. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue. Overall, the comment is 4, as it offers valuable insights for improvement but could be expanded for greater clarity and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the fairness of comparing the student and refinement networks, which are trained simultaneously. It suggests that the comparison might be unfair and requests the authors to provide KID/FID metrics for their teacher network. While the comment explicitly asks for clarification and provides a specific request for additional metrics, it does not offer explicit guidance on how to address the fairness issue or how to incorporate the KID/FID metrics into the comparison. The action is implicit and somewhat vague, as the authors need to infer that they should provide these metrics to address the concern. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the fairness of comparing student and refinement networks, which are trained simultaneously. It suggests that the comparison might be unfair and requests the authors to provide KID/FID metrics for their teacher network. However, the comment does not specify which part of the paper discusses the training of these networks or where the comparison is made. This lack of grounding makes it difficult for the authors to identify the exact section or part of the paper that needs attention. While the comment is specific in its request for metrics, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the fairness of comparing student and refinement networks, which are trained simultaneously, and requests the authors to provide KID/FID metrics for their teacher network. However, the comment does not provide any justification or reasoning for why this comparison might be unfair or how the request for metrics would address the issue. It lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the fairness of comparing student and refinement networks, which are trained simultaneously, and requests the authors to provide KID/FID metrics for their teacher network. This feedback is 3 as it identifies a potential issue with the comparison and suggests a specific metric to consider. However, it lacks detailed guidance on how to address the fairness concern or how to incorporate the KID/FID metrics into the analysis. The comment provides a starting point for improvement but does not offer comprehensive advice or suggestions for enhancing the draft. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should delve deeper into how specific models behave differently when ReGuide is applied, providing a more nuanced understanding of the conclusions. It gives an example of comparing false positive rates (FPR) between models with and without ReGuide. However, the comment does not explicitly instruct the authors to conduct this analysis or present the results in a specific way. While the action is implied, it lacks concrete guidance on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment suggests a deeper investigation into how specific models behave differently when ReGuide is applied, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper this investigation should be conducted in, making it weakly grounded. The comment is specific in its suggestion to compare false positive rates (FPR) between models with and without ReGuide, providing a clear direction for the authors to follow. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should provide a deeper investigation into how specific models behave differently when ReGuide is applied, particularly focusing on false positive rates (FPR). However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand and address the suggestion effectively. Without detailed guidance or evidence, the claim remains 3, as it lacks the necessary depth and clarity to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting a deeper investigation into how specific models behave differently when ReGuide is applied. It provides a specific example, such as comparing false positive rates (FPR) between models with and without ReGuide, which could enhance the nuance of the conclusions. However, the comment could be more helpful if it offered additional guidance on how to conduct this analysis or presented preliminary results. Overall, the feedback is 3 as it points out a valuable area for further exploration but lacks detailed instructions or examples to fully guide the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the explicitness (E) and size (S) of the traditional DCI framework, suggesting that these aspects may already be considered implicit. It provides an example of how the capacity of probing and latent size can affect the DCI evaluation, implying that the authors need to clarify the motivation for considering explicitness and size as extra evaluation. However, the comment does not explicitly instruct the authors to address this clarification or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the need for clarification and the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the traditional DCI framework and its consideration of explicitness (E) and size (S). It provides an example of how the capacity of probing and latent size can affect the DCI evaluation, suggesting that these aspects may already be considered implicit. However, the comment does not specify which part of the paper discusses the DCI framework or where the authors can find the relevant information. This makes it difficult for the authors to pinpoint the exact section or part of the paper being addressed. While the comment is specific about the issue of explicitness and size, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the explicitness (E) and size (S) of the traditional DCI framework, suggesting that these aspects may already be considered implicit. It provides an example of how the capacity of probing and latent size can affect the DCI evaluation, implying that the authors need to clarify the motivation for considering explicitness and size as extra evaluation. However, the comment lacks specific examples or references to support the claim that the DCI framework is already considered explicit or sizerelated. Without detailed reasoning or evidence, the claim is 3, as it provides a basis for discussion but lacks the depth needed for full understanding. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the explicitness and size of the traditional DCI framework, suggesting that these aspects may already be considered implicit. It provides an example of how the capacity of probing and latent size can affect the DCI evaluation, implying that the authors need to clarify the motivation for considering explicitness and size as extra evaluation. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what changes could be made to the framework. While it identifies a potential area for improvement, it does not provide actionable steps or detailed reasoning to help the authors enhance their work. Therefore, the comment is 3, as it highlights a relevant concern but does not offer comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that while the computational types of interventions are reasonable, it is important to consider their practicality and safety for realworld querying. However, it does not provide explicit guidance on how the authors should address this concern or what specific aspects of the interventions need to be evaluated for practicality and safety. The action is implicit and vague, as it leaves the authors to infer the necessary steps without clear direction. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that while the computational types of interventions are reasonable, it is important to consider their practicality and safety for realworld querying. However, it does not specify which part of the paper discusses the types of interventions or where the authors should address the practicality and safety concerns. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment is somewhat specific in that it highlights the importance of considering practicality and safety, but it lacks detailed guidance on how to achieve this. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that while the types of interventions are reasonable computationally, they need to be considered for practicality and safety in realworld querying. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence or justification to be considered 5. Therefore, the comment is rated as 2, as it offers a suggestion but lacks the necessary depth and support for the authors to fully understand and address the issue.", "helpfulness_rationale": "The review comment identifies a potential issue with the practicality and safety of the interventions discussed in the paper. It suggests that while the computational types are reasonable, they need to be considered for realworld querying. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or what aspects of the interventions should be evaluated for practicality and safety. While it points out an important consideration, it does not provide actionable advice or detailed feedback, making it 3. The authors would need to infer the necessary steps to improve their draft, which limits the comment\"s effectiveness. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could benefit from a different approach where everything is learned. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit, as the authors need to infer that they should consider removing the manual disentangling and exploring a learned approach. While the suggestion is concrete, the lack of explicit guidance makes the comment 3.", "grounding_specificity_rationale": "The comment raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could benefit from a different approach where everything is learned. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in that it identifies a potential issue with the manual disentangling process and suggests an alternative approach. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could benefit from a different approach where everything is learned. However, the comment does not provide any specific reasoning, examples, or references to support why this manual disentangling is a problem or why the suggested alternative approach is better. Without additional context or justification, the claim is difficult to verify, making it 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could benefit from a different approach where everything is learned, which is a valuable insight for the authors. However, the comment lacks specific guidance on how the authors might address this issue or what changes they should consider making to their draft. While it points out a potential area for improvement, it does not provide detailed suggestions or actionable steps, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the connection between the theoretical analysis and the proposed method, specifically noting that the proposed method appears to simply adopt the selfattention mechanism from transformers and apply it to graphs without clearly explaining how it enhances generalization for distant nodes. While the comment identifies a potential issue with the clarity of the connection, it does not provide explicit guidance on how the authors should address this concern or what specific actions they should take to improve the manuscript. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the connection between the theoretical analysis and the proposed method, specifically noting that the proposed method seems to simply adopt the selfattention mechanism from transformers and apply it to graphs without clearly explaining how it enhances generalization for distant nodes. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its critique of the connection, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the connection between the theoretical analysis and the proposed method, specifically noting that the proposed method appears to simply adopt the selfattention mechanism from transformers and apply it to graphs without clearly explaining how it enhances generalization for distant nodes. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the proposed method lacks a strong connection to the theoretical analysis. This lack of evidence makes the claim 3, as the authors may need to provide additional context or justification to address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by questioning the connection between the theoretical analysis and the proposed method. It highlights that the proposed method seems to simply adopt the selfattention mechanism from transformers and apply it to graphs without clearly explaining how it enhances generalization for distant nodes. This feedback is 3 as it points out a specific area where the authors could improve the clarity and depth of their explanation. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this issue, such as by elaborating on the theoretical underpinnings or providing additional examples. Overall, the comment is 3, as it offers a clear area for improvement but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the contribution of the work is incremental and that the proposed pipeline is not impressive or novel, consisting of a pack of tricks to improve defense evaluation. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. The comment lacks actionable steps or concrete advice, leaving the authors without a clear path to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the technical contribution of the work, suggesting that it is incremental and lacks novelty. However, it does not specify which part of the paper this critique refers to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to understand where the comment applies and what specific issues need to be addressed. Additionally, the comment is somewhat specific in its critique of the pipeline being a \"pack of tricks,\" but without clear examples or suggestions for improvement, it remains vague. Therefore, this comment is weakly grounded and somewhat specific, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the contribution of the work is incremental and that the proposed pipeline is not impressive or novel, consisting of a pack of tricks to improve defense evaluation. However, the comment lacks specific evidence or references to support this claim. It does not provide examples of similar work or detailed reasoning to substantiate the assertion that the pipeline is merely a collection of tricks. Without such evidence, the claim remains unsubstantiated and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the technical contribution of the work, suggesting that it is incremental and lacks novelty, consisting of a pack of tricks to improve defense evaluation. While the comment identifies a potential weakness in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance their work. The feedback is 3 as it highlights an area for improvement, but it lacks depth and actionable advice, making it difficult for the authors to fully understand and address the critique. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the reason for the noncentral chisquared distribution of the eta_ri term. While it identifies a potential area of confusion, it does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The comment lacks specificity and does not offer concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the reason for the noncentral chisquared distribution of the eta_ri term, but it does not specify which part of the paper this issue is discussed in. Without explicit references to sections, tables, or figures, the authors cannot confidently identify the exact location of the issue. Additionally, the comment does not provide specific details or examples to clarify why this distribution is noncentral chisquared, making it difficult for the authors to address the concern. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point questions the reason for the noncentral chisquared distribution of the eta_ri term. However, it does not provide any supporting evidence, reasoning, or references to justify why this distribution is noncentral chisquared. Without additional context or explanation, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific point of confusion regarding the noncentral chisquared distribution of the eta_ri term. While it highlights a potential area of concern, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the reasoning behind the distribution. The comment lacks depth and actionable advice, leaving the authors without a clear path forward. Therefore, it is 2, as it points out a specific area of confusion but does not offer any constructive feedback or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment provides specific feedback on the vagueness of the statement at L15, suggesting that certain RNNs work well for specific natural language reasoning tasks and providing a reference to support this claim. It also critiques the reinforcement learningagent analogy at L1618, suggesting that it is outofplace and that generalization capabilities are better illustrated by examples later in the paper. While the comment identifies areas for improvement, it does not offer explicit or concrete actions for the authors to take. The feedback is 3 as it directs the authors to clarify the vague statement and reconsider the reinforcement learningagent analogy, but it lacks detailed guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific parts of the paper, as it refers to lines 15, 1618, and later sections (229 to 253). This provides clear grounding for the authors to identify the relevant sections. The comment also specifies what needs to be addressed, such as clarifying the vagueness of the statement at L15 and reconsidering the reinforcement learningagent analogy at L1618. Additionally, it suggests that generalization capabilities are better illustrated by examples later in the paper. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point includes a claim that the statement at L15 is too vague, suggesting that certain RNNs work well for specific natural language reasoning tasks and providing a reference to support this claim. The comment also critiques the reinforcement learningagent analogy at L1618, suggesting it is outofplace and that generalization capabilities are better illustrated by examples later in the paper. The claim about the vagueness of the statement is supported by the reference to the literature on natural language inference and the SNLI leaderboard, which provides evidence for the claim. However, the critique of the reinforcement learningagent analogy lacks specific examples or detailed reasoning, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the vagueness of a statement at L15, suggesting that certain RNNs work well for specific natural language reasoning tasks and providing a reference to support this claim. It also critiques the reinforcement learningagent analogy at L1618, suggesting that it is outofplace and that generalization capabilities are better illustrated by examples later in the paper. While the comment identifies areas for improvement, it lacks detailed guidance on how the authors might address these issues or what specific changes should be made. The feedback is 3 as it directs the authors to clarify the vague statement and reconsider the reinforcement learningagent analogy, but it does not offer a comprehensive or actionable plan for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper, noting the absence of speed analysis and suggesting that comparisons of inference speed between the proposed network and prior work would be more interesting than reducing FLOPs. However, the comment does not provide explicit guidance on how the authors should conduct this analysis or what specific aspects of inference speed need to be addressed. While the action is implied, it lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment identifies a specific issue with the paper, noting the lack of speed analysis and suggesting that comparisons of inference speed between the proposed network and prior work would be more interesting than reducing FLOPs. However, it does not specify which part of the paper this issue is related to, such as a particular section or table. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper needs attention. The comment is specific in its suggestion to include speed analysis, but without grounding, it is difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks speed analysis, specifically noting the absence of comparisons of inference speed between the proposed network and prior work. It suggests that such comparisons would be more interesting than reducing FLOPs. However, the comment does not provide any evidence or reasoning to support this claim, such as examples of where such comparisons could be made or references to similar analyses in other works. Without specific justification or examples, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of speed analysis, specifically mentioning the absence of comparisons of inference speed between the proposed network and prior work. It suggests that such comparisons would be more interesting than reducing FLOPs, which implies that the authors should consider including a more comprehensive analysis of the network\"s performance. However, the comment does not provide specific guidance on how to conduct this analysis or what aspects of inference speed should be compared. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it identifies a crucial issue but does not offer comprehensive guidance for the authors to address it."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the proposed method is not wellpositioned in the literature and points out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known and used in other works, such as the original denoising score matching objective [1] and scoreinterpolation [2]. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the positioning of their method in the literature. The action is implicit and vague, as it does not specify how the authors should conduct a thorough literature review or what specific aspects of their method need to be highlighted. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and suggests a thorough literature review, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known and used in other works, such as the original denoising score matching objective [1] and scoreinterpolation [2]. This provides clear guidance on what the authors should consider in their literature review. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method is not wellpositioned in the literature and suggests that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known and used in other works, such as the original denoising score matching objective [1] and scoreinterpolation [2]. The claim is supported by providing specific examples of related work, which helps the authors understand the existing literature and how their method relates to it. However, the comment could be more robust if it included a broader range of references or a more detailed explanation of how the proposed method differs from or builds upon these existing works. Overall, the claim is 4, as it is supported by logical reasoning and specific examples, but it could be strengthened with additional references or elaboration.", "helpfulness_rationale": "The review comment identifies a significant gap in the literature positioning of the proposed method, noting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known and used in other works, such as the original denoising score matching objective [1] and scoreinterpolation [2]. This feedback is valuable as it directs the authors to conduct a thorough literature review and acknowledge the existing work that aligns with their method. However, the comment could be more helpful if it provided specific suggestions on how the authors could position their method within the existing literature or highlighted the unique contributions of their work. Despite this, the comment offers a clear direction for improvement, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare their proposed approach with a \"small learning rate for attention parameters\" benchmark. However, it does not provide explicit instructions on how to conduct this comparison or what specific aspects of the comparison should be highlighted. The action is implicit, as the authors need to infer that they should perform the comparison, but it lacks concrete guidance on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"small learning rate for attention parameters\" benchmark, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a comparison with the proposed approach, providing clear guidance on what needs to be done. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification or comparison, rather than a claim that requires verification. It does not contain any subjective opinions, logical reasoning, or references, making it a factual statement. Therefore, it should be classified as \"No\".", "helpfulness_rationale": "The review comment is 3 as it suggests a comparison with a specific benchmark, which could provide valuable insights for the authors. However, the comment lacks depth and does not offer detailed guidance on how to conduct the comparison or what aspects to focus on. While it prompts the authors to consider an additional benchmark, it does not provide a comprehensive suggestion or detailed feedback, making it 3 rather than fully helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the handling of a debate in the paper, specifically questioning why the distribution might have changed and whether experiments disentangle changes in distribution from the removal of information. It also expresses confusion about aspects that were not understood. While the comment implies that the authors should address these questions, it does not provide explicit instructions or concrete guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses specific issues raised in the paper, such as the handling of a debate and the potential reasons for changes in distribution. However, it does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the questions and concerns raised, such as why the distribution might have changed and whether experiments disentangle changes in distribution from the removal of information. This provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the handling of a debate in the paper, specifically questioning why the distribution might have changed and whether experiments disentangle changes in distribution from the removal of information. While the comment implies that the authors should address these questions, it does not provide specific examples or references to support the claim that the paper was previously careful to leave open the debate. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 2, as it lacks sufficient support to fully address the issue.", "helpfulness_rationale": "The review comment raises specific questions about the handling of a debate in the paper, particularly concerning the potential reasons for changes in distribution and whether experiments disentangle these changes from the removal of information. It also expresses confusion about aspects that were not understood. While the comment identifies areas that need clarification, it lacks detailed guidance or suggestions on how to address these issues. The feedback is 3 as it points out specific areas for improvement, but it could be more comprehensive with additional advice or examples. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. While it suggests an area for further exploration, it does not provide explicit guidance on how the authors should address this question or incorporate it into their work. The comment lacks concrete actions or suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the performance of the SOTA method (e.g., LST) combined with the adaptive metric, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its inquiry about the performance of a particular method, but it lacks detail on how this information could be integrated or utilized. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the performance of the SOTA method (e.g., LST) combined with the adaptive metric, but it does not provide any specific reasoning, examples, or references to support the claim. The comment lacks detailed justification or evidence to substantiate the inquiry, making it difficult for the authors to understand the basis of the question or how it relates to their work. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of the SOTA method (e.g., LST) combined with the adaptive metric, which could be a valuable area for further exploration. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this question or incorporate it into their work. Without actionable feedback or detailed insights, the authors may find it challenging to understand the implications of the question or how to proceed with it. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer substantial guidance or direction."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point critiques the quality of the plots, specifically mentioning that they are too small, have hardtodistinguish colors, poorly labeled axes (e.g., \"error\"), and visually similar labels. The reviewer suggests that these issues are the reason for the substandard clarity. While the comment identifies several aspects of the plots that need improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The actions are implicit and somewhat vague, as the authors would need to infer how to improve the plot\"s clarity. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the plots,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the plots, such as their size, color distinguishability, poor labeling, and visually similar labels. The comment provides clear guidance on what needs to be improved, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point critiques the quality of the plots, detailing specific issues such as their size, color distinguishability, poor labeling, and visually similar labels. These claims are supported by examples and logical reasoning, providing clear evidence for the issues. The comment is 4 as it offers specific examples and detailed descriptions of the problems, allowing the authors to understand and address the concerns effectively. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it provides specific feedback on the quality of the plots, which are a crucial part of the paper. It identifies several issues, such as the small size of the plots, the difficulty in distinguishing colors (e.g., pink vs. red), poorly labeled axes (e.g., \"error\"), and visually similar labels (e.g., sdropout(tr) vs. edropout(tr)). These observations are clear and actionable, giving the authors a clear understanding of what needs to be improved to enhance the clarity and presentation of their experimental results. The comment is detailed and provides specific examples, making it highly valuable for the authors to address and improve their work. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific observation regarding the performance gains of the proposed approach compared to a baseline. It notes that the difference in metrics between the baseline and the best approach is less than 1%, which is not considered significant. However, the comment does not provide any explicit or implicit suggestions for improvement or action. The authors are left without guidance on how to address this issue or enhance the performance of their approach. Therefore, the comment is 1, as it lacks any direction for the authors to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the performance gains and the comparison between the baseline and the best approach. It provides specific details about the metrics and the observed differences, allowing the authors to accurately identify the part of the paper being addressed. However, the comment does not specify what needs to be addressed or improved in this context, making it specific but lacking in detail. Therefore, this comment is 5, aligning with category 4.", "verifiability_rationale": "The review point claims that the performance gains are not very high, noting that the difference between the baseline and the best approach is less than 1% in most metrics. However, the comment lacks specific evidence or references to support this claim. Without additional context or data, the authors may find it difficult to assess the validity of the claim or understand its implications. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a specific observation regarding the performance gains of the proposed approach, noting that the difference between the baseline and the best approach is less than 1% in most metrics. This observation is important as it suggests that the performance improvement may not be significant enough to warrant the complexity of the proposed method. However, the comment does not provide any suggestions or guidance on how to address this issue or enhance the performance of the approach. While it identifies a potential weakness, it lacks actionable feedback, making it 3. The authors would need to infer that they should consider alternative approaches or further refine their method to achieve more substantial performance gains. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance boost due to additional parameters, specifically questioning whether a better Unary baseline might still yield a performance boost. While it identifies a potential issue with the current analysis, it does not provide explicit guidance on how to address this concern or what actions the authors should take. The comment is somewhat vague, as it leaves the authors to infer the need for further investigation or experimentation. Therefore, the comment is 3, aligning with a score of 3.", "grounding_specificity_rationale": "The comment addresses the performance boost due to additional parameters, referencing specific tables (Tab 1, 2, 3) and a baseline comparison with [14]. It questions whether a better Unary baseline might still yield a performance boost. However, the comment does not explicitly mention which part of the paper these tables or the baseline comparison are located in, making it weakly grounded. The comment is specific in detailing the issue with the performance boost and the comparison with a different neural network, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the performance boost due to additional parameters, specifically questioning whether a better Unary baseline might still yield a performance boost. It references specific tables (Tab 1, 2, 3) and a baseline comparison with [14], which provides some context for the claim. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to infer the reasoning and provide additional evidence to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the performance boost due to additional parameters, specifically questioning whether a better Unary baseline might still yield a performance boost. It references specific tables (Tab 1, 2, 3) and a baseline comparison with [14], which provides context for the concern. However, the comment does not offer detailed guidance or suggestions on how to address this issue or what experiments might be needed to clarify the performance boost. While it identifies a potential area for further investigation, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper would benefit from a more detailed discussion of related work, specifically by not only describing the related works but also discussing the differences to the presented work. This comment provides an explicit action for the authors to take, which is to expand the related work section. However, it lacks specific guidance on how to achieve this, such as suggesting particular aspects to compare or discuss. The action is clear and direct, but it is somewhat vague in terms of implementation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed discussion of related work, specifically by not only describing the related works but also discussing the differences to the presented work. However, it does not specify which part of the paper this suggestion is intended for, making it weakly grounded. The comment is specific in its suggestion to enhance the related work section, but without clear guidance on which part of the paper it should be applied to, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed discussion of related work, specifically by not only describing the related works but also discussing the differences to the presented work. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed discussion of related work, specifically by not only describing the related works but also discussing the differences to the presented work. This feedback is 3 as it identifies an area for improvement, but it lacks specific guidance on how to achieve this. The authors are left with a general idea of what to do but without detailed suggestions or examples, which limits the comment\"s impact. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments are limited to neural networks and image classification tasks and recommends exploring the performance of attacks on other architectures and classification tasks. While the comment implies that the authors should consider expanding their experiments, it does not provide explicit guidance on which specific architectures or tasks to include. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments are limited to neural networks and image classification tasks and recommends exploring the performance of attacks on other architectures and classification tasks. However, it does not specify which parts of the paper these experiments are discussed or how they relate to the overall content. The authors cannot confidently determine which sections or figures are being addressed, making the comment weakly grounded. Additionally, while it suggests exploring other tasks, it does not provide specific examples or guidance on which tasks to consider, making the comment specific but not fully specific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments are limited to neural networks and image classification tasks and recommends exploring the performance of attacks on other architectures and classification tasks. However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is valuable or how it could enhance the paper. Without additional context or justification, the claim lacks sufficient support, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the experiments conducted in the paper, noting that they are limited to neural networks and image classification tasks. It suggests that exploring the performance of attacks on other architectures and classification tasks would be interesting and could enhance the paper\"s impact. While the comment highlights a potential area for improvement, it does not provide specific guidance on which architectures or tasks to consider, nor does it offer suggestions on how to approach this expansion. The feedback is 3 as it points out a potential avenue for future work but lacks depth and actionable advice, making it a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the output of the algorithm depends on the order of data processing and suggests that this dependency should be clarified. While the comment explicitly states the issue, it does not provide specific guidance on how to clarify this dependency or what aspects of the algorithm or data processing need to be addressed. The action is clear but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the output of the algorithm depends on the order of data processing and recommends clarifying this dependency. However, it does not specify which part of the paper discusses the algorithm or the data processing order, making it weakly grounded. The comment is specific in identifying the issue that needs clarification, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the output of the algorithm depends on the order in which the data are processed and suggests that this dependency should be clarified. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand why this dependency is important or how it should be addressed. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the algorithm\"s output dependency on the order of data processing, suggesting that this dependency should be clarified. While the comment highlights a specific area that needs attention, it lacks detailed guidance or suggestions on how to address this issue. The authors are informed about a potential problem but are not provided with actionable steps or examples to improve the clarity of the algorithm or data processing. Therefore, the comment is 3, as it points out a specific area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the importance of the sampling method for convergence to the optimum but notes that this aspect is not experimentally evaluated beyond a comparison to sampling from a uniform distribution in Table 1 of the supplementary material. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how to conduct a more thorough experimental evaluation or what specific aspects of the sampling method should be explored. The action is implicit and somewhat vague, as the authors are left to infer how to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the importance of the sampling method for convergence to the optimum, noting that it is not experimentally evaluated carefully on the proposed benchmarks, except for a comparison to sampling from a uniform distribution in Table 1 of the supplementary material. However, the comment does not specify which part of the paper discusses the sampling method or the benchmarks used, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issue of sampling, it lacks grounding as it does not provide clear references or guidance on where to focus the authors. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the sampling method is important for convergence to the optimum but notes that it is not experimentally evaluated carefully on the proposed benchmarks, except for a comparison to sampling from a uniform distribution in Table 1 of the supplementary material. However, the comment lacks specific details or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains 3, as it is based on an observation that could be further substantiated with more detailed analysis or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental evaluation of the sampling method, noting that it is only compared to sampling from a uniform distribution in Table 1 of the supplementary material. This observation highlights a gap in the experimental evaluation, as the sampling method\"s importance for convergence to the optimum is not thoroughly explored. However, the comment does not provide specific guidance or suggestions on how to address this issue or what additional experiments could be conducted to strengthen the evaluation. While it points out a potential area for improvement, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its relation to [9] and [16]. It questions the rationale behind the order of comparisons and the focus on computational cost with [9] while omitting [16]. The comment implies that the authors should provide a clearer explanation of the logic and comparisons, but it does not offer specific guidance on how to address these issues. The feedback is 3 as it identifies areas for improvement, but it lacks concrete suggestions or detailed guidance on how to implement the changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the logic and comparisons between the proposed method and specific references [9] and [16]. It also questions the rationale behind the order of comparisons and the focus on computational cost with [9] while omitting [16]. However, the comment does not specify which part of the paper these questions relate to, making it weakly grounded. The comment is specific in detailing the issues with the comparisons and the focus on computational cost, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its relation to [9] and [16]. It questions the rationale behind the order of comparisons and the focus on computational cost with [9] while omitting [16]. However, the comment does not provide any specific reasoning, examples, or references to support the claims made, leaving the authors to infer the validity of the feedback. This lack of detailed justification makes the claim 3, as the authors would need to rely on their own judgment to understand the issues. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its relation to [9] and [16]. It questions the rationale behind the order of comparisons and the focus on computational cost with [9] while omitting [16]. This feedback highlights areas where the authors could improve the clarity and comprehensiveness of their comparisons and discussions. However, the comment lacks specific guidance or suggestions on how to address these issues, making it 3. The authors would need to infer the need for additional explanations and discussions to improve the paper\"s clarity and coherence. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should explore how their model works with tabular data, noting that it is another form of multimodal data. However, it does not provide explicit instructions or concrete guidance on how to implement this suggestion. The action is implicit, as the authors need to infer that they should conduct experiments or analysis to understand the model\"s performance on tabular data. The lack of detailed guidance on how to approach this exploration makes the comment 3. Therefore, this comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment suggests exploring the use of tabular data as another form of multimodal data, which is an interesting idea. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to explore the model\"s performance on tabular data, but without a clear reference to a specific section or figure, the authors may find it challenging to understand where to focus their attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that tabular data is another form of multimodal data and proposes exploring how the model works with it. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should explore how their model performs with tabular data, noting that it is another form of multimodal data. While the comment identifies an interesting avenue for further investigation, it lacks specific guidance or suggestions on how to approach this exploration. The authors are left with a vague idea of what to do, which limits the comment\"s helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more details on using attention would be beneficial, potentially as an extra appendix. While the comment implies that additional information is needed, it does not explicitly instruct the authors to provide these details or specify how they should be presented. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the use of attention. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that more details on using attention would be useful, potentially as an extra appendix. However, it does not specify which part of the paper discusses attention or where these additional details should be included. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in suggesting the inclusion of more details, but it lacks specificity in terms of what those details should include or how they should be presented. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details on using attention would be useful, potentially as an extra appendix. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that more details on using attention would be beneficial, potentially as an extra appendix. While this feedback provides a clear direction for improvement, it lacks specificity regarding the nature of the additional details or how they should be presented. The comment is 3 as it identifies a potential area for enhancement, but it does not offer detailed guidance or suggestions for what specific aspects of attention should be elaborated upon. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind showing results only on images corrupted with Gaussian noise, despite the paper mentioning the model\"s ability to handle various image noise types. While the comment implies that the authors should provide a reason for this limitation, it does not explicitly instruct them to do so or suggest how to address it. The action is implicit, as the authors need to infer that they should explain the choice of Gaussian noise. However, the comment lacks concrete guidance on how to provide this explanation or what aspects to consider. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the rationale behind showing results only on images corrupted with Gaussian noise, despite the paper mentioning the model\"s ability to handle various image noise types. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact area where the clarification is needed. While the comment is specific in its request for an explanation, the absence of explicit grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the rationale behind showing results only on images corrupted with Gaussian noise, despite the paper mentioning the model\"s ability to handle various image noise types. However, the comment does not provide any specific reasoning or evidence to support why Gaussian noise was chosen over other types. It lacks detailed justification or examples, making it difficult for the authors to understand the basis of the question. As a result, the claim is not verifiable, aligning with a score of 1.", "helpfulness_rationale": "The review comment raises a valid question about the rationale behind showing results only on images corrupted with Gaussian noise, despite the paper mentioning the model\"s ability to handle various image noise types. This feedback highlights a potential gap in the experimental validation, as it does not provide a clear explanation for the choice of noise type. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or expand their experiments to include other noise types. While it identifies an area for improvement, the feedback is somewhat limited in its scope and does not offer detailed guidance on how to enhance the paper. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the empirical version of the objective (3) could be moved to the supplementary materials. This is an explicit action that the authors can take to improve their draft. The comment provides a clear and concrete instruction on where to place the objective, making it actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests moving the empirical version of the objective (3) to the supplementary materials. However, it does not specify which part of the paper this objective is located in, making it difficult for the authors to identify the exact section to address. While the comment is specific about the content to be moved, the lack of grounding makes it challenging for the authors to understand the context and relevance of the suggestion. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the empirical version of the objective (3) might be appropriate to put in the supplementary materials. This is a suggestion for improvement, but it lacks specific reasoning or justification for why this placement would be beneficial. Without additional context or explanation, the authors may find it challenging to understand the rationale behind this suggestion. Therefore, the comment is considered 2, as it provides some guidance but lacks sufficient detail to be fully convincing.", "helpfulness_rationale": "The review comment suggests that the empirical version of the objective (3) could be moved to the supplementary materials. This is a specific and actionable suggestion that provides a clear direction for improving the organization of the paper. By moving the objective to the supplementary materials, the authors can potentially enhance the clarity and focus of the main body of the paper. However, the comment could be more helpful if it provided additional context or reasoning for why this placement would be beneficial. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific claim about Corollary 10, stating that it only shows that uncertainty sampling moves in descent directions of the expected 01 loss, which does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. This comment provides a clear and explicit action for the authors to consider, as it questions the interpretation of the results presented in Corollary 10. However, it does not offer specific guidance on how to address this issue or what changes might be needed in the draft. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ln. 180182,\" which allows the authors to accurately identify the specific part of the paper being addressed. It also specifies what the issue is: that Corollary 10 only shows uncertainty sampling moving in descent directions of the expected 01 loss, which does not necessarily mean it is minimizing the expected convex surrogate. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Corollary 10 only shows that uncertainty sampling moves in descent directions of the expected 01 loss, which does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. This claim is based on a logical reasoning argument, as it highlights a potential misinterpretation of the results presented in Corollary 10. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would benefit from additional context or examples to fully understand the implications of this critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Corollary 10, noting that it only demonstrates that uncertainty sampling moves in descent directions of the expected 01 loss, which does not necessarily imply that it is minimizing the expected convex surrogate. This feedback is clear and actionable, as it points out a potential misinterpretation of the results and suggests that the authors should consider this nuance in their analysis or discussion. However, the comment could be more helpful if it provided additional context or suggestions for how the authors might address this issue. Overall, the comment is 3, as it provides a clear direction for improvement but lacks depth in terms of actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should provide details about the division of the dataset into training and testing sets, including the numbers used and the method of division. It specifies that the division should be clearly explained, addressing whether it was random or based on other considerations. This provides a clear and concrete action for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for details about the division of the dataset into training and testing sets, which is a specific part of the paper. It specifies what information is missing, including the numbers used and the method of division, such as whether it was random or based on other considerations. This provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point is a request for additional information regarding the division of the dataset into training and testing sets. It does not contain a subjective opinion or claim that requires verification. The comment is factual and descriptive, aligning with the \"No\" category.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on a critical aspect of the paper. It highlights the importance of including details about the division of the dataset into training and testing sets, including the numbers used and the method of division. This feedback is clear and directly addresses a potential weakness in the paper, guiding the authors to improve the transparency and reproducibility of their work. The comment is detailed and provides a clear path for the authors to enhance their draft, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the testing of the model on other tasks within the bAbI dataset. It does not provide an explicit action or suggestion for the authors to take, such as testing on additional tasks or providing results for those tasks. The comment is vague and lacks concrete guidance on how the authors might address this issue. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the testing of the model on other tasks within the bAbI dataset, specifically mentioning that it was only tested on Task 1. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific about the issue, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the testing of the model on other tasks within the bAbI dataset, specifically mentioning that it was only tested on Task 1. However, it does not provide any evidence, reasoning, or references to support why this is a concern or what implications it might have. The comment lacks specific details or justification, making it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the testing of the model on other tasks within the bAbI dataset, specifically noting that it was only tested on Task 1. This feedback highlights a potential limitation in the evaluation of the model\"s capabilities, as it suggests that the model\"s performance might be more robust if tested on additional tasks. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as testing on other tasks or providing results for those tasks. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that the dataset used in the experiments is small and suggests that results on medium or large datasets, such as ImageNet, would be more convincing. However, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take to improve their draft. The comment is vague and lacks concrete details, making it difficult for the authors to understand how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of the dataset used in the experiments being small, suggesting that results on medium or large datasets, such as ImageNet, would be more convincing. However, it does not specify which part of the paper discusses the dataset or the experiments, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its suggestion but lacks grounding as it does not provide clear guidance on which part of the paper to focus on. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the dataset used in the experiments is small and suggests that results on medium or large datasets, such as ImageNet, would be more convincing. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the dataset used in the experiments, noting that they are all very small. It suggests that including results on medium or large datasets, such as ImageNet, would make the findings more convincing. However, the comment does not provide specific guidance on how to address this issue or what changes might be necessary to improve the draft. While it highlights a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide empirical justification for their claim that the proposed algorithm does not take as many points or does not need apriori knowledge about dimensions of subspaces. However, the comment does not specify how this justification should be presented or what kind of empirical evidence would be most effective. The action is implicit, as the authors need to infer that they should include empirical evidence to support their claim. While the action is somewhat vague, it is clear that the authors need to address this aspect of their paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first claimed contribution of the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the authors should provide empirical justification for the claim that the proposed algorithm does not take as many points or does not need apriori knowledge about dimensions of subspaces. This provides a clear direction for the authors to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper should provide empirical justification for the claim that the proposed algorithm does not take as many points or does not need apriori knowledge about dimensions of subspaces. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific aspect of the paper that could be improved by providing empirical justification for the claim that the proposed algorithm does not take as many points or does not need apriori knowledge about dimensions of subspaces. This feedback is clear and actionable, as it directs the authors to strengthen their claims with empirical evidence. However, the comment could be more helpful if it provided guidance on how to conduct or present this empirical justification. Despite this, the feedback is 4 as it offers a clear direction for improvement, allowing the authors to enhance the rigor and persuasiveness of their paper."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include a comparison of their approach with other LLMs, specifically mentioning the potential for crafting adversarial prompts and transferring them. This provides a clear and explicit action for the authors to take, as they can directly incorporate this comparison into their work. However, the comment does not specify how to implement this comparison or what aspects of the comparison should be included, making it 3. The minor point about the low jailbreaking percentage is not actionable as it does not provide guidance on how to address this issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including a comparison of the GCG approach with other LLMs, specifically mentioning the potential for crafting adversarial prompts and transferring them. This provides a clear direction for the authors to address a specific aspect of their work. However, the comment does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting the inclusion of a comparison, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors should include a comparison of their approach with other LLMs, specifically mentioning the potential for crafting adversarial prompts and transferring them. This claim is 3 as it suggests a logical extension of the work, but it lacks specific examples or references to support the suggestion. The comment does not provide detailed reasoning or evidence to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment suggests that the authors should include a comparison of their approach with other LLMs, specifically mentioning the potential for crafting adversarial prompts and transferring them. This feedback is 3 as it provides a clear direction for the authors to enhance their work by expanding the scope of their analysis. However, the comment lacks specific guidance on how to implement this comparison or what aspects of the comparison should be included, which limits its impact. Additionally, the comment does not address the minor point about the low jailbreaking percentage, which could be a valuable addition to the feedback. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the unified framework in handling different types of POMDP formulations, specifically continuous or infinite spaces. It does not provide explicit instructions or suggestions on how the authors should address this question or what changes might be needed in their draft. The comment is vague and lacks concrete guidance, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitations of a unified framework in handling different types of POMDP formulations, specifically continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is specific in its inquiry about the limitations of the framework, but it lacks grounding as it does not provide clear references or context within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitations of a unified framework in handling different types of POMDP formulations, specifically continuous or infinite spaces. However, it does not provide any specific evidence, reasoning, or references to support the claim that the framework might not be applicable to these formulations. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the limitations of a unified framework in handling different types of POMDP formulations, specifically continuous or infinite spaces. This question is relevant as it challenges the authors to consider the scope and applicability of their framework. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this limitation or expand their work. While it identifies an important area for consideration, it does not offer actionable advice or insights that would significantly enhance the authors\" draft. Therefore, the comment is 3, as it highlights a potential area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the dataset created by the authors is optional and recommends using the Kialo dataset, which is wellstudied and cleaner. However, it does not provide explicit guidance on how the authors should implement this suggestion or what specific actions they should take to incorporate the Kialo dataset into their work. The comment implies that the authors should consider using the Kialo dataset as an additional resource, but it lacks concrete steps or details on how to do so. Therefore, the comment is 3, as it provides a clear direction but lacks specific guidance on implementation.", "grounding_specificity_rationale": "The comment suggests that the dataset creation process is optional and recommends using the Kialo dataset, which is wellstudied and cleaner. However, it does not specify which part of the paper discusses the dataset creation or how the authors should address this suggestion. The comment lacks grounding as it does not provide clear references to specific sections or parts of the paper, making it difficult for the authors to identify the exact area that needs attention. Additionally, the comment is specific in its recommendation to use the Kialo dataset, but without grounding, it is challenging for the authors to understand how to apply this suggestion. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the dataset creation process is optional and recommends using the Kialo dataset, which is wellstudied and cleaner. However, the comment lacks specific examples or references to support the claim that the Kialo dataset is indeed cleaner or more suitable for the authors\" needs. Without detailed reasoning or evidence, the claim remains 3, as the authors may need to conduct further research or analysis to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the dataset creation process is optional and recommends using the Kialo dataset, which is wellstudied and cleaner. It provides a specific recommendation for the authors to consider using the Kialo dataset as an additional resource. However, the comment lacks detailed guidance on how the authors should implement this suggestion or what specific steps they should take to incorporate the Kialo dataset into their work. While it offers a valuable insight, the feedback could be more helpful if it included actionable steps or examples of how to use the dataset effectively. Therefore, the comment is 3, as it provides a direction but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the limited number of tasks in the experiments and suggests that the authors should include at least 10 tasks. It also requests sequential results in terms of tasks learned rather than epochs. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes they should make to their draft. While the authors can infer that they need to expand their experiments and provide sequential results, the lack of concrete instructions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses concerns about the number of tasks in the experiments, suggesting that the authors should include at least 10 tasks and provide sequential results in terms of tasks learned rather than epochs. However, the comment does not specify which part of the paper discusses the experiments or tasks, making it weakly grounded. It is specific in detailing the issue with the number of tasks and the desired format of the results. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the limited number of tasks in the experiments and suggests that the authors should include at least 10 tasks and provide sequential results in terms of tasks learned rather than epochs. However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is necessary or beneficial. The lack of justification makes it difficult for the authors to understand the basis of the claim and how it relates to the paper\"s content. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experimental setup, specifically the limited number of tasks used. It suggests that the authors should include at least 10 tasks and provide sequential results in terms of tasks learned rather than epochs. This feedback is 3 as it highlights an area for improvement and provides a clear direction for the authors to consider. However, the comment lacks depth and does not offer specific guidance on how to address the issue or what changes might be necessary. The authors would need to infer the exact steps to take, which limits the comment\"s helpfulness. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. While the comment identifies a potential gap in the reasoning, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the analysis need clarification. The action is implicit, as the authors would need to infer that they should provide a clearer explanation for their analysis choice. However, the comment lacks concrete details on how to implement this suggestion, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its question about the motivation, the absence of explicit grounding makes it challenging for the authors to understand which part of the paper to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. This is a valid question that requires the authors to provide a clear rationale for their analysis choice. However, the comment does not offer any specific examples, references, or detailed reasoning to support the claim that numerosity might not appear in earlier layers. Without additional context or evidence, the authors may find it challenging to fully understand and address the question. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a valid question about the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. This question highlights a potential gap in the reasoning or explanation provided in the paper, prompting the authors to clarify their analysis choices. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or improve their analysis. While it identifies an area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the parameter S, suggesting that it remains a problem. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address this issue or what steps should be taken to resolve it. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the parameter S, suggesting that it remains a problem. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Additionally, the comment does not provide specific guidance or suggestions on how to address the problem with parameter S. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the parameter S, suggesting that it remains a problem. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or explanation, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the parameter S, suggesting that it remains a problem. However, it does not provide any specific guidance or suggestions on how to address this issue or what steps the authors should take to resolve it. The comment lacks depth and actionable advice, leaving the authors without a clear path forward to improve their draft. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point critiques the claim in the introduction that \"these shape constraints do not require tuning a free parameter.\" It argues that while technically true, the choice of employing a convex or concave constraint, or an increasing/decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback provides a clear and explicit action for the authors to consider, as it highlights a potential oversight in the introduction. The comment is specific in identifying the issue with the claim and suggests a more nuanced perspective on the constraints. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment critiques the claim in the introduction that \"these shape constraints do not require tuning a free parameter.\" It argues that while technically true, the choice of employing a convex or concave constraint, or an increasing/decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback is fully grounded as it explicitly mentions the part of the paper being addressed, the introduction. It is also specific because it clearly specifies what needs to be addressed, namely the potential oversight in the introduction regarding the choice of constraints as a hyperparameter. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the claim in the introduction that \"these shape constraints do not require tuning a free parameter.\" It argues that while technically true, the choice of employing a convex or concave constraint, or an increasing/decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback is 4 as it provides a logical reasoning for the critique, explaining why the initial claim might be an oversimplification. However, it could be strengthened by providing specific examples or references to support the claim that these choices can be considered hyperparameters. Overall, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment critiques the claim in the introduction that \"these shape constraints do not require tuning a free parameter.\" It argues that while technically true, the choice of employing a convex or concave constraint, or an increasing/decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback is clear and actionable, as it identifies a potential oversight in the introduction and suggests a more nuanced perspective on the constraints. By highlighting this point, the comment provides the authors with a specific area to consider and improve their understanding of the constraints. Therefore, the comment is 5, as it offers valuable insights and guidance for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several limitations in the paper, specifically regarding the limited scope of bias benchmarks and the absence of assessments on stateoftheart generative models. It points out that the current benchmarks only assess gender, race, and religion, and suggests that other important biases and datasets should be included. However, the comment does not provide explicit guidance on how the authors should address these limitations or what specific steps they should take to expand their analysis. While the authors can infer that they need to include more diverse biases and datasets, and consider evaluating stateoftheart generative models, the lack of concrete suggestions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitations of the bias benchmarks used in the paper, specifically noting that they only assess gender, race, and religion. It also points out the absence of assessments on other important biases and datasets, as well as the lack of evaluation on stateoftheart generative models like GPT. However, the comment does not specify which part of the paper discusses the bias benchmarks or the datasets used, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as expanding the scope of bias benchmarks and including evaluations on stateoftheart models. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are missing. It also notes the absence of assessments on stateoftheart generative models like GPT. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to verify the accuracy of the critique. Without detailed evidence or examples, the claim remains 3, as the authors may need to conduct further research to confirm the extent of the limitations. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper by pointing out the limited scope of bias benchmarks, which only assess gender, race, and religion. It also highlights the absence of assessments on other important biases and datasets, as well as the lack of evaluation on stateoftheart generative models like GPT. This feedback is valuable as it directs the authors to expand the scope of their analysis and include more comprehensive evaluations. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address these limitations, such as recommending additional datasets or models to consider. Overall, the comment is 4 as it identifies key areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights specific issues with Figure 3, such as the difficulty in understanding the workflow and captions, and the confusion in representing communication modes on the left side. While the comment identifies areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should clarify the workflow and captions and improve the representation of communication modes. However, the lack of specific suggestions or actionable steps makes the comment somewhat vague and leaves the authors with limited direction on how to improve the figure. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as the difficulty in understanding the workflow and captions, and the confusion in representing communication modes. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 3 is challenging to understand due to unclear workflow and captions, as well as confusing representation of communication modes. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it difficult to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that it is challenging to understand due to unclear workflow and captions, as well as confusing representation of communication modes. This feedback is clear and actionable, as it provides the authors with specific areas to improve the figure. However, the comment could be more helpful if it offered suggestions on how to clarify the figure or improve its presentation. Despite this, the feedback is 4 as it directs the authors to areas that need attention, allowing them to make meaningful improvements to their draft. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. The comment also suggests that error analysis will aid in guiding subsequent improvements and expansions of the ERC research. However, it does not explicitly instruct the authors on how to conduct the error analysis or what specific aspects of the model\"s performance should be analyzed. While the action is implied, it lacks concrete details on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that error analysis is crucial for evaluating model performance and identifying potential issues, and it encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. However, the comment does not specify which part of the paper should be addressed for this analysis, making it weakly grounded. It is specific in suggesting the need for error analysis and detailed explanations, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas to focus on. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the suggestion. The reasoning is somewhat vague, and the claim is not 5 without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights the importance of error analysis in evaluating model performance and suggests that the authors should conduct it to identify potential issues. It encourages the authors to provide detailed explanations of the model\"s performance under different scenarios, which could guide subsequent improvements and expansions of the ERC research. While the comment identifies a key area for improvement, it lacks specific guidance on how to conduct the error analysis or what aspects of the model\"s performance should be analyzed. This makes the feedback 3, as it provides a direction for improvement but could be more comprehensive with additional details. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. It points out that the authors do not provide any evidence or explanation of how their approach is NLPspecific. This feedback is implicit, as the authors need to infer that they need to clarify the NLPspecific aspects of their approach. However, the action is vague because it does not provide specific guidance on what needs to be added or how to demonstrate the NLPspecificity of their approach. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the authors\" claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. However, it does not specify which part of the paper this claim is made or which sections or figures might contain this information. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific details about what aspects of the approach are NLPspecific, leaving the authors uncertain about how to address the feedback. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the authors\" claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. However, it does not provide any specific evidence or reasoning to support this claim, nor does it offer examples or references to substantiate the assertion. Without detailed justification or supporting evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the authors\" claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. It points out that the authors do not provide any evidence or explanation of how their approach is NLPspecific. This feedback is 3 as it highlights a potential gap in the authors\" claim and encourages them to clarify the NLPspecific aspects of their approach. However, the comment lacks specific guidance on how to address this issue or what evidence should be provided to support their claim. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that at least one NCEbased method should be included for comparison, referencing a specific paper that demonstrates the possibility of learning an EnergyBased Model (EBM) on natural images with a strong noise distribution. However, the comment does not provide explicit guidance on how to incorporate this method or what specific aspects of the comparison should be highlighted. The action is implicit, as the authors would need to infer that they should include a comparison with a NCEbased method and potentially discuss the findings of the referenced paper. The lack of concrete details makes the action somewhat vague, aligning with a score of 3.", "grounding_specificity_rationale": "The comment suggests including at least one NCEbased method for comparison, referencing a specific paper that demonstrates the possibility of learning an EnergyBased Model (EBM) on natural images with a strong noise distribution. However, the comment does not specify which part of the paper this suggestion relates to, such as a specific section or methodology. This makes it difficult for the authors to pinpoint the exact area where the suggestion should be addressed. While the suggestion is specific about the type of method to include, the lack of grounding makes it challenging for the authors to understand how to apply it. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that at least one NCEbased method should be included for comparison, referencing a specific paper that demonstrates the possibility of learning an EnergyBased Model (EBM) on natural images with a strong noise distribution. However, the comment lacks specific details or examples to support the claim, making it difficult for the authors to understand the basis of the suggestion or how to incorporate it into their work. The absence of clear reasoning or references makes the claim 3, as it provides a general direction but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that at least one NCEbased method should be included for comparison, referencing a specific paper that demonstrates the possibility of learning an EnergyBased Model (EBM) on natural images with a strong noise distribution. This feedback is 3 as it identifies a potential area for improvement by suggesting a relevant comparison method. However, the comment lacks depth and does not provide specific guidance on how to incorporate this method or what aspects of the comparison should be highlighted. The suggestion is clear but could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiment section could be improved by carrying out significance tests on the human evaluation results and comparing the proposed method with some recent LLMs. While the comment provides explicit actions\u2014carrying out significance tests and comparing with recent LLMs\u2014it does not specify how these actions should be implemented or what data should be used for the significance tests. The lack of detail makes the action somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests improvements to the experiment section, specifically mentioning the need to carry out significance tests on human evaluation results and to compare the proposed method with recent LLMs. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestions, as it provides clear directions for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiment section could be improved by carrying out significance tests on human evaluation results and comparing the proposed method with recent LLMs. However, the comment lacks specific details or references to support these suggestions, such as which significance tests should be used or which specific recent LLMs should be compared against. Without these details, the claim is 3, as the authors may need to infer the necessary information to address the feedback effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests improvements to the experiment section, specifically recommending the inclusion of significance tests on human evaluation results and comparisons with recent LLMs. This feedback is clear and actionable, providing the authors with specific areas for enhancement. However, it could be more helpful if it included details on which significance tests to use or which specific LLMs to compare against. Despite this, the comment offers valuable guidance that can significantly improve the draft, making it 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the fairness of the comparison with stateoftheart (SOTA) methods due to the use of a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method might be attributed to the larger dataset size, which significantly impacts accuracy. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to ensure a fair comparison. The action is implicit and vague, as it does not specify how the authors should adjust their comparison or what additional experiments might be needed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the fairness of the comparison with stateoftheart methods due to the use of a newly collected 209M dataset, while existing methods use smaller datasets. It provides an example of a method, GEM, which employs only 20M unlabeled data. However, the comment does not specify which part of the paper this issue is related to, such as the experimental setup or results section. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific about the issue of dataset size affecting performance, it does not provide detailed guidance on how to address this concern. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the fairness of the comparison with stateoftheart methods due to the use of a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer provides an example of a method, GEM, which employs only 20M unlabeled data, suggesting that the superior performance of the proposed method might be attributed to the larger dataset size. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. It does not provide references or logical arguments to support the assertion that the dataset size significantly impacts accuracy. As a result, the claim is 3, as it is based on a logical argument but lacks sufficient evidence or references to fully substantiate the concern.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of the comparison with stateoftheart methods due to the use of a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer provides an example of a method, GEM, which employs only 20M unlabeled data, suggesting that the superior performance of the proposed method might be attributed to the larger dataset size. This feedback highlights a potential issue with the experimental setup and encourages the authors to consider the impact of dataset size on accuracy. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors could address this issue, such as conducting additional experiments with smaller datasets or comparing their method with others using similar datasets. Overall, the comment is 3 as it identifies a potential weakness but lacks detailed actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the generalizability of the specific examples of biases and prediction shifts presented in the paper. It points out that while the paper demonstrates these biases, it does not explain how common or general these situations are. However, the comment does not provide explicit guidance on how the authors should address this issue or what actions they should take to clarify the generalizability of their findings. The action is implicit and vague, as it does not specify how the authors can improve the clarity or provide more context on the generalizability of the examples. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the clarity of the paper, particularly concerning the generalizability of the specific examples of biases and prediction shifts presented in section 3.2 and Theorem 1. It highlights that while the paper demonstrates these biases, it does not explain how common or general these situations are. This provides clear guidance on what needs to be addressed, making the comment fully grounded. The specificity is also high as it specifies the exact parts of the paper where the issue is raised, allowing the authors to understand the exact areas that need improvement. Therefore, this comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the generalizability of the specific examples of biases and prediction shifts presented in the paper. It suggests that while the paper demonstrates these biases, it does not explain how common or general these situations are. However, the comment lacks specific examples or references to support the claim that the authors are unsure about the generalizability of these situations. Without additional context or evidence, the claim remains 3, as it is based on an observation without detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the generalizability of the specific examples of biases and prediction shifts presented in section 3.2 and Theorem 1. It points out that while the paper demonstrates these biases, it does not explain how common or general these situations are, leaving the authors unsure about the scope of these findings. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or clarify the generalizability of their examples. Without specific recommendations or detailed feedback on how to improve the clarity or provide more context, the comment is 3 as it highlights an important area for improvement but does not offer a comprehensive solution. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether the authors have made any additional novel effort in the Sec. 3.1 for 3D Gaussians generation, noting that it seems to follow the previous work, Luciddreamer. While the comment implies that the authors should clarify the novelty of their approach, it does not explicitly instruct them to provide evidence or details about any additional contributions. The action is implicit and somewhat vague, as the authors are left to infer that they need to address the novelty of their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions whether the Sec. 3.1 for 3D Gaussians generation follows the previous work, Luciddreamer, and asks for clarification on any additional novel effort. However, it does not specify which part of the paper Sec. 3.1 corresponds to, making it difficult for the authors to pinpoint the exact section being addressed. The comment is specific in its request for clarification regarding novelty, but the lack of grounding makes it challenging for the authors to understand which part of the paper needs attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions whether the Sec. 3.1 for 3D Gaussians generation follows the previous work, Luciddreamer, and asks for clarification on any additional novel effort. While the comment implies that the authors should address the novelty of their approach, it does not provide specific examples, references, or detailed reasoning to support the claim. The lack of explicit evidence or justification makes the claim 3, as the authors are left to infer the basis of the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the novelty of the Sec. 3.1 for 3D Gaussians generation, noting that it appears to follow the previous work, Luciddreamer. While the comment identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it prompts the authors to consider the novelty of their approach, but it lacks actionable advice or detailed insights that would guide them in improving their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the first paragraph of the Introduction is devoted to a general introduction of DNNs and lacks any mention of drift. It suggests that this paragraph is not central to the paper\"s focus on detecting drift types and magnitude, and that it provides little valuable information. This feedback is clear and specific, as it identifies a specific part of the paper that needs revision and provides a clear rationale for why it is not relevant to the paper\"s core focus. The authors can directly infer that they should either remove or reframe this paragraph to align with the paper\"s main contribution. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the first paragraph of the Introduction, providing full grounding as the authors can accurately identify the section being addressed. It also specifies the issue with this paragraph, noting that it is devoted to a general introduction of DNNs without mentioning drift, which is central to the paper\"s focus. This level of detail allows the authors to understand exactly what part of the paper needs revision and what specific issue needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first paragraph of the Introduction is devoted to a general introduction of DNNs without mentioning drift, which is central to the paper\"s focus on detecting drift types and magnitude. The comment suggests that this paragraph provides little valuable information to readers. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. Without detailed reasoning or examples, the claim is 3, as it provides a basis for improvement but lacks the depth needed for full validation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction section, noting that it is devoted to a general introduction of DNNs without mentioning drift, which is central to the paper\"s focus. This feedback is clear and actionable, as it directs the authors to reconsider the relevance of the DNN introduction to their core contribution. By highlighting the lack of focus on drift, the comment provides a clear suggestion for improvement, encouraging the authors to either remove or reframe the paragraph to align with the paper\"s main focus. This level of guidance is 4, as it offers a clear direction for enhancing the draft, though it could be further detailed to provide more specific advice. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a simplified version of Theorem 2 could be presented for the general audience, as it is currently difficult to understand. However, it does not provide explicit guidance on how to simplify the theorem or what aspects should be emphasized. The action is implicit, as the authors would need to infer that they should simplify the theorem and explain it more clearly. The comment lacks concrete details on how to achieve this simplification, making it 3.", "grounding_specificity_rationale": "The comment suggests that a simplified version of Theorem 2 could be presented for the general audience, noting that it is currently difficult to understand. However, it does not specify which part of the paper this comment is referring to, such as a particular section or figure. The comment is specific in its suggestion to simplify the theorem, but it lacks grounding as the authors cannot confidently determine which part of the paper it addresses. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that a simplified version of Theorem 2 could be presented for the general audience, as it is currently difficult to understand. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of Theorem 2, suggesting that it might be difficult for the general audience to understand. It proposes that a simplified version of the theorem could be presented to enhance clarity. However, the comment lacks specific guidance on how to simplify the theorem or what aspects should be emphasized. While it points out a potential area for improvement, it does not provide actionable advice or detailed suggestions, making it 3. The authors would need to infer that they should simplify the theorem and explain it more clearly, but the comment does not offer concrete steps to achieve this. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should conduct experiments using a larger resolution than 224*224. While it implies an action, it does not provide explicit guidance on how to implement this suggestion or what specific changes should be made to the draft. The action is implicit and vague, as it does not specify which parts of the draft need to be updated or how the larger resolution experiments should be conducted. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests conducting experiments with a larger resolution, which is a specific aspect of the methodology. However, it does not explicitly mention which part of the paper this suggestion relates to, such as the experimental setup or results section. This makes it weakly grounded, as the authors may need to infer which part is being addressed. The comment is specific in its suggestion to use a larger resolution, but the lack of explicit grounding makes it difficult for the authors to focus their attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests conducting experiments with a larger resolution, which is a logical and straightforward suggestion. However, it lacks specific details or references to support why this change would be beneficial or how it might impact the results. Without additional context or evidence, the claim is 3, as it provides a reasonable suggestion but lacks depth and support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests conducting experiments with a larger resolution, which is a logical and interesting idea. However, it lacks specific guidance on how to implement this suggestion or what impact it might have on the results. The comment is 3 as it identifies a potential area for improvement but does not provide detailed feedback or actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. This is a specific and explicit action that the authors can take to improve their draft. By adding this detail, the authors can provide more context and clarity regarding the behavior of the algorithms. The comment is clear and concrete, allowing the authors to understand exactly what needs to be added. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section or context. The comment is specific in its suggestion but lacks grounding as it does not provide enough information for the authors to pinpoint the relevant part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this suggestion is important or how it relates to the paper\"s content. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. This is a specific and actionable suggestion that could enhance the clarity and completeness of the paper. By providing this additional detail, the authors can offer more context and improve the understanding of their work. However, the comment could be more helpful if it included more context or examples of why this detail is important. Overall, the comment is 3 as it provides a clear direction for improvement, but it could be more comprehensive to fully assist the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that additional experiments on larger datasets would be beneficial, but acknowledges that computational resources might be a constraint. It also expresses a preference for maintaining probabilities, particularly at large batch sizes, but deems this aspect not critical. The comment is explicit in suggesting additional experiments, which provides a clear action for the authors to take. However, it lacks specific guidance on which datasets or types of experiments to conduct, making it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests additional experiments on larger datasets, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper these experiments relate to, making it weakly grounded. The comment is specific in suggesting that maintaining probabilities might become an issue at large batch sizes, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that additional experiments on larger datasets would be beneficial, but acknowledges the potential issue of computational resources. It also expresses a preference for maintaining probabilities, particularly at large batch sizes, but deems this aspect not critical. The comment is 3 as it provides a rationale for the suggestion, but it lacks specific examples or references to support the claim about the potential issues with maintaining probabilities at large batch sizes. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that additional experiments on larger datasets would be beneficial, which is a valuable piece of feedback for improving the paper. However, the comment also acknowledges the potential issue of computational resources, which is a practical consideration for the authors. The reviewer expresses a preference for maintaining probabilities, particularly at large batch sizes, but deems this aspect not critical. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific suggestions or guidance on how to conduct these additional experiments or address the computational concerns. Overall, the comment is 3 as it identifies an area for improvement but lacks depth and specificity in its suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, perhaps in the appendix. This provides a clear and explicit action for the authors to take, which is to expand the explanation of the bounds. The comment is specific in its suggestion, detailing what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from more explanation of the meaning of the bounds, specifically mentioning the possibility of including this in the appendix. However, it does not specify which part of the paper discusses the bounds or where the explanation should be added. This makes the comment weakly grounded, as the authors cannot confidently determine which section or part of the paper needs improvement. Additionally, the comment is specific in suggesting the inclusion of the explanation in the appendix, providing a clear direction for the authors. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could benefit from more explanation of the meaning of the bounds, particularly in the appendix. However, the comment does not provide any specific reasoning, examples, or references to support why this additional explanation would be beneficial. Without further elaboration or evidence, the claim remains 3, as the authors may need to infer the importance of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, particularly in the appendix. This feedback is clear and actionable, as it provides a specific direction for improvement by recommending that the authors expand on the explanation of the bounds. By doing so, the authors can enhance the clarity and comprehensibility of their work, making it more accessible to readers. The comment is 4 as it offers a clear and constructive suggestion for improvement, though it could be further elaborated to provide more detailed guidance. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the number of datasets used for the tasks might be insufficient for a rigorous evaluation, particularly if some datasets are too large for all algorithms. It also mentions that the authors have provided an addendum clarifying the novelty of the datasets and the motivations for their choice. However, the comment does not explicitly instruct the authors to add more datasets or provide additional details on their selection process. While the suggestion is clear, it lacks concrete guidance on how to address the issue, such as proposing specific datasets or methods for evaluation. Therefore, the comment is 3, as it provides a direction but lacks detailed instructions on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of dataset size and the number of datasets used for the tasks, allowing the authors to accurately identify the part of the paper being addressed. It also provides specific feedback on the potential insufficiency of the datasets for rigorous evaluation, particularly when some datasets are too large for all algorithms. The comment further suggests that the authors have addressed this issue by providing an addendum clarifying the novelty of the datasets and the motivations for their choice. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the number of datasets used for the tasks might be insufficient for a rigorous evaluation, especially if some datasets are too large for all algorithms. The comment suggests that the authors have addressed this issue by providing an addendum clarifying the novelty of the datasets and the motivations for their choice. However, the claim lacks specific examples or detailed reasoning to fully support the assertion. While the authors\" response is acknowledged, the initial claim remains 3 due to the lack of comprehensive evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the number of datasets used for the tasks, suggesting that it might be insufficient for a rigorous evaluation, particularly if some datasets are too large for all algorithms. It acknowledges the authors\" response, which includes an addendum clarifying the novelty of the datasets and the motivations for their choice. This feedback is 3 as it points out a potential limitation in the evaluation and provides some context for the authors\" response. However, it could be more helpful if it offered specific suggestions or guidance on how to address the issue of dataset size or the number of datasets. Overall, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the results presented in the paper, noting that while there are good performance results with ResNet50/34/18, there are no results with larger models like ResNet101/152. This feedback suggests that the authors should include results with larger models to provide a more comprehensive evaluation of their work. However, the comment does not specify which part of the paper should be updated or how the results should be presented. The action is implicit and somewhat vague, as the authors need to infer that they should add results for larger models and potentially update the discussion section to reflect this addition. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"imageNet classification\" and the models used, \"ResNet50/34/18,\" and suggests the inclusion of results for \"larger models like ResNet101/152.\" This provides clear guidance on which part of the paper needs attention. However, the comment is somewhat specific as it does not provide detailed guidance on how to include these results or what aspects of the results should be highlighted. The authors can infer that they need to add results for larger models, but the lack of specific instructions makes it somewhat specific. Therefore, this comment is classified as fully grounded and somewhat specific, aligning with category 3.", "verifiability_rationale": "The review point claims that there are no results with larger models like ResNet101/152, despite good performance with ResNet50/34/18. However, the comment lacks specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the claim is valid or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a gap in the results presented in the paper, specifically noting that while there are good performance results with ResNet50/34/18, there are no results with larger models like ResNet101/152. This feedback highlights an area where the authors could enhance their evaluation by including results with larger models. However, the comment lacks specific guidance on how to incorporate these results or what aspects of the results should be emphasized. While it identifies a potential improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for improvement but does not offer comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about how the proposed method addresses sparse reward problems and suggests that it might be similar to providing a dense reward signal. It also questions whether other methods, such as Qmix, could solve sparsereward tasks. However, the comment does not provide explicit guidance on how the authors should address these questions or improve their method. The action is implicit and vague, as it does not specify what changes or actions the authors should take to clarify or improve their work. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about how the proposed method addresses sparse reward problems, suggesting that it might be similar to providing a dense reward signal. It also questions whether other methods, such as Qmix, could solve sparsereward tasks. However, the comment does not specify which part of the paper discusses the method or the experiments, making it difficult for the authors to identify the exact section being addressed. While the comment is specific in its questioning of the method\"s approach to sparse rewards, the lack of grounding makes it challenging for the authors to understand the context and address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about how the proposed method addresses sparse reward problems and suggests that it might be similar to providing a dense reward signal. It also questions whether other methods, such as Qmix, could solve sparsereward tasks. However, the comment lacks specific examples or detailed reasoning to support its claims, making it difficult for the authors to understand the basis of the critique. The absence of references or detailed explanations makes the claim 3, as it relies on the authors\" interpretation of the method and experiments. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about how the proposed method addresses sparse reward problems and suggests that it might be similar to providing a dense reward signal. It also questions whether other methods, such as Qmix, could solve sparsereward tasks. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve their method. While it identifies a potential area for improvement, it does not provide actionable feedback or detailed insights that would help the authors enhance their draft. Therefore, the comment is 2, as it points out a weakness but does not offer substantial guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment identifies two main issues with the paper: the presence of confusing mistakes in the proof of the main results and the lack of detailed discussion and comparison with previous work, as well as the absence of new insights in the field. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks concrete guidance on how to correct the mistakes, discuss the work in detail, or provide new insights. Without specific suggestions or steps, the authors are left without a clear path to improve their draft. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment identifies two main issues with the paper: the presence of confusing mistakes in the proof of the main results and the lack of detailed discussion and comparison with previous work, as well as the absence of new insights in the field. However, it does not specify which part of the paper these issues are present in, making it difficult for the authors to pinpoint the exact areas that need attention. The comment is 1 as it does not provide specific references or sections to address. While it is somewhat specific in identifying the issues, the lack of grounding makes it challenging for the authors to understand which parts of the paper need revision. Therefore, this comment is weakly grounded and somewhat specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks detailed discussion and comparison with previous work, and that it does not provide new insights in the field. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without concrete evidence or examples, the authors may find it difficult to understand the basis of the criticism and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the presence of confusing mistakes in the proof of the main results and the lack of detailed discussion and comparison with previous work, as well as the absence of new insights in the field. However, the comment does not provide specific suggestions or guidance on how to address these issues. It lacks actionable advice, such as recommending specific areas for clarification or improvement, or suggesting ways to enhance the discussion and comparison with previous work. Without detailed feedback or constructive suggestions, the authors may find it challenging to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the clarity of the motivation for using an adversarial network in the model and questions the fairness of the experimental comparisons. It also points out that the proposed model is equipped with newly added components (CAT and GAN), making it a larger model than others, and even the pretrained model is compared with other models. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. The authors are left without guidance on how to clarify the motivation, ensure fair comparisons, or address the concerns about the model\"s size and the comparison methods. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the clarity of the motivation for using an adversarial network in the model and questions the fairness of the experimental comparisons. However, it does not specify which part of the paper these issues are related to, such as the introduction, methodology, or results sections. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need clarification or improvement. While the comment is specific in identifying the issues, the absence of explicit references to specific sections or parts of the paper makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the clarity of the motivation for using an adversarial network and questions the fairness of the experimental comparisons. However, it does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of these concerns and how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the lack of clarity in the motivation for using an adversarial network and the unfairness of the experimental comparisons. It also points out that the proposed model is equipped with newly added components (CAT and GAN), making it a larger model than others, and even the pretrained model is compared with other models. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the clarity of their motivation or the fairness of their comparisons. While it highlights areas for improvement, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential issue with the method, specifically the lack of adversarial loss to ensure that perturbed data remains similar to authentic data. However, it does not provide any explicit or implicit suggestions on how to address this issue or what specific changes should be made to the draft. The comment identifies a gap in the methodology but lacks guidance on how to improve it. As a result, the authors are left without a clear understanding of what actions to take to address the identified issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the lack of adversarial loss to ensure that perturbed data remains similar to authentic data. However, it does not specify which part of the paper this issue is related to, such as a specific section, table, or figure. Without this context, the authors cannot confidently determine where the issue lies and how to address it. The comment is 1 as it lacks specific references, and it is also not specific because it does not detail what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the lack of adversarial loss to ensure that perturbed data remains similar to authentic data. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the method, specifically the lack of adversarial loss to ensure that perturbed data remains similar to authentic data. However, it does not provide any suggestions or guidance on how to address this issue or what specific changes should be made to the draft. The comment highlights a gap in the methodology but lacks actionable feedback, leaving the authors without a clear understanding of how to improve their work. As a result, the comment is 2, as it points out a problem but does not offer any constructive advice or suggestions for improvement. Therefore, it aligns with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern regarding the limited number of methods used for comparison and the inconsistent performance of the proposed method compared to others. It suggests that the authors should provide an analysis for the inferior results, as they contradict the motivation. However, the comment does not explicitly instruct the authors on how to conduct this analysis or what specific aspects to focus on. While the action is implied, it lacks concrete guidance, making it 3.", "grounding_specificity_rationale": "The comment addresses the issue of limited comparisons and inconsistent performance, suggesting that the authors should provide an analysis for the inferior results. However, it does not specify which part of the paper this issue is related to, such as the experimental section or the results section. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its critique of the performance, the absence of grounding information makes it weakly grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the performance is only compared with a few methods and that the proposed method is not consistently better than others. This claim is supported by the observation that the results violate the motivation. However, the comment lacks specific examples or references to support the claim that the results are inconsistent or contradict the motivation. Without detailed evidence or examples, the claim is 3, as it provides a general observation but lacks the necessary depth to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the limited number of methods used for comparison and the inconsistent performance of the proposed method compared to other methods. It highlights that the results do not align with the motivation, which is a critical point for the authors to address. The comment suggests that the authors should provide an analysis for the inferior results, indicating that the feedback is actionable and constructive. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or what aspects of the results to focus on. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be interesting to compare the support of the solution obtained by the proposed scheme with that obtained by baseline methods, using a Jaccard index as an example. This comment provides a clear and explicit action for the authors to take, as they can directly compare the support of their proposed scheme with baseline methods using the suggested metric. The action is also concrete, as it specifies the exact method for comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the support of the solution obtained by the proposed scheme with that obtained by baseline methods, using a Jaccard index as an example. However, it does not specify which part of the paper this comparison should be made or which sections or figures might contain the relevant information. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, while it provides a suggestion for comparison, it lacks specificity in terms of how this comparison should be conducted or what results are expected. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests comparing the support of the solution obtained by the proposed scheme with that obtained by baseline methods using a Jaccard index. This is a suggestion for an additional analysis or comparison that could enhance the paper. However, the comment does not provide any specific reasoning, examples, or references to support why this comparison is important or how it would be conducted. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the value of the suggestion without explicit guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests comparing the support of the solution obtained by the proposed scheme with that obtained by baseline methods, using a Jaccard index as an example. This feedback is 3 as it provides a specific suggestion for an additional analysis that could enhance the paper. However, it lacks depth and does not offer detailed guidance on how to conduct this comparison or what results to expect. The comment identifies an area for improvement but does not fully address the authors\" needs for a comprehensive analysis. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the originality of the article, suggesting that its reasoning and writing logic are similar to those in a previous study. It questions whether the work is merely an extension of that study or if it introduces novel contributions. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or enhance the originality of their work. The action is implicit and vague, as it does not specify what changes or improvements the authors should make to differentiate their work from the previous study. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the originality of the article, suggesting that its reasoning and writing logic are similar to those found in a previous study. It questions whether the work is merely an extension of that study or if it introduces novel contributions. However, the comment does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact area that needs attention. The comment is 1 as it lacks specific references or sections, and it is also not specific in detailing what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the originality of the article, suggesting that its reasoning and writing logic are similar to those found in a previous study. It questions whether the work is merely an extension of that study or if it introduces novel contributions. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without detailed reasoning or references, the claim remains 1, as the authors cannot confidently assess the validity of the concern. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a concern about the originality of the article, suggesting that its reasoning and writing logic are similar to those found in a previous study. It questions whether the work is merely an extension of that study or if it introduces novel contributions. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or enhance the originality of their work. It lacks actionable feedback, leaving the authors without a clear path to improve their draft. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the verylongterm forecasting task is of limited practical significance and recommends improving the discussion by conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon to provide context for the results. While the comment provides explicit guidance on what actions the authors should take\u2014namely, to conduct additional experiments and train models with the correct forecast horizon\u2014it does not specify how to implement these actions or what specific datasets or forecast horizons to use. The actions are concrete but lack detailed guidance, making the comment 4.", "grounding_specificity_rationale": "The comment suggests that the verylongterm forecasting task is of limited practical significance and recommends improving the discussion by conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon to put the results in a proper context. However, the comment does not specify which part of the paper discusses the verylongterm forecasting task or which sections or figures need improvement. This lack of grounding makes it difficult for the authors to identify the specific areas that require attention. While the comment is specific about the need for additional experiments and training, the absence of explicit references to the paper makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the verylongterm forecasting task is of limited practical significance and recommends improving the discussion by conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon to provide context for the results. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim about the limited practical significance of the task. The suggestion to conduct experiments on more datasets and train models with the correct forecast horizon is clear and actionable, but the overall claim about the task\"s significance is not fully substantiated. Therefore, the comment is 4, as it provides some justification but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a potential limitation in the practical significance of the verylongterm forecasting task and suggests improvements to the discussion. It recommends conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon to provide context for the results. This feedback is clear and actionable, offering specific suggestions for enhancing the paper\"s discussion and ensuring that the results are properly contextualized. However, the comment could be more helpful if it provided more detailed guidance on which datasets to use or how to determine the \"correct\" forecast horizon. Despite this, the feedback is 4 as it directs the authors towards improving the practical relevance and clarity of their work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could be more novel and interesting by exploring theoretical analyses or extensive experiments to explain why a simple greedy selection approach outperforms more principled acquisition functions, and why deterministic MLP predictors outperform robust probabilistic predictors. However, it does not provide explicit guidance on how to conduct these analyses or experiments, nor does it offer concrete steps for the authors to take. The comment is 3 as it identifies a potential area for improvement but lacks detailed instructions on how to implement it. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment suggests that the paper could be more novel and interesting by exploring theoretical analyses or extensive experiments to explain why a simple greedy selection approach outperforms more principled acquisition functions, and why deterministic MLP predictors outperform robust probabilistic predictors. However, it does not specify which part of the paper these analyses or experiments are intended to address, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is fully grounded in terms of identifying the area of the paper that could be improved, but it is not specific in detailing what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the paper could be more novel and interesting by exploring theoretical analyses or extensive experiments to explain why a simple greedy selection approach outperforms more principled acquisition functions, and why deterministic MLP predictors outperform robust probabilistic predictors. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that such analyses are missing. This lack of evidence makes the claim 3, as the authors may need to infer the basis for the suggestion. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that it could be more novel and interesting if it included theoretical analyses or extensive experiments to explain why a simple greedy selection approach outperforms more principled acquisition functions, and why deterministic MLP predictors outperform robust probabilistic predictors. This feedback is 3 as it points out a specific direction for enhancing the paper\"s contribution, but it lacks detailed guidance on how to conduct these analyses or experiments. The authors would need to infer the exact steps to take, which limits the comment\"s impact. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific area where the authors lack analysis, namely the security and privacy protection of the proposed framework. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. The comment identifies a gap in the analysis but does not offer guidance on what steps to take to improve the draft. As a result, the authors are left without a clear direction on how to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a specific area of the paper that needs analysis, namely the security and privacy protection of the proposed framework. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in pointing out the lack of analysis, but without clear guidance on where to add this analysis, the authors may find it challenging to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not analyze the security and privacy protection of the proposed framework. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the exact nature of the missing analysis. Without additional context or references, the authors may struggle to address the issue effectively. Therefore, the comment is considered 2, as it provides a general claim but lacks sufficient evidence or justification.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of analysis regarding the security and privacy protection of the proposed framework. This is a crucial aspect that needs to be addressed for the paper to be considered complete and robust. However, the comment does not provide any suggestions or guidance on how the authors might approach this analysis, leaving the authors without a clear direction on how to improve their draft. While the feedback highlights an important area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the multiscale statement, suggesting that the slow and fast RNNs operate on logical time scales rather than physical time scales. It also points out that the primary benefit seems to be the reduction of gradient path by the slow RNN. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary to clarify the statement. The action is implicit, as the authors would need to infer that they should revise the statement to accurately reflect the operation of the RNNs. The lack of concrete suggestions or detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment raises a concern about the multiscale statement, suggesting that the slow and fast RNNs operate on logical time scales rather than physical time scales. However, it does not specify which part of the paper this concern pertains to, making it difficult for the authors to pinpoint the exact section or figure being addressed. While the comment is specific in its critique of the multiscale statement, the lack of grounding makes it challenging for the authors to understand where to focus their attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the multiscale statement, suggesting that the slow and fast RNNs operate on logical time scales rather than physical time scales. The reviewer provides a logical explanation for this claim, arguing that the sequentialization in the graph leads to logical time scales. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the reasoning and potentially seek additional evidence to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the multiscale statement, suggesting that the slow and fast RNNs operate on logical time scales rather than physical time scales. This observation is insightful and could help the authors clarify their explanation of the RNNs\" operation. However, the comment does not provide specific guidance on how the authors might address this issue or what changes could be made to improve the clarity of their explanation. While it offers a valuable point for consideration, the feedback lacks depth and actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the feature selection presented in Section 4.2 could be further improved by considering representation learning, which is discussed in the appendix. However, it does not provide explicit guidance on how to implement this improvement or what specific aspects of the feature selection should be considered. The action is implicit and vague, as it leaves the authors to infer the necessary steps to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the proposed invariant learning module in Section 4.2, specifically mentioning mask selection and rawlevel features. It also refers to the discussion of representation learning in the appendix, suggesting that the feature selection could be improved by considering representation learning. However, the comment does not specify which part of the paper the authors should focus on for improvement, making it weakly grounded. The comment is specific in suggesting that the feature selection could be enhanced by considering representation learning, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the feature selection presented in Section 4.2 could be further improved by considering representation learning, which is discussed in the appendix. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide a clear explanation of why considering representation learning would enhance the feature selection process or how it could be implemented. Without these details, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered 2, as it provides some basis for improvement but lacks sufficient depth and clarity to be 5.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that the feature selection presented in Section 4.2 could be further enhanced by considering representation learning, which is discussed in the appendix. This feedback is 3 as it points out a specific aspect that could be improved, but it lacks detailed guidance on how to implement this suggestion or what specific aspects of the feature selection should be considered. The comment provides a clear direction for improvement but does not offer a comprehensive or actionable plan, leaving the authors with a general idea of what to work on. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern regarding the quality of paraphrases used for training data generation. It points out that the difference between the paraphrases and the original sentences is unclear, which could impact the subsequent steps and the overall quality of the training data. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the paraphrases. The feedback is somewhat vague and lacks concrete details on how to implement the suggested improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of generating paraphrases for training data, specifically noting that the difference between the paraphrases and the original sentences is unclear. This provides a clear indication of which part of the paper the comment is addressing, making it fully grounded. The comment also specifies the impact of this issue on the subsequent steps and the quality of the training data, offering a detailed explanation of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the quality of paraphrases used for training data generation, specifically noting that the difference between the paraphrases and the original sentences is unclear. This is a valid concern as the quality of the training data is crucial for the model\"s performance. However, the comment does not provide specific examples or references to support the claim that the difference is unclear or how it impacts the subsequent steps. While the reasoning is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue regarding the quality of paraphrases used for training data generation. It highlights that the difference between the paraphrases and the original sentences is unclear, which can significantly impact the subsequent steps and the overall quality of the training data. The comment provides a clear and actionable suggestion that the authors should ensure the paraphrases are sufficiently different from the original sentences to maintain the quality of the training data. This feedback is valuable as it directs the authors to address a specific aspect of their methodology that could affect the effectiveness of their model. However, the comment could be more helpful if it provided additional guidance on how to ensure the paraphrases are sufficiently different or what specific techniques could be used to achieve this. Overall, the comment is 4, as it offers a clear direction for improvement but could be expanded for more comprehensive guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the FlippedQA framework, which is described as general for various generative VideoQA models, should be further verified for its effectiveness and universality in nonLLMbased models like HiTeA and InternVideo. However, the comment does not provide explicit guidance on how to verify this claim or what specific steps the authors should take to address it. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the FlippedQA framework, described as general for various generative VideoQA models, should be further verified for its effectiveness and universality in nonLLMbased models like HiTeA and InternVideo. However, the comment does not specify which part of the paper discusses the FlippedQA framework or the models it is applied to. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs attention. While the comment is specific in its suggestion to verify the framework\"s effectiveness and universality, the absence of explicit grounding makes it challenging for the authors to understand where to focus their efforts. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the FlippedQA framework, described as general for various generative VideoQA models, should be further verified for its effectiveness and universality in nonLLMbased models like HiTeA and InternVideo. However, the comment lacks specific evidence or references to support this claim. It does not provide examples or detailed reasoning to justify why the framework should be verified in these specific models. Without additional context or supporting arguments, the claim remains 3, as it lacks the necessary depth and clarity to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by suggesting that the FlippedQA framework, described as general for various generative VideoQA models, should be further verified for its effectiveness and universality in nonLLMbased models like HiTeA and InternVideo. This feedback is 3 as it points out a specific area that could enhance the paper\"s comprehensiveness and applicability. However, the comment lacks detailed guidance or suggestions on how to verify the framework\"s effectiveness or universality, which limits its impact on the authors. The feedback is incomplete and could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the proposed method primarily builds upon existing methods, such as ClopperPearson intervals and Gaussian elimination, and that it lacks significant theoretical novelty. The comment also expresses a willingness to improve the score if the authors address these concerns. However, the comment does not provide specific guidance on how the authors might address these issues or what changes could be made to enhance the theoretical novelty of their method. The action is implicit, as the authors need to infer that they should focus on improving the theoretical aspects of their work. The comment is 3 because it identifies a clear area for improvement but lacks concrete details on how to achieve it. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and the specific methods it builds upon, such as ClopperPearson intervals and Gaussian elimination. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue of lack of theoretical novelty and suggests that the authors are willing to improve their score if they address these concerns. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method primarily builds upon existing methods, specifically mentioning ClopperPearson intervals and Gaussian elimination, and that it lacks significant theoretical novelty. The comment provides specific references to these methods, which are wellknown and established techniques. However, it does not offer additional reasoning or examples to fully support the claim about the lack of theoretical novelty. While the references provide some context, the claim could be strengthened with more detailed explanations or examples of how the proposed method differs from or builds upon these existing methods. Therefore, the comment is 4, as it is supported by some evidence but lacks complete detail.", "helpfulness_rationale": "The review comment identifies a key weakness in the paper, noting that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. This feedback is valuable as it highlights an area where the authors could enhance their work. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue. For example, it could suggest exploring new theoretical frameworks or providing a more detailed comparison of the proposed method with existing approaches. Without such guidance, the authors may struggle to understand how to improve their draft. Therefore, the comment is 3, as it points out a critical area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether the text input is concatenated by four text elements of an object. While it prompts the authors to consider this aspect, it does not provide explicit guidance on how to address this question or what changes might be necessary. The action is implicit, as the authors need to infer that they should investigate and clarify the concatenation process. However, the comment lacks concrete details on how to implement this investigation or what specific aspects need clarification. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment raises a question about whether the text input is concatenated by four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment lacks specificity in addressing the issue, as it does not provide details on what needs to be clarified or how the concatenation process might be relevant. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about whether the text input is concatenated by four text elements of an object. However, it does not provide any claim, assertion, or suggestion that requires verification or justification. The comment is purely factual and descriptive, lacking any critical analysis or reasoning. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about whether the text input is concatenated by four text elements of an object. While this question prompts the authors to consider a specific aspect of their work, it does not provide any guidance or suggestions on how to address this issue or what changes might be necessary. The comment lacks depth and actionable feedback, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is 2, as it identifies a potential area for clarification but does not offer substantial guidance or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could be improved by first motivating the \"why\" behind the research. However, it does not provide explicit guidance on how to motivate the \"why\" or what specific aspects of the paper need to be addressed to achieve this. The action is implicit, as the authors would need to infer that they should add a section or discussion motivating the importance of the research question. The comment is vague and lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment suggests that the paper could be improved by first motivating the \"why\" behind the research. However, it does not specify which part of the paper this motivation should be included in, nor does it provide any guidance on how to motivate the \"why.\" The authors cannot confidently determine which section or aspect of the paper needs to be addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide details on what aspects of the motivation are missing or how to effectively motivate the \"why.\" Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the paper could be improved by first motivating the \"why\" behind the research. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper could be improved by first motivating the \"why\" behind the research, which is a valuable piece of feedback. It highlights a potential area for improvement by emphasizing the importance of clearly articulating the motivation and relevance of the research question. However, the comment lacks specific guidance on how to motivate the \"why\" or what aspects of the paper need to be addressed to achieve this. While it provides a direction for improvement, the feedback is somewhat limited in its actionable depth, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that additional experiments on realistic noisy datasets, such as WebVision, would provide more support for the C2D (Contrastive 2D) approach. However, it does not specify which aspects of the C2D approach would benefit from these experiments or how the experiments should be conducted. The comment implies that the authors should consider adding such experiments, but it lacks concrete guidance on what specific experiments to perform or how to integrate them into the draft. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on implementation.", "grounding_specificity_rationale": "The comment suggests that additional experiments on realistic noisy datasets, such as WebVision, would provide more support for the C2D approach. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to pinpoint the exact section or aspect that needs improvement. The comment is specific in its suggestion regarding the type of experiments, but it lacks grounding as it does not clearly indicate where in the paper these experiments should be discussed or how they would enhance the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that additional experiments on realistic noisy datasets, such as WebVision, would provide more support for the C2D approach. However, the comment lacks specific details or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to implement it. Without additional context or evidence, the claim remains 3, as it lacks the necessary depth and clarity to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that additional experiments on realistic noisy datasets, such as WebVision, would provide more support for the C2D approach. This feedback is 3 as it identifies a potential area for improvement by suggesting a specific type of experiment that could enhance the paper\"s support for the C2D approach. However, the comment lacks depth and does not provide detailed guidance on how to conduct these experiments or what specific aspects of the C2D approach would benefit from them. While it offers a direction for improvement, it does not fully address the authors\" needs for comprehensive feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of essential visualization of intermediate processes and comparisons in the paper. While it identifies a gap in the presentation of the work, it does not provide explicit guidance on what specific visualizations are missing or how they should be incorporated. The comment suggests that the authors should consider adding visualizations to better illustrate the intermediate processes and comparisons, but it does not specify which aspects of the paper would benefit from these visualizations or how they should be designed. This lack of detail makes it difficult for the authors to understand the exact actions they need to take to address the issue. Therefore, the comment is 3, as it provides a clear direction but lacks concrete details on implementation.", "grounding_specificity_rationale": "The comment identifies a lack of essential visualization of intermediate processes and comparisons in the paper. However, it does not specify which part of the paper this issue pertains to, such as specific sections, figures, or tables. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific in its critique of the visualization, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that there is a lack of essential visualization of intermediate processes and comparisons in the paper. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to understand the specific areas where the visualization is lacking. This makes the claim 3, as it lacks sufficient justification or examples to fully substantiate the assertion.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting the lack of essential visualization of intermediate processes and comparisons. This feedback is clear and actionable, as it directs the authors to enhance the presentation of their work by incorporating visualizations that better illustrate the intermediate steps and comparisons. However, the comment could be more helpful if it provided specific examples of what kind of visualizations would be beneficial or suggested ways to integrate them into the paper. Despite this, the feedback is 4 as it offers a clear direction for improvement, allowing the authors to make informed decisions about enhancing their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the importance of the result and questions the novelty of the findings, particularly in light of existing work on perturbed gradient descent. It highlights a specific issue with the iteration complexity of Theorem 3, noting that it is no longer dimensionfree. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback is vague and lacks actionable steps for the authors to take. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the importance of the result and questions the novelty of the findings, referencing existing work on perturbed gradient descent. It highlights a specific issue with the iteration complexity of Theorem 3, noting that it is no longer dimensionfree. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or theorem. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the result, it lacks grounding as it does not provide clear references or sections to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the importance of the result and questions the novelty of the findings, referencing existing work on perturbed gradient descent. It highlights a specific issue with the iteration complexity of Theorem 3, noting that it is no longer dimensionfree. However, the comment lacks detailed reasoning or specific examples to support the claim that the findings are not surprising or that the iteration complexity is no longer dimensionfree. The absence of references or detailed explanations makes it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises concerns about the importance of the result and questions the novelty of the findings, referencing existing work on perturbed gradient descent. It highlights a specific issue with the iteration complexity of Theorem 3, noting that it is no longer dimensionfree. However, the comment lacks detailed reasoning or specific examples to support the claim that the findings are not surprising or that the iteration complexity is no longer dimensionfree. The absence of references or detailed explanations makes it difficult for the authors to understand the basis of the critique. While the comment identifies a potential issue, it does not provide actionable guidance or suggestions for improvement, leaving the authors with limited insight into how to address the concerns. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a critical concern about the sensitivity of the empirical results to hyperparameter choices. It highlights the importance of this issue, noting that incorrect choices could potentially negate the benefits of the method. However, the comment does not provide any explicit guidance or suggestions on how the authors might address this concern, such as conducting additional experiments or providing a detailed analysis of the impact of different hyperparameter settings. The action is implicit, as the authors are left to infer that they need to investigate the robustness of their results to hyperparameter variations. While the comment is 3, it lacks concrete details on how to implement the suggested action, making it 3.", "grounding_specificity_rationale": "The comment raises a concern about the sensitivity of the empirical results to hyperparameter choices, which is a crucial issue. However, it does not specify which part of the paper this concern pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its focus on hyperparameter sensitivity, the absence of explicit grounding makes it challenging for the authors to understand which part of the paper to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sensitivity of the empirical results to hyperparameter choices, suggesting that incorrect choices could potentially negate the benefits of the method. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical concern about the sensitivity of the empirical results to hyperparameter choices, noting that incorrect choices could potentially negate the benefits of the method. This is a significant issue that needs to be addressed to ensure the robustness and reliability of the findings. However, the comment lacks specific guidance or suggestions on how the authors might investigate or mitigate this issue. While it highlights an important area for improvement, the feedback is somewhat limited in its actionable nature, as it does not provide detailed steps or recommendations for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors need to further claim the novelty and contribution of their proposed method, given that the work utilizes existing attack methods on a surrogate model and is similar to using the transferability of adversarial examples. However, the comment does not provide explicit guidance on how to claim the novelty or contribution, nor does it offer specific examples or detailed instructions on how to address this issue. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"This work utilizes existing attack methods on a surrogate model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the similarity to using the transferability of adversarial examples and the need to further claim the novelty and contribution of the proposed method. This provides the authors with clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the work utilizes existing attack methods on a surrogate model and is similar to using the transferability of adversarial examples. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty and contribution of the proposed method, noting that it utilizes existing attack methods on a surrogate model and is similar to using the transferability of adversarial examples. While the comment highlights a concern, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides two explicit actions for the authors to take: first, to clarify the experiment and its implications, and second, to strengthen the experiment by addressing the issue of pseudo feature importance. The actions are clear and specific, giving the authors a direct understanding of what needs to be done. The comment also suggests that the experiment could be strengthened by addressing the issue of pseudo feature importance, which provides a concrete direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"one experiment to estimates the quality of uncertainty estimates,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the issue of using pseudo feature importance and the reliance on Prop 3.2 and a large enough perturbation value. This provides clear guidance on how to improve the experiment. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the experiment\"s reliance on pseudo feature importance, which is based on Prop 3.2 and a large enough perturbation value. The comment suggests that the correctness of the pseudo feature importance is difficult to judge due to the similarity between the tested method and the pseudo feature importance, which only differs in the number of perturbations. However, the comment does not provide specific examples or references to support the claim that the experiment is difficult to trust. This lack of detailed justification makes the claim 3, as it lacks sufficient evidence to fully substantiate the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed critique of an experiment, specifically questioning its ability to accurately estimate uncertainty due to the use of pseudo feature importance. It highlights the reliance on Prop 3.2 and the importance of a large enough perturbation value, which are crucial for the experiment\"s validity. The comment suggests that the experiment could be strengthened by addressing these issues, offering actionable feedback for improvement. However, it could be more helpful if it provided specific guidance on how to address these concerns or suggested alternative approaches. Overall, the comment is 4 as it identifies a significant weakness and provides a clear direction for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that nonconvexity may not be an issue for SGD convergence if the function Z has certain properties. However, it does not provide any specific guidance or action for the authors to take in response to this observation. The comment lacks explicit instructions on how the authors might address this point or incorporate it into their work. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (ln. 182184) of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it provides a clear observation about the potential issue of nonconvexity in the context of SGD convergence, suggesting that this may not be a problem if the function Z has good properties. This feedback is actionable and provides a clear direction for the authors to consider. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that nonconvexity may not be an issue for SGD convergence if the function Z has good properties. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand or address this point effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue regarding the convergence of SGD in the context of nonconvex functions, specifically mentioning that the convergence may not be a problem if the function Z has good properties. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or incorporate it into their work. While it points out a potential area for consideration, it does not offer actionable advice or insights that would significantly enhance the authors\" understanding or improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a critical issue regarding the lack of proper mention of experimental settings, which is essential for result reproducibility. It also points out that the authors do not provide the code, which is a significant omission. While the comment identifies two separate issues, it does not explicitly instruct the authors to address these by providing detailed experimental settings and the code. The action is implicit and somewhat vague, as the authors need to infer that they should include these details to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a critical issue regarding the lack of proper mention of experimental settings, which is essential for result reproducibility. It also points out that the authors do not provide the code, which is a significant omission. However, the comment does not specify which part of the paper discusses the experimental settings or where the code is mentioned. This makes it difficult for the authors to identify the exact sections that need revision. While the comment is specific about the issues, it lacks grounding as it does not provide clear references to the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experimental settings are not mentioned properly, which is critical for result reproducibility, and that the authors do not provide the code. However, the comment lacks specific details or examples to support these claims. Without additional information or references, the authors may find it challenging to understand the exact nature of the issue or how to address it. Therefore, the claim is considered 2, as it provides some indication of the problem but lacks sufficient detail or evidence to fully substantiate the authors\" concerns.", "helpfulness_rationale": "The review comment identifies a critical issue regarding the lack of proper mention of experimental settings, which is essential for result reproducibility. It also points out that the authors do not provide the code, which is a significant omission. While the comment highlights these important aspects, it does not offer specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it directs the authors to areas that need improvement, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the claim that \"Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts,\" based on the slight improvement observed in Table 6 and Table 7. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to strengthen their claims. The comment lacks concrete suggestions or detailed instructions on how to improve the experimental results or the claims made. As a result, the authors are left without a clear understanding of how to respond to the critique and improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the claim that \"Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts,\" based on the slight improvement observed in Table 6 and Table 7. However, it does not specify which part of the paper this claim is made or which tables or figures are being referenced. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific details on what needs to be addressed or how the authors should improve their claims. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the claim that \"Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts,\" based on the slight improvement observed in Table 6 and Table 7. However, the comment does not provide any specific reasoning, examples, or references to support why this claim is questionable or how the slight improvement might undermine the effectiveness of the proposed prompts. Without additional justification or evidence, the claim remains 1, as the authors are left without a clear understanding of how to address the critique or strengthen their claims. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the claim that \"Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts,\" based on the slight improvement observed in Table 6 and Table 7. While the comment identifies a potential issue with the claim, it does not provide specific guidance or suggestions on how the authors might address this concern or strengthen their experimental results. The feedback is 3 as it highlights a critical point that needs attention, but it lacks actionable advice or detailed insights into how the authors can improve their claims or experimental setup. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the Cycle FC method, noting that it aligns features at different spatial locations to the same channel, but the analysis is slightly insufficient. It suggests that there could be many different designs for this method and recommends exploring experiments or analysis with different sampling intervals and sample sizes. While the comment identifies an area for improvement and provides a direction for further exploration, it does not explicitly instruct the authors to conduct these experiments or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the Cycle FC method, specifically mentioning that it aligns features at different spatial locations to the same channel, but the analysis is slightly insufficient. It suggests exploring experiments or analysis with different sampling intervals and sample sizes. However, the comment does not specify which part of the paper discusses the Cycle FC method or where the analysis is conducted. This makes it difficult for the authors to pinpoint the exact section or figure that needs revision. While the comment is specific about the issue of insufficient analysis, it lacks grounding as it does not provide clear references to the relevant parts of the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the analysis of the Cycle FC method is slightly insufficient, suggesting that there could be many different designs and that exploring experiments with different sampling intervals and sample sizes could enhance the analysis. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism or how to address it. The reasoning is vague and lacks detailed evidence, which limits the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the Cycle FC method, specifically noting that aligning features at different spatial locations to the same channel results in slightly insufficient analysis. It suggests that exploring experiments with different sampling intervals and sample sizes could enhance the analysis. While the comment points out a specific area for improvement, it does not provide detailed guidance or examples on how to conduct these additional experiments or what specific aspects of the analysis could be improved. The feedback is 3 as it directs the authors to consider expanding their analysis, but it lacks depth and specificity, making it challenging for the authors to fully address the issue. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the dimensionality of each region being 512 and asks for clarification on which feature extractor is used. While the comment identifies a specific detail that needs clarification, it does not provide explicit guidance on how the authors should address this question or what information they should include in their response. The action is implicit, as the authors need to infer that they should clarify the feature extractor used. However, the comment lacks concrete details on how to implement this clarification, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the dimensionality of each region being 512 and asks for clarification on which feature extractor is used. This provides a clear direction for the authors to address the question. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the dimensionality of each region being 512 and asks for clarification on which feature extractor is used. This is a factual question that requires the authors to provide additional information or context. However, the comment does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment points out a specific detail in the paper, namely the dimensionality of each region being 512, and asks for clarification on which feature extractor is used. This is a clear and actionable piece of feedback that helps the authors identify a potential gap in their explanation or methodology. By prompting the authors to clarify this aspect, the comment provides a direct path for improvement, making it 3. However, it could be more helpful if it suggested specific ways to address the question or provided examples of how to clarify the feature extractor. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. While the comment implies that the authors should provide a clearer explanation, it does not specify exactly what needs to be done or how to demonstrate the motivation more explicitly. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on the motivation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure. This makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific about the need for a clearer explanation, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the motivation behind applying CMD in federated learning. It suggests that the authors could benefit from a more explicit demonstration or explanation of this motivation. However, the comment lacks specific guidance or examples on how to address this issue, leaving the authors with a general idea of what to improve but without detailed instructions. This makes the feedback 3, as it points out an area for enhancement but does not provide comprehensive suggestions. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point questions the contribution of the CoNO model, specifically whether the performance boost is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are inevitable and provides references to support the claim. While the comment implies that the authors should compare their model to UNets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include comparisons to UNets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed CoNO model and questions the source of the performance boost, specifically whether it is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are inevitable, especially given the strong performance of UNets on regular gridded domains, referencing works by Raonic et al. and Gupta et al. This comment is fully grounded as it explicitly mentions the CoNO model and the specific aspect of the model being questioned. It is also specific because it provides clear guidance on what comparisons should be made, namely comparisons to UNets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the source of the performance boost in the proposed CoNO model, specifically whether it is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are inevitable, especially given the strong performance of UNets on regular gridded domains, referencing works by Raonic et al. and Gupta et al. This provides a logical reasoning and specific examples to support the claim, making it 4. The comment is clear and provides sufficient evidence for the authors to understand and address the issue.", "helpfulness_rationale": "The review comment raises a critical question about the source of the performance boost in the proposed CoNO model, specifically questioning whether it is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are inevitable, especially considering the strong performance of UNets on regular gridded domains, as demonstrated in works by Raonic et al. and Gupta et al. This feedback is valuable as it prompts the authors to provide a more detailed analysis of their model\"s performance and to compare it with established architectures like UNets. However, the comment could be more helpful if it provided specific guidance on how to conduct these comparisons or suggested additional experiments to further clarify the source of the performance boost. Overall, the comment is 4, as it identifies a key area for improvement and provides a clear direction for the authors to follow, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses an opinion that the contribution of the paper is marginal, suggesting that the methods used are welldesigned and demonstrated. It proposes adding another stream for lowresolution as a potential contribution, but does not provide explicit guidance on how to implement this suggestion or what specific aspects of the lowresolution stream should be emphasized. The action is implicit and vague, as it does not specify how the authors should address the issue or what changes are needed to make the contribution more significant. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment expresses an opinion about the marginal contribution of the paper, suggesting that the methods used are welldesigned and demonstrated. It proposes adding another stream for lowresolution as a potential contribution, but does not specify which part of the paper this suggestion relates to. The comment lacks grounding as it does not provide specific references or sections of the paper that need to be addressed. It is also not specific in detailing what aspects of the lowresolution stream should be emphasized. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion that the contribution of the paper is marginal, suggesting that the methods used are welldesigned and demonstrated. It proposes adding another stream for lowresolution as a potential contribution, but does not provide specific examples or references to support this claim. The comment lacks detailed reasoning or evidence to substantiate the assertion that the contribution is marginal. Without additional context or justification, the claim remains somewhat subjective and difficult for the authors to address effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment expresses an opinion that the contribution of the paper is marginal, suggesting that the methods used are welldesigned and demonstrated. It proposes adding another stream for lowresolution as a potential contribution, but does not provide specific guidance on how to implement this suggestion or what aspects of the lowresolution stream should be emphasized. The comment lacks actionable feedback, as it does not offer concrete steps or suggestions for improving the paper\"s contribution. Without detailed guidance or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the value of the comprehensive Appendix and mentions that the authors did not have time to read additional experiments, such as the Brusselator, described in the Appendix. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve their draft. The comment lacks concrete guidance on what actions the authors should take to ensure that the additional experiments are considered or discussed. As a result, the authors are left without a clear understanding of how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment acknowledges the value of the comprehensive Appendix and mentions that the authors did not have time to read additional experiments, such as the Brusselator, described in the Appendix. However, it does not specify which part of the paper the authors should focus on or what specific issues they need to address. The comment lacks grounding as it does not provide clear guidance on which sections or parts of the paper need attention. It is also specific in that it mentions the Brusselator experiment as an example of additional detail that was not read. However, without explicit guidance on what needs to be addressed, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point acknowledges the value of the comprehensive Appendix and mentions that the authors did not have time to read additional experiments, such as the Brusselator, described in the Appendix. However, it does not provide any specific reasoning or evidence to support why the authors should consider reading these additional experiments or how they might benefit from doing so. The comment lacks detailed justification or examples, making it difficult for the authors to understand the significance of the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the value of the comprehensive Appendix and notes that the authors did not have time to read additional experiments, such as the Brusselator, described in the Appendix. While the comment highlights a potential issue with the draft\"s completeness, it does not provide specific suggestions or guidance on how the authors might address this concern or improve their draft. The feedback is 3 as it identifies an area for improvement, but it lacks actionable advice or detailed suggestions, leaving the authors with limited insight into how to enhance their work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" claim about using active learning in step 2, specifically asking whether the \"active learning pipeline\" is the same as traditional active learning. This question implies that the authors should clarify the distinction between the two methods to avoid misleading readers. While the comment is explicit in its request for clarification, it lacks concrete guidance on how to address the issue or what specific aspects of the method need to be clarified. The authors are aware of the need to provide more detail but are not given explicit steps on how to do so. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment questions the authors\" claim about using active learning in step 2, specifically asking whether the \"active learning pipeline\" is the same as traditional active learning. This question is clear and specific, as it directly addresses the method used in the paper. However, it does not provide explicit references to specific sections or parts of the paper, making it weakly grounded. The comment is specific in its request for clarification, as it asks for a comparison between the \"active learning pipeline\" and traditional active learning. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" claim about using active learning in step 2, specifically asking whether the \"active learning pipeline\" is the same as traditional active learning. This is a subjective claim that requires clarification and justification. The comment does not provide any evidence or reasoning to support the claim, making it difficult for the authors to understand the basis of the question. Therefore, the comment is 1.", "helpfulness_rationale": "The review comment raises a valid concern about the authors\" claim regarding the use of active learning in step 2. It questions whether the \"active learning pipeline\" is the same as traditional active learning, which could potentially mislead readers. This feedback is clear and identifies a specific area that needs clarification. However, it does not provide detailed guidance on how the authors should address this issue or what specific aspects of the method need to be clarified. While the comment is 3 as it highlights a potential issue, it could be more helpful with additional suggestions or guidance on how to improve the clarity of the description. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of the experimental methodology, specifically questioning whether the 300WLP dataset is used in all experiments or just some. It highlights a potential unfair advantage for the proposed method if the dataset is used in all experiments. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this concern or what changes might be necessary. The action is implicit, as the authors need to infer that they should clarify the use of the 300WLP dataset in their experiments. However, the comment lacks concrete details on how to implement this clarification, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the concern about the experimental methodology is raised, specifically mentioning the use of 300WLP. It is also specific because it clearly identifies the issue: the discrepancy in the use of the 300WLP dataset between the proposed method and the baselines, questioning whether it is used in all experiments or just some. This allows the authors to understand exactly what part of the paper needs clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the experimental methodology, specifically regarding the use of the 300WLP dataset. It points out that while the paper claims the same procedure is used as for baselines, most baselines do not use this dataset. This raises a concern about potential unfair advantages for the proposed method. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the baselines do not use the 300WLP dataset. Without this additional information, the claim is difficult to verify, making it 2.", "helpfulness_rationale": "The review comment identifies a critical issue with the experimental methodology, specifically questioning the use of the 300WLP dataset. It highlights a potential unfair advantage for the proposed method if the dataset is used in all experiments, which is a significant concern. However, the comment lacks detailed guidance on how the authors should address this issue or what changes might be necessary to ensure a fair comparison. While it points out a potential problem, it does not provide actionable steps or suggestions for improvement, making it 3. The feedback is valuable but could be more impactful with additional guidance on how to clarify the experimental setup."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that some techniques behind the algorithm may not be novel, specifically mentioning \"computation offloading\" and \"gradient augmentation.\" However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific aspects of the algorithm need to be revised. Without further clarification or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some techniques behind the algorithm may not be novel, specifically mentioning \"computation offloading\" and \"gradient augmentation.\" However, it does not specify which part of the paper these techniques are discussed in, making it difficult for the authors to identify the exact section or context. The comment is specific in its critique of the novelty of the techniques but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some techniques behind the algorithm may not be novel, specifically mentioning \"computation offloading\" and \"gradient augmentation.\" However, the comment lacks specific evidence or references to support this claim. Without detailed examples or citations, the authors may find it challenging to understand the basis of the critique or how to address it. The comment is 3 as it provides a general observation but lacks the necessary depth and support to be fully convincing. Therefore, it is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of some techniques used in the algorithm, specifically mentioning \"computation offloading\" and \"gradient augmentation.\" While it points out a concern, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the novelty of their approach. The comment lacks actionable advice, leaving the authors without a clear path to enhance their work. Therefore, the comment is 2, as it highlights a potential area for improvement but does not offer substantial guidance or constructive feedback. This aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the formulation of the integral in Equation (1), suggesting that the assumption of averaging observations might not be accurate and that other aggregation methods, such as simple summation or populationweighted average, could be more appropriate. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the formulation. The action is implicit and vague, as it leaves the authors to infer the necessary steps to improve their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (1)\" and \"the formulation introduced by the authors,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the integral formulation, suggesting that the assumption of averaging observations might be inaccurate and that other aggregation methods, such as simple summation or populationweighted average, could be more appropriate. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the formulation introduced by the authors assumes that observations are obtained by averaging over the corresponding support $v$. However, it argues that the data might be aggregated by other procedures, such as simple summation or populationweighted average, and that disease incident data are often available in count or rate per the number of residents. This claim is 3 as it provides a logical reasoning for why the assumption might be inaccurate, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the formulation of the integral in Equation (1), suggesting that the assumption of averaging observations might not be accurate. It points out that the data might be aggregated by other procedures, such as simple summation or populationweighted average, and that disease incident data are often available in count or rate per the number of residents. This feedback is 3 as it highlights a potential area for improvement in the paper\"s methodology. However, it could be more helpful if it provided specific guidance on how the authors could address this issue or what changes might be necessary to the formulation. Overall, the comment offers a clear direction for improvement, but it lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the comprehensiveness of the experiments, noting that the analyses of the method itself and the experimental outcomes are not detailed enough. It also questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific aspects of the analysis need to be expanded. The action is implicit and vague, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the comprehensiveness of the experiments, specifically noting that the analyses of the method itself and the experimental outcomes are not detailed enough. It also questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. However, the comment does not specify which part of the paper this issue is related to, such as specific sections or figures. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the issue of comprehensiveness and the question about performance improvement, it lacks grounding as it does not provide clear references to specific sections or parts of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the analyses of the method itself and the experimental outcomes are not comprehensive enough, and that the underperformance of the method compared to the baseline raises questions about the attribution of performance improvement. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide references or logical arguments to substantiate the assertion that the analyses are insufficient or that the performance improvement is questionable. Without concrete evidence or detailed explanations, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the comprehensiveness of the experiments, specifically noting that the analyses of the method itself and the experimental outcomes are not detailed enough. It also questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. However, the comment lacks specific guidance or suggestions on how the authors might address these concerns or what aspects of the analysis need to be expanded. While it points out a potential area for improvement, it does not provide actionable advice or detailed feedback, making it 3. The authors would need to infer how to improve their draft based on this feedback, which limits its overall helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the practical implications of the theoretical results, suggesting that the paper could benefit from providing more takeaway points for practitioners. It also notes that the main takeaway point about querying a cluster proportionally to the square root of its size is unclear regarding its novelty. However, the comment does not explicitly instruct the authors to include more practical takeaways or clarify the novelty of the finding. While the authors can infer that they need to address these points, the action is implicit and somewhat vague, as it lacks specific guidance on how to incorporate practical takeaways or clarify the novelty. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical results and their practical implications, suggesting that the paper could benefit from providing more takeaway points for practitioners. It also mentions that the main takeaway point about querying a cluster proportionally to the square root of its size is unclear regarding its novelty. However, the comment does not specify which part of the paper discusses the theoretical results or the takeaway points, making it weakly grounded. The comment is specific in detailing the issue with the practical implications and the lack of clarity regarding the novelty of the finding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical results lack immediate practical implications, which is a subjective observation. It suggests that the paper could benefit from providing more takeaway points for practitioners, but this is not a claim that requires verification. The comment also notes that the main takeaway point about querying a cluster proportionally to the square root of its size is unclear regarding its novelty, which is a valid observation but lacks specific examples or references to support the claim. Therefore, the comment is 3, as it provides some reasoning but lacks detailed evidence or references. The label aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a key area for improvement by pointing out that the theoretical results lack immediate practical implications. It suggests that the paper could benefit from providing more takeaway points for practitioners, which is a valuable insight for enhancing the paper\"s relevance and impact. Additionally, the comment highlights a specific concern regarding the novelty of the main takeaway point about querying a cluster proportionally to the square root of its size, which is a clear and actionable suggestion for the authors to consider. However, the comment could be more helpful if it provided specific guidance on how to address these issues or examples of how to make the takeaways more practical. Overall, the comment is 4 as it directs the authors towards important areas for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point questions the necessity of introducing separators in Section 4, asking for clarification on their purpose beyond T/I/O. While it prompts the authors to explain the role of separators, it does not provide explicit guidance on how to address this issue or what specific changes might be needed. The action is implicit, as the authors need to infer that they should clarify the purpose of separators. However, the comment lacks concrete details on how to implement this clarification, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of introducing separators and asks for clarification on their purpose beyond T/I/O, providing a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the necessity of introducing separators in Section 4, specifically asking for clarification on their purpose beyond T/I/O. While it does not contain a subjective claim or opinion, it prompts the authors to provide additional information or reasoning to justify the inclusion of separators. The comment is 3 as it encourages the authors to elaborate on the purpose of separators, but it lacks specific examples or references to support the claim. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the introduction of separators in Section 4, questioning their necessity and purpose beyond T/I/O. This feedback is clear and actionable, as it prompts the authors to clarify the role of separators and provide additional context or reasoning for their inclusion. By addressing this question, the authors can improve the clarity and coherence of their paper. However, the comment could be more helpful if it suggested specific ways to clarify the purpose of separators or provided examples of how they enhance the understanding of the content. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors consider using longer video sequences to better capture motion, color, and object changes. It also acknowledges the paper\"s interesting idea and extensive experiments, noting that the results are still not perfect but show improvement over the previous stateoftheart. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors are left to infer how to apply the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"short video sequences\" and provides examples, such as \"16 frames,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider, such as \"videos with a longer duration\" and suggests that this could be achieved by running the LSTM over many time steps. The comment is specific in detailing what needs to be addressed, including the observation of inconsistent motion, changing color, and object disappearing over time in the synthesized results for UCF101. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is interesting and extensive in its experiments, noting that the results are still not perfect but show improvement over the previous stateoftheart. However, the comment lacks specific evidence or references to support these claims, such as detailed comparisons with previous work or specific metrics demonstrating the improvement. Without concrete examples or detailed reasoning, the claim is difficult to verify, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides feedback on the paper\"s approach by suggesting the use of longer video sequences to better capture motion, color, and object changes. It acknowledges the paper\"s interesting idea and extensive experiments, noting that the results are still not perfect but show improvement over the previous stateoftheart. However, the comment lacks specific guidance on how to implement the suggestion of using longer video sequences or what additional experiments could be conducted to address the identified issues. While it offers a direction for improvement, the feedback is somewhat limited in its actionable and detailed nature, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the cost of insurance for men and women after the method is applied. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or what steps they should consider to provide a comprehensive answer. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the cost of insurance for men and women after a method is applied, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide any details or context about the method or the insurance cost, leaving the authors without a clear understanding of what needs to be addressed. Therefore, this comment is 2, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the cost of insurance for men and women after a method is applied. However, it does not provide any context, reasoning, or references to support the question or its relevance to the paper. Without additional information or justification, the authors are left without a basis to understand or address the question. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the cost of insurance for men and women after a method is applied. However, it does not provide any context, reasoning, or suggestions for how the authors might address this question or what information would be relevant. The comment lacks depth and actionable guidance, leaving the authors without a clear understanding of how to improve their draft. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the paper\"s categorization method, noting that splitting papers based on publication years on the ACL anthology might be inaccurate due to the availability of some papers on arXiv before the anthology. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to their categorization method. The action is implicit, as the authors need to infer that they should consider the arXiv dates when categorizing the papers. While the comment identifies a potential problem, it lacks concrete instructions on how to implement the suggested change, making it 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the categorization of papers based on publication years on the ACL anthology, noting that some papers are available on arXiv earlier than the anthology. However, it does not explicitly mention which part of the paper this issue pertains to, such as a specific section or table. This makes it weakly grounded, as the authors may need to infer the relevant section. The comment is specific in detailing the issue with the categorization method, but without explicit grounding, the authors may find it challenging to pinpoint the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s categorization method, which splits papers according to their publication years on the ACL anthology, is inaccurate because many papers are posted on arXiv much earlier than the anthology. The example provided, such as the BERT paper being available on arXiv in October, supports the claim. However, the comment lacks specific examples or references to other papers that might have been posted earlier on arXiv, which could strengthen the argument. While the reasoning is logical, the lack of detailed evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s categorization method, specifically noting that splitting papers based on publication years on the ACL anthology might be inaccurate due to the availability of some papers on arXiv before the anthology. The example provided, such as the BERT paper being available on arXiv in October, effectively illustrates the concern. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or improve their categorization method. Without actionable feedback or specific recommendations, the authors may find it challenging to understand how to proceed. Therefore, the comment is 3, as it highlights a potential problem but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two distinct issues regarding the proposed relaxation of rejection sampling and the differences between QRS and RS in Algorithm 1. For the first issue, the reviewer questions the rationale behind not using importance sampling, which is a direct action for the authors to clarify. However, the action is somewhat vague as it does not provide specific guidance on how to address the concern. For the second issue, the reviewer points out a lack of clarity in distinguishing QRS and RS, which is also somewhat vague. While the comment provides explicit actions for the authors to address, the lack of detailed guidance on how to implement these actions makes the comment 3. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses two specific issues related to the relaxation of rejection sampling and the differences between QRS and RS in Algorithm 1. It explicitly mentions the use of an arbitrary parameter \u03b2 instead of the true upper bound of the ratio p q, and it questions the rationale for not using importance sampling. Additionally, it highlights the lack of clarity in distinguishing QRS and RS, which is a specific issue that needs to be addressed. The comment is fully grounded as it clearly identifies the parts of the paper being discussed, and it is specific as it provides detailed feedback on the issues. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point raises two distinct issues: the rationale behind not using importance sampling and the differences between QRS and RS in Algorithm 1. The first part of the comment questions the authors\" decision to use an arbitrary parameter \u03b2 instead of the true upper bound of the ratio p q, which is a valid question that requires further explanation. The second part of the comment highlights a lack of clarity in distinguishing QRS and RS, which is also a valid point that needs clarification. However, the comment does not provide specific examples or references to support these claims, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises two distinct issues that could be helpful for the authors to address. First, it questions the rationale behind using an arbitrary parameter \u03b2 instead of the true upper bound of the ratio p q, which is a valid point that could be clarified. Second, it points out a lack of clarity in distinguishing between QRS and RS in Algorithm 1, which could be addressed by providing more detailed explanations or examples. However, the comment lacks depth and does not offer specific guidance or suggestions on how to address these issues, making it 3. The feedback is incomplete and could be more actionable with additional details, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the phrase \"nonsequential information such as chunks\" and asks for clarification on whether chunks are still sequential information. While the comment identifies a specific point of confusion, it does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit, as the authors need to infer that they should clarify the meaning of \"chunks\" in the context of the paper. However, the comment lacks concrete details on how to implement this clarification, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it directly questions the clarity of the phrase \"nonsequential information such as chunks\" and asks for clarification on whether chunks are still sequential information. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point raises a question about the phrase \"nonsequential information such as chunks\" and asks for clarification on whether chunks are still sequential information. This is a subjective question that seeks clarification rather than making a claim that requires verification. The comment does not provide any evidence, reasoning, or references to support the question, making it a normal statement. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment raises a specific question about the phrase \"nonsequential information such as chunks\" and asks for clarification on whether chunks are still sequential information. This feedback is clear and actionable, as it identifies a point of confusion in the paper and prompts the authors to clarify their terminology. By addressing this question, the authors can improve the clarity and precision of their writing, making the paper easier to understand. However, the comment could be more helpful if it provided additional context or suggested specific ways to clarify the term. Overall, the comment is 4 as it identifies a specific area for improvement and encourages the authors to address it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the limited technical novelty of the paper, suggesting that it is similar to previous works that focus on graphbased approaches, coattention mechanisms, and architectures. However, it does not provide explicit guidance on how the authors might address this issue or what specific aspects of the paper could be improved to enhance its novelty. The comment lacks concrete suggestions or actionable steps for the authors to take, leaving them uncertain about how to proceed. As a result, the comment is 1, as it does not provide the authors with a clear path forward to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the two papers, Xing and Tsang, 2022a, b, which allows the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of limited technical novelty and suggests that the paper is similar to previous works in terms of idea, coattention mechanism, and architecture. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point claims that the paper has limited technical novelty, as it is similar to previous works that focus on graphbased approaches, coattention mechanisms, and architectures. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references or detailed comparisons that would help the authors understand the extent of the similarity or novelty. Without this additional information, the claim is difficult to verify, making the comment 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the limited technical novelty compared to previous works. It highlights that the paper is similar to previous studies that focus on graphbased approaches, coattention mechanisms, and architectures. This feedback is valuable as it points out a potential area for improvement, suggesting that the authors need to differentiate their work more effectively from existing literature. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue, such as proposing novel techniques or applications. Without actionable advice, the comment is 3, as it provides a clear direction for improvement but lacks depth and specificity. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the problem to other downstream tasks or if it is specific to binding affinity prediction. While it prompts the authors to consider this aspect, it does not provide explicit guidance on how to address it or what changes might be necessary. The action is implicit, as the authors need to infer that they should explore the broader applicability of their work. However, the comment lacks concrete details on how to implement this exploration, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the problem to other downstream tasks or if it is specific to binding affinity prediction. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is 1 as it lacks specific references or context. Additionally, it does not provide detailed guidance on how to address the question or what changes might be necessary. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the applicability of the problem to other downstream tasks or if it is specific to binding affinity prediction. However, it does not provide any claim, assertion, or suggestion that requires verification or justification. The comment is purely descriptive and does not offer any insight or guidance that would help the authors understand or address the issue. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment raises a question about the applicability of the problem to other downstream tasks or if it is specific to binding affinity prediction. This question prompts the authors to consider the broader context and potential applications of their work. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address this question or what changes might be necessary. While it identifies an area for improvement, it does not offer actionable feedback that would empower the authors to enhance their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the comparison of computation cost or running time, but it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what changes could be made to the draft to include such a comparison. Without specific instructions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the comparison of computation cost or running time, but it does not specify which part of the paper this comparison is intended for or how it relates to the content of the draft. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to address the comparison or what aspects of the paper need to be revised. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the comparison of computation cost or running time, but it does not provide any specific reasoning, examples, or references to support why this comparison is important or how it should be addressed. The comment lacks depth and does not offer any guidance or justification for the suggestion, making it difficult for the authors to understand the basis for the request. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the comparison of computation cost or running time, which is a relevant aspect for evaluating the efficiency and practicality of the proposed method. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or what changes could be made to their draft to include such a comparison. Without actionable feedback or detailed suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it identifies a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the division of tables in Section 3, specifically questioning whether one type (the column header) should be included. While the comment implies that the current division might be redundant or unnecessary, it does not provide explicit guidance on how the authors should revise the tables or what specific changes are needed. The action is implicit, as the authors need to infer that they should consider removing or consolidating the table division. However, the comment lacks concrete details on how to implement this suggestion, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3 (line 247252)\" and the specific issue regarding the division of tables. It clearly specifies what the authors should consider, questioning whether one type (the column header) should work. This provides the authors with a clear understanding of the part of the paper being addressed and the specific issue to address. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point raises a question about the division of tables in Section 3, specifically questioning whether one type (the column header) should work. However, it does not provide any claim, suggestion, or critique that requires verification or justification. The comment is purely descriptive and does not offer any new information or reasoning that would help the authors understand or address the issue. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the division of tables in Section 3, specifically questioning whether one type (the column header) should work. While it identifies a potential issue with the organization of the tables, it does not provide any suggestions or guidance on how the authors might address this concern. The comment lacks actionable feedback, as it does not offer any specific advice or recommendations for improvement. Therefore, it is 2, as it only points out a potential area for clarification without providing any actionable steps for the authors to take. This aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the task might be closer to Argument Mining than Summarization and recommends that the paper further clarify the differences between the two. While the comment implies an action\u2014further clarifying the distinctions\u2014it does not provide explicit guidance on how to achieve this clarification. The authors are left to infer that they need to elaborate on the differences, but the comment lacks concrete details on what specific aspects need clarification. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment suggests that the task might be closer to Argument Mining than Summarization and recommends that the paper further clarify the differences between the two. However, it does not specify which part of the paper this clarification should be made, leaving the authors to infer that it pertains to the methodology or results sections. The comment is specific in its suggestion to clarify the differences but lacks grounding as it does not pinpoint the exact section or part of the paper that needs clarification. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the task might be closer to Argument Mining than Summarization and recommends that the paper further clarify the differences between the two. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors are left to interpret the suggestion, making it difficult to fully understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the task might be closer to Argument Mining than Summarization and recommends that the paper further clarify the differences between the two. This feedback is 3 as it points out a potential area for clarification that could enhance the paper\"s focus and understanding. However, the comment lacks depth and specificity, as it does not provide detailed guidance on how to distinguish between the two tasks or what aspects of the paper need clarification. Without concrete suggestions or examples, the authors may struggle to fully address the feedback, making the comment 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the specific definition of the sparsity of the residual term, asking whether it implies the inclusion of many zero elements. It also suggests that the authors should provide evidence to support the sparsity assumption across various noisy cases and compare the advantages of their proposed method with existing methods. While the comment explicitly asks for clarification and provides a clear direction for the authors to address the issue, it lacks concrete guidance on how to demonstrate the advantages of the proposed method or how to provide evidence for the sparsity assumption. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the specific issue of the sparsity of the residual term in the paper, which is a clear and specific concern. It questions the definition of sparsity and requests evidence to support the assumption across various noisy cases. The comment is fully grounded as it explicitly mentions the part of the paper being addressed, and it is specific in detailing what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the specific definition of the sparsity of the residual term, asking whether it implies the inclusion of many zero elements. It also suggests that the authors should provide evidence to support the sparsity assumption across various noisy cases and compare the advantages of their proposed method with existing methods. While the comment raises a valid point about the need for clarification and evidence, it lacks specific examples or references to support the claim that the sparsity assumption is not welljustified. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the definition of the sparsity of the residual term in the paper. It questions whether the term implies the inclusion of many zero elements and requests evidence to support the sparsity assumption across various noisy cases. Additionally, the comment suggests that the authors should demonstrate the advantages of their proposed method compared to existing methods. This feedback is clear and actionable, providing the authors with specific areas to address and improve their work. However, it could be more helpful if it included examples or detailed guidance on how to demonstrate the advantages of the proposed method. Overall, the comment is 4, as it offers valuable insights and directions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the toylike nature of the models and datasets used in the paper, suggesting that more challenging datasets like CIFAR100, ResNet 34 or 50, and ViTtiny or small should be considered. The comment also questions the feasibility of experimenting on language tasks. While the comment implies that the authors should address these issues, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the models and datasets used in the paper, suggesting that they are too toylike. It specifically mentions the need to include more challenging datasets like CIFAR100, ResNet 34 or 50, and ViTtiny or small. However, the comment does not specify which part of the paper discusses the models and datasets, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the models and datasets used in the paper, suggesting that they are too toylike and that more challenging datasets like CIFAR100, ResNet 34 or 50, and ViTtiny or small should be considered. However, the comment does not provide specific reasoning or examples to support why these datasets are necessary or how they would improve the paper. Without detailed justification or references, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out that the models and datasets used are too simplistic. It suggests that the authors should consider using more challenging datasets, such as CIFAR100, ResNet 34 or 50, and ViTtiny or small, to better evaluate their models. Additionally, the comment raises a question about the feasibility of experimenting on language tasks, which could be a valuable point for discussion. However, the comment lacks specific guidance on how to address these issues or what experiments could be conducted to improve the paper. While it provides a clear direction for improvement, the feedback could be more helpful if it included detailed suggestions or examples of how to implement the recommendations. Therefore, the comment is 3, as it highlights important areas for enhancement but does not provide comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant gap in the paper by noting the absence of a comparison against baselines. It points out that the functionality similarity comparison study only reports accuracy across optimization levels of binaries, without considering any baselines. The comment suggests that many papers have developed architectureagnostic similarity comparison or reported it as codesearch, which are similar tasks. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting specific baselines to include or how to conduct a more comprehensive comparison. While the action is implied, it is vague and lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment addresses the lack of comparison against baselines in the functionality similarity comparison study, specifically mentioning that the study only reports accuracy across optimization levels of binaries without considering baselines. It also notes that many papers have developed architectureagnostic similarity comparison or reported it as codesearch, which are similar tasks. However, the comment does not specify which part of the paper this issue is discussed in, such as a specific section or table. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs attention. The comment is specific in detailing the issue of missing baselines and the relevance of similar tasks in other papers, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a comparison against baselines in the functionality similarity comparison study, specifically noting that the study only reports accuracy across optimization levels of binaries without considering baselines. It also mentions that many papers have developed architectureagnostic similarity comparison or reported it as codesearch, which are similar tasks. However, the comment does not provide specific examples or references to support the claim that these baselines are widely understood or commonly used. While the reasoning is somewhat logical, the lack of detailed examples or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of a comparison against baselines in the functionality similarity comparison study. It highlights that the study only reports accuracy across optimization levels of binaries without considering baselines, which is a critical oversight. The comment also notes that many papers have developed architectureagnostic similarity comparison or reported it as codesearch, which are similar tasks. This feedback is valuable as it directs the authors to include a more comprehensive comparison, thereby enhancing the depth and rigor of their analysis. However, the comment could be more helpful if it provided specific examples of baselines or suggested how to conduct a more thorough comparison. Overall, the comment is 4 as it identifies a key area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a concern that the contribution of the paper is not enough, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, the comment does not provide any explicit or implicit suggestions on how the authors might improve their draft to address this concern. It lacks concrete guidance on what specific aspects of the contribution could be expanded or enhanced. Without actionable advice, the authors are left without a clear path to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the contribution of the paper, which is the overfitting problem of training GANs with limited data and the proposed differentiable augmentation. This allows the authors to accurately identify the part of the paper being addressed. However, the comment is not specific because it does not provide detailed guidance on how the authors might address the issue of limited data or how they could enhance the contribution of their work. It lacks specific suggestions or examples of how to improve the paper. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the contribution of the paper is not enough, specifically mentioning the overfitting problem of training GANs with limited data and the proposed differentiable augmentation. However, the comment lacks specific evidence or reasoning to support this claim. It does not provide examples, references, or detailed explanations of why the contribution is insufficient. Without this additional context, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically the limited contribution of addressing the overfitting problem of training GANs with limited data and the proposed differentiable augmentation. While the comment highlights an important factor, it lacks actionable suggestions or guidance on how the authors might enhance their contribution or address the identified issue. Without specific advice or examples, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is 2, as it provides a general critique but lacks depth and actionable insights."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It also mentions that this is acknowledged by the authors in Section 3, where they state that normalizing the input makes the results from Theorem 1 inapplicable. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary to the proof technique. The action is implicit and vague, as it does not specify how the authors should modify the proof or what specific aspects need to be revised. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W2.3. Proof Technique\" and \"Section 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the reliance on a special case where a contradiction arises as matrix norms approach infinity and the inapplicability of results from Theorem 1 due to normalization. This provides clear guidance on how the authors should revise their proof technique. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proof technique relies on a special case where a contradiction arises as matrix norms approach infinity, which is acknowledged by the authors in Section 3. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks sufficient evidence or references to substantiate the assertion that this is a significant issue or a common problem in the field. Without additional context or justification, the claim remains 3, as it is based on an observation without thorough explanation or supporting evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It also mentions that this is acknowledged by the authors in Section 3, where they state that normalizing the input makes the results from Theorem 1 inapplicable. This feedback is 3 as it points out a potential limitation in the proof technique and highlights an area where the authors might need to reconsider their approach or provide additional context. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might address this issue or improve the robustness of their proof. Overall, the comment provides a clear indication of a weakness but lacks depth in terms of actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity. It also expresses a concern that allowing \"t\" to be arbitrary does not add value. While the comment provides a specific suggestion for improvement, it does not explicitly instruct the authors to make this change or provide detailed guidance on how to implement it. The action is somewhat explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment addresses the histogram intersection kernel and suggests replacing \"t\" with the size of T for clarity. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion regarding the clarity of the notation, but without explicit references to the paper, the authors may find it challenging to pinpoint the exact section. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity. However, it does not provide any reasoning, examples, or references to support why this change would be beneficial or how it would enhance the paper. The comment lacks detailed justification, making it difficult for the authors to understand the basis of the suggestion and whether it is a valid improvement. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the histogram intersection kernel by replacing \"t\" with the size of T. This feedback is actionable and directly addresses a potential area of confusion for the authors. However, the comment lacks broader context or suggestions for other areas that could be improved, which limits its overall impact. While it offers a clear and constructive suggestion, it does not provide a comprehensive guide for enhancing the draft, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the assumption of the general Gaussian distribution in the proposed algorithm, suggesting that it might be possible to assume an isotropic Gaussian instead. However, it does not provide any explicit guidance or suggestions on how the authors should address this question or what changes might be necessary. The comment lacks concrete actions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm, suggesting that it might be possible to assume the latter. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact area where the comment is relevant. While the comment is specific in its inquiry about the distribution assumption, the absence of explicit grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. It does not contain any subjective opinions, claims, or suggestions that require verification. The comment is purely factual and descriptive, aligning with the classification of \"X.\" Therefore, it is labeled as \"X.\"", "helpfulness_rationale": "The review comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. It prompts the authors to consider whether it is possible to assume the latter and asks for clarification on the difference between the two assumptions. While the comment identifies a potential area for clarification and exploration, it does not provide specific guidance or suggestions on how the authors might address this question or what changes could be made to the algorithm. The feedback is 3 as it highlights a potential area for improvement, but it lacks depth and actionable advice, making it only 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the intent of Section 5.2, but it does not provide any explicit or implicit suggestions on how the authors should address this question or what changes might be needed. Without further guidance or clarification, the authors are left without a clear understanding of what action to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the section or figure being referred to. Additionally, the comment is not specific because it does not provide any details on what is intended or how it should be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the intent of Section 5.2 but does not provide any claim, suggestion, or critique that requires verification. It is a factual question that does not offer any guidance or insight into how the authors should improve their work. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the intent of Section 5.2, which could be helpful for the authors to clarify their writing or improve the flow of the paper. However, it does not provide any specific suggestions or guidance on how to address this question or what changes might be needed. The comment lacks actionable feedback, making it 2 as it does not offer any actionable steps for the authors to take. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the need for careful selection of basis functions and meshes, as well as the assembly of stiffness matrices, particularly in the context of the current work, which heavily relies on FEniCS. The comment also notes that while current operator learning methods may not yet achieve the same accuracies as specialized numerical solvers, they are more universal and do not require adaptation to specific PDEs. However, the comment does not provide explicit or implicit suggestions on how the authors might address these issues or improve their approach. The feedback lacks concrete guidance on potential modifications or strategies to enhance the proposed method, leaving the authors without clear direction on how to proceed. As a result, the comment is 1, as it does not offer actionable steps for the authors to take to improve their draft.", "grounding_specificity_rationale": "The comment critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the need for careful selection of basis functions and meshes, as well as the assembly of stiffness matrices, particularly in the context of the current work, which heavily relies on FEniCS. The comment also notes that while current operator learning methods may not yet achieve the same accuracies as specialized numerical solvers, they are more universal and do not require adaptation to specific PDEs. However, the comment does not specify which part of the paper this critique is directed towards, making it difficult for the authors to identify the exact section being addressed. While the critique provides some specificity regarding the issues raised, the lack of explicit grounding makes it challenging for the authors to understand which parts of the paper need revision. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the need for careful selection of basis functions and meshes, as well as the assembly of stiffness matrices, particularly in the context of the current work, which heavily relies on FEniCS. The comment also notes that while current operator learning methods may not yet achieve the same accuracies as specialized numerical solvers, they are more universal and do not require adaptation to specific PDEs. However, the comment lacks specific examples or detailed reasoning to fully substantiate these claims, making it 3. The authors would need to provide more evidence or examples to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the need for careful selection of basis functions and meshes, as well as the assembly of stiffness matrices, particularly in the context of the current work, which heavily relies on FEniCS. The comment also notes that while current operator learning methods may not yet achieve the same accuracies as specialized numerical solvers, they are more universal and do not require adaptation to specific PDEs. However, the comment does not provide specific suggestions or actionable feedback on how the authors might address these issues or improve their approach. While it identifies a potential area for improvement, it lacks detailed guidance or examples, making it 3. The authors would need to infer potential improvements based on the feedback, which limits the overall helpfulness of the comment."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses confusion about whether the paper targets singletoken or multitoken cloze queries, noting that this distinction is not clear until the conclusion. While the comment identifies a potential issue with clarity, it does not provide explicit guidance on how the authors should address this confusion or clarify the distinction in their draft. The action is implicit, as the authors would need to infer that they should clarify the target queries in the introduction or methodology sections. However, the lack of specific guidance on how to clarify the distinction makes the action vague and less actionable. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment expresses confusion about whether the paper targets singletoken or multitoken cloze queries, noting that this distinction is not clear until reading the conclusion. However, it does not specify which part of the paper this confusion pertains to, making it weakly grounded. The comment is specific in identifying the issue of clarity regarding the type of cloze queries targeted, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses confusion about whether the paper targets singletoken or multitoken cloze queries, noting that this distinction is not clear until reading the conclusion. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand the basis of the confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a potential confusion regarding the scope of the paper, specifically whether it targets singletoken or multitoken cloze queries. The reviewer notes that this distinction is not clear until reading the conclusion, which suggests a lack of clarity in the paper\"s focus. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or clarify the distinction in their draft. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the reproducibility of the results, questioning whether the code will be publicly available. While it identifies a potential issue, it does not provide any explicit or implicit suggestions on how the authors might address this concern. The comment lacks concrete guidance on what steps the authors should take to ensure reproducibility, such as providing detailed instructions or guidelines for sharing the code. As a result, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the reproducibility of the results, specifically questioning whether the code will be publicly available. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Additionally, the comment does not provide specific guidance or suggestions on how to address the reproducibility issue, such as proposing alternative methods for sharing the code or providing detailed instructions. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the reproducibility of the results, specifically questioning whether the code will be publicly available. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific details or examples that would help the authors understand the issue or how to address it. Without additional context or justification, the claim remains 1, making the comment unsuitable for guiding the authors to improve their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a concern about the reproducibility of the results, specifically questioning whether the code will be publicly available. This is a critical issue for scientific research, as reproducibility is essential for validating findings. However, the comment lacks actionable guidance or suggestions on how the authors might address this concern. It does not provide any specific steps or recommendations that could help the authors improve their draft, such as proposing alternative methods for sharing the code or providing detailed instructions. As a result, the comment is 2, as it identifies a significant issue but does not offer any concrete solutions or guidance for the authors to improve their work. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the technical contribution of the paper is limited because $kNNECD$ is very similar to $kNNMT$. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve the technical contribution or what specific aspects need to be revised. Without concrete suggestions or actionable steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment claims that the technical contribution of the paper is limited because $kNNECD$ is very similar to $kNNMT$. However, it does not specify which part of the paper this comparison is made or where the similarity is discussed. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its critique of the similarity between the two methods, but it lacks detailed guidance on how to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the technical contribution of the paper is limited because $kNNECD$ is very similar to $kNNMT$. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the technical contribution of the paper, suggesting that the similarity between $kNNECD$ and $kNNMT$ might limit the novelty of the work. However, the comment lacks specific details or actionable suggestions on how the authors might address this issue or enhance their contribution. Without further guidance or examples, the authors may struggle to understand the implications of this feedback or how to improve their work. Therefore, the comment is 2, as it provides a general observation but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the authors were unclear about the number of parameters used in each approach, as mentioned in Section B.3. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. The comment lacks guidance on what specific steps the authors should take to clarify the number of parameters or how to present this information effectively. As a result, the authors are left without a clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section B.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a lack of clarity regarding the number of parameters used in each approach, providing a clear direction for the authors to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the clarity of the numbers of parameters used in each approach, as mentioned in Section B.3. It does not contain any subjective opinions, suggestions, or claims that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment points out a specific issue in the paper, namely the lack of clarity regarding the number of parameters used in each approach, as mentioned in Section B.3. While it identifies a potential area for improvement, it does not provide any suggestions or guidance on how the authors might address this issue. The comment is clear and highlights a specific aspect of the paper that needs attention, but it lacks actionable advice or suggestions for improvement. Therefore, the comment is 3, as it provides a clear indication of a problem but does not offer comprehensive guidance for resolution."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the statistical significance of the evaluation results reported in Table 1, noting that the results are based on only three trials per case, which is not statistically significant. The comment suggests that the reported deviations are not meaningful and that the claims made based on these results are not valid. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to improve the statistical significance of their results. The action is implicit and vague, as it leaves the authors to infer that they need to increase the number of trials or reconsider their claims. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the statistical significance of the results reported in the table, explaining why the deviations are not meaningful and why the claims made based on these results are not valid. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation results in Table 1 are based on only three trials, which is not statistically significant. It suggests that the reported deviations are not meaningful and that the claims made based on these results are not valid. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of supporting evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical issue with the statistical significance of the evaluation results reported in Table 1, noting that the results are based on only three trials per case. This is a significant concern, as it undermines the reliability and validity of the reported deviations and claims. The comment suggests that the deviations are not meaningful and that the claims made based on these results are not valid. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as increasing the number of trials or reconsidering their claims. While it highlights a crucial weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a significant problem but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind the model size increase affecting performance, referencing a recent paper that suggests scaling laws apply to dense retrieval models. It implies that the authors should provide more detailed preliminary experimental results on Wikipedia to support their claims. However, the comment does not explicitly instruct the authors to provide these results or specify how to do so, leaving the action somewhat vague. The authors can infer that they need to provide more detailed results, but the lack of concrete guidance makes the action 3.", "grounding_specificity_rationale": "The comment questions the rationale behind the model size increase affecting performance, referencing a recent paper that suggests scaling laws apply to dense retrieval models. It implies that the authors should provide more detailed preliminary experimental results on Wikipedia to support their claims. However, the comment does not explicitly mention which part of the paper this issue is related to, such as specific sections or figures. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific about the issue of model size affecting performance, it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the rationale behind the model size increase affecting performance, referencing a recent paper that suggests scaling laws apply to dense retrieval models. It implies that the authors should provide more detailed preliminary experimental results on Wikipedia to support their claims. However, the comment lacks specific examples or detailed reasoning to substantiate the claim, making it difficult for the authors to understand and address the issue effectively. The absence of clear evidence or references weakens the verifiability of the claim, aligning with a score of 2.", "helpfulness_rationale": "The review comment raises a valid concern about the unexpected impact of increasing model size on performance, referencing a recent paper that suggests scaling laws apply to dense retrieval models. This observation highlights a potential inconsistency in the authors\" findings and suggests that providing more detailed preliminary experimental results on Wikipedia could help clarify the issue. However, the comment lacks specific guidance on how to address this concern or what additional experiments might be necessary. While it identifies a potential area for improvement, the feedback is somewhat limited in its actionable value, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses interest in knowing if other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or what steps they should consider. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses interest in knowing if other multilingual pretraining setups also struggle with Greek. However, it does not specify which part of the paper this question relates to, making it difficult for the authors to pinpoint the exact area that needs attention. The comment is 1 as it does not provide specific references or sections of the paper. Additionally, it lacks specificity in addressing the issue, as it does not provide any suggestions or guidance on how to investigate or address the question. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses interest in knowing if other multilingual pretraining setups also struggle with Greek. However, it does not provide any specific evidence, reasoning, or references to support this claim. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The comment expresses interest in knowing if other multilingual pretraining setups also struggle with Greek. However, it does not provide any specific feedback, suggestions, or guidance on how the authors might address this question or what steps they should consider. The comment lacks actionable insights and does not offer any constructive feedback that could help the authors improve their draft. Therefore, it is 2, as it does not provide any meaningful direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scope of the study, suggesting that the current approach of considering only one truck and one drone could be extended to multiple trucks and drones. While the comment implies that this extension would be more interesting and practical, it does not provide explicit guidance on how to implement this extension or what specific aspects of the current study need to be addressed to make this extension feasible. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to apply the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the scope of the study, suggesting that the current approach of considering only one truck and one drone could be extended to multiple trucks and drones. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or methodology. The comment is weakly grounded because the authors cannot confidently determine which part of the paper it addresses. It is also specific in that it suggests an interesting and practical extension to the study, but without grounding, the authors are left to make an educated guess about where to apply this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the scope of the study, suggesting that the current approach of considering only one truck and one drone could be extended to multiple trucks and drones. This is a logical suggestion that aligns with the idea of making the study more interesting and practical. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the claim is considered 2, as it lacks sufficient support to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment raises a question about the scope of the study, suggesting that the current approach of considering only one truck and one drone could be extended to multiple trucks and drones. This is a logical and interesting suggestion that could enhance the practicality and applicability of the research. However, the comment does not provide specific guidance on how to extend the study to multiple trucks and drones, nor does it offer any suggestions on how to implement this extension. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides a direction for future work but lacks detailed guidance for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that subtracting dynamic factors from dynamic information in Equation 8 might lead to the loss of some dynamic information, which could hinder the LSTM module\"s ability to capture complete dynamic changes. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the equation. The action is implicit and vague, as it does not specify how to mitigate the potential loss of dynamic information or how to ensure the LSTM module captures complete dynamic changes. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to Equation 8, which is a part of the paper. It provides a clear and specific explanation of a potential problem with the equation, suggesting that subtracting dynamic factors might lead to the loss of dynamic information, thereby affecting the LSTM module\"s ability to capture complete dynamic changes. This feedback is fully grounded as it explicitly mentions the part of the paper being addressed, and it is specific in detailing the issue and its potential impact. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that subtracting dynamic factors from dynamic information in Equation 8 might result in the loss of some dynamic information, which could hinder the LSTM module\"s ability to capture complete dynamic changes. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with Equation 8, specifically suggesting that subtracting dynamic factors might lead to the loss of dynamic information, which could affect the LSTM module\"s ability to capture complete dynamic changes. While the comment highlights a specific area that requires attention, it does not provide detailed guidance or suggestions on how to address this issue or what modifications might be necessary. The feedback is 3 as it points out a potential problem, but it lacks actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about the empirical impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. However, it does not provide explicit or implicit actions for the authors to take. The comment lacks guidance on how to address these questions or what experiments to conduct to explore these effects. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the empirical impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. However, it does not specify which part of the paper these questions relate to, such as specific sections, tables, or figures. This lack of grounding makes it difficult for the authors to identify the exact areas that need attention. While the questions are specific, the absence of grounding information limits the authors\" ability to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the empirical impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. However, it does not provide any claims, opinions, or suggestions that require verification or justification. The comment is purely descriptive and does not offer any guidance or insight that would help the authors improve their work. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises questions about the empirical impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. While it identifies areas that could be explored further, it does not provide specific guidance or suggestions on how to address these questions or what experiments to conduct. The feedback is 3 as it points out potential areas for improvement, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the metric learning theory in the paper, suggesting that it is not novel or better than existing theoretical results. It implies that the authors should consider how to improve the metric learning aspect of their work. However, the comment does not provide specific guidance on what changes or improvements could be made to address the identified issue. The action is implicit and vague, as the authors are left to infer that they need to enhance the metric learning section. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the metric learning theory in the paper, referencing the generalization theory of neural networks and suggesting that the proposed metric perspective analysis does not offer better results compared to previous work. It also notes that the part of metric learning in the paper does not seem to work. However, the comment does not specify which part of the paper discusses metric learning, making it difficult for the authors to pinpoint the exact section that needs improvement. While the comment is specific in its critique of the metric learning aspect, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the metric learning theory in the paper is not novel or better than existing theoretical results, referencing the generalization theory of neural networks. It suggests that the proposed metric perspective analysis does not yield better results compared to previous work. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The absence of references or detailed explanations weakens the verifiability of the claim, aligning with a score of 2.", "helpfulness_rationale": "The review comment critiques the metric learning theory in the paper, noting that it is not novel or better than existing theoretical results. It suggests that the proposed metric perspective analysis does not yield better results compared to previous work, and that the part of metric learning in the paper does not seem to work. While the comment identifies a potential weakness in the paper\"s theoretical contribution, it lacks specific guidance or suggestions on how the authors might address this issue or improve their work. The feedback is 3 as it points out an area for improvement, but it does not provide actionable steps or detailed advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential confusion in the notation used in the paper, specifically mentioning the use of \"r\" to denote both the risk for minimization problems and primal risk for minimax problems. While the comment identifies a potential issue with clarity, it does not provide explicit guidance on how the authors should address this confusion. The authors are left to infer that they need to clarify the notation, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it points out a specific issue but does not provide detailed guidance on how to resolve it.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the notation used in the paper, noting that using \"r\" to denote both the risk for minimization problems and primal risk for minimax problems can be confusing. This provides clear guidance on what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper this issue is discussed in, leaving the authors to infer that it relates to the notation section. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that using \"r\" to denote both the risk for minimization problems and primal risk for minimax problems is confusing. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors are left to infer the confusion, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the notation used in the paper, specifically the use of \"r\" to denote both the risk for minimization problems and primal risk for minimax problems. This observation highlights a potential source of confusion for the readers, as it could lead to misunderstandings. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their notation. While it points out a specific area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment questions the necessity of making claims about sparsity in training, suggesting that it is not obvious why sparsity is desirable. It also implies that the authors should demonstrate the benefits of sparsity, such as improved performance or cost savings, especially in the context of parallelized computation. However, the comment does not provide explicit guidance on how to address this issue or what specific actions the authors should take to improve their draft. The action is implicit and vague, as it does not specify how to demonstrate the benefits of sparsity or how to make the claims more convincing. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the necessity of making claims about sparsity in training, suggesting that it is not obvious why sparsity is desirable. It implies that the authors should demonstrate the benefits of sparsity, such as improved performance or cost savings, especially in the context of parallelized computation. However, the comment does not specify which part of the paper discusses sparsity or training, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the issue of sparsity and its relevance, it lacks grounding as it does not provide clear guidance on which part of the paper to address. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the necessity of making claims about sparsity in training, suggesting that it is not obvious why sparsity is desirable. It implies that the authors should demonstrate the benefits of sparsity, such as improved performance or cost savings, especially in the context of parallelized computation. However, the comment does not provide specific examples, references, or detailed reasoning to support its claim. The lack of evidence or detailed explanation makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some basis for questioning the claims but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment questions the necessity of making claims about sparsity in training, suggesting that it is not obvious why sparsity is desirable. It implies that the authors should demonstrate the benefits of sparsity, such as improved performance or cost savings, especially in the context of parallelized computation. However, the comment does not provide specific guidance or suggestions on how to address this issue or what additional evidence might be needed to support the claims. While it raises a valid point about the need for demonstration, it lacks actionable advice or detailed feedback on how to improve the draft. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer substantial guidance for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaningfulness of the geometry of the vector space used in the study. It suggests that the authors should provide evidence or analysis to support the claim that the space is meaningful, such as examining whether the addition of morphological variants results in semantically coherent outcomes. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide evidence or analysis to support the claim. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the meaningfulness of the geometry of the vector space used in the study, specifically questioning whether the space is meaningful and suggesting that the authors provide evidence or analysis to support this claim. It does not specify which part of the paper this question pertains to, making it weakly grounded. However, the comment is specific in its request for evidence or analysis, which would help the authors address the issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the meaningfulness of the geometry of the vector space used in the study, specifically questioning whether the space is meaningful and suggesting that the authors provide evidence or analysis to support this claim. The comment does not provide any specific examples, reasoning, or references to support the claim that the geometry of the space is meaningful. Without such evidence, the claim remains speculative and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the meaningfulness of the vector space used in the study, specifically questioning whether the geometry of the space is meaningful and whether the morphfitting results in a more meaningful space or just better embeddings. It suggests that the authors should provide evidence or analysis to support the claim that the space is meaningful, such as examining whether the addition of morphological variants results in semantically coherent outcomes. This feedback is 3 as it identifies a potential area for improvement and encourages the authors to provide evidence or analysis to support their claims. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct this analysis. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that if the authors did not see improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides an example, such as the potential for easier modeling of sequential relationships in a recurrent model. However, the comment does not explicitly instruct the authors on how to implement this suggestion or what specific aspects to focus on. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking at accuracy or specific properties. However, it does not specify which part of the paper this issue is related to, such as a particular section or table. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to understand which part of the paper to focus on. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that if the authors did not see improvements in FLOPs or inference time, they should consider looking at accuracy or specific properties. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this suggestion is relevant or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a suggestion for the authors to consider if they did not see improvements in FLOPs or inference time, suggesting they should look for improvements in accuracy or specific properties. While the comment offers a potential direction for exploration, it lacks specific guidance on which aspects to focus on or how to approach this analysis. The suggestion is 3 as it prompts the authors to consider alternative metrics or properties, but it does not provide detailed instructions or examples, which could limit its effectiveness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the clarity of how the authors arrived at the different components of the \"scoring function\" and the different threshold values/ranges. While it acknowledges that the information is unclear, it does not provide explicit guidance on how the authors should address this issue or what steps they should take to clarify the process. The comment is vague and lacks concrete suggestions, making it difficult for the authors to know how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the clarity of how the authors arrived at the different components of the \"scoring function\" and the different threshold values/ranges. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to identify the exact area that needs clarification. While the comment is specific in its critique, the absence of grounding information makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the clarity of how the authors arrived at the different components of the \"scoring function\" and the different threshold values/ranges. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of how the authors arrived at the different components of the \"scoring function\" and the different threshold values/ranges. This feedback is valuable as it highlights a potential issue with the transparency and reproducibility of the methodology. However, the comment lacks actionable guidance on how the authors might address this issue, such as suggesting specific steps or providing additional context. While it points out a potential weakness, it does not offer detailed advice on how to improve the clarity or transparency of the scoring function. Therefore, the comment is 3, as it provides a clear area for improvement but lacks depth in terms of actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the model comparison by highlighting the limitation of the dataset selection, specifically noting that only one dataset contains categorical features, while the others are exclusively numerical. It also points out the absence of onehot encoding for the categorical dataset, which could negatively impact model performance. While the comment identifies specific issues with the dataset selection and the lack of onehot encoding, it does not provide explicit guidance on how the authors should address these issues or what changes should be made to the draft. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, namely the model comparison section. It provides detailed feedback on the dataset selection, noting that only one dataset contains categorical features while the others are exclusively numerical. This feedback is specific, as it highlights a particular issue with the dataset selection and suggests that the authors should consider employing onehot encoding for the categorical dataset. The comment is clear and provides specific guidance on how the authors can improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the model comparison by highlighting the limitation of the dataset selection, specifically noting that only one dataset contains categorical features while the others are exclusively numerical. It also points out the absence of onehot encoding for the categorical dataset, which could negatively impact model performance. The comment provides a clear and logical explanation of why the dataset selection is inadequate and suggests a specific improvement (onehot encoding). However, it lacks references to external sources or detailed examples to fully substantiate the claim. Therefore, the comment is 4, as it provides a reasonable basis for the critique but could be strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment provides a detailed critique of the model comparison section, highlighting a significant limitation in the dataset selection. It points out that only one dataset contains categorical features, while the others are exclusively numerical, which may affect the generalizability of the conclusions. Additionally, the comment notes the absence of onehot encoding for the categorical dataset, which could negatively impact model performance. This feedback is specific and actionable, as it identifies a clear weakness in the model comparison and suggests a specific improvement (onehot encoding). However, the comment could be more helpful if it provided additional guidance on how the authors might address this issue or what alternative approaches they could consider. Overall, the comment is 4, as it offers valuable insights and actionable feedback that can guide the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the choice of IoT datasets, specifically FlatCam Face [26] and Headpose detection [11], is unpopular and outdated. The authors are questioned about why these datasets were chosen, and the comment suggests that better options, such as wearable health or mobile activity recognition data, or data from UCI, might have been more appropriate. While the comment identifies a potential issue with the dataset selection, it does not provide explicit guidance on how the authors should address this concern or what specific datasets they should consider. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative datasets and potentially reevaluate their benchmarking results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the popularity and relevance of the IoT datasets used, suggesting that the choice of these datasets is questionable. The comment provides clear guidance on what needs to be addressed, recommending the inclusion of better options for IoT benchmarking. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the choice of IoT datasets, specifically FlatCam Face [26] and Headpose detection [11], is unpopular and outdated, questioning the authors\" rationale for selecting these datasets. The comment suggests that better options, such as wearable health or mobile activity recognition data, or data from UCI, might be more appropriate. However, the comment lacks specific examples or references to support the claim that these datasets are indeed unpopular or outdated. Without detailed justification or evidence, the claim remains 3, as the authors may need to conduct further research to substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the choice of IoT datasets used in the paper, noting that the selected datasets, FlatCam Face [26] and Headpose detection [11], are unpopular and outdated. The authors are questioned about their rationale for choosing these datasets, and the comment suggests that better options, such as wearable health or mobile activity recognition data, or data from UCI, might be more appropriate. This feedback is 3 as it highlights a potential weakness in the dataset selection and provides suggestions for improvement. However, the comment could be more helpful if it offered more detailed guidance on why these alternative datasets are better or how they might impact the results. Overall, the comment provides a clear direction for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the authors\" claim about the placement of the regret bound and the reviewer\"s inability to find it in the supplementary material. While the comment points out a potential issue with the authors\" claim, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should doublecheck the placement of the regret bound in the appendix or supplementary material. However, the comment lacks concrete details on how to implement this action, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the authors\" claim about the placement of the regret bound in the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the authors did not find the regret bound for the minibatch estimator in the supplementary material, and it references a specific paper [1] that might contain relevant information. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" claim about the regret bound being cast to the appendix is not supported by the supplementary material. However, the comment does not provide any specific evidence or reasoning to substantiate this claim. It lacks detailed references or examples that would allow the authors to verify the claim. As a result, the claim is 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the authors\" claim regarding the placement of the regret bound in the appendix. It points out that the authors did not find the regret bound for the minibatch estimator in the supplementary material, referencing a specific paper [1] that might contain relevant information. This feedback is clear and actionable, as it directs the authors to doublecheck the placement of the regret bound and consider the provided reference. However, the comment could be more helpful if it offered additional guidance on how to address the issue or suggested alternative approaches. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This observation identifies a key weakness of the method. However, the comment does not provide any explicit or implicit suggestions on how to address this issue or improve the method. The authors are left without guidance on what steps to take to enhance their work, making the comment 1. Therefore, this comment aligns with a score of 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the proposed compression\" and \"PQ,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by stating that the proposed compression performs worse than PQ when a small code length is allowed, which is a clear and specific critique. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point claims that the proposed compression performs worse than PQ when a small code length is allowed, which is identified as the main weakness of the method. However, the comment lacks specific evidence or references to support this claim. Without additional context or data, the authors may find it challenging to understand the basis of this claim or how to address it. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This observation highlights a critical area for improvement, as it points out a limitation of the method that could impact its practical applicability. However, the comment does not provide any suggestions or guidance on how to address this issue or enhance the method. While it identifies a significant concern, the lack of actionable feedback limits its helpfulness to the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the extraction of proportions from documents and sentences, specifically asking for clarification on how these parts are extracted and whether the extraction rules have an effect on the experiment. It also suggests a more detailed analysis. While the comment explicitly asks for clarification and suggests a more detailed analysis, it does not provide explicit instructions on how to conduct the analysis or what specific aspects need to be detailed. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"p indicates the proportion of documents,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what the authors need to clarify: how the parts of sentences and documents are extracted and whether the extraction rules have an effect on the experiment. The request for a more detailed analysis further clarifies the need for additional information. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the extraction of proportions from documents and sentences, specifically asking for clarification on how these parts are extracted and whether the extraction rules have an effect on the experiment. It also suggests a more detailed analysis. However, the comment does not provide any evidence, reasoning, or references to support these claims or questions. The authors are left to interpret the questions and decide how to address them, which makes the comment 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the extraction of proportions from documents and sentences, specifically asking for clarification on how these parts are extracted and whether the extraction rules have an effect on the experiment. It also suggests a more detailed analysis. While the comment identifies a potential area for clarification and improvement, it lacks specific guidance or suggestions on how to address these issues or what kind of analysis would be beneficial. The feedback is 3 as it points out a need for more detail, but it does not provide actionable steps or examples for the authors to follow. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the content on lines 107114 is speculative or overly opinionated and recommends it be stated as a remark, included in a Discussion section, or removed. This provides the authors with clear guidance on how to address the issue, making the comment 5. The explicit suggestion to either rephrase, include in a discussion, or remove the content gives the authors a direct path to improvement.", "grounding_specificity_rationale": "The comment suggests that the content on lines 107114 is speculative or overly opinionated and recommends it be stated as a remark, included in a Discussion section, or removed. This provides the authors with clear guidance on how to address the issue, making the comment 5. However, the comment does not specify which part of the paper this refers to, leaving the authors to infer that it is the content on lines 107114. Therefore, the comment is fully grounded but lacks specificity, aligning with a score of 4.", "verifiability_rationale": "The review point suggests that the content on lines 107114 is speculative or overly opinionated and recommends it be stated as a remark, included in a Discussion section, or removed. While the comment provides a clear recommendation, it lacks specific examples or references to support the claim that the content is speculative or overly opinionated. This makes the claim 3, as the authors would need to independently assess the content to fully understand the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific section of the paper (lines 107114) as being speculative or overly opinionated, suggesting that it should be rephrased, included in a discussion section, or removed. This feedback is clear and actionable, providing the authors with a direct path to improve the draft by addressing the speculative nature of the content. However, the comment could be more helpful if it offered additional guidance on how to rephrase the content or suggested specific ways to integrate it into a discussion section. Overall, the comment is 4 as it highlights an important issue and provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. While it highlights a lack of clarity in the motivation, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the motivation need clarification. The action is implicit, as the authors would need to infer that they should provide a clearer explanation of the motivation behind their choice of distributions. However, the comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment questions the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to identify the exact section they need to address. While the comment is specific in questioning the motivation, the absence of grounding information makes it challenging for the authors to understand the context and relevance of the question. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. However, it does not provide any specific reasoning, examples, or references to support why this choice is unclear or problematic. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a valid concern about the lack of clarity in the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. This feedback is 3 as it identifies a potential area for improvement in the paper, specifically regarding the explanation of the chosen distributions. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as suggesting alternative distributions or providing a more detailed rationale for their choice. Without actionable advice, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the clarity of how quantitative results are obtained, specifically asking for details on the data used for training, validation, and testing. While the comment identifies a lack of clarity, it does not provide explicit guidance on what actions the authors should take to address this issue. The authors are left to infer that they need to clarify these details in their draft, but the comment lacks concrete suggestions on how to do so. Therefore, the comment is 3, as it points out a specific area needing clarification but does not provide detailed guidance on how to implement the suggestion.", "grounding_specificity_rationale": "The comment raises a question about the clarity of how quantitative results are obtained, specifically asking for details on the data used for training, validation, and testing. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table. This makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its request for details, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the clarity of how quantitative results are obtained, specifically asking for details on the data used for training, validation, and testing. This is a factual question that requires the authors to provide additional information to ensure the reproducibility and transparency of their results. However, the comment does not offer any suggestions or reasoning to address this issue, making it a normal statement rather than a claim. Therefore, it should be classified as \"No\"", "helpfulness_rationale": "The review comment identifies a critical gap in the paper by questioning the clarity of how quantitative results are obtained, specifically asking for details on the data used for training, validation, and testing. This feedback is valuable as it highlights a lack of transparency and reproducibility in the methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending additional explanations or clarifications. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it identifies a significant issue but does not offer comprehensive guidance for resolution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the SE framework can help improve the paper and suggests that the authors should provide more context on why and how it manages to achieve these results. It also mentions that the authors could consider increasing the rating based on their response. However, the comment does not explicitly instruct the authors to provide specific details or actions to address the question. While it implies that the authors should elaborate on the benefits of the SE framework, the lack of explicit guidance makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about how the SE framework can help improve the paper, suggesting that the authors should provide more context on why and how it manages to achieve these results. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment also references a similar point in the review, indicating that the authors should show their work and reasoning, but it does not provide specific guidance on what needs to be shown. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about how the SE framework can help improve the paper and suggests that the authors should provide more context on why and how it manages to achieve these results. It references a similar point in the review, indicating that the authors should show their work and reasoning. However, the comment lacks specific examples or detailed reasoning to support the claim that the authors should provide more context. It does not offer a clear justification for why the authors should address this issue, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about how the SE framework can help improve the paper and suggests that the authors should provide more context on why and how it manages to achieve these results. It references a similar point in the review, indicating that the authors should show their work and reasoning. However, the comment lacks specific guidance or suggestions on how the authors can address this issue, making it 3. While it identifies a potential area for improvement, it does not provide detailed feedback or actionable steps for the authors to take, which limits its overall impact. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of the approach to two views and suggests that it should be able to generalize to more views. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this limitation or what changes could be made to the approach. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitation of the approach to two views and suggests that it should be able to generalize to more views. However, it does not specify which part of the paper this issue is related to, such as a particular section or methodology. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in questioning the limitation of the approach, but it lacks detailed guidance on how to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitation of the approach to two views and suggests that it should be able to generalize to more views. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the assertion that the system should be able to generalize to more views without difficulty. As a result, the claim is considered 1, as it lacks sufficient support for the authors to understand or address the issue effectively.", "helpfulness_rationale": "The review comment raises a question about the limitation of the approach to two views and suggests that it should be able to generalize to more views. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this limitation or what changes could be made to the approach. The comment is 3 as it points out a potential issue that could enhance the paper\"s impact, but it does not provide actionable advice or detailed insights to help the authors improve their draft. Therefore, it aligns with a score of 3, as it offers some direction but could be more comprehensive and detailed."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the suitability of the metrics used for evaluating continual learning in specific settings, noting that these metrics are not applicable when task boundaries are unknown or nonexistent. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative metrics. The comment lacks concrete actions or suggestions for improvement, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the suitability of the metrics used for evaluating continual learning in specific settings, noting that these metrics are not applicable when task boundaries are unknown or nonexistent. However, it does not specify which part of the paper discusses these metrics or the datasets used, making it difficult for the authors to identify the exact section being addressed. While the comment is specific about the issue of metric applicability, the lack of grounding makes it challenging for the authors to understand where to focus their attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the suitability of the metrics used for evaluating continual learning in specific settings, noting that these metrics are not applicable when task boundaries are unknown or nonexistent. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 3, as it lacks the necessary depth and context to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the metrics used for evaluating continual learning, specifically noting that they are not suitable for settings where task boundaries are unknown or nonexistent. This critique is important because it highlights a limitation in the paper\"s evaluation methodology, which could affect the validity of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their evaluation approach. While it points out a significant concern, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is rated as 3, as it provides a clear critique but lacks detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses concern about the ablations in the paper, noting that they seem to raise many questions. However, it does not provide any specific guidance or suggestions on how the authors should improve the experiment setup or address these questions. The comment lacks explicit actions or concrete details, leaving the authors uncertain about what changes to make. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses concern about the ablations in the paper, noting that they seem to raise many questions. However, it does not specify which part of the paper the ablations are discussed in, nor does it provide any guidance on how to address these questions. The lack of specific information about the sections or content being referred to makes it difficult for the authors to understand the exact issue being raised. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point expresses concern about the ablations in the paper, noting that they seem to raise many questions. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without detailed justification or examples, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses concern about the ablations in the paper, noting that they seem to raise many questions. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might address these concerns or improve the experiment setup. Without detailed guidance or examples, the authors may find it challenging to understand the issues or how to resolve them. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the error analysis on the movie dataset, noting that it is missing. It suggests that the authors should provide details on the cases where the model fails, which would be beneficial for other researchers to continue on this task. The comment is explicit in identifying the missing information and provides a clear action for the authors to take, namely to include the error analysis and detail the cases of failure. This explicit guidance makes the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the error analysis on the movie dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the details of the cases where the model fails, which is crucial for other researchers to continue on this task. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the error analysis on the movie dataset is missing, which is a factual observation. However, it does not provide any reasoning or evidence to support why this is a significant issue or how it impacts the paper. Without additional context or explanation, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the error analysis on the movie dataset is missing. It highlights the importance of providing details on the cases where the model fails, as this information is crucial for other researchers to build upon the work. The comment is clear and actionable, offering a direct suggestion for improvement. However, it could be more helpful if it provided additional guidance on how to conduct or present the error analysis effectively. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper by noting the absence of a separate part or subsection dedicated to introducing the inference strategy. While it points out the missing element, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take to include this information. The comment is somewhat vague, as it leaves the authors to infer the need for a detailed explanation of the inference strategy. Therefore, the comment is 3, aligning with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the approach method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue: the lack of a separate part or subsection to introduce the inference strategy, particularly how multiple prompts are used in the test stage. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point claims that the paper lacks a separate part or subsection to introduce the inference strategy, specifically mentioning the use of multiple prompts in the test stage. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by pointing out the absence of a detailed explanation of the inference strategy, particularly how multiple prompts are used in the test stage. This feedback is clear and actionable, as it directs the authors to include a separate part or subsection that elaborates on this aspect. By addressing this gap, the authors can enhance the clarity and completeness of their paper, making it more informative and easier to understand. The comment is 4 as it provides a clear direction for improvement, though it could be further detailed to offer more specific guidance on how to implement the suggested change. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the low results obtained using only ML in the ablation experiments, noting that these results are even lower than those of some simple early methods. However, it does not provide any explicit or implicit suggestions or actions for the authors to take to address this issue. The comment lacks guidance on how the authors might investigate or improve their results, leaving them without a clear path forward. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment expresses a concern about the low results obtained using only ML in the ablation experiments, noting that these results are even lower than those of some simple early methods. However, it does not specify which part of the paper this issue is related to, such as the methodology or experimental results sections. The lack of specific referencing makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the results, it is 1 because it does not provide clear guidance on which part of the paper to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern about the low results obtained using only ML in the ablation experiments, noting that these results are even lower than those of some simple early methods. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand or address the issue raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the low results obtained using only ML in the ablation experiments, noting that these results are even lower than those of some simple early methods. While the comment identifies a potential issue with the experimental setup or methodology, it lacks specific guidance or suggestions on how the authors might address this concern. The feedback is 3 as it points out a potential area for improvement, but it does not provide actionable steps or detailed explanations to help the authors enhance their work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. While the comment implies an action, it does not explicitly instruct the authors to include a detailed plan or specify how to address the limitations. The action is somewhat vague, as it lacks concrete guidance on what constitutes a detailed plan or how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. However, it does not specify which part of the paper discusses the limitations, making it difficult for the authors to identify the exact section or aspect that needs attention. The comment is specific in its suggestion to provide a detailed plan, but it lacks grounding as it does not mention the specific part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. However, the comment lacks specific details or examples of how this detailed plan might be structured or what actions could be taken. Without additional information or guidance, the authors may find it challenging to understand how to implement this suggestion effectively. Therefore, the comment is considered 2, as it provides some indication of what needs to be addressed but lacks sufficient detail or examples to be 5.", "helpfulness_rationale": "The review comment suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. This feedback is 3 as it identifies a specific area for improvement\u2014addressing the limitations\u2014but lacks depth and specificity. The authors are given a direction to enhance their work, but the comment does not provide detailed guidance or examples of how to develop this plan. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point mentions that similar methods have been proposed for multitask learning but does not discuss them in the paper, referencing a specific work [1]. While it implicitly suggests that the authors should discuss these methods, the action is not explicit, and the authors are left to infer that they need to address this gap. The comment lacks concrete guidance on how to incorporate or discuss these methods, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"multitask learning,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that similar methods have been proposed but are not discussed in the paper, referencing a specific work [1]. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the label is 5.", "verifiability_rationale": "The review point claims that similar methods have been proposed for multitask learning but are not discussed in the paper, referencing a specific work [1]. This claim is 3 as it provides a reference to support the assertion that similar methods are missing. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that similar methods have been proposed for multitask learning but are not discussed. This feedback is valuable as it highlights an area where the authors could enhance their work by providing a more comprehensive discussion of related methods. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address this gap, such as recommending additional references or sections to include. Overall, the comment is 3 as it identifies a meaningful weakness but lacks depth in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors have compared the computational cost of FedMITR with other methods. While it implies that a comparison should be made, it does not explicitly instruct the authors to perform this comparison or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to compare the computational cost. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether the authors have compared the computational cost of FedMITR with other methods. However, it does not specify which part of the paper this comparison should be made or which methods are being referred to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in questioning the comparison of computational costs, but without explicit guidance on how to conduct this comparison, it lacks specificity. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about whether the authors have compared the computational cost of FedMITR with other methods. However, it does not provide any specific evidence, reasoning, or references to support this claim. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about whether the authors have compared the computational cost of FedMITR with other methods. While it identifies a potential area for improvement, it does not provide specific guidance or suggestions on how to conduct this comparison or what aspects of the computational cost should be considered. The comment is 3 as it highlights a potential oversight, but it lacks depth and actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should use a generic external knowledge base to avoid issues with points 1 and 2, as demonstrated in Figure 3. However, it does not provide explicit guidance on how to implement this suggestion or clarify what specific issues are being addressed. The comment is vague and lacks concrete details, making it difficult for the authors to understand how to apply the proposed solution. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests using a generic external knowledge base to avoid issues with points 1 and 2, referencing Figure 3. However, it does not specify which part of the paper these points correspond to, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific about the solution, the lack of grounding makes it challenging for the authors to understand the context and address the issue effectively. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the writing is too confusing, making it difficult for the authors to understand if the suggested solution is valid. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the writing, specifically mentioning that points 1 and 2 could be avoided by using a generic external knowledge base, as demonstrated in Figure 3. However, the comment lacks specific guidance on how to improve the writing or address the confusion. While it points out a potential area for improvement, it does not provide actionable advice or detailed suggestions, making it 3. The authors may gain some insight into the issue but would need to infer the exact nature of the problem and how to address it. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the theoretical foundation of the paper, specifically questioning the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization. However, it does not provide explicit instructions or suggestions on how the authors might address these issues. The comment implies that the authors should consider providing these details, but it lacks concrete guidance on how to do so. As a result, the authors are left without a clear understanding of what specific actions to take to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the theoretical foundation of the paper, specifically mentioning the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization. It implies that the authors should provide these details, but it does not explicitly mention which part of the paper these issues are discussed in. This makes it difficult for the authors to pinpoint the exact section or part of the paper that needs improvement. However, the comment is specific in detailing what needs to be addressed, such as the existence and smoothness of the solution and the guarantees of the discretization. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis is weak due to the lack of theoretical support, specifically regarding the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization. The comment provides specific examples of what is missing, such as the existence and smoothness of the solution and the guarantees of the discretization. However, it does not offer detailed reasoning or references to support these claims, making the claim 3. The authors would need to infer the need for these details, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the theoretical foundation of the paper, specifically regarding the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization. It provides specific examples of what is missing, such as the existence and smoothness of the solution and the guarantees of the discretization. However, the comment does not offer detailed guidance or suggestions on how the authors might address these issues or improve the theoretical analysis. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for the authors to consider but lacks depth and specificity in its suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point indicates that the model has several components with hyperparameters that are not fully provided, requiring the authors to trace them in the source code. This feedback is explicit, as it clearly states what information is missing and what action the authors should take to address it. The action is also concrete, as it specifies exactly what needs to be done: trace the hyperparameters in the source code. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly states that the model has many components whose hyperparameters are not fully provided, requiring the authors to trace them in the source code. This provides a clear direction for the authors to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model has many components whose hyperparameters are not fully provided, requiring the authors to trace them in the source code. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the model has several components with hyperparameters that are not fully provided, requiring the authors to trace them in the source code. This feedback is clear and actionable, as it highlights a potential area for improvement in the paper. However, the comment could be more helpful if it provided additional guidance on how the authors might address this issue or suggested specific steps they could take to ensure the completeness of their work. Despite this, the comment is 4 as it directs the authors to a critical aspect of their draft that needs attention."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include qualitative results, possibly with zoomedin views, for cases where previous methods failed but are okay with the proposed method. It also recommends showing failure cases and analyzing the limitations. While the comment provides a clear direction for improvement, it lacks specific guidance on how to present these qualitative results or what specific aspects of the failure cases should be analyzed. The action is explicit but somewhat vague, as it does not detail the exact steps or methods for generating and presenting these results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including qualitative results, zoomedin views, and analysis of failure cases, which are relevant to the paper. However, it does not specify which part of the paper these elements should be included in, making it weakly grounded. The comment is specific in its suggestions for improvement, such as showing qualitative results and analyzing limitations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including qualitative results, zoomedin views, and analysis of failure cases, which are valuable additions to the paper. However, the comment lacks specific examples or references to support these suggestions, making it difficult for the authors to understand how to implement these improvements. The feedback is 3 as it provides a general direction for improvement but does not offer detailed guidance or evidence to support the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the paper by including qualitative results, zoomedin views, and analysis of failure cases. These suggestions are actionable and offer a clear direction for enhancing the paper\"s impact and comprehensiveness. However, the comment could be more helpful if it provided additional guidance on how to present these qualitative results or what specific aspects of the failure cases should be analyzed. Despite this, the feedback is 4 as it directs the authors towards meaningful improvements that could strengthen the paper."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting that it does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any explicit or implicit actions for the authors to take to address this gap. The comment lacks guidance on how the authors might evaluate this tax or what specific aspects of the method should be considered. Without concrete suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a gap in the paper by noting that it does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint where the evaluation should be conducted. Additionally, the comment does not provide specific guidance on how to evaluate the interpretability tax, leaving the authors without a clear direction. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, the comment lacks specific evidence or references to support this claim. Without detailed reasoning or examples, the authors may find it challenging to understand why this omission is significant or how to address it. The comment is therefore considered 1, as it does not provide sufficient justification for the claim.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that it does not evaluate the magnitude of the interpretability tax associated with the method. This is a specific and actionable piece of feedback that could help the authors improve their draft by providing a clear direction for further analysis or evaluation. However, the comment could be more helpful if it suggested specific ways to evaluate the tax or provided examples of how to do so. Overall, the comment is 3 as it highlights an important area for improvement, but it lacks depth and guidance, making it only partially beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should include some training losses. While the comment implies that the authors should provide training losses to address the question, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given a clear direction on how to include the training losses or what specific information should be included. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should include some training losses. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The comment is 1 as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment is specific in that it suggests including training losses to address the question of stability. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should include some training losses. However, it does not provide any reasoning, examples, or references to support why this is a concern or how it might impact the results. The comment lacks specific details or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should include some training losses. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance or suggestions on how to address the issue. The comment is 3 as it points out a potential concern, but it does not offer actionable advice or examples to help the authors improve their draft. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the paper overclaims the strength of the proposed BC loss in theoretical analysis, suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are essentially the same concept from different viewpoints. However, the comment does not provide explicit guidance on how the authors should address this overclaiming or what specific aspects need to be revised. The action is implicit and vague, as it does not offer concrete steps for the authors to take. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"theoretical analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the overclaiming of the BC loss and provides a clear explanation of why the different aspects are considered the same concept. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper overclaims the strength of the proposed BC loss in theoretical analysis, suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are essentially the same concept from different viewpoints. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without further elaboration or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential overclaiming of the proposed BC loss in the theoretical analysis section, suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are essentially the same concept from different viewpoints. This feedback is 3 as it points out a potential issue with the paper\"s claims, but it lacks specific guidance on how the authors might address this concern or what changes could be made to clarify the distinction. The comment provides a clear direction for improvement but does not offer detailed suggestions or actionable steps, which limits its overall impact on the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the relevance of the proposed method to the authors\" motivations in the abstract section, specifically questioning the effectiveness of automatic scores and the cost of human evaluation. It suggests that arenabased evaluation systems, such as Chatbot Arena, may not be suitable for evaluating single dialogue systems. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to improve their draft. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to respond or make changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses concerns about the relevance of the proposed method to the authors\" motivations in the abstract section, specifically questioning the effectiveness of automatic scores and the cost of human evaluation. It also critiques the use of arenabased evaluation systems like Chatbot Arena for evaluating single dialogue systems, suggesting that these systems may not be suitable for the current scorebased evaluation systems. However, the comment does not specify which part of the paper discusses the abstract section or the evaluation methods, making it weakly grounded. The comment is specific in detailing the issues with the proposed method and the critique of arenabased evaluation systems, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the relevance of the proposed method to the authors\" motivations in the abstract section, specifically questioning the effectiveness of automatic scores and the cost of human evaluation. It critiques the use of arenabased evaluation systems, such as Chatbot Arena, for evaluating single dialogue systems, suggesting that these systems may not be suitable for the current scorebased evaluation systems. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is 3, as it provides a general critique but lacks detailed evidence or reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the relevance of the proposed method to the authors\" motivations in the abstract section, specifically questioning the effectiveness of automatic scores and the cost of human evaluation. It critiques the use of arenabased evaluation systems, such as Chatbot Arena, for evaluating single dialogue systems, suggesting that these systems may not be suitable for the current scorebased evaluation systems. While the comment identifies a potential issue with the proposed method, it lacks specific guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback is 3 as it points out areas for improvement but does not provide detailed actionable advice. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind using focal loss in regression tasks, specifically focusing on the potential issue of lower gradients for easy samples leading to inaccurate predictions. It suggests that the authors might only be aiming for a unified form without considering the differences between classification and regression tasks. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit and vague, as it leaves the authors to infer the need for further clarification or discussion. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the use of focal loss in regression tasks, specifically questioning its application in the context of IoU regression. It highlights the difference between focal loss\"s effectiveness in classification tasks, where it handles class imbalance, and its potential issues in regression, where lower gradients for easy samples might lead to inaccurate predictions. However, the comment does not specify which part of the paper discusses the use of focal loss or the IoU regression, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific about the issue of focal loss in regression, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the rationale behind using focal loss in regression tasks, specifically focusing on the potential issue of lower gradients for easy samples leading to inaccurate predictions. It highlights the difference between focal loss\"s effectiveness in classification tasks and its potential issues in regression, particularly in the context of IoU regression. However, the comment does not provide specific examples, references, or detailed reasoning to support its claim. The lack of detailed justification makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some context but lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a valid concern about the use of focal loss in regression tasks, specifically questioning its effectiveness in IoU regression. It points out that while focal loss is effective for class imbalance in classification, its lower gradients for easy samples might lead to inaccurate predictions in regression tasks. This observation suggests that the authors might be aiming for a unified form without considering the nuances between classification and regression tasks. However, the comment lacks specific guidance or suggestions on how the authors could address this issue or improve their approach. While it identifies a potential area for improvement, it does not provide actionable steps or detailed insights, making it 3. Therefore, the comment aligns with a score of 3, as it offers a clear observation but requires further elaboration or guidance for the authors to fully benefit from it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the scalability of the method as the corpus size or hidden dimension size is increased. However, it does not provide any explicit or implicit suggestions or actions for the authors to take to address this question. The comment lacks guidance on how the authors might investigate or discuss the scalability of their method, leaving them without a clear path forward. As a result, the comment is 1, as it does not offer any actionable feedback or suggestions for improvement.", "grounding_specificity_rationale": "The comment raises a question about the scalability of the method as the corpus size or hidden dimension size is increased. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. Without explicit mention or context, the authors may find it challenging to identify the exact area of the paper being addressed. Additionally, the comment does not provide specific guidance or suggestions on how to address this scalability issue. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the scalability of the method as the corpus size or hidden dimension size is increased. However, it does not provide any claim, suggestion, or critique that requires verification or justification. The comment is purely descriptive and does not offer any insight or guidance for the authors. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the scalability of the method as the corpus size or hidden dimension size is increased. This is a relevant concern for the authors, as it pertains to the practical applicability and robustness of their method. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue. It lacks actionable advice or insights that could help the authors improve their work. As a result, the comment is 2, as it identifies a potential area for improvement but does not offer any concrete steps or suggestions for the authors to take. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether the authors should use a better encoder, such as RoBERTabase, instead of BERT to improve the results. While it suggests an alternative model, it does not provide explicit guidance on how to implement this change or what specific improvements might be observed. The action is implicit and somewhat vague, as the authors need to infer that they should experiment with a different encoder and potentially report the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions whether a better encoder, such as RoBERTabase, could improve the results compared to using BERT. However, it does not specify which part of the paper this question pertains to, such as the methodology or experimental setup. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in suggesting an alternative model but does not provide detailed guidance on how to implement or evaluate this change. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether a better encoder, such as RoBERTabase, could improve the results compared to using BERT. While it suggests an alternative model, it does not provide specific evidence or reasoning to support this claim. The comment lacks detailed justification or examples to substantiate the assertion that a better encoder would lead to improved results. Therefore, the claim is considered 2, as it is somewhat supported but lacks sufficient detail or references.", "helpfulness_rationale": "The review comment raises a pertinent question about the potential benefits of using a better encoder, such as RoBERTabase, instead of BERT. It suggests that the authors should consider experimenting with a more advanced model to potentially improve their results. However, the comment lacks specific guidance on how to implement this change or what kind of improvements might be expected. While it provides a direction for improvement, it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it identifies a potential area for enhancement but does not fully support the authors in making the necessary adjustments. The score aligns with a rating of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that it does not provide information about the type of GPUs used and the inference time during testing. While the comment identifies a gap in the paper\"s content, it does not offer any explicit or implicit suggestions on how the authors might address this issue. The authors are left without guidance on what additional information to include or how to improve the paper. Therefore, the comment is 1, as it lacks any direction for the authors to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the missing information regarding the type of GPUs and inference time when testing. This provides the authors with a clear understanding of what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a factual issue regarding the lack of information about the type of GPUs and inference time when testing. While it points out a missing detail, it does not provide any reasoning, examples, or references to support why this information is important or how it impacts the paper. The comment is factual but lacks depth and context, making it 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by pointing out the absence of information regarding the type of GPUs used and the inference time during testing. This feedback is clear and actionable, as it directs the authors to include these details to enhance the completeness and clarity of their work. By addressing this issue, the authors can provide a more comprehensive understanding of their experimental setup and results, which is crucial for the reproducibility and interpretability of their findings. Therefore, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This comment provides a specific action for the authors to take, indicating that they should adjust the connections in the figure to accurately represent the data. The action is explicit and concrete, as it clearly specifies what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear and actionable suggestion for improving the figure by adjusting the connections between the Second Inpainted Images, the Inpainted Image, and the Images Masked by Second Masks. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This comment is specific and provides a clear suggestion for improvement, but it does not offer any reasoning or evidence to support why this adjustment is necessary or beneficial. Without additional context or justification, the authors may find it challenging to understand the basis for this suggestion. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, suggesting that the Perceptual Metric should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This feedback is clear and actionable, providing the authors with a specific direction to improve the accuracy and clarity of their figure. By addressing this suggestion, the authors can enhance the visual representation of their data and ensure that the figure accurately reflects the intended connections. This level of detail and specificity makes the comment 5 for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of adaptive gradient methods instead of SGD and suggests that such a method might affect the findings, particularly by amplifying updates for weights associated with hard features. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or incorporate it into their work. The action is implicit, as the authors would need to infer that they should consider the impact of adaptive gradient methods on their findings and potentially explore this aspect in their analysis or experiments. The comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the use of adaptive gradient methods instead of SGD and suggests that such a method might affect the findings, particularly by amplifying updates for weights associated with hard features. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The authors may need to infer that this relates to the methodology or experimental setup, but the lack of explicit mention makes it weakly grounded. The comment is specific in its inquiry about the potential impact of adaptive gradient methods, but without grounding, the authors may struggle to identify the exact area to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of adaptive gradient methods instead of SGD and suggests that such a method might affect the findings, particularly by amplifying updates for weights associated with hard features. However, the comment does not provide any specific reasoning, examples, or references to support the claim that adaptive gradient methods could affect the findings or amplify updates. Without detailed justification or evidence, the claim remains speculative and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the use of adaptive gradient methods instead of SGD and suggests that such a method might affect the findings, particularly by amplifying updates for weights associated with hard features. This feedback is 3 as it identifies a potential area for consideration and prompts the authors to think critically about the implications of their choice of optimization method. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this concern or incorporate it into their work. The authors would need to infer that they should consider the impact of adaptive gradient methods on their findings and potentially explore this aspect in their analysis or experiments. While the comment offers a starting point for improvement, it could be more helpful with additional details or suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two specific issues with the experiments: the limited types of teacher architectures and the age of the compared methods. While it identifies these areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to expand the types of teacher architectures and include more recent methods in their comparisons. This lack of explicit and detailed guidance makes the comment 3, as the authors can understand the need for improvement but may struggle to implement it effectively. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"21) There are limited types of teacher architectures\" and \"22) Most compared methods are proposed before 2019 (see Tab.\" This allows the authors to accurately identify the parts of the paper being addressed. Additionally, the comment is specific because it clearly specifies the issues with the limited types of teacher architectures and the age of the compared methods, providing clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are not sufficient enough, specifically noting the limited types of teacher architectures and the age of the compared methods. While the comment identifies these issues, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the need for more comprehensive experiments, but without explicit guidance or references, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the experiments: the limited types of teacher architectures and the age of the compared methods. While it points out these issues, it does not provide specific suggestions or guidance on how to address them. The authors are left to infer that they need to expand the types of teacher architectures and include more recent methods in their comparisons. This feedback is 3 as it highlights important areas for improvement, but it lacks depth and actionable suggestions, making it only 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic and suggests an interesting comparison between sequential and combinational designs. However, it does not provide explicit or implicit actions for the authors to take, such as conducting the comparison or providing feedback on the results. The comment lacks concrete guidance on how the authors should address this suggestion, leaving them without a clear path forward. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the performance of the proposed method in pure combinational logic and suggests an interesting comparison between sequential and combinational designs. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is 1 as it does not provide explicit references to specific sections, tables, or figures. Additionally, while it suggests an interesting comparison, it does not specify what needs to be compared or how this comparison should be conducted. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic and suggests an interesting comparison between sequential and combinational designs. However, it does not provide any specific evidence, reasoning, or references to support the claim that the method performs better in pure combinational logic. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises an interesting question about the performance of the proposed method in pure combinational logic and suggests a comparison between sequential and combinational designs. This feedback is 3 as it prompts the authors to consider an additional aspect of their method\"s performance and could lead to a more comprehensive evaluation. However, the comment lacks specific guidance on how to conduct this comparison or what results to expect, making it 3 but not fully actionable. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the practicality of the paper, noting that the use of known causal relationships might not be feasible in practice due to the unavailability or inaccuracy of prior knowledge. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the practicality of their work. The authors are left without guidance on how to respond to this concern, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the practicality of the paper, specifically questioning the use of known causal relationships due to the unavailability or inaccuracy of prior knowledge. However, it does not specify which part of the paper this concern pertains to, such as a particular section or methodology. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment is specific in identifying the issue with the use of known causal relationships, but it lacks detailed guidance on how to address this concern. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the practicality of the paper, specifically questioning the use of known causal relationships due to the unavailability or inaccuracy of prior knowledge. While the comment highlights a potential limitation, it does not provide specific examples or references to support the claim that prior knowledge is often unavailable or inaccurate. This lack of detailed justification makes the claim 3, as the authors may need to infer the basis of the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the practicality of the paper, specifically questioning the use of known causal relationships due to the unavailability or inaccuracy of prior knowledge. This is a valid point that highlights a potential limitation in the paper\"s approach. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the practicality of their work. Without actionable feedback or suggestions, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a concern but lacks depth and direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific area in the paper, Section 4.3, where the authors should include comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback is explicit and provides a clear action for the authors to take, namely to add these experiments to better showcase the unique advantages or potential shortcomings of the proposed method. The comment is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback provides a clear direction for the authors to improve the paper by including these additional experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This claim is 3 as it suggests a specific area for improvement, but it does not provide detailed reasoning or examples to support why these comparisons are necessary or how they would enhance the paper. The authors would need to infer the need for such comparisons to fully understand the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area in the paper where additional comparative experiments are needed to better showcase the advantages or potential shortcomings of the proposed method. By suggesting the inclusion of experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2, the comment provides a clear and actionable direction for the authors to improve their draft. This feedback is 4 as it offers a specific and constructive suggestion that could significantly enhance the paper\"s comprehensiveness and impact. However, it could be more helpful if it included more detailed reasoning or examples of how these experiments would be conducted or what specific outcomes they would demonstrate. Overall, the comment is 4, aligning with a score of 4."}
